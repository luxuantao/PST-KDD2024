<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<address>
									<postCode>97006</postCode>
									<settlement>Hillsboro</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TCAD.2010.2061613</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-Networks-on-chip (NoCs) have recently emerged as a scalable alternative to classical bus and point-to-point architectures. To date, performance evaluation of NoC designs is largely based on simulation which, besides being extremely slow, provides little insight on how different design parameters affect the actual network performance. Therefore, it is practically impossible to use simulation for optimization purposes. In this paper, we present a mathematical model for on-chip routers and utilize this new model for NoC performance analysis. The proposed model can be used not only to obtain fast and accurate performance estimates, but also to guide the NoC design process within an optimization loop. The accuracy of our approach and its practical use is illustrated through extensive simulation results.</p><p>Index Terms-Multiprocessor systems-on-chip (MPSoCs), networks-on-chip (NoCs), performance analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>N ETWORKS-on-chip (NoCs) communication architec- tures offer a scalable and modular solution for implementing complex systems which consist of a large number of heterogeneous components <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr">[15]</ref>. NoCs target single chip multiprocessor systems that possibly implement multiple applications. The complexity of such systems, as well as the tight requirements in terms of power, performance, cost and time-to-market, place a tremendous pressure on the design team. To cope with this situation, application and platform models are usually developed separately <ref type="bibr" target="#b14">[16]</ref>, <ref type="bibr" target="#b16">[18]</ref>. After that, the application is mapped to the target platform and the resulting system is evaluated to ensure its compliance with the design specifications, as depicted in Fig. <ref type="figure">1</ref>.</p><p>The application model comes with some workload characterization (usually given in probabilistic terms), while the platform itself may come with some low-level information from the designers, depending on the targeted level of accuracy for this type of evaluation. These models are used during the mapping step when the target application is mapped onto the target architecture. Next, a performance analysis step is needed to determine whether or not the chosen application-architecture combination satisfies the imposed design constraints. Finally, the information provided during the performance analysis step is used to refine the communication architecture and decide the communication topology [e.g., bus, point-to-point (P2P)], buffer space, and so on <ref type="bibr" target="#b17">[19]</ref>. The success of this methodology depends critically on the availability of adequate power and/or performance analysis tools that can guide the overall design process. In order to be used in an optimization loop, such as the one shown in Fig. <ref type="figure">1</ref>, the analysis needs to be tractable, while providing meaningful feedback to the designer. Time consuming simulations can only come into the picture at later stages, typically after the design space is already reduced to only a few practical choices (i.e., the outer loop in Fig. <ref type="figure">1</ref>).</p><p>We note that for traffic with guaranteed service <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b19">[21]</ref>, accurate performance figures can be easily derived. However, performance analysis for best effort traffic relies largely on simulation or performance metrics derived under idealized conditions. For example, the average hop count is commonly used to approximate the average packet latency <ref type="bibr" target="#b20">[22]</ref>. While this metric ignores the queuing delays and network contention, approaches that do consider queuing delays often make other idealistic assumptions such as exponential service times, infinite buffers, and so on <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Likewise, analysis of power consumption of the NoC architectures depends largely on simulation <ref type="bibr" target="#b23">[25]</ref>, <ref type="bibr" target="#b29">[31]</ref>.</p><p>In order to advance the state-of-the-art in NoC design, this paper presents a formal approach for NoC performance analysis. At the very heart of the proposed methodology lies a new router model which is basically based on a set of FIFO buffers interconnected by a switch as shown in Fig. <ref type="figure">2</ref>. The newly proposed router model enables us to derive a closed-form expression for the average number of packets at each input buffer in the router under Poisson traffic arrival assumption for the header flits. We first show that the proposed model retrieves the traditional M/G/1 queuing model as a particular case when the number of input ports in the router is set to one. Then, we show that the proposed performance model can also capture as special cases communication architectures where the input buffers are connected via shared buses or P2P links.</p><p>The proposed network performance approach provides three performance metrics, namely, average buffer utilization of each buffer, average packet latency per flow, and maximum network Fig. <ref type="figure">1</ref>. Proposed performance analysis methodology is illustrated here using the Y-chart scheme <ref type="bibr" target="#b16">[18]</ref>. Fig. <ref type="figure">2</ref>. Router model as a collection of FIFO buffers is illustrated for a router with four input channels. The arrival rates to the router are described by the diagonal matrix , and the average number of packets at each input channel is described by N.</p><p>throughput. Consequently, the proposed analytical framework can be easily used for design and optimization purposes, as well as obtaining quick performance estimates. At the same time, using the newly proposed performance model, we are able to formally prove that dedicated P2P links result in better performance than router-based communication, while routerbased communication results in better performance figures than shared buses under identical input traffic and service time distributions. Finally, we utilize the proposed model to analyze the performance of a basic NoC, given its topology, routing algorithm, as well as the driver application and its mapping to the network nodes.</p><p>The remaining part of this paper is organized as follows. Section II surveys the related work and highlights our main contributions. Section III states our assumptions and presents the router model used for power/performance analysis. Sections IV and V present our techniques for router and network performance analysis, respectively. We summarize the overall performance analysis framework in Section VI and present experimental results in Section VII. Finally, Section VIII concludes the paper by summarizing our major contributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Related Work</head><p>The design of application-specific NoCs is commonly formulated as a constrained optimization problem <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b20">[22]</ref>, <ref type="bibr" target="#b21">[23]</ref>.</p><p>Therefore, performance analysis techniques that can be used in optimization loops are extremely important. The authors in <ref type="bibr" target="#b12">[13]</ref> consider the buffer sizing problem and present a performance model based on queuing theory. However, the approach is applicable to only packet switched networks. The work in <ref type="bibr" target="#b9">[10]</ref> presents a wormhole delay model applicable to routers with single flit buffers and assumes that packet size dominates the overall latency. For an extensive review of recent literature on such optimization approaches we refer the reader to <ref type="bibr" target="#b18">[20]</ref>.</p><p>Related work about analysis techniques for wormhole routing comes mainly from parallel computing and macro-network research communities. Many studies target specific network topologies such as k-ary n-cubes <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b6">[7]</ref> and hypercubes <ref type="bibr" target="#b22">[24]</ref>. The study presented in <ref type="bibr" target="#b8">[9]</ref> is not restricted to a particular topology, but it assumes an exponential message length distribution and it has a very high complexity for high dimensional networks. A more general analytical model for wormhole routing is presented in <ref type="bibr" target="#b13">[14]</ref>. The model provides average packet latency estimates using a sophisticated analysis.</p><p>The main contribution of this paper is a novel performance model for on-chip routers which generalizes the traditional delay models for single queues and consequently captures the classical results as a special case. This new model is used to develop a thorough performance analysis for wormhole routing with arbitrary size messages and finite buffers under application-specific traffic patterns.</p><p>The performance model we propose has several unique features. More precisely: 1) it directly targets NoCs under application-specific traffic patterns; 2) it supports arbitrary network topologies and deterministic routing; and, finally, 3) it provides not only aggregate performance metrics, such as average latency and throughput, but also feedback about the network behavior at finer granularity (e.g., utilization of all buffers, the average latency experienced at each router, average latency per flow). Given the generality of this newly proposed model, it can be invoked in any loop for NoC optimization (e.g., application mapping <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b20">[22]</ref>, network architecture synthesis <ref type="bibr" target="#b21">[23]</ref>, buffer space allocation <ref type="bibr" target="#b12">[13]</ref>) for fast and accurate performance estimations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. On-Chip Router Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Basic Assumptions and Notation</head><p>We consider input buffered routers with P channels and target wormhole flow control under deterministic routing algorithms. The size of the packets (bits) is denoted by the random variable S, as listed in Table <ref type="table" target="#tab_1">I</ref> along with other parameters. The probability distribution of S is given by the driver application.</p><p>The network channel bandwidth is denoted by W (bits/s). The router service time for the header flit is given by H S . We note that H S is a function of the router design and includes the time to traverse the router (t R ) and the link (t L ). Since the remaining flits follow the header flit in a pipelined fashion, the service time of a packet, excluding the queuing delay (this will be accounted for in Section V), is given by</p><formula xml:id="formula_0">T = H S + S W .<label>(1)</label></formula><p>We denote by x sd (packets/s) the rate of the traffic transmitted from the source node at router s to the destination node at router d. Likewise, the traffic arrival rate of the header flits to input channel i which is routed toward channel j is given by λ ij (packets/s). We assume that the arrival process of the header flits to the router inputs (λ ij ) follows a Poisson process. Note that under this model, the arrival process for the body flits is not assumed to be Poisson; the Poisson assumption refers only to the header flit distribution. This assumption, which is actually quite common in network performance analysis <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, enables us to derive closed loop solutions and show that our model generalizes the classical results for single queue systems.</p><p>We note that our evaluations on the actual distribution of the header inter-arrival times based on the Pearson's chisquare test <ref type="bibr" target="#b24">[26]</ref> (see Section VII-F) show that the Poisson assumption holds pretty well at low and medium traffic rates, and it deviates from the Poisson assumption at high traffic loads. Hence, the accuracy of the average packet latency predicted by the proposed analytical model is expected to degrade only when the network gets closer to its saturation point. However, we note that the degradation in the accuracy of average packet latency is acceptable as long as the saturation point can be predicted accurately. So while, in general, the real arrival process may exhibit a more deterministic or longrange dependent behavior <ref type="bibr" target="#b28">[30]</ref>, our model provides valuable insights into the router design process and reasonably accurate results for pruning the design space at early design stages (see Section VII). Relaxing the Poisson assumption completely is left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Analytical Model of the Router</head><p>In this section, we focus on modeling a single router as a set of first-come first-serve buffers connected by a crossbar switch, as shown in Fig. <ref type="figure">2</ref>. The parameter of interest is the average number of packets at the input buffers, at each input channel 1, ..., P, i.e., N = [N 1 , N 2 , . . . , N P ] T . Since Poisson arrivals see time averages (PASTA), <ref type="foot" target="#foot_0">1</ref> the following equilibrium equation is valid for the input buffer at any channel j:</p><formula xml:id="formula_1">λ j = N j τ j (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where τ j denotes the average time an incoming packet spends in queue j. τ j is composed of the following components: 1) service time of the packets already waiting in the same buffer; 2) the packets waiting in the other buffers of the same router and served before the incoming packet; 3) the residual service time seen by an incoming packet (R). Therefore, for an NoC architecture with non-blocking routers (i.e., the arbitration is invoked only when there is contention for an output port), τ j can be written as</p><formula xml:id="formula_3">I II III τ j = TN j + T P k=1,k =j c jk N k + R<label>(3)</label></formula><p>where the coefficients c jk denote the contention probabilities, i.e., the probability that channels j and k compete for the same output. The second component of the average waiting time [i.e., term II in (3)] applies only to those packets that will be served before the incoming packet. More precisely, the fraction of packets that will be served before the incoming packets is captured by the coefficients c ij 's which represent the contention probabilities among the packets arriving at ports i and j. This makes our approach an average-case rather than a worst-case type of analysis. The computation of these contention probabilities is illustrated in Section III-C. Note also that the average time an incoming packet spends in queue j is derived under stability (the utilization of the network is much smaller than 1) and strict stationary network assumptions. Moreover, since we assume that the packet arrival processes obey a Poisson law, the average estimates of any performance metric converge to the long run time averages. Depending on the output channel requested by the incoming packet and the router scheduling policy (e.g., priority, Round Robin, and so on), an incoming packet can be served earlier than a packet that is already waiting in one of the other buffers. In the following, we assume a Round Robin policy, but the results can be extended for other scheduling disciplines. Round Robin arbitration ensures that the router bandwidth is utilized equally by all the input ports, as detailed in Section III-C where we illustrate the computation of the contention probabilities. For example, if a priority-based arbitration is used, then the average packet latency needs to be different for each input port. More precisely, the port with the highest priority would have the smallest latency, basically the router service time plus the residual time. Similarly, the latency of the packets that arrive at all other ports would need to only consider the ports with higher priorities.</p><p>Let C j be the row vector C j = [c j1 , c j2 , ..., c jP ] of the contention probability matrix C, where c jj = 1. Then, (2) can be written using τ j from (3) as</p><formula xml:id="formula_4">λ j = N j TC j N + R since C j N = N j + P k=1,k =j c jk N k</formula><p>so re-arranging the terms yields</p><formula xml:id="formula_5">λ j TC j N + λ j R = N j . (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>Equation ( <ref type="formula" target="#formula_5">4</ref>) describes the equilibrium condition of the buffer at the input channel j only. For the entire router, we denote the arrival rates ( ), the contention matrix (C), and the residual time (R) by</p><formula xml:id="formula_7">= ⎡ ⎢ ⎢ ⎣ λ 1 0 . . . 0 0 λ 2 . . . 0 . . . . . . . . . . . . 0 0 . . . λ P ⎤ ⎥ ⎥ ⎦ P×P C = ⎡ ⎢ ⎢ ⎣ C 1 C 2 . . . C P ⎤ ⎥ ⎥ ⎦ P×P R = R ⎡ ⎢ ⎢ ⎣ 1 1 . . . 1 ⎤ ⎥ ⎥ ⎦ P×1 .</formula><p>Then, the equilibrium condition for the router can be written as</p><formula xml:id="formula_8">T CN + R = N (I − T C) N = R. Finally N = (I − T C) −1 R. (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>The router model described by ( <ref type="formula" target="#formula_8">5</ref>) provides a closed form expression for the average number of packets at each buffer of the router, given the traffic arrival rates ( ), the packet contention probabilities (C), router design specifications (H S , W ), and target application (S). Equation ( <ref type="formula" target="#formula_8">5</ref>) generalizes the single queue model <ref type="bibr" target="#b1">[2]</ref>; this is one of the major contributions of this paper.</p><p>We note that when det(I − T C) = 0, the packet population in the router grows to infinity. This corresponds to the case when the utilization is 1 for a system with a single queue. The following example gives more intuition for <ref type="bibr" target="#b4">(5)</ref>.</p><p>Example 1: Consider the case P = 1 (i.e., single queue system) and infinite buffers. In this case, (5) simply becomes</p><formula xml:id="formula_10">N = λR 1 − Tλ .</formula><p>Furthermore, the residual waiting time R = λT 2 /2, where T 2 is the second moment of the service time <ref type="bibr" target="#b1">[2]</ref>. As a result</p><formula xml:id="formula_11">N = λ 2 T 2 2 (1 − Tλ) (6)</formula><p>which is precisely the average number of packets in an M/G/1 system. Hence, the commonly studied distributions M/G/1, M/M/1, and M/D/1 become special cases of our newly proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Computation of the Contention Matrix</head><p>Let f ij be the probability that a packet arrives at channel i and leaves the router through channel j. Then, the forwarding probability matrix is defined as</p><formula xml:id="formula_12">F = ⎡ ⎢ ⎢ ⎣ 0 f 12 f 13 . . . f 1P f 21 0 f 23 . . . f 2P . . . . . . . . . . . . . . . f P1 f P2 f P3 . . . 0 ⎤ ⎥ ⎥ ⎦ where f ij = λ ij P k=1 λ ik 1 ≤ i, j ≤ P (7)</formula><p>where λ ij is the traffic arrival rate at input channel i which is routed toward the output channel j.</p><p>Assuming that the forwarding probabilities are independent for a deterministic routing algorithm, the contention probabilities can be written in terms of the forwarding probabilities as</p><formula xml:id="formula_13">1 ≤ i, j ≤ P i = j c ij = P k=1 f ik f jk i = j c ii = 1. (8)</formula><p>Example 2: Consider a router with three ports. The packets arriving at port 1 are directed either to port 2 or port 3 with probability 0.5, that is</p><formula xml:id="formula_14">f 12 = 0.5 f 13 = 0.5.</formula><p>Similarly, suppose that the packets arriving at port 2 are forwarded with probability 0.4 to port 1 and with probability 0.6 to port 3. Finally, assume that packets arriving at port 3 are always routed to port 1. Hence, the forwarding matrix for this simple scenario becomes</p><formula xml:id="formula_15">F = ⎡ ⎣ 0 0.5 0.5 0.4 0 0.6 1 0 0 ⎤ ⎦ .</formula><p>The diagonal entries c 11 , c 22 , c 33 are 1 by definition. Other entries are found using <ref type="bibr" target="#b7">(8)</ref>, as follows:</p><formula xml:id="formula_16">c 12 = 3 k=1 f 1k f 2k = 0.03, c 13 = 3 k=1 f 1k f 3k = 0,<label>and</label></formula><formula xml:id="formula_17">c 23 = 3 k=1 f 2k f 3k = 0.4.</formula><p>In particular, we note that c 13 = 0, i.e., there is no contention, since all packets arriving at port 3 are routed to port 1, while no packet arriving at input port 1 is directed back to output port 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Performance Analysis of Virtual Channel Router, Shared Bus, and P2P Configurations</head><p>In this section, we first show how we model the performance of routers with multiple virtual channels using the proposed approach. Then, we show that the on-chip router model given  captures the shared bus architecture with Round Robin arbitration policy as a special case. Using this model, we formally prove that the on-chip router has always a better performance compared to shared bus architecture. Finally, we compare the performance of on-chip routers with varying number of virtual channels against the performance of a shared bus using a multimedia system as a driver application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Router with Multiple Virtual Channels</head><p>When there are multiple virtual channels connected to each physical port, we can view the router as shown in Fig. <ref type="figure" target="#fig_0">3</ref>. Essentially, the input received from the physical link is statically demultiplexed to the available virtual channels. The on-chip router model developed in Section III is valid when there are multiple virtual channels. In this case, the state of the router is given by the average number of packets at each virtual channel; hence the dimension of the router model becomes the total number of input channels available, i.e., number of physical channels (P) times the number of virtual channels per physical channel (V ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Models for Shared Bus and P2P Architectures</head><p>In Fig. <ref type="figure" target="#fig_1">4</ref>, we show a set of processing elements connected through a shared bus. The PEs write the messages to dedicated buffers which correspond to the input channels of the router shown in Fig. <ref type="figure">2</ref>. When more than one buffer has data ready to be sent, an arbitration phase takes place to determine which flow can use the shared bus. As opposed to the router, where simultaneous connections between different input channels are possible, the shared bus can be used only by a single flow at any given time. This means that the contention probabilities between each pair of buffers [i.e., c jk in <ref type="bibr" target="#b2">(3)</ref>] are equal to one. That is</p><formula xml:id="formula_18">C Bus = ⎡ ⎢ ⎢ ⎣ 1 1 1 . . . 1 1 1 1 . . . 1 . . . . . . . . . . . . . . . 1 1 1 . . . 1 ⎤ ⎥ ⎥ ⎦ . (9)</formula><p>So, we can use (5) to compute the average number of packets in the buffers connected by a shared bus as follows:</p><formula xml:id="formula_19">N Bus = (I − T Bus C Bus ) −1 R (<label>10</label></formula><formula xml:id="formula_20">)</formula><p>where T Bus is the service time of the Bus architecture and C Bus is the contention matrix given in <ref type="bibr" target="#b8">(9)</ref>. Finally, we note that when each buffer shown in Fig. <ref type="figure" target="#fig_1">4</ref> is connected to all the remaining buffers via P2P links, the contention probabilities will be zero (i.e., c ij = 0 when i = j). Consequently, the average number of packets in the buffers connected by dedicated P2P links is found as follows:</p><formula xml:id="formula_21">N P2P = (I − T P2P C P2P ) −1 R (11)</formula><p>where T P2P is the service time of the P2P architecture and the contention matrix becomes the identity matrix. In fact, it is easy to see that (11) models the system as a combination of independent M/G/1 buffers, which is expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analytical Performance Comparisons</head><p>Since we obtained analytical expressions of average number of packets for NoC, shared bus, and P2P architectures, we can now make a qualitative comparison among them. In general, in order to prove that the NoC architecture performs better than the shared bus architecture, we need to prove that N NoC ≤ N Bus , that is</p><formula xml:id="formula_22">N NoC ≤ N Bus (I − T NoC C NoC ) −1 R ≤ (I − T Bus C Bus ) −1 R. (<label>12</label></formula><formula xml:id="formula_23">)</formula><p>Similarly, in order to prove that the P2P architecture performs better than the NoC architecture, we need to prove that N P2P ≤ N NoC . In what follows, we provide a proof based on the properties of the contention matrix C, which makes the major difference between these three architectures.</p><p>In general, the service times T P2P , T NoC , and T Bus depend on the micro-architecture (e.g., how many clock cycles the arbitration, buffer read/write, routing take) and layout design (e.g., how fast each operation is performed or what is the clock frequency). While the shared bus and P2P architectures enjoy the simplicity of the control logic, the clock frequency may be lower due to large capacitive load of the long interconnects. On the other hand, it usually takes more clock cycles to pass through the router, but the router may operate faster due to the structured wiring. Here, we consider the case when the overall service times are equal, i.e., T P2P = T NoC = T Bus , and leave the general solution for future work.</p><p>Lemma 1: Let C 2 = C 1 + δ, where C 1 , C 2 , and δ are P×P square matrices and δ ij ≥ 0, for 1 ≤ i, j ≤ P, i.e., all elements of δ are non-negative. Suppose that T is a positive where the inequality applies to each element of the matrices. <ref type="foot" target="#foot_2">3</ref>That is, each component of (I−T C 2 ) −1 is greater than or equal to each component of (I−T C 1 ) −1 .</p><p>Proof: The proof is given in the Appendix.</p><p>Example 3: Consider the case P = 1. The lemma reduces to the following statement. For a ≥ 0, c 1 ≥ 0, c 2 ≥ 0 and ac 1 &lt; 1, ac 2 &lt; 1.</p><formula xml:id="formula_24">c 2 ≥ c 1 ⇒ 1 1 − ac 2 ≥ 1 1 − ac 1</formula><p>.</p><p>Theorem : Consider P buffers connected by a router (as in Fig. <ref type="figure">2</ref>), by a shared bus (as in Fig. <ref type="figure" target="#fig_1">4</ref>), and via P2P links. Also, assume the following.</p><p>1) The arrival rates to the buffers, λ 1 , λ 2 , . . . , λ P are all identical and follow the assumptions stated in Section III-A.</p><p>2) The service times are all equal, i.e., T P2P = T NoC = T Bus = T, Then, we have that</p><formula xml:id="formula_25">N P2P ≤ N NoC ≤ N Bus . Proof: Let C = C Bus = C NoC + δ NoC = C P2P + δ P2P + δ NoC (<label>15</label></formula><formula xml:id="formula_26">)</formula><p>where δ P2P and δ NoC are matrices with non-zero entries. We can write these relations, since C P2P is the P × P identity matrix, C Bus consists of all ones, and 0 ≤ c i,j ≤ 1 for all entries of C NoC . The average number of packets in the buffers for the shared bus case is given by (5) as follows:</p><formula xml:id="formula_27">N = (I − T C) −1 R.</formula><p>We are interested in the operating domain where the inverse of T C exists, i.e., N is finite. <ref type="foot" target="#foot_3">4</ref> When lim k→∞ (T C) k exists [or equivalently the eigenvalues of the matrix (T C) are less than one <ref type="bibr" target="#b26">[28]</ref>], <ref type="bibr" target="#b22">(24)</ref> holds. Consequently, using the result of Lemma 1, we have</p><formula xml:id="formula_28">(I − T C P2P ) −1 ≤ (I − T C NoC ) −1 ≤ (I − T C Bus ) −1</formula><p>where the equality holds for each component of the P×P matrices. Finally, since all elements of R are greater than or equal to 0 ( R ≥ 0), we use <ref type="bibr" target="#b4">(5)</ref> to prove the theorem</p><formula xml:id="formula_29">(I − T C P2P ) −1 R ≤ (I − T C NoC ) −1 R ≤ (I − T C Bus ) −1 R N P2P ≤ N NoC ≤ N Bus (<label>16</label></formula><formula xml:id="formula_30">)</formula><p>Equation <ref type="bibr" target="#b14">(16)</ref> gives the relation between the average number of packets in queues connected by P2P links, router, and shared bus under identical service times and arrival rates. The relation for arbitrary arrival rates and service times can be analyzed using ( <ref type="formula" target="#formula_8">5</ref>), <ref type="bibr" target="#b9">(10)</ref>, and (11), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Performance Comparisons Using Multimedia System</head><p>The router model described by <ref type="bibr" target="#b4">(5)</ref> provides an analytical approach to analyze the effect of various router parameters on network performance. Consider a multimedia system design <ref type="bibr" target="#b11">[12]</ref> where the packets in the network carry data as 8 × 8 pixel blocks. Each pixel value is represented by 16 bits, so S = 1024 bits. We assume that the channel bandwidth is given by W = 256 × f ch , where f ch is the clock frequency of the router.</p><p>Two major concerns in router design are the number of pipeline stages, i.e., the number of cycles it takes to route the header flit (H S ), and the size of the input buffers (B). To analyze the impact of these parameters on router utilization, we first map the system to a 4×4 mesh network running under XY routing, and determine arrival rates ( ) and the contention matrix C for the bottleneck router. Then, we use <ref type="bibr" target="#b4">(5)</ref> to analyze the impact of H S and B on buffer utilization. Fig. <ref type="figure" target="#fig_3">5</ref> shows the average number of flits in the router (at all buffers) as a function of H S and B. For a given buffer size, the average number of flits in the router increases with increasing service time, as expected. This increase is more severe for larger buffers, since more flits are stored in the buffer before being blocked. Likewise, for a given service time, the router utilization saturates, as the buffer size increases. The saturation occurs earlier for lower service times, as depicted in Fig. <ref type="figure" target="#fig_3">5</ref>. For example, when H S = 2, increasing the buffer size beyond B j = 2 for 1 ≤ j ≤ 5 does not increase the buffer utilization (see point "A" in Fig. <ref type="figure" target="#fig_3">5</ref>), since the router is very fast. On the other hand, for larger service times (e.g., H S = 8, point "B" in Fig. <ref type="figure" target="#fig_3">5</ref>), the saturation point moves further away, i.e., more flits wait in the buffer before being served. This case study illustrates the possible use of the proposed router model as a powerful tool for router design space exploration. Indeed, this model can be used by designers to evaluate possible tradeoffs offered by different design choices (e.g., buffer size, channel width) that are nowadays determined mostly in an ad-hoc manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Network Performance Analysis</head><p>The router model presented in Section III enables the calculation of the average utilization of the input buffers given the traffic input to the router. In this section, we discuss how this model can be actually utilized to analyze the performance of the entire network. More specifically, we compute the average buffer utilization in the router, average packet latency and the maximum network throughput using the proposed model.</p><p>The processing elements connected to the routers, put the new packets first to an egress queue. This queue is connected to one of the input ports of the router. Therefore, packets experience some latency before being injected to the network; M/G/1/m queuing is used to model this queuing delays at the sources. In order to account for these effects, we compute the traffic arrival rates (λ i j ) at input channel j at router i as follows:</p><formula xml:id="formula_31">λ i j = ∀s ∀d x sd (s, d, i, j)<label>(17)</label></formula><p>where is the routing function such that (s, d, i, j) = 1 if the packet sent from the source PE s to the destination PE d is routed through the input channel j of router i, and (s, d, i, j) = 0 otherwise. We note that the routers are typically interconnected in a network. Hence, the service time for the header flits may increase due to chained blocking at the downstream routers. In general, the blocking probabilities, hence the expected waiting time of the header flit due to blocking can be computed using an iterative process similar to <ref type="bibr" target="#b6">[7]</ref> or through computation ordering <ref type="bibr" target="#b13">[14]</ref>. In order to compute the delay experienced at the intermediate routers, in our experimental work, we first apply <ref type="bibr" target="#b15">(17)</ref> by going through all the flows x sd and, following the routing algorithm, traverse the network from source s to destination d to find the packet arrival rates at each input port of each router. Knowing the traffic arrival rates λ i j , we compute the forwarding probabilities, i.e., matrix F using ( <ref type="formula">7</ref>) and then we compute the contention matrix C using (8); this captures the congestion effects at various points in the network. Finally, we use (5) to find the utilization of each input port.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Average Buffer Utilization and Packet Latency</head><p>Given the arrival rates, λ i j , at each input channel in the network, the contention matrix for each router, and T, we use (5) to find the average number of packets in the input buffer at each router. This information can be used for optimization purposes (e.g., to determine the buffer sizing), since buffer utilization provides information about the distribution of the traffic load across the network. The average buffer utilization can also be used to compute the average waiting time in buffers. By Little's theorem</p><formula xml:id="formula_32">W ij = N ij /λ i j (18)</formula><p>where W ij is the average waiting time in the channel j buffer at router i and N ij represents the average number of packets at the input channel j at router i. Since we already know the packet service time, W ij enables us to compute the average packet latency at each router.</p><p>The delay experienced at each router is a performance metric with very fine granularity. Indeed, it can be used to compute the average latency for each traffic source/destination pair separately, as well as the average packet latency in the network. When a packet is sent from the source node s to the destination node d, it traverses a set of routers and the corresponding input buffers denoted by sd . The average latency for any packet from node s to node d (denoted by L sd ) is given by</p><formula xml:id="formula_33">L sd = W s + (i,j)∈ sd W ij + H s + S W</formula><p>where W s is the queuing delay at the source, W ij is the queuing delay at channel j of router i, and other parameters are defined in Table <ref type="table" target="#tab_1">I</ref>. W S is computed using the M/G/1/m model, since the buffers in the PEs are also finite. Then, the overall average packet latency in the network is found as</p><formula xml:id="formula_34">L = 1 ∀s,d x sd ∀s,d x sd × L sd . (<label>19</label></formula><formula xml:id="formula_35">)</formula><p>This relation provides fast and accurate estimates of L for a variety of traffic patterns and application mappings, as in Section VII. It can be applied to a wide range of optimization problems, since average packet latency is a popular performance metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network Throughput</head><p>The network throughput is defined as the rate at which the packets are delivered to the destination nodes. At low traffic loads, the packet delivery rate is equal to the packet injection rate. However, as the traffic load increases, the throughput starts saturating. In order to investigate the impact of increasing packet injection rates on the average number of packets at the router input buffers and implicitly on the network throughput, we multiply the source to destination traffic generation rates by a positive scaling parameter (i.e., α &gt; 1 but still close to 1). Scaling the traffic arrival rates to the router inputs, αλ j , in <ref type="bibr" target="#b4">(5)</ref> allows us to write the following relation between the throughput N and scaling parameter α:</p><formula xml:id="formula_36">N (α) = (I − T C) −1 α R (<label>20</label></formula><formula xml:id="formula_37">)</formula><p>where N(α) is the average number of packets in the router as a function of α. When the utilization of the input buffers approaches unity, the router will be always busy so its throughput will saturate. The approximate value of α that will saturate a given router can be found by solving the following equation:</p><formula xml:id="formula_38">P j=1 N j (α) = 1. (<label>21</label></formula><formula xml:id="formula_39">)</formula><p>We solve ( <ref type="formula" target="#formula_36">20</ref>) and ( <ref type="formula" target="#formula_38">21</ref>) to find the minimum value of α over all the routers, i.e., α min . Then, the traffic generation rates at which the application throughput saturates is found as α min x sd . Finally, the saturation throughput of the network is found as</p><formula xml:id="formula_40">= α min ∀s,d x sd . (<label>22</label></formula><formula xml:id="formula_41">)</formula><p>Fig. <ref type="figure">6</ref>. Overview of the proposed approach with the latency and throughput evaluation paths shown explicitly.</p><p>In summary, the basic idea of our approach is to identify the bottleneck router, which happens to be the router with the highest amount of traffic through it. The critical load of this router defines the critical load of the overall network, since the congestion propagates quickly across the entire network. Techniques to compute average packet latency have been proposed before. however, to the best of our knowledge, the presented model provides the first analytical approach for finding the maximum network throughput for arbitrary traffic patterns, i.e., non-uniform spatial distribution of sourcedestination pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Overview of the Analysis Methodology</head><p>The proposed analysis technique is summarized for convenience in Fig. <ref type="figure">6</ref>. First, the traffic input rates to the routers and packet service time (including the waiting time due to blocking) are computed using ( <ref type="formula" target="#formula_0">1</ref>) and <ref type="bibr" target="#b15">(17)</ref>. In order to find the average packet latency, we follow the path on the left in Fig. <ref type="figure">6</ref>. The average utilization of the input buffers in the routers is found using (5) (Step 2a). Next, the average packet latency in the network is found using (19) (Step 3a).</p><p>Finally, to find the saturation throughput, we identify the bottleneck router and use ( <ref type="formula" target="#formula_40">22</ref>) (Steps 2b and 3b in Fig. <ref type="figure">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. Experimental Results</head><p>This section provides a detailed study on the accuracy and run-time of the proposed approach. The analytical results obtained using the proposed method are compared against those obtained with a cycle-accurate (flit-level) NoC simulator <ref type="bibr" target="#b31">[33]</ref>. Both the simulator and the analytical model are implemented in C++ and tested on a Pentium 4 computer with 512M memory running Linux OS.</p><p>Throughout the experiments, we assume that each input and output buffer slot can hold a 64-bit flit. In the absence of contention, the router service time is 4 cycles. We also assume that the link transmission takes 1 cycle. Simulations run for 5×10 4 cycles with an initial warm-up period of 2000 cycles. Also, simulations of a particular configuration are repeated  50-100 times with different seeds in order to collect reliable averages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Average Packet Latency</head><p>We first consider a multimedia application <ref type="bibr" target="#b11">[12]</ref> which is manually mapped to a 4 × 4 2-D network (see Fig. <ref type="figure" target="#fig_4">7</ref>) with input and output buffer sizes of 5 × 64 bits and 1 × 64 bits, respectively.</p><p>We compare the average packet latency obtained using the proposed approach against the values obtained by simulation. The average packet latency as a function of the packet injection rate is shown in Fig. <ref type="figure" target="#fig_5">8</ref>.</p><p>We observe that the latency values estimated by the proposed approach follow the simulation results closely. More precisely, for packet injection rates below 0.2 packets/cycle, the relative error between the analytical and simulation results is within 5%. After that, the latency values start increasing abruptly, since at this critical traffic load the network enters congestion. Our approach is also capable of estimating this critical value, as we demonstrate in Section VII-C.</p><p>We also investigate the impact of packet sizes (i.e., the number of flits per packet) and router service time (i.e., 2, 3, and 4 clock cycles) on the average packet latency for a multimedia application mapped on a 4 × 4 2-D mesh NoC with input and output buffer sizes of 5×64 bits and 1×64 bits, respectively, and a packet injection rate of 0.16 packets/cycle. The channels are 64-bit wide and link traversal latency is 1 clock cycle.</p><p>As shown in Fig. <ref type="figure" target="#fig_6">9</ref>, the average packet latency values are close for both analysis and simulation for all three router service times and for packet sizes up to 16 flits per packet. For instance, the average packet latency for a router service time of 2 clock cycles and packet sizes of 16 flits is 44.5 cycles via our proposed approach and 43.2 cycles via simulation. Similarly, for router service time of 3 clock cycles and packet sizes of 15 flits, the average packet latency is 45.2 cycles via our approach and 45.7 via simulation. The differences that emerge for packet sizes larger than 16 flits per packet can be attributed to the congestion effects.</p><p>Next, we assess the accuracy of our approach for different application mappings. We performed experiments for 1000 random mappings. For each mapping, the average packet latency is computed using the proposed approach and by simulation, at 0.16 packets/cycle injection rate, which is a possible operating point (see Fig. <ref type="figure" target="#fig_5">8</ref>). We repeat each simulation 50 times with different seeds; the results are averaged such that the measured latency is within one standard deviation of the actual value with 95% confidence. More formally, let L S (i) be the average packet latency for mapping i obtained by simulation and L A (i) be the corresponding latency obtained using <ref type="bibr" target="#b17">(19)</ref>. The relative error between the analytical and simulation results, for 1000 different mappings, is</p><formula xml:id="formula_42">Err = 1 1000 1000 i=1 |L S (i) − L A (i)| L S (i)</formula><p>.</p><p>Using this definition, the relative error between the analytical and simulation results is about 9%. This is actually a very good accuracy level, given that the relative error is very sensitive even to small differences in data values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Analysis for Application Mapping</head><p>In general, the NoC design space is too big to explore by simulation. For instance, there are n! different ways to map a given application to a network with n nodes. Since the proposed performance model targets NoC design and optimization, we illustrate the effectiveness of our approach using application mapping, which is a common optimization problem for NoCs <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b20">[22]</ref>. More precisely, based on the average packet latency, we first rank order 1000 different mappings obtained in Section VII-A. It takes about 22 h to find the best mapping through simulation, <ref type="foot" target="#foot_4">5</ref> whereas our approach completes the analysis of all possible solutions in about 7 s, which is about four orders of magnitude faster! According to the simulation results, the best among all 1000 mappings is the mapping with ID 268 with an average latency of 35.5 cycles. According to the analysis we propose, the best mapping is the one with ID 732 which has average latency of 35.3 cycles. The latency for mapping ID 732 found by simulation is 36.2 cycles. As such, the analysis approach selects a mapping whose latency is within 2% of the best one found by simulation. We also note that by using a zeroload model (i.e., ignoring the impact of communication load) results in 33.5% error in average packet latency estimation when compared to the simulation reference. Additionally, the analysis discovers the best mapping four orders of magnitude faster than the simulation approach and so much more mappings can be explored, within the same time budget, using the proposed analytical technique.</p><p>To evaluate the analysis approach from a different angle, assume now that the objective is to select the ten best mappings for more detailed evaluations. Therefore, we denote the top ten mappings obtained via simulation as being the golden set. Then, we find the top k mappings based on the analysis results, where 1 ≤ k ≤ 100. When we pick strictly the top ten mappings based on analysis, only five mappings selected by simulation are missed. However, the number of misses drops exponentially to zero as k increases. For instance, the top 20 mappings picked by our approach include seven best mappings found by simulation, while top 46 mappings contain all ten best mappings, as shown in Fig. <ref type="figure" target="#fig_7">10</ref>. For completeness, we also select the top ten mappings according to zero-load model and do a pairwise comparison between these mappings in terms of average latency. Then, using simulation results, we check whether or not the conclusion drawn based on zero-load model (e.g., mapping configuration i is better than mapping j) is correct. We find that 69% of the comparisons agree with the simulation results, while 31% of the comparisons result in wrong decisions. Finally, we repeat the same experiment using the mappings obtained via the proposed approach. We observe Fig. <ref type="figure">11</ref>. Sustainable network throughput for an 8 × 8 2-D mesh network with local traffic described by <ref type="bibr" target="#b21">(23)</ref>.</p><p>that 87% of the comparisons lead to the same conclusion with the simulation results. Hence, the proposed approach increases the comparison accuracy from 69% to 87% which means about 26% improvement.</p><p>To sum up, the proposed method can be used to prune the large design space accurately in a very short time compared to simulation. Experiments performed on larger networks show several orders of magnitude achievable speedup compared to a single simulation run. Considering that many simulations are needed to obtain high confidence intervals, the overall speedup due to the analytical approach is significant. Moreover, the simulation run-time grows faster for heavier traffic, while the run-time of the analytical approach remains about the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Network Throughput</head><p>Next, we compare the maximum network throughput obtained via simulation against the analysis results found using <ref type="bibr" target="#b20">(22)</ref>. In order to test the robustness of our approach to non-uniform traffic conditions, each node communicates only with the nodes that are located within a forwarding radius. Furthermore, if the distance between the source and destination nodes is given by dist(s, d), then the forwarding probability</p><formula xml:id="formula_43">p f (s, d) is p f (s, d) = ≈ 1/dist (s, d) dist (s, d) ≤ F R 0 dist (s, d) &gt; F R (<label>23</label></formula><formula xml:id="formula_44">)</formula><p>where F R (number of hops) is the radius of the forwarding region. The maximum network throughput of an 8×8 mesh network as a function of the traffic locality is given in Fig. <ref type="figure">11</ref>.</p><p>As expected, the network throughput increases with the level of the locality. Furthermore, our technique provides a close approximation to the simulation results over a wide range of characteristics in the traffic locality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Performance Analysis for Arbitrary Topologies</head><p>Since the proposed performance analysis is general, we apply it now on arbitrary topologies <ref type="bibr" target="#b21">[23]</ref>. To this end, we analyze and simulate the simple network in Fig. <ref type="figure" target="#fig_8">12(a)</ref>. Fig. <ref type="figure" target="#fig_8">12(b</ref>) describes the traffic pattern and the deadlock-free routing algorithm used in the network. The entries of routing matrix, RM(i, j)1 ≤ i, j ≤ 8, show whether there is communication between nodes i and j, and the routing choice in case they communicate. For instance, in Fig. <ref type="figure" target="#fig_8">12</ref>(b), RM(1, 5) = − implies that node 1 does not send packets to node 5. On the other hand, RM(1, 6) = 4 means that node 1 forwards the packets to node 4, when it needs to communicate with node 6. For the pairs that communicate the traffic rate is uniform. Finally, the traffic load between all pairs of communicating nodes is uniform and the packets consist of 15 flits.</p><p>The maximum throughput of this network is found as 0.2 packets/cycle using our technique. To evaluate the accuracy of this value, we also run 50 simulations with different random seeds and identify the maximum throughput as 0.18 packets/cycle. As such, the difference between simulation and analysis is about 11%. More detailed evaluations (such as the one shown in Fig. <ref type="figure" target="#fig_5">8</ref>) are omitted here due to lack of space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Complexity and Run-time Analysis</head><p>Finally, we compare the run-time of the proposed approach for latency computation (left branch in Fig. <ref type="figure">6</ref>) with the runtime of Wormsim NoC simulator <ref type="bibr" target="#b31">[33]</ref>. The methodology has three major steps:</p><p>1) computation of the input rates for each network channel (17); 2) computation of the average buffer utilization and queuing delay at each input buffer (5); 3) computation of the average packet latency <ref type="bibr" target="#b17">(19)</ref>. Computational complexity of solving steps 1 and 3 is proportional to the product between the number of routers (R), the number of ports per router (P), and the number of traffic flows in the network (T f ). On the other hand, the computational complexity of step 2 is proportional to R × P 3 . As a result, the overall complexity is obtained as O(RPT f ) + O(R × P 3 ).</p><p>Both the simulator and the analytical model are implemented in C++ and tested on a Pentium 4 computer with 512M memory running Linux OS. Fig. <ref type="figure" target="#fig_9">13</ref> shows the run-time values for the proposed analytical model and simulation on 2-D mesh networks with sizes ranging from 4×4 to 12×12. We observe that the analysis is about two orders of magnitude faster than a single run of the simulation. It is important to note that the two orders of magnitude reduction we show in Fig. <ref type="figure" target="#fig_9">13</ref> are a lower bound, since it compares the analysis run-time against a single simulation run. In practice, simulations of a single configuration are repeated many times to reduce the impact of randomness involved in traffic generations <ref type="bibr" target="#b25">[27]</ref>. For instance, simulation results reported in this paper are averaged over The empirical distribution is tested against five hypothesized distributions: exponential, Gaussian, Gamma, lognormal, and generalized Pareto. According to null hypothesis testing, if h = 1 then the hypothesized distribution can be rejected at the 5% significance level. The p-value gives the probability of observing the hypothesized distribution. The analysis is about two orders of magnitude faster than a single simulation run, as the log scale on the y-axis shows.</p><p>100 simulations with different seeds. Consequently, the actual speedup gained by using the proposed analytical technique as opposed to simulation is much higher as reported in Section VII-B. Finally, we also note that simulation run-time grows faster for heavier traffic, while the run-time of the analytical approach remains pretty much the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Detailed Investigation of Poisson Assumption and Limitations of the Current Approach</head><p>In this section, we revisit the assumption that the header flit arrival process at the router inputs is Poisson. To investigate the arrival process, we observe the packet inter-arrival times at the router inputs. Then, we test the empirical results against several theoretical types of distributions to see the discrepancy between the actual distribution of the header inter-arrival times and the hypothesized distribution via the Pearson's chi-square test <ref type="bibr" target="#b24">[26]</ref>. According to the Pearson statistical test result h = 0 shows that the collected evidence (i.e., inter-arrival times) does not reject the hypothesized distribution, while h = 1 means that the initial hypothesis should be rejected.</p><p>Table <ref type="table" target="#tab_2">II</ref> summarizes the Pearson's chi-square test results for header inter-arrival times at six typical router inputs obtained by simulating a 4 × 4 mesh NoC for 7 × 10 6 clock cycles, under XY wormhole routing. To apply the Pearson's chisquare test, we first estimate an empirical distribution of header inter-arrival times via a kernel density method <ref type="bibr" target="#b30">[32]</ref> from the traffic traces and then via maximum likelihood method the parameters of the hypothesized distribution. We note that for the uniform traffic with 0.16 packets/cycle total injection rate, it is reasonable to model the header inter-arrival times via  <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b0">1)</ref> 117.525 (0, 0.081) 99.634 (1, 0) East at <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b2">3)</ref> 101.820 (0, 0.054) 82.477 (1, 0) West at <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b0">1)</ref> 122.610 (0, 0.504) 98.617 (0, 0.021) South at <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b0">1)</ref> 2605.842 (0, 0.545) 2137.036 (0, 0.310)</p><p>The empirical distribution is tested against exponential distribution. According to null hypothesis testing, if h = 0 then the hypothesized distribution can be accepted at the 5% significance level. The p-value gives the probability of observing the hypothesized distribution.</p><p>exponential distribution as we did in our reported experiments (see the first column of Table <ref type="table" target="#tab_2">II</ref>).</p><p>Table <ref type="table" target="#tab_2">II</ref> also shows that we can also rule out the Gaussian and Lognormal distributions as their p-values are consistently zero. For instance, the results on the second raw and third column in Table <ref type="table" target="#tab_2">II</ref> show that the test accepts the null hypothesis, that the header inter-arrival times obtained from local buffer at (1, 1) (see the first column in Table <ref type="table" target="#tab_2">II</ref>) follow an exponential distribution with a p-value of 0.821 at 5% significance level. In contrast, the null hypothesis testing rejects the Gamma distribution with a p-value of 0.383×10 −10 at 5% significance level.</p><p>We also observed a similar behavior for the hotspot traffic, but the results are not reported here due to space limitations. We repeated this analysis using the multimedia traffic used for the average latency studies in Section VII-A. According to Pearson's test results summarized in Table <ref type="table" target="#tab_3">III</ref>, the exponential distribution models the header flit inter-arrival times at 0.16 packets/cycle traffic load with a high confidence level. As such, this supports our experimental results in Fig. <ref type="figure" target="#fig_5">8</ref>; that is, the analytical model provides a good approximation compared to the cycle accurate simulations.</p><p>Furthermore, Fig. <ref type="figure" target="#fig_5">8</ref> shows that the accuracy of the approximation of the analytical solution of the packet latency decreases as the network reaches a regime close to its saturation point; indeed, this type of behavior is also revealed by the Person's chi-square test shown in the last column of Table <ref type="table" target="#tab_3">III</ref>. This observation is in agreement with our simulation results in Section VII-A which show that as the network throughput reaches its saturation point, the difference between the average packet latency predicted analytically and the average packet latency estimated via simulation grows rapidly.</p><p>This rapid growth is due to the divergence of the average packet latency approaching the saturation throughput of the network. Therefore, at high traffic loads, we actually become more interested in predicting the saturation throughput than knowing precisely the actual packet latency. Consequently, degradation in the accuracy of average packet latency is acceptable as long as the saturation point is predicted accurately, as shown in Fig. <ref type="figure" target="#fig_5">8</ref>. From a practical stand point, the divergence in latency is caused by the increased number of contention points between various packet flows. As such, a packet can be blocked at multiple routers on its way toward the final destination. Therefore, at high traffic loads, a new formalism is needed to estimate the latency of packets blocked across several routers, similar to the recursive computation approach presented in <ref type="bibr" target="#b15">[17]</ref>. Extensions of our current framework for dealing with performance analysis in regimes close to criticality are left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. Conclusion and Future Work</head><p>In this paper, we presented a novel router model for NoC performance analysis. Our approach provides not only aggregate performance metrics such as average latency and throughput, but also feedback about the network characteristics (e.g., buffer utilization, average latency per router and per flow) at a fine-level of granularity. Furthermore, our approach makes the impact of different design parameters on the performance explicit so it provides invaluable insight into NoC design. As a result, the proposed approach can be used as a powerful design and optimization tool. Experimental results demonstrate the effectiveness of the proposed analysis on real and synthetic benchmarks.</p><p>We note that the proposed model is applicable for NoC platforms using synchronous routers. When the routers are used to interconnect different clock domains or the router itself is distributed across multiple clock domains, the impact of having to deal with different clock frequencies should be included in the router model. Such an extension is left for future work. Also, it is desirable to have similar models and comparisons involving the power aspects in order to be able to fully analyze various energy/performance tradeoffs. We plan to address such issues as part of our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Router model with multiple virtual channels. The outgoing links are not shown for simplicity. The structure of , and N remains the same as for the no virtual channels case.</figDesc><graphic url="image-3.png" coords="5,74.72,53.48,198.48,102.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Interconnection of the input channels shown in Fig. 2 using a shared bus. While the router architectures shown in Figs. 2 and 3 allow multiple simultaneous connections, the shared bus allows only one connection at any given time.</figDesc><graphic url="image-4.png" coords="5,101.72,204.76,144.24,101.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>constant and is a P×P diagonal matrix with non-negative components, such that 2 lim k→∞ (T C 1 ) k = 0 lim k→∞ (T C 2 ) k = 0. (13) Then (I−T C 2 ) −1 ≥ (I−T C 1 ) −1 (14)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Average number of flits in the router (i.e., the sum of the flits in all five buffers) is shown as a function of the buffer size and service time of the router.</figDesc><graphic url="image-5.png" coords="6,322.52,53.71,233.52,145.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Multimedia application [12] mapped onto a 4 × 4 NoC assumed to operate at 100 MHz. The numbers associated with the directed arcs represent the communication volume between the corresponding nodes in multiplies of 10 kB.</figDesc><graphic url="image-8.png" coords="8,329.52,238.13,220.08,148.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Average packet latency values found analytically (with the proposed approach) and by simulation are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Average packet latency found analytically and by simulation as a function of packet sizes (i.e., number of flits per packet) and three router service times.</figDesc><graphic url="image-9.png" coords="9,54.22,53.80,240.24,134.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Top mappings selected by simulation, but missed by analysis are shown.</figDesc><graphic url="image-10.png" coords="9,328.73,53.37,216.48,117.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. (a) Arbitrary network topology used to test the proposed technique and (b) its routing matrix (RM).</figDesc><graphic url="image-12.png" coords="10,319.52,53.92,239.52,119.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Run times (ms) of the proposed analytical method and a single simulation run are shown for increasing network sizes (number of routers).The analysis is about two orders of magnitude faster than a single simulation run, as the log scale on the y-axis shows.</figDesc><graphic url="image-13.png" coords="11,66.72,213.07,215.04,103.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>An Analytical Approach for Network-on-Chip Performance Analysis Umit Y. Ogras, Member, IEEE, Paul Bogdan, Student Member, IEEE, and Radu Marculescu, Member, IEEE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I</head><label>I</label><figDesc>List of Input Parameters Used in the Paper</figDesc><table><row><cell cols="2">Input Explanation</cell><cell>Depends</cell></row><row><cell></cell><cell></cell><cell>on</cell></row><row><cell>S</cell><cell>Random variable (rv) denoting the packet size</cell><cell></cell></row><row><cell>x sd</cell><cell>Packet transmission rate from node s to node d</cell><cell>Application</cell></row><row><cell>R</cell><cell>Residual packet waiting time</cell><cell></cell></row><row><cell>H S</cell><cell>Service time for the header flit</cell><cell></cell></row><row><cell>W</cell><cell>Network channel bandwidth</cell><cell>Router</cell></row><row><cell>B ij</cell><cell>Size of the input buffer at router i, channel j</cell><cell></cell></row><row><cell>T, T,</cell><cell>rv T denotes the packet service time. T and T 2 are</cell><cell>Application</cell></row><row><cell>T 2</cell><cell>its first and second order moments</cell><cell>and</cell></row><row><cell></cell><cell></cell><cell>Router</cell></row><row><cell cols="2">c ij , C Contention probability between channels i and j</cell><cell></cell></row><row><cell>λ j</cell><cell>Mean arrival rate at input buffer of channel j</cell><cell>Topology,</cell></row><row><cell></cell><cell></cell><cell>routing,</cell></row><row><cell></cell><cell></cell><cell>application</cell></row><row><cell>λ ij</cell><cell>Traffic arrival rate at channel i which is routed</cell><cell></cell></row><row><cell></cell><cell>toward channel j</cell><cell></cell></row><row><cell>λ i j</cell><cell>Traffic arrival rate at router i, input channel j</cell><cell></cell></row><row><cell cols="2">Bold symbols (e.g., S and T ) denote random variables.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II</head><label>II</label><figDesc>Pearson's Statistics of Six Typical Header Inter-Arrival Times from Simulating a 4 × 4 Mesh NoC Under XY Wormhole Routing (Packets Consisting of Two Flits), Uniform Traffic with 0.16 Total Packet Injection Rate</figDesc><table><row><cell>Buffers ID</cell><cell cols="2">Exponential</cell><cell>Gaussian</cell><cell></cell><cell cols="2">Gamma Distribution</cell><cell cols="2">Log-Normal</cell><cell cols="2">Generalized Pareto</cell></row><row><cell></cell><cell cols="2">Distribution</cell><cell>Distribution</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Distribution</cell><cell>Distribution</cell></row><row><cell></cell><cell>λ</cell><cell>(h, p)</cell><cell>µ, σ</cell><cell>(h, p)</cell><cell>k, θ</cell><cell>(h, p)</cell><cell>µ, σ</cell><cell>(h, p)</cell><cell>k, σ, θ</cell><cell>(h, p)</cell></row><row><cell>Local at (1, 1)</cell><cell>101.254</cell><cell>(0, 0.821)</cell><cell>101.254, 100.029</cell><cell>(1, 0)</cell><cell cols="5">1.082, 93.547 (1, 0.383×10 −10 ) 4.089, 1.165 (1, 0) −0.012, 102.564, 2</cell><cell>(0, 0.168)</cell></row><row><cell>Local at (4, 4)</cell><cell>101.501</cell><cell>(0, 0.691)</cell><cell>101.501, 100.198</cell><cell>(1, 0)</cell><cell>1.085, 93.551</cell><cell cols="4">(1, 1.234×10 −6 ) 4.093, 1.164 (1, 0) −0.013, 102.748, 2</cell><cell>(0, 0.168)</cell></row><row><cell>North at (4, 1)</cell><cell>126.804</cell><cell>(0, 0.233)</cell><cell>126.804, 124.148</cell><cell>(1, 0)</cell><cell cols="6">1.124, 112.832 (1, 0.383×10 −14 ) 4.336, 1.123 (1, 0) −0.011, 126.964, 3 (1, 0.8×10 −5 )</cell></row><row><cell>East at (2, 2)</cell><cell>127.131</cell><cell>(0, 0.420)</cell><cell>127.131, 124.984</cell><cell>(1, 0)</cell><cell cols="5">1.107, 114.842 (1, 0.665×10 −6 ) 4.330, 1.139 (1, 0) −0.011, 127.702, 3</cell><cell>(0, 0.385)</cell></row><row><cell>West at (1, 2)</cell><cell>128.171</cell><cell>(0, 0.318)</cell><cell>128.171, 125.568</cell><cell>(1, 0)</cell><cell cols="5">1.131, 113.367 (1, 0.381×10 −10 ) 4.350, 1.119 (1, 0) −0.009, 128.006, 3</cell><cell>(0, 0.067)</cell></row><row><cell>South at (2, 4)</cell><cell>129.053</cell><cell>(0, 0.128)</cell><cell>129.053, 125.759</cell><cell>(1, 0)</cell><cell cols="5">1.179, 109.477 (1, 0.139×10 −24 ) 4.379, 1.070 (1, 0) −0.002, 126.335, 3</cell><cell>(0, 0.144)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III</head><label>III</label><figDesc>Pearson's Statistic Investigation of Six Typical Header Inter-Arrival Times from Simulating a 4 × 4 Mesh NoC Under XY Wormhole Routing (Packets Consisting of Two Flits),</figDesc><table><row><cell cols="5">Running an MPEG2 Application with 0.055 Packet Injection</cell></row><row><cell></cell><cell cols="2">Rate per Node</cell><cell></cell><cell></cell></row><row><cell>Buffers ID</cell><cell cols="2">0.16 Packets/Cycle</cell><cell cols="2">0.2 Packets/Cycle</cell></row><row><cell></cell><cell>λ</cell><cell>(h, p)</cell><cell>λ</cell><cell>(h, p)</cell></row><row><cell>Local at (4, 3)</cell><cell>136.737</cell><cell>(0, 0.811)</cell><cell>109.929</cell><cell>(0, 0.081)</cell></row><row><cell>Local at (1, 1)</cell><cell>114.476</cell><cell>(0, 0.858)</cell><cell>114.031</cell><cell>(0, 0.503)</cell></row><row><cell>North at</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The PASTA definition implies that the distribution of packets in the system, that is seen by a new (arriving) packet, is the same as the long run (time asymptotic) or steady-state behavior of the packet distribution. This allows us to relate the mean waiting time of a packet in the buffer to the mean number of packets in all the buffers of the router.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Equivalently, the eigenvalues of matrices T C 1 and T C 2 are less than one.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Note that, in this paper, we use A ≤ B to denote the element-wise comparison for two matrices of same dimensions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">When P = 1, this condition reduces to λ T &lt; 1 known as the stability condition for a single buffer.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">Each mapping is simulated 100 times and the average latency over all runs is used for ranking to increase the confidence level of the results. Run-time comparisons against a single simulation run are presented in Section VII-E.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The authors gratefully acknowledge the financial support from the Semiconductor Research Corporation (SRC) and National Science Foundation (NSF). Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. P. Bogdan also acknowledges the financial support received through a Fellowship from the Roberto Rocca Education Program.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Semiconductor Research Corporation, under Grant 2008-HJ-1823, and in part by the National Science Foundation, under Grants CCF-0702420 and CCF-0916752. This paper was presented in part as "Analytical router modeling for networks-on-chip performance analysis" at the Proceedings of the Design, Automation and Test in Europe Conference, Nice, France, April 2007. This paper was recommended by Associate Editor L. Benini. U. Y. Ogras is with the Strategic CAD Laboratories, Intel Corporation,</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>When the conditions given in (13) hold, we can use the Neumann series expansion for matrix inversion, that is</p><p>So, we need to prove</p><p>To prove the inequality given in (25) holds, we will show that</p><p>This inequality is trivially satisfied for k = 0. We will employ mathematical induction to show that the inequality also holds for k≥ 0.</p><p>For k = 1:</p><p>since all elements of and δ are non-negative.</p><p>For k = n: suppose (T C 2 ) n ≥ (T C 1 ) n and let (T C 2 ) n − (T C 1 ) n = n ≥ 0, i.e., all components of n are nonnegative.</p><p>For k = n + 1: let</p><p>With this notation, now we can derive the following relations:</p><p>(28) In line (1), we simply rewrite <ref type="bibr" target="#b25">(27)</ref> by factoring out T C 2 and T C 1 , respectively. Then, we further factor T out and substitute C 2 with C 1 +δ, in lines (2) and (3). Next, we observe that (T C 2 ) n −(T C 1 ) n = n in line <ref type="bibr" target="#b3">(4)</ref>. Finally, we note that all the matrices in line ( <ref type="formula">5</ref>) are non-negative. So</p><p>since all the terms in the left-hand side are greater than or equal to the corresponding terms in the right-hand side.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Networks on chips: A new SoC paradigm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="78" />
			<date type="published" when="2002-01">Jan. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gallager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Data</forename><surname>Networks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Performance analysis of k-ary n-cube interconnection networks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="775" to="785" />
			<date type="published" when="1990-06">Jun. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Route packets, not wires: On-chip interconnection networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Towles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DAC</title>
				<meeting>DAC</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="684" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Principles and Practices of Interconnection Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Towles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Concepts and implementation of the Philips network-on-chip</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dielissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goossens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rijpkema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IP-Based SoC Des</title>
				<meeting>IP-Based SoC Des</meeting>
		<imprint>
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A comprehensive analytical model for wormhole routing in multicomputer systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Draper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distributed Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="214" />
			<date type="published" when="1994-11">Nov. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">High-level power analysis of on-chip networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Eisley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Compilers Architectures Synthesis Embedded Syst</title>
				<meeting>Int. Conf. Compilers Architectures Synthesis Embedded Syst</meeting>
		<imprint>
			<date type="published" when="2004-09">Sep. 2004</date>
			<biblScope unit="page" from="104" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An analytical model for wormhole routing in multicomputer interconnection networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Parallel Process. Symp</title>
				<meeting>Int. Parallel ess. Symp</meeting>
		<imprint>
			<date type="published" when="1993-04">Apr. 1993</date>
			<biblScope unit="page" from="650" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient link capacity and QoS design for wormhole network-on-chip</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bolotin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cidon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ginosar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kolodny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DATE</title>
				<meeting>DATE</meeting>
		<imprint>
			<date type="published" when="2006-03">Mar. 2006</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Network on a chip: An architecture for billion transistor era</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hemani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jantsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Postula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Öberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Millberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lindquist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE NorChip Conf</title>
				<meeting>IEEE NorChip Conf</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="166" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Energy and performance-aware mapping for regular NoC architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="551" to="562" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">System-level buffer allocation for application-specific networks-on-chip router design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">Y</forename><surname>Ogras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2919" to="2933" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An analytical model for wormhole routing with finite size input buffers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kleinrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Int. Teletraffic Congr</title>
				<meeting>15th Int. Teletraffic Congr</meeting>
		<imprint>
			<date type="published" when="1997-06">Jun. 1997</date>
			<biblScope unit="page" from="549" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An approach for quantitative analysis of application-specific dataflow architectures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kienhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deprettere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vissers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ASAP</title>
				<meeting>IEEE ASAP</meeting>
		<imprint>
			<date type="published" when="1997-07">Jul. 1997</date>
			<biblScope unit="page">338</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Real-time wormhole channels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="311" />
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A methodology for architecture exploration of heterogeneous signal processing systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lieverse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deprettere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vissers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. VLSI Signal Process. Syst. Signal Image Video Technol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="197" to="207" />
			<date type="published" when="2001-11">Nov. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computation and communication refinement for multiprocessor SoC design: A systemlevel perspective</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">Y</forename><surname>Ogras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Zamora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Des. Automotation Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="564" to="592" />
			<date type="published" when="2006-07">Jul. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Outstanding research problems in NoC design: System, microarchitecture, and circuit perspectives</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">Y</forename><surname>Ogras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Peh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Jerger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hoskote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="21" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Guaranteed bandwidth using looped containers in temporally disjoint networks within the Nostrum network on chip</title>
		<author>
			<persName><forename type="first">M</forename><surname>Millberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jantsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DATE</title>
				<meeting>DATE</meeting>
		<imprint>
			<date type="published" when="2004-02">Feb. 2004</date>
			<biblScope unit="page" from="890" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bandwidth-constrained mapping of cores onto NoC architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Murali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DATE</title>
				<meeting>DATE</meeting>
		<imprint>
			<date type="published" when="2004-03">Mar. 2004</date>
			<biblScope unit="page">20896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">It&apos;s a small world after all: NoC performance optimization via long-range link insertion</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">Y</forename><surname>Ogras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Very Large Scale Integr</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="693" to="706" />
			<date type="published" when="2006-07">Jul. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An analytical model of adaptive wormhole routing in hypercubes in the presence of hot spot traffic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ould-Khaoua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distributed Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="292" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Performance evaluation and design tradeoffs for network-on-chip interconnect architectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grecu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saleh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1025" to="1040" />
			<date type="published" when="2005-08">Aug. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Papoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Pillai</surname></persName>
		</author>
		<title level="m">Probability, Random Variables and Stochastic Processes</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>4th ed</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Simulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Elsevier Academic</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Introduction to Linear Algebra</title>
		<author>
			<persName><forename type="first">G</forename><surname>Strang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Wellesley-Cambridge Press</publisher>
			<pubPlace>Wellesley, MA</pubPlace>
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Takagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queueing Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1993">1993</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On-chip traffic modeling and synthesis for MPEG-2 video applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Varatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Very Large Scale Integr</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="119" />
			<date type="published" when="2004-01">Jan. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Orion: A power-performance simulator for interconnection networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Micro-Architecture</title>
				<meeting>Int. Symp. Micro-Architecture</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Wasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">All of Statistics: A Concise Course in Statistical Inference</title>
		<title level="s">Springer Texts in Statistics</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">He is currently a Research Scientist with Strategic CAD Laboratories, Intel Corporation, Hillsboro, OR. His current research interests include the areas of embedded systems and electronic design automation</title>
		<author>
			<persName><surname>Sim</surname></persName>
		</author>
		<ptr target="http://www.ece.cmu.edu/∼sld/software/index.phpUmitY.Ogras" />
	</analytic>
	<monogr>
		<title level="m">particular, his research focuses on communication-centric design methodologies for nanoscale SoCs</title>
				<meeting><address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>(M&apos;00) received the Ph.D. degree in electrical. with a special interest on networkson-chip communication architectures</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">His current research interests include developing design methodologies and software tools for SoC design, on-chip communication, and ambient intelligence. Dr. Marculescu is a recipient of the National Science Foundation&apos;s CAREER Award in the area of design automation of electronic systems in 2000</title>
	</analytic>
	<monogr>
		<title level="m">He has received the 2005 Transactions on Very Large Scale Integration Systems Best Paper Award from the IEEE Circuits and Systems Society, two Best Paper Awards from the Design Automation and Test in Europe Conference in 2001 and 2003, and a Best Paper Award from the Asia and South Pacific Design Automation Conference in 2003</title>
				<meeting><address><addrLine>Pittsburgh, PA; Los Angeles; Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Politehnica University of Bucharest, Bucharest, Romania ; Department of Electrical and Computer Engineering, Carnegie Mellon University ; Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>2004, where he was involved in research on control theory and dynamical systems. He received the Carnegie Institute of Technology&apos;s Ladd Research Award in 2002. He is a member of the</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
