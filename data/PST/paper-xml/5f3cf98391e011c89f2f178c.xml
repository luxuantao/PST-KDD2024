<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">S 3 -Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Wang</surname></persName>
							<email>hui.wang@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Gaoling School of Artificial Intelligence</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods 4 Meituan-Dianping Group</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Gaoling School of Artificial Intelligence</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods 4 Meituan-Dianping Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yutao</forename><surname>Zhu</surname></persName>
							<email>yutao.zhu@umontreal.ca</email>
							<affiliation key="aff3">
								<orgName type="institution">UniversitÃľ de MontrÃľal</orgName>
								<address>
									<settlement>MontrÃľal</settlement>
									<region>QuÃľbec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">UniversitÃľ de MontrÃľal</orgName>
								<address>
									<settlement>MontrÃľal</settlement>
									<region>QuÃľbec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sirui</forename><surname>Wang</surname></persName>
							<email>wangsirui@meituan.com</email>
						</author>
						<author>
							<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods 4 Meituan-Dianping Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
							<email>jrwen@ruc.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Gaoling School of Artificial Intelligence</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods 4 Meituan-Dianping Group</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Gaoling School of Artificial Intelligence</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing Key Laboratory of Big Data Management and Analysis Methods 4 Meituan-Dianping Group</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">S 3 -Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3340531.3411954</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Self-Supervised Learning</term>
					<term>Sequential Recommendation</term>
					<term>Mutual Information Maximization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, significant progress has been made in sequential recommendation with deep learning. Existing neural sequential recommendation models usually rely on the item prediction loss to learn model parameters or data representations. However, the model trained with this loss is prone to suffer from data sparsity problem. Since it overemphasizes the final performance, the association or fusion between context data and sequence data has not been well captured and utilized for sequential recommendation.</p><p>To tackle this problem, we propose the model S 3 -Rec, which stands for Self-Supervised learning for Sequential Recommendation, based on the self-attentive neural architecture. The main idea of our approach is to utilize the intrinsic data correlation to derive self-supervision signals and enhance the data representations via pre-training methods for improving sequential recommendation. For our task, we devise four auxiliary self-supervised objectives to learn the correlations among attribute, item, subsequence, and sequence by utilizing the mutual information maximization (MIM) principle. MIM provides a unified way to characterize the correlation between different types of data, which is particularly suitable in our scenario. Extensive experiments conducted on six real-world datasets demonstrate the superiority of our proposed method over existing state-of-the-art methods, especially when only limited training data is available. Besides, we extend our self-supervised learning method to other recommendation models, which also improve their performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years have witnessed the great success of many online platforms, such as Amazon and Taobao. Within online platforms, users' behaviors are dynamic and evolving over time. Thus it is critical to capture the dynamics of sequential user behaviors for making appropriate recommendations. In order to accurately characterize user interests and provide high-quality recommendations, the task of sequential recommendation has been widely studied in the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>Typically, sequential recommendation methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref> capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with deep learning. Various methods using recurrent neural networks (RNNs) <ref type="bibr" target="#b2">[3]</ref>, convolutional neural networks (CNNs) <ref type="bibr" target="#b23">[24]</ref>, and self-attention mechanisms <ref type="bibr" target="#b7">[8]</ref> have been proposed to learn good representations of user preference and characterize sequential user-item interactions.</p><p>Furthermore, researchers have incorporated rich contextual information (such as item attributes) to neural sequential recommenders <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">29]</ref>. It has been demonstrated that contextual information is important to consider for improving the performance of sequential recommender systems.</p><p>Although existing methods have been shown effective to some extent, there are two major shortcomings that are likely to affect the recommendation performance. First, they rely on the item prediction loss to learn the entire model. When context data is incorporated, the involved parameters are also learned through the only optimization objective. It has been found that such an optimization way is easy to suffer from issues such as data sparsity <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2008.07873v1 [cs.IR] 18 Aug 2020</head><p>Second, they overemphasize the final performance, while the association or fusion between context data and sequence data has not been well captured in data representations. As shown in increasing evidence from various fields <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref>, effective data representation (e.g., pre-trained contextualized embedding) has been a key factor to improve the performance of existing models or architectures. Therefore, there is a need to rethink the learning paradigm to develop more effective sequential recommender systems.</p><p>To address the above issues, we borrow the idea of self-supervised learning for improving sequential recommendation. Self-supervised learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref> is a newly emerging paradigm, which aims to let the model learn from the intrinsic structure of the raw data. A general framework of self-supervised learning is to first construct training signals directly from the raw data and then pre-train the model parameters with additionally devised optimization objectives. As previously discussed, limited supervision signals and ineffective data representations are the two major learning issues with existing neural sequential methods. Fortunately, self-supervised learning seems to provide a promising solution to both problems: it utilizes the intrinsic data correlation to devise auxiliary training objectives and enhances the data representations via pre-trained methods with rich self-supervised signals. However, for sequential recommendation, the context information exists in different forms or with varying intrinsics, including item, attribute, subsequence, or sequence. It is not easy to develop a unified approach to characterizing such data correlations. For this problem, we are inspired by the recently proposed mutual information maximization (MIM) method <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b29">30]</ref>. It has been shown to be particularly effective to capture the correlation between different views (or parts) of the original input by maximizing the mutual information between the encoded representations of these views.</p><p>To this end, in this paper, we propose a novel Self-Supervised learning approach to improve Sequential Recommendation with MIM, which is called S 3 -Rec. Based on a self-attentive recommender architecture <ref type="bibr" target="#b7">[8]</ref>, we propose to first pre-train the sequential recommender with self-supervised signals and then fine-tune the model parameters according to the recommendation task. The major novelty lies in the pre-training stage. In particular, we carefully devise four self-supervised optimization objectives for capturing item-attribute, sequence-item, sequence-attribute and sequencesubsequence correlations, respectively. These optimization objectives are developed in a unified form of MIM. As such, S 3 -Rec is able to characterize the correlation in varying levels of granularity or between different forms in a general way. It is also flexible to adapt to new data types or new correlation patterns. Via such a pre-trained method, we can effectively fuse various kinds of context data, and learn attribute-aware contextualized data representations. Finally, the learned data representations are fed into the neural recommender, which will be optimized according to the recommendation performance.</p><p>To validate the effectiveness of our proposed S 3 -Rec method, we conduct extensive experiments on six real-world recommendation datasets of different domains. Experimental results show that S 3 -Rec achieves state-of-the-art performance compared to a number of competitive methods, especially when training data is limited.</p><p>We also show that our S 3 -Rec is effective to adapt to other classes of neural architectures, such as GRU and CNN.</p><p>Our main contributions are summarized as follows: (1) To the best of our knowledge, it is the first time that self-supervised learning with MIM has been applied to improve the sequential recommendation task; <ref type="bibr" target="#b1">(2)</ref> We propose four self-supervised optimization objectives to maximize the mutual information of context information in different forms or granularities; (3) Extensive experiments conducted on six real-world datasets demonstrate the effectiveness of our proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Sequential Recommendation</head><p>Early works on sequential recommendation are based on the Markov Chain assumption. MC-based methods <ref type="bibr" target="#b19">[20]</ref> estimated an item-item transition probability matrix and utilized it to predict the next item given the last interaction of a user. A series of works follow this line and extend it for high-order MCs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24]</ref>. With the development of the neural networks, Hidasi et al. <ref type="bibr" target="#b2">[3]</ref> firstly introduced Gated Recurrent Units (GRU) to the session-based recommendation and a surge of following variants modified this model by introducing pair-wise loss functions <ref type="bibr" target="#b3">[4]</ref>, memory networks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, hierarchical structures <ref type="bibr" target="#b16">[17]</ref>, copy mechanism <ref type="bibr" target="#b17">[18]</ref> and reinforcement learning <ref type="bibr" target="#b26">[27]</ref>, etc. There are also studies that leverage other architectures <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> for sequential recommendation. However, these approaches neglect the rich attribute information about items. To tackle this problem, TransFM <ref type="bibr" target="#b15">[16]</ref> utilized Factorization Machines to incorporate arbitrary real-valued features to the sequential recommendation. FDSA <ref type="bibr" target="#b28">[29]</ref> employed a feature-level self-attention block to leverage the attribute information about items in user history. Despite the remarkable success of these sequential recommendation models, the correlations among attribute, item, and sequence are still not utilized and modeled sufficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Self-supervised Learning</head><p>Self-supervised learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15]</ref> aims at training a network on an auxiliary objective where the ground-truth samples are obtained from the raw data automatically. The general framework is to construct training signals directly from the correlation within the raw data and utilize them to train the model. The correlation information learned through self-supervised learning can then be easily utilized to benefit other tasks. Several self-supervised objectives have been introduced to use non-visual but intrinsically correlated features to guide the visual feature learning <ref type="bibr" target="#b4">[5]</ref>. As for language modeling <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref>, it is a popular self-supervised objective for natural language processing, where the model learns to predict the next word or sentence given the previous sequences. The learned representations of words or sequences can improve the performance of downstream tasks such as machine reading comprehension <ref type="bibr" target="#b0">[1]</ref> and natural language understanding <ref type="bibr" target="#b9">[10]</ref>.</p><p>Mutual information maximization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref> is a special branch of the self-supervised learning. It is inspired by the InfoMax principle <ref type="bibr" target="#b10">[11]</ref> and has made important progress in several domains such as computer vision <ref type="bibr" target="#b4">[5]</ref>, audio processing <ref type="bibr" target="#b24">[25]</ref>, and nature language understanding <ref type="bibr" target="#b9">[10]</ref>. This method splits the input data into multiple (possibly overlapping) views and maximizes the mutual information between representations of these views. The views derived from other inputs are used as negative samples.</p><p>Different from the above approaches, our work is the first to consider the correlations within the contextual information as the self-supervised signals in sequential recommendation. We maximize the mutual information among the views of the attribute, item, and sequence, which are in different levels of granularity of the contextual information. The enhanced data representations can improve recommendation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we first formulate the sequential recommendation problem and then introduce the technique of mutual information maximization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Statement</head><p>Assume that we have a set of users and items, denoted by U and I, respectively, where u ∈ U denotes a user and i ∈ I denotes an item. The numbers of users and items are denoted as |U| and |I|, respectively. Generally, a user u has a chronologically-ordered interaction sequence with items: {i 1 , • • • , i n }, where n is the number of interactions and i t is the t-th item that the user u has interacted with. For convenience, we use i j:k to denote the subsequence, i.e.,</p><formula xml:id="formula_0">i j:k = {i j , • • • , i k } where 1 ≤ j &lt; k ≤ n. Besides, each item i is associated with several attributes A i = {a 1 , • • • , a m }.</formula><p>For example, a song is typical with auxiliary information such as artist, album, and popularity for music recommender. All attributes constitute an attribute set A, and the number of attributes is donated as |A|.</p><p>Based on the above notations, we now define the task of sequential recommendation. Formally, given the historical behaviors of a user {i 1 , • • • , i n } and the attributes A i of each item i, the task of sequential recommendation is to predict the next item that the user is likely to interact with at the (n + 1)-th step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mutual Information Maximization</head><p>An important technique in our approach is the Mutual Information Maximization (MIM). It is developed on the core concept of mutual information, which measures dependencies between random variables. Given two random variables X and Y , it can be understood as how much knowing X reduces the uncertainty in Y or vice versa. Formally, the mutual information between X and Y is:</p><formula xml:id="formula_1">I (X , Y ) = H (X ) − H (X |Y ) = H (Y ) − H (Y |X ).<label>(1)</label></formula><p>Maximizing mutual information directly is usually intractable. Thus we resort to a lower bound on I (X , Y ). One particular lower bound that has been shown to work well in practice is InfoNCE <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b24">25]</ref>, which is based on Noise Contrastive Estimation (NCE) <ref type="bibr" target="#b1">[2]</ref>. InfoNCE is defined as:</p><formula xml:id="formula_2">E p(X,Y ) [f θ (x, y) − E q( Ỹ ) [log ỹ ∈ Ỹ exp f θ (x, ỹ)]] + log | Ỹ |, (2)</formula><p>where x and y are different views of an input, and f θ is a function parameterized by θ (e.g., a dot product between encoded representations of a word and its context <ref type="bibr" target="#b9">[10]</ref> or a dot product between encoded representations of an image and the local regions of the image <ref type="bibr" target="#b4">[5]</ref>), and Ỹ is a set of samples drawn from a proposal distribution q( Ỹ ), which contains a positive sample y and | Ỹ | − 1 negative samples.</p><p>Note that InfoNCE is related to the cross-entropy. If Ỹ always includes all possible values of the random variable Y (i.e., Ỹ = Y ) and they are uniformly distributed, maximizing InfoNCE is analogous to maximize the standard cross-entropy loss:</p><formula xml:id="formula_3">E p(X,Y ) [f θ (x, y) − log ỹ ∈Y exp f θ (x, ỹ)].<label>(3)</label></formula><p>This equation shows that InfoNCE is related to maximize p θ (y|x), and it approximates the summation over elements in Y (i.e.,, the partition function) by negative sampling. Based on this formula, we can utilize specific X , Y to maximize the mutual information between different views of the raw data, e.g., an item and its attributes, or a sequence and the items that it contains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPROACH 4.1 Overview</head><p>Existing studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24]</ref> mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone.</p><p>Inspired by recent progress with MIM <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28]</ref>, we take a different perspective to develop neural sequential recommenders by maximizing the mutual information among different views of the raw data.</p><p>The basic idea of our approach is to incorporate several elaborately designed self-supervised learning objectives for enhancing the original model. To develop such objectives, we leverage effective correlation signals reflected in the intrinsic characteristics of the input. For our task, we consider the information in different levels of granularity, including attribute, item, segment (i.e., subsequence), and sequence, which are considered as different views of the input. By capturing the multi-view correlation, we unify these self-supervised learning objectives with the recently proposed pretraining framework in language modeling <ref type="bibr" target="#b0">[1]</ref>.</p><p>The overview of S 3 -Rec is presented in Fig. <ref type="figure" target="#fig_0">1</ref>. In the following sections, we first introduce the base model of our proposed approach that is developed on the Transformer architecture <ref type="bibr" target="#b7">[8]</ref>. Then, we will describe how we utilize the correlation signals among attributes, items, segments, and sequences to enhance the data representations based on the InfoNCE <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref> method. Finally, we present the discussions on our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Base Model</head><p>We develop the basic framework for sequential recommendation model by stacking the embedding layer, self-attention blocks, and the prediction layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Embedding Layer.</head><p>In the embedding mapping stage, we maintains an item embedding matrix M I ∈ R |I |×d and an attribute embedding matrix M A ∈ R | A |×d . The two matrices project the high-dimensional one-hot representation of an item or attribute to low-dimensional dense representations. Given a n-length item sequence, we apply a look-up operation from M I to form the input embedding matrix E ∈ R n×d . Besides, we incorporate a learnable</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Items Attributes</head><p>Item Embedding Bidirectional Self-Attenion ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequence-Item MIM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Item Embedding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequence-Attribute MIM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Item-Attribute MIM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attribute Embedding Item Embedding</head><p>Sequence-Sequence MIM  position encoding matrix P ∈ R n×d to enhance the input representation of the item sequence. By this means, the sequence representation E I ∈ R n×d can be obtained by summing two embedding matrices: E I = E + P. Since our task utilizes auxiliary context data, we also form an embedding matrix E A ∈ R k ×d for each item from the entire attribute embedding matrix M A , where k is the number of item attributes.</p><formula xml:id="formula_4">Bidirectional Self-Attenion<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Self-Attention Block.</head><p>Based on the embedding layer, we develop the item encoder by stacking multiple self-attention blocks.</p><p>A self-attention block generally consists of two sub-layers, i.e., a multi-head self-attention layer and a point-wise feed-forward network. The multi-head self-attention mechanism has been adopted for effectively extracting the information selectively from different representation subspaces. Specifically, the multi-head self-attention is defined as:</p><formula xml:id="formula_5">MultiHeadAttn(F l ) = [head 1 , head 2 , ..., head h ]W O ,<label>(4)</label></formula><formula xml:id="formula_6">head i = Attention(F l W Q i , F l W K i , F l W V i ),<label>(5)</label></formula><p>where the F l is the input for the l-th layer. When l = 0, we set F 0 = E I , and the projection matrix</p><formula xml:id="formula_7">W Q i ∈ R d ×d /h , W K i ∈ R d ×d /h , W Q V ∈ R d ×d /h and W O ∈ R d ×d</formula><p>are the corresponding learnable parameters for each attention head. The attention function is implemented by scaled dot-product operation:</p><formula xml:id="formula_8">Attention(Q, K, V) = softmax( QK ⊤ d/h )V,<label>(6)</label></formula><p>where</p><formula xml:id="formula_9">Q = F l W Q i , K = F l W K i</formula><p>, and V = F l W V i are the linear transformations of the input embedding matrix, and d/h is the scale factor to avoid large values of the inner product.</p><p>Since the multi-head attention function is mainly built on the linear projections. We endow the non-linearity of the self-attention block by applying a point-wise feed-forward network. The computation is defined as:</p><formula xml:id="formula_10">F l = [FFN(F l 1 ) ⊤ ; • • • ; FFN(F l n ) ⊤ ],<label>(7)</label></formula><formula xml:id="formula_11">FFN(x) = (ReLU(xW 1 + b 1 ))W 2 + b 2 ,<label>(8)</label></formula><p>where</p><formula xml:id="formula_12">W 1 ,b 1 ,W 2 ,b 2 are trainable parameters.</formula><p>In sequential recommendation, only the information before the current time step can be utilized, thus we apply the mask operation for the output of the multi-head self-attention function to remove all connections between Q i and K i . Inspired by BERT <ref type="bibr" target="#b0">[1]</ref>, at the pre-training stage, we remove the mask mechanism to acquire the bidirectional context-aware representation of each item in an item sequence. It is beneficial to incorporate context from both directions for sequence representation learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Prediction Layer.</head><p>In the final layer of S 3 -Rec, we calculate the user's preference score for the item i in the step (t + 1) under the context from user history as:</p><formula xml:id="formula_13">P(i t +1 = i |i 1:t ) = e ⊤ i • F L t ,<label>(9)</label></formula><p>where e i is the representation of item i from item embedding matrix M I , F L t is the output of the L-layer self-attention block at step t and L is the number of self-attention blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Self-supervised Learning with MIM</head><p>Based on the above self-attention model, we further incorporate additional self-supervised signals with MIM to enhance the representations of input data. We adopt a pre-training way to construct different loss functions based on the multi-view correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Modeling Item-Attribute Correlation.</head><p>We first maximize the mutual information between items and attributes. For each item, the attributes provide fine-grained information about it. Therefore, we aim to fuse item-and attribute-level information through modeling item-attribute correlation. In this way, it is expected to inject useful attribute information into item representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given an item i and the attribute set</head><formula xml:id="formula_14">A i = {a 1 , • • • , a k },</formula><p>we treat the item itself and its associated attributes as two different views. Formally, let e i denote the item embedding obtained by the embedding layer, and e a j denote the embedding for the j-th attribute a j ∈ A i . We design a loss function by the contrastive learning framework that maximizes the mutual information between the two views. Following Eq. 3, we minimize the Associated Attribute Prediction (AAP) loss by: <ref type="bibr" target="#b9">(10)</ref> where we sample negative attributes ã that enhance the association between the item i and the ground-truth attributes, "\" defines set subtraction operation. The function f (•, •) is implemented with a simple bilinear network:</p><formula xml:id="formula_15">L AAP (i, A i ) = E a j ∈A i [f (i, a j ) − log ã ∈A\A i exp(f (i, ã))],</formula><formula xml:id="formula_16">f (i, a j ) = σ e ⊤ i • W AAP • e a j ,<label>(11)</label></formula><p>where W AAP ∈ R d ×d is a parameter matrix to learn and σ (.) is the sigmoid function. Note that for clarity, we give the loss definition L AAP for a single item. It will be easy to define this loss over the entire item set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Modeling</head><p>Sequence-Item Correlation. Conventional sequential recommendation models are usually trained to predict the item at the next step. This approach only considers the sequential characteristics in an item sequence from left to right. While it is noted that the entire interaction sequence is indeed observed by the model in the training process. Inspired by the masked language model like BERT <ref type="bibr" target="#b0">[1]</ref>, we propose to model the bidirectional information in item sequence by a Cloze task. For our task, the Cloze setting is described as below: at each training step, we randomly mask a proportion of items in the input sequence (i.e., replace them with special tokens "[mask]"). Then we predict the masked items from the original sequence based on the surrounding context in both directions.</p><p>Therefore, the second loss we consider is to recover the actual item with the bidirectional context from the input sequences. For this purpose, we prepare a pre-trained version of the base model in Section 4.2, which is a bidirectional Transformer architecture. As illustration, let us mask the t-th item i t in a sequence</p><formula xml:id="formula_17">{i 1 , • • • , i t , • • • , i n }. We treat the rest sequence {i 1 , • • • , mask, • • • , i n }</formula><p>as the surrounding context for i t , denoted by C i t . Given the surrounding context C i t and the masked item i t , we treat them as two different views to fuse for learning data representations. Following Eq. 3, we minimize the Masked Item Prediction (MIP) loss by:</p><formula xml:id="formula_18">L M I P (C i t , i t ) = f (C i t , i t ) − log[ ĩ ∈I\{i t } f (C i t , i t )],<label>(12)</label></formula><p>where ĩ denotes an irrelevant item, and f (•, •) is implemented according to the following formula:</p><formula xml:id="formula_19">f (C i t , i t ) = σ F ⊤ t • W M I P • e i t ,<label>(13)</label></formula><p>where W M I P ∈ R d ×d is a parameter matrix to learn and F t is the learned representation for the t-th position using the bidirectional Transformer architecture obtained in the same way as Eq. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Modeling Sequence-Attribute Correlation.</head><p>Having modeled both item-attribute and sequence-item correlations, we further consider directly fusing attribute information with sequential contexts. Specifically, we adopt a similar way as in Section 4.3.2 to recover the attributes of a masked item based on surrounding contexts. Given a masked item i t , we treat its surrounding context C i t and its attribute set A i t as two different views for MIM. As such, we can develop the following Masked Attribute Prediction (MAP) loss by:</p><formula xml:id="formula_20">L MAP (C i t , A i t ) =E a ∈A i t [f (C i t , a) − log ã ∈A\A i exp(f (C i t , ã))],<label>(14)</label></formula><p>where f (•, •) is implemented according to the following formula:</p><formula xml:id="formula_21">f (C i t , a) = σ F ⊤ t • W MAP • e a ,<label>(15)</label></formula><p>where W MAP ∈ R d ×d is a parameter matrix to learn. Note that existing methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24]</ref> seldom directly model the correlation between the sequential context and attribute information. While, we would like to explicitly model the correlation to derive more meaningful supervision signals, which is useful to improve the data representations for multi-granularity information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Modeling</head><p>Sequence-Segment Correlation. As shown above, the Cloze learning strategy plays a key role in our pre-trained approach in fusing sequential contexts with target information. However, a major difference between item sequence with word sequence is that a single target item may not be highly related to surrounding contexts. For example, a user has bought some products just because they were on sale. Based on this concern, we extend the Cloze strategy from a single item to item subsequence (i.e., called segment). Apparently, an item segment reflects more clear, stable user preference than a single item. Therefore, we follow a similar strategy in Section 4.3.2 to recover an item subsequence from surrounding contexts. It is expected to enhance the self-supervised learning signal and improve the pre-trained performance. Let i j 1 :j 2 denote the subsequence from item i j 1 to i j 2 , and C i j 1 :j 2 denote the context for i j 1 :j 2 within the entire sequence. Similar to Eq. 12, we can recover the missing item segment with a MIM formulation, which is so called the Segment Prediction (SP) loss as:</p><formula xml:id="formula_22">L S P (C i j 1 :j 2 , i j 1 :j 2 ) =f (C i j 1 :j 2 , i j 1 :j 2 ) − log ĩj 1 :j 2 exp f (C i j 1 :j 2 , ĩj 1 :j 2 ) ,<label>(16)</label></formula><p>where ĩj 1 , j 2 is the corrupted negative subsequence and f (•, •) is implemented according to the following formula:</p><formula xml:id="formula_23">f (C i j 1 :j 2 , i j 1 :j 2 ) = σ s ⊤ • W S P • s ,<label>(17)</label></formula><p>where W S P ∈ R d ×d is a parameter matrix to learn, and s and s are the learned representations for the contexts C i j 1 :j 2 and subsequence i j 1 :j 2 , respectively. In order to learn s and s, we apply the bidirectional Transformer to obtain the state representations of the last position in a sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Learning and Discussion</head><p>In this part, we present the learning and related discussions of our S<ref type="foot" target="#foot_2">3</ref> -Rec for sequential recommendation.</p><p>4.4.1 Learning. The entire procedure of S 3 -Rec consists of two important stages, namely pre-training and fine-tuning stages. We adopt bidirectional and unidirectional Transformer <ref type="bibr" target="#b25">[26]</ref> architectures for the two stages, respectively. At the pre-trained stage, we optimize the self-supervised learning objectives by considering four different kinds of correlations (Eq. 10, Eq. 12, Eq. 14 and Eq. 16); at the fine-tuning stage, we utilize the learned parameters from the pre-trained stage to initialize the parameters of the unidirectional Transformer, and then utilize the left-to-right supervised signals to train the network. We adopt the pairwise rank loss to optimize its parameters as:</p><formula xml:id="formula_24">L main = − u ∈U n t =1 log σ P(i t +1 |i 1:t ) − P(i − t +1 |i 1:t ) ,<label>(18)</label></formula><p>where we pair each ground-truth item i t +1 with a negative item i − t +1 that is randomly sampled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Discussion</head><p>. Our work provides a novel self-supervised approach to capturing the intrinsic data correlation from the input as an additional signal through the pre-trained models. This approach is quite general so that many existing methods can be included in this framework. We make a brief discussion below.</p><p>Feature-based approaches such as Factorization Machine <ref type="bibr" target="#b19">[20]</ref> and AutoInt <ref type="bibr" target="#b21">[22]</ref> mainly learn data representations through the interaction of context features. The final prediction is made according to the actual interaction results between the user and item features. In S 3 -Rec, the associated attribute prediction loss L AAP in Eq. 10 and the masked attribute prediction loss L M AP in Eq. 14 have the similar effect in feature interaction. However, we do not explicitly model the interaction between attributes. Instead, we focus on capturing the association between attribute information and item/sequential contexts. A major difference in our work is to utilize feature interaction as additional supervision signals to enhance data representations instead of making predictions.</p><p>Sequential models such as GRU4Rec <ref type="bibr" target="#b20">[21]</ref> and SASRec <ref type="bibr" target="#b7">[8]</ref> mainly focus on modeling the sequential dependencies between contextual items and the target item in a left-to-right order. S 3 -Rec additionally incorporates a pre-trained stage that leverages four different kinds of self-supervised learning signals for enhancing data representations. In particular, the masked item prediction loss L M I P in Eq. 12 has a similar effect to capture sequential dependencies as in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21]</ref> except that it can also utilize bidirectional sequential information.</p><p>Attribute-aware sequential models such as TransFM <ref type="bibr" target="#b15">[16]</ref> and FDSA <ref type="bibr" target="#b28">[29]</ref> leverage the contextual features to improve the sequential recommender models, in which these features are treated as auxiliary information to enhance the representation of items or sequences. In our S 3 -Rec, the L AAP loss and L M AP loss aim to fuse attribute with items or sequential contexts, which is able to achieve the same effect as previous methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b28">29]</ref>. Besides, the pre-trained data representations can be also applied to improve existing methods.  <ref type="table" target="#tab_1">1</ref>.</p><p>(1) Meituan<ref type="foot" target="#foot_0">1</ref> : this dataset consists of six-year (from Jan. 2014 to Jan. 2020) transaction records in Beijing on the Meituan platform. We select categories, locations, and the keywords extracted from customer reviews as attributes.</p><p>(2) Amazon Beauty, Sports, and Toys: these three datasets are obtained from Amazon review datasets in <ref type="bibr" target="#b13">[14]</ref>. In this work, we select three subcategories: "Beauty", "Sports and Outdoors", and "Toys and Games", and utilize the fine-grained categories and the brands of the goods as attributes.</p><p>(3) Yelp<ref type="foot" target="#foot_1">2</ref> : this is a popular dataset for business recommendation. As it is very large, we only use the transaction records after January 1st, 2019. We treat the categories of businesses as attributes.</p><p>(4) LastFM 3 : this is a music artist recommendation dataset and contains user tagging behaviors for artists. In this dataset, the tags of the artists given by the users are used as attributes.</p><p>For all datasets, we group the interaction records by users and sort them by the interaction timestamps ascendingly. Following <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29]</ref>, we only keep the 5-core datasets, and filter unpopular items and inactive users with fewer than five interaction records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Evaluation Metrics.</head><p>We employ top-k Hit Ratio (HR@k), topk Normalized Discounted Cumulative Gain (NDCG@k), and Mean Reciprocal Rank (MRR) to evaluate the performance, which are widely used in related works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29]</ref>. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>, we apply the leave-oneout strategy for evaluation. Concretely, for each user interaction sequence, the last item is used as the test data, the item before the last one is used as the validation data, and the remaining data is used for training. Since the item set is large, it is time-consuming to use all items as candidates for testing. Following the common strategy <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, we pair the ground-truth item with 99 randomly sampled negative items that the user has not interacted with. We calculate all metrics according to the ranking of the items and report the average score over all test users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Baseline Models.</head><p>We compare our proposed approach with the following eleven baseline methods:</p><p>(1) PopRec is a non-personalized method that ranks items according to popularity measured by the number of interactions.</p><p>(2) FM <ref type="bibr" target="#b19">[20]</ref> characterizes the pairwise interactions between variables using factorized model.</p><p>(3) AutoInt <ref type="bibr" target="#b21">[22]</ref> utilizes the multi-head self-attentive neural network to learn the feature interaction.</p><p>(4) GRU4Rec <ref type="bibr" target="#b2">[3]</ref> applies GRU to model user click sequence for session-based recommendation. We represent the items using embedding vectors rather than one-hot vectors.</p><p>(5) Caser <ref type="bibr" target="#b23">[24]</ref> is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.</p><p>(6) SASRec <ref type="bibr" target="#b7">[8]</ref> is a self-attention based sequential recommendation model, which uses the multi-head attention mechanism to recommend the next item.</p><p>(7) BERT4Rec <ref type="bibr" target="#b22">[23]</ref> uses a Cloze objective loss for sequential recommendation by the bidirectional self-attention mechanism.</p><p>(8) HGN <ref type="bibr" target="#b12">[13]</ref> is recently proposed and adopts hierarchical gating networks to capture long-term and short-term user interests.</p><p>(9) GRU4Rec F <ref type="bibr" target="#b3">[4]</ref> is an improved version of GRU4Rec, which leverages attributes to improve the performance.</p><p>(10) SASRec F is our extension of SASRec, which concatenates the representations of item and attribute as the input to the model. ( <ref type="formula" target="#formula_16">11</ref>) FDSA <ref type="bibr" target="#b28">[29]</ref> constructs a feature sequence and uses a featurelevel self-attention block to model the feature transition patterns. This is the state-of-the-art model in sequential recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Implementation Details.</head><p>For Caser and HGN, we use the source code provided by their authors. For other methods, we implement them by PyTorch. All hyper-parameters are set following the suggestions from the original papers.</p><p>For our proposed S 3 -Rec, we set the number of the self-attention blocks and the attention heads as 2. The dimension of the embedding is 64, and the maximum sequence length is 50 (following <ref type="bibr" target="#b7">[8]</ref>). Note that our training phase contains two stages (i.e., pre-training and fine-tuning stage), the learned parameters in the pre-training stage are used to initialize the embedding layers and self-attention layers of our model in the fine-tuning stage.</p><p>In the pre-training stage, the mask proportion of item is set as 0.2 and the weights for the four losses (i.e., AAP, MIP, MAP, and SP) are set as 0.2, 1.0, 1.0, and 0.5, respectively, based on our empirical experiments. We use the Adam optimizer <ref type="bibr" target="#b8">[9]</ref> with a learning rate of 0.001, where the batch size is set as 200 and 256 in the pre-training and the fine-tuning stage, respectively. We pre-train our model for 100 epochs and fine-tune it on the recommendation task. The code and data set are available at the link: https://github.com/RUCAIBox/ CIKM2020-S3Rec<ref type="foot" target="#foot_3">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head><p>The results of different methods on all datasets are shown in Table <ref type="table" target="#tab_2">2</ref>. Based on the results, we can find:</p><p>For three non-sequential recommendation baselines, the performance order is consistent across all datasets, i.e., PopRec &gt; AutoInt &gt; FM. Due to the "rich-gets-richer" effect in product adoption, PopRec is a robust baseline. AutoInt performs better than FM on most datasets because the multi-head self-attention mechanism has a stronger capacity to model attributes. However, the performance of AutoInt is worse than that of FM on Meituan dataset. A potential reason is that the multi-head self-attention may incorporate more noise from the attributes since they are keywords extracted from the reviews on Meituan platform. In general, non-sequential recommendation methods perform worse than sequential recommendation methods, since the sequential pattern is important to consider in our task.</p><p>As for sequential recommendation baseline methods, SASRec and BERT4Rec utilize the unidirectional and bidirectional selfattention mechanism respectively, and achieve better performance than GRU4Rec and Caser. It indicates that self-attentive architecture is particularly suitable for modeling sequential data. However, their improvements are not stable when training with the conventional next-item prediction loss. Besides, HGN achieves comparable performance with SASRec and BERT4Rec. This indicates the hierarchical gating network can well model the relations between closely relevant items. However, when directly injecting the attribute information into GRU4Rec and SASRec (i.e., GRU4Rec F and SASRec F ), the performance improvement is not consistent. This method yields improvement on Beauty, Sports, Toys, and Yelp datasets, but has a negative influence on other datasets. One possible reason is that simply concatenating item representations and its attributes representations cannot effectively fuse the two kinds of information. In most cases, FDSA achieves the best performance among all baselines. This suggests that the feature-level self-attention blocks can capture useful sequential feature interaction patterns.</p><p>Finally, by comparing our approach with all the baselines, it is clear to see that S 3 -Rec performs consistently better than them by a large margin on six datasets. Different from these baselines, we adopt the self-supervised learning to enhance the representations of the attribute, item, and sequence for the recommendation task, which incorporates four pre-training objectives to model multiple data correlations by MIM. This result also shows that the selfsupervised approach is effective to improve the performance of the self-attention architecture for sequential recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Further Analysis</head><p>Next, we continue to study whether S 3 -Rec works well in more detailed analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Ablation Study.</head><p>Our proposed self-supervised approach S 3 -Rec designs four pre-training objectives based on MIM. To verify the effectiveness of each objective, we conduct the ablation study on Meituan, Beauty, Sports, and Toys datasets to analyze the contribution of each objective. NDCG@10 is adopted for this evaluation. The results from the best baseline FDSA are also provided for comparison.</p><p>From the results in Fig. <ref type="figure">2</ref>, we can observe that removing any self-supervised objective would lead to the performance decrease. It indicates all the objectives are useful to improve the recommendation performance. Besides, the importance of these objectives    It is clearly seen that all model variants are better than the best baseline FDSA, which is trained only with next-item predication loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Applying</head><p>Self-Supervised Learning to Other Models. Since self-supervised learning itself is a learning paradigm, it can generally apply to various models. Thus, in this part, we conduct an experiment to examine whether our method can bring improvements to other models. We use the self-supervised approach to pre-training some baseline models on Beauty and Toys datasets. For GRU4Rec, GRU4Rec F , SASRec, and SASRec F , we directly apply our pre-training objectives to improve them. It is worth noting that GRU4Rec and SASRec are unidirectional models, so we maintain the unidirectional encoder layer in the pre-training stage. For Au-toInt and Caser, since their architectures do not support some of the pre-training objectives 5 , we only utilize the pre-trained parameters to initialize the parameters of the embedding layers.</p><p>The results of NDCG@10 on Beauty and Toys datasets are shown in Fig. <ref type="figure" target="#fig_1">3</ref>. First, after pre-training by our approach, all the baselines achieve better performance. This shows that self-supervised learning can also be applied to improve their performance. Second, S 3 -Rec outperforms all the baselines after pre-training. This is because 5 Because their base models do not support the mask operations.  our model adopts the bidirectional Transformer encoder in the pretraining stage, which is more suitable for our approach. Third, we can see the GRU-based models achieve less improvement than the other models. One possible reason is that RNN-based architecture limits the potential of self-supervised learning. Conventional recommendation systems require a considerable amount of training data, thus they are likely to suffer from the cold start problem in real-world applications. This problem can be alleviated by our method because the proposed self-supervised learning approach can better utilize the data correlation from input. We simulate the data sparsity scenarios by using different proportions of the full dataset, i.e., 20%, 40%, 60%, 80%, and 100%. Fig. <ref type="figure" target="#fig_2">4</ref> shows the evaluation results on Sports and Yelp datasets. As we can see, the performance substantially drops when less training data is used. While, S 3 -Rec is consistently better than baselines in all cases, especially in an extreme sparsity level (20%). This observation implies that S 3 -Rec is able to make better use of the data with the self-supervised method, which alleviates the influence of data sparsity problem for sequential recommendation to some extent. Our approach consists of a pre-training stage and a finetuning stage. In the pre-training stage, our model can learn the enhanced representations of the attribute, item, subsequence, and sequence for the recommendation task. The number of pre-training epochs affects the performance of the recommendation task. To investigate this, we pre-train our model with a varying number of epochs and fine-tune it on the recommendation task.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref> presents the results on Beauty and Toys datasets. The horizontal dash lines represent the performance without pre-training. We can see that our model benefits mostly from the first 20 pretraining epochs. And after that, the performance improves slightly. Based on this observation, we can conclude that the correlations among different views (i.e., the attribute, item, subsequence, and sequence) can be well-captured by our self-supervised learning approach through pre-training within a small number of epochs. So that the enhanced data representations can improve the performance of sequential recommendation.  our model on the recommendation task. To examine the convergence speed on the final recommendation task, we gradually increase the number of epochs for the fine-tuning stage and compare the performance of our model and other baselines. Fig. <ref type="figure" target="#fig_8">6</ref> shows the results on Beauty and Toys datasets. It can be observed that our model converges quickly and achieves the best performance after about 40 epochs. In contrast to our model, the comparison models need more epochs to achieve stable performance. This result shows that our approach can utilize pre-trained parameters to help the model converge faster and achieve better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we proposed a self-supervised sequential recommendation model S 3 -Rec based on the mutual information maximization (MIM) principle. In our approach, we adopted the self-attentive recommender architecture as the base model and devised four selfsupervised learning objectives to learn the correlations within the raw data. Based on MIM, the four objectives can learn the correlations among attribute, item, segment, and sequence, which enhances the data representations for sequential recommendation. Experimental results have shown that our approach outperforms several competitive baselines.</p><p>In the future, we will investigate how to design other forms of self-supervised optimization objectives. We will also consider applying our approach to more complex recommendation tasks, such as conversational recommendation and multimedia recommendation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overview of S 3 -Rec in the pre-training stage. We assume that the user sequence is {i 1 , • • • , i n } and each item i is associated with several attributes A i = {a 1 , • • • , a m }. We incorporate four self-supervised learning objectives: (1) Associated Attribute Prediction (AAP), (2) Masked Item Prediction (MIP), (3) Masked Attribute Prediction (MAP), and (4) Segment Prediction (SP). The embedding layers and bidirectional self-attention blocks are shared by the four pre-training objectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Performance (NDCG@10) comparison of different models enhanced by our self-supervised learning approach on Beauty and Toys datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance (NDCG@10) comparison w.r.t. different sparsity levels on Sport and Yelp datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance (NDCG@10) comparison w.r.t. different numbers of pre-training epochs on Beauty and Toys datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5. 3 . 3</head><label>33</label><figDesc>Performance Comparison w.r.t. the Amount of Training Data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5. 3 . 4</head><label>34</label><figDesc>Performance Comparison w.r.t. the Number of Pre-training Epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>5. 3 . 5</head><label>35</label><figDesc>Convergence Speed Comparison. After obtaining the enhanced representations of the attribute, item, and sequence, we fine-tune</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: Performance tuning (NDCG@10) of our approach and other baselines with the increasing iterations in the finetuning stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets after preprocessing.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Meituan Beauty Sports</cell><cell>Toys</cell><cell cols="2">Yelp LastFM</cell></row><row><cell># Users</cell><cell cols="6">13,622 22,363 25,598 19,412 30,431 1,090</cell></row><row><cell># Items</cell><cell cols="6">20,062 12,101 18,357 11,924 20,033 3,646</cell></row><row><cell># Avg. Actions / User</cell><cell>54.9</cell><cell>8.9</cell><cell>8.3</cell><cell>8.6</cell><cell>10.4</cell><cell>48.2</cell></row><row><cell># Avg. Actions / Item</cell><cell>37.3</cell><cell>16.4</cell><cell>16.1</cell><cell>14.1</cell><cell>15.8</cell><cell>14.4</cell></row><row><cell># Actions</cell><cell cols="6">747,827 198,502 296,337 167,597 316,354 52,551</cell></row><row><cell>Sparsity</cell><cell cols="6">99.73% 99.93% 99.95% 99.93% 99.95% 98.68%</cell></row><row><cell># Attributes</cell><cell cols="5">331 1,221 2,277 1,027 1,001</cell><cell>388</cell></row><row><cell># Avg. Attribute / Item</cell><cell>8.8</cell><cell>5.1</cell><cell>6.0</cell><cell>4.3</cell><cell>4.8</cell><cell>31.5</cell></row><row><cell cols="2">5 EXPERIMENT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">5.1 Experimental Setup</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">5.1.1 Dataset. We conduct experiments on six datasets collected</cell></row><row><cell cols="7">from four real-world platforms with varying domains and spar-</cell></row><row><cell cols="7">sity levels. The statistics of these datasets after preprocessing are</cell></row><row><cell>summarized in Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of different methods on six datasets. The best performance and the second best performance methods are denoted in bold and underlined fonts respectively. " * " indicates the statistical significance for p &lt; 0.01 compared to the best baseline method.</figDesc><table><row><cell cols="3">Datasets Metric</cell><cell>PopRec</cell><cell cols="2">FM</cell><cell cols="6">AutoInt GRU4Rec Caser SASRec BERT4Rec HGN GRU4Rec F SASRec F FDSA S 3 -Rec Improv.</cell></row><row><cell></cell><cell></cell><cell>HR@1</cell><cell cols="5">0.0946 0.1084 0.0804</cell><cell>0.1194</cell><cell cols="2">0.1368 0.1797</cell><cell>0.1381</cell><cell>0.1603</cell><cell>0.1436</cell><cell>0.1746</cell><cell>0.1778 0.2040  *  13.52%</cell></row><row><cell></cell><cell></cell><cell>HR@5</cell><cell cols="5">0.2660 0.3218 0.2662</cell><cell>0.3382</cell><cell cols="2">0.3812 0.4524</cell><cell>0.3985</cell><cell>0.4110</cell><cell>0.3799</cell><cell>0.4386</cell><cell>0.4595 0.4925  *</cell><cell>7.18%</cell></row><row><cell cols="2">Meituan</cell><cell>NDCG@5 HR@10</cell><cell cols="5">0.1813 0.2170 0.1739 0.3863 0.4709 0.4077</cell><cell>0.2303 0.4881</cell><cell cols="2">0.2619 0.3207 0.5267 0.6053</cell><cell>0.2713 0.5514</cell><cell>0.2887 0.5573</cell><cell>0.2639 0.5378</cell><cell>0.3098 0.5962</cell><cell>0.3236 0.3527  *  0.6164 0.6368  *</cell><cell>8.99% 3.31%</cell></row><row><cell></cell><cell></cell><cell cols="6">NDCG@10 0.2200 0.2651 0.2194</cell><cell>0.2787</cell><cell cols="2">0.3090 0.3700</cell><cell>0.3208</cell><cell>0.3359</cell><cell>0.3149</cell><cell>0.3607</cell><cell>0.3743 0.3994  *</cell><cell>6.71%</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell cols="5">0.1923 0.2242 0.1854</cell><cell>0.2359</cell><cell cols="2">0.2617 0.3146</cell><cell>0.2689</cell><cell>0.2863</cell><cell>0.2666</cell><cell>0.3064</cell><cell>0.3167 0.3421  *</cell><cell>8.02%</cell></row><row><cell></cell><cell></cell><cell>HR@1</cell><cell cols="5">0.0678 0.0405 0.0447</cell><cell>0.1337</cell><cell cols="2">0.1337 0.1870</cell><cell>0.1531</cell><cell>0.1683</cell><cell>0.1702</cell><cell>0.1778</cell><cell>0.1840 0.2192  *  17.22%</cell></row><row><cell></cell><cell></cell><cell>HR@5</cell><cell cols="5">0.2105 0.1461 0.1705</cell><cell>0.3125</cell><cell cols="2">0.3032 0.3741</cell><cell>0.3640</cell><cell>0.3544</cell><cell>0.3727</cell><cell>0.3863</cell><cell>0.4010 0.4502  *  12.27%</cell></row><row><cell cols="2">Beauty</cell><cell>NDCG@5 HR@10</cell><cell cols="5">0.1391 0.0934 0.1063 0.3386 0.2311 0.2872</cell><cell>0.2268 0.4106</cell><cell cols="2">0.2219 0.2848 0.3942 0.4696</cell><cell>0.2622 0.4739</cell><cell>0.2656 0.4503</cell><cell>0.2759 0.4753</cell><cell>0.2870 0.4843</cell><cell>0.2974 0.3407  *  14.56% 0.5096 0.5506  *  8.05%</cell></row><row><cell></cell><cell></cell><cell cols="6">NDCG@10 0.1803 0.1207 0.1440</cell><cell>0.2584</cell><cell cols="2">0.2512 0.3156</cell><cell>0.2975</cell><cell>0.2965</cell><cell>0.3090</cell><cell>0.3185</cell><cell>0.3324 0.3732  *  12.27%</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell cols="5">0.1558 0.1096 0.1226</cell><cell>0.2308</cell><cell cols="2">0.2263 0.2852</cell><cell>0.2614</cell><cell>0.2669</cell><cell>0.2751</cell><cell>0.2844</cell><cell>0.2943 0.3340  *  13.49%</cell></row><row><cell></cell><cell></cell><cell>HR@1</cell><cell cols="5">0.0763 0.0489 0.0644</cell><cell>0.1160</cell><cell cols="2">0.1135 0.1455</cell><cell>0.1255</cell><cell>0.1428</cell><cell>0.1466</cell><cell>0.1573</cell><cell>0.1585 0.1841  *  16.15%</cell></row><row><cell></cell><cell></cell><cell>HR@5</cell><cell cols="5">0.2293 0.1603 0.1982</cell><cell>0.3055</cell><cell cols="2">0.2866 0.3466</cell><cell>0.3375</cell><cell>0.3349</cell><cell>0.3547</cell><cell>0.3730</cell><cell>0.3855 0.4267  *  10.69%</cell></row><row><cell cols="2">Sports</cell><cell>NDCG@5 HR@10</cell><cell cols="5">0.1538 0.1048 0.1316 0.3423 0.2491 0.2967</cell><cell>0.2126 0.4299</cell><cell cols="2">0.2020 0.2497 0.4014 0.4622</cell><cell>0.2341 0.4722</cell><cell>0.2420 0.4551</cell><cell>0.2535 0.4758</cell><cell>0.2683 0.4912</cell><cell>0.2756 0.3104  *  12.63% 0.5136 0.5614  *  9.31%</cell></row><row><cell></cell><cell></cell><cell cols="6">NDCG@10 0.1902 0.1334 0.1633</cell><cell>0.2527</cell><cell cols="2">0.2390 0.2869</cell><cell>0.2775</cell><cell>0.2806</cell><cell>0.2925</cell><cell>0.3064</cell><cell>0.3170 0.3538  *  11.61%</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell cols="5">0.1660 0.1202 0.1435</cell><cell>0.2191</cell><cell cols="2">0.2100 0.2520</cell><cell>0.2378</cell><cell>0.2469</cell><cell>0.2549</cell><cell>0.2680</cell><cell>0.2748 0.3071  *  11.75%</cell></row><row><cell></cell><cell></cell><cell>HR@1</cell><cell cols="5">0.0585 0.0257 0.0448</cell><cell>0.0997</cell><cell cols="2">0.1114 0.1878</cell><cell>0.1262</cell><cell>0.1504</cell><cell>0.1673</cell><cell>0.1797</cell><cell>0.1717 0.2003  *</cell><cell>6.66%</cell></row><row><cell></cell><cell></cell><cell>HR@5</cell><cell cols="5">0.1977 0.0978 0.1471</cell><cell>0.2795</cell><cell cols="2">0.2614 0.3682</cell><cell>0.3344</cell><cell>0.3276</cell><cell>0.3695</cell><cell>0.3927</cell><cell>0.3994 0.4420  *  10.67%</cell></row><row><cell>Toys</cell><cell></cell><cell>NDCG@5 HR@10</cell><cell cols="5">0.1286 0.0614 0.0960 0.3008 0.1715 0.2369</cell><cell>0.1919 0.3896</cell><cell cols="2">0.1885 0.2820 0.3540 0.4663</cell><cell>0.2327 0.4493</cell><cell>0.2423 0.4211</cell><cell>0.2719 0.4782</cell><cell>0.2911 0.4981</cell><cell>0.2903 0.3270  *  12.33% 0.5129 0.5530  *  7.82%</cell></row><row><cell></cell><cell></cell><cell cols="6">NDCG@10 0.1618 0.0850 0.1248</cell><cell>0.2274</cell><cell cols="2">0.2183 0.3136</cell><cell>0.2698</cell><cell>0.2724</cell><cell>0.3070</cell><cell>0.3252</cell><cell>0.3271 0.3629  *  10.94%</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell cols="5">0.1430 0.0819 0.1131</cell><cell>0.1973</cell><cell cols="2">0.1967 0.2842</cell><cell>0.2338</cell><cell>0.2454</cell><cell>0.2717</cell><cell>0.2886</cell><cell>0.2863 0.3202  *  10.95%</cell></row><row><cell></cell><cell></cell><cell>HR@1</cell><cell cols="5">0.0801 0.0624 0.0731</cell><cell>0.2053</cell><cell cols="2">0.2188 0.2375</cell><cell>0.2405</cell><cell>0.2428</cell><cell>0.2293</cell><cell>0.2301</cell><cell>0.2198 0.2591  *</cell><cell>6.71%</cell></row><row><cell></cell><cell></cell><cell>HR@5</cell><cell cols="5">0.2415 0.2036 0.2249</cell><cell>0.5437</cell><cell cols="2">0.5111 0.5745</cell><cell>0.5976</cell><cell>0.5768</cell><cell>0.5858</cell><cell>0.5937</cell><cell>0.5728 0.6085  *</cell><cell>1.82%</cell></row><row><cell>Yelp</cell><cell></cell><cell>NDCG@5 HR@10</cell><cell cols="5">0.1622 0.1333 0.1501 0.3609 0.3153 0.3367</cell><cell>0.3784 0.7265</cell><cell cols="2">0.3696 0.4113 0.6661 0.7373</cell><cell>0.4252 0.7597</cell><cell>0.4162 0.7411</cell><cell>0.4137 0.7574</cell><cell>0.4178 0.7706</cell><cell>0.4014 0.4401  *  0.7555 0.7725</cell><cell>3.50% 0.25%</cell></row><row><cell></cell><cell></cell><cell cols="6">NDCG@10 0.2007 0.1692 0.1860</cell><cell>0.4375</cell><cell cols="2">0.4198 0.4642</cell><cell>0.4778</cell><cell>0.4695</cell><cell>0.4694</cell><cell>0.4751</cell><cell>0.4607 0.4934  *</cell><cell>3.26%</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell cols="5">0.1740 0.1470 0.1616</cell><cell>0.3630</cell><cell cols="2">0.3595 0.3927</cell><cell>0.4026</cell><cell>0.3988</cell><cell>0.3929</cell><cell>0.3962</cell><cell>0.3834 0.4190  *</cell><cell>4.07%</cell></row><row><cell></cell><cell></cell><cell>HR@1</cell><cell cols="5">0.0725 0.0183 0.0349</cell><cell>0.0642</cell><cell cols="2">0.0899 0.1211</cell><cell>0.1220</cell><cell>0.0908</cell><cell>0.1385</cell><cell>0.1147</cell><cell>0.0936 0.1743  *  25.85%</cell></row><row><cell></cell><cell></cell><cell>HR@5</cell><cell cols="5">0.1982 0.0954 0.1550</cell><cell>0.1817</cell><cell cols="2">0.2982 0.3385</cell><cell>0.3569</cell><cell>0.2872</cell><cell>0.3202</cell><cell>0.3073</cell><cell>0.2624 0.4523  *  26.73%</cell></row><row><cell cols="2">LastFM</cell><cell>NDCG@5 HR@10</cell><cell cols="5">0.1350 0.0552 0.0946 0.3037 0.1578 0.2596</cell><cell>0.1228 0.2817</cell><cell cols="2">0.1960 0.2330 0.4431 0.4706</cell><cell>0.2409 0.4991</cell><cell>0.1896 0.4193</cell><cell>0.2301 0.4670</cell><cell>0.2113 0.4569</cell><cell>0.1766 0.3156  *  31.01% 0.4055 0.5835  *  16.91%</cell></row><row><cell></cell><cell></cell><cell cols="6">NDCG@10 0.1687 0.0753 0.1285</cell><cell>0.1550</cell><cell cols="2">0.2428 0.2755</cell><cell>0.2871</cell><cell>0.2324</cell><cell>0.2775</cell><cell>0.2594</cell><cell>0.2225 0.3583  *  24.80%</cell></row><row><cell></cell><cell></cell><cell>MRR</cell><cell cols="5">0.1506 0.0743 0.1122</cell><cell>0.1405</cell><cell cols="2">0.2033 0.2364</cell><cell>0.2424</cell><cell>0.1983</cell><cell>0.2410</cell><cell>0.2201</cell><cell>0.1884 0.3072  *  26.73%</cell></row><row><cell>0.35 0.37 0.39 0.41</cell><cell></cell><cell cols="2">Meituan</cell><cell></cell><cell cols="2">0.32 0.34 0.36 0.38</cell><cell></cell><cell>Beauty</cell><cell></cell><cell>0.28 0.30 0.32 0.34 0.36</cell><cell>Sports</cell><cell>0.32 0.34 0.36 0.38</cell><cell>Toys</cell></row><row><cell>0.33</cell><cell cols="4">F D S A ¬ A A P ¬ M IP ¬ M A P ¬ S P S 3 -R e c</cell><cell cols="2">0.30</cell><cell cols="3">F D S A ¬ A A P ¬ M IP ¬ M A P ¬ S P S 3 -R e c</cell><cell>0.26</cell><cell>F D S A ¬ A A P ¬ M IP ¬ M A P ¬ S P S 3 -R e c</cell><cell>0.30</cell><cell>F D S A ¬ A A P ¬ M IP ¬ M A P ¬ S P S 3 -R e c</cell></row><row><cell cols="12">Figure 2: Ablation study of our approach on four datasets (NDCG@10). "¬" indicates that the corresponding objective is re-</cell></row><row><cell cols="11">moved in the pre-training stage, while the rest objectives are kept.</cell></row></table><note>is varying on different datasets. Overall, the AAP (Associated Attribute Prediction) and the MAP (Masked Attribute Prediction) are more important than the other objectives. Removing each of them yields a larger drop of performance on all datasets. One possible reason is that these two objectives enhance the representations of item and sequence with the attributes information.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.meituan.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://www.yelp.com/dataset</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://grouplens.org/datasets/hetrec-2011/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">To further verify the effectiveness of our method, we have performed the experiments that rank the ground-truth item with all the items as candidates. The complete results are shown on our project website at this link.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>This work was partially supported by the National Natural Science Foundation of China under Grant No. 61872369 and 61832017, Beijing Academy of Artificial Intelligence (BAAI) under Grant No. BAAI2020ZJ0301, and Beijing Outstanding Young Scientist Program under Grant No. BJJWZYJH012019100020098, the Fundamental Research Funds for the Central Universities, the Research Funds of Renmin University of China under Grant No.18XNLG22 and 19XNQ047. Xin Zhao is the corresponding author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="307" to="361" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Session-based Recommendations with Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tikk</surname></persName>
		</author>
		<idno>ICLR 2016</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tikk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>ICLR 2019</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Taxonomy-Aware Multi-Hop Reasoning Networks for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="573" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR 2018</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="505" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-Attentive Sequential Recommendation</title>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM 2018</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>ICLR 2015</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A Mutual Information Maximization Perspective of Language Representation Learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-Organization in a Perceptual Network</title>
		<author>
			<persName><forename type="first">R</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="1988">1988. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An efficient framework for learning sentence representations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hierarchical Gating Networks for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="825" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image-Based Recommendations on Styles and Substitutes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR 2015</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Translation-based factorization machines for sequential recommendation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pasricha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="63" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cremonesi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">RepeatNet: A Repeat Aware Neural Recommendation Machine for Session-Based Recommendation</title>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI 2019</title>
				<imprint>
			<date type="published" when="2019-06">Jun Ma, and Maarten de Rijke. 2019</date>
			<biblScope unit="page" from="4806" to="4813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sequential Recommendation with Self-Attentive Multi-Adversarial Network</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR 2020</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Factorization Machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM 2010</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="995" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Factorizing personalized Markov chains for next-basket recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW 2010</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1161" to="1170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1441" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM 2018</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="565" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Representation Learning with Contrastive Predictive Coding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-Supervised Reinforcement Learning for Recommender Systems</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Arapakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joemon</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR 2020</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="931" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">QAInfomax: Learning Robust Question Answering System by Mutual Information Maximization</title>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3368" to="3373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Feature-level Deeper Self-Attention Network for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI 2019</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4320" to="4326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Improving Conversational Recommender Systems via Knowledge Graph based Semantic Fusion</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuqing</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingsong</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
