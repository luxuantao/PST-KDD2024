<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Fusion in Metabolomics Using Coupled Matrix and Tensor Factorizations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Evrim</forename><surname>Acar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Food Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<postCode>DK-1958</postCode>
									<settlement>Frederiksberg C</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rasmus</forename><surname>Bro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Food Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<postCode>DK-1958</postCode>
									<settlement>Frederiksberg C</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Age</forename><forename type="middle">K</forename><surname>Smilde</surname></persName>
							<email>a.k.smilde@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Food Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<postCode>DK-1958</postCode>
									<settlement>Frederiksberg C</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Swammerdam Institute for Life Sciences</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
								<address>
									<postCode>1090 GE</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data Fusion in Metabolomics Using Coupled Matrix and Tensor Factorizations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7D866E5F98C10FEF15A66870C6765AD8</idno>
					<idno type="DOI">10.1109/JPROC.2015.2438719</idno>
					<note type="submission">received November 18, 2014; revised February 2, 2015; accepted May 21, 2015. Date of publication August 14, 2015; date of current version August 20, 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data fusion</term>
					<term>matrix factorizations</term>
					<term>metabolomics</term>
					<term>tensor factorizations</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, the authors formulate data fusion as a coupled matrix and tensor factorization problem and discuss its extension to a structure-revealing data fusion model, i.e., a data fusion model that can identify shared and unshared factors in order to jointly analyze heterogeneous data sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In many disciplines, joint analysis of data from multiple sources has the potential to enhance knowledge discovery. For instance, in metabolomics, biological fluids such as blood or urine are measured using different analytical techniques, e.g., nuclear magnetic resonance (NMR) and liquid chromatography-mass spectrometry (LC-MS), in order to detect the chemicals related to various diseases or diets. Measurements from such platforms are partly complementary in terms of the chemicals they are capable of detecting; therefore, their joint analysis has the potential for more accurate characterization of physiological conditions <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. Similarly, data fusion has proved useful in other fields such as social network analysis <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b7">[8]</ref>, signal processing <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, and bioinformatics <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>.</p><p>Data fusion has often been formulated as a joint factorization problem. Data from multiple sources can be represented as multiple matrices, and these matrices can be jointly analyzed using collective (coupled) matrix factorization methods <ref type="bibr" target="#b13">[14]</ref>. Coupled matrix factorization methods have been developed and applied in chemometrics <ref type="bibr" target="#b14">[15]</ref>, bioinformatics <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, signal processing <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, and data mining <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b17">[18]</ref>. In recent years, these methods have been extended to coupled matrix and tensor factorizations (or coupled tensor factorizations) to deal with multirelational and heterogeneous data, i.e., data sets in the form of higher order tensors and matrices <ref type="bibr" target="#b18">[19]</ref>. For instance, suppose that the goal of a recommender system is activity recommendation, and the system records activities performed by users at different locations. This data set can be represented as a third-order tensor with modes: users, activities, and locations. While activity recommendation can be achieved using this single source of information, additional sources of information such as a location-feature matrix showing the features of locations improve the activity recommendation performance <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. Joint analysis of a third-order tensor and a matrix requires methods like coupled matrix and tensor factorizations. Heterogeneous coupled data sets are also encountered in metabolomics applications. For instance, in fluorescence spectroscopy, measurements for each sample are represented as an excitation-emission matrix, and multiple samples form a third-order tensor with modes: samples, excitation, and emission wavelengths (Fig. <ref type="figure" target="#fig_0">1</ref>). The potential of fluorescence spectroscopic measurements of human plasma samples in cancer diagnostics has recently been demonstrated <ref type="bibr" target="#b19">[20]</ref>. Plasma samples are also commonly measured using LC-MS and NMR in metabolomics studies, and measurements from these analytical methods are arranged as samples by features matrices (Fig. <ref type="figure" target="#fig_0">1</ref>). Exploring all these information sources simultaneously requires data fusion models that can deal with heterogeneous data sets.</p><p>While data fusion has been successfully applied in many fields, joint analysis of data from multiple sources remains a challenging task in need of advanced data mining tools. When the goal of data fusion is missing data estimation as in recommender system applications, coupled factorization methods have proved useful <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>. On the other hand, when the goal of the application is to reveal the underlying structures in data sets, identify shared/unshared factors, and use those extracted factors for interpretation, e.g., for identification of chemicals related to the condition of interest in metabolomics applications, data fusion is still challenging since there is a lack of such structure-revealing data fusion models. There are coupled matrix factorization methods tailored to identify shared/unshared factors <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b22">[23]</ref>; however, they cannot jointly analyze heterogeneous data sets. To the best of our knowledge, the structurerevealing coupled matrix and tensor factorization (CMTF) model <ref type="bibr" target="#b23">[24]</ref> is the only method that addresses the identification of shared/unshared factors within the context of coupled matrix and tensor factorizations in an unsupervised setting.</p><p>In this paper, we focus on the structure-revealing CMTF model and compare it with the state-of-the-art structure-revealing data fusion models in terms of jointly analyzing heterogeneous data sets with shared/unshared factors. Using simulations, we demonstrate that matrix factorization-based data fusion models: 1) can perform as well as the structure-revealing CMTF model when their identifiability assumptions are not violated; and 2) fail to capture the underlying structures and identify shared/ unshared factors accurately in noisy cases or when their identifiability assumptions are violated. On the other hand, in all these cases, the structure-revealing CMTF model can successfully capture the underlying factors by exploiting the low-rank structure of higher order data sets without imposing additional constraints on the factors. Furthermore, we use prototypical coupled experimental data sets, i.e., diffusion-ordered spectroscopy (DOSY) NMR <ref type="bibr" target="#b24">[25]</ref>, and LC-MS measurements of mixtures with known chemical composition, and demonstrate the limitations of matrix factorization-based data fusion models in terms of tackling real data fusion problems with heterogeneous data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DATA FUSION BASED ON COUPLED FACTORIZATIONS</head><p>Data fusion has been a topic of interest in diverse disciplines under different names such as multiview learning <ref type="bibr" target="#b25">[26]</ref>, multiblock or multiset data analysis <ref type="bibr" target="#b14">[15]</ref>, and collective/coupled analysis of data sets <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Here, we are particularly interested in studies that formulate data fusion as a joint factorization problem. We first review the literature on coupled factorizations of data sets in the form of matrices, and then discuss data fusion studies jointly factorizing heterogeneous data sets. In this paper, only unsupervised data fusion methods are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Coupled Matrix Factorizations</head><p>Earlier studies on data fusion focus on joint factorization of multiple matrices. With a goal of analyzing multirelational data, Singh and Gordon <ref type="bibr" target="#b13">[14]</ref> introduced a collective matrix factorization framework that simultaneously factorizes multiple matrices sharing factor matrices corresponding to the entities common to multiple relations. Given matrices X 2 R IÂJ and Y 2 R IÂK coupled in the first mode/dimension, their collective matrix factorization can be formulated as</p><formula xml:id="formula_0">f ðU; V; WÞ ¼ kX À UV T k 2 þ kY À UW T k 2 (1)</formula><p>where U 2 R IÂR is the shared factor matrix corresponding to the common mode; V 2 R JÂR and W 2 R KÂR are the factor matrices extracted from the second mode of X and Y, respectively; and R indicates the number of factors. The terms factor and component are used interchangeably throughout the paper. k:k denotes the Frobenius norm for higher order tensors/matrices and the 2-norm for vectors. This formulation is a special case of the framework introduced in <ref type="bibr" target="#b13">[14]</ref>, where each relation can be modeled using a different loss function. Similar joint matrix factorization methods have also been developed for clustering multirelational data <ref type="bibr" target="#b17">[18]</ref> and making accurate predictions in recommender systems <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b27">[28]</ref>. In bioinformatics, coupled matrix factorizations have been used to compare gene expression data of different diseases <ref type="bibr" target="#b11">[12]</ref> and multiple organisms <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b28">[29]</ref>. Coupled matrix factorizations are also used within the context of joint diagonalization of multiple matrices in signal processing <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, and, more recently, in audio source separation applications <ref type="bibr" target="#b8">[9]</ref>. Furthermore, joint factorization of matrices has long been studied in psychometrics, e.g., for simultaneous factorization of Gramian matrices <ref type="bibr" target="#b29">[30]</ref>, and chemometrics <ref type="bibr" target="#b14">[15]</ref>. In some applications such as in metabolomics, sparsityinducing penalty terms are added to the coupled matrix factorization formulation in (1) to extract interpretable factors <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Recently, a convex formulation of coupled matrix factorizations has also been proposed <ref type="bibr" target="#b32">[33]</ref>.</p><p>A closely related method to coupled matrix factorizations is canonical correlation analysis (CCA) <ref type="bibr" target="#b33">[34]</ref>, which extracts maximally correlated factors from two matrices rather than the exact same factors as in <ref type="bibr" target="#b0">(1)</ref>. CCA has been extended to multiple matrices <ref type="bibr" target="#b34">[35]</ref> and also used in data fusion studies, e.g., for jointly analyzing brain imaging modalities such as functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) <ref type="bibr" target="#b35">[36]</ref>. In computational neuroscience, joint independent component analysis (ICA), which performs ICA on concatenated data sets, has also been used to fuse fMRI and EEG signals <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Coupled Matrix and Tensor Factorizations</head><p>When we have data from multiple sources, it is quite restrictive to assume that data sets from different sources are all in the form of matrices. While some data sets are in the form of matrices, some of them may be in the form of higher order tensors as in Fig. <ref type="figure" target="#fig_0">1</ref>. Higher order tensors are higher order extensions of vectors and matrices. A vector is a first-order tensor while a matrix is a second-order tensor, and tensors of order three or more are called higher order tensors <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b40">[41]</ref>. Coupled heterogeneous data sets as in Fig. <ref type="figure" target="#fig_0">1</ref> are ubiquitous in social networks, chemometrics, biomedical signal processing, and becoming widespread in other disciplines as well such as metabolomics. As an extension of (1), joint factorization of heterogeneous data sets, e.g., a third-order tensor X 2 R IÂJÂK , coupled with a matrix Y 2 R IÂM in the first mode, can be formulated as</p><formula xml:id="formula_1">f ðA; B; C; VÞ ¼ X À gA; B; CÄ k k 2 þkY À AV T k 2 (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where X is modeled using a CANDECOMP/PARAFAC (CP) <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> model and Y is factorized in such a way that the factor matrix corresponding to the common mode, i.e., A 2 R IÂR , is the same in both factorizations. B 2 R JÂR and C 2 R KÂR are factor matrices corresponding to the second and third modes of X, respectively. We use the notation X ¼ gA; B; CÄ to denote the CP model. V 2 R MÂR is the factor matrix that corresponds to the second mode of Y. This formulation is not restricted to a thirdorder tensor coupled with a matrix, and extends to joint factorizations of multiple matrices and higher order tensors coupled in different modes. To the best of our knowledge, coupled factorization of higher order tensors has first been introduced by Harshman and Lundy <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref> as the linked-mode PARAFAC model, where two or more third-order tensors coupled in one mode are jointly factorized using a CP model by extracting the same factor matrix from the common mode. Factorization of multiple data sets in the form of matrices and higher order tensors has also been of interest in chemometrics and discussed as multiway multiblock component models <ref type="bibr" target="#b45">[46]</ref>. Instead of extracting the same factor matrix from the coupled mode, Smilde et al. <ref type="bibr" target="#b45">[46]</ref> model each data set separately using matrix or tensor factorizations and use a term in the objective function to account for the similarity of the factor matrices extracted from the common mode.</p><p>In recent years, the CMTF formulation in (2) has been widely used, in particular, in missing data estimation problems. For instance, Zheng et al. <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b46">[47]</ref> jointly factorize an incomplete tensor with modes: users, activities, and locations, coupled with additional side information such as matrices showing user-user similarities in social networks with a goal of filling in the missing entries in the tensor. The same problem in the form of a link prediction problem has also been addressed by Ermis et al. <ref type="bibr" target="#b7">[8]</ref>, who demonstrated that rather than the squared Euclidean distance and the CP model in <ref type="bibr" target="#b1">(2)</ref>, different loss functions and tensor models are crucial for more accurate missing link prediction. Acar et al. <ref type="bibr" target="#b47">[48]</ref> have demonstrated not only the advantages but also the limitations of the CMTF formulation in terms of missing data estimation in coupled data sets. Other than missing data estimation problems, CMTF has also been used to jointly analyze in vitro and histology tissue samples in bioinformatics <ref type="bibr" target="#b12">[13]</ref>. Similar coupled factorization problems have also been encountered as the joint factorization problem of covariance matrices and cumulant tensors in signal processing <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref> and in combined analysis of EEG and magnetoencephalography (MEG) data <ref type="bibr" target="#b50">[51]</ref>.</p><p>While the traditional way of minimizing the objective in (2) is to use alternating algorithms solving the problem for one factor matrix at a time, all-at-once optimization methods such as nonlinear conjugate gradient (NCG) <ref type="bibr" target="#b26">[27]</ref> and nonlinear least squares <ref type="bibr" target="#b51">[52]</ref> methods have also been studied for fitting CMTF models. As fast and scalable CMTF approaches, Papalexakis et al. <ref type="bibr" target="#b52">[53]</ref> have introduced a sampling-based method that fits CMTF models in parallel and then combines the partial results, while Beutel et al. <ref type="bibr" target="#b53">[54]</ref> have proposed to use a stochastic gradient-descent algorithm on Hadoop.</p><p>In different disciplines, the model in (2) has been extended to loss functions other than the squared Euclidean distance. For instance, in social network analysis applications, Kullback-Leibler (KL) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref> and Itakura-Saito (IS) <ref type="bibr" target="#b7">[8]</ref> divergence-based cost functions have proved useful. The CMTF model in (2) has also been extended to coupled tensor factorizations, where higher order tensors are modeled by more flexible models than the CP model. For instance, Sorber et al. <ref type="bibr" target="#b51">[52]</ref> discuss, in particular, Tucker and block term decomposition in addition to the CP model within the context of coupled matrix and tensor factorizations, and Yilmaz et al. <ref type="bibr" target="#b9">[10]</ref> introduce a generalized coupled tensor factorization framework, which can handle arbitrary factorizations of the data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Challenges</head><p>While data fusion studies demonstrate promising results in many tasks, e.g., missing data estimation <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, link prediction <ref type="bibr" target="#b7">[8]</ref>, clustering <ref type="bibr" target="#b17">[18]</ref>, and understanding biological processes <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>, there are several issues that still need to be addressed to explore the full potential of data fusion. For instance, in many data fusion problems, the objective function has multiple parts corresponding to loss functions modeling different data sets. However, how to combine these parts is an open research question <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b54">[55]</ref>. Recent studies tackle this problem by using weights for different parts and learning the weights using maximum-likelihood approaches <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>.</p><p>Another challenge is to understand the uniqueness properties of data fusion methods. Matrix factorizations require constraints such as orthogonality or statistical independence, to capture the underlying factors uniquely; otherwise, they suffer from rotational ambiguities. It has been previously shown that jointly analyzing matrices (coupled in one mode) can mitigate the rotational ambiguity problem <ref type="bibr" target="#b57">[58]</ref>, and when matrices are jointly analyzed, shared/unshared factors may enable the use of constraints such as selectivity that improves the recovery of the true factors <ref type="bibr" target="#b58">[59]</ref>. However, even in those cases, identifiability of the underlying factors still relies on additional constraints imposed on the factors. On the other hand, in the presence of multiple matrices with the same underlying factors in each mode and scaled differently in each matrix, it is possible to uniquely recover the factors without imposing any constraints on the factors. This can be achieved using the CP model, which is unique under mild uniqueness conditions discussed in detail in <ref type="bibr" target="#b39">[40]</ref> and <ref type="bibr" target="#b59">[60]</ref>. When a CP model is used to model higher order tensors in coupled matrix and tensor factorizations, CMTF models inherit uniqueness properties from the CP model <ref type="bibr" target="#b60">[61]</ref>. Recently, it has also been shown that joint analysis of multiple higher order tensors using coupled CP models has more relaxed uniqueness conditions than the CP model <ref type="bibr" target="#b60">[61]</ref>.</p><p>Identification of shared and unshared factors remains to be another difficult but crucial task in data fusion. Previously, generalized singular value decomposition (GSVD) <ref type="bibr" target="#b61">[62]</ref> was used to find shared/unshared factors in joint analysis of data sets in genomics <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b62">[63]</ref>, and extended to joint factorization of multiple matrices <ref type="bibr" target="#b28">[29]</ref>. Alternative methods addressing the same problem within the context of coupled matrix factorizations have also been developed in different disciplines. For instance, Van Deun et al. <ref type="bibr" target="#b21">[22]</ref> have introduced an additional step in coupled matrix factorizations to rotate the components to a specified target structure showing shared/unshared components while Lock et al. <ref type="bibr" target="#b22">[23]</ref> have jointly factorized multiple coupled data sets into matrices showing the joint and individual effects orthogonal to each other in each data set. An extension of nonnegative matrix factorization (NMF) to joint matrix factorizations that takes into account both shared and unshared components has also been studied in social media retrieval <ref type="bibr" target="#b63">[64]</ref>. Recently, Klami et al. <ref type="bibr" target="#b20">[21]</ref> have built onto CCA-based approaches and introduced a Bayesian treatment of interbattery factor analysis (IBFA) <ref type="bibr" target="#b64">[65]</ref>, which factorizes coupled data sets into shared and data-specific parts. Data fusion methods that can capture shared/unshared factors not only improve the understanding of the underlying processes as in genomics <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b62">[63]</ref> but also provide better performance, for instance, in terms of image/video retrieval <ref type="bibr" target="#b63">[64]</ref>. For joint analysis of heterogeneous data sets, Acar et al. <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b65">[66]</ref> demonstrate that the CMTF formulation in (2) fails to capture the true underlying factors in the presence of unshared factors and introduce a structure-revealing CMTF model. Liu et al. <ref type="bibr" target="#b66">[67]</ref> also formulate coupled tensor factorizations by taking into account shared/unshared components; however, the method is used in a supervised setting and a number of shared/unshared components are determined through cross-validation on the training data. We discuss some of these structure-revealing methods in detail in Section III and provide a comprehensive comparison on simulated and real data in Section IV.</p><p>For a broader list of challenges in data fusion, see <ref type="bibr" target="#b67">[68]</ref> and <ref type="bibr" target="#b68">[69]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Data Fusion in Metabolomics</head><p>Metabolomics is a rich source of data sets, whose joint analysis has the potential to enhance knowledge discovery. In metabolomics, samples are measured using different analytical techniques including gas chromatography-mass spectrometry (GC-MS), LC-MS, NMR, and fluorescence spectroscopy, and measurements from different platforms provide partly complementary information <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. Therefore, fusing data sets from these platforms has been a topic of interest in many studies. Furthermore, it is also of interest to jointly analyze measurements from samples of different types, e.g., plasma, urine, tissues, and cerebrospinal fluid. Richards et al. <ref type="bibr" target="#b0">[1]</ref> provide a comprehensive review of both interplatform and intersample data fusion studies as well as the data mining methods used in such studies.</p><p>Commonly used unsupervised data mining tools for data fusion in metabolomics are variants of collective matrix factorization methods developed in chemometrics such as consensus principal component analysis (PCA) and hierarchical PCA <ref type="bibr" target="#b14">[15]</ref>. However, these methods often lack a clear optimization criterion and are also only devised to jointly analyze multiple data sets all coupled in the same mode. CCA has also been used for data fusion in metabolomics in comparison with PCA-based approaches, and it has been demonstrated that both CCA-and PCA-based methods provide biologically meaningful but different results <ref type="bibr" target="#b69">[70]</ref>. Recently, coupled matrix factorizations with sparsity constraints on the factors have been used to jointly analyze metabolomics data obtained from different platforms <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Metabolomics data from multiple platforms, i.e., GC-MS and LC-MS, have also been analyzed using coupled matrix factorization methods with a goal of identifying shared and unshared factors <ref type="bibr" target="#b21">[22]</ref>. In addition to unsupervised methods, there are many data fusion studies in metabolomics making use of supervised approaches to extract patterns from multiple data sets and using those patterns for classification of a specific condition <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b70">[71]</ref>. The promise of data fusion has been discussed in numerous studies in metabolomics but there is still a need for advanced data mining tools. This is especially crucial as increasingly more applications produce complex and complementary measurements in the form of heterogeneous data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. STRUCTURE-REVEALING DATA FUSION MODELS</head><p>In this section, we describe in detail several structurerevealing data fusion models that will be compared using simulations and real data in Section IV. We are particularly interested in the following models: 1) representative matrix factorization-based models that have been used to identify shared/unshared factors in coupled data sets in different disciplines, i.e., GSVD <ref type="bibr" target="#b61">[62]</ref>, adapted GSVD <ref type="bibr" target="#b21">[22]</ref>, joint and individual variation explained (JIVE) <ref type="bibr" target="#b22">[23]</ref> and Bayesian interbattery factor analysis (BIBFA) <ref type="bibr" target="#b20">[21]</ref>; and 2) the structure-revealing CMTF model proposed for joint analysis of heterogeneous data sets <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Coupled Factorization of Matrices</head><p>1) GSVD and Adapted GSVD: The GSVD is an exact decomposition for any two matrices with the same number of columns <ref type="bibr" target="#b61">[62]</ref>. Given X 2 R MÂN with M ! N and Y 2 R PÂN with P ! N, let Z ¼ ½X T Y T T and R ¼ rankðZÞ. In the case R ¼ N, the GSVD jointly decomposes these matrices in such a way that the same factor matrix is extracted from the common mode as follows:</p><formula xml:id="formula_3">X ¼ UCW; Y ¼ VSW<label>(3)</label></formula><p>where</p><formula xml:id="formula_4">U 2 R MÂM and V 2 R PÂP are orthogonal matrices, W 2 R NÂN is nonsingular, C ¼ diagðc 1 ; . . . c N Þ 2 R MÂN and S ¼ diagðs 1 ; . . . s N Þ 2 R PÂN are diagonal matrices, and c 2 i þ s 2 i ¼ 1.</formula><p>The relation between c i and s i has been previously used for identification of shared/unshared components <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b62">[63]</ref>. For instance, c 2 i ¼ 1, s 2 i ¼ 0 indicates an unshared component in X. A higher order GSVD has also been proposed to extend GSVD to joint analysis of multiple matrices <ref type="bibr" target="#b28">[29]</ref>.</p><p>Van Deun et al. <ref type="bibr" target="#b21">[22]</ref> have recently discussed a modified GSVD method, called adapted GSVD, which performs rank reduction on the concatenated matrix Z ¼ ½X T Y T T as the first step of GSVD in order to compute a least squares approximation rather than the exact decomposition.</p><p>2) JIVE: JIVE <ref type="bibr" target="#b22">[23]</ref> has been developed to extract joint (shared) and individual (unshared) effects in multiple matrices. Let X ð1Þ ; X ð2Þ ; . . . ; X ðMÞ be I m Â N matrices for m ¼ 1; . . . ; M, M ! 2. They can be jointly modeled by JIVE as</p><formula xml:id="formula_5">X ð1Þ ¼ J ð1Þ þ A ð1Þ þ R ð1Þ X ð2Þ ¼ J ð2Þ þ A ð2Þ þ R<label>ð2Þ</label></formula><p>. . .</p><formula xml:id="formula_6">X ðMÞ ¼ J ðMÞ þ A ðMÞ þ R ðMÞ<label>(4)</label></formula><p>where A ðmÞ 2 R I m ÂN represents the individual structure of X ðmÞ , R ðmÞ 2 R I m ÂN corresponds to the residual error, and the joint structure is captured by the matrix</p><formula xml:id="formula_7">J ¼ J<label>ð1Þ</label></formula><p>. . . The model assumes that ranks of J and A ðmÞ are R and R m , respectively; in other words, the number of shared components is R while the number of unshared components in each X ðmÞ is R m . Another assumption is that joint and individual structures are orthogonal to each other, i.e., JA ðmÞT ¼ 0, for m ¼ 1; . . . ; M. Lock et al. <ref type="bibr" target="#b22">[23]</ref> estimate matrices J and A ðmÞ using an alternating algorithm minimizing the residuals in a least squares sense. The model corresponds to the following formulation, which explicitly shows the coupled factorization into shared/unshared factors:</p><formula xml:id="formula_8">X ð1Þ ¼ U ð1Þ S þ W ð1Þ S ð1Þ þ R ð1Þ X ð2Þ ¼ U ð2Þ S þ W ð2Þ S ð2Þ þ R<label>ð2Þ</label></formula><p>. . .</p><formula xml:id="formula_9">X ðMÞ ¼ U ðMÞ S þ W ðMÞ S ðMÞ þ R ðMÞ</formula><p>where U ðmÞ 2 R I m ÂR and S 2 R RÂN model the joint structures while W ðmÞ 2 R I m ÂR m and S ðmÞ 2 R R m ÂN reveal the individual structures.</p><p>3) BIBFA: BIBFA <ref type="bibr" target="#b20">[21]</ref> has been motivated by CCA but rather than just extracting the correlated components between data sets, it is based on interbattery factor analysis <ref type="bibr" target="#b64">[65]</ref>, which takes into account both shared and unshared components. Given two matrices X ðmÞ ¼ ½x where Nð; 2Þ corresponds to the normal distribution with mean and covariance 2; 2 ðmÞ is a diagonal matrix; 0 and I denote the zero and identity matrices of appropriate sizes. Here, z corresponds to the shared factors while z ðmÞ corresponds to the unshared factors in each data set X ðmÞ .</p><p>In order to come up with an effective inference scheme to learn shared and unshared factors, the model is reformulated in <ref type="bibr" target="#b20">[21]</ref> as follows: y $ Nð0; IÞ; x $ NðWy; 2Þ where</p><formula xml:id="formula_10">W ¼ A ð1Þ B ð1Þ 0 A ð2Þ 0 B ð2Þ y ¼ z z ð1Þ z ð2Þ " # 2 ¼ 2 ð1Þ 0 0 2<label>ð2Þ</label></formula><p>:</p><p>The correct structure in W is achieved by imposing groupwise sparsity on W through an extension of the automatic relevance determination (ARD) prior. Variational approximation has been used for inference and an identifiable model is obtained based on the priors that assume maximally orthogonal components; for further details, see <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Coupled Factorization of Heterogeneous Data Sets</head><p>When heterogeneous data sets, e.g., a third-order tensor X 2 R IÂJÂK and a matrix Y 2 R IÂM coupled in the first mode, are jointly factorized using the CMTF formulation in (2), the true underlying factors can be accurately captured if all factors are shared <ref type="bibr" target="#b26">[27]</ref>, i.e., all columns of the common factor matrix A are shared by the matrix and the thirdorder tensor. However, in the presence of both shared and unshared components, it may fail to extract the true factors <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b65">[66]</ref>. Therefore, with a goal of identifying shared/ unshared factors, the model in (2) has been modified as follows <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b65">[66]</ref>:</p><formula xml:id="formula_11">f ðL; 2; A; B; C; VÞ ¼ X À gL; A; B; CÄ k k 2 þ kY À A2V T k 2 þ kLk 1 þ kSk 1 (5)</formula><p>where the columns of factor matrices have unit norm, i.e., ka r k ¼ kb r k ¼ kc r k ¼ kv r k ¼ 1 for r ¼ 1; . . . ; R, and L 2 R RÂ1 and S 2 R RÂ1 correspond to the weights of rank-one components in the third-order tensor and the matrix, respectively. 2 2 R RÂR is a diagonal matrix with entries of S on the diagonal. k:k 1 denotes the 1-norm of a vector, i.e., kxk 1 ¼ P R r¼1 jx r j. &gt;0 is a penalty parameter. Here, a r denotes the rth column of A. This formulation sparsifies the weights through the 1-norm penalties so that unshared factors are expected to have weights equal to 0 in some data sets.</p><p>The objective function in <ref type="bibr" target="#b4">(5)</ref> is minimized by converting it into a differentiable unconstrained optimization problem and solving the problem using NCG <ref type="bibr" target="#b23">[24]</ref>. In order to have an unconstrained optimization problem with a differentiable objective function, the norm constraints are added as quadratic penalty terms to the objective and the 1-norm terms are replaced with differentiable approximations, i.e., for sufficiently small &gt; 0, ffiffiffiffiffiffiffiffiffiffiffiffi</p><formula xml:id="formula_12">x 2 i þ p ¼ jx i j.</formula><p>The objective function of the reformulated CMTF model, called the structurerevealing CMTF model, is as follows, for ! 0:</p><formula xml:id="formula_13">f ðL; 2; A; B; C; VÞ ¼ X À gL; A; B; CÄ k k 2 þkY À A2V T k 2 þ X R r¼1 ffiffiffiffiffiffiffiffiffiffiffi ffi 2 r þ p þ X R r¼1 ffiffiffiffiffiffiffiffiffiffiffi 2 r þ p þ X R r¼1 ka r kÀ1 ð Þ 2 þ X R r¼1 kb r kÀ1 ð Þ 2 þ X R r¼1 kc r kÀ1 ð Þ 2 þ X R r¼1 kv r kÀ1 ð Þ 2 (6)</formula><p>where the terms weighted by correspond to differentiable approximations of the 1-norm penalties, and the terms weighted by impose the unit norm constraints on the columns of the factor matrices.</p><p>In the presence of missing entries, the objective can be modified by introducing binary higher order tensors/ matrices to ignore missing entries and fit the model to the known entries <ref type="bibr" target="#b23">[24]</ref>. While the problem is formulated only for two data sets here, it can also be used for jointly analyzing multiple data sets <ref type="bibr" target="#b23">[24]</ref>. Unlike the traditional alternating methods used for fitting tensor models and coupled factorization models, the algorithmic approach for fitting the structure-revealing CMTF model is an all-at-once optimization approach solving the problem for all factors simultaneously since such all-at-once methods have been previously shown to outperform alternating methods when fitting CP <ref type="bibr" target="#b71">[72]</ref>- <ref type="bibr" target="#b73">[74]</ref> and CMTF models <ref type="bibr" target="#b26">[27]</ref>. As an alternative to the unconstrained optimization approach discussed in this section, a general purpose optimization solver that can handle nonlinear functions in the objective and constraints has also been recently used to fit the structurerevealing CMTF model to have a more flexible modeling framework <ref type="bibr" target="#b74">[75]</ref>. Using that solver, nonnegativity constraints as well as angular constraints that can improve the robustness of the model to overfactoring, can be easily added to the structure-revealing CMTF model <ref type="bibr" target="#b74">[75]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>We compare the structure-revealing data fusion models described in Section III on simulated and real heterogeneous coupled data sets with shared/unshared factors. The simulated data sets, described in Section IV-A, are a collection of data sets consisting of a third-order tensor coupled with a matrix with both shared and unshared components. While generating these data sets, different types of underlying components are considered, i.e., factors with different levels of correlation. We also consider multiple levels of noise to study the effect of noise on the performance of the methods. Implementation details for all methods are given in Section IV-B. In Section IV-C, we discuss the results of the simulations. The results demonstrate that certain matrix factorization-based methods, i.e., BIBFA, perform as well as the structure-revealing CMTF model under low levels of noise and when the underlying factors are not highly correlated. Even under these cases, GSVD fails to identify shared factors; JIVE and adapted GSVD capture distorted components as soon as their assumptions are violated, i.e., when only some factors are orthogonal. When the noise level is increased or underlying factors are correlated, BIBFA also fails, and we observe that the structurerevealing CMTF model is the only one that succeeds in revealing the true shared/unshared components. In Section IV-D, we assess the performance of structurerevealing data fusion models on real data sets, i.e., DOSY NMR and LC-MS measurements of mixtures with known chemical composition. Since real coupled data sets violate the assumptions of matrix factorization-based structurerevealing data fusion models, such methods fail to capture the true design used in mixture preparation and the signatures (spectra/features) of the chemicals. The structurerevealing CMTF model, on the other hand, successfully recovers the design and the signatures corresponding to the underlying chemicals by making use of the low-rank structure in the third-order tensor without imposing additional constraints on the factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulation Data</head><p>We generate factor matrices A 2 R IÂR , B 2 R JÂR , C 2 R KÂR , and V 2 R MÂR , and then use those factor matrices to construct a third-order tensor X 2 R IÂJÂK coupled with a matrix Y 2 R IÂM in such a way that X ¼ gL; A; B; CÄ and Y ¼ A2V T . Here, L and diagonal entries of diagonal matrix 2, i.e., S of length R, correspond to the weights of rank-one third-order tensors and matrices, respectively. A certain amount of Gaussian noise is added to data sets. Let N 2 R IÂJÂK and N 2 R IÂM be a third-order tensor and a matrix, respectively, with entries randomly drawn from the standard normal distribution. Then, the coupled data sets used in simulations are generated as follows:</p><formula xml:id="formula_14">X noisy ¼ X þ kXk N kNk Y noisy ¼ Y þ kYk N kNk</formula><p>where indicates the noise level. Using different types of underlying components and/or noise levels, we generate coupled data sets based on the following test cases (for all test cases, we use I ¼ 50, J ¼ 30, K ¼ 40, and M ¼ 100). Case 1: All factor matrices A, B, C, and V have entries randomly chosen from the standard normal distribution. The columns of factor matrices are normalized to unit norm. There is one shared and one unshared component in each data set, i.e., L ¼ ½1 0 1 T and S ¼ ½1 1 0 T , where R ¼ 3. The noise level is set to ¼ 0:1. The correlations of the columns of the factor matrices are in the interval (À0.25, 0.25) for this case. Case 2: The common factor matrix A has a certain structure as illustrated in the top plot of Fig. <ref type="figure" target="#fig_3">2</ref> (same factors were also used in <ref type="bibr" target="#b20">[21]</ref>). The other factor matrices B, C, and V are generated with entries randomly chosen from the standard normal distribution, and columns of all factor matrices are normalized to unit norm. There are two shared components and one unshared component in each data set, i.e., L ¼ ½1 1 1 0 T and S ¼ ½1 1 0 1 T , where R ¼ 4. The correlations of the columns of the factor matrices are in the interval (À0.50, 0.50). The noise level is set to ¼ 0:1. Case 3: The setup for Case 3 is the same as the one for Case 2, except that the noise level is set to ¼ 0:4. Case 4: The common factor matrix A has the structure illustrated in the bottom plot of Fig. <ref type="figure" target="#fig_3">2</ref>. The other factor matrices are generated with entries randomly chosen from the standard normal distribution and columns of all factor matrices are normalized to unit norm. There are two shared components and one unshared component in each data set, i.e., L ¼ ½1 1 1 0 T and S ¼ ½1 1 0 1 T , where R ¼ 4. The correlations of the columns of the factor matrices are in the interval (À0.75, 0.75). The noise level is set to ¼ 0:1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>In this section, we give the details of the implementation of each method used in comparisons. All experiments were performed using MATLAB v7.14, except for BIBFA, for which we used R v3.1.1.</p><p>The data sets generated using the approach in Section IV-A consist of a third-order tensor coupled with a matrix in the first mode. In order to jointly analyze these heterogeneous data sets using matrix factorization-based methods, the third order tensor is unfolded in the first mode. Unfolding (or matricization) in the first mode reshapes a higher-order tensor as a matrix by using the mode-1 fibers as the columns of the matrix (see <ref type="bibr" target="#b38">[39]</ref> and <ref type="bibr" target="#b39">[40]</ref> for details).</p><p>GSVD was performed using MATLAB's gsvd function to produce the ''economy-sized'' decomposition while adapted GSVD was performed using the code provided by <ref type="bibr" target="#b21">[22]</ref>. For adapted GSVD, the correct total number of components, i.e., the sum of shared and unshared components, is given as an input. JIVE was performed using the implementation available at https://genome.unc.edu/jive/. The rank selection approach based on permutation testing proposed in <ref type="bibr" target="#b22">[23]</ref> was used to determine the number of shared/unshared components. However, whenever it failed, the performance of the method was assessed by providing the true number of shared/unshared components. As stopping conditions, the convergence threshold is set to 10 À9 while the maximum number of iterations is set to 3000. (In all experiments, JIVE stopped since the convergence threshold was reached.) Before jointly analyzing matrices X ðmÞ in (4), each matrix may need to be properly preprocessed, i.e., mean centering across the samples mode and dividing by its Frobenius norm <ref type="bibr" target="#b22">[23]</ref>. We assess the performance of the method both with and without preprocessing and report the best results.</p><p>For BIBFA, the R implementation from http://cran.rproject.org/package=CCAGFA was used. BIBFA is expected to automatically select the number of shared and unshared components (through the use of its priors). Only the correct total number of components is given as an input. We use the default parameters for the implementation, except that as the stopping condition, iter_crit, i.e., the relative change in the lower bound for the marginal likelihood, is set to 10 À10 , and the optimization parameter for limited memory BFGS (L-BFGS), i.e., lbfgs_factr, is set to 10 5 . A number of random initializations (at least 50) are used, and the results based on the one returning the maximum lower bound for the marginal log likelihood are reported.</p><p>In order to compare matrix factorization-based approaches with models developed to jointly analyze heterogeneous data, the CMTF model in (2) and the structurerevealing CMTF model in <ref type="bibr" target="#b5">(6)</ref> were used. CMTF-OPT and ACMTF-OPT implementation in the MATLAB CMTF Toolbox (available from http://www.models.life.ku.dk/ joda/CMTF_Toolbox) was used for the CMTF model and the structure-revealing CMTF model, respectively. In this section, ACMTF refers to the structure-revealing CMTF model in <ref type="bibr" target="#b5">(6)</ref>. Before fitting the models, each data set is divided by its Frobenius norm. Both CMTF-OPT and ACMTF-OPT use gradient-based optimization and minimize the objective for all factor matrices (and also weights in the case of ACMTF) simultaneously. In our experiments, we used NCG as the optimization algorithm. As stopping conditions, both methods use the relative change in function value (set to 10 À10 ) and the 2-norm of the gradient divided by the number of entries in the gradient (set to 10 À10 ). Penalty parameters ¼ 10 À3 and ¼ 1 are used in all experiments. The sensitivity of the structure-revealing CMTF model to different values has been previously demonstrated in <ref type="bibr" target="#b23">[24]</ref>. A number of random initializations are used, and the results returning the minimum function value are reported. In order to obtain the plots suggesting the uniqueness/nonuniqueness of the models in Figs. <ref type="figure" target="#fig_7">4</ref> and<ref type="figure" target="#fig_10">7</ref>, we use 200 random starts. The correct total number of components is given as an input. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysis</head><p>In this section, we demonstrate how well each structure-revealing data fusion model performs in terms of capturing the true underlying factors used to generate the data and identifying shared/unshared factors.</p><p>In Case 1, we observe that both matrix factorizationbased data fusion models and the structure-revealing CMTF model can capture the true factors. Fig. <ref type="figure" target="#fig_4">3</ref> compares the true columns of factor matrix A, i.e., a r , with the columns of A extracted by each model, i.e., âr , and Table <ref type="table" target="#tab_0">1</ref> reports the similarity scores, where the similarity is computed as: jâ T r a r j=kâ r kka r k after finding the best matching permutation of the columns. Adapted GSVD, JIVE, BIBFA, and ACMTF perform almost equally well in terms of identifying shared/unshared components. Furthermore, for this case, given the total number of components, all these methods can detect the number of shared and unshared components accurately. For ACMTF, we use the weights, i.e., L and diagonal entries of the diagonal matrix 2 estimated by <ref type="bibr" target="#b5">(6)</ref>, to identify shared and unshared components. Fig. <ref type="figure" target="#fig_7">4</ref> demonstrates the weights, i.e., and , estimated using ACMTF and CMTF for multiple runs returning the same function value, i.e., multiple random starts are used and the minimum function value is obtained several times. When we use CMTF, weights are estimated by normalizing the columns of the extracted factor matrices. Weights captured by CMTF suggest that CMTF fails to find a unique solution and identify shared/unshared components. On the other hand, ACMTF reveals the true structure indicating that there is one shared and one unshared component in each data set. In addition to CMTF, GSVD also has issues in terms of identifying shared/unshared factors. Fig. <ref type="figure" target="#fig_8">5</ref> Here, a 1 is the shared factor while a 2 and a 3 are the unshared factors in the matrix and the third-order tensor, respectively.   Case 2 increases the number of factors, i.e., instead of a single shared component, there are two shared components, and correlations between some factors are also higher. Fig. <ref type="figure" target="#fig_9">6</ref> demonstrates that GSVD suffers from the same issue we have observed in Case 1), i.e., while it can capture the unshared factors accurately, shared components are not easy to identify since it extracts several components similar to shared components. Two similar components, i.e., 0.01 within the maximum similarity achieved, are plotted for a 1 while three similar components are plotted for a 2 in Fig. <ref type="figure" target="#fig_9">6(a)</ref>. In this case, adapted GSVD and JIVE both extract distorted factors. The JIVE model assumes that shared and unshared parts are orthogonal, which is likely the reason for the distorted unshared components. Note that also in the presence of more than one unshared/shared component, JIVE is likely to fail because it needs to impose additional constraints such as orthogonality for the identification of components. In this case, on the other hand, JIVE can capture the shared factors accurately because they are already orthogonal. Given the total number of components, BIBFA and ACMTF can automatically identify that there are two shared components and one unshared component in each data set. They both extract factors which match with the true underlying factors better compared to the factors extracted by adapted GSVD and JIVE. As in Case 1, CMTF fails to return a unique solution (Fig. <ref type="figure" target="#fig_10">7</ref> shows the weights estimated by ACMTF and CMTF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) plots</head><p>Case 3 increases the level of noise and demonstrates that when the noise level increases, it becomes crucial to make use of the underlying low-rank structure in the  third-order tensor in data fusion models. Matrix factorization-based data fusion models, even the competitive ones in Cases 1 and 2 such as BIBFA, cannot identify the underlying factors accurately in Case 3. In Fig. <ref type="figure" target="#fig_11">8</ref> and Table <ref type="table" target="#tab_0">1</ref>, we observe that none of the matrix factorization-based approaches can capture the shared factors. On the other hand, ACMTF performs better except for the distortions in the unshared factor in the matrix.</p><p>Finally, in Case 4, underlying factors, more specifically, the columns of factor matrix A, have higher correlations compared to other cases (see Fig. <ref type="figure" target="#fig_3">2</ref>); therefore, the  assumptions of orthogonal or close to orthogonal factors in matrix factorization-based data fusion models are violated. In this case, we observe that ACMTF is the only model that can extract the true factors in Fig. <ref type="figure" target="#fig_12">9</ref> and Table <ref type="table" target="#tab_0">1</ref>. GSVD and adapted GSVD can find unshared factors but they fail to capture the shared factors. GSVD extracts six factors similar to a 1 and five factors similar to a 2 . These factors are all plotted in Fig. <ref type="figure" target="#fig_12">9(a)</ref>. For adapted GSVD [Fig. <ref type="figure" target="#fig_12">9(b)]</ref>, true shared components are both similar to the same component extracted by the model. That is why shared components are plotted together with one of the extracted factors. It is also the case for JIVE and BIBFA. Unlike GSVD and adapted GSVD, JIVE also fails to find the true unshared components. The most competitive method so far, i.e., BIBFA, cannot extract the shared factors accurately, either.</p><p>Experiments demonstrate that when the goal is to jointly analyze heterogeneous data sets and identify shared/unshared factors, structure-revealing data fusion models that exploit the underlying structures in higher order tensors perform better than the approaches based on unfolding higher order tensors and using matrix factorizationbased methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Prototypical Coupled Data Sets</head><p>In this section, we jointly analyze diffusion NMR and LC-MS measurements of mixtures with known chemical composition and compare the structure-revealing data fusion models discussed in Section III in terms of finding the true design used in preparation of mixtures. We also discuss the performance of the methods in terms of capturing the patterns of chemicals used to prepare the mixtures. The NMR spectrum captured by each component can be used for identification purposes in comparison with the true spectra of chemicals. We do not show the spectra here since it is beyond the scope of this paper. We refer interested readers to <ref type="bibr" target="#b23">[24]</ref> for NMR spectra and LC-MS features extracted by the structure-revealing CMTF model, and true NMR spectra of pure chemicals. NMR and LC-MS are both commonly used techniques in metabolomics. In this case, we use a special variant of NMR called DOSY NMR, which produces three-way data.</p><p>1) Data Description: Twenty nine samples were prepared using varying concentrations of five chemicals according to a predetermined design. The following chemicals were used in preparing the mixtures: valine-tyrosine-valine (Val-Tyr-Val), tryptophan-glycine (Trp-Gly), phenylalanine (Phe), maltoheptaose (Malto), and propanol. The mixtures were then measured using diffusion NMR and LC-MS. NMR measurements for a single mixture are in the form of a set of spectra recorded at different gradient levels. When there are several mixtures, NMR data can be arranged as a third-order tensor with modes: mixtures, chemical shift, and gradient levels. The chemical shift is related to the chemical environment of the protons, and the gradient levels encode the diffusion property of the various molecular species. LC-MS measurements, after automatic peak detection and integration, are arranged as a mixtures by features (peaks) matrix. Measurements of mixtures from these two platforms form heterogeneous data sets coupled in mixtures mode (Fig. <ref type="figure" target="#fig_13">10</ref>). For details of sample preparation and measurements, see <ref type="bibr" target="#b23">[24]</ref>. The data are publicly available at http://www.models.life.ku.dk/ joda/prototype.</p><p>2) Analysis: Joint analysis of diffusion NMR and LC-MS measurements makes it possible to extract underlying structures useful for identification of chemicals used in mixture preparation. All five chemicals show up in diffusion NMR measurements while one of the chemicals, i.e., propanol, is invisible to LC-MS. We have previously shown that analysis of only NMR data using a CP model reveals the design used in mixture preparation and captures the true underlying components corresponding to  the chemicals <ref type="bibr" target="#b23">[24]</ref>. On the other hand, analysis of only LC-MS data is challenging since LC-MS measurements contain many irrelevant features due to the sensitivity of the analytical technique and matrix factorizations (even with constraints such as orthogonality or sparsity) do not reveal the design accurately. When these coupled data sets are jointly analyzed using a structure-revealing CMTF model, we have been able to: 1) identify the shared and unshared factors in each data set; 2) recover the true design; and 3) reveal the relevant patterns corresponding to the chemicals in LC-MS <ref type="bibr" target="#b23">[24]</ref>. Fig. <ref type="figure" target="#fig_14">11</ref> demonstrates the design captured by ACMTF versus the true design used in mixture preparation (taken from <ref type="bibr" target="#b23">[24]</ref>). We have fitted a six-component ACMTF model since there are five chemicals in the mixtures, and we expect to have some experimental noise. Even though NMR data can be modeled well using a five-component CP model, singular values of LC-MS data suggest that there are at least six components. Fitting a five-component ACMTF model, therefore, cannot find the underlying factors accurately due to the additional structured noise in LC-MS. For an in-depth discussion of the selection of the number of components, see <ref type="bibr" target="#b23">[24]</ref>. The weights have indicated that four components are shared by both data sets while one component corresponding to propanol shows up only in NMR (as expected) and one component corresponding to noise is mainly visible in LC-MS. The noise component most probably models structured noise. For real data sets, weights captured by the ACMTF model are more difficult to interpret since we may get small weights for unshared components. We discuss this drawback further in Section V.</p><p>In this section, we jointly analyze these data sets using matrix factorization-based structure-revealing data fusion models. In order to use matrix factorization-based approaches, the third-order tensor corresponding to NMR measurements is unfolded in the mixtures mode; in other words, a mixtures by chemical shift-gradient levels matrix is formed. This matrix is jointly analyzed with the matrix corresponding to LC-MS measurements using GSVD, adapted GSVD, JIVE, and BIBFA. Before the analysis, each data set is divided by its Frobenius norm and LC-MS features are scaled by their standard deviation. This is the same preprocessing approach applied before fitting the ACMTF model in <ref type="bibr" target="#b23">[24]</ref>. Note that while it was not necessary to scale the data sets by their Frobenius norms in simulations (simulated coupled data sets have similar Frobenius norms), here, real data sets have orders of magnitude difference in their Frobenius norms and need to be scaled to get meaningful results.</p><p>GSVD extracts 29 components, and based on c i ; s i , we observe that: 1) there are many unshared components in LC-MS and all correspond to noise; 2) many components look like shared components but none of them matches with the true underlying components; and 3) two components seem to be visible only in NMR and one of these components corresponds to proponal. Except for capturing the unshared component corresponding to propanol, GSVD performs poorly in terms of both identifying shared/ unshared components and capturing the signatures of chemicals. Fig. <ref type="figure" target="#fig_15">12</ref>(a) demonstrates the design captured by GSVD versus the true design. Out of 29 components, we chose the components that look most similar to the true design.</p><p>Using adapted GSVD, more meaningful components are extracted. The same number of components, i.e., six, as in ACMTF is used. Using c i ; s i , we observe that: 1) two components show up as unshared components in NMR and their NMR signatures look like those of maltoheptaose and propanol; 2) there are three shared components corresponding to Val-Tyr-Val, Phe, and Trp-Gly; and 3) one component which corresponds to noise shows up only in LC-MS. While results make more sense compared to the components captured by GSVD, adapted GSVD fails to identify maltoheptaose as a shared component and the NMR signatures captured by the model for all chemicals are distorted compared to the true signatures. Furthermore, as we see in Fig. <ref type="figure" target="#fig_15">12(b)</ref>, adapted GSVD cannot capture the design accurately.</p><p>While modeling the data sets using JIVE, the number of shared components, i.e., four, and unshared components, i.e., one in each data set, are given as inputs since the model fails to give any meaningful results using the component numbers selected by the permutation testing approach. Given the number of shared/unshared components, the NMR signatures of extracted components are distorted but still resemble the true signatures of the chemicals. Fig. <ref type="figure" target="#fig_15">12(c</ref>) shows that the extracted scores are highly correlated with the true design. Note that, here, the best performance is achieved when both data sets are centered across the samples mode. Due to centering, we expect a shift in the y-axis rather than a perfect alignment between the true design and the extracted components. However, even if we take into account the effect of centering, the extracted factors do not match well with the true design.</p><p>BIBFA is expected to be the most robust model to component number selection since the groupwise ARD prior can make unnecessary components inactive. In other words, the model has the potential to determine not only the number of shared/unshared components but also the total number of components. When NMR measurements coupled with LC-MS data are modeled with BIBFA using a six-component model, six shared components are extracted; therefore, we have increased the number of components up to ten components with a goal of detecting inactive components. Even the ten-component model suggested that all components were shared. Among the models with a different number of components, the tencomponent model returns the best results in terms of similarity with the true design [Fig. <ref type="figure" target="#fig_15">12(d)]</ref>. While results look promising, the true design cannot be captured as well as in Fig. <ref type="figure" target="#fig_14">11</ref>. Furthermore, even though proponal is an unshared component, it is detected as a shared component using BIBFA and the NMR signatures captured by the components only remotely resemble the true signatures of the chemicals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>As a result of emerging technologies, there is a vast amount of data being collected from multiple sources in many disciplines. Therefore, in many applications, we are faced with the challenge of jointly analyzing data sets with a goal of enhancing knowledge discovery. While data mining tools for data fusion have been a topic of study for decades and proved useful in numerous applications in social networks, bioinformatics, and signal processing, there is still a lack of mathematical models that can jointly analyze heterogeneous data sets and identify underlying shared/ unshared factors. Such models are particularly needed in disciplines like metabolomics, where heterogeneous data sets are collected from different measurement platforms with a goal of identifying patterns related to certain physiological or pathological conditions.</p><p>In this paper, we have reviewed and compared the state-of-the-art data fusion models developed to reveal shared/unshared factors in terms of jointly analyzing heterogeneous data sets. Traditional structure-revealing data fusion models are matrix factorization-based methods. On the other hand, we have formulated data fusion as a coupled matrix and tensor factorization problem and discussed its extension to a structure-revealing data fusion model. Numerical results on simulated data sets demonstrate that structure-revealing data fusion models exploiting the low-rank structure in higher order tensors outperform traditional matrix factorization-based methods because matrix factorization-based approaches need additional constraints on the factors and become more susceptible to noise due to the unfolding of higher order data sets. Furthermore, using diffusion NMR and LC-MS measurements of mixtures, we show that constraints/ assumptions in matrix factorization-based data fusion models are not valid for typical real data sets encountered in metabolomics, and structure-revealing CMTF models capture the underlying components more accurately than the matrix factorization-based methods.</p><p>Even though heterogeneous data sets are encountered in increasingly more applications, there are only few studies on structure-revealing CMTF models. Such models need to be better understood and improved to achieve accurate factor recovery in real applications. For instance, the structure-revealing CMTF model discussed in this paper inherits uniqueness properties from the CP model, and as we observe in Figs. <ref type="figure" target="#fig_7">4</ref> and<ref type="figure" target="#fig_10">7</ref>, in the presence of shared/ unshared factors, sparsity penalties on the weights enable the structure-revealing CMTF model to return unique solutions while CMTF fails to do so. However, when there are more than one unshared factor in the matrix, those unshared factors will still have rotational freedom as shown in <ref type="bibr" target="#b23">[24]</ref>. Therefore, uniqueness properties of the structurerevealing CMTF models need to be studied further. Also, we have consistently observed in the simulations that while unshared factors in the higher-order tensors and shared factors are accurately extracted by a structure-revealing CMTF model, there are slight distortions in the unshared matrix component. It is important to understand and be aware of such potential limitations of the models when using these models in real applications. Furthermore, even though we have learned and used the weights of the rankone components to identify shared/unshared factors, in real applications, due to noise or maybe experimental artifacts, we observe small weights, and it is difficult to decide how small the weight of a component should be to consider that component as unshared. This is also closely related to another problem: parameter selection. The ultimate goal is to select the value and the total number of components automatically. In a recent study, we have introduced additional constraints that make the structure-revealing CMTF model robust to overfactoring and alleviate the model selection problem <ref type="bibr" target="#b74">[75]</ref>. Another interesting research direction would be to extend BIBFA that can handle model selection implicitly to joint analysis of heterogeneous data sets by building onto models like BIBFA and the recent multiview tensor factorization approach introduced in <ref type="bibr" target="#b75">[76]</ref>. Besides, extensions of structure-revealing CMTF models that can model higher-order tensors with more flexible tensor models than the CP model would be of interest. While DOSY NMR and fluorescence spectroscopic measurements follow a CP model, more flexible tensor factorization models may be needed to model data sets in real applications.</p><p>The structure-revealing CMTF model discussed in this paper has been motivated by metabolomics applications, and we have demonstrated the potential of the model on real coupled data sets collected by measurement platforms used in metabolomics studies. However, in the prototypical coupled data sets, there is a limited number of chemicals while in real metabolomics applications, we encounter hundreds of chemicals and extracting hundreds of meaningful CP components from metabolomics data is often not feasible. Therefore, how well the model extends to real metabolomics applications, where hundreds of chemicals are measured using different measurement platforms, is a topic of ongoing research. We have recently used the structure-revealing CMTF model to jointly analyze fluorescence and NMR measurements of plasma samples of a group of verified colorectal cancer patients and a group of controls with nonmalignant findings <ref type="bibr" target="#b65">[66]</ref>. The preliminary findings have shown that there are shared/unshared factors, and some of the shared factors achieve 71.4% accuracy (with 63.6% sensitivity and 78.1% specificity) in terms of separating the two groups. However, even in that application, a structure-revealing CMTF model with few components, i.e., eight, has been used since the number of chemicals that can be detected by fluorescence spectroscopy is limited. In order to deal with the issue of a high number of metabolites, one possible approach is to use a windowing scheme, i.e., instead of modeling the whole data set, data can be partitioned into windows. For instance, measurements from GC-MS or LC-MS, which detect hundreds of chemicals, can be arranged as third-order tensors with modes: samples, mass spectra, and elution time as in <ref type="bibr" target="#b76">[77]</ref>, and then partitioned into windows in the time mode. Each window is still a third-order tensor and can be jointly analyzed with data from other windows and platforms.</p><p>The potential of joint analysis of heterogeneous data sets is yet to be explored in metabolomics. Measurements from commonly used platforms in metabolomics such as GC-MS, LC-MS, and NMR can be represented as higher order data sets. So far, such higher-order tensors have often been arranged as matrices due to the lack of data fusion models that can jointly analyze heterogeneous data sets. With increased modeling power, structure-revealing CMTF models could facilitate better identification of measured metabolites. h</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Third-order tensor corresponding to fluorescence spectroscopic measurements (with modes: samples, emission, and excitation wavelengths) coupled with a matrix of NMR measurements in the samples mode.</figDesc><graphic coords="2,116.63,627.57,110.54,62.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>N</head><label></label><figDesc>for m ¼ 1; 2, BIBFA relies on the following probabilistic interpretation of IBFA: z $ Nð0; IÞ z ðmÞ $ Nð0; IÞ x ðmÞ $ N A ðmÞ z þ B ðmÞ z ðmÞ ; 2 ðmÞ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Factor matrix A used for generation of data sets in Cases 2 and 4.</figDesc><graphic coords="8,65.27,76.41,204.14,156.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Case 1. Original factors used to generate the data (in blue) are compared with the factors extracted by each method (in red).</figDesc><graphic coords="9,47.75,76.29,475.34,249.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) GSVD. (b) Adapted GSVD. (c) JIVE. (d) BIBFA. (e) ACMTF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>the squared c i and s i [from<ref type="bibr" target="#b2">(3)</ref>]. There is one component with c 2 i ¼ 1, s 2 i ¼ 0, and one component with c 2 i ¼ 0, s 2 i ¼ 1 corresponding to unshared components. However, identification of the shared component based on c i ; s i is not possible, i.e., there are many components similar to the shared component. Fig. 3(a) plots 20 components similar to the shared component, i.e., with a similarity score s such that s max À s 0:01, where s max indicates the similarity of the best matching factor. Fig. 5(b), on the other hand, shows that adapted GSVD can accurately indicate one shared and one unshared component in each data set. This is a relatively easy test case because randomly generated components have low correlations, and there are only one shared and one unshared factors. Still, the results demonstrate that GSVD and CMTF are not competitive as structure-revealing data fusion models even for this simple case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Case 1. Weights estimated by ACMTF and CMTF for multiple runs returning the same function value. (a) ACMTF. (b) CMTF.</figDesc><graphic coords="10,129.35,76.65,318.38,138.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Case 1. Diagonal entries (squared) of diagonal matrices C and S [from (3)]. (a) GSVD. (b) Adapted GSVD.</figDesc><graphic coords="10,127.43,593.37,322.22,127.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Case 2. Original factors (in blue) are compared with the factors extracted by each method (in red). Here, a 1 and a 2 are the shared components while a 3 and a 4 are the unshared components in the third-order tensor and the matrix, respectively. (a) GSVD. (b) Adapted GSVD. (c) JIVE. (d) BIBFA. (e) ACMTF.</figDesc><graphic coords="11,47.75,76.29,475.34,315.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Case 2. Weights estimated by ACMTF and CMTF for multiple runs returning the same function value. (a) ACMTF. (b) CMTF.</figDesc><graphic coords="11,125.87,585.33,317.90,135.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Case 3. Original factors (in blue) are compared with the factors extracted by each method (in red). Here, a 1 and a 2 are the shared factors while a 3 and a 4 are the unshared factors in the third-order tensor and the matrix, respectively. (a) GSVD. (b) Adapted GSVD. (c) JIVE. (d) BIBFA. (e) ACMTF.</figDesc><graphic coords="12,51.71,76.29,475.34,315.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Case 4. Original factors (in blue/green) are compared with the factors extracted by each method (in red). Here, a 1 and a 2 correspond to the shared factors while a 3 and a 4 are the unshared factors in the third-order tensor and the matrix, respectively. Original shared factors are both similar to the same component extracted by the model (for adapted GSVD, JIVE, and BIBFA). Therefore, top plots in (b), (c), and (d) show original shared components plotted together with one of the factors extracted by the model. (a) GSVD. (b) Adapted GSVD. (c) JIVE. (d) BIBFA. (e) ACMTF.</figDesc><graphic coords="13,47.75,76.41,475.34,319.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Third-order tensor corresponding to diffusion NMR measurements (with modes: mixtures, chemical shift, and gradient levels) coupled with a matrix of LC-MS measurements in the mixtures mode.</figDesc><graphic coords="13,350.75,619.77,121.58,68.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. True design used in mixture preparation (blue) versus the columns of factor matrix A corresponding to the mixtures mode extracted by the ACMTF model (red).</figDesc><graphic coords="14,51.71,76.77,231.74,250.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. True design used in mixture preparation (blue) versus the columns of factor matrix A corresponding to the mixtures mode extracted by each matrix factorization-based structure-revealing data fusion model (red). (a) GSVD. (b) Adapted GSVD. (c) JIVE. (d) BIBFA.</figDesc><graphic coords="15,47.85,75.75,475.20,524.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Similarity of the Factors Extracted by Each Model to the Original Factors. Ã Indicates That There Are Several Factors With a Similarity Score Within 0.01 of the Reported Score</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Vol. 103, No. 9, September 2015 | Proceedings of the IEEE 1605</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Acar et al.: Data Fusion in Metabolomics Using Coupled Matrix and Tensor Factorizations</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Vol. 103, No. 9, September 2015 | Proceedings of the IEEE 1615</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Vol. 103, No. 9, September 2015 | Proceedings of the IEEE 1617</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the Danish Council for Independent Research (DFF), Technology and Production Sciences (FTP) Program under Projects 11-116328 and 11-120947.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABOUT THE AUTHORS</head><note type="other">Evrim</note></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">&apos;Intra-and inter-omic fusion of metabolic profiling data in a systems biology framework</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="121" to="131" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The human urine metabolome</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouatra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">73076</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The human cerebrospinal fluid metabolome</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Wishart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chromatography B</title>
		<imprint>
			<biblScope unit="volume">871</biblScope>
			<biblScope unit="page" from="164" to="173" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SoRec: Social recommendation using probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th ACM Conf</title>
		<meeting>17th ACM Conf</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="931" to="940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MetaFac: Community discovery via relational hypergraph factorization</title>
		<author>
			<persName><forename type="first">Y.-R</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</title>
		<meeting>15th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Like like alike: Joint friendship and interest propagation in social networks</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Int. Conf. World Wide Web</title>
		<meeting>20th Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards mobile intelligence: Learning from GPS history data for collaborative recommendation</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="issue">185</biblScope>
			<biblScope unit="page" from="17" to="37" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Link prediction in heterogeneous data via generalized coupled tensor factorization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining Knowl. Disc</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="203" to="236" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nonnegative matrix partial co-factorization for drum source separation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. IEEE Int. Conf. Acoust. Speech Signal Process</title>
		<imprint>
			<biblScope unit="page" from="1942" to="1945" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Generalised coupled tensor factorisation Advances in Neural Information Processing Systems 24</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Simsekli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="2151" to="2159" />
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized singular value decomposition for comparative analysis of genome-scale expression data sets of two different organisms</title>
		<author>
			<persName><forename type="first">O</forename><surname>Alter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Botstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="3351" to="3356" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extracting gene expression profiles common to colon and pancreatic adenocarcinoma using simultaneous nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Badea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Pacific Symp. Biocomput</title>
		<meeting>Pacific Symp. Biocomput</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="279" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coupled analysis of in vitro and histology tissue samples to quantify structure-function relationship</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Plopper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Art. ID. e32227</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relational learning via collective matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</title>
		<meeting>14th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="650" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A framework for sequential multiblock component methods</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Smilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Westerhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemometrics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="323" to="337" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Non-orthogonal joint diagonalization in the least-squares sense with application in blind source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yeredor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1545" to="1553" />
			<date type="published" when="2002-07">Jul. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A fast algorithm for joint diagonalization with non-orthogonal transformations and its application to blind source separation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ziehe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Laskov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="777" to="800" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spectral clustering for multi-type relational data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Int. Conf. Mach. Learn</title>
		<meeting>23rd Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-way clustering on relation graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Merugu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIAM Int. Conf. Data Mining</title>
		<meeting>SIAM Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="145" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fluorescence spectroscopy as a potential metabonomic tool for early detection of colorectal cancer</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lawaetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metabolomics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="111" to="121" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian canonical correlation analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="965" to="1003" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DISCO-SCA and properly applied GSVD as swinging methods to find common and distinctive processes</title>
		<author>
			<persName><forename type="first">K</forename><surname>Van Deun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">37840</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint and individual variation explained (JIVE) for integrated analysis of multiple data types</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Lock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Hoadley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Nobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="523" to="542" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Structure-revealing data fusion</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2105-15-239</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinf</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Diffusion ordered nuclear magnetic resonance spectroscopy: Principles and applications</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progr. Nuclear Magn. Resonance Spectroscopy</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="203" to="256" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A survey on multi-view learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">All-at-once optimization for coupled matrix and tensor factorizations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dunlavy</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1105.3422" />
	</analytic>
	<monogr>
		<title level="m">Proc. KDD Workshop Mining Learn. Graphs</title>
		<meeting>KDD Workshop Mining Learn. Graphs</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Social contextual recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st ACM Conf</title>
		<meeting>21st ACM Conf</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A higher order generalized singular value decomposition for comparison of global mRNA expression from multiple organisms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponnapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Alter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Art. ID. e28072</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Simultaneous factor analysis of several gramian matrices</title>
		<author>
			<persName><forename type="first">J</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="413" to="419" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A flexible framework for sparse simultaneous component based data integration</title>
		<author>
			<persName><forename type="first">K</forename><surname>Van Deun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wilderjans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Antoniadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Mechelen</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2105-12-448</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinf</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Coupled matrix factorization with sparse factors to identify potential biomarkers in metabolomics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Knowl. Disc. Bioinf</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="22" to="43" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Convex collective matrix factorization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Int. Conf</title>
		<meeting>16th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Canonical analysis of several sets of variables</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kettenring</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<pubPlace>Chapel Hill, NC, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Stat., Univ. North Carolina at Chapel Hill</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis for data fusion and group inferences</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adall L</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-O</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Calhoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neuronal chronometry of target detection: Fusion of hemodynamic and event-related potential data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Calhoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adall L</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pearlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kiehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="544" to="553" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Incorporating higher dimensionality in joint decomposition of EEG and fMRI</title>
		<author>
			<persName><forename type="first">W</forename><surname>Swinnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hunyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Huffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. 22nd Eur. Signal Process</title>
		<imprint>
			<biblScope unit="page" from="121" to="125" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised multiway data analysis: A literature survey</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6" to="20" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tensors: A brief introduction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Analysis of individual differences in multidimensional scaling via an N-way generalization of &apos;&apos;Eckart-Young&apos;&apos; decomposition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="283" to="319" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Foundations of the PARAFAC procedure: Models and conditions for an &apos;&apos;explanatory&apos;&apos; multi-modal factor analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCLA Working Papers Phonetics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="84" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Data preprocessing and the extended PARAFAC model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Lundy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Research Methods for Multi-mode Data Analysis</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Law</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Snyder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hattie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Mcdonald</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="216" to="284" />
			<date type="published" when="1984">1984</date>
			<publisher>Praeger</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">PARAFAC: Parallel factor analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Lundy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="39" to="72" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multiway multiblock component and covariates regression models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Smilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Westerhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemometrics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="301" to="331" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Collaborative filtering meets mobile recommendation: A user-centered approach</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Conf</title>
		<meeting>24th Conf</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="236" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Understanding data fusion within the framework of coupled matrix and tensor factorizations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Savorani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="53" to="63" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dimensionality reduction in higher order signal processing and rank-ðR 1 ; R 2 ; . . . ; R N Þ reduction in multilinear algebra</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">De</forename><surname>Lathauwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="page" from="31" to="55" />
			<date type="published" when="2004-11">Nov. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Blind identification and source separation in 2Â 3 under-determined mixtures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="22" />
			<date type="published" when="2004-01">Jan. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Tensor-based processing of combined EEG/MEG data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Albera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Eur. Signal Process</title>
		<meeting>20th Eur. Signal ess</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="275" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Structured data fusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sorber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Barel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">De</forename><surname>Lathauwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Top. Signal Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="586" to="600" />
			<date type="published" when="2015-06">Jun. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Turbo-SMT: Accelerating coupled sparse matrix-tensor factorizations by 200Â</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611973440.14</idno>
		<ptr target="http://dx.doi.org/10.1137/1.9781611973440.14" />
	</analytic>
	<monogr>
		<title level="m">Proc. SIAM Int. Conf. Data Mining</title>
		<meeting>SIAM Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">FlexiFaCT: Scalable flexible factorization of coupled tensors on hadoop</title>
		<author>
			<persName><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611973440.13</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. SIAM Int. Conf. Data Mining</title>
		<meeting>SIAM Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Simultaneous analysis of coupled data blocks differing in size: A comparison of two weighting schemes</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wilderjans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ceulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Mechelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1086" to="1098" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Simultaneous analysis of coupled data matrices subject to different amounts of noise</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wilderjans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ceulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Mechelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British J. Math. Stat. Psychol</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="277" to="290" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Optimal weight learning for coupled tensor factorization with mixed divergences</title>
		<author>
			<persName><forename type="first">U</forename><surname>Simsekli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. 21st Eur. Signal Process</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Joint processing of the parallel and crossed polarized Raman spectra and uniqueness in blind nonnegative source separation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dossot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Carteret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Margueron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="7" to="18" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Selectivity, local rank, three-way data analysis and ambiguity in multivariate curve resolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tauler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kowalski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemometrics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="31" to="58" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Three-way arrays: Rank and uniqueness of trilinear decompositions, with application to arithmetic complexity and statistics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="138" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Coupled canonical polyadic decompositions and (coupled) decompositions in multilinear rank-ðl r;n ; l r;n ; 1Þ termsVPart I: Uniqueness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sørensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">De</forename><surname>Lathauwer</surname></persName>
		</author>
		<ptr target="ftp://ftp.esat.kuleuven.be/pub/SISTA/sistakulak/reports/Coupled_CPD_Uniqueness_plusSM.pdf" />
	</analytic>
	<monogr>
		<title level="j">ESAT-STADIUS</title>
		<imprint/>
		<respStmt>
			<orgName>KU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 13-143</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix Computations</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>John Hopkins Univ. Press</publisher>
			<pubPlace>Baltimore, MD, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">GSVD comparison of patient-matched normal and tumor aCGH profiles reveals global copy-number alterations predicting glioblastoma multiforme survival</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Alter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Art. ID. e30098</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Nonnegative shared subspace learning and its application to social media retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</title>
		<meeting>16th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1169" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An inter-battery method of factor analysis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="111" to="136" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Structure-revealing data fusion model with applications in metabolomics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lawaetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Annu. Int. Conf</title>
		<meeting>17th Annu. Int. Conf</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6023" to="6026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Mining labelled tensors by discovering both their common and discriminative subspaces</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramamohanarao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIAM Int. Conf. Data Mining</title>
		<meeting>SIAM Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="614" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A generic linked-mode decomposition model for data fusion</title>
		<author>
			<persName><forename type="first">I</forename><surname>Van Mechelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Smilde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Challenges in multimodal data fusion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lahat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. 22nd Eur. Signal Process</title>
		<imprint>
			<biblScope unit="page" from="101" to="105" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Metabolomics data exploration guided by prior knowledge</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Rubingh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Westerhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Werf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Smilde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytica Chimica Acta</title>
		<imprint>
			<biblScope unit="volume">651</biblScope>
			<biblScope unit="page" from="173" to="181" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Harnessing the complexity of metabolomic data with chemometrics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boccard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rudaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemometrics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A comparison of algorithms for fitting the PARAFAC model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1700" to="1734" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A scalable optimization approach for fitting canonical tensor decompositions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dunlavy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chemometrics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="67" to="86" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Optimization-based algorithms for tensor decompositions: Canonical polyadic decomposition, decomposition in rank-ðl r ; l r ; 1Þ terms, new generalization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sorber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Barel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Lathauwer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="695" to="720" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A flexible modeling framework for coupled matrix and tensor factorizations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. 22nd Eur. Signal Process</title>
		<imprint>
			<biblScope unit="page" from="111" to="115" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Bayesian multi-view tensor factorization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<biblScope unit="volume">8724</biblScope>
			<biblScope unit="page" from="656" to="671" />
			<date type="published" when="2014">2014</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Plant metabolomics: Resolution and quantification of elusive peaks in liquid chromatographymass spectrometry profiles of complex plant extracts using multi-way decomposition methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Khakimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Amigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Engelsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chromatography A</title>
		<imprint>
			<biblScope unit="volume">1266</biblScope>
			<biblScope unit="page" from="84" to="94" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
