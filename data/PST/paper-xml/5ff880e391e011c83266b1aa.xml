<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Selective Event Processing for Energy Efficient Mobile Gaming with SNIP</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Prasanna</forename><forename type="middle">Venkatesh</forename><surname>Rengasamy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University. {pur128</orgName>
								<address>
									<addrLine>huz123,suz53,axs53</addrLine>
									<postCode>mtk2</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University. {pur128</orgName>
								<address>
									<addrLine>huz123,suz53,axs53</addrLine>
									<postCode>mtk2</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University. {pur128</orgName>
								<address>
									<addrLine>huz123,suz53,axs53</addrLine>
									<postCode>mtk2</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Mahmut</roleName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University. {pur128</orgName>
								<address>
									<addrLine>huz123,suz53,axs53</addrLine>
									<postCode>mtk2</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">T</forename><surname>Kandemir</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University. {pur128</orgName>
								<address>
									<addrLine>huz123,suz53,axs53</addrLine>
									<postCode>mtk2</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chita</forename><forename type="middle">R</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Pennsylvania State University. {pur128</orgName>
								<address>
									<addrLine>huz123,suz53,axs53</addrLine>
									<postCode>mtk2</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Selective Event Processing for Energy Efficient Mobile Gaming with SNIP</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/IISWC50251.2020.00035</idno>
					<note type="submission">Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 14:03:04 UTC from IEEE Xplore. Restrictions apply.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Gaming is an important class of workloads for mobile devices. They are not only one of the biggest markets for game developers and app stores, but also amongst the most stressful applications for the SoC. In these workloads, much of the computation is user-driven, i.e. events captured from sensors drive the computation to be performed. Consequently, event processing constitutes the bulk of energy drain for these applications. To address this problem, we conduct a detailed characterization of event processing activities in several popular games and show that (i) some of the events are exactly repetitive in their inputs, not requiring any processing at all; or (ii) a significant number of events are redundant in that even if the inputs for these events are different, the output matches events already processed. Memoization is one of the obvious choices to optimize such behavior, however the problem is a lot more challenging in this context because the computation can span even functional/OS boundaries, and the input space required for tables can takes gigabytes of storage. Instead, our Selecting Necessary InPuts (SNIP) software solution uses machine learning to isolate the input features that we really need to track in order to considerably shrink memoization tables. We show that SNIP can save up to 32% of the energy in these games without requiring any hardware modifications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Gaming is an important application domain with an estimated 2.3 billion users playing games on their mobile devices <ref type="bibr" target="#b0">[1]</ref>. Games are extremely demanding in terms of their hardware impositions, performance requirements, and user interactions. When running a game, the CPU needs to constantly interact with a diverse set of hardware units -main memory, codecs, SD cards, GPUs, displays and the networkto interactively respond in real-time to a continuous stream of user inputs coming from input sensors such AR/VR wands, screen, accelerometer, gyroscope, camera, etc. Even if one were to offload much of the main processing to a backend server on the cloud, these hardware units still consume a significant amount of energy, often leading to a drain on the limited battery capacity in the mobile device. It has been noted that heavy-weight games can drain the entire battery of a mobile device in a couple of hours <ref type="bibr" target="#b1">[2]</ref>. This paper looks to develop a holistic solution to reduce end-to-end energy consumption of the entire mobile device rather than a piecemeal solution for any single component.</p><p>The main idea of our solution is selective event processing, rather than reacting to every event. Gaming applications are inherently event driven, with user input continuously (generated by numerous sensors) driving the computation. The applications need to prepare and react to each such event, which can result in significant energy consumption. Instead, if we are selective about which event will really impact the game behavior, we could avoid unnecessarily (re-)processing thousands of events. Such redundant processing can happen due to two classes of events: (i) Repeated Events: When the exact same events keep recurring, the consequent actions/impact are also usually repetitive. For instance, if a game registers for a screen swipe or a button press event (with the OS), and during execution, the user keeps pressing the same button again and again, the application may not need to react to every subsequent press. Since user inputs are highly complex, one may expect we do find a significant number of repeated events. However, our study shows that there were only around 2-5% of such repeated event executions across a spectrum of 7 games. Upon closer examination, we find that "exact" repetition has a lower probability, as opposed to close enough inputs/events that eventually result in the exact/same game behavior. This leads to the next category of (ii) Redundant Events: These events, though they may not exactly match to prior occurrences, they still do not impact the application execution when they occur. For instance, a game that reacts to rotation/gyroscope events for some windows of execution (say for switching from portrait to landscape), may need to react only for significant movement of the device as opposed to minor movements (which can be largely ignored). Our characterization of 7 different top chart games from the Play Store show that, anywhere from 17% to 43% of the events processed fall in the latter redundant category, not needing any processing at all. Our solution is intended to avoid processing both kinds of events, which can result in multiple hardware component energy savings.</p><p>One of the previously proposed techniques for dealing with redundancy/repetition is memoization. Essentially, we identify frequently executing computations for which the input values repeat, and maintain a table mapping these input values to the corresponding output produced by the computation. Subsequently, when the same input occurs for this computation, the entire processing can be "snipped" by simply substituting it with the output from the table. This popular technique has drawn applicability at the instruction level (to ease functional unit pressure) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, or even at functional levels <ref type="bibr" target="#b4">[5]</ref> to reduce computation. Our SNIP -Selecting Necessary InPuts -solution is similar to this strategy with the following key differences: (i) We do not stop at single Instructions or even functional granularity for memoization. Instead, our solution tries to snip the entire sequence of instructions, which could potentially span multiple functions and even application-OS boundaries, that are driven by the event we are targeting to avoid processing; (ii) Apart from reducing the overhead of fetching and executing these instructions, SNIP also avoids the overheads when certain parts of the computation (in event processing) are offloaded to accelerators/IPs on the mobile SoC; and (iii) As pointed above, if we are to stick to exactly matching inputs, the scope for optimization is relatively small. Instead, we also include the Redundant Events in our memoization, where even if the inputs do not exactly match, we can still snip those computation to produce an output that is no different than performing the entire computation. SNIP, thus, goes well beyond prior techniques to identify and cut-short computations for redundant events.</p><p>However, such an ambitious goal has considerable challenges. Memoization requires look-up tables, which are indexed by the inputs to find the corresponding output. When we move to such large granularity for memoization, the number of inputs becomes enormous -spanning not just registers, but also numerous memory locations. Further, each of these can have a wide spectrum of values that we need to look up the table. In fact, we find that required table sizes for the games under consideration can run into gigabytes, defeating the whole purpose of memoization. Hence, conventional approaches to doing this will simply not work.</p><p>To address the above challenges, SNIP uses the following software based approach:</p><p>• Pre-processing/Profiling: Mobile applications go through extensive debugging and testing, before getting deployed in the App store. We suggest another phase of profiling, which could happen either before the application is deployed (as part of the testing phases by different users), or continuously from the usage by different users as they play their games.</p><p>The purpose of such profiling is to collect event data that is needed to build lookup tables as is discussed next. Thus the app is distributed along with its profile data when downloaded. • Shrinking the Table <ref type="table">:</ref> Thousands of input locations, each containing possibly millions of values, make memoization tables hard to construct. We use a machine learning technique called Permutation Feature Importance (PFI) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> which is essentially a feature extraction utility that is very useful for our needs. It trains on the input-output data for each event, to identify only a subset of "essential inputs" that is needed for a bulk of memoization needs. After this stage, numerous input possibilities will get mapped to a small subset of output values/actions. By capturing only the necessary inputs (and their values), SNIP requires less than 1% of the original table that would have been needed, while still sufficing to succinctly capture a significant number of memoization opportunities. Hence, the term SNIP, for Selecting Necessary InPuts. SNIP can be run on the cloud, not needing the mobile devices limited resources.  • Correctness issues: Since it is a lossy compression of the table, we can get into erroneous behaviors. Although important, gaming is not a mission critical domain (unlike financial, healthcare, etc.). At the same time, we still would like to reduce errors as much as possible. Hence, we allow some over-ride mechanisms (i) Developer over-rides -where the developer can over-ride with necessary input fields that cannot be left out in the compressed form, and (ii) Continuous learning -where the PFI adapts to changes in user behavior by continuously learning and updating the necessary input fields. The entire SNIP framework, comprising the profiler and compiler which snips the computation using the reduced tables, is completely implemented in software for Android OS. We have experimentally evaluated this approach using 7 most popular games from the Play store on a Google Pixel XL phone with Snapdragon 821 SoC. Results show a 32% average energy saving, which is a significant portion of battery drainage on mobile devices. Even if the profiler is not able to do a perfect job in the first attempt (to avoid errors), within a handful of usages and continuous profiling, we are able to make the executions almost completely error free.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Looking up the</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OVERVIEW OF GAMING WORKLOADS</head><p>Gaming workloads perform event-driven computations to react to various user actions, gestures, etc., and render the resulting output to the user. For example, Fig. <ref type="figure" target="#fig_0">1</ref> shows a user playing a typical Augmented Reality (AR) game <ref type="bibr" target="#b1">[2]</ref> on a phone, where the user swipes, tilts and walks with the device. The user's objective is to capture the various objects that are augmented into the scene that is captured continuously in the phone's camera (and simultaneously processed and displayed on its screen). To achieve this, the game uses the input data (walking, tilting, swiping, camera feeds, etc.) to process and respond back to the user. Under the hood, the gaming device captures the three events below continuously: (i) swipe action is captured using a series of touch events on the screen; (ii) tilt is captured using a series of gyro events; and (iii) walk is captured using a series of both the camera feed and the GPS position. To understand the implications of such events in the hardware, we next walk through the example in Fig. <ref type="figure" target="#fig_0">1</ref> and illustrate what happens in the hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. What happens in the hardware?</head><p>Towards better performance and energy efficient executions, the apps running on contemporary System on Chip (SoC) designs leverage a combination of compute units (such as general purpose CPU, GPU cores) and domain-specific accelerators/IPs (such as encoders, decoders, neural networks, image processors), to take advantage of the spectrum of performance and energy efficiency tradeoffs offered by them. To understand how these components get orchestrated and work together during execution, we next delve into what happens in the underlying hardware during application execution. As depicted in Fig. <ref type="figure" target="#fig_0">1</ref>, the event generation begins with the user interacting with the device. As the user interacts (e.g., swipes, walks with the phone, etc.), the corresponding sensors are read by the sensor hub (step 2 in Fig. <ref type="figure" target="#fig_0">1</ref>), and the values of the sensors are subsequently passed on to the CPU as interrupts. The OS framework for these interrupts (e.g., SensorManager in Android <ref type="bibr" target="#b7">[8]</ref>) processes these raw sensor values into high-level events (e.g., swipe, tilt, etc.) -that are further passed onto the game execution at the CPU through shared memory between the sensor hub's runtime and the game workload execution (step 3 in Fig. <ref type="figure" target="#fig_0">1</ref>). This is accomplished using the Binder framework in Android <ref type="bibr" target="#b8">[9]</ref>. The workload execution at the CPU subsequently processes these events using a sequence of event handler functions in CPU as well as accelerator/IPs and after processing, renders the outputs back to the user (e.g., display "pokemon is captured" on the screen).</p><p>In short, the CPU cores initiate and manage all the event handling and initial processing, and it subsequently offloads the heavier tasks such as frame/audio rendering, storing and batching events etc., to domain-specific microphone, display controller, codecs, GPUs and sensor hubs. Since there are multiple components that interact closely during game executions, we first study the normalized energy breakdown in these components (grouped as sensors, memory, CPUs and IPs) in a modern Pixel XL class phone hardware in Fig. <ref type="figure" target="#fig_1">2</ref>. As seen, the sensors and memory consume very small portion of the total energy (&lt; 10%), while the rest is split more or less equally between the CPU and IPs. The major components of energy consumption are from the CPU and IP executions, where the CPU consumes 40% to 60% of the total energy, and the IPs also consuming 34% to 51% of the total energy.  While it may seem similar across all the games in the x-axis, they are actually sorted in the order of complexity of playing the game -as evident in their battery drain characteristics (same x-axis ordering in Fig. <ref type="figure" target="#fig_3">3</ref>). For example, lightweight games such as Colorphun <ref type="bibr" target="#b9">[10]</ref> involves an occasional touch event from the user and even this drains the battery fast ≈ 8.5 hours (vs. ≈ 20 hours for idle phone). It gets much worse as the game play gets more and more complex: AR (Chase Whisply <ref type="bibr" target="#b10">[11]</ref>), 3D graphics games (Race Kings <ref type="bibr" target="#b11">[12]</ref>), etc. the battery drains from a 100% charge to 0% in ≈ 3 hours (6× faster than the idle phone).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Characterizing the game executions</head><p>Combining the above two observations, to solve this rampant battery drain problem, we look into the "whole" SoC execution rather than optimizing for an individual component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Opportunities, drawbacks, and challenges</head><p>Since the SoC is for general purpose executions, a particular game execution may not need all its hardware. In turn, we can use this domain knowledge to optimize execution. For the example in Fig. <ref type="figure" target="#fig_0">1</ref>, the hardware execution starts from the sensors generating raw values, to the output generation at the display/speakers, etc. The opportunities are: At the sensors: Each of the sensors have a range of values it can generate for an external user interaction. For example, a gravity/rotation sensor has value limits from 0 • to 360 • its x (α), y (β ) and z(γ) rotation angles, that captures the accurate way in which the device is currently held by the user. However, the execution may only require whether the device is held in landscape (β &gt; 90 • ) or portrait mode (β &lt; 90 • ), and not care about the rest of the details at all. In such scenarios, as discussed in <ref type="bibr" target="#b12">[13]</ref>, one could employ a low fidelity mode for the sensors to save energy.</p><p>However, the drawback of such an optimization is that our workloads do not consume much energy at the sensors itself (Fig. <ref type="figure" target="#fig_1">2</ref>). Optimizing at this level could result in very small energy benefits overall. When processing an event and generating output: After the sensor values are obtained at the OS, the app event handler is invoked with the corresponding sensor data packed into an event object as arguments. To actually leverage the domain-level behavior, we first need to understand when/which the event values are useful/not useful before processing them. For example, a swipe-up in Fig. <ref type="figure" target="#fig_0">1</ref> may only be relevant when the game has a pokemon displayed for the user to swipe up and has no effect otherwise. To understand whether there is scope for such "wasted processing" in the game execution, we present the % of events that resulted in no change in the game state at all in Fig. <ref type="figure">4</ref> We observe that, in all the workloads, anywhere from 17% to 43% of event processing result in no output change at all, and that in turn wastes about 34% of energy in processing these events. For example, in AB Evolution game, the game play involves stretching a catapult to release an object aimed towards a target. But, when the catapult is stretched to the maximum, no matter what the user swipe action is, it has no effect on the game. Thus, it leads to the highest useless events (43%). If such useless events are identified before processing them, we can (i) save energy from not executing CPU and (ii) not invoke the accelerators. To do so, we could use prior occurrences of events to track whether it resulted in output changes or not and then short-circuit subsequent occurrences. Such lookup table approaches have been studied in the past <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14]</ref> in the context of scientific computations. However, in the context of mobile game executions that are already draining battery, there are three main questions to determine its feasibility: (i) are the inputs and outputs reasonably small to fit a lookup table?, (ii) are all the input/output locations known apriori?, and (iii) is there any dynamism/variations in loading inputs or generating outputs among repeating instances? For such an approach to be feasible, all the locations from where the inputs are loaded and outputs are stored should be known apriori (Fig. <ref type="figure" target="#fig_4">5(a)</ref>). However, the various hardware components involved in the compute black box (CPU cores and IPs) in a mobile SoC often involve dynamic memory accesses during execution, as shown in Fig. <ref type="figure" target="#fig_4">5</ref>(b) -where two instances of the computation (shown as different shades), consume varying number of inputs from varying locations, and also produce outputs to store into different locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. IMPRACTICALITY OF LOOKUP TABLE APPROACH</head><p>To overcome the variability and still use a lookup mechanism, we consider the lookup table to contain the input values from all the possible input locations, i.e., union of all the input locations; and short-circuit the execution for all the possible outputs, i.e., union of all output locations. We study the impact of this approach for a sample game execution, AB Evolution <ref type="bibr" target="#b14">[15]</ref>, by plotting the size of the lookup table necessary for short-circuiting varying portions of the game execution in Fig. <ref type="figure">6</ref>. Here, the x-axis plots the execution coverage in terms of the % of events weighted by the number of dynamic instructions each instance of the event processing executedto account for the dynamism in context-sensitive processing. As seen, even for short circuiting 1% of the execution, the lookup table grows to 5GB in size, while consuming the entire memory capacity (6GB) to short circuit 3%, and the entire SD card capacity (64GB) for short-circuiting 39% of the execution. This is because:</p><p>• Since this approach includes the union of all the input/output locations in each record, the sizes of the records are huge. • In addition, the input values used by each event are not common and can have a wide range of values -resulting in millions of records in the lookup table. This is further exacerbated by the fact that games execute a large number of events, causing the lookup table to explode in volume. • Not utilizing the output redundancy: As illustrated earlier in Fig. <ref type="figure">4</ref>, up to 43% of outputs are exactly the same as prior executions. While even a one byte difference in the input record can potentially create a new entry in this lookup table approach, the outputs are still going to be the same for up to 43% of the events. While prior works use lookup tables to optimize redundant output generations in other workload domains <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14]</ref>, there is a clear contrast in games, where the table grows in both row size and number of rows. Thus, we next look into reducing both these aspects by exploiting the innate characteristics of input-outputs observed in game executions to identify the best heuristics to detect and short-circuit redundant computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. INPUT-OUTPUT BEHAVIOR OF EVENT PROCESSING</head><p>In order to overcome the above drawbacks of lookup table size, we need to answer the following questions: what is in these huge input/output records?, are all these necessary to capture the redundant outputs in Fig. <ref type="figure">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?, if not, what parts of input/output to keep? and what to trim down?</head><p>To answer, we define the categories of inputs the lookup table should contain, and use the definition to explore the feasibility of trimming the inputs/outputs of event processing, while minimizing errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Inputs Characteristics</head><p>For processing events, the execution not only takes the sensor events as input, but also the internal application state data from memory/storage, and external data from network/cloud. These three categories of input data respectively reside in different locations: Event Objects (In.Event), Previous Execution Output (In.History), and External Sources (In.Extern). To understand whether they are amenable for memoization or not, we next study their individual size/location characteristics in detail for an example execution of AB Evolution game in Fig. <ref type="figure" target="#fig_5">7a</ref> by plotting the size spread of each of these categories in the x-axis and their cumulative % occurrences among various events processed during the game execution in y-axis. Event Objects (In.Event): These contain the sensor values from user interactions and are passed as arguments to event handlers. Fig. <ref type="figure" target="#fig_5">7a</ref> (x-axis) shows that the size of In.Events are relatively small and varies from 2 to 640 bytes (different event types have different sizes). While all event processing consume In.Event data, these inputs are also easily located using their object handles, and have fixed size for the same event type. For example, the event handler for detecting a change of swipes, always gets a MotionEvent object of a fixed size passed as argument to the handler -making the handler know its location in memory. Previous Execution Output (In.History): While In.Event data are instantaneous user interactions captured from sensors, the game needs the context involved in the execution progress. To understand the huge spread of sizes for In.History in Fig. <ref type="figure" target="#fig_5">7a</ref> (600 bytes to 119 kB), we next use the example in Fig. <ref type="figure" target="#fig_5">7c</ref>. Here, a user playing some AR game has two options to walk in. If it is an empty room, processing the camera feed will result in a plain surface to render the AR objects on top. Owing to the simplicity, the input data is also relatively small. On the other hand, if the room is cluttered with a lot of physical objects, the camera feed generates many options for rendering the AR objects, making the input size larger. This user input-based data size variation illustrates that this input cannot be found in static memory locations and, as seen in Fig. <ref type="figure" target="#fig_5">7a</ref>, In.History is consumed as input in 47% of the execution.</p><p>External Sources (In.Extern): This is the data received from outside the scope of an application execution. For example, data from the cloud, network, etc., are not within the scope of the application executing inside the phone. We observe from Fig. <ref type="figure" target="#fig_5">7a</ref> that In.Extern input is only used in the &lt; 0.05% of the events, as most of the images/audio, etc. are read from external sources only a limited number of times during execution and are stored in memory for future (becomes In.History). Note that, the audio, images etc. are also huge in size and thus consume 1MB size of inputs in those instances of execution.</p><p>To summarize, In.Event can be used to index into the lookup table because of their ubiquitous occurrence (53%) in event processing and their fixed-size and fixed-location property. On the other hand, In.History and In.Extern do not have a fixed size and also are not statically located in the memory. Therefore, it is impractical for using them in lookup tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Shrinking the table using event data to lookup</head><p>Stemming from the previous characterization, we next study the effects of trimming the naive lookup table by using only the input fields from In.Event categories for indexing the table. Since this scheme only uses In.Event data to index into the lookup table, there is a chance that it can lead to wrong outputs. For example, if a swipe up event is generated in the example in Fig. <ref type="figure" target="#fig_0">1</ref>, it may lead to increase in a user's game score output only when the Pokemon object is displayed (In.History category). When the object is not displayed, the swipe up event will not result in any change. By considering only the swipe event (In.Event data) to index into the lookup table, and not using the knowledge of whether a pokemon is being displayed or not (no In.History data), the memoization may sometime lead to correct outputs and erroneous outputs some other times as well.</p><p>To understand the impact of such a scheme on both execution coverage and erroneous outputs, we present the differences in employing In.Event based memoization with respect to the naive lookup table approach in Fig. <ref type="figure" target="#fig_7">8(a)</ref>.  As seen, this scheme is clearly advantageous as the lookup table size is very small (1.5% or 290 MB) compared to the approach explored in Sec. III (19GB in Fig. <ref type="figure">6</ref>) for short-circuiting 27% of the execution. This lookup table can easily fit in the memory, and can even reside in the software <ref type="bibr" target="#b15">[16]</ref>.</p><p>While this can help in improving the overall energy efficiency, this scheme can match more than one possible outputs for 22% of the total execution. Since there is no way of knowing which of these possible outputs is correct without additional input data, namely the In.History and In.Extern inputs that are not known prior to execution, this scheme cannot be realized for short-circuiting redundant events. Thus, the clear advantage of implementing a much smaller lookup table by only indexing the In.Event data is not possible as it can result in erroneous outputs.</p><p>Note that, similar to different input categories, outputs also belong to the categories below. Fig. <ref type="figure" target="#fig_5">7b</ref> shows that there are three categories of outputs: • Out.Temp: Temporary responses from a game to the user such as a displayed frame block, vibrate/haptic feedback etc., are categorized as Out.Temp. Even if this category of outputs is short-circuited to a wrong output value, the execution itself does not get affected except for the particular user reaction. This could still go unnoticed by the user and can result in expected correct execution progress. Note in Fig. <ref type="figure" target="#fig_5">7b</ref> that, these outputs are usually &lt; 64 bytes in size. For example, there may be a tile in the displayed frame for the user that is wrong due to an erroneous output from this In.Event based lookup table. Since 60 frames or higher <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> are displayed per second in these devices, one frame's tile being wrong will have little to no impact on the user as well (displayed for &lt; 16ms -while the user's reaction time is ≈ 10 × −20× slower <ref type="bibr" target="#b18">[19]</ref>). • The other two categories, Out.History and Out.Extern compliment the In.History and In.Extern respectively, i.e., Out.History outputs are used as inputs in subsequent event processing and Out.Extern are outputs sent to the cloud/network, etc. Therefore, if we short-circuit either of the Out.History or Out.Extern outputs wrong, the execution itself risks becoming erroneous as these outputs are used subsequently as inputs to future executions. Thus, as long as the erroneous results of this approach is not in these two output categories, it could still be a useful tool for identifying and short-circuiting redundant executions, albeit with wrong Out.Temp outputs. Fig. <ref type="figure" target="#fig_7">8(b)</ref> shows the breakdown of erroneous outputs produced as a result of this scheme and as seen, 44% of the erroneous executions are Out.Temp, and so, even if it has errors, it will only lead to minimal quality degradation to the user. On the other hand, the remaining 56% of erroneous executions fall into the other two output categories (Out.History and Out.Extern) being wrong, and so, the scheme cannot be viable to short-circuit redundant event processing.</p><p>We next analyze how such erroneous executions can be avoided by augmenting this mechanism to still take advantage of a relatively small lookup table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SELECTING NECESSARY INPUTS (SNIP)</head><p>Motivated by the fact that ≈ 600 bytes of In.Event fields of the 1MB input data are enough to short-circuit 14% of the execution, we further investigate whether there are other "influential" input fields from In.History and In.Extern categories that can help avoid erroneous outputs or not?. Since there is no specific fixed location or fixed size known for these mostinfluential/necessary input fields to identify, we actually need to search the mega bytes of inputs that determine the correct outputs when short-circuiting executions. Therefore, finding necessary input fields could involve much complex techniques such as scouring through gigabytes of profile data. We next address this problem with our proposed SNIP approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Identifying necessary inputs</head><p>While dataflow analysis techniques such as <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b19">20]</ref> traverse through the dataflow graphs within a function or basic blocks and find the necessary inputs for every output, such schemes do not scale well to analyze executions spanning multiple function calls, OS, and IP invocations, that are a common occurrence in mobile game executions. Fortunately, scouring big data to identify necessary fields are well known in the machine learning domain, where mature techniques such as Permutation Feature Importance (PFI <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>) have already been employed. In the context of identifying necessary input fields, the PFI takes the lookup table described in Sec. III, and trims it down by identifying a subset of input fields that is most influential in accurately short-circuiting the output fields. Towards achieving this, PFI searches through different random permutations of input fields and measure the % output fields that resulted in erroneous values. By repeating this process for different permutations of input fields, it identifies the permutation of input fields (usually a small subset of the input fields), that results in the least erroneous outputs. Our goal is to trim down the number of input fields to the bare minimum, while being able to short-circuit without errors. Towards this, Fig. <ref type="figure" target="#fig_8">9</ref> demonstrates an example execution of the PFI approach to identify necessary input fields for AB Evolution game, where it starts with the complete set of input fields (left most bar in the x-axis = 1MB size) to short-circuit all the output fields with 100% accuracy, akin to the naive lookup table approach. Moving from left to right in x-axis, PFI iteratively trims the input fields further and further with not much loss of accuracy among the outputs short-circuited (y-axis) at first -where just 1% of output fields are erroneous even with the input fields getting trimmed down to 1200 bytes. After 1200 bytes however, the error rate rapidly increases -approximately 1% for every ≈50 bytes of trimming. These 1.2kB constitute the most necessary input fields for this application.</p><p>To understand what category of inputs constitute these necessary input fields, we also color-code the category of inputs that got trimmed down from the previous input permutation to the left, that resulted in the corresponding decrease in the % of outputs that can be short-circuited with 100% accuracy. The right most bar belongs to In.Event category, indicating that just 50 bytes in In.Event category can short-circuit 12% of the output fields with 100% accuracy. Similarly, PFI also automatically identifies around 1kB of input fields from In.History category at various points of x-axis to be necessary for shortcircuiting the execution. It also identifies some of the fields from In.Extern category as necessary. In total, these fields only represent ≈ 1.2kB of data (approximately 0.2% of the total input fields), and can predict 99% all of the outputs in the event processing with 100% accuracy. On the other end of the spectrum, using PFI approach can disregard all of the remaining 99.8% of the input fields with only 1% of the output fields with erroneous values. And, in order to short-circuit the 1% of output fields with 100% accuracy, we also need all the remaining input fields in the lookup table. As mentioned earlier, we can still tolerate erroneous executions if all the 1% of the erroneous output fields belong to the Out.Temp category.</p><p>Towards using PFI for picking all necessary inputs, we need to ensure that SNIP to address the challenges below:</p><p>• Minimizing overheads at the mobile phone: PFI trains on profile data that typically exceeds the total storage capacity of a mobile phone (Fig. <ref type="figure">6</ref>). Thus, we need to employ mechanisms with minimal overheads to transfer the profile data to an offline cloud and only get the necessary input fields back from the cloud. • Dealing with correctness from profile: Since the necessary input combination produced by PFI can also have certain a % of erroneous output fields (for just 1% of the outputs), if those fields belong to Out.History category, it can subsequently cause the whole execution to be erroneous. • Dealing with correctness at runtime: Since PFI operates on profiled data, it is not clear if the profile captures all the scenarios/input variations that can occur during execution.</p><p>In case of an insufficient profile, PFI can miss learning of the necessary input fields, which can result in a higher % of erroneous outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Methodology</head><p>Fig. <ref type="figure" target="#fig_9">10</ref> shows the overall flow of the proposed methodology with the following steps: Record and send events to cloud: The first step in SNIP is to record the different inputs and outputs of event processing observed when the user is playing a game. This can be done either during the rigorous testing phases involved in app development <ref type="bibr" target="#b20">[21]</ref> or continuously when users play the game. We describe the latter approach in Fig. <ref type="figure" target="#fig_9">10</ref>. As recording the input-output of event processing is data intensive (Fig. <ref type="figure">6</ref>), SNIP records only the event inputs and send them to the cloud. To trace these event data, future android versions can instrument the Binder instances from Android HAL to dump all the events into a background service similar to logcat <ref type="bibr" target="#b21">[22]</ref>.</p><p>In our experiments, we use the debug features of Android Studio to record these events of the phone connected to an <ref type="bibr">Android Studio [23]</ref> host. Since camera is not a part of the sensorhub, we leverage the existing screen record features in the debuggers to capture the camera feed. Run app on AOSP Emulator and build the profile: At the cloud, we use an offline profiler based on the AOSP emulator setup <ref type="bibr" target="#b22">[23]</ref> running the game app with input events from the previous step in Fig. <ref type="figure" target="#fig_9">10</ref>. In order to capture the input-output behavior accurately, the recorded events are fed in the same manner as if the user is playing the game once again in the emulator using additional tools such as <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>. During this emulation, we dump the input and outputs consumed by the event processing (across various game execution threads) by instrumenting the emulator to record memory traces <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref> along with additional information about the source of the data accesses (e.g., CPU instruction, IP, sensor hub, etc.). To achieve this, we use various tools in the existing Android framework such as heap profiler <ref type="bibr" target="#b25">[26]</ref> to capture the whole memory dump and function call execution trace from Android Studio. On top of the traces, we use a set of analysis tools such as apat <ref type="bibr" target="#b26">[27]</ref>, hprof and dmtrace <ref type="bibr" target="#b22">[23]</ref> to process the memory dumps and obtain the exact input and output addresses, the data in those addresses (from the memory dump) and the call stack. PFI gets necessary inputs: Once the input-output data is available from the previous step, SNIP runs the PFI technique on the profiled data to get the necessary input fields. To ensure correctness during execution, SNIP allows two options: Option 1: Developer intervention: This option is useful when PFI is applied on the testing phase of app development, where the necessary input fields from PFI, can be fed back to the app developers for corrections as shown in Fig. <ref type="figure" target="#fig_9">10</ref>. As seen, the necessary input fields are mapped to the source code's variables using the additional information tracked during the above profile phase, and the app developers can fine tune the necessary inputs by adding more necessary inputs and/or marking Out.Temp variables that can tolerate errors. Option 2: Continuous learning: Instead of statically fixing the necessary inputs for an app during the development stage, SNIP also facilitates continuous learning by just looping through the initial steps (without developer intervention stage) by recording events, building the profile and developing a PFI based lookup approach repeatedly when the user is playing the game. This option is more generic than the developer intervention, as it allows to fix any short comings due to insufficient profile data. We will demonstrate in Sec. VII that this continuous learning can effectively adapt and control the erroneous executions based on user behaviors. User feedback vs. Options 1 and 2: While SNIP already could use developer feedback to decide on whether an erroneous output field will impact the execution, user experience rating can also be taken as feedback to understand this impact as examined in <ref type="bibr" target="#b27">[28]</ref>. In this paper, we have limited the scope to energy efficiency, without unduly impacting user experience. We will conduct user experience studies in the future. Using the lookup table during execution: After the PFI based lookup table is built, it contains only the necessary inputs and is subsequently sent to the device as an over-the-air update, along with additional code instrumentation as shown in Fig. <ref type="figure" target="#fig_9">10</ref>. As seen, the lookup table is loaded as a hash table during app initialization. During execution, on any event, the table is indexed with the event hash-code and if hit, all the other necessary inputs are loaded and compared against the corresponding important input entries in the lookup table. If the comparisons lead to a match, the execution is directly short-circuited. Else, process the event as baseline.</p><p>Thus, SNIP could achieve minimal overhead, and also tunes towards a user's game play to potentially short-circuit all the redundant event processing. We next evaluate whether SNIP could actually be beneficial to game executions or not (in comparison to baseline and state of the art), and if not, how to minimize the short comings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Game Workloads</head><p>We consider a mix of both open source and off the shelf games from Play store with a mix of input data characteristics as described below, to study the effects of SNIP on a wide spectrum of game workload execution behaviors. All these apps are consistently ranked as top games in Play Store <ref type="bibr" target="#b28">[29]</ref>. Simple Touch based games: Simple In.Event based games such as Colorphun <ref type="bibr" target="#b9">[10]</ref> and Memory Game <ref type="bibr" target="#b29">[30]</ref> involve the user to touch specific places on the display to score and make forward progress. These games are also light on graphics and compute components, and mainly use CPU and display for most of their execution. Swipe based games: Games such as Candy Crush <ref type="bibr" target="#b30">[31]</ref> and Greenwall <ref type="bibr" target="#b31">[32]</ref> (open source version Fruit Ninja <ref type="bibr" target="#b32">[33]</ref> game) involve swipe as the major In.Event input, and also have more animations in the game outputs compared to the simple touch based games. These games also display more components on the screen compared to touch based games, with which the users can interact, performs animated reactions, and more computations in each event processing as well. Multi In.Event games: AB Evolution or Angrybirds Evolution <ref type="bibr" target="#b14">[15]</ref>, Chase Whisply <ref type="bibr" target="#b10">[11]</ref> and Race Kings <ref type="bibr" target="#b11">[12]</ref> games have much more complex In.Event objects involving drag, tilt, and multi-touch events. Unlike the above four games, these games also use 3D rendering in the screen with the GPU heavily involved to process the events, that involve heavy physics computations <ref type="bibr" target="#b33">[34]</ref>. In addition to other IPs, ChaseWhisply also uses the camera feed continuously to render AR objects in it and display them to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. System Setup</head><p>All our studies and experiments are conducted in a Pixel XL class mobile device, that has a Qualcomm Snapdragon 821 SoC <ref type="bibr" target="#b34">[35]</ref> containing Quad-core Kryo CPUs, a 4 GB LPDDR4 memory and a 32 GB internal storage, and is powered by a 3450 mAh battery. Using this hardware for our experiments has two specific objectives, namely, (i) measure the energy consumption of the different hardware components in the app execution; and (ii) record the event data during app execution to subsequently send to cloud to follow the steps in Sec. V. We next describe the system setup to achieve the objectives.</p><p>Measuring the energy at hardware components: While there are multiple ways of measuring energy at the hardware <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref>, we use Qualcomm's Trepn power monitor app <ref type="bibr" target="#b36">[37]</ref> installed in the phone, that can tap into any process or the whole system execution to collect detailed stats on battery consumption, CPU, memory, GPU, and other hardware usage. To record individual components' energy consumption, we deploy specific microbenchmark apps to use only specific components, namely, CPU, CPU+memory, display, sensors, camera, audio and video codecs and measure their power consumption using the Trepn app. With this system, any game's events recorded (using the process described next) can be plugged-in with the power consumption of the different components to get a detailed time series view of component level energy consumption in the course of execution.</p><p>To compute the duration taken to drain a 100% charged battery, we also make use of the above system to measure the game play's power consumption behavior over a duration of ≈ 5-10 minutes, to calculate how long the execution will take to consume 3450 mAh (100% battery capacity). Recording the events in game execution: In order to record all the events occurring during execution (as described in Sec. V-B), we customize the Android OS to log all the event data occurring in the execution. In our experiments, we connect the phone to an Android Debugger <ref type="bibr" target="#b38">[39]</ref> client and collect the event logs directly and use it for building the profile with the setup described earlier. However, we envision that the system will be able to transfer the event logs to cloud from any smartphone in the future. While capturing all the sensor activities and events are straightforward (by instrumenting binder threads), capturing the camera feed is a special case because of how the hardware is built in modern SoCs <ref type="bibr" target="#b34">[35]</ref>. For tracking camera events, we run a screen record process that simultaneously record the camera feed into a video file that are sent to the cloud for building the PFI. In the future, the screen record feature in upcoming Android versions <ref type="bibr" target="#b39">[40]</ref> can be leveraged to accomplish this across all apps. We next use this experimental setup to study the effectiveness and drawbacks of SNIP.  To evaluate the benefits from SNIP, we next list comparison points from prior works and best case scenarios, that specifically test the different aspects of our proposal namely, optimizing only the CPU part <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b41">42]</ref>, optimizing only the IP part <ref type="bibr" target="#b42">[43]</ref> and the lookup table overheads. They are:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example</head><p>• Max CPU: To study the effects of short-circuiting the CPU computations alone using prior approaches such as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b41">42]</ref> for game executions, and also understand the energy gap between optimizing just for CPU execution (example in Table <ref type="table" target="#tab_4">I</ref>) vs optimizing the whole SoC in SNIP, we present the Max CPU scheme. Note that, this scheme also assumes quantifies the maximum benefits from techniques such as <ref type="bibr" target="#b41">[42]</ref> which assumes all data to be known apriori (recall from Fig. <ref type="figure" target="#fig_4">5</ref>(a)), whereas the game execution needs our proposed lookup table solution to find all inputs apriori. • Max IP: Prior approaches such as <ref type="bibr" target="#b42">[43]</ref> show that IPs can be switched to sleep states when they are idle. This scheme studies the impact of such techniques in game executions (example in Table <ref type="table" target="#tab_4">I</ref>) and also quantifies the gap between short-circuiting just the IP calls vs the whole event processing in SNIP.</p><p>• SNIP: This is our proposed technique, where both CPU and IPs can benefit from avoiding redundant event processing and hence both IPs and CPUs can save their energy. • No Overheads: This scheme follows the exact same optimization steps of SNIP. In addition, it does not incur any overheads in terms of lookup table costs and comparisons on each input event processing and shows the scope for future optimizations in this domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Energy benefits and overheads of SNIP approach</head><p>We next discuss the energy benefits from the schemes described earlier and the reason for these benefits in Fig. <ref type="figure" target="#fig_12">11</ref>. First, Fig. <ref type="figure" target="#fig_12">11a</ref> shows the energy benefits for all the schemes w.r.t baseline execution, where we observe that both Max CPU and Max IP have limited energy benefits in games, where Max CPU can save 0.5% (Chase Whisply) to 13% (Race Kings), and Max IP saves 0.7% (Memory Game) to 9% (Candy Crush) in terms of energy. In contrast, by taking both SNIP can benefit anywhere between 24% (Race Kings) to 37% (AB Evolution) of the event processing energy, translating to an extra battery life of 1.6 hours on an average and a maximum of 2.6 hours in Colorphun game. This benefit is mainly from the better opportunity to short-circuit the event processing end-to-end instead of optimizing only certain parts of the execution as shown in the example code in Table <ref type="table" target="#tab_4">I</ref>. For example, Max CPU can only optimize repeated CPUFunc i and not the IP i calls and Max IP can optimize for only the IP i invocations. Quantitatively, Fig. <ref type="figure" target="#fig_12">11b</ref> shows the % of executions that can be short-circuited by each of the above schemes. As seen, Max CPU and Max IP could potentially short-circuit a maximum of 26% and 15 % of the execution for Colorphun but the energy gains from Colorphun is just 0.6% and 5% respectively. This is primarily because Colorphun game is already a light weight application, and even the overheads for looking up the necessary inputs (Fig. <ref type="figure" target="#fig_12">11c</ref>) compares 7.5kB of data on every event. On the other hand, SNIP can potentially short-circuit anywhere between 40% (Race Kings) to 61% (Candy Crush) of the execution with an average scope for short-circuiting 52% of the execution -that translates to 32% average energy savings (or 1.6 hours of extra battery life).</p><p>Note that, SNIP approach also has additional overheads as seen in Fig. <ref type="figure" target="#fig_12">11c</ref>, where it needs to load a lookup table (memory operations) and compare against each and every necessary input for that event (Comparisons × PFI Input Size) in the table in order to find when to short-circuit the execution. In order to measure this overhead, we also present SNIP scheme without any overheads from these comparisons to save additional energy of anywhere from 1% (Colorphun, Greenwall, and AB Evolution) to 3% (Race Kings) with the exception of 12% in Memory Game -due to the high amount of comparisons for each event processing. On an average, the overheads in SNIP approach can consume 3% of the execution energy -indicating the PFI based Selecting Necessary InPuts scheme to be viable, software based alternative compared to the traditional memoization approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Continuous learning to avoid developer intervention</head><p>The above analysis assume the profile and the developer instrumentation to accurately capture all necessary input fields for the execution to result in correct execution. However, in practical purposes prior studies such as <ref type="bibr" target="#b43">[44]</ref> show that users generate vastly different events/inputs and it is important for any event learning approach such as PFI in SNIP to fine tune the learning continuously (Option 2 in Sec. V-B). Fig. <ref type="figure" target="#fig_10">12</ref> shows the PFI detection can adapt to recover itself from erroneous shortcircuits by relearning the user behavior continuously. We plot the different instances of the same user playing a sample game in x-axis, and plot the % erroneous output fields in y-axis as a result of short-circuiting using SNIP without developer intervention for AB Evolution game. In this experiment, we artificially keep the initial few iterations of the profile to be insufficient for PFI to not capture all the necessary input fields of the subsequent execution. Therefore, we also observe the initial few iterations of short-circuiting using PFI to be approximately 40% erroneous for the first few instances of execution. However, as more and more instances of user events get to the cloud, a more accurate lookup table is built. Thus, after a few initial bad runs, the % of erroneous output fields get to &lt; 0.1% in just 40 training epochs.</p><p>To avoid developer intervention (Option 1 in Sec. V-B), one could train the PFI model and test on subsequent event records till a confidence threshold is reached. This could ensure that the user will only start experiencing PFI based short-circuiting when the % of erroneous output fields is negligible. As a future extension, the profiler can also direct the mobile phone to "clear" the PFI lookup table if it detects the error rate to worsen (although not observed in our experiments), as well as receive user feedback on the quality of execution -to even "turn off" SNIP feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Overheads and limitations</head><p>For SNIP to be effective, the mobile phone should just  capture and send the user events to the server. Therefore, at the client side, the event collection overhead is negligible. However, at the backend, processing 2 minutes game play to get a sleek lookup table could take around 2 days of processing in a 48 core, 64GB memory Xeon E5 class server. In this process, the lookup table size gets shrunk from 100s of GBs to 600MB. While this back-end overhead is costly, techniques such as federated AI <ref type="bibr" target="#b44">[45]</ref> can be explored as future research directions for reducing the backend overheads as well as performing collective learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. RELATED WORK</head><p>We next discuss the related works to SNIP below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Memoization</head><p>Prior works such as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b45">46]</ref> have built look up tables (both in hardware and software) for short-circuiting such repeated computations in the CPU execution contexts for scientific workloads. For example, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14]</ref> use hardware table to short circuit data flow graphs based on register information, <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b46">47]</ref> uses a software based compiler and runtime memoization engine, <ref type="bibr" target="#b41">[42]</ref> replaces frequently executed hot codes with a trained CNN engine to approximately short circuit the execution. However, as the example code in Table <ref type="table" target="#tab_4">I</ref> illustrates, these prior works cannot be directly adopted to fully exploit short-circuit the end to end execution from event generation and all the nested function calls crossing app/OS/IP invocations occurring in a mobile game execution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Mobile SoC Optimizations</head><p>In mobile SoC, many prior works such as <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48]</ref> target optimizations towards a single component such as CPU <ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref>, video codecs <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53]</ref>, sensors <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>, interconnects <ref type="bibr" target="#b47">[48]</ref>, memory <ref type="bibr" target="#b55">[56]</ref>, neural/vision processing <ref type="bibr" target="#b56">[57]</ref> and battery <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref>, and while considering the whole SoC, works such as <ref type="bibr" target="#b55">[56]</ref> aim to meet the QoS requirements of frame based apps by reorganizing the IP scheduling. The most related work to our proposal is <ref type="bibr" target="#b42">[43]</ref> where individual IPs are aggressively switched to sleep states when they are idle, to save energy. While SNIP also aims to conserve energy of the whole SoC, it creates more opportunities by exploiting the significant occurrences of redundant event processing and snips the computation to get the outputs directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. ML based Optimizations</head><p>ML is emerging as a useful tool to optimize different parts of the system such as prefetchers <ref type="bibr" target="#b59">[60]</ref>, branch predictors <ref type="bibr" target="#b60">[61]</ref>, approximating executions <ref type="bibr" target="#b41">[42]</ref> and scheduling <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> in the recent years. Particularly techniques such as <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> are already implemented in mobile phones, and they focus on better user interactions, manage the battery as per user behavior, etc. by training appropriate ML models for them. However, Android battery optimization techniques are not domain specific and just learn to suspend/kill idle threads in the whole system. SNIP exploits the redundant events in these games to bring additional gains on top of the existing energy savings from the Android battery optimization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSIONS</head><p>Although gaming is a widely popular domain of applications in mobile phones, these applications drain the battery much faster than many other classes of applications. This is primarily because of the user-driven interactive mode of operation, where the generated events continuously stress the SoC. In this paper, we propose a software solution, called SNIP, to minimize the energy consumption by exploiting the repetitive nature of inputs and outputs. While memoization can identify and short-circuit redundant events, the event processing involves multiple function calls spanning to even OS and IP invocations and hence, the lookup table size becomes prohibitively large. Our proposed solution SNIP uses a machine learning technique on the execution profile, to trim down the lookup table size by keeping only a small subset of necessary inputs needed to generate correct outputs. The complete SNIP design consists of a lightweight event tracker at the smartphone, a cloud based offline profiler, a Permutation Feature Importance (PFI) module to trim down the lookup table size, and subsequent compiler based code instrumentation to leverage the PFI lookup table during execution. We have implemented and evaluated SNIP approach on a Pixel XL phone and observe that we can save 32% energy in 7 popular games while being almost completely error free.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1: Example game execution in a smart phone. The user generated events are captured at sensors, to be processed at both CPUs and IPs and finally produces the outputs back to the user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Both CPU and IPs consume almost equal amount of energy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Rampant battery drain in games.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Compute scenarios: (a) has deterministic locations for input/outputs; (b) has varying input/output locations and count. Lookup tables store constant size inputs and outputs per record with the record itself consisting of the input/output values seen in prior executions. Using this history, future executions can index into a particular record based on the current input values, and get the outputs directly without actually executing the computations.For such an approach to be feasible, all the locations from where the inputs are loaded and outputs are stored should be known apriori (Fig.5(a)). However, the various hardware components involved in the compute black box (CPU cores and IPs) in a mobile SoC often involve dynamic memory accesses during execution, as shown in Fig.5(b)-where two instances of the computation (shown as different shades), consume varying number of inputs from varying locations, and also produce outputs to store into different locations.To overcome the variability and still use a lookup mechanism, we consider the lookup table to contain the input values from all the possible input locations, i.e., union of all the input locations; and short-circuit the execution for all the possible outputs, i.e., union of all output locations. We study the impact of this approach for a sample game execution, AB Evolution<ref type="bibr" target="#b14">[15]</ref>, by plotting the size of the lookup table necessary for short-circuiting varying portions of the game execution in Fig.6. Here, the x-axis plots the execution coverage in terms of the % of events weighted by the number of dynamic instructions each instance of the event processing executedto account for the dynamism in context-sensitive processing.</figDesc><graphic url="image-2.png" coords="4,59.19,306.86,175.20,77.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Example characteristics of AB Evolution game illustrates that (a) the three types of inputs vary in sizes and vary for different instances of event processing; (b) likewise, the three types of outputs also vary similarly; and (c) the reason for such variations is the dynamism involved in these game executions.</figDesc><graphic url="image-3.png" coords="5,420.45,72.64,124.67,101.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: (a) Using only In.Event objects for input records, the AB Evolution game's lookup table is smaller, but produces erroneous outputs; (b) The breakdown of erroneous outputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Permutation Feature Importance [6] identifies the most influential input fields from all input categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 :</head><label>10</label><figDesc>Fig. 10: Overall flow of the proposed methodology</figDesc><graphic url="image-72.png" coords="7,59.41,73.27,235.44,66.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 :</head><label>12</label><figDesc>Fig. 12: Avoiding developer intervention is possible with adaptive, continuous learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 :</head><label>11</label><figDesc>Fig. 11: (a) Energy benefits using various schemes; (b) The % execution that can leverage each of the optimizations; (c) The overheads in SNIP are due to the extra energy spent at the CPU and memory for looking up the table before each event processing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.</figDesc><table><row><cell>% Events that did not have any</cell><cell>impact in the game</cell><cell>0% 10% 20% 30% 40% 50%</cell><cell>% Useless Events</cell><cell>% Energy Wasted</cell><cell>0% 10% 20% 30% 40% 50%</cell><cell>% Battery consumption wasted</cell><cell>on processing useless events</cell></row><row><cell cols="7">Fig. 4: % of user events captured in mobile</cell><cell></cell></row><row><cell cols="7">games that resulted in the exact same output</cell><cell></cell></row><row><cell cols="5">as current state after processing.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table Size (GB) % Execution Coverage Input Only Input + Output Exceeds Typical SD card capacity Exceeds Typical memory capacity</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>64</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>32</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>16</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Naïve Lookup</cell><cell>1 2 4 8</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell>10%</cell><cell>20%</cell><cell>30%</cell><cell>40%</cell></row></table><note>Fig. 6: Lookup table size vs. coverage.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I :</head><label>I</label><figDesc>Example Code in Games and what parts can be optimized by the prior works.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 14:03:04 UTC from IEEE Xplore. Restrictions apply.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>X. ACKNOWLEDGEMENTS This research is supported in part by NSF grants 1763681, 1629915, 1629129, 1317560, 1526750, 1714389, 1912495, and a DARPA/SRC JUMP grant.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 14:03:04 UTC from IEEE Xplore. Restrictions apply.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Number of active mobile gamers worldwide from 2014 to 2021 (in millions)</title>
		<ptr target="https://www.statista.com/statistics/748089/number-mobile-gamers-world-platform/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Pokémon GO</title>
		<author>
			<persName><forename type="first">I</forename><surname>Niantic</surname></persName>
		</author>
		<ptr target="https://play.google.com/store/apps/details?id=com.nianticlabs.pokemongo" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic Instruction Reuse</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sodani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="page" from="194" to="205" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SlicK: Slice-based Locality Exploitation for Efficient Redundant Multithreading</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gurumurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2006-10">Oct. 2006</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="95" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Microarchitectural innovations: boosting microprocessor performance beyond semiconductor technology scaling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
				<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1560" to="1575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Machine learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
	<note>Random forests</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">All Models are Wrong but many are Useful: Variable Importance for Black-Box, Proprietary, or Misspecified Prediction Models, using Model Class Reliance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dominici</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01489</idno>
		<imprint>
			<date type="published" when="2018-01">Jan 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<author>
			<persName><surname>Hardware</surname></persName>
		</author>
		<author>
			<persName><surname>Sensormanager</surname></persName>
		</author>
		<ptr target="https://developer.android.com/reference/android/hardware/SensorManager" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">"</forename><surname>Google</surname></persName>
		</author>
		<author>
			<persName><surname>Binder</surname></persName>
		</author>
		<ptr target="https://developer.android.com/reference/android/os/Binder" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A Simple Color Game in Android</title>
		<author>
			<persName><forename type="first">P</forename><surname>Srivastav</surname></persName>
		</author>
		<ptr target="https://github.com/prakhar1989/ColorPhun" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Chase Whisply -Beta</title>
		<ptr target="https://play.google.com/store/apps/details?id=fr.tvbarthel.games.chasewhisply" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Race Kings</title>
		<author>
			<persName><forename type="first">H</forename><surname>Games</surname></persName>
		</author>
		<ptr target="https://play.google.com/store/apps/details?id=com.hutchgames.racingnext" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">RedEye: Analog ConvNet Image Sensor Architecture for Continuous Mobile Vision</title>
		<author>
			<persName><forename type="first">R</forename><surname>Likamwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Polansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="255" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploiting value locality in physical register files</title>
		<author>
			<persName><forename type="first">S</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture</title>
				<meeting>the International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="265" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Angry Birds Evolution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Corporation</surname></persName>
		</author>
		<ptr target="https://play.google.com/store/apps/details?id=com.rovio.tnt" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic and Transparent Memoization</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J M M</forename><surname>Van Goghbrian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Beckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">US Patent</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">B2</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Never Settle -OnePlus</title>
		<author>
			<persName><surname>Oneplus</surname></persName>
		</author>
		<ptr target="https://www.oneplus.com/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Play the Next Level of Gaming</title>
		<author>
			<persName><surname>Oculus</surname></persName>
		</author>
		<ptr target="https://www.oculus.com" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A comparative study of visual and auditory reaction times on the basis of gender and physical activity levels of medical first year students</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied and Basic Medical Research</title>
		<imprint>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Load Slice Core microarchitecture</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Allam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="272" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Monkeyrunner</title>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/test/monkeyrunner/index.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Logcat command-line tool</title>
		<author>
			<persName><forename type="first">A</forename><surname>Studio</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/command-line/logcat" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Android Studio</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/index.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">rePLay: A Hardware Framework for Dynamic Optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lumetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="page" from="590" to="608" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GemDroid: A Framework to Evaluate Mobile Platforms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chidambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yedlapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</title>
				<meeting>the International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">View the Java Heap and Memory Allocations with Memory Profiler</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/profile/memory-profiler" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Android analysis tools</title>
		<author>
			<persName><surname>Madvay</surname></persName>
		</author>
		<ptr target="https://github.com/madvay/android-analysis-tools" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The Role of the CPU in Energy-Efficient Mobile Web Browsing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="26" to="33" />
			<pubPlace>Micro</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<ptr target="https://play.google.com/store/apps/top/category/GAME" />
		<title level="m">Top Charts -Android Apps on Google Play</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Simple and Beautiful Memory Game for Kids</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kushnarenko</surname></persName>
		</author>
		<ptr target="https://github.com/sromku/memory-game" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Candy Crush Saga</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Aragon</surname></persName>
		</author>
		<ptr target="https://play.google.com/store/apps/details?id=com.king.candycrushsaga" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A Weirdly Addictive Arcade-style Android Game, Where you Fling Fruit at a Wall</title>
		<author>
			<persName><forename type="first">T</forename><surname>Messick</surname></persName>
		</author>
		<ptr target="https://github.com/awlzac/greenwall" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fruit Ninja</title>
		<author>
			<persName><forename type="first">H</forename><surname>Studios</surname></persName>
		</author>
		<ptr target="https://play.google.com/store/apps/details?id=com.halfbrick.fruitninjafree" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">What is Unreal Engine 4</title>
		<author>
			<persName><forename type="first">U</forename><surname>Engine</surname></persName>
		</author>
		<ptr target="https://www.unrealengine.com" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Qualcomm Snapdragon 821 Mobile Platform</title>
		<ptr target="https://www.qualcomm.com/products/snapdragon-821-mobile-platform" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Qualcomm Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Inspect energy use with profiler</title>
		<ptr target="https://developer.android.com/studio/profile/energy-profiler" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Trepn Power Profiler</title>
		<ptr target="https://developer.qualcomm.com/forums/software/trepn-power-profiler" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Qualcomm Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<author>
			<persName><surname>Batterymanager</surname></persName>
		</author>
		<ptr target="https://developer.android.com/reference/android/os/BatteryManager" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Android Debug Bridge (adb)</title>
		<author>
			<persName><forename type="first">Android</forename><surname>Studio</surname></persName>
		</author>
		<ptr target="https://developer.android.com/studio/command-line/adb" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Android Q has a native screen recorder, but it&apos;s pretty rough for now</title>
		<author>
			<persName><forename type="first">A</forename><surname>Authority</surname></persName>
		</author>
		<ptr target="https://www.androidauthority.com/android-q-screen-recorder-965837/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An Empirical Analysis of Instruction Repetition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sodani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural Acceleration for General-Purpose Approximate Programs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Esmaeilzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ceze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture</title>
				<meeting>the International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="449" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Domain knowledge based energy management in handhelds</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yedlapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="150" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Quick, Draw! The Data</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://quickdraw.withgoogle.com/data" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Federated learning: Collaborative machine learning without centralized training data</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Blog</surname></persName>
		</author>
		<ptr target="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Compiler-directed dynamic computation reuse: rationale and initial results</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Conners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A compiler scheme for reusing intermediate computation results</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Code Generation and Optimization (CGO)</title>
				<meeting>the International Symposium on Code Generation and Optimization (CGO)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="277" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Vip: Virtualizing ip chains on handheld platforms</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture (ISCA)</title>
				<meeting>the International Symposium on Computer Architecture (ISCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="655" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Characterizing Diverse Handheld Apps for Customized Hardware Acceleration</title>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Chidhambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><surname>Chita R Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Symposium on Workload Characterization</title>
				<meeting>IEEE International Symposium on Workload Characterization</meeting>
		<imprint>
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Critics critiquing criticality in mobile apps</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Rengasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="867" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">NVIDIA&apos;s Denver processor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rozas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Venkatraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HOTChips</title>
		<imprint>
			<biblScope unit="page" from="86" to="95" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A 28 nm 0.6 V Low Power DSP for Mobile Applications</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ickes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gammie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Sinangil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rithe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Honnavara-Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Buss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Chandrakasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Race-To-Sleep + Content Caching + Display Caching: A Recipe for Energyefficient Video Streaming on Handhelds</title>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Chidambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chita</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Microarchitecture (MICRO)</title>
				<meeting>the International Symposium on Microarchitecture (MICRO)</meeting>
		<imprint>
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Iotrepair: Systematically addressing device faults in commodity iot</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/ACM Fifth International Conference on Internetof-Things Design and Implementation (IoTDI)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="142" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Understanding energy efficiency in iot app executions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Rengasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhuyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="742" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">FLOSS: FLOw Sensitive Scheduling on Mobile Platforms</title>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rengasamy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Nachiappan</forename><surname>Chidambaram Nachiappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shulin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Sivasubramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chita</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Design and Automation Conference (DAC)</title>
				<meeting>the Design and Automation Conference (DAC)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Exploring Architectural Heterogeneity in Intelligent Vision Systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chandramoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tagliavini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Irick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pullini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Advani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Habsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cotter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Power management -Android</title>
		<author>
			<persName><surname>Android</surname></persName>
		</author>
		<ptr target="https://developer.android.com/about/versions/pie/power" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<ptr target="https://developer.android.com/about/versions/nougat/android-7.0.html" />
		<title level="m">Doze on the Go</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Bingo Spatial Data Prefetcher</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="399" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Dynamic branch prediction with perceptrons</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<meeting>the International Symposium on High-Performance Computer Architecture (HPCA)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
