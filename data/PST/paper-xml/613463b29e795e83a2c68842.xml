<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
							<email>qinkai@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<email>yuxiaod@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Da</forename><surname>Yin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiarong</forename><surname>Xu</surname></persName>
							<email>jiarongxu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
							<email>yangya@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University • Fudan University Zhejiang University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the GRB pipeline, the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards across different scenarios. As a starting point, we conduct extensive experiments to benchmark baseline techniques. GRB is open-source and welcomes contributions from the community. Datasets, codes, leaderboards are available at https://cogdl.ai/grb/home. * Jie Tang is the corresponding author. 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph machine learning (GML) models, from network embedding <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> to graph neural networks (GNNs) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>, have shown promising performance in various domains, such as social network analysis <ref type="bibr" target="#b0">[1]</ref>, molecular graphs <ref type="bibr" target="#b4">[5]</ref>, and recommender systems <ref type="bibr" target="#b9">[10]</ref>. However, GML models are known to be vulnerable to adversarial attacks <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>. Attackers can modify the original graph by adding or removing edges <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>, perturbing node attributes <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>, or injecting malicious nodes <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref> to conduct adversarial attacks. Despite the relatively minor changes to the graph, the performance of GML models can be impacted dramatically.</p><p>Threatened by adversarial attacks, a line of attempts have been made to have robust GML models. For example, recent GNN architectures such as RobustGCN <ref type="bibr" target="#b20">[21]</ref>, GRAND <ref type="bibr" target="#b21">[22]</ref>, and ProGNN <ref type="bibr" target="#b22">[23]</ref> are designed to improve the adversarial robustness of GNNs. In addition, pre-processing based methods, such as GNN-SVD <ref type="bibr" target="#b23">[24]</ref> and GNNGuard <ref type="bibr" target="#b24">[25]</ref>, alleviate the impact of attacks by leveraging the intrinsic graph properties and thus improve the model robustness. Despite various efforts in this direction, there are several common limitations from both the attacker and the defender sides: 1. Unrealistic Attack/Defense Scenarios. The existing attack and defense setups are often ambiguously defined with unrealistic assumptions, such as ignoring the real-world capabilities of attackers and defenders, resulting in less practical applications. 2. Lack of A Unified Evaluation Protocol. Previous works often use different settings (e.g., datasets, data splittings, attack constraints) in their experiments, resulting in biases in the evaluation and thus making it difficult to fairly compare different methods. 3. Lack of Scalability. Most existing attacks and defenses are performed on very small-scale graphs (e.g., &lt;10,000 nodes) without considering different levels of attack/defense difficulties, which are far from the scale and complexity of real-world applications.</p><p>To date, there exist several well-established GML benchmarks. For example, the Open Graph Benchmark (OGB) <ref type="bibr" target="#b25">[26]</ref> offers abundant datasets and a unified evaluation pipeline for GML. Benchmarking GNNs <ref type="bibr" target="#b26">[27]</ref> is a standardized benchmark with consistent experimental settings. However, they mainly focus on evaluating the performance of GML models, regardless of their robustness. DeepRobust <ref type="bibr" target="#b27">[28]</ref> is a toolkit with implementations of attacks and defenses on both image and graph data, which by design is not a GML benchmark. Therefore, to address the aforementioned limitations, there is an urgent need for public benchmarks on evaluating the adversarial robustness of GML models.</p><p>In this paper, we propose the Graph Robustness Benchmark (GRB)-the first attempt to benchmark the adversarial robustness of GML models. The goal of GRB is to provide a reproducible framework that enables a fair evaluation for both adversarial attacks &amp; defenses on GML models under unified settings. To achieve this, GRB is designed to have the following properties:</p><p>1. Refined Attack/Defense Scenarios. GRB includes two refined attack scenarios: graph modification and graph injection, covering the majority of works in the field. By revisiting the limitations of previous works, we formalize precise definitions for both attackers' and defenders' capabilities, including available information to use and allowed actions, forming more realistic evaluations. 2. Scalable and Unified Evaluations. GRB contains various datasets of different orders of magnitude in size, with a specific robustness-focused splitting scheme for various levels of attacking/defending difficulties. It also provides a unified evaluation pipeline that calibrates all experimental settings, enabling fair comparisons for both attacks and defenses. 3. Reproducible and Public Leaderboards. GRB offers a modular code framework * that supports the implementations of a diverse set of baseline methods covering GML models, attacks, and defenses. Additionally, it hosts public leaderboards across all evaluation scenarios, which will be continuously updated to track the progress in this community.</p><p>Overall, GRB serves as a scalable, unified, modular, and reproducible benchmark on evaluating the adversarial robustness of GML models. It is designed to facilitate the robust developments of graph adversarial learning, summarizing existing progress, and generating insights into future research.</p><p>2 Adversarial Robustness in Graph Machine Learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>In graph machine learning, adversarial robustness refers to the ability of GML models to maintain their performance under potential adversarial attacks. Take the task of node classification as an instance, for an undirected attributed graph G = (A, F) where A ∈ R N ×N represents the adjacency matrix of N nodes and F ∈ R N ×D denotes the set of node features with D dimensions. Define a GML model M : G → Z where Z ∈ [0, 1] N ×L , which maps a graph G to probability vectors with L classes. Generally, the objective of adversarial attacks on GML models can be formulated as:</p><formula xml:id="formula_0">max G | arg max l∈[1,...,L] M(G ) = arg max l∈[1,...,L] M(G)| s.t. d A (A , A) ≤ ∆ A and d F (F , F) ≤ ∆ F (1)</formula><p>where G = (A , F ) is the attacked graph, and d A and d F are distance metrics in the metric space (A, d A ) and (F, d F ). The attacker tries to maximize the number of incorrect predictions by GML models, under the constraints ∆ A and ∆ F . For instance, ∆ A can be the limited number of modified edges and ∆ F can be the limited range of modified features (Cf. Section 3 for detailed discussions). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Revisiting Adversarial Attacks and Defenses in GML</head><formula xml:id="formula_1">DICE [19] - - - FGA [11] - - - FLIP [29] - - - NEA [29] - - - FGSM [12] - - Nettack [12] - - RL-S2V [30] - - Metattack [13] - - - STACK [31] - - - AFGSM [16] - - - SPEIT [17] - - - TDGIA [18] - - - GRB Mod. Scenario - - - GRB Inj. Scenario - - - GRB Support †</formula><p>The table represents the original settings, while methods can be adapted to other settings by using GRB's modualr coding framework.</p><p>In the work of Szegedy et al. <ref type="bibr" target="#b31">[32]</ref>, the existence of adversarial examples was revealed for ML models in image classification-imperceptible perturbations on inputs have ineligible impact on outputs of models. Recent works (in Table 1) show that GML models are no exception. Graph adversarial attacks can mainly be categorized into two types according to the attack approach: graph modification attack and graph injection attack. Graph modification attacks directly modify the existing graph, by adding or removing edges (e.g., DICE <ref type="bibr" target="#b18">[19]</ref>, FGA <ref type="bibr" target="#b10">[11]</ref>, FLIP <ref type="bibr" target="#b28">[29]</ref>, NEA <ref type="bibr" target="#b28">[29]</ref>, STACK <ref type="bibr" target="#b30">[31]</ref>), or further modifying node features (e.g., Nettack <ref type="bibr" target="#b11">[12]</ref>, FGSM <ref type="bibr" target="#b11">[12]</ref>, RL-S2V <ref type="bibr" target="#b29">[30]</ref>, Metattack <ref type="bibr" target="#b12">[13]</ref>). Differently, graph injection attacks add new malicious nodes without modifying the original graph (e.g., AFGSM <ref type="bibr" target="#b15">[16]</ref>, SPEIT <ref type="bibr" target="#b16">[17]</ref>, TD-GIA <ref type="bibr" target="#b17">[18]</ref>). Facing the problem of scalability, some attacks are not applicable to large graphs due to their high time complexity <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b29">30]</ref> or expensive memory consumption <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>Defenses can mainly be categorized into two types: preprocess-based defense and model-based defense. The first type regards the attacked graphs as noisy ones and defenders can preprocess the adjacency matrix (e.g., GNN-SVD <ref type="bibr" target="#b23">[24]</ref>, GNN-Jaccard <ref type="bibr" target="#b32">[33]</ref>) or the features of nodes (e.g., feature transformation <ref type="bibr" target="#b16">[17]</ref>), to alleviate the effect of perturbations. The second type achieves robustness through model enhancement, either by robust training schemes (e.g., adversarial training <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>) or new model architectures (e.g., RobustGCN <ref type="bibr" target="#b20">[21]</ref>, GNNGuard <ref type="bibr" target="#b24">[25]</ref>). Some defenses also suffer from the problem of scalability, due to the need of calculation on large dense matrices <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Notwithstanding the significant progress, existing works share some common limitations: (1) Lack of scalability: Most works only consider very small graphs and cannot be scaled up to larger ones due to time/memory complexity. (2) Lack of generalization: Most attacks/defenses are evaluated on very basic GML models, but not on other variants. Meanwhile, some methods are only effective for specific models with ad-hoc designs, which makes the results less generalized and practical.</p><p>(3) Ill-defined scenarios: The scenarios and assumptions proposed in some previous works are not realistic, e.g., the unnoticeability under poisoning setting ignores the real capability of the defenders (Cf. Appendix A.3 for details). Besides, there are no unified standards on evaluating the adversarial robustness. Different settings (e.g., the choice of datasets, random splitting, different constraints) introduce biases, which makes it hard to compare the effectiveness of different methods. In light of these challenges, there is an urgent need for benchmarking the adversarial robustness of GML. To overcome the limitations of previous works, we propose the Graph Robustness Benchmark (GRB)-a standardized benchmark for evaluating the adversarial robustness of GML. To ensure GRB's scalability, we include datasets of different sizes with scalable attack/defense baselines. To have a unified process, we standardize the evaluation scenarios with precise constraints and realistic assumptions on attackers and defenders. To make GRB easy-to-use, we provide a modular pipeline that facilitates the implementation of GML models, attacks, and defenses. To guarantee the reproducibility, we open-source and maintain the GRB public leaderboards that are continuously updated to track the progress of the community.</p><p>Altogether, GRB serves as a scalable, unified, modular, reproducible benchmark on evaluating the adversarial robustness of GML models. We present the solutions to achieve these goals for GRB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Unified Evaluation Scenario of GML Adversarial Robustness</head><p>To evaluate the adversarial robustness, it is essential to be aware of the capabilities of potential attackers. We categorize attacks into the following aspects (as shown in Table <ref type="table" target="#tab_0">1</ref>):</p><p>1. Knowledge. Black-box: Attackers do NOT have access to the targeted model (including its architecture, parameters, defense mechanism, etc.). However, they can access the graph data (structure, features, labels of training data, etc.). Additionally, they have limited chances to query the model to get outputs. White-box: Attackers have access to ALL information. However, if the targeted model has a random process, the run-time randomness is still preserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Objective. Poisoning: Attackers generate corrupted graph data and assume that the targeted model is (re)trained on these data to get a worse model. Evasion: The target model has already been trained, and attackers can generate corrupted graph data to affect its inference.</p><p>3. Approach. Modification: Attackers modify the original graph (the same one used by defenders for training) by adding/removing edges or perturbing node features. Injection: Attackers do not modify the original graph but inject new malicious nodes to influence a set of targeted nodes.</p><p>In practice, the most common real-world case is that the GML models have already been trained for specific tasks and deployed in a secret way, i.e., black-box and evasion settings. Thus, in GRB, we propose two unified evaluation scenarios under these settings, graph modification and graph injection.</p><p>Graph Modification. This has been the most studied scenario, in which attackers can directly modify the graph (by adding/removing edges or perturbing node attributes) to attack the GML models. Under real-world conditions, this is theoretically possible but practically difficult, as the modification attacks require the authority to access the target nodes in order to to change their contents. Nevertheless, this scenario enables us to understand how the GML models behave under intended modifications.</p><p>Graph Injection. This scenario was first introduced in the KDDCUP 2020 task of Graph Adversarial Attacks &amp; Defenses † , which targeted at injecting new nodes to a large-scale academic graph. It is more realistic than the modification one since injecting new nodes is more practically possible than modifying the existing ones. However, the task in KDDCUP 2020 considers a transductive setting, i.e., test nodes (except for their labels) are available during training. In this case, defenders can simply memorize benign nodes and identify the injected nodes, making it an imperfect setting.</p><p>Thus, to further GRB's practical usage (Cf. Appendix A.3 for detailed discussions), we make the following assumptions for both scenarios: ( 2. For defenders: (a) They have knowledge about the graph excluding the test nodes to be attacked. (b) They are allowed to use any method to increase the adversarial robustness, but do not have prior knowledge about the edges/nodes that are modified/injected.</p><p>3. For both sides: Attackers/defenders can of course make assumptions even in the black-box scenario. For instance, attackers can assume that the target system deploys a certain type of GML models, then it can be used as the surrogate model to conduct transfer attacks. Moreover, it is not reasonable to assume that the defense mechanism can be completely held secretly, known as the Kerckhoffs' principle <ref type="bibr" target="#b35">[36]</ref>. If a defense wants to be general and universal, it should guarantee part of the robustness even when attackers have some knowledge about it. In GRB, we evaluate an attack vs. multiple defenses (vice versa), thus the assumptions can hardly violate the black-box conditions. As a result, the objective for both sides is to be generally effective against all potential methods rather than just a single one.</p><p>By following the above rules, we provide unified evaluation scenarios for attacks and defenses in a principled way. It is worth noting that these unified scenarios are not the only valid ones, GRB will include more scenarios as this field eveloves over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Modular GRB Pipeline</head><p>GRB offers a modular pipeline, which is based on PyTorch <ref type="bibr" target="#b36">[37]</ref> as well as other popular GML libraries like CogDL <ref type="bibr" target="#b37">[38]</ref> and DGL <ref type="bibr" target="#b38">[39]</ref>. Specifically, it contains the following modules: (1) Dataset: GRB provides data-loaders for GRB datasets and applies necessary preprocessing including splitting and feature normalization; it also supports external datasets like OGB <ref type="bibr" target="#b25">[26]</ref> or user-defined datasets.</p><p>(  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The GRB Baselines</head><p>Currently, GRB covers a rich set of baselines for the GML models, attacks, and defenses.</p><p>Seven GML models: GCN <ref type="bibr" target="#b3">[4]</ref>, GAT <ref type="bibr" target="#b5">[6]</ref>, GIN <ref type="bibr" target="#b6">[7]</ref>, APPNP <ref type="bibr" target="#b7">[8]</ref>, TAGCN <ref type="bibr" target="#b19">[20]</ref>, GraphSAGE <ref type="bibr" target="#b4">[5]</ref>, SGCN <ref type="bibr" target="#b8">[9]</ref>. Note that these models are not originally designed to increase robustness.</p><p>Twelve Attacks: Seven modification attacks-RND <ref type="bibr" target="#b11">[12]</ref>, DICE <ref type="bibr" target="#b18">[19]</ref>, FGA <ref type="bibr" target="#b10">[11]</ref>, FLIP <ref type="bibr" target="#b28">[29]</ref>, NEA <ref type="bibr" target="#b28">[29]</ref>, STACK <ref type="bibr" target="#b30">[31]</ref>, and PGD <ref type="bibr" target="#b33">[34]</ref>-and five injection attacks-RND, FGSM <ref type="bibr" target="#b39">[40]</ref>, PGD <ref type="bibr" target="#b33">[34]</ref>, SPEIT <ref type="bibr" target="#b16">[17]</ref>, and TDGIA <ref type="bibr" target="#b17">[18]</ref>. More details can be found in Appendix A.4.2.</p><p>Five Defenses: GRB adopts RobustGCN (R-GCN) <ref type="bibr" target="#b20">[21]</ref>, GNN-SVD <ref type="bibr" target="#b23">[24]</ref>, and GNNGuard <ref type="bibr" target="#b24">[25]</ref>. Additionally, we find that techniques like layer normalization (LN) <ref type="bibr" target="#b40">[41]</ref> and adversarial training (AT) <ref type="bibr" target="#b33">[34]</ref>, if properly used in the proposed evaluation scenarios, can significantly increase the robustness of various GML models. The LN can be applied on the input features and after each graph convolutional layer (except for the last one). The idea is to stabilize the dynamics of input and hidden states to alleviate the impact of adversarial perturbations. The AT uses modification/injection attacks during training to make GML models more robust. Note that most of previous works only use AT to perturb the existing graph, however, we find that AT also works well by injecting new nodes during training. These two defenses are general and scalable, and the experiment results show that they outperform previous dedicated methods. Thus, we include them in GRB as strong baselines for defenses. More details can be found in Appendix A.4.3. Scalability. GRB includes five datasets of different scales, grb-cora, grb-citeseer, grb-flickr, grbreddit, and grb-aminer. The original datasets are gathered from previous works <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b17">18]</ref> and are reprocessed for GRB. The basic statistics of these datasets are shown in Table <ref type="table" target="#tab_2">2</ref>. More details about datasets can be found in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">The GRB Datasets</head><p>Data Splitting. GRB introduces a new splitting data scheme designed for evaluating the GML adversarial robustness. Its key idea is based on the assumption that nodes with lower degrees are easier to attack, as demonstrated in <ref type="bibr" target="#b17">[18]</ref>. If a target node has few neighbors, it is more likely to be influenced by adversarial perturbations aggregated from its neighbors. Thus, we construct test subsets with different average degrees to represent different difficulties. First, we rank all nodes by their degrees. Second, we filter out 5% nodes with the lowest degrees (e.g., isolated nodes that are too easy to attack) and 5% nodes with the highest degrees (e.g., nodes connected to hundreds of other nodes that are too hard to attack). Third, we divide the rest of nodes into three equal partitions without overlapping, and randomly sample 10% nodes (without repetition) from each partition. Finally, we get three test subsets with different degree distributions as shown in Figure <ref type="figure" target="#fig_4">4</ref>, which are defined as Easy/Medium/Hard/Full ('E/M/H/F') with 'F' containing all test nodes. For the rest of nodes, we divide them into the training set (60%) and validation set (10%).</p><p>Feature Normalization. Initially, the features in each dataset have various ranges. To unify their constraints and to have values in the same scale (e.g., range [−1, 1]), we apply a standardization followed by an arctan transformation:</p><formula xml:id="formula_3">F = 2 π arctan( F −mean(F ) std(F )</formula><p>). The statistics of datasets after the splitting scheme and the feature normalization can be found in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>With the support of GRB's modular framework, we conduct extensively experiments to evaluate the adversarial robustness of GML models under the unified evaluation protocol, from which insights are generated into the developments of the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Baselines. (1) For GML models, we include 7 baselines: GCN <ref type="bibr" target="#b3">[4]</ref>, GAT <ref type="bibr" target="#b5">[6]</ref>, GIN <ref type="bibr" target="#b6">[7]</ref>, APPNP <ref type="bibr" target="#b7">[8]</ref>, TAGCN <ref type="bibr" target="#b19">[20]</ref>, GraphSAGE <ref type="bibr" target="#b4">[5]</ref>, SGCN <ref type="bibr" target="#b8">[9]</ref>. All models are salable to large graphs. (2) For modification attacks, we include 7 baselines: RND, DICE <ref type="bibr" target="#b18">[19]</ref>, FGA <ref type="bibr" target="#b10">[11]</ref>, FLIP <ref type="bibr" target="#b28">[29]</ref>, NEA <ref type="bibr" target="#b28">[29]</ref>, STACK <ref type="bibr" target="#b30">[31]</ref>, and PGD <ref type="bibr" target="#b33">[34]</ref>, among which RND, DICE, FLIP, and PGD are scalable to large graphs. FGA, NEA, and PGD need to train a surrogate model to conduct transfer attacks. (3) For injection attacks, we include 5 baselines: RND, FGSM <ref type="bibr" target="#b39">[40]</ref>, PGD <ref type="bibr" target="#b33">[34]</ref>, SPEIT <ref type="bibr" target="#b16">[17]</ref>, TDGIA <ref type="bibr" target="#b17">[18]</ref>. They are all scalable and FGSM, PGD, SPEIT, TDGIA need to train a surrogate model to conduct transfer attacks. (4) For defenses, we include R-GCN <ref type="bibr" target="#b20">[21]</ref>, GNN-SVD <ref type="bibr" target="#b23">[24]</ref>, GNNGuard <ref type="bibr" target="#b24">[25]</ref>. Among which only R-GCN is scalable, since the other two methods require calculation on dense adjacency matrix. Thus, we also adapt two general defense methods, layer normalization (LN) <ref type="bibr" target="#b40">[41]</ref> and adversarial training (AT) <ref type="bibr" target="#b33">[34]</ref> to the proposed scenarios. More details and hyper-parameter settings can be found in Appendix A.4 A.5.</p><p>Evaluation Metrics. For attacks: (1) Avg.: Average accuracy of all defenses (including vanilla GML models). ( <ref type="formula" target="#formula_2">2</ref> (1/j 2 ) , s i = (S ATK ascend ) i where S ATK ascend is the set of attack scores in an ascending order. The metric attaches more weight to more effective attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>We show an example of GRB leaderboard, robust ranking of GML models, and various factors that affect the adversarial robustness in GML. More results can be found in Appendix and on our website.</p><p>An Example of the GRB Leaderboard. Following the process in Figure <ref type="figure" target="#fig_0">1</ref>, we evaluate the performance of attacks vs. defenses in graph injection scenario. Table <ref type="table" target="#tab_3">3</ref> shows an example of leaderboard for grb-aminer dataset. Each attack is repeated 10 times to report the error bar. Both attacks and defenses are ranked by the weighted accuracy under 'F' difficulty, where red and blue indicate the best results of attacks/defenses in each difficulty. Note that the metric is not fixed and will be updated when there are more effective methods. For instance, when there are more powerful attacks, the ranking will change so as the attached weights. It is reasonable that less effective attacks become less important on the final ranking of defenses, the same for defenses. As a result, GRB leaderboard can indicate the most robust defenses and the most effective attacks.   Robust Ranking of GML Models. In Figure <ref type="figure" target="#fig_6">5</ref> and 6, we show the rankings of GML models for all five datasets in graph injection scenario. The ranking is determined by s DEF w calculated by multiple attacks, which makes the results more general than previous works (only consider very few attacks and vanilla GML models). We find that the rankings are different across datasets, indicating that the robustness is related to the properties of graph data. Similar situations can be found in other graph benchmarks. For example in OGB, there is no dominant GML model, the performance of certain model architecture may vary a lot across datasets. Thus, we suggest that when giving conclusions about robustness in GML, one should not only consider the model itself but also take the graph data into account. GRB provides scalable datasets of various domains, which can help to investigate the robustness of GML models in different situations. Among current vanilla GML models, we find that GAT and GIN generally perform better under attacks in several datasets, which might be due to the higher expressiveness of model architecture. Meanwhile, models like APPNP and SGCN that rely on high-order message propagation seem to be sensible to perturbations on the graph. Besides, GML models with defense mechanisms (i.e., R-GCN, GNNGuard) are generally more robust. Moreover, we find simple methods like LN can be applied to all GML models to increase robustness. In the following, we further analyze some factors that affect the adversarial robustness of GML models. Effect of Difficulties. The new splitting scheme investigates the effect of the average degree of target nodes on the attack performance. In Figure <ref type="figure" target="#fig_8">7</ref>, attacks tend to better decrease the performance on nodes with lower degrees, which confirms the assumption that these low-degree nodes are more vulnerable. Moreover, according to Figure <ref type="figure" target="#fig_6">5</ref> and 6, the robustness on these nodes is indeed harder to achieve. This phenomenon encourages future work to deal with these vulnerable nodes to design more robust GML models.  Effect of Constraints. As shown in Figure <ref type="figure" target="#fig_10">8 and 9</ref>, for both graph modification and graph injection scenarios, the variation of constraints on the ratio of modification/injection affects the effectiveness of attacks. Meanwhile, the ranking of methods nearly agrees with different constraints. Without loss of generality, it is reasonable to fix a specific constraint to build GRB leaderboards, where the relative robustness of GML models will still be indicative.</p><p>Effect of General Defenses. Figure <ref type="figure" target="#fig_11">10</ref> and 11 shows the results of the adapted LN and AT for all five datasets. LN is a node-wise normalization technique, which can alleviate the perturbations on node features as well as hidden features in each layer of GML models. AT applies adversarial attacks during training via modification or injection, which changes the decision boundary of models to tolerate perturbed nodes. The results indicate that these approaches can generally increase the robustness of various types of GML models, which can serve as simple but strong baselines for future works. The details of these algorithms can be found in Appendix A.4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>To improve and facilitate the evaluation of the adversarial robustness in GML, we revisit the limitations of previous works and present the Graph Robustness Benchmark (GRB), a scalable, unified, modular, and reproducible benchmark. It has scalable datasets, unified evaluation scenarios, as well as a  modular coding framework that ensures the reproducibility and promotes the development of future methods. Extensive experiments with GRB provide insights on the understanding of the adversarial robustness in GML. We welcome the community to contribute more advanced GML models, attacks and defenses to further enrich GRB and to promote the research of this field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Broader Impact</head><p>Positive Impact. GRB provides a general framework for GML attacks and defenses. On one hand, it will researchers to develop more robust GML models against attacks. On the other hand, it will also help possible attackers to develop better attack methods to turn down defenses. More public information of potential attacks will make it harder to conduct secret attacks based on private methods. As a result, more generally robust defense mechanisms can be designed.</p><p>Negative Impact. By exposing the attack methods widely, the GML models may face more threats. Attackers can use the benchmark to design destructive attacks that may cause damage to GML-based systems. Additionally, GRB has some limitations. For example, it only considers homogeneous graphs rather than heterogeneous ones for now. It focuses on node classification, while other tasks like link prediction and graph classification are also vulnerable. We will regularly update GRB (e.g., adding task-specific modules, designing related metrics.) to overcome these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Maintenance Plan</head><p>Open Source. We host the GRB homepage (https://cogdl.ai/grb/home) with detailed introduction, leaderboards, and documentations. The codes are available in (https://github.com/ THUDM/grb). All materials are accessible to ensure reproducibility.</p><p>Submissions of New Methods. GRB will regularly include SOTA methods by updating the "method zoo". To welcome the contribution of the community, we allow submissions through google form. There are detailed examples and rules that guide researchers to add new attacks or defenses. Results will be updated on leaderboards to track the progress of the domain.</p><p>Extension of Tasks. Due to the modular design, GRB can be extended to other tasks. It requires adding task-specific functions in each module (dataset, model, trainer, attack, defense, etc.). Other common functions in GML can be reused for different tasks. There are online examples (https: //github.com/THUDM/grb/tree/master/examples) showing how to use GRB for other tasks, e.g., graph classification. In the future, GRB will support more GML tasks and define related threat models and metrics to unify the evaluation of adversarial robustness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of GRB's attack vs. defense (graph injection) scenario: Black-box: attackers only have access to the attributed graph but not the target models; Inductive: target models are trained in an inductive setting (test nodes are unseen during training); Injection: attackers are allowed to inject new nodes without modifying the existing ones; Evasion: attacks happen during model inference. All attacks and defenses are evaluated under unified settings to be fairly compared.</figDesc><graphic url="image-1.png" coords="2,108.00,72.00,396.00,137.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: GRB Framework.</figDesc><graphic url="image-2.png" coords="4,306.00,119.79,198.00,128.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) Model: The GML models are implemented based on PyTorch, CogDL, and DGL and GRB can automatically transform inputs to compatible formats. (3) Attack: We implement adversarial attacks by abstracting the attack process to different components, e.g., graph injection attacks are decomposed to node injection and feature generation. (4) Defense: GRB engages defense mechanisms to GML models, including preprocess-based and model-based ones.<ref type="bibr" target="#b4">(5)</ref> Evaluator: The attack or defense methods are evaluated under unified settings and metrics. Essentially, GRB unifies and modularizes the entire process, including loading datasets, training/loading models, applying attacks/defenses, and generating the evaluation results; it also helps to reproduce the exact results on GRB leaderboards. In addition to these modules, GRB also offers other functions including Trainer for model training, AutoML for automatic parameter search, and Visualise for visualizing the attack process.The GRB framework has the following features: (1) Easy-to-use: the baseline methods are easy to use by only a few lines of codes, as shown in Figure3. (2) Fair-to-compare: all methods are fairly compared under unified settings. (3) Up-to-date: the leaderboards for each dataset are maintained to continuously track the progress in the domain. (4) Reproducible: GRB prioritizes reproducibility. All necessary materials are made public to reproduce results on leaderboards, including the trained models, generated attack results, etc. Users can reproduce results by a single command line (Cf. Appendix A.5 for GRB reproducibility rules). All codes are available in https://github.com/THUDM/grb, where the implementation details and examples can be also found. The API documentations are covered in https://grb.readthedocs.io/en/latest/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: GRB usage examples. Left: Train GCNs on the grb-cora dataset. Right: Apply the TDGIA attack on the trained model. GRB facilitates the usage of GML models, attacks,and defenses.</figDesc><graphic url="image-3.png" coords="6,108.00,72.00,395.98,150.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: GRB's splitting scheme. Difficulties are related to the average degree of test nodes.</figDesc><graphic url="image-4.png" coords="7,108.00,72.00,395.97,70.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>= n i=1 w i s i , w i = 1 /i 2 nj=1 ( 1 /j 2 )</head><label>1212</label><figDesc>) Avg. 3-Max: Average accuracy for the 3 most robust methods. (3) Weighted: Weighted accuracy, calculated by:s ATK w , s i = (S DEF descend ) i where S DEF descend is the set of defense scores in a descending order. The metric attaches more weight to more robust methods. For defenses: (1) Avg.: Average accuracy of all attacks. (2) Avg. 3-Min: Average accuracy of the 3 most effective attacks. (3) Weighted: Weighted accuracy across various attacks, calculated by:s DEF w = n i=1 w i s i , w i =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ranking of vanilla GML models in graph injection scenario for all five datasets.</figDesc><graphic url="image-5.png" coords="8,108.00,426.61,396.00,90.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Ranking of top 10 defensed GML models in graph injection scenario for all five datasets.</figDesc><graphic url="image-6.png" coords="8,108.00,550.60,395.98,95.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Effect of dataset difficulties on the performance of graph injection attacks.</figDesc><graphic url="image-7.png" coords="9,108.00,216.23,395.99,76.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Effect of constraints on GML models. Left: graph modification. Right: graph injection.</figDesc><graphic url="image-8.png" coords="9,108.00,390.65,194.04,85.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Effect of constraints on attacks. Left: graph modification. Right: graph injection.</figDesc><graphic url="image-9.png" coords="9,307.47,390.52,194.04,85.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Effect of the adapted LN on the adversarial robustness of vanilla GML models for all five datasets. Adding LN can generally increase robustness of GML models.</figDesc><graphic url="image-10.png" coords="10,108.00,72.00,396.02,72.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Effect of the adapted AT on the adversarial robustness of vanilla GML models for all five datasets. Adding AT can generally increase robustness of GML models.</figDesc><graphic url="image-11.png" coords="10,108.00,188.72,396.00,73.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A categorization of graph adversarial attacks. There are mainly two scenarios: graph modification and graph injection. GRB supports the implementation of all types of methods. †</figDesc><table><row><cell>Adversarial Attack</cell><cell>Knowledge Black. White. Poi. Eva. Mod. Inj. Objective Approach Scalability</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>the methods each other applied. (2) Inductive: The GML models are trained in trusted data and used to classify unseen data (e.g., new users), i.e., the validation and test data is unseen during training. (3) Evasion: Attacks will only happen during the inference phase. Furthermore, we clarify attackers' and defenders' capabilities in GRB:1. For attackers: (a) They have knowledge about the entire graph (including all nodes, edges and labels but excluding the labels of the test nodes), but do not have knowledge about the target model or defense mechanism. (b) For graph modification, following the most common setting in previous works, attackers are allowed to perturb a limited number of edges in the graph (∆ A : the number of modified edges less than a ratio γ e of all edges). (c) For graph injection, we follow the heuristic setting of KDDCUP 2020, attackers are allowed to inject new nodes with limited edges (∆ A : less than N n injected nodes each with less than N e edges; ∆ F : constrained range of features [F min , F max ].). (d) They are not allowed to modify the original graph for training. (e) They are allowed to get predictions from the target model through a limited number of queries.</figDesc><table /><note>1) Black-box: Both attackers and defenders do not have knowledge about</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of five GRB datasets covering from small-to large-scale graphs.</figDesc><table><row><cell>Dataset</cell><cell>Scale</cell><cell>#Nodes</cell><cell>#Edges</cell><cell cols="2">#Feat. #Classes</cell><cell>Feat. Range (original)</cell><cell>Feat. Range (normalized)</cell></row><row><cell>grb-cora</cell><cell>Small</cell><cell>2,680</cell><cell>5,148</cell><cell>302</cell><cell>7</cell><cell>[-2.30, 2.40]</cell><cell>[-0.94, 0.94]</cell></row><row><cell>grb-citeseer</cell><cell>Small</cell><cell>3,191</cell><cell>4,172</cell><cell>768</cell><cell>6</cell><cell>[-4.55, 1.67]</cell><cell>[-0.96, 0.89]</cell></row><row><cell>grb-flickr</cell><cell>Medium</cell><cell>89,250</cell><cell>449,878</cell><cell>500</cell><cell>7</cell><cell>[-0.90, 269.96]</cell><cell>[-0.47, 1.00]</cell></row><row><cell>grb-reddit</cell><cell>Large</cell><cell cols="2">232,965 11,606,919</cell><cell>602</cell><cell cols="2">41 [-28.19, 120.96]</cell><cell>[-0.98, 0.99]</cell></row><row><cell>grb-aminer</cell><cell>Large</cell><cell>659,574</cell><cell>2,878,577</cell><cell>100</cell><cell>18</cell><cell>[-1.74, 1.62]</cell><cell>[-0.93, 0.93]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>grb-aminer leaderboard (Top 5 ATK. vs. Top 10 DEF.) in graph injection scenario.</figDesc><table><row><cell></cell><cell cols="2">Defenses</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>Avg.</cell><cell>Avg. 3-Max</cell><cell>Weighted</cell></row><row><cell cols="2">Attacks</cell><cell></cell><cell>GAT+AT</cell><cell cols="2">R-GCN+AT SGCN+LN</cell><cell>R-GCN</cell><cell>GCN+LN</cell><cell>GATLN</cell><cell>GIN+LN</cell><cell cols="2">TAGCN+LN TAGCN+AT</cell><cell>GAT</cell><cell>Accuracy</cell><cell>Accuracy</cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.54±0.05 56.83±0.06 56.73±0.06 56.12±0.07 53.51±0.21 43.93±0.41 51.10±0.12</cell><cell>54.63±0.20</cell><cell>49.59±0.50</cell><cell cols="2">42.40±0.52 52.44±0.17</cell><cell>57.70±1.31</cell><cell>58.08±0.04</cell></row><row><cell>1</cell><cell>TDGIA</cell><cell cols="8">M 68.39±0.02 65.61±0.02 66.11±0.02 65.23±0.03 66.78±0.05 61.84±1.20 64.49±0.10 H 75.83±0.02 72.35±0.02 72.10±0.00 71.94±0.02 73.39±0.02 75.22±0.04 72.92±0.02</cell><cell>64.62±0.02 68.94±0.03</cell><cell>67.27±0.04 73.98±0.01</cell><cell cols="2">62.47±1.01 65.28±0.23 75.03±0.03 73.17±0.01</cell><cell>67.48±0.68 75.36±0.34</cell><cell>67.69±0.02 75.33±0.01</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.69±0.03 63.62±0.32 62.20±0.15 61.99±0.22 60.38±1.46 59.69±1.57 59.59±0.42</cell><cell>59.06±1.75</cell><cell>57.24±5.04</cell><cell cols="2">56.63±6.75 60.81±1.71</cell><cell>64.52±2.32</cell><cell>65.74±0.21</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.54±0.07 56.80±0.05 56.94±0.10 55.64±0.10 56.15±0.06 56.13±0.07 54.24±0.09</cell><cell>56.61±0.06</cell><cell>56.59±0.08</cell><cell cols="2">57.36±0.09 56.60±0.04</cell><cell>57.95±1.14</cell><cell>58.62±0.05</cell></row><row><cell>2</cell><cell>SPEIT</cell><cell cols="8">M 68.37±0.03 65.46±0.03 66.20±0.02 65.25±0.05 66.75±0.03 67.49±0.06 65.05±0.06 H 75.94±0.04 72.27±0.03 72.36±0.03 71.86±0.03 73.41±0.01 75.34±0.03 72.87±0.03</cell><cell>64.47±0.04 68.88±0.05</cell><cell>66.95±0.05 73.98±0.02</cell><cell cols="2">66.81±0.04 66.28±0.02 73.83±0.04 73.07±0.01</cell><cell>67.60±0.59 75.08±0.82</cell><cell>67.86±0.03 75.33±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.04±0.03 64.05±0.04 64.84±0.04 64.06±0.04 65.51±0.02 64.02±0.04 63.11±0.02</cell><cell>62.59±0.04</cell><cell>63.77±0.06</cell><cell cols="2">63.58±0.06 64.36±0.02</cell><cell>66.13±1.38</cell><cell>66.89±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.56±0.06 57.53±0.06 57.41±0.06 56.38±0.11 57.76±0.05 58.83±0.10 54.41±0.13</cell><cell>58.07±0.12</cell><cell>58.14±0.04</cell><cell cols="2">57.46±0.10 57.55±0.03</cell><cell>58.85±0.57</cell><cell>59.09±0.05</cell></row><row><cell>3</cell><cell>RND</cell><cell cols="8">M 68.22±0.04 65.86±0.03 66.29±0.03 65.34±0.06 67.03±0.03 68.62±0.05 65.54±0.06 H 75.75±0.02 72.66±0.02 72.42±0.03 72.00±0.03 73.52±0.02 75.63±0.03 73.36±0.03</cell><cell>64.98±0.08 69.30±0.06</cell><cell>67.34±0.04 74.04±0.02</cell><cell cols="2">67.71±0.06 66.69±0.02 75.36±0.03 73.40±0.01</cell><cell>68.18±0.38 75.58±0.17</cell><cell>68.24±0.03 75.39±0.01</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.72±0.04 64.98±0.02 65.31±0.04 64.45±0.04 66.17±0.02 67.54±0.04 64.36±0.06</cell><cell>64.33±0.03</cell><cell>66.42±0.03</cell><cell cols="2">66.23±0.04 65.75±0.02</cell><cell>67.23±0.58</cell><cell>67.34±0.03</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.70±0.06 57.71±0.05 57.73±0.09 57.19±0.07 57.60±0.08 57.05±0.17 54.69±0.09</cell><cell>58.18±0.07</cell><cell>58.27±0.09</cell><cell cols="2">58.46±0.11 57.66±0.05</cell><cell>58.81±0.64</cell><cell>59.14±0.05</cell></row><row><cell>4</cell><cell>PGD</cell><cell cols="8">M 68.40±0.05 66.12±0.02 66.39±0.04 65.67±0.04 67.04±0.03 68.24±0.04 65.64±0.08 H 75.83±0.03 72.91±0.02 72.47±0.04 72.18±0.05 73.52±0.02 75.55±0.05 73.58±0.04</cell><cell>65.17±0.05 69.64±0.05</cell><cell>67.32±0.03 73.89±0.02</cell><cell cols="2">67.85±0.05 66.78±0.02 74.34±0.04 73.39±0.01</cell><cell>68.16±0.23 75.24±0.65</cell><cell>68.12±0.03 75.36±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.01±0.02 65.41±0.01 65.54±0.03 65.05±0.03 66.22±0.02 66.49±0.04 64.63±0.04</cell><cell>64.82±0.04</cell><cell>66.32±0.02</cell><cell cols="2">66.14±0.04 65.86±0.01</cell><cell>66.94±0.76</cell><cell>67.37±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.71±0.05 57.69±0.08 57.62±0.06 57.16±0.08 57.60±0.06 56.97±0.09 54.67±0.08</cell><cell>58.20±0.10</cell><cell>58.23±0.06</cell><cell cols="2">58.46±0.07 57.63±0.05</cell><cell>58.81±0.65</cell><cell>59.15±0.04</cell></row><row><cell>5</cell><cell>FGSM</cell><cell cols="8">M 68.37±0.02 66.10±0.03 66.38±0.04 65.70±0.05 67.03±0.04 68.27±0.04 65.61±0.08 H 75.82±0.02 72.92±0.04 72.48±0.03 72.18±0.05 73.52±0.02 75.55±0.05 73.60±0.04</cell><cell>65.16±0.05 69.64±0.04</cell><cell>67.30±0.02 73.90±0.01</cell><cell cols="2">67.84±0.07 66.78±0.02 74.34±0.04 73.39±0.01</cell><cell>68.16±0.23 75.23±0.65</cell><cell>68.11±0.02 75.35±0.02</cell></row><row><cell></cell><cell></cell><cell cols="8">F 68.00±0.02 65.41±0.02 65.54±0.04 65.05±0.04 66.22±0.02 66.50±0.06 64.65±0.04</cell><cell>64.82±0.03</cell><cell>66.34±0.03</cell><cell cols="2">66.15±0.06 65.87±0.01</cell><cell>66.95±0.75</cell><cell>67.37±0.01</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.67±0.00 58.08±0.00 60.22±0.00 58.53±0.00 58.14±0.00 60.78±0.00 56.83±0.00</cell><cell>59.47±0.00</cell><cell>59.62±0.00</cell><cell cols="2">59.88±0.00 59.12±0.00</cell><cell>60.29±0.37</cell><cell>60.42±0.00</cell></row><row><cell cols="2">6 W/O Attack</cell><cell cols="8">M 68.28±0.00 66.14±0.00 67.11±0.00 66.35±0.00 67.00±0.00 68.98±0.00 66.26±0.00 H 75.85±0.00 73.05±0.00 72.69±0.00 72.66±0.00 73.46±0.00 75.64±0.00 73.69±0.00</cell><cell>65.41±0.00 69.84±0.00</cell><cell>67.53±0.00 74.10±0.00</cell><cell cols="2">68.41±0.00 67.15±0.00 75.76±0.00 73.67±0.00</cell><cell>68.56±0.30 75.75±0.09</cell><cell>68.59±0.00 75.52±0.00</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.93±0.00 65.76±0.00 66.68±0.00 65.85±0.00 66.20±0.00 68.47±0.00 65.59±0.00</cell><cell>64.91±0.00</cell><cell>67.08±0.00</cell><cell cols="2">68.02±0.00 66.65±0.00</cell><cell>68.14±0.24</cell><cell>68.11±0.00</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.62±0.02 57.44±0.03 57.77±0.03 56.84±0.04 56.79±0.04 55.62±0.06 54.33±0.04</cell><cell>57.53±0.05</cell><cell>56.74±0.09</cell><cell>55.67±0.10</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg.</cell><cell cols="8">M 68.34±0.01 65.88±0.01 66.41±0.01 65.59±0.02 66.94±0.02 67.24±0.19 65.43±0.03</cell><cell>64.97±0.02</cell><cell>67.28±0.01</cell><cell>66.85±0.18</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="8">H 75.84±0.01 72.69±0.01 72.42±0.01 72.14±0.02 73.47±0.01 75.49±0.01 73.33±0.02</cell><cell>69.38±0.02</cell><cell>73.98±0.00</cell><cell>74.78±0.02</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.90±0.01 64.87±0.05 65.02±0.03 64.41±0.04 65.12±0.25 65.45±0.26 63.65±0.07</cell><cell>63.42±0.29</cell><cell>64.53±0.84</cell><cell>64.46±1.13</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.55±0.03 57.05±0.04 57.02±0.03 56.05±0.07 55.73±0.07 52.33±0.12 53.25±0.07</cell><cell>56.43±0.07</cell><cell>54.77±0.16</cell><cell>52.41±0.17</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Avg. 3-Min</cell><cell cols="8">M 68.28±0.01 65.64±0.02 66.20±0.01 65.28±0.03 66.84±0.02 65.85±0.40 65.02±0.04</cell><cell>64.69±0.03</cell><cell>67.17±0.02</cell><cell>65.66±0.34</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="8">H 75.80±0.02 72.42±0.02 72.29±0.01 71.93±0.02 73.42±0.01 75.36±0.02 73.05±0.02</cell><cell>69.04±0.03</cell><cell>73.92±0.01</cell><cell>74.17±0.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.78±0.02 64.22±0.11 64.12±0.06 63.50±0.08 64.02±0.49 63.39±0.53 62.35±0.14</cell><cell>61.99±0.58</cell><cell>62.44±1.69</cell><cell>62.11±2.26</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="8">E 59.53±0.04 56.93±0.04 56.94±0.04 55.93±0.08 54.63±0.14 48.21±0.27 52.23±0.08</cell><cell>55.55±0.14</cell><cell>52.18±0.33</cell><cell>47.45±0.35</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Weighted</cell><cell cols="8">M 68.25±0.02 65.57±0.02 66.17±0.02 65.28±0.02 66.79±0.02 63.85±0.80 64.77±0.07</cell><cell>64.60±0.03</cell><cell>67.06±0.03</cell><cell>64.07±0.68</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="8">H 75.78±0.02 72.37±0.02 72.20±0.01 71.92±0.03 73.41±0.01 75.30±0.02 72.98±0.02</cell><cell>68.99±0.04</cell><cell>73.91±0.01</cell><cell>74.08±0.03</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell cols="8">F 67.73±0.03 63.96±0.21 63.19±0.10 62.80±0.15 62.18±0.98 61.58±1.05 61.00±0.28</cell><cell>60.54±1.18</cell><cell>59.82±3.38</cell><cell>59.37±4.53</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">† https://www.biendata.xyz/competition/kddcup_2020_formal/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deepwalk: online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 20th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<editor>
			<persName><forename type="first">A</forename><surname>Sofus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Claudia</forename><surname>Macskassy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jure</forename><surname>Perlich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wei</forename><surname>Leskovec</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rayid</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ghani</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<editor>
			<persName><forename type="first">Balaji</forename><surname>Krishnapuram</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mohak</forename><surname>Shah</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dou</forename><surname>Aggarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rajeev</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><surname>Rastogi</surname></persName>
		</editor>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (WSDM)</title>
				<meeting>the Eleventh ACM International Conference on Web Search and Data Mining (WSDM)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="459" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Predict then propagate: Graph neural networks meet personalized pagerank</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amauri</forename><forename type="middle">H</forename><surname>Souza</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (ICML)</title>
				<meeting>the 36th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pong</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast gradient attack on network embedding</title>
		<author>
			<persName><forename type="first">Jinyin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Xuan</surname></persName>
		</author>
		<idno>abs/1809.02797</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial attacks on graph neural networks via meta learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Attacking graph convolutional networks via rewiring</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Derr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906">1906.03750, 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial attacks on graph neural networks via node injections: A hierarchical reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yu</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasant</forename><forename type="middle">G</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Web Conference 2020 (WWW)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="673" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Scalable attack on graph data by injecting vicious nodes</title>
		<author>
			<persName><forename type="first">Jihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minnan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fnu</forename><surname>Suya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinghua</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004.13825. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">KDD CUP 2020 ML Track 2 Adversarial Attacks and Defense on Academic Graph 1st Place Solution</title>
		<author>
			<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixiao</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingmin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minhao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibo</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="https://github.com/" />
		<imprint>
			<date type="published" when="2020">Stanislas0/KDD_CUP_2020_MLTrack2_SPEIT, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tdgia: Effective injection attacks on graph neural networks</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Kharlamov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hiding individuals and communities in a social network</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Waniek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tomasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Talal</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName><surname>Rahwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="147" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Topology adaptive graph convolutional networks</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José Mf</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soummya</forename><surname>Kar</surname></persName>
		</author>
		<idno>abs/1710.10370</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust graph convolutional networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Dingyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1399" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graph random neural networks for semi-supervised learning on graphs</title>
		<author>
			<persName><forename type="first">Wenzheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Kharlamov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33th Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graph structure learning for robust graph neural networks</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</title>
				<editor>
			<persName><forename type="first">Rajesh</forename><surname>Gupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">Aditya</forename><surname>Prakash</surname></persName>
		</editor>
		<meeting>the 26th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">All you need is low (rank): Defending against adversarial attacks on graphs</title>
		<author>
			<persName><forename type="first">Negin</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saba</forename><forename type="middle">A</forename><surname>Al-Sayouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Darvishzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirteenth ACM International Conference on Web Search and Data Mining (WSDM)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Gnnguard: Defending graph neural networks against adversarial attacks</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006.08149, 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Open graph benchmark: Datasets for machine learning on graphs</title>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33th Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Benchmarking graph neural networks</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Prakash Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<idno>abs/2003.00982</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Deeprobust: A pytorch library for adversarial attacks and defenses</title>
		<author>
			<persName><forename type="first">Yaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<idno>abs/2005.06149</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adversarial attacks on node embeddings via graph poisoning</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (ICML), volume 97 of Proceedings of Machine Learning Research</title>
				<meeting>the 36th International Conference on Machine Learning (ICML), volume 97 of Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="695" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adversarial attack on graph structured data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1123" to="1132" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Query-free black-box adversarial attacks on graphs</title>
		<author>
			<persName><forename type="first">Jiarong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangang</forename><surname>Lu</surname></persName>
		</author>
		<idno>abs/2012.06757</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adversarial examples on graph data: Deep insights into attack and defense</title>
		<author>
			<persName><forename type="first">Huijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuriy</forename><surname>Tyshetskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Docherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liming</forename><surname>Zhu</surname></persName>
		</author>
		<idno>abs/1903.01610</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph adversarial training: Dynamically regularizing based on graph structure</title>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">La cryptographie militaire</title>
		<author>
			<persName><forename type="first">Auguste</forename><surname>Kerckhoffs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1883">1883</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Köpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32th Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Cogdl: An extensive toolkit for deep learning on graphs</title>
		<author>
			<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiguang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Dai</surname></persName>
		</author>
		<idno>preprint, abs/2103.00959</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Deep graph library: Towards efficient and scalable deep learning on graphs</title>
		<author>
			<persName><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mufei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lei Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Ryan Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>abs/1607.06450</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Dimensional reweighting graph convolution networks</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuye</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Graphsaint: Graph sampling based inductive learning method</title>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajitesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajgopal</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><forename type="middle">K</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Revisiting semi-supervised learning with graph embeddings</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning (ICML)</title>
				<meeting>the 33nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
				<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The numpy array: a structure for efficient numerical computation</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Colbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gael</forename><surname>Varoquaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in science &amp; engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">On evaluating adversarial robustness</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<idno>abs/1902.06705</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Benchmarking adversarial robustness on image classification</title>
		<author>
			<persName><forename type="first">Yinpeng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi-An</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="318" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Robustbench: a standardized adversarial robustness benchmark</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Croce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikash</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Flammarion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mung</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<idno>abs/2010.09670</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust graph representation learning via neural sparsification</title>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingchao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenchao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
