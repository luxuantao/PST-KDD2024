<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Applying Informed Coding and Embedding to Design a Robust High-Capacity Watermark</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Matt</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gwenaël</forename><forename type="middle">J</forename><surname>Doërr</surname></persName>
							<email>doerr@eurecom.fr</email>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Ingemar</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
							<email>ingemar@ieee.org</email>
						</author>
						<author>
							<persName><roleName>Dr</roleName><forename type="first">Jean-Luc</forename><forename type="middle">M L</forename><surname>Dugelay</surname></persName>
						</author>
						<author>
							<persName><surname>Miller</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">NEC Research Institute</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Eurécom Institute</orgName>
								<address>
									<settlement>Sophia-Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">NEC Research Institute</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Departments of Computer Science and Electronic and Electrical Engineering</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<postCode>WC1E 7JE</postCode>
									<settlement>London</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Applying Informed Coding and Embedding to Design a Robust High-Capacity Watermark</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">606B206CEB13C19D41390AE73FFD65B9</idno>
					<idno type="DOI">10.1109/TIP.2003.821551</idno>
					<note type="submission">received October 15, 2001; revised May 14, 2003.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dirty-paper code</term>
					<term>high capacity</term>
					<term>informed coding</term>
					<term>informed embedding</term>
					<term>perceptual shaping</term>
					<term>robustness</term>
					<term>watermarking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a new watermarking system based on the principles of informed coding and informed embedding. This system is capable of embedding 1380 bits of information in images with dimensions 240 368 pixels. Experiments on 2000 images indicate the watermarks are robust to significant valumetric distortions, including additive noise, low-pass filtering, changes in contrast, and lossy compression. Our system encodes watermark messages with a modified trellis code in which a given message may be represented by a variety of different signals, with the embedded signal selected according to the cover image. The signal is embedded by an iterative method that seeks to ensure the message will not be confused with other messages, even after addition of noise. Fidelity is improved by the incorporation of perceptual shaping into the embedding process. We show that each of these three components improves performance substantially.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>they exhibit only limited robustness against simple valumetric scaling, such as changes in image contrast or audio volume.</p><p>In this paper, we develop an algorithm for embedding of robust image watermarks with large data payloads using informed embedding and coding techniques.</p><p>We begin, in Section II, by describing an informed embedding algorithm. Experimental results indicate that this algorithm can embed trellis-coded, 1380-bit watermarks into 240 368 images with acceptable effectiveness. By contrast, in the same context, a simple blind embedder, using the same code and fidelity, almost always fails to embed these watermarks.</p><p>Section III then proceeds to develop a method of informed coding based on a simple modification of a trellis code. When combined with our informed embedding algorithm, this results in a further substantial increase in effectiveness. Unfortunately, images watermarked with these methods exhibit an unacceptable loss of fidelity.</p><p>The fidelity problem is reduced in Section IV, where we incorporate perceptual shaping, based on Watson's perceptual distance measure <ref type="bibr" target="#b22">[23]</ref>. This reduces the perceptual distance between watermarked and unmarked images by a factor of three, as measured by Watson's model, without substantially changing effectiveness or robustness.</p><p>Section V presents several experiments showing that, even after rather severe addition of noise, filtering, valumetric scaling, or lossy compression, all 1380 bits are correctly detected in at least 80% of watermarked images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. INFORMED EMBEDDING</head><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the basic idea of informed embedding. Here, we view watermark embedding as a three-step process. First, the message to be embedded is encoded as a signal, . Second, the signal is modified in preparation for embedding, yielding a modified signal . Finally, the modified signal is added to the cover image, , to obtain the watermarked image, . In blind embedding, the modification step is performed independently of the cover image; it is usually just a simple, global scaling. In informed embedding, by contrast, the modification is a function of the image and the message signal.</p><p>Since complete information about the cover image is available, an informed embedder has complete control over the final, watermarked image. That is, it can select any image as by letting . The task is to find an image that satisfies two conflicting criteria: <ref type="bibr" target="#b0">1)</ref> should be similar enough to to be perceptually indistinguishable and 2) should be close enough to to be detected as containing the watermark, even after distortion by subsequent processing.</p><p>In practice, an informed embedding algorithm can be implemented using methods for estimating perceptual distance and watermark robustness. The algorithm may then attempt to either:</p><p>1) maximize the estimated robustness while keeping a constant perceptual distance; 2) minimize the perceptual distance while keeping a constant robustness. We believe that most watermarking applications are best served by embedders that maintain constant robustness, and our proposed algorithm is, therefore, designed using the second constraint.</p><p>In order to describe the watermark embedding algorithm, we first describe the detection algorithm in Section II-A. In Section II-B, we then define a measure of robustness. Sections II-C and II-D describe two embedding methods that seek to obtain a specific value of this robustness measure while keeping the mean squared error low between the original and watermarked Works. The first of these two methods is general, and can be applied with a variety of different detection algorithms. The second is specific to the detector described in Section II-A, and is substantially faster than the general method. Section II-E describes an experiment showing that this second embedding method yields substantially better results than a simple blind embedder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Detection Algorithm</head><p>Our watermarking system is built around a trellis-code, as illustrated in Fig. <ref type="figure">2</ref>. This code is similar to that used in the E_TRELLIS8/D_TRELLIS8 watermarking system of <ref type="bibr" target="#b6">[7]</ref>. Each path through this trellis, originating at node A0, represents a specific message. Since two arcs exit each node, there are possible paths, where is the length of the paths. Thus, the system encodes bits. In our experiments, . Each arc in the trellis is labeled with a randomly generated, length reference vector. In principle, these labels can be arbitrary, but for efficiency we use the same set of labels in each step of the trellis. Thus, for example, the label for the arc from node A0-A1 has the same label as the arc from node A1-A2, and so on. Each path, and thus each message, is coded with a length vector that is the concatenation of the labels for the arcs it contains. In our experiments, . Note that the paths for two different messages always differ in at least four arcs. To see this, consider one message that is encoded with the path connecting all the A nodes (A0, A1, etc.), and another message in which the first arc is from A0 to B1. The shortest way that this second message path can get back to Fig. <ref type="figure">2</ref>. Simple, 8-state trellis. Each possible message corresponds to a path from node A0 (state A at time 0) to one of the nodes at the right (any state at time L). We refer to the transition from one column of nodes to the next column of nodes as a step, and each such step corresponds to one bit in the coded message. A bold arc is traversed if the corresponding bit is a 1, a nonbold arc is traversed if the corresponding bit is a 0. state A takes three additional steps: B1-C2, C2-E3, and E3-A4. Thereafter, the rest of the path can be identical to that for the first message. Thus, these two messages differ in at least four arcs. A little reflection will show that all pairs of messages are similarly distinct. This means that, even if two messages differ in only a single bit, their representations will differ substantially, and they will be unlikely to be confused as a result of added noise.</p><p>The detection algorithm proceeds as follows.</p><p>1) Convert the image into the 8 8 block-DCT domain. 2) Place all the low-frequency ac terms of the blocks into a single, length vector, in random order. We refer to this as the extracted vector. The discrete cosine transform (DCT) terms used are shown in Fig. <ref type="figure" target="#fig_1">3</ref>. 3) Use a Viterbi decoder <ref type="bibr" target="#b20">[21]</ref> to identify the path through the trellis whose vector has the highest correlation with the extracted vector. 4) Identify the message that is represented by the highest correlation path.</p><p>Note that this detection algorithm does not attempt to determine whether or not the image contains a watermark. It simply maps every possible image into an -bit message, regardless of whether the image has had a watermark embedded. In large payload applications it is usually not important for the detector to determine whether a watermark is present, since most combinations of bit values are not meaningful. For example, suppose we use our system to embed strings of 172 ascii characters. An unwatermarked image will yield an unintelligible string, so we can easily recognize it as unwatermarked when the string is displayed.</p><p>Alternatively, if we need the detector to determine presence of watermarks, we can use some number of bits to contain an error detection checksum or signature of the message. If the signature does not match the message, the detector announces that there is no watermark. This reduces the payload by a small amount, but it yields a detector with an easily predicted false positive probability-if we use, say, 20 bits for the signature, then the probability of a false positive is <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Estimate of Robustness</head><p>In <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b12">[13]</ref>, we defined an estimate of robustness suitable for small-payload watermarking systems that use correlation coefficient to test whether or not a mark is present. This was based on the amount of additive white Gaussian noise that could be added to a watermarked image before it is expected to fall outside the detection region. Since the present detector does not use correlation coefficient, or test for the presence of a watermark, this measure of robustness is not appropriate. Instead of estimating the likelihood that a watermarked image will be detected as unwatermarked, we need to estimate the likelihood that it will be detected as containing the wrong message.</p><p>To develop our new robustness measure, consider a simple system in which there are only two possible messages, represented by two different vectors. We shall denote one of the vectors , and the other . When presented with an image, , the detector returns the message associated with if</p><p>, where is the correlation between and .</p><p>Suppose we wish to embed into an image (so is the "good" vector-the one we want to embed-and is a "bad" vector-one we do not want the watermarked image to be confused with). Our task is to estimate the chances that a proposed watermarked image will, after corruption by subsequent processing, be detected as containing the message rather than the message . More precisely, we need a value that is monotonically related to the probability that message will be correctly detected in a corrupted version of the watermarked Work, . As in <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b12">[13]</ref>, we proceed by assuming that the distortions applied to the Work after watermark embedding can be modeled as the addition of white Gaussian noise. 1 Thus, we assume that the detector will receive , where is a length vector whose elements are drawn independently</p><p>1 See <ref type="bibr" target="#b6">[7]</ref> for a justification of this assumption. from a Gaussian distribution with variance . The probability that will be detected in is <ref type="bibr" target="#b0">(1)</ref> where is a random scalar value drawn from a unit-variance, Gaussian distribution. Clearly, the larger the value of (2) the higher the probability that it will be greater than . Thus, the larger is, the greater the chances that the watermark will be correctly detected in . , then, can serve as our robustness measure for a simple, two-message watermarking system.</p><p>To extend this measure to larger payloads, we take the minimum of over all possible erroneous message vectors, . Thus </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. General Embedding Algorithm</head><p>In practice, it is difficult to implement an algorithm to find the optimal watermarked image, as illustrated in Fig. <ref type="figure" target="#fig_2">4</ref>. Instead, we use a suboptimal, iterative algorithm. Here we present a general version of this algorithm that can be used with a wide variety of watermark coding schemes. We first present a basic outline of the algorithm that is independent of the specific definition of . We then present a practical, Monte Carlo version of the algorithm, that relies on being a measure of robustness against white noise. A version specifically designed for the trellis-coded watermarks we have implemented is presented in Section II-D.</p><p>We assume that we have a black-box watermark encoder that maps a sequence of bits into a watermark signal . We further have a black-box watermark detector, , that maps an image, , into the sequence of bits corresponding to the watermark signal with which the image has the highest correlation. We make no assumptions about how these two functions work internally.</p><p>We now give the basic outline of the iterative embedding algorithm. Given a cover image , a message to embed , and a target robustness value [i.e., a target value for from (3)], the algorithm proceeds as follows.</p><p>1) Let and . 2) Find the signal that minimizes .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) If</head><p>, then terminate. 4) Otherwise, modify so that , and go to step 2).</p><p>The modification of in step 4) is performed as follows:</p><p>(4)</p><p>The new yields exactly equal to , while having a minimum Euclidian distance from the previous .</p><p>The operation of this algorithm is shown geometrically in Fig. <ref type="figure">5</ref>. In the first iteration, lies in the detection region for , so in step 2), and is moved to a point beyond the boundary between and . In the second iteration, , and is moved into the detection region for . In the final iteration, the closest bad vector is still , but is already satisfactory, so the algorithm terminates. The figure clearly illustrates that this algorithm is suboptimal, since it does not yield the optimal point identified in Fig. <ref type="figure" target="#fig_2">4</ref>. Nevertheless, it is practical to implement.</p><p>The identification of in step 2) depends on the method of coding. For most codes, it is not easy. We therefore apply a Fig. <ref type="figure">5</ref>. Geometric interpretation of a sub-optimal, iterative method for informed embedding. In each iteration, the cover image is modified to prevent it from being decoded as one "bad" vector. In this illustration, the first iteration modifies c so that it will not be detected as containing message b (even after addition of some noise). The second iteration modifies it so it will not be detected as containing b . This results in a watermarked image c within the embedding region around g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>simple, Monte Carlo approach by letting</head><p>, where is some random noise. If a small amount of noise is added to , and the detector returns a message other than , then is likely to yield a low value of . If there exist any vectors that yield values of below the target value , then is likely to be one of them. The best amount of noise to add changes as the embedding process progresses. In the first iteration, when , it is unlikely that , so we need not add any noise at all to find the nearest bad vector. This will remain true through several iterations, until . At that point, the closest bad vectors are likely to yield very low values of , so we need add only a small amount of noise to find them. As is modified to be robust against confusion with these vectors, the remaining vectors yield higher values of , and thus require the addition of more noise. In general, if too little noise is added, will equal . If too much noise is added, has a high chance of producing a vector for which is much larger than the minimum available value. We therefore dynamically adjust the amount of noise added in each iteration. At the beginning, the standard deviation of the noise, , is 0, so no noise is added. Whenever yields , we increase by a small, fixed amount, . When yields a bad vector, , but is greater than or equal to , we decrease by . If yields a bad vector , and , we modify and leave unchanged. In our experiments, . Since this Monte Carlo approach does not guarantee that we find the that minimizes in each iteration, we cannot terminate the algorithm the first time that is greater than or equal to the target value-there might still be some other for which . We therefore maintain a count of the number of consecutive 's found for which . The algorithm terminates when this count reaches a specified limit. In our experiments, the limit was set at 100. Thus, the complete, general version of our informed embedding algorithm proceeds as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Let</head><p>, , , and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Let</head><p>, where is a random vector with each element drawn independently from a Gaussian distribution with variance .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) If</head><p>, let and go back to step 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) If</head><p>, then modify according to (4), reset to 0, and go back to step 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) If</head><p>, then increment . If , then let and go back to step 2). Otherwise, terminate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Specific Embedding Algorithm for Trellis-Codes</head><p>The general method outlined above is very slow, as it can often take many thousands of iterations to terminate. When implemented with our trellis-coded watermarking system, each iteration requires running the Viterbi decoder on the entire extracted vector (sequence of low-frequency DCT coefficients). This, in turn, requires performing length correlations, where is the number of arcs in each step of the trellis.</p><p>Thus, instead of adding noise to and running the detector in each iteration, we use a modified version of the Viterbi decoder that produces probabalistic results. Normally, the Viterbi algorithm maintains a table that indicates the correlation between the extracted vector, , and the vectors for the paths up to all the states in a given step of the trellis (see <ref type="bibr" target="#b6">[7]</ref> for a description of the Viterbi algorithm in these terms). Our modified decoder adds a random number to each value in this table before proceeding to the next step of the trellis. This means that the decoder might return a path other than the one that yields the highest correlation with .</p><p>The behavior of the modified Viterbi decoder is similar to the results of adding noise to before running the detector, but it is not identical. Nevertheless, in informal tests, we found the performance of our informed embedder to be unaffected by the difference. By using the modified Viterbi decoder, we can significantly reduce running time because the correlations for the arcs of the trellis need not be recomputed every time the detector is used. Instead, they need only be recomputed when is modified. As each of these correlations compares two lengthvectors, eliminating these operations reduces the running time by almost a factor of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Performance</head><p>To examine the effectiveness of the informed embedding algorithm described here, we used it to embed 1380-bit watermarks into two thousand, 240 368-pixel images. We then applied the detector to them, with no intervening processing, and measured the number of message errors (i.e., the number of times that at least one of the 1380 bits was incorrectly detected). In theory, the algorithm should be 100% effective [0% message error rate (MER)], since it does not terminate before . However, our implementation operates on the extracted vector, rather than on the image itself. That is, we begin by extracting a vector from the block DCT of in the same manner as the detector. We then use the embedding algorithm to modify this vector so that it has the desired message embedded. Finally, we put the elements of the modified vector back into their respective DCT coefficients, and convert the image back to the spatial domain. This is mathematically equivalent to applying the embedding algorithm to the entire image, but round-off and clipping introduce the possibility of subsequent decoding errors. Fig. <ref type="figure" target="#fig_4">6</ref> shows the original cover image.</p><p>For purposes of comparison, we also implemented a simple, blind embedding algorithm. This used the same watermark extraction process (same DCT coefficients and ordering), data payload, and trellis code, as the informed embedder. However, in the blind embedder, the watermarked image was computed as , where is a constant controlling the embedding strength. We chose to produce roughly the same fidelity impact as that produced by the informed embedding algorithm. The degradation in fidelity was measured using Watson's model ( <ref type="bibr" target="#b22">[23]</ref>). The results of both experiments are shown in Table <ref type="table" target="#tab_0">I</ref>.</p><p>Clearly, for the same average fidelity impact, our informed embedder is far more effective than blind embedding. However, it must be noted that the perceptual impact of the algorithm is unacceptable, as measured by Watson's model and illustrated in Fig. <ref type="figure" target="#fig_5">7</ref>. This problem is dealt with in Sections III-V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. INFORMED CODING</head><p>The embedding algorithm of the Sections II uses information contained in the cover image during the modification stage.  However, each message is represented by a unique codeword that is independent of the image. Research in communications with side-information at the embedder suggests that better results can be obtained if the coding process itself is a function of the cover image. Therefore, we now consider informed coding, in which each message is mapped into a set of alternative codewords and the choice of which codeword to embed is determined by information contained in the cover image. This is illustrated in Fig. <ref type="figure" target="#fig_6">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dirty-Paper Codes</head><p>The use of informed coding in watermarking was inspired by the results of Costa <ref type="bibr" target="#b5">[6]</ref>. Costa studied the capacity of a communications channel that consists of two additive white-Gaussiannoise sources, the first of which is perfectly known to the transmitter, while the receiver has no knowledge of either (see Fig. <ref type="figure" target="#fig_7">9</ref>).</p><p>He described this channel using the analogy of writing on dirty paper. Imagine a sheet of paper covered with a Normally-distributed pattern of "dirt." This dirt is the first noise source, which the transmitter can examine. The transmitter writes a message on this paper and sends it to a receiver. Along the way, the paper may acquire a second layer of "dirt," corresponding to the second noise source. The receiver cannot distinguish between dirt and the ink used to write the message. Surprisingly, Costa showed that the first noise source-the dirty paper-has no effect on channel capacity. His proof of this relied on the use of a code book in which each message can be represented by a variety of alternative signals. In reference to his analogy, we refer to such a code book as a dirty-paper code <ref type="bibr" target="#b11">[12]</ref>. <ref type="foot" target="#foot_0">2</ref>In using a dirty-paper code, , to transmit a message, , the transmitter performs the following steps.</p><p>1) Identify a coset of the code book associated with the message . 2) Search through to find the code signal that is closest to the signal which will be added by the first noise source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Transmit</head><p>, where is a function that is analogous to informed embedding. In Costa's construction,</p><p>, where is a constant. To decode a received signal. using a dirty paper code , the receiver performs the following steps.</p><p>1) Search the entire codebook for the closest code signal .</p><p>2) Identify the coset that contains and report reception of the message associated with that subset. According to Moulin and O'Sullivan <ref type="bibr" target="#b13">[14]</ref>, Costa's work was first brought to the attention of the watermarking community by Chen, who realized that the cover image can be considered to be a noise source that is perfectly known to the watermark encoder (dirty paper). The implication of Costa's analysis to watermarking is substantial-it implies that the channel capacity of a watermarking system is independent of the cover image. More recently, Moulin and O'Sullivan <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>extended Costa's analysis to more realistic models of watermarking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Practical Dirty-Paper Codes</head><p>Unfortunately, Costa's research does not provide a practical solution to designing a dirty-paper code. His work was based on the use of random codes, and did not address the practical problem of efficient search. With random dirty-paper codes and exhaustive search, it is only possible to implement watermarks with very limited payloads (see, for example, the system studied in <ref type="bibr" target="#b11">[12]</ref>). Thus, it is neccessary to introduce a structured code that allows for more efficient searches. A number of such codes have been proposed for watermarking.</p><p>Dither index modulation, proposed by Chen and Wornell <ref type="bibr" target="#b0">[1]</ref>, uses a lattice code, i.e., a code in which each code signal is a point on a regular -dimensional lattice, where is the dimension of the coding space. Different messages are represented with sublattices and finding the nearest code signal is simply a matter of quantization.</p><p>While most dither index modulation codes are very simple to implement, and allow for large payloads, they suffer some inherent problems. One problem is that rectilinear lattices are known to produce inefficient codes in high dimension, meaning that the payloads are not as large as possible for the robustness achieved. This can be solved by using more efficient lattices, such as can be found in <ref type="bibr" target="#b4">[5]</ref>, at the expense of complicating the implementation.</p><p>Another problem is that lattice codes are not robust to scaling in the coding space. This means that, if coding space is a linear projection of pixel space, image watermarks will not be robust to changes in contrast. Some nonlinear coding spaces have been proposed <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b15">[16]</ref>, but few experimental results with these spaces have been reported.</p><p>An alternative approach to designing structured codes is based on syndrome coding, proposed by <ref type="bibr" target="#b16">[17]</ref> and applied to watermarking in <ref type="bibr" target="#b3">[4]</ref>. This employs a modification of traditional error-correcting codes (ECCs). In essence, syndrome codes encode messages in patterns of "errors" in coded bit sequences. Using a binary ECC, it is possible to arrange that many different bit sequences contain the same pattern of errors, thus allowing a given message to be encoded with a variety of different code words.</p><p>The central problem in using syndrome coding for watermarking is that syndrome codes do not introduce any redundancy, and, hence, do not provide any inherent robustness. The flipping of even a single bit in a syndrome-coded word is likely to change the pattern of errors, and thus change the message. This can be solved by combining a syndrome code with a lattice code. Messages are coded with syndrome codes first, and the resulting bit sequences are embedded using a lattice code. While such a system can have better performance than a lattice code alone, it still suffers from the basic problems with lattice codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Trellis Based Dirty-Paper Code</head><p>In this section, we propose a simple modification of a trellis code to produce a dirty-paper code. This code is likely to yield performance different from the types of codes discussed above, but we have yet to identify all the differences. Our principal motivation in developing the present code is that it allows a straightforward application of the informed embedding method described in Section II.</p><p>Fig. <ref type="figure">2</ref> shows an example of a traditional trellis code. In this code, two arcs exit from each state: one bold arc that corresponds to a 1 bit in the coded message, and one nonbold arc corresponding to a 0 bit. This traditional trellis coding scheme assigns one unique path to each message once a starting state has been chosen.</p><p>To create a dirty paper code, the trellis is modified so that multiple alternative codewords can be obtained for each message. The basic idea is to have more than two arcs enter and exit each state, but still use each step of the trellis to encode a single bit. This is shown in Fig. <ref type="figure" target="#fig_8">10</ref>.</p><p>Let us assume that we have arcs and states. Since there is no reason to privilege one state more than another, arcs exit and enter each state. Half of those arcs will encode a 0 (nonbold arcs) and the other half will encode a 1 (bold arcs). There are many alternative paths in the trellis which encode the same message. Suppose we wish to encode an -bit-long message, Bold arcs along a path correspond to 1 bits, and nonbold arcs correspond to 0 bits. Not that, since there are two bold and two nonbold arcs eminating from each node, and a message path may begin at any of the nodes at the left, a given bit sequence can be represented by a number of different paths. Fig. <ref type="figure" target="#fig_0">11</ref>. Version of the dirty-paper trellis in Fig. <ref type="figure" target="#fig_8">10</ref> modified to represent a message beginning with 100 and ending with 1. The first step in this trellis, from states A0 … H0 to states A1 … H1, has been modified by removing all the nonbold arcs, so every path represents a message that begins with 1. The second step, from A1 … H1 to A2 … H2, has had all the bold arcs removed, so the second bit in every path is a 0. And so on to the last step.</p><p>. If we do not impose any starting state, the number of codewords, , which encode the message is given by <ref type="bibr" target="#b4">(5)</ref> We must now define how the embedder selects a path from the set of paths through the trellis that all represent that message that is to be embedded. Conceptually, this can be thought of as being done in two steps. First, we modify the trellis to eliminate all paths that do not encode the desired message. This is a simple matter of removing bold arcs from steps that should encode 0's, and removing nonbold arcs from steps that should encode 1's. In the resulting trellis, every possible path represents the desired message. An example of such a modified trellis is shown in Fig. <ref type="figure" target="#fig_0">11</ref>.</p><p>Second, the embedder applies the detection algorithm to the image, as described in Section II-A, except that it uses the modified trellis instead of the complete trellis. That is, it extracts a vector from the image, and then uses a Viterbi decoder to find the path through the modified trellis that yields the highest correlation with that extracted vector. Once the highest correlation path through the modified trellis has been identified, we can use the informed embedding algorithm of Section II-D to embed the watermark. Alternatively, for purposes of comparison, we can embed the watermark pattern by blindly adding it to the extracted vector.</p><p>During the detection process, the decoder applies the Viterbi algorithm to the entire trellis. This identifies the path that yields the highest correlation with the watermark. The hidden message is then decoded by looking at the bits represented by the arcs in that path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Trellis Structure</head><p>Given the general framework of the algorithm, we now proceed to investigate how the structure of the trellis affects performance. In particular, we examine how the number of arcs, , and states, , impact the effectiveness of the embedding method.</p><p>• If the number of arcs per state is greater than twice the number of states , there will be some parallel arcs in the trellis, i.e for each bit value, there will be several arcs linking the same pair of states. In the extreme case of only a single state, , all the arcs are parallel arcs as depicted in Fig. <ref type="figure" target="#fig_9">12.</ref> • If the number of arcs per state is equal to twice the number of states , the trellis is fully connected i.e., for each bit value, each state is connected exactly once with itself and every other state.</p><p>• If the number of arcs per state is lower than twice the number of states , not all the states can be reached from any given state. This is the case depicted in Fig. <ref type="figure" target="#fig_8">10</ref> . Two experiments were performed to investigate how the structure of the trellis influences the effectiveness of the watermarking scheme. In both experiments, we used uniformly distributed, random vectors as simulated extracted vectors. We represented each arc of the trellis with a length vector <ref type="foot" target="#foot_1">3</ref> . Since we wished to examine the effectiveness of informed coding only, the mark output by the coder was blindly embedded with varying strengths, . Immediately after embedding, the detector was applied to decode the watermark, and the resulting bit error rate (BER) was measured.</p><p>It must be noted that the BER, as opposed to the MER is effected in several different ways by the structure of the trellis. In particular, when the number of arcs per state is lower than the number of states , then whenever an error occurs it may take several steps in the trellis before we return to the correct path. This will introduce burst errors in the decoded messages, increasing the BER. However, since multiple errors should reduce the correlation with the extracted vector, we expect them to happen rarely. In contrast, in a trellis with only  one state, whenever an error occurs the decoder can immediately return to the correct path at the next iteration. Thus, in this configuration, a single error does not induce consecutive errors. However, the cost of single errors is less than for burst errors and they may therefore occur more frequently.</p><p>In the first experiment, we restricted the number of states to 1 and varied the number of arcs. According to <ref type="bibr" target="#b4">(5)</ref>, this means that the number of codewords representing the same message is varying. The results are shown in Fig. <ref type="figure" target="#fig_10">13</ref>. One can observe a very significant reduction in BER as the number of arcs increases from 2 to 64. Performance continues to improve as the number of arcs increases beyond 64, but the improvement is less dramatic. Since computational cost increases with the number of arcs, a good compromise appears to be . For 1 state and 64 arcs, (5) yields the number of codewords, , that encode a message.</p><p>In a second experiment, the number of states and the number of arcs were varied in such a way that the number of codewords representing the same message was kept constant at . This means that is held roughly constant at 64. The results are shown in Fig. <ref type="figure" target="#fig_11">14</ref>. Once again, the error rate quickly drops as the number of states grows before flattening as the number of states exceeds 64. Thus, there is little point in increasing the number of states beyond this point. The two experiments suggest that a configuration of 64 states and 64 arcs per states is a reasonable compromise.</p><p>It should be noted that these experiments are quite preliminary. There are a wide variety of trellis configurations that may provide better results, and it will be interesting to study their behavior. In particular, it is interesting to examine the effect of different values of . As decreases, the minimum difference between paths for different messages increases, and the code becomes more robust against errors. As increases, the number of different paths coding the same message increases, and the code becomes easier to embed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Performance of Informed Coding and Informed Coding With Informed Embedding</head><p>To demonstrate the improvement due to informed coding, 2000 images were watermarked with informed coding (using a trellis of 64 states and 64 arcs per state) and informed embedding. Immediately after embedding, the 2000 images were sent to a watermark detector and the message error rate (MER) was calculated. These results were then compared with the results from Section II-E in which blind coding and informed embedding were applied. We expect informed coding to improve the image fidelity, because the code offers the embedder a choice between a large number of signals to embed. The embedder chooses the one that is already most similar to the image, and hence will lead to the smallest fidelity impact.</p><p>Indeed, the image fidelity is significantly improved with informed coding. To quantify this, we calculated the average perceptual distance according to Watson's model in both cases. The results are summarized in Table <ref type="table" target="#tab_0">II</ref> in which we see that the MER has been reduced from 2% to zero while simultaneously improving the image quality. The average perceptual distance using informed coding is about half that using blind coding.</p><p>To examine how much of this performance improvement was due to informed coding alone, we performed a second experiment in which 2000 images were watermarked using informed coding and blind embedding. The blind embedding strength was chosen to yield an average Watson distance of 89, i.e., roughly the same as the previous experiment with informed coding and informed embedding. Once again, the effectiveness of the embedder was measured. These results are summarized in Table <ref type="table" target="#tab_0">III</ref>. This shows that our informed coding algorithm alone makes a significant improvement over blind coding, but its effectiveness is not satisfactory without informed embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PERCEPTUAL SHAPING</head><p>At this point, the combination of informed coding and informed embedding is promising. However, many of the resulting watermarked images still have unacceptable fidelity. For example, Fig. <ref type="figure" target="#fig_12">15</ref> illustrates how an image can be distorted by our watermarking scheme. Artifacts are particularly noticeable in the region of the sky, where a noisy pattern can be detected. To alleviate this problem, we introduce a perceptual shaping stage to the proposed algorithm, based on Watson's perceptual measure <ref type="bibr" target="#b22">[23]</ref>.</p><p>The perceptual shaping is based on the E-PERC-OPT algorithm described in <ref type="bibr" target="#b6">[7]</ref>. The basic idea is to shape the difference pattern used in step 4) of the informed embedding algorithm (Section II-C). Each element of a watermark vector in our system is a single coefficient from the 8 8 block DCT of an image. Watson's model assigns a perceptual slack to each such  coefficient, which indicates how much that coefficient may be changed before becoming perceptually noticeable. We can arrange the slacks for the low-frequency ac terms (Fig. <ref type="figure" target="#fig_1">3</ref>) into a vector , such that the th component, , is the slack for the th component of the extracted vector. The perceptual shaping of is then performed as <ref type="bibr" target="#b5">(6)</ref> This results in the vector that yields maximum correlation with for a given perceptual distance (see <ref type="bibr" target="#b6">[7]</ref> for the derivation of this function).</p><p>In step 4) of the informed embedding algorithm, where we modify to ensure that , we no longer use (4). Rather, we now modify as follows: <ref type="bibr" target="#b6">(7)</ref> This modification of the algorithm is not expected to effect the performance of the watermarking scheme since robustness is inherently ensured by the informed embedding algorithm.</p><p>To evaluate the effect of this perceptual shaping, 2000 images werewatermarked with informed coding (64 states and 64 arcs per state), informed embedding and perceptual shaping. The Watson distance between the original and the watermarked images was then computed. A watermark detector was immediately applied to the 2000 watermarked images and the MER was computed.</p><p>The results are summarized in Table <ref type="table" target="#tab_2">IV</ref>. While the message error rate has not increased, the perceptual distance between watermarked and unwatermarked images has been reduced almost three-fold. The improvement in fidelity is easily seen in Fig. <ref type="figure" target="#fig_13">16</ref> where the Watson-based perceptual shaping has been used. In comparison with Fig. <ref type="figure" target="#fig_12">15</ref>, one can noticed that the sky is far less distorted after incorporating perceptual shaping.</p><p>However, Fig. <ref type="figure" target="#fig_13">16</ref> also illustrates a limitation with Watson's model. Some undesirable blocking artifacts have appeared along sharp edges, particularly on the left side of the image, where there is a thin black border. This is due to the fact that Watson's model is block based and each block is independently examined.  Blocks that contain sharp edges contain energy in all frequencies, and are erroneously judged to contain much texture that can mask watermark patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. ROBUSTNESS EXPERIMENTS</head><p>Our previous experiments have examined only the embedding effectiveness of the watermark embedder, i.e., the performance when the watermarked image is not distorted between the times of embedding and detection. In practice, watermarked content will be subjected to a variety of distortions before reaching the detector. Watermarks designed to survive legitimate and everyday usage of content, e.g., low-pass filtering, noise, JPEG compression, are referred to as robust watermarks.</p><p>In this section, we measure the effect of a wide range of distortions on three different watermark algorithms: i) blind coding, informed embedding, no shaping (bciens); ii) informed coding, informed embedding, no shaping (iciens); and iii) informed coding, informed embedding and shaping (icies). Algorithms employing blind embedding were not tested, since they have been found to have unacceptable performance even without image distortions. We report robustness results for addition of Gaussian noise, low-pass filtering, valumetric scaling, and JPEG compression. For each class of distortion, the 2000 watermarked images were modified with a varying magnitude of distortion. The MER was then computed. Following the practice suggested in <ref type="bibr" target="#b9">[10]</ref>, we considered the watermarking scheme to be robust if at least 80% of the watermarks were correctly retrieved, i.e., the MER is below 20%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gaussian Noise</head><p>Normally distributed noise with mean 0 and standard deviation was added to each of the watermarked images. The experiment was repeated for different standard deviations, , and the MER has been computed.</p><p>The results are summarized in Fig. <ref type="figure" target="#fig_14">17</ref>. Notice that the two schemes that use informed coding-iciens (no perceptual shaping) and icies (with perceptual shaping)-have quite  similar performance. This is because the perceptual shaping does not interfere with informed embedding, as explained in Section IV. Remember, however, that images embedded using the icies algorithm have substantially better fidelity.</p><p>The gain obtained by introducing informed coding is small but noticeable. This is to be expected since the informed embedding algorithm is designed to embed any code with the same level of robustness to additive Gaussian noise. However, referring to Table II, the perceptual distortion, as measured by the Watson distance, is almost halved when informed coding is used. Fig. <ref type="figure" target="#fig_15">18</ref> shows the watermarked image of Fig. <ref type="figure" target="#fig_13">16</ref> after being altered by additive Gaussian noise with standard deviation . The degradation is clearly observable in uniform areas like the sky.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Low-Pass Filtering</head><p>All three watermarking schemes use only low-frequency DCT coefficients. As a result we expect them to be quite resilient against low-pass filtering. To verify this, the watermarked images were filtered with Gaussian filters of width . The experiment was repeated for different values of and the MER computed.</p><p>Fig. <ref type="figure" target="#fig_16">19</ref> summarizes the results. Once again, the informed coding methods have similar performance and the improvement between blind coding and informed coding is clear. With blind coding, the MER reaches 20% with a Gaussian filter of width . In contrast, with informed coding, the images can be filtered with a Gaussian filter of width before the same MER is reached. Fig. <ref type="figure" target="#fig_17">20</ref> shows the watermarked image shown in Fig. <ref type="figure" target="#fig_13">16</ref> after being filtered by a Gaussian filter of width . Clearly, the image fidelity is very poor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Valumetric Scaling</head><p>Another simple, but important distortion is changing amplitude. That is <ref type="bibr" target="#b7">(8)</ref> where is an image and a scaling factor. This corresponds to a change of brightness and contrast for images and video. This attack is of particular interest for us, and was indeed the main weakness of the watermarking schemes proposed by Chen and Wornell <ref type="bibr" target="#b0">[1]</ref>.</p><p>Two tests were performed. The first reduced the image intensities, i.e., varied from 1 to 0.1. The second experiment increased the image intensities as increased from 1 to 2.</p><p>The results of the first test are summarized in Fig. <ref type="figure" target="#fig_18">21</ref>. As usual, the two informed coding methods have very similar per-  formance and are superior to the blind coding method. The results clearly demonstrate that our watermarking schemes are resilient against valumetric scaling down. Whatever watermarking scheme is chosen, its performance remains the same down to a scaling factor of 0.1.</p><p>A scaling with a factor of 0.1 produced a serious image degradation. An example of a scaled image cannot be shown in this article because, with such a scaling factor, the image is almost completely black. However, even if the distorted image is much darker, the hidden message is still correctly extracted. This is because valumetric scaling multiplies all the correlation scores by the same scaling factor (modulo some rounding). As a result the best path along the trellis remains the same.</p><p>In a second test, we investigated the robustness of our watermarking methods to valumetric scaling for . Fig. <ref type="figure" target="#fig_19">22</ref> summarizes the results. Once more, the two informed coding methods have similar performance and outperform the blind coding method for scale factors up to . Surprisingly, for the blind coding method is superior. We hypothesise that this is due to the fact that the blind code is embedded with significantly more strength since the perceptual distortion is twice as large for images watermarked with blind coding.</p><p>The robustness to scaling intensities up is much worse than the robustness to scaling intensities down. This is because, in addition to rounding, valumetric scaling up introduces some clipping, i.e., all the pixel values above 255 after scaling are truncated to 255. This has a more severe impact than rounding. Fig. <ref type="figure" target="#fig_20">23</ref> shows the watermarked image of Fig. <ref type="figure" target="#fig_13">16</ref> after valumetric scaling up with a factor . The image is globally brighter, but one can also notice that some textured areas have become uniformly white after scaling (the flowers in the central bottom part).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Lossy Compression</head><p>Here we tested the effects of JPEG compression. The JPEG standard does not actually specify a compression method, so different encoders can, in principle, have different effects on watermarks. However, there is a conventional method of encoding which is very common. This specifies the quantization values for DCT coefficients by multiplying a quantization matrix (Table <ref type="table" target="#tab_3">V</ref>) by a global quantization level . For example, if , the DC term is quantized with a quantization level of and the highest-frequency term with . The quantization level is related to a user-specified quality factor, , in the range of 0-100, as <ref type="bibr" target="#b10">[11]</ref> if</p><formula xml:id="formula_0">if . (<label>9</label></formula><formula xml:id="formula_1">)</formula><p>To test the effects of JPEG, then, it is sufficient to apply only this quantization. This is preferable to using some encoder from a third party, as we cannot be sure of the algorithms used (and the algorithms may change over time, making it difficult to reproduce results).</p><p>The effects of JPEG compression were simulated by applying quantization in the DCT domain. The block-DCT transform was computed for each watermarked image. The DCT coefficients were then quantized according to the following: <ref type="bibr" target="#b9">(10)</ref> where is the quantization value obtained as described above. After quantization, the inverse block-DCT was applied. The watermarked images were quantized with different values for the parameter and the MER was computed.</p><p>The results are summarized in Fig. <ref type="figure" target="#fig_21">24</ref> and expressed in terms of JPEG quality factor . The reader should keep in mind that it is easy to switch between the JPEG quality factor and the global quantization level thanks to <ref type="bibr" target="#b8">(9)</ref>. Again, the two informed coding methods have similar performance and better than the blind coding method for JPEG quality factors greater  than 40. However, once again, we point out that the perceptual distortion is halved using the informed coding methods. Fig. <ref type="figure" target="#fig_22">25</ref> shows the impact of lossy compression with a quality factor . The image fidelity is very degraded at this point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND FUTURE WORK</head><p>Five different watermarking schemes have been investigated in this paper and their performances have been gathered in Table <ref type="table" target="#tab_4">VI</ref>. On one hand, informed coding reduces the fidelity impact of the watermarking process and, on the other hand, informed embedding ensures a specified robustness. However, only the combination of those two approaches gives satisfactory results. Furthermore, the fidelity impact of those algorithms can be decreased by introducing a perceptual model. The final watermarking scheme (informed coding informed embedding perceptual shaping) exhibits good robustness against a wide range of everyday distortions.</p><p>Possible areas of further research include the following.</p><p>• Increasing the capacity: The watermarking schemes presented here embed one bit for every 64 pixels in an image.</p><p>With a 240 368 image, 1380 bits have been embedded. However some researchers are still interested in increasing the capacity of the watermark beyond this point. One possible solution would be to associate more than one bit to the different arcs of the trellis. Some preliminary theoretical and mathematical analysis has been conducted and the results have been checked with some experiments. They show that it might be possible to increase the capacity of our watermarking scheme, but at the cost of increasing the embedding strength, i.e., the perceptual impact induced by the watermarking process will be greater. • Better perceptual models: It has already been noted in Section IV that Watson's perceptual model has introduced an annoying blocking artifact. This is inherent to Watson's model, because the perceptual slacks take in account only the pixels in a given DCT block. Smoothness at the edges between the DCT blocks is consequently not guaranteed. We are currently studying the application of a model due to van de Branden Lambrecht and Farrell <ref type="bibr" target="#b19">[20]</ref>, which is based on Gabor filters and does not divide images into blocks. Alternatively, we might employ pixel-based models such as that proposed by Voloshinovsky <ref type="bibr" target="#b21">[22]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Watermarking with informed embedding.</figDesc><graphic coords="1,317.04,163.02,222.24,82.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. DCT coefficients used by watermarking system. The upper-left corner of this figure corresponds to the DC term of an 8 2 8 block's DCT. The 12 coefficients shaded in gray indicate the low-frequency ac terms used.</figDesc><graphic coords="2,351.60,273.66,150.12,150.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Geometric interpretation of embedding region defined by placing a lower limit on R(c ; g). Each point in this space corresponds to a possible image. The Voronoi diagram indicates the detection regions for seven different message vectors, which are indicated with X's. Six of these are "bad" vectors we do not want to embed. The seventh, g, is the "good" vector we intend to embed. The gray region indicates the set of images which satisfy the constraint on R(). The open circle, the arrow, and the solid dot illustrate the behavior of an ideal embedder-cover image c would be moved to the closest point in the embedding region c .</figDesc><graphic coords="3,316.62,62.28,223.08,204.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 3 )</head><label>3</label><figDesc>Fig.4illustrates a geometric interpretation of the embedding region that results when we specify that must be greater than or equal to a given value. The figure shows a Voronoi diagram representing the detection regions for various messages. By specifying a minimum value for , we are insisting that must lie a certain distance from the edge of the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Original cover image. (Note: we chose this image for our figures because it exhibited typical behavior in our various experiments, and it shows the perceptual differences between the embedding algorithms we present.)</figDesc><graphic coords="5,108.48,62.29,376.36,245.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Result of iterative informed embedding algorithm. Watermark noise is clearly visible, particularly in the sky.</figDesc><graphic coords="6,106.98,62.29,376.36,245.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Watermarking with informed coding.</figDesc><graphic coords="6,315.72,451.32,221.88,81.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. "Dirty paper" channel studied by Costa.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Dirty-paper trellis with eight states and four arcs per state (thus S = 8 and A = 8 2 4 = 32). Each path from one of the nodes at the left (A0 through H0) to one of the nodes at the right (AL throught HL) represents a message.</figDesc><graphic coords="8,52.20,284.34,222.84,133.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Extreme case where there is only one state in the dirty paper trellis.</figDesc><graphic coords="8,51.84,62.28,223.56,133.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. BER versus number of codewords with one state trellis.</figDesc><graphic coords="9,54.48,62.28,221.28,177.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. BER with a constant number of codewords.</figDesc><graphic coords="9,54.72,262.92,220.80,177.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Image watermarked with informed coding and informed embedding.</figDesc><graphic coords="10,106.98,229.27,376.36,245.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Fidelity improvement with the introduction of perceptual shaping.</figDesc><graphic coords="11,306.36,417.96,243.60,200.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Robustness versus Gaussian noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Watermarked reference image subjected to a Gaussian noise with standard deviation = 5:5.</figDesc><graphic coords="12,106.98,62.29,376.36,245.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Robustness versus low-pass filtering.</figDesc><graphic coords="12,43.80,345.06,239.64,195.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Watermarked reference image low-pass filtered with a Gaussian filter of width = 0:63.</figDesc><graphic coords="13,108.48,62.29,376.36,245.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. Robustness versus valumetric scaling down.</figDesc><graphic coords="13,43.02,336.60,244.20,201.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 22 .</head><label>22</label><figDesc>Fig. 22. Robustness versus scaling up.</figDesc><graphic coords="13,306.30,336.60,243.72,201.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Watermarked reference image scaled with a scaling factor = 1:25.</figDesc><graphic coords="14,106.98,62.29,376.36,245.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. Robustness versus JPEG quantization.</figDesc><graphic coords="14,304.56,341.28,244.20,201.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. Close-up detail of the watermarked reference image compressed with a quality factor equal to 40%.</figDesc><graphic coords="15,108.78,62.26,375.71,282.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I BLIND</head><label>I</label><figDesc></figDesc><table /><note><p>EMBEDDING VERSUS INFORMED EMBEDDING</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV EFFECT</head><label>IV</label><figDesc>OF PERCEPTUAL SHAPING</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE V LUMINANCE</head><label>V</label><figDesc>QUANTIZATION MATRIX USED IN JPEG</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE VI EMBEDDING</head><label>VI</label><figDesc></figDesc><table /><note><p>PERFORMANCE WITH FIVE SCHEMES</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Costa did not invent the concept of a dirty-paper code. However, his analogy provides us with a colorful name.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>These experiments were performed before we decided to use only N = 12 length vectors for marking real images.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Digital watermarking and information embedding using dither modulation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Wornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 2nd Workshop on Multimedia Signal Processing</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="273" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An information-theoretic approach to the design of robust digital watermarking systems</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoustics, Speech, Signal Processing (CASSP &apos;99)</title>
		<meeting>IEEE Int. Conf. Acoustics, Speech, Signal essing (CASSP &apos;99)</meeting>
		<imprint>
			<date type="published" when="1999-03">Mar. 1999</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2061" to="2064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Preprocessed and postprocessed quantization index modulation methods for digital watermarking</title>
	</analytic>
	<monogr>
		<title level="m">Security and Watermarking of Multimedia Contents II</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">3971</biblScope>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the duality between distributed source coding and data hiding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd Asilomar Conf. Signals, Systems, and Computers</title>
		<meeting>33rd Asilomar Conf. Signals, Systems, and Computers</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1503" to="1507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J A</forename><surname>Sloane</surname></persName>
		</author>
		<title level="m">Sphere Packings, Lattices, and Groups</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Writing on dirty paper</title>
		<author>
			<persName><forename type="first">M</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="439" to="441" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Digital</forename><surname>Watermarking</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Watermarking as communications with side information</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mckellips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1999-07">July 1999</date>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1127" to="1141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A blind watermarking scheme based on structured codebooks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Girod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inst. Elect. Eng. Seminar on Secure Images and Image Authetication</title>
		<imprint>
			<biblScope unit="page" from="4" to="5" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A fair benchmark for image watermarking systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A P</forename><surname>Petitcolas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE-Security and Watermarking of Multimedia Contents</title>
		<meeting>SPIE-Security and Watermarking of Multimedia Contents</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3657</biblScope>
			<biblScope unit="page" from="226" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-fragile watermarking for authenticating JPEG visual content</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE-Security and Watermarking in Multimedia Contents II</title>
		<meeting>SPIE-Security and Watermarking in Multimedia Contents II</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">3971</biblScope>
		</imprint>
	</monogr>
	<note>p. (AUTHOR: PLS. SUPPLY PAGES</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Watermarking with dirty-paper codes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Processing</title>
		<meeting>IEEE Int. Conf. Image essing<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="538" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Informed embedding: Exploiting image and detector information during watermark insertion</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. on Image Processing</title>
		<imprint>
			<date type="published" when="2000-09">Sept. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Information-theoretic analysis of information hiding</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>O'sullivan</surname></persName>
		</author>
		<ptr target="http://www.ifp.uiuc.edu/~moulin/paper.html" />
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Information-theoretic analysis of information hiding</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>in ICASSP&apos;00</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data hiding within audio signals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Winograd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jemili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Metois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th Int. Conf. Telecommunications in Modern Satellite Cable and Broadcasting Services</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed source coding: Symmetric rates and applications to sensor networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Data Compression Conf</title>
		<meeting>IEEE Data Compression Conf</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="363" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Ramkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data hiding in multimedia: Theory and applications</title>
		<meeting><address><addrLine>Newark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Channels with side information at the transmitter</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Devel</title>
		<imprint>
			<biblScope unit="page" from="289" to="293" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Perceptual quality metric for digitally coded color images</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Branden</forename><surname>Lambrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Farrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO</title>
		<meeting>EUSIPCO</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="1175" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">CDMA: Principles of Spread Spectrum Communications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Viterbi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A stochastic approach to content adaptive digital image watermarking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Voloshynovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herrigel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Baumgaetner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd Int. Workshop on Information Hiding</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DCT quantization matrices optimized for individual images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Vision, Visual Processing, and Digital Display IV</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">1913</biblScope>
			<biblScope unit="page" from="202" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">he became Lead Programmer at NPS, a startup company developing color desktop-publishing software. From 1990 to 1993, he delivered graduate-level lecture courses in color graphics at Aarhus University, Denmark</title>
		<author>
			<persName><forename type="first">L</forename><surname>Matt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Miller receiving the B.A. degree in cognitive science from the University of Rochester</title>
		<meeting><address><addrLine>Rochester, NY; Prague, Czech Republic; Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1996. 1986</date>
		</imprint>
		<respStmt>
			<orgName>Charles University and Czech Technical University ; NEC Research Institute</orgName>
		</respStmt>
	</monogr>
	<note>In 1997, he sold Baltic Images to join NEC&apos;s watermarking startup company, Signafy, where he was one of the main contributers to the proposed Galaxy watermarking standard for DVD video. He is now a Research Staff Member at NEC Labs America</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">winning the Louis Leprince Ringuet Award for his work. His research interests currently include security against collusion, image hashing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gwenaël</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Doërr received the engineering degree in telecommunications from the Institut National des Télécommunications (Télécom INT)</title>
		<meeting><address><addrLine>Evry, France; Sophia-Antipolis, France; Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>NEC Research Institute</orgName>
		</respStmt>
	</monogr>
	<note>where he is currently pursuing the Ph.D. degree in the area of video watermarking. He was an intern with. video mosaicing, hostile attacks, and turbo codes</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">as a Senior Research Scientist in the Computer Science Division. At NEC, his research shifted to problems in computer vision and he was responsible for creating the computer vision group at NECI. He has worked on problems to do with stereo and motion correspondence and multimedia issues of image database retrieval and watermarking. From 1997-1999, he was Chief Technical Officer of Signafy, Inc., a subsiduary of NEC, responsible for the commercialization of watermarking. Between 1996 and 1999, he led the design of NEC&apos;s watermarking proposal for DVD video disks and later colloborated with IBM in developing the technology behind the joint &quot;Galaxy&quot; proposal supported by Hitachi, IBM, NEC, Pioneer, and Sony</title>
		<author>
			<persName><forename type="first">Ingemar</forename><forename type="middle">J</forename><surname>Cox ; London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><surname>Ph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">S&apos;79-M&apos;83-SM&apos;95) received the B.Sc. degree from University College of</title>
		<meeting><address><addrLine>Oxford, U.K; Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989. 1999</date>
		</imprint>
		<respStmt>
			<orgName>NEC Research Institute ; NEC Research Institute as a Research Fellow</orgName>
		</respStmt>
	</monogr>
	<note>He is currently Professor and Chair of Telecommunications in the Departments of Electronic Engineering and Computer Science, University College London. He is co-author of the book Digital Watermarking and co-editor of two books, Autonomous Robots Vehicles and Partitioning Data Sets: With Applications to Psychology, Computer Vision and Target Tracking. He is on the editorial boards of the. Paper Award (in the area of image and multidimensional signal processing area) for a paper he co-authored on watermarking in 1999</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
