<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse Contextual Activation for Efficient Visual Re-ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Bai</forename><surname>Song</surname></persName>
						</author>
						<title level="a" type="main">Sparse Contextual Activation for Efficient Visual Re-ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0E8AD850B90C2DCDE6A1E602B4000E47</idno>
					<idno type="DOI">10.1109/TIP.2016.2514498</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2514498, IEEE Transactions on Image Processing IEEE TRANSACTIONS ON IMAGE PROCESSING 1 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2514498, IEEE Transactions on Image Processing IEEE TRANSACTIONS ON IMAGE PROCESSING This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2514498, IEEE Transactions on Image Processing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Jaccard distance</term>
					<term>Feature Fusion</term>
					<term>Re-ranking</term>
					<term>Retrieval</term>
					<term>Inverted index</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose an extremely efficient algorithm for visual re-ranking. By considering the original pairwise distance in the contextual space, we develop a feature vector called Sparse Contextual Activation (SCA) that encodes the local distribution of an image. Hence, re-ranking task can be simply accomplished by vector comparison under the generalized Jaccard metric, which has its theoretical meaning in fuzzy set theory. In order to improve the time efficiency of re-ranking procedure, inverted index is introduced successfully to speed up the computation of generalized Jaccard metric. As a result, the average time cost of re-ranking for a certain query can be controlled within one millisecond. Furthermore, inspired by Query Expansion, we also develop an additional method called Local Consistency Enhancement (LCE) on the proposed sparse contextual activation to improve the retrieval performance in an unsupervised manner. On the other hand, the retrieval performance using a single feature may not be satisfactory enough, which inspires us to fuse multiple complementary features for accurate retrieval. Based on sparse contextual activation, a robust feature fusion algorithm is exploited that also preserves the characteristic of high time efficiency. We assess our proposed method in various visual re-ranking tasks. Experimental results on Princeton Shape Benchmark (3D object), WM-SRHEC07 (3D competition), YAEL dataset B (face), MPEG-7 dataset (shape) and Ukbench dataset (image) manifest the effectiveness and efficiency of SCA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>C ONTEXTUAL similarity/dissimilarity [1], [2], [3] has been extensively exploited recently due to its effectiveness in various visual retrieval tasks, such as natural image search, shape retrieval, biological information retrieval, analysis of time series, etc.. Unlike traditional Content-based Image Retrieval (CBIR) systems that consider only pairwise dissimilarity measure for ranking and indexing, the approaches about contextual dissimilarity measure are proposed to explore the contextual information from the database instances, and enhance and refine the dissimilarity measure to improve the retrieval performance, which is usually considered as an unsupervised re-ranking procedure based on the given distance measure.</p><p>This work was primarily supported by National Natural Science Foundation of China (NSFC) (No. 61573160, No. 61222308), and in part by Program for New Century Excellent Talents in University (No. NCET-12-0217).</p><p>The associate editor coordinating the review of this manuscript and approving it for publication was Prof. Li Chunming. (Corresponding author: Xiang Bai.)</p><p>The authors are all with the School of Electronic Information and Communications, Huazhong University of Science and Technology (HUST), Wuhan, 430074, China (e-mail: songbai@hust.edu.cn; xbai@hust.edu.cn).</p><p>In general, the re-ranking procedure is often performed as a post-processing step of ranking initialization, which creates a ranking list for a given query. For image retrieval, the dissimilarity measure between a pair of images is often obtained by calculating the distance of their corresponding features under a certain metric. Given a query image, all the database images are sorted in an ascending/descending order according to their dissimilarities/similarities to the query. The ranking list for the query image can be finally initialized, where the most similar images occupy its top positions. A key issue in ranking initialization is to design proper features with enough discriminative power to represent an image, during which the Bag-of-Words (BoW) <ref type="bibr" target="#b3">[4]</ref> image representation is often suggested.</p><p>Instead of ranking with pairwise dissimilarity measure, the contextual re-ranking algorithms have been proposed and demonstrate their effectiveness by considering the relationships among all database instances <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. In these re-ranking algorithms, the dissimilarity measure between two instances is iteratively updated and refined by taking into account their local distributions (neighborhood structure). As the neighborhood of each instance can be directly obtained from the ranking list, the key advantage of these re-ranking approaches is that training/labeled data is not required, operating in an unsupervised manner.</p><p>Though extensively studied, almost all the existing contextual re-ranking algorithms only pay much attention to the effectiveness, which refers to the level of retrieval accuracy. The efficiency, which refers to the time cost for the procedure of re-ranking, has been more or less neglected. However, both effectiveness and efficiency are quite important for a realtime retrieval system, and the tradeoff between them is badly required at present. The contextual re-ranking approaches <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr">[8]</ref> often consider all the distances among instances of a given dataset, and the contextual dissimilarities are often achieved by operating on such a distance matrix. Therefore, a large computational effort is essential (typically, between O(N 2 ) and O(N 3 ), N is the number of images in the database), which seriously hinders their use in retrieval services that require for fast re-ranking. As a result, some re-ranking algorithms <ref type="bibr" target="#b8">[9]</ref> are only applied to a subset of retrieved images to make a tradeoff between efficiency and effectiveness.</p><p>In this paper, we address the contextual re-ranking problem in an alternative and simpler manner. The contextual dissimilarity measure between two images is calculated by comparing two neighborhood sets, i.e. the neighborhood sets of a query and a target. It shares a similar intuition with the traditional approaches that the relationship between two images should not only be determined by the distance between them, but also influenced by their neighbors on the distance manifold. Our main contribution is to propose an extremely fast re-ranking algorithm called Sparse Contextual Activation (SCA) to compute the dissimilarity between such two neighborhood sets. Given a certain image, the basic idea of SCA is encoding its local distribution according to the original pairwise similarity into a single vector. Consequently, the contextual dissimilarity measure (set-to-set distance) between two images can be simply obtained by comparing two encoded vectors. Due to the sparsity property of such encoded vectors, the inverted index <ref type="bibr" target="#b9">[10]</ref> can be further used to speed up the computation of the vector comparison for re-ranking. Besides the efficiency of SCA, it also achieves state-of-the-art retrieval performances on several standard benchmarks. In addition, we extend the proposed SCA for efficiently fusing multiple kinds of distance metrics for highly effective re-ranking while the inverted index can be also incorporated. Though the focus of this paper is re-ranking, contextual similarity has been successfully adopted in many image processing or vision tasks including image segmentation <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, object tracking <ref type="bibr" target="#b12">[13]</ref>. In this sense, the high efficiency of SCA is significant.</p><p>The rest of the paper is organized as follows. We first review some related work in Section II. The details of Sparse Contextual Activation (SCA) are introduced in Section III, and feature fusion based on SCA is described in Section IV. Experiments are carried out in Section V. Conclusions and future work are summarized in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Since there exist a large amount of works on re-ranking algorithms, we only review the unsupervised re-ranking algorithms in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Re-ranking with single distance measure</head><p>In recent years, contextual information has been successfully explored to improve the retrieval accuracy by replacing a given pairwise similarity with a more faithful one, which is learned by considering the relationships among the database objects <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. The contextual reranking has a very diverse taxonomy (graph transduction <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b15">[16]</ref>, diffusion process <ref type="bibr">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b1">[2]</ref>, rank aggregation <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, contextual similarity/dissmilaries measure <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b13">[14]</ref>, query expansion <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, ranking list comparison <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>). These post-processing approaches share the common spirit that the effectiveness of retrieval tasks is improved by taking use of relationships among dataset objects in an unsupervised manner, without labeled data.</p><p>One of the most classical algorithms is graph transduction (GT) <ref type="bibr" target="#b2">[3]</ref>. As an unsupervised method, GT spreads the information from the labeled data to unlabeled data by regarding the query itself as the only labeled data.</p><p>A popular branch for re-ranking is diffusion process, which is summarized as a generic framework in <ref type="bibr" target="#b1">[2]</ref>. Most variants of diffusion process share the same perspective that the pairwise similarity is context-sensitive, and the geometric structure of data manifold should be considered. In <ref type="bibr">[8]</ref>, Locally Constrained Diffusion Process (LCDP) is proposed to apply the affinity propagation with the constraint of locality. Tensor Product Graph (TPG) <ref type="bibr" target="#b16">[17]</ref> diffuses the similarity information in the tensor product graph achieved by the tensor product of the original graph with itself.</p><p>Based on the observation that a good ranking is usually asymmetric, Contextual Dissimilarity Measure (CDM) <ref type="bibr" target="#b0">[1]</ref> improves the retrieval performance of BoW vectors by modifying the neighborhood structure using Sinkhorn's scaling algorithm. Ranking consistency in <ref type="bibr" target="#b17">[18]</ref> is used as a verification method to refine an existing ranking list. Query Expansion <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> can substantially improve the retrieval performance by using relevant images as extra queries. Spatial verification <ref type="bibr" target="#b8">[9]</ref> is proposed for re-ranking by considering the spatial constraints.</p><p>These aforementioned algorithms, as well as Self Diffusion (SD) <ref type="bibr" target="#b10">[11]</ref>, diffusion maps <ref type="bibr" target="#b24">[25]</ref>, aims at improving the retrieval accuracy, however the re-ranking efficiency is more or less neglected. For example, the time complexity of LCDP <ref type="bibr">[8]</ref> and TPG <ref type="bibr" target="#b16">[17]</ref> is O(N 3 ). By contrast, our proposed SCA is a highly efficient re-ranking algorithm (in O(N ) time complexity), while also performs better in retrieval accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Re-ranking with multiple distance measures</head><p>Multiple distance measure fusion has been proven effective in various visual applications, such as visual tracking <ref type="bibr" target="#b12">[13]</ref>, image classification <ref type="bibr" target="#b25">[26]</ref> etc.. Considering that one distance measure only focuses one aspect of images, some re-ranking algorithm also deals with multiple complementary features.</p><p>Zhang et al. <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> fuse BoW feature and holistic feature by a graph-based query specific fusion, and re-ranking is performed by using the local PageRank algorithm or finding the weighted maximum density subgraph. Co-transduction <ref type="bibr" target="#b28">[29]</ref> adopts a semi-supervised framework based on co-training <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> to combine complementary features for image and shape retrieval. In <ref type="bibr" target="#b31">[32]</ref>, a regularization-based feature selection algorithm is proposed to leverage both the sparsity and clustering properties of multiple features.</p><p>Besides multiple distance measure fusion, some algorithms also focus on designing an individual distance measure using multiple features. For example, c-MI <ref type="bibr" target="#b32">[33]</ref> integrates SIFT descriptor <ref type="bibr" target="#b33">[34]</ref> and color descriptor into a multi-dimensional inverted index. In <ref type="bibr" target="#b34">[35]</ref>, a multi-IDF scheme is proposed, by which different binary features are coupled into the inverted index. Co-indexing <ref type="bibr" target="#b35">[36]</ref> jointly embeds local invariant features and semantic attributes.</p><p>Based on sparse contextual activation, we also propose a re-ranking version that deals with multiple distance measures, which not only maintains the characteristic of efficiency, but also improves the performance significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SPARSE CONTEXTUAL ACTIVATION</head><p>Let X = {x 1 , x 2 , . . . , x N } denote a collection of images. We define two functions listed as follows:</p><formula xml:id="formula_0">• Function f : x → R n : it extracts a n-dimensional feature</formula><p>to represent the input image x.</p><p>• Function d : R n × R n → R: it computes the distance for the two input feature vectors f (x q ) and f (x p ) under a certain metric, where x q and x p represent two images in the database.</p><p>The distance d (f (x q ), f (x p )) is taken as the dissimilarity of the images x q and x p . To simplify the notation, we use d(x q , x p ) to replace d (f (x q ), f (x p )) below where possible. After all the pairwise dissimilarity values related to the given query x q are achieved, we could initialize the ranking list by sorting the dissimilarity in an increasing order. The images with smaller dissimilarity values are ranked higher in the retrieval list, and vice versa.</p><p>Next, we introduce our proposed re-ranking algorithm to refine the original distance measure with high time efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preliminary</head><p>We deem that if x q and x p are similar, their retrieval results, especially the top-ranked results, are exactly or approximately the same in the expected situation. Let N k (x q ) represent the neighborhood set of x q achieved by the k-nearest neighbors rule in the original distance space d. N k (x q ) is a mathematical set that contains the top-k candidates in the ranking list of x q . Then, the distance of two neighborhood sets N k (x q ) and N k (x p ) is measured by Jaccard distance as</p><formula xml:id="formula_1">d J (x q , x p ) = 1 - |N k (x q ) ∩ N k (x p )| |N k (x q ) ∪ N k (x p )| ,<label>(1)</label></formula><p>where |.| calculates the cardinality of the input set, and</p><formula xml:id="formula_2">|N k (x q )| = k.</formula><p>With the distance measure defined by Eq. ( <ref type="formula" target="#formula_1">1</ref>), the original ranking list of a given query x q can be re-ranked. The re-ranking distance measure in Eq. 1 is expected to achieve better performance than the original one, for it utilizes the additional contextual information as diffusion process does. However it also has many shortcomings.</p><p>1) The neighbors in the neighborhood set contribute equally. It is not a proper behavior, since the top-ranked neighbors are more likely to be true positive patterns.</p><p>Assigning larger weights to the top-ranked neighbors, and increasing their effects on the re-ranking distance measure is more reasonable.</p><p>2) The re-ranking distance measure is defined between two sets. In the specific scenario of re-ranking, it is more convenient to define the distance measure on two vectorial features. 3) The neighborhood set is simply defined as the k-nearest neighbors, which cannot guarantee that the images from the same category could own similar neighborhood sets, especially when a certain amount of outliers also occupy top positions in the ranking list.</p><p>In the next section, Sparse Contextual Activation (SCA) is proposed to address these problems. The Jaccard distance defined in Eq. (1) will serve as the baseline method, and we will compare it with our proposed SCA in terms of retrieval performance and running time. For notation clarity, we refer to the baseline method as Jaccard re-ranking below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Proposed Sparse Contextual Activation</head><p>The neighborhood set N k (x q ) is converted to a vector representation by defining an binary indicator function F q = [F q,1 , F q,2 , . . . , F q,N ] as</p><formula xml:id="formula_3">F q,p = 1 if x p ∈ N k (x q ) 0 otherwise.<label>(2)</label></formula><p>As we can see, the binary vector F q shows whether a certain image x p appears in the neighborhood set of x q .</p><p>Based on the definition of the indicator function, the intersection and union set of N k (x q ) and N k (x p ) are interpreted as</p><formula xml:id="formula_4">N k (x q ) ∩ N k (x p ) ⇐⇒ M IN (F q , F p ) ,<label>(3)</label></formula><formula xml:id="formula_5">N k (x q ) ∪ N k (x p ) ⇐⇒ M AX (F q , F p ) ,<label>(4)</label></formula><p>where M IN (or M AX) calculates the element-wise minimum (or maximum) value for two input vectors of the same length. Thus we attain the cardinality for the intersection and the union set by computing the L 1 norm of their corresponding indicators as</p><formula xml:id="formula_6">|N k (x q ) ∩ N k (x p )| = M IN (F q , F p ) 1 , (5) |N k (x q ) ∪ N k (x p )| = M AX(F q , F p ) 1 .<label>(6)</label></formula><p>Based on Eq. ( <ref type="formula">5</ref>) and Eq. ( <ref type="formula" target="#formula_6">6</ref>), we can rewrite the the definition of Jaccard distance in Eq. (1) as</p><formula xml:id="formula_7">dJ (x q , x p ) = 1 - N i=1 min (F q,i , F p,i ) N i=1 max (F q,i , F p,i ) .<label>(7)</label></formula><p>Now, the definition of Jaccard distance in Eq. (1) has been successfully defined in vector space. That is to say, we do not use a set, but use an indicator function to represent the neighbors of an image. As a result, the Jaccard distance of two neighborhood sets can be easily achieved by vector comparison through Eq. <ref type="bibr" target="#b6">(7)</ref>.</p><p>Note that the indicator function in Eq. ( <ref type="formula" target="#formula_3">2</ref>) also considers the neighbors equally, but it is easy to implement different weights by restricting the value of the original binary indicator vector in the unit interval [0, 1]. However, it may be misleading that F q,p is assigned to a certain constant between 0 and 1, since the role of F q,p is to indicate the membership of the image x p in the neighborhood set N k (x q ). In classical set theory, the membership of x p in the set N k (x q ) is exact (x q either belongs or does not belong to the set). It seems difficult to generalize the binary indicator function in the unit interval [0, 1] with rational explanations.</p><p>To tackle with the problem, we introduce the fuzzy set theory. In mathematics, fuzzy set is a set whose elements have degrees of membership determined by a membership function. Compared with the classical set theory, fuzzy set allows the gradual assessment of the membership of elements in a set. At last, we define the neighborhood set as a fuzzy set in fuzzy set theory, and the membership grade of x p in the neighborhood set N k (x q ) is determined by the corresponding membership function F q,p ∈ [0, 1].</p><p>The problem we face now is how to determine the membership grade of neighbors. A natural solution is to use the elements in N k (x q ) to reconstruct x q in the feature space with non-negative constraint, and the weights for reconstruction can be used as the membership grades. It can be formulated as</p><formula xml:id="formula_8">min q f (x q ) - i|xi∈N k (xq) F q,i f (x i ) 2 , s.t. 1 T F q = 1, F q 0. (8)</formula><p>Except for the non-negative constraint, this formulation almost shares the same perspective with Locally Linear Embedding (LLE) <ref type="bibr" target="#b36">[37]</ref>, a classical non-linear dimension reduction algorithm. LLE expects each data point and its neighbors lie on or close to a locally linear patch of the manifold, and the reconstruction weights are used for dimension reduction by a neighborhood preserving mapping.</p><p>However, in the specific scenario, the above solution may be not fit enough for visual re-ranking for three reasons. First, LLE usually presumes that there is sufficient data so that the data manifold is well-sampled, but retrieval task may also be needed in small datasets. Second, the requirement for real-time retrieval is usually declared, and it is time-consuming to solve the least square optimization problem for each query presented in Eq. ( <ref type="formula">8</ref>). On the other hand, the image is represented by a set of vectors instead of a single vector in some cases (e.g. shape analysis in <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>), which makes the above optimization problem more difficult to solve. Hence, we just apply the (truncated) Gaussian kernel to the pairwise distances with the given query x q , and the membership function is defined as</p><formula xml:id="formula_9">F q,p = exp (-d(x q , x p )) if x p ∈ N k (x q ) 0 otherwise. (<label>9</label></formula><formula xml:id="formula_10">)</formula><p>As a result, the top-ranked neighbors are assigned larger membership grades. F q is subsequently L 1 normalized according to the sum-to-one constraint, and used for re-ranking through Jaccard distance defined in Eq. <ref type="bibr" target="#b6">(7)</ref>. In this way, the Jaccard distance is generalized to non-binary vectors. In summary, the neighbors of x q actually act as Local Coordinate System, and we can get a Sparse Contextual Activation denoted by F q for x q through Eq. ( <ref type="formula" target="#formula_9">9</ref>). The "Contextual" here indicates that F q has non-zero values only in the index where the neighbors of x q are located. Usually the cardinality of N k (x q ) is much smaller than the size of the entire dataset, so the contextual activation is also a sparse vector. The property of sparsity is crucial in our algorithm. With this constraint, the negative influences of unreliable references are eliminated. What is more important is that the calculation of Jaccard distance in Eq. ( <ref type="formula" target="#formula_7">7</ref>) can be accelerated using inverted file as presented in Section III-C. In Fig. <ref type="figure" target="#fig_0">1</ref>, we give an illustration of our proposed Sparse Contextual Activation (SCA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Inverted Index Embedding</head><p>The proposed Sparse Contextual Activation (SCA) already manages assigning different weights to the neighbors at different positions in the ranking list, and gives a vector representation used for re-ranking. However, distance computation between a pair of SCAs is also waste of time, especially when the size of database becomes larger. Although the length of SCA is equal to the size of image database N , but the number of non-negative values in SCA is independent, only determined by the cardinality of neighborhood set. Considering the sparsity property of SCA, we introduce the inverted index <ref type="bibr" target="#b9">[10]</ref> to reduce the computation complexity significantly. Inverted index is a scalable indexing structure to store a large collection of images with their features. Although it has been applied to image retrieval successfully (e.g. <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>), it is the first work that introduces inverted index to visual re-ranking to our best knowledge now. Moreover, different from the usage of inverted index in Minkowski metric (Euclidean distance, Manhattan distance, etc.), we prove the feasibility of applying it in the metric of Jaccard distance theoretically.</p><p>Given two sparse contextual activations F q and F p , the M IN operation can be computed as</p><formula xml:id="formula_11">M IN (F q , F p ) 1 = i|Fq,i =0,Fp,i =0 min(F q,i , F p,i ) + i|Fq,i=0 min(F q,i , F p,i ) + i|Fp,i=0</formula><p>min(F q,i , F p,i ). <ref type="bibr" target="#b9">(10)</ref> Since the sparse contextual activation only contains nonnegative values, it is easy to find that last two items in Eq. ( <ref type="formula">10</ref>) are equal to zero. So the M IN operation can be achieved much more efficiently by <ref type="bibr" target="#b10">(11)</ref> and it is only a query-dependent operation.</p><formula xml:id="formula_12">M IN (F q , F p ) 1 = i|Fq,i =0,Fp,i =0 min(F q,i , F p,i ),</formula><p>By contrast, the computation of the M AX operation seems to be a bit complicated, since the item i|Fq,i=0 max(F q,i , F p,i ) = i|Fq,i=0 F p,i is not only determined by the query side. However, we also offer an efficient way to calculate the M AX operation. Note that</p><formula xml:id="formula_13">F q 1 + F p 1 = M IN (F q , F p ) 1 + M AX(F q , F p ) 1 .</formula><p>For two L 1 normalized sparse contextual activation, we can get In summary, our structure of inverted index is built as follows: (1) It has N entries as Fig. <ref type="figure" target="#fig_1">2</ref> shows, where N is the size of database. Each entry relates to an image that acts as a base for activation. (2) For each entry p, we store the IDs of images whose neighborhood sets contain x p and the corresponding membership grades. In other words, x p owns non-zero membership grades in these neighborhood sets. (3) When re-ranking for the query x q , distance computation can be conducted in a much smaller space using Eq. ( <ref type="formula">11</ref>) and Eq. ( <ref type="formula" target="#formula_14">12</ref>) as inverted index usually does.</p><formula xml:id="formula_14">M AX(F q , F p ) 1 = 2 -M IN (F q , F p ) 1 , = 2 - i|Fq,i =0,Fp,i =0 min(F q,i , F p,i ). (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>Different from the inverted index on local descriptors in the paradigm of Bag of Words (BoW) model <ref type="bibr" target="#b3">[4]</ref>, our inverted index for re-ranking can be assumed as the second-level index, which is used in the level of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Local Consistency Enhancement</head><p>The images from the same category are expected to own the same neighborhood set, so that the distances between their sparse contextual activations are small. However, the neighborhood set is determined using k-nearest neighbors rule, which may be the simplest and the most efficient principle. Indeed, one can identify the neighborhood set by using more sophisticated rules (e.g. dominant neighbors <ref type="bibr" target="#b16">[17]</ref>), but it will increase the computational time dramatically. Any extra time cost is not what we want in the proposed algorithm.</p><p>Inspired by the query expansion <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> and local relevance feedback <ref type="bibr" target="#b43">[44]</ref> in information retrieval, we propose to enhance the local consistency in generating SCAs of images from the same category using a similar way. In more detail, we define the Local Consistency Enhancement (LCE) on the sparse contextual activation as</p><formula xml:id="formula_16">F q := 1 |N k (x q )| i∈N k (xq) F i ,<label>(13)</label></formula><p>by speculating that the images which are located very high in the initial ranking list of the query x q are from the same category as the query. In our experiment, LCE is applied only once, both in the query side and database side.</p><p>In order to confirm our conjecture, an empirical analysis is performed on Princeton Shape Benchmark (PSB) <ref type="bibr" target="#b44">[45]</ref>. We plot the percentage of true positives at the k-th position in the ranking list for all the queries. It can be seen that the percentage of true positives decreases with the value of k increasing, and it is extremely high when k is small. Note that several false positives also exist at smaller value of k, which is known as query drift, but the small percentage of false positives will not impair the whole performance too much. Algorithm 1: The pseudocode of SCA.</p><p>Input: D = {d(x q , x p )}, ∀x ∈ X: the original distance matrix; k 1 : the size of neighborhood set; k 2 : the parameter in local consistency enhancement.</p><p>Output:</p><formula xml:id="formula_17">DJ = { dJ (x q , x p )}, ∀x ∈ X: the refined distance matrix; begin for i = 1 to N do Determine N k (x i ) using k 1 .</formula><p>Compute F i according to Eq. ( <ref type="formula" target="#formula_9">9</ref>).</p><formula xml:id="formula_18">if k 2 = 1 then for i = 1 to N do Determine N k (x i ) using k 2 .</formula><p>Enhance F i according to Eq. ( <ref type="formula" target="#formula_16">13</ref>).</p><p>Build inverted file on F i , 1 ≤ i ≤ N ; for x q ∈ X do Determine non-zero entries of x q in inverted file.</p><p>Estimate dJ (x q , x p ) according to Eq. ( <ref type="formula">11</ref>) and Eq. ( <ref type="formula" target="#formula_14">12</ref>), ∀x p ∈ X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>return DJ</head><p>Based on the above analysis, the proposed LCE is an unsupervised method that does not need to know the labels. Compared with sparse contextual activation that considers the information from the direct neighbors of x q , LCE is defined to consider the neighbors of the second order (i.e. the neighbors of the neighbors of x q ). As a result, LCE is more likely to include noise and outliers. Hence, we restrict the size of the neighborhood set used in LCE to a much smaller value in the experiments.</p><p>In order to distinguish the two neighborhood sets, both derived from the original distance space d, used in sparse contextual activation (Eq. ( <ref type="formula" target="#formula_9">9</ref>)) and local consistency enhancement (Eq. ( <ref type="formula" target="#formula_16">13</ref>)), we denote the size of the former one as k 1 and that of the latter one as k 2 below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SPARSE CONTEXTUAL ACTIVATION WITH MULTIPLE DISTANCE MEASURES</head><p>The proposed Sparse Contextual Activation presented above deals with only one input distance measure. In this section, we present how to introduce our method into rank aggregation for multiple input distance measures. We take two input distance measures as an example.</p><p>Let f α and f β denote two feature extractor functions for images, and d α and d β represent the corresponding distance functions respectively. Then for the image x q with the feature extractor f α (or f β ), we can also achieve the neighborhood set N α k (x q ) (or N β k (x q )).</p><p>High Set and Low Set. Given a query image x q and its two neighborhood sets N α k (x q ) and N β k (x q ). We call the intersection set of the two neighborhood sets High Set, which can be described as</p><formula xml:id="formula_19">N (H) k (x q ) = N α k (x q ) ∩ N β k (x q ),<label>(14)</label></formula><p>and call the union set Low Set as</p><formula xml:id="formula_20">N (L) k (x q ) = N α k (x q ) ∪ N β k (x q ).<label>(15)</label></formula><p>The "high" indicates that the images in the high set are more likely to be true positives, since the images in the set occupy top positions in two ranking lists achieved by two distance functions d α and d β . By contrast, the low set may contains more false positives, for it is defined with a looser constraint, i.e. the images will be assigned to the low set as long as they are ranked high by either d α or d β .</p><p>In order to perform extremely fast rank aggregation later, we also generate the sparse contextual activations for high set and low set similarly. In more detail, let F α q (or F β q ) denote the sparse contextual activation of x q computed using Eq. ( <ref type="formula" target="#formula_9">9</ref>) under the distance measure d α (or d β ). The membership functions of high set and low set are defined respectively based on Eq. (3) and Eq. ( <ref type="formula" target="#formula_5">4</ref>)</p><formula xml:id="formula_21">N (H) k (x q ) ⇐⇒ F (H) q = M IN F α q , F β q ,<label>(16)</label></formula><formula xml:id="formula_22">N (L) k (x q ) ⇐⇒ F (L) q = M AX F α q , F β q . (<label>17</label></formula><formula xml:id="formula_23">)</formula><p>As a result, two sparse contextual activations F (H) q and F (L) q , corresponding with high set and low set respectively, are achieved for x q .</p><p>One can find that we perform feature fusion naturally by defining the two sets, so the unsupervised estimation about the weights of two individual features during fusion procedure are avoided. As we all know, different features are often in different scales or measured by different statistics, which makes the weight learning in feature fusion difficult, especially in an unsupervised way. Our proposed sparse contextual activation for feature fusion is simple yet delicate. It does not require any complicated learning or optimization methods.</p><p>Distance Fusion. After getting two sparse contextual activations for each image in the database, we define the distance measure for rank aggregation as</p><formula xml:id="formula_24">dJ (x q , x p ) = 1 - 1 2 I=H,L N i=1 min F (I) q,i , F (I) p,i N i=1 max F (I) q,i , F (I) p,i .<label>(18)</label></formula><p>The contribution of high set and low set are treated equally, which avoids the parameter tuning at the stage. It seems that the individual performance of high set is better than low set, due to its high percentage of true positives. The true fact is that the definition of high set may be too strict in the specific scenario of re-ranking. In some cases (especially when parameter k 1 not large enough), a much small number of images will be assigned to the high set, which deprives its discriminative ability. However, with k 1 increasing, the individual performance of high set will surpass low set after a certain threshold without doubt. We will experimentally the performance difference between high set and low set in Section V-E, and prove that a simple linear combination of them is better than using either one only.</p><p>It should be mentioned that the inverted index (Section III-C) and local consistency enhancement (Section III-D) can also be introduced into this feature fusion paradigm. The two additional methods can improve the efficiency and accuracy remarkably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In this section, we will evaluate the performance of the proposed Sparse Contextual Activation (SCA) in various visual re-ranking task. The datasets we use are Princeton Shape Benchmark (PSB) <ref type="bibr" target="#b44">[45]</ref>, Watertight Models track of SHape REtrieval Contest 2007 dataset (WM-SHREC07) <ref type="bibr" target="#b45">[46]</ref>, YALE face dataset B <ref type="bibr" target="#b46">[47]</ref>, and MPEG-7 shape dataset <ref type="bibr" target="#b47">[48]</ref> and Ukbench image dataset <ref type="bibr" target="#b9">[10]</ref>. The discussion about the parameter settings and the analysis of the algorithm complexity are presented in Section V-E and Section V-F respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. 3D Object Retrieval</head><p>In this section, we show the application of the proposed SCA to 3D object retrieval on the well-known Princeton Shape Benchmark (PSB) <ref type="bibr" target="#b44">[45]</ref> and Watertight Models track of SHape REtrieval Contest 2007 dataset (WM-SHREC07) <ref type="bibr" target="#b45">[46]</ref>.</p><p>The PSB benchmark contains 1,804 3D polygonal models, which are divided into training set and testing set with 907 models each. Following the common settings, only the testing set is used to evaluate the performance of 3D object retrieval. The testing set is spilt into 92 categories, and the number of models per category ranges from 4 to 50.</p><p>SHape REtrieval Contest (SHREC) is the most authoritative competition for evaluating the effectiveness of 3D object retrieval algorithms. It will be held each year, involving multiple tracks, such as sketch-based 3D retrieval, textured 3D retrieval, etc.. In this paper, WM-SHREC07 is chosen, which consists of 400 watertight mesh models that are evenly distributed into 20 classes. The models exhibit sufficient and diverse variation, from pose change to shape variability in the same semantic category. evaluation metrics are adopted to assess the retrieval performance, listed as follows:</p><p>• Nearest Neighbor (NN): the percentage of the closest matches that belongs to the same class as the query. • First Tier (FT): the recall for the top C -1 matches in the ranked list, where C is the number of shapes in the category that query belongs to.</p><p>• Second Tier (ST): the recall for the top 2(C -1) matches in the ranked list, where C is the number of shapes in the category that query belongs to. • Discounted Cumulative Gain (DCG): a statistic that attaches more importance to the correct results near the front of the ranked list than the correct results at the end of the ranked list, under the assumption that a user is more likely to consider the retrieved candidates in the front of the list. Please refer to <ref type="bibr" target="#b44">[45]</ref> for more details about the definition of NN, FT, ST and DCG if needed. The values of all the aforementioned metrics range from 0 to 1, and larger values indicate better performance.</p><p>In the 3D object retrieval task, we use two view-based baseline methods (one is Vector of Aggregated Local Descriptor (VLAD) <ref type="bibr" target="#b48">[49]</ref>, and the other one is deep learned with Convolutional Neural Network (CNN)). For VLAD, we use the same pipeline as <ref type="bibr" target="#b49">[50]</ref>. The number of depth views is set to 64, and the codebook size is 2048. For the deep feature, we utilize the descriptor proposed in <ref type="bibr" target="#b50">[51]</ref>.</p><p>We first demonstrate the performance of different re-ranking algorithms using the same baseline methods (i.e., VLAD and deep feature) in Table <ref type="table">I</ref>, and FT is chosen as the evaluation metric. When computing SCA, we fix the size of neighborhood set k 1 to 10 for PSB dataset and 17 for WM-SHREC07 dataset, and the parameter k 2 for local enhancement to 4. We report the performances of some typical re-ranking algorithms (Self diffusion (SD) <ref type="bibr" target="#b10">[11]</ref>, Tensor Product Graph (TPG) <ref type="bibr" target="#b16">[17]</ref>, Locally Constrained Diffusion Process (LCDP) <ref type="bibr">[8]</ref>) in the optimal parameter setup.</p><p>It can be observed that our proposed SCA achieves the best performance among all the compared re-ranking methods. SD obtains the worst results since it loses the constraint of "locality" used in LCDP and TPG. The percent gain in performance of LCDP and TPG in PSB dataset is not as large as in WM-SHREC07. It can be explained in two aspects: the first one is that the baseline in PSB dataset is much lower than that in WM-SHREC07 dataset, which means that it will include more noise and outliers in the neighborhood set; the second one is that the number of objects per category in PSB dataset is various. By contrast, the distribution of objects in WM-SHREC07 is exactly balanced, i.e. 20 objects are assigned to one category. The imbalanced distribution of objects in PSB dataset makes kNN rule difficult to generalize well. Nevertheless, our proposed SCA also performs stably and well in both datasets although kNN is used to define the neighborhood set.</p><p>The comparison with other state-of-the-art algorithms are presented in Table <ref type="table" target="#tab_2">II</ref>. As we can see, our proposed SCA achieves the new state-of-the art performance among all other algorithms for all the four evaluation metrics by fusion VLAD and deep feature in both datasets. PANORAMA is one of the most representative 3D shape descriptors in recent years, and our proposed SCA outperforms it by 8.4% in NN, 22.1% in FT and 20.7% in ST in PSB dataset. In <ref type="bibr" target="#b43">[44]</ref>, the performance of PANORAMA is improved by large margins using Local Relevance Feedback (LRF). LRF also exploits the contextual contribution as SCA, and the superior results reveal the Algorithm Bull's eye score</p><p>Graph Transduction <ref type="bibr" target="#b2">[3]</ref> 68.70% Self Diffusion <ref type="bibr" target="#b10">[11]</ref> 71.46% Tensor Product Graph <ref type="bibr" target="#b16">[17]</ref> 75.32% Locally Constrained Diffusion Process <ref type="bibr">[8]</ref> 75.59% Generic diffusion <ref type="bibr" target="#b1">[2]</ref> 77.30% SCA 77.80% effectiveness of our proposed method. Among the all compared methods, 2D/3D Hybrid [57], PANORAMA <ref type="bibr" target="#b43">[44]</ref> and 3DVFF <ref type="bibr" target="#b58">[59]</ref> consider the fusion of multiple complementary features in the hope of more robust distance measure. 2D/3D Hybrid just simply concatenates 2D features based on depth buffers and 3D features based on spherical harmonics, and the dissatisfactory performance verifies the importance of designing more discriminative feature fusion methods. 3DVFF employs Multi-Feature Anchor Manifold that approximates multiple manifolds of heterogeneous features, which can be assumed as one variant of diffusionbased re-ranking methods. SCA also leads to a better retrieval accuracy than 3DVF in DCG (DCG is the only widelyaccepted evaluation metric adopted in <ref type="bibr" target="#b58">[59]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Face Retrieval</head><p>We also evaluate the performance of SCA in face retrieval on YALE face dataset B <ref type="bibr" target="#b46">[47]</ref>. YALE face dataset B is a standard benchmark widely used for face clustering, which is composed of face images sharing various poses and illumination conditions. In order to keep the comparison fair, we use the same subset and the same baseline method as generic diffusion framework <ref type="bibr" target="#b1">[2]</ref>. Specifically, 15 subjects with 11 different conditions are gathered to generate a new dataset. Each image is normalized to 0-mean and 1-variance, and Euclidean distance between the vectorized representations is adopted to measure the pairwise dissimilarity directly. The evaluation metric is bull's eye score, which counts the recall before top-15 ranking list.</p><p>The baseline bull's eye score for the selected subset is 69.48%. Note that our goal is not achieving superior retrieval performance in this dataset, since better performance can be obtained easily by using more discriminative descriptors, such as LBP <ref type="bibr" target="#b59">[60]</ref>, etc.. Instead, we focus on the performance improvement by our proposed re-ranking method. In <ref type="bibr" target="#b1">[2]</ref>, a classical branch of re-ranking methods called diffusion process is summarized, so the comparison with these methods will be more convincing. Similar to SCA, diffusion-based re-ranking methods capture the structure of the underlying data manifold by using the contextual information. The primary difference is that they propagate the affinity values with random walks on a pre-defined graph in an iterative manner, while SCA does not need the iterative procedure that is often of great computational cost. We refer the readers to <ref type="bibr" target="#b1">[2]</ref> for more details about diffusion process if necessary.  In Table <ref type="table" target="#tab_2">III</ref>, the retrieval performances resulting from other state-of-the-art methods and our proposed method are reported. All the numerical results are borrowed from <ref type="bibr" target="#b1">[2]</ref> or computed by using the public-available codes. When computing our sparse contextual activation, we manually set the size of neighborhood set k 1 to 4, and the parameter k 2 for local consistency enhancement to 5.</p><p>As we can see from the table, SCA outperforms Self Diffusion (SD) <ref type="bibr" target="#b10">[11]</ref>, Tensor Product Graph (TPG) <ref type="bibr" target="#b16">[17]</ref>, Locally Constrained Diffusion Process (LCDP) <ref type="bibr">[8]</ref> by 6.34%, 2.48% and 2.21%. As for the generic diffusion process, it enumerates all the variants of diffusion process by using four different types of initialization, six different types of transition and matrices and three different update schemes. The bull's eye score of the generic version of diffusion process is chosen as the best performance for all the variants. However, SCA also achieves 77.80%, which is the best performance among all re-ranking methods, including the generic diffusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Shape Retrieval</head><p>Finally, we test our method for shape retrieval on MPEG-7 dataset <ref type="bibr" target="#b47">[48]</ref>. It consists of 1,400 binary images divided into 70 categories evenly. Bull's eye score is used to evaluate the performance, which counts the recall in the top-40 ranking list. We use the same baseline methods as Co-transduction <ref type="bibr" target="#b28">[29]</ref>, where Shape Context (SC) <ref type="bibr" target="#b37">[38]</ref> and Inner Distance Shape Context (IDSC) <ref type="bibr" target="#b38">[39]</ref> are used as the raw descriptors.</p><p>The comparison with other state-of-the-art algorithms is presented in Table <ref type="table" target="#tab_4">IV</ref>. In order to improve the readability of the comparison, the table is divided into three parts with each Descriptor Re-ranking algorithm Score SC -86.80% GT <ref type="bibr" target="#b2">[3]</ref> 92.91% SCA 95.21% IDSC -85.40% CDM <ref type="bibr" target="#b0">[1]</ref> 88.30% Indexing Re-Ranking <ref type="bibr" target="#b5">[6]</ref> 91.56% GT <ref type="bibr" target="#b2">[3]</ref> 91.61% Pairwise Recom. <ref type="bibr" target="#b60">[61]</ref> 92.21% RL-Sim <ref type="bibr" target="#b18">[19]</ref> 92.62% LCDP <ref type="bibr">[8]</ref> 93.32% SSP <ref type="bibr" target="#b4">[5]</ref> 93.35% SCA 93.44% SC+IDSC -92.16% Co-T <ref type="bibr" target="#b28">[29]</ref> 97.72% LCMD <ref type="bibr" target="#b6">[7]</ref> 98.84% SCA 99.01%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE IV THE PERFORMANCE COMPARISON WITH OTHER STATE-OF-THE-ART</head><p>ALGORITHMS ON MPEG-7 DATASET.</p><p>part using the same baseline method. The baseline of the direct sum of SC and IDSC is 92.16%. As we can see, our proposed SCA leads to the best performance in each part by setting k 1 to 7 and k 2 to 4, and improves the baseline method by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Natural Image Retrieval</head><p>We first demonstrate the performance of SCA for natural image retrieval in Ukbench image dataset <ref type="bibr" target="#b9">[10]</ref>, which consists of 10,200 images. The whole dataset is divided into 2,550 categories with only 4 images per category. Each image is   <ref type="bibr" target="#b32">[33]</ref> a , <ref type="bibr" target="#b34">[35]</ref> a AND <ref type="bibr" target="#b32">[33]</ref> b , <ref type="bibr" target="#b34">[35]</ref> b IS THE METHODS WITH SUPERSCRIPT "b" USE THE ADDITIONAL GRAPH FUSION ALGORITHM PROPOSED IN <ref type="bibr" target="#b26">[27]</ref>. <ref type="bibr" target="#b26">[27]</ref> a AND <ref type="bibr" target="#b26">[27]</ref> b DENOTE GRAPH PAGERANK AND GRAPH DENSITY RESPECTIVELY.</p><p>used in turn as a query. The performance is measured by the average recall of the top four ranked images, referred as N-S score (maximum is 4). The limited ground-truth images per category makes it challenging to achieve good performance for context-based re-ranking methods. We implement two baseline methods using a local feature and a holistic feature. For local feature, SIFT <ref type="bibr" target="#b33">[34]</ref> descriptors are extracted at Hessian-affine <ref type="bibr" target="#b61">[62]</ref> interest points, and RootSIFT <ref type="bibr" target="#b21">[22]</ref> variant is used. We train the codebook of size 1M using K-means on the independent Flickr60k data <ref type="bibr" target="#b41">[42]</ref>. The Bag-of-Words (BoW) feature is computed with hardassignment and TF-IDF weighting <ref type="bibr" target="#b42">[43]</ref>. For holistic feature, we use the 1000-dimensional HSV color histogram (20×10×5 bins for H, S, V components) following <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b32">[33]</ref>. The HSV histogram is first normalized by its L 1 norm, and finally each element of the histogram is square rooted. The baselines of SIFT and HSV histogram are 3.56 and 3.40 respectively.</p><p>We compare our proposed SCA with several state-of-the-art algorithms in Table <ref type="table" target="#tab_4">V</ref>. For computing the sparse contextual activation, the size of neighborhood set k 1 is to 4. The parameter for enhancement enhancement k 2 is set to 2 empirically.</p><p>In order to keep the comparison fair, we first compare those methods which use only single feature, but different extra improvements. These selected methods are L p norm ID-F <ref type="bibr" target="#b42">[43]</ref>, Vector of Aggregated Local Descriptors (VLAD) <ref type="bibr" target="#b48">[49]</ref>, Triangulation embedding <ref type="bibr" target="#b62">[63]</ref>, Spatial Contextual Weighting (SCW) <ref type="bibr" target="#b63">[64]</ref>, Tensor Product Graph (TPG) <ref type="bibr" target="#b16">[17]</ref>, Burstiness <ref type="bibr" target="#b40">[41]</ref>, RNN re-ranking <ref type="bibr" target="#b64">[65]</ref> and Contextual Dissimilarity Measure <ref type="bibr" target="#b0">[1]</ref>.</p><p>As shown in Table <ref type="table" target="#tab_4">V</ref>, our proposed SCA improves the baseline of SIFT from 3.56 to 3.69 and improves the baseline of HSV histogram from 3.40 to 3.56, which makes a significant gain in performance. The performances of Graph Transduction (GT) <ref type="bibr" target="#b2">[3]</ref> are also implemented by us using the same features as those of SCA, which are 3.60 for SIFT feature and 3.53 for HSV histogram respectively. Among those methods, GT, TPG, RNN re-ranking and CDM follow the similar principle with our method. They all attach importance to the local context of a given image in the manifold and adopt an iterative to update the similarity measure, but achieve inferior performances compared with SCA, which does not need to iterate until convergence. It can be drawn that SCA can get better performances by exploiting a more reliable distance measure with higher time efficiency.</p><p>The performance comparison of the algorithms using multifeature is also conducted in Table <ref type="table" target="#tab_4">V</ref>. We list nearly all the feature fusion algorithms which report their N-S scores to my best knowledge now, including Co-indexing <ref type="bibr" target="#b35">[36]</ref>, Coupled Binary Embedding <ref type="bibr" target="#b34">[35]</ref>, Bayes <ref type="bibr" target="#b65">[66]</ref>, Co-transduction <ref type="bibr" target="#b28">[29]</ref>, CrDP <ref type="bibr" target="#b66">[67]</ref>, c-MI <ref type="bibr" target="#b32">[33]</ref> and Graph Fusion <ref type="bibr" target="#b26">[27]</ref>.</p><p>Graph Fusion is a representative re-ranking algorithm which deals with multiple input features. The performances of two variants of Graph Fusion, Graph PageRank and Graph Desnity, are 3.76 and 3.77 respectively. By contrast, our proposed feature fusion strategy with SIFT and HSV histogram achieves 3.86 N-S score. Considering that c-MI <ref type="bibr" target="#b32">[33]</ref> b and Coupled Binary Embedding <ref type="bibr" target="#b34">[35]</ref> b actually fuse three features (fuse SIFT and color descriptor at the indexing level, and HSV histogram descriptor is also combined at the post-processing level), it seems unfair to compare them with SCA, since we actually utilize two features only. However, as can be seen from the table, the performance of SCA is also higher than both of them. Compared with our baseline methods used here, we improve the performance from 3.40 (HSV histogram) and 3.56 (SIFT) to 3.86 significantly. The superior performance demonstrates the discriminative power of our SCA-based feature fusion algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Discussion</head><p>Two important parameters are involved in our method: the size of neighborhood set k 1 in sparse contextual activation and the size of neighborhood set k 2 for local consistency enhancement. In this section, we will discuss their effect on the retrieval performance, and compare with the Jaccard reranking to show the performance improvement brought by SCA simultaneously.</p><p>The parameter k 1 . The performance of standard Jaccard distance (Eq. ( <ref type="formula" target="#formula_1">1</ref>)) and the proposed sparse contextual activation (Eq. ( <ref type="formula" target="#formula_7">7</ref>)) with regard to the value of k 1 are reported in Fig. <ref type="figure" target="#fig_3">4</ref>. We utilize N-S score for Ukbench dataset and First Tier for PSB dataset to evaluate the retrieval performance.</p><p>It can be observed that SCA outperforms the standard Jaccard distance consistently when the size of neighborhood set k 1 varies, which demonstrates firmly that it is beneficial to bring the weights into account such that the importance of top-ranked images is increased. On the other hand, we can find that when k 1 increase, the performance first increases and drops later after k 1 reaches a certain threshold. It is easy to understand the decreasing of performance when k 1 is relatively larger, owing to the fact that the percentage of false positives will increase in that case.</p><p>The parameter k 2 . In Fig. <ref type="figure" target="#fig_4">5</ref>, we discuss the effect the  parameter used in local consistency enhancement by fixing the size of neighborhood set to 4 for Ukbench dataset and 10 for dataset following Section V-D and Section V-A respectively. Note that when k 2 is equal to 1, the local consistency enhancement is not applied at all. Hence, the performances of SCA and SCA with local consistency enhancement are identical at the starting point of the curves in Fig. <ref type="figure" target="#fig_4">5</ref>.</p><p>It is observed that when local consistency enhancement is applied by using a proper factor k 2 , the performance of sparse contextual activation can be improved further. Such a phenomenon demonstrates our previous analysis in Section III-D. It should also be mentioned that if a much larger k 2 is used, the performance will decease without question. Since local consistency enhancement considers the contributions from the neighbors of the second order, it is easier to include the negative effects of noise and outliers compared with only using the direct neighbors (i.e., the neighbors of the first order). However, we find local consistency enhancement of great help to improve the retrieval performance when k 2 is small. Metric. Note that our sparse contextual activation is computed using Eq. ( <ref type="formula" target="#formula_7">7</ref>), a generalized version of Jaccard distance. Indeed, many other metrics can be used here despite the fact that these metrics cannot be interpreted well using the set  theory, such as L r distance 1 , χ 2 distance 2 and Hellinger distance 3 .</p><p>In Table <ref type="table" target="#tab_6">VI</ref>, we list the performances of sparse contextual activation with LCE or without LCE under different metrics in PSB dataset. The baseline method is the deep feature and First Tier is chosen as the evaluation measure. We can find that the metric defined in Eq. ( <ref type="formula" target="#formula_7">7</ref>) outperforms all the other evaluation metrics. The performance of the widely-used Euclidean distance is not satisfactory enough.</p><p>Discussion on rank aggregation. In Fig. <ref type="figure">6</ref>, we compare the 1 The Lr distance for two SCAs Fq and Fp is</p><formula xml:id="formula_25">( N i |F q,i -Fp i | r ) 1 r</formula><p>2 The χ 2 distance for two SCAs Fq and Fp is 1</p><formula xml:id="formula_26">2 N i (F q,i -F p,i ) 2 F q,i +F p,i<label>3</label></formula><p>The Hellinger distance for two SCAs Fq and Fp is  performances of using low set alone, using high set alone and using the linear combination of high set and low set. First, as the figure shows, the performances of high set and low set reach the peak at different values of k 1 , and this value for low set is usually smaller than that for high set. Second, the two curves that represents the performance of high set and low set have a intersection point, before which the performance of set is superior to high set. At last, the linear combination of high set and low set is always better than using either one alone.</p><formula xml:id="formula_27">N i ( F q,i -Fp i ) 2<label>1057</label></formula><p>Feature Weight. In Eq. ( <ref type="formula" target="#formula_24">18</ref>), high set and low set are combined linearly with equal weights for rank aggregation task. To clarify the influence of weight, an experiment on PSB dataset is conducted by setting the weight of high set to w, and that of low set to 1 -w. ranges from 0 1 with a step size of 0.1, and the influence of w on retrieval performance (First Tier) is given in Fig. <ref type="figure">7</ref>. As the figure shows, a linear combination of high set and low set outperforms their individual counterpart (w = 0 or 1), which is consistent to previous analysis. The best performance is achieved when w is around 0.5. However, the performance only changes a little or remains the same when w shifts to 0.4 or 0.6. Hence, we set the default value of w to 0.5 for simplicity. Note that one can learn the weights automatically if some prior information (e.g. the baseline performances) is known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Complexity Analysis</head><p>Considering that SCA is a post-processing procedure that focuses on re-ranking instead of ranking initialization, we only analyse the time efficiency and memory cost after the original ranking are given. The operation in the pre-processing, such as feature extraction, feature quantization, pairwise distance computation, etc., are beyond the scope of our concern. Time Complexity. Given an image collection with N elements and their pairwise distances known, the computation of the sparse contextual activation for an given image x q requires the computational complexity O(k 1 ), where k 1 is the size of the neighborhood set. When local consistency enhancement determined by the parameter k 2 is applied, the computation time cost for SCA is equivalent to O(k 2 ×k 1 ). We can find that the initiation of SCA is independent of the image collection size N , but related to the size of the local distribution around q on the manifold. Usually, the values of k 1 and k 2 are much smaller than N , which indicates that the computation of SCA for a single image can be assumed to achieve in O(1) efficiently.</p><p>As for re-ranking with SCA, the direct computation of the distance between x q and all the other images in the database requires O(2 × N 2 ). However, the time complexity can be reduced significantly by using inverted index as presented in Section III-C. Embedded with inverted index, the M IN operation needs O(M ×k 1 ) through Eq. ( <ref type="formula">11</ref>) in the worst case, where M denotes the number of images that have overlaps in neighborhood sets with x q . M AX only needs O(M ) through Eq. ( <ref type="formula" target="#formula_14">12</ref>). In summary, the time complexity is reduced from O(2 × N 2 ) to O (M × (k 1 + 1)) by introducing the inverted index. In fact, the value of M is also much smaller than N (e.g., for the HSV histogram in Ukbench dataset, the average value of M is merely 7.46).</p><p>All our experiments are carried out on a desktop machine with an Intel(R) Core(TM) i5 CPU (3.40 GHz) and 16 GB memory. In Ukbench dataset, the generation of SCA takes 0.14ms and local consistency enhancement takes 0.36ms per image. It takes 0.33s to build the inverted index for the whole dataset. For a given query, the average cost for re-ranking is only 0.39ms.</p><p>Methods Jaccard TPG <ref type="bibr" target="#b16">[17]</ref> LCDP <ref type="bibr">[8]</ref> SCA  Many previous re-ranking algorithms (e.g. <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>) are time-consuming due to their high time complexity (O(N 3 ) in most cases). They usually need an iterative procedure to spread the affinity values on a huge graph which establishes the relationship among all the images. Table VII compares the average time for re-ranking of some typical algorithms, including Jaccard re-ranking defined in Eq. ( <ref type="formula" target="#formula_1">1</ref>). As the table shows, SCA reduces the time cost of Jaccard re-ranking by more than 8,000 times in Ukbench dataset when inverted index is applied. Compared with the two representative diffusionbased re-ranking methods, SCA is 90 times faster than LCDP, and 9,800 times faster than TPG. It indicates that our proposed re-ranking method has the potential for large scale re-ranking task.</p><p>Space Complexity. The scale of the inverted index is equivalent to the number of images in the database, which indicates the space complexity of SCA is O(N ).</p><p>For each entry in the inverted index used for re-ranking, we use 4 bytes to store one image index. 4 bytes (single format) are used to denote the activation for a certain image. On the Ukbench dataset, it only takes 65.2KB to save the inverted index in our implementation. Considering the big improvement on the computational efficiency, the minor extra memory cost can be tolerated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION AND FUTURE WORK</head><p>In this paper, we propose an extremely efficient algorithm called Sparse Contextual Activation (SCA) for visual reranking. SCA is a merely single vector that encodes the contextual distribution for an image. The re-ranking procedure can be simply conducted by vector comparison using generalized Jaccard distance. For the first time, inverted index is introduced into re-ranking task, which makes is possible that re-ranking for a single query can be finished within one millisecond. Local Consistency Enhancement (LCE) is also developed to improve the performance of SCA further. The experimental results on PSB dataset (3D object), WM-SHREC07 (3D competition), YALE dataset B (face), MPEG-7 dataset (shape) and Ukbench dataset (natural image) demonstrate the effectiveness and efficiency of the proposed method.</p><p>Note that we design an inverted index for visual re-ranking, so an efficient method about the dynamical of insertion, deletion and modification should be taken into consideration. Meanwhile, since SCA is defined in the context, it requires for accurate contextual distribution if possible. So does it benefit from adding more extra images or artificial ghost points <ref type="bibr" target="#b67">[68]</ref> to densify the feature space? Moreover, as SCA provides a more efficient and effective similarity measure similar to diffusion process, it can be potentially applied to other important tasks such as image segmentation <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b68">[69]</ref>, image matching/registration <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>, visual object tracking <ref type="bibr" target="#b12">[13]</ref>, and analysis of medical data <ref type="bibr" target="#b71">[72]</ref>. We leave all these problems for the future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FFig. 1 .</head><label>1</label><figDesc>Fig. 1. The illustration of sparse contextual activation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FFig. 2 .</head><label>2</label><figDesc>Fig. 2. The inverted index for re-ranking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The distribution of the percentage of true positives at the k-th position in the ranking list for all the queries. "VLAD" and "Deep" denote two visual features used in our experiment. Please refer to Section V-A for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The impact of the neighborhood set size on retrieval accuracy. N-S score for Ukbench (a), and First Tier for PSB (b) are presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The impact of the parameter k 2 in local consistency enhancement on retrieval accuracy. N-S score for Ukbench (a) and First Tier for PSB (b) are presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. The discussion about rank aggregation. The performances of high set, low set and their combination are presented. N-S score for Ukbench (a), First Tier for PSB (b) are presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II THE</head><label>II</label><figDesc>PERFORMANCE COMPARISON WITH OTHER STATE-OF-THE-ART ALGORITHMS ON PSB DATASET AND WM-SHREC07 DATASET.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V THE</head><label>V</label><figDesc>PERFORMANCE COMPARISON WITH STATE-OF-THE-ART METHODS IN UKBENCH DATASET. THE DIFFERENCE BETWEEN</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI THE</head><label>VI</label><figDesc>PERFORMANCE COMPARISON OF SCA UNDER DIFFERENT METRICS.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2016.2514498, IEEE Transactions on Image Processing</figDesc><table /><note><p>-7149 (c) 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VII THE</head><label>VII</label><figDesc>COMPARISON OF AVERAGE RE-RANKING TIME.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Accurate image search using the contextual dissimilarity measure</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Harzallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="11" />
			<date type="published" when="2009">2010. 1, 2, 8, 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diffusion processes for retrieval revisited</title>
		<author>
			<persName><forename type="first">M</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<meeting><address><addrLine>1, 2, 7, 8</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1320" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning contextsensitive shape similarity by graph transduction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2009">2010. 1, 2, 7, 8, 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning context-sensitive similarity by shortest path propagation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2367" to="2374" />
			<date type="published" when="2008">2011. 1, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A scalable re-ranking method for content-based image retrieval</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pedronette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape similarity analysis by self-tuning locally constrained mixed-diffusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Multimedia</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Locally constrained diffusion process on locally densified distance spaces with applications to shape retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koknar-Tezel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<meeting><address><addrLine>1, 2, 7, 8</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Object retrieval with large vocabularies and fast spatial matching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scalable recognition with a vocabulary tree</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stewénius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006. 2, 4, 6, 8</date>
			<biblScope unit="page" from="2161" to="2168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Affinity learning via self-diffusion for image segmentation and clustering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A global/local affinity graph for image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Masnou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fusion with diffusion for robust visual tracking</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Beyond pairwise shape similarity analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kontschieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="655" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving shape retrieval by spectral matching and meta similarity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Egozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guterman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1319" to="1327" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">From one graph to many: Ensemble transduction for content-based database retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="31" to="37" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Affinity learning with diffusion on tensor product graph</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2009">2013. 2, 5, 7, 8, 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ranking consistency for image matching and object retrieval</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1349" to="1360" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image re-ranking and rank aggregation based on similarity of ranked lists</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pedronette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised manifold learning using reciprocal knn graphs in image re-ranking and rank aggregation tasks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pedronette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Penatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Computing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Total recall ii: Query expansion revisited</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perdoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Three things everyone should know to improve object retrieval</title>
		<author>
			<persName><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Comparing top k lists</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sivakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Discrete Math</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="134" to="160" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A similarity measure for indefinite rankings</title>
		<author>
			<persName><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Applied and computational harmonic analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lafon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Diffusion maps</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On feature combination for multiclass object classification</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="221" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Query specific fusion for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Query specific rank fusion for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="803" to="815" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Co-transduction for shape retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2009">2012. 2, 8, 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tri-training: Exploiting unlabeled data using three classifiers</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1529" to="1541" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Knowledge and Data Engineering</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semi-supervised regression with co-training</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="908" to="913" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic image annotation and retrieval using group sparsity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="838" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Packing and padding: Coupled multi-index for accurate image retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Coupled binary embedding for largescale image retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semantic-aware co-indexing for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Shape classification using the innerdistance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Shape matching and classification using height functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="134" to="143" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the burstiness of visual elements</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Hamming embedding and weak geometric consistency for large scale image search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Lp-norm idf for scalable image retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Panorama: A 3d shape descriptor based on panoramic views for unsupervised 3d object retrieval</title>
		<author>
			<persName><forename type="first">P</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pratikakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Theoharis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Perantonis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The princeton shape benchmark</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shilane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SMI</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Shape retrieval contest 2007: Watertight models track</title>
		<author>
			<persName><forename type="first">D</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biasotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paraboschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SHREC competition</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Shape descriptors for nonrigid shapes with a single closed contour</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lakamper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eckhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="424" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Aggregating local image descriptors into compact codes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Compact vectors of locally aggregated tensors for 3d shape retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tabia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Laga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Gosselin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Neural shape codes for 3d model retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On visual similarity based 3d model retrieval</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">P</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ouhyoung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="223" to="232" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A new 3dmatching method of nonrigid and partially similar models using curve analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tabia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Vandeborre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Colot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="852" to="858" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Desire: a composite 3d-shape descriptor</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Vranic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICME</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="962" to="965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Shape retrieval using hierarchical total bregman soft clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2407" to="2419" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Covariance descriptors for 3d shape matching and retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tabia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Laga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-H</forename><surname>Gosselin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="4185" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">3d object retrieval using an efficient and compact hybrid shape descriptor</title>
		<author>
			<persName><forename type="first">P</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pratikakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Theoharis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Passalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
	<note>Perantonis. in 3DOR, 2008</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Shape vocabulary: A robust and efficient shape representation for shape matching</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3935" to="3949" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Fusing multiple features for shape-based 3d model retrieval</title>
		<author>
			<persName><forename type="first">T</forename><surname>Furuya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ohbuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Exploiting pairwise recommendation and clustering strategies for image re-ranking</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C G E</forename><surname>Pedronette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Da S Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="19" to="34" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Scale and affine invariant interest point detectors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Triangulation embedding and democratic aggregation for image search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="3310" to="3317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Contextual weighting for vocabulary tree based image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Hello neighbor: Accurate object retrieval with k-reciprocal nearest neighbors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gammeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bossard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Quack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="777" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Bayes merging of multiple vocabularies for scalable image retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1963" to="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Unsupervised metric fusion by cross diffusion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2997" to="3004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Densifying distance spaces for shape and image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koknar-Tezel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Latecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="28" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Distance regularized level set evolution and its application to image segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Robust point matching via vector field consensus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Robust l2e estimation of transformation for non-rigid registration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TSP</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">He is currently a Professor with the School of Electronic Information and Communications, HUST. He is also the Vice-Director of National Center of Anti-Counterfeiting Technology, HUST. His research interests include object recognition, shape analysis, scene text recognition and intelligent systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Xiang received the B.S., M.S. and Ph.D. degrees from Huazhong University of Science and Technology (HUST)</title>
		<meeting><address><addrLine>Wuhan, China; Wuhan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2014. 2013. 2003, 2005, and 2009</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="333" to="337" />
		</imprint>
	</monogr>
	<note>He is a senior member of IEEE</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
