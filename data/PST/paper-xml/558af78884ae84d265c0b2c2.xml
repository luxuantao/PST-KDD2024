<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributed Algorithms for Constructing Approximate Minimum Spanning Trees in Wireless Sensor Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Maleq</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Gopal</forename><surname>Pandurangan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Anil Kumar</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Simulation Science Laboratory</orgName>
								<orgName type="institution">Virginia Bioinformatics Institute</orgName>
								<address>
									<addrLine>1880 Pratt Drive</addrLine>
									<region>Virginia Tech</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">CRC Building XV</orgName>
								<address>
									<postCode>24061</postCode>
									<settlement>Blacksburg</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<addrLine>305 N. University Street</addrLine>
									<postCode>47907</postCode>
									<settlement>West Lafayette</settlement>
									<region>IN</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributed Algorithms for Constructing Approximate Minimum Spanning Trees in Wireless Sensor Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A1B3A6A1650ABDE91637D56B5AEDB694</idno>
					<idno type="DOI">10.1109/TPDS.2008.57</idno>
					<note type="submission">received 8 Nov. 2006; revised 30 Aug. 2007; accepted 1 Apr. 2008; published online 10 Apr. 2008.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Distributed algorithms</term>
					<term>randomized approximation algorithms</term>
					<term>energy-efficient algorithms</term>
					<term>minimum spanning tree</term>
					<term>wireless networks</term>
					<term>sensor networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While there are distributed algorithms for the minimum spanning tree (MST) problem, these algorithms require relatively large number of messages and time, and are fairly involved, making them impractical for resource-constrained networks such as wireless sensor networks. In such networks, a sensor has very limited power, and any algorithm needs to be simple, local, and energy efficient. Motivated by these considerations, we design and analyze a class of simple and local distributed algorithms called Nearest Neighbor Tree (NNT) algorithms for energy-efficient construction of an approximate MST in wireless networks. Assuming that the nodes are uniformly distributed, we show provable bounds on both the quality of the spanning tree produced and the energy needed to construct them. We show that while NNT produces a close approximation to the MST, it consumes asymptotically less energy than the classical message-optimal distributed MST algorithm due to Gallagery, Humblet, and Spira. Further, the NNTs can be maintained dynamically with polylogarithmic rearrangements under node insertions/deletions. We also perform extensive simulations, which show that the bounds are much better in practice. Our results, to the best of our knowledge, demonstrate the first tradeoff between the quality of approximation and the energy required for building spanning trees on wireless networks, and motivate similar considerations for other important problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>T HE minimum spanning tree (MST) problem is an important and commonly occurring primitive in the design and operation of data and communication networks. For instance, in ad hoc sensor networks, MST is the optimal routing tree for data aggregation <ref type="bibr" target="#b1">[2]</ref>. Traditionally, the efficiency of distributed algorithms is measured by the running time and the number of messages exchanged among the computing nodes, and a lot of research has gone into the design of algorithms that are optimal with respect to such criteria. The classical algorithm due to Gallagery, Humblet, and Spira (henceforth referred to as the GHS algorithm) <ref type="bibr" target="#b0">[1]</ref> uses Âðn ln n þ jEjÞ messages, and is essentially optimal with respect to the message complexity. There are distributed algorithms that find the MST <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> and are essentially optimal in terms of time complexity: they run in OðDiamðGÞ þ n 1=2 polylogðnÞÞ time, and there are (almost) matching lower bounds. However, these time-optimal algorithms involve a lot of message transfers (much more than GHS). Even for a wireless network modeled by a unit disk graph (UDG) or even a ring, any distributed algorithm to construct an MST needs ðn ln nÞ messages <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Despite their theoretical optimality, these algorithms are fairly involved, require synchronization and a lot of bookkeeping; such algorithms are impractical for ad hoc and sensor networks <ref type="bibr" target="#b4">[5]</ref>. For example, consider sensor networks-an ad hoc network formed by large numbers of small, battery-powered, wireless sensors. In many applications, the sensors are typically "sprinkled" liberally in the region of interest, and the network is formed in an ad hoc fashion by local self-configuration. Since each sensor usually knows only its neighbors, the network management and communication has to be done in a local and distributed fashion. Additionally, because of battery limitations, energy is a very crucial resource. A distributed algorithm, which exchanges a large number of messages, can consume a relatively large amount of energy (and also time) and is not suitable in an energy-constrained sensor network. This is especially true in a dynamic setting-when the network needs to be reconfigured (e.g., due to mobility or failures) frequently and quickly. Reconfiguration is also necessary to evenly distribute the energy consumption among all nodes and, thus, to increase the network lifetime <ref type="bibr" target="#b6">[7]</ref>.</p><p>Thus, it is necessary to develop simple local distributed algorithms which are energy efficient, and preferably also time efficient, even at the cost of being suboptimal (see, e.g., <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> for such algorithms in the context of wireless sensor networks-discussed more below). This adds a new dimension to the design of distributed algorithms for such networks. Thus, we can potentially trade off optimality of the solution to work done by the algorithm. In a sensor network, the total energy required ("energy complexity") in a distributed algorithm typically depends on the time needed, the number of messages exchanged, and the radiation energy needed to transmit the messages over a certain distance <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. The radiation energy needed to transmit a message is typically proportional to some work function f (typically square or some small power) of the distance between the sender and the receiver <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Thus, it becomes important to measure efficiency of a distributed algorithm in terms of energy, besides the number of messages.</p><p>While there has been a lot of recent work on local algorithms for construction of low-weight connected subgraphs in wireless ad hoc networks (motivated by topology control and energy-efficient routing) <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, to the best of our knowledge, there has been little work on localized construction of exact or approximate MSTs, especially in the context of wireless ad hoc networks. A structure is low weight if its total edge length is within a small factor of the total edge length of the MST, but the structure may have cycles. It is easy to show that MST cannot be constructed in a purely localized manner, i.e., each node cannot determine which edge is in the defined structure by using only the information of the nodes within some constant hops. For example, Li et al. <ref type="bibr" target="#b7">[8]</ref> proposed a method to build what they call a local minimum spanning tree (LMST), which is guaranteed to be connected and has bounded degree, but is not a low-weight structure. In fact, Li et al. <ref type="bibr" target="#b4">[5]</ref> demonstrate the difficulty in constructing an MST and gives a localized algorithm to construct a low-weight connected subgraph (that can have cycles) for topology control in wireless ad hoc networks.</p><p>In this paper, we study a class of simple, local, distributed, approximation algorithms called the Nearest Neighbor Tree (NNT) algorithms that are provably good: they build slightly suboptimal trees with low energy complexity and are easy to maintain dynamically. A fundamental step in all existing algorithms for the MST problem is cycle detection: given an edge, one needs to determine whether the edge would form a cycle with the edges already chosen. This deceptively simple operation leads to a big overhead: a significant amount of bookkeeping and message passing needs to be done in order to maintain the components, and answer such queries. The NNT algorithms bypass such a step completely by a very simple idea: each node chooses a unique rank, a quantity from a totally ordered set, and a node connects to the nearest node of higher rank. Observe that this immediately precludes cycles, and the only information that needs to be exchanged is the rank; also, this information does not need to be updated continuously over the course of the algorithm.</p><p>The NNT scheme is closely related to the approximation algorithm for the traveling salesman problem (coincidentally called Nearest Neighbor (NN) algorithm) analyzed in a classic paper by Rosenkrantz et al. <ref type="bibr" target="#b13">[14]</ref>. Imase and Waxman <ref type="bibr" target="#b14">[15]</ref> also used a scheme based on <ref type="bibr" target="#b13">[14]</ref>, which can also be considered a variant of the NNT scheme, to show that it can maintain an Oðln nÞ-approximate Steiner tree dynamically assuming only node additions, but not deletions. These results can easily be used to show that NNT with any ranking of the nodes gives an Oðln nÞ-approximation to MST on a metric graph, i.e., a complete graph with edge weights satisfying the triangle inequality. In contrast, in this paper, we consider a different graph model (more suitable to model wireless ad hoc networks): a random geometric graph where nodes are distributed uniformly at random in a unit square and show an expected approximation ratio of Oð1Þ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">MST and Work Complexity</head><p>Formally, our focus is the following geometric weighted MST problem: given a set N of points (nodes) 1 in a plane, find a tree T spanning N such that P ðu;vÞ2T d ðu; vÞ is minimized, where dðu; vÞ is the length of edge ðu; vÞ, the euclidean distance between u and v, and is a small positive number. The motivation for this objective function comes from the energy requirements in a wireless communication paradigm: to transmit a signal over a distance r, the required radiation energy is proportional to r , where typically is 2 and can range up to 4 in environments with multiple-path interferences or local noise <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>. In this paper, we mainly focus on ¼ 2. Thus, given a spanning tree T , the cost (or quality) of a spanning tree T is defined by</p><formula xml:id="formula_0">Q ðT Þ ¼ P e2T jej</formula><p>, where e denotes an edge of T , and our goal is to find a tree that minimizes the cost for a given . Notice that when ¼ 1, this problem becomes the traditional MST problem. It can easily be shown (e.g., using Kruskal's algorithmic construction <ref type="bibr" target="#b15">[16]</ref>) that the MST which minimizes P ðu;vÞ2T dðu; vÞ also minimizes P ðu;vÞ2T d ðu; vÞ for any &gt; 0. In the rest of this paper, we use the terms cost and quality interchangeably.</p><p>Two important applications of an MST in wireless networks are broadcasting and data aggregation. An MST can be used as broadcast tree to minimize energy consumption since it minimizes P ðu;vÞ2T d ðu; vÞ. It was shown in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, and <ref type="bibr" target="#b18">[19]</ref> that broadcasting based on MST consumes energy within a constant factor of the optimum. In data aggregation, the idea is to combine the data coming from different sources en route to eliminate redundancy and minimize the number of transmissions, and thus, saving energy. Some common aggregate functions are minimum, maximum, average, etc. <ref type="bibr" target="#b1">[2]</ref>. One popular paradigm for computing aggregates is to construct a tree rooted at the sink where each node forwards its (locally) aggregated data collected from its subtree to its parent <ref type="bibr" target="#b19">[20]</ref>. For such cases, MST is the optimal data aggregation tree.</p><p>Since energy is an important constraint in the setting of sensor networks, a lot of work has focused on constructing low energy subgraphs <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref>. However, it is counterproductive to use a lot of resources (e.g., time and energy) in order to compute a low-cost subgraph, e.g., an MST; the energy used by the algorithm is also an important measure. Motivated by this consideration, in addition to the traditional time and message complexity of distributed algorithms, we consider a complexity term called work complexity defined as w ¼ P M i¼1 r i , where r i is the transmission distance for message i and M is the number of messages exchanged by the nodes to run the algorithm/protocol (this is implicit in many papers, see, e.g., the survey of <ref type="bibr" target="#b5">[6]</ref>). Thus, total radiation energy is directly proportional to the work done by the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Network Model</head><p>We consider a wireless network composed of n nodes distributed uniformly at random in a unit square (a popular 1. For example, the nodes may represent sensors. We assume that these nodes have distinct identifiers. probabilistic model for wireless ad hoc networks, e.g., see <ref type="bibr" target="#b20">[21]</ref>). We assume that the nodes have distinct identifiers, each node has an omnidirectional antenna, and a single transmission can be received by any node within the transmission radius (called local broadcasting). (We assume a directional antenna only for dynamic algorithm given in Section 7.) We utilize this broadcasting property to reduce the communications needed in our algorithm. Each node can adjust its transmission radius (power level) to any value up to a given maximum level. When the maximum transmission power of the nodes is large enough so that any two nodes can communicate directly with each other, we call it a complete graph model. Otherwise, we model it as a UDG, where two nodes u and v communicate directly if and only if dðu; vÞ R for some given R; that is, there is an edge between u and v if and only if dðu; vÞ R. In this paper, we also refer the UDG model as multihop setting. This model is a popular graph model for multihop wireless networks <ref type="bibr" target="#b5">[6]</ref>. When the nodes are uniformly distributed in a unit square, to have a connected graph with high probability (WHP), it is necessary and sufficient that R be Âð ffiffiffiffiffi ffi</p><formula xml:id="formula_1">ln n n q Þ [21]</formula><p>. Thus, we assume that R ¼ Âð ffiffiffiffiffi ffi</p><formula xml:id="formula_2">ln n n q Þ.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Our Contributions and Results</head><p>Our main contribution is a detailed theoretical and experimental study of the NNT algorithms in the context of wireless ad hoc and sensor networks for the above network models. First, we present NNT algorithms for the complete graph model where the maximum transmission range of the nodes are large enough so that any pair of nodes can communicate directly with each other (cf. Section 3). Depending on how the ranks are chosen, we study two NNT algorithms: Random-NNT (ranks are chosen randomly) and Coordinate-NNT (Co-NNT in short; ranks are based on coordinates of the nodes). <ref type="foot" target="#foot_0">2</ref>For multihop wireless networks modeled by a UDG, we present another NNT algorithm, which we refer to as UDG-NNT. Given the simple and local nature of this construction, it is quite surprising to have trees of reasonable properties. We show that the NNTs have some properties that can make them attractive for the ad hoc networks. Our main results are: 1) the tree produced by such an algorithm, called the NNT, has low cost, 2) the NNT paradigm can be used to design a simple dynamic algorithm for maintaining a low-cost spanning tree, and 3) the time, message, and work complexities of the NNT algorithms are close to the optimal in several settings. Our performance analysis is with respect to the following metrics: the quality of the spanning tree produced by the NNT algorithm, and the message, time, and work needed by the algorithm to construct the tree. The results are summarized in Table <ref type="table" target="#tab_0">1</ref>. Quality, work, and the number of messages are expected (average) values for all of the algorithms (including GHS), and the time complexity is the worst-case bound for all algorithms. While the NNTs are a close approximation to MST, NNT algorithms consume much less energy compared to the messageoptimal GHS algorithm. The radiation energy to transmit messages is directly proportional to the work complexity. Some energy is consumed to process the messages by the electronic devices at the nodes. Energy consumption in electronic devices also depends on running time-the longer the running time, the more the energy consumption. Thus, the number of messages, work, and time together determines the total energy (energy consumption in transceiver electronics plus radiation energy) consumed in running an algorithm/protocol. The NNT algorithms perform significantly better in all three: the number of messages, work, and time.</p><p>Although most of our analyses are generalized to any , we mainly focus on ¼ 2 for the purpose of discussion. For quality, the case ¼ 1 is also interesting by the fact that in this case, the problem becomes the traditional MST problem. Thus, we emphasize quality for ¼ 1 and 2, and the work complexity for ¼ 2.</p><p>Quality bounds. We show that with respect to the expected quality (or cost) of the tree, Random-NNT gives an Oð1Þ and Oðln nÞ approximation to MST for the case of ¼ 1 and ¼ 2, respectively; and UDG-NNT gives an Oð ffiffiffiffiffiffiffiffi ln n p Þ and Oðln nÞ approximation, respectively. In contrast, Co-NNT gives an Oð1Þ approximation for both ¼ 1 and ¼ 2. Thus, NNT algorithms give good bounds on the cost of the trees, with Co-NNT being better than Random-NNT-this shows that at a cost of increased information (i.e., about the coordinates), we can get better approximations.</p><p>Message, time, and work complexity. NNT algorithms have significantly lower message, time, and work complexity compared to the message-optimal GHS algorithm which computes the exact MST. We show that the average work complexities of Co-NNT, Random-NNT, and UDG-NNT are Oð1Þ, Oðln nÞ, and Oðln nÞ, respectively, for ¼ 2, whereas the work complexity of GHS algorithm is ðln 2 nÞ. For all of the NNT algorithms, the expected message complexity is OðnÞ, which is essentially the best possible, while GHS takes expected ðn ln nÞ messages. The time complexity of Simulation results. We also performed extensive simulations of our algorithms. We tested our algorithms on both uniformly random distributions of points, and on realistic distributions of points in an urban setting obtained from TRANSIMS <ref type="bibr" target="#b21">[22]</ref>. Experimental results show that the work and number of messages for NNT algorithms are significantly smaller than that for an optimal MST algorithm, while the quality of the NNT trees is very close to MST. For example, for the TRANSIMS data, we found that the cost of the trees found by the NNT algorithms are within a factor of 2 of the MST, but there is more than a tenfold saving on the work and about a fivefold saving on the number of messages.</p><p>Maintaining a low-cost tree dynamically. We show that the degree of a node in NNT is Oðln nÞ WHP. This property of low node degree can be used to design a simple dynamic algorithm for maintaining a Random-NNT. We show that the expected number of rearrangements, i.e., the number of nodes whose outgoing edge must change, as a result of a node insertion or deletion is Oðln nÞ. This dynamic algorithm does not require any complicated data structures or severe constraints on the sensors. The dynamic aspect of the NNT scheme makes them very useful in a sensor network setting, where it is very common for nodes to fail, or become alive asynchronously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Other Related Work</head><p>Li et al. <ref type="bibr" target="#b4">[5]</ref> give a local algorithm to construct a low-weight subgraph that has many desirable properties: connectivity (but may have cycles), sparseness, spanner, bounded degree, and planarity. They assume that the nodes need to know coordinate or at least relative positions, whereas for Random-NNT, no coordinate information is needed. Their algorithm takes OðnÞ messages, which is asymptotically optimal, in the worst case for arbitrary node distribution. However, their low-weight structure is not a tree and cannot be used for applications where a tree is needed, e.g., data aggregation. Moreover, their structure is low weight only if the weight of an edge is interpreted as the distance between two nodes (and not as th power of the distance, for some &gt; 1). Quality of this structure is Oðn À1 Þ in the worst case. Li et al. <ref type="bibr" target="#b7">[8]</ref> devised a localized algorithm to build similar structure called LMST. They use only one hop neighbor information to build LMST. However, LMST is not a lowweight structure even for ¼ 1 <ref type="bibr" target="#b4">[5]</ref>. Both <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b7">[8]</ref> assume arbitrary node distribution. Kempe and Kleinberg <ref type="bibr" target="#b22">[23]</ref> presented an algorithm to construct an approximate euclidean MST (assuming uniform node distribution) using spatial gossip mechanism where they use a ranking of the nodes, similar to our Random-NNT. This algorithm achieves an expected Oðln nÞ approximation to the MST for ¼ 1, where our NNTs give an expected Oð1Þ approximation. They did not show any approximation factor for &gt; 1 in which case approximation ratio can be significantly larger than Oðln nÞ. The expected message complexity is OðnfðnÞ ln nÞ, where fðnÞ is some polylogarithmic function, which can even be larger than the number of messages in GHS algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A LOCAL DISTRIBUTED ALGORITHM FOR CONSTRUCTION OF APPROXIMATE MST</head><p>In this section, we describe the NNT scheme to construct a low-cost spanning tree, where each node chooses a rank and connects to the closest node of higher rank. An abstract form of the scheme is given in Algorithm 1. For a node v, let nntðvÞ denote the node that v connects to, if it exists. If v has the highest rank, nntðvÞ is not defined. If nntðvÞ is defined, it must be the case that rankðnntðvÞÞ &gt; rankðvÞ and rankðvÞ &gt; rankðwÞ, for each node w that is closer to v than nntðvÞ. If we think of the edges ðv; nntðvÞÞ as being directed from v to nntðvÞ, it is clear that each edge is directed from a low rank node to a higher rank node-this immediately rules out cycles, and gives a spanning tree. Thus, the NNT algorithm is extremely simple, local, requires no complex synchronization among the nodes, and is naturally robust.</p><p>Algorithm 1: Basic NNT scheme All nodes have distinct ids from a totally ordered set.</p><p>Output: A spanning tree. Every node v executes the following steps independently: 1) Choose a unique rank rankðvÞ.</p><p>2) Connect to the nearest node w such that rankðwÞ &gt; rankðvÞ, i.e., add the edge ðv; wÞ to the NNT. We consider the following two rankings of the nodes: Random-NNT:</p><p>1) v chooses pðvÞ, a uniform random number 2 ½0; 1.</p><p>2) rankðwÞ &gt; rankðvÞ if pðwÞ &gt; pðvÞ or if pðwÞ ¼ pðvÞ and idðwÞ &gt; idðvÞ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coordinate-NNT:</head><p>1) Assume that V is a set of points in a plane. rankðvÞ ¼ ðxðvÞ; yðvÞÞ, i.e., the coordinates of v. 2) For two nodes v and w, rankðwÞ &gt; rankðvÞ if xðwÞ &gt; xðvÞ or if xðwÞ ¼ xðvÞ and yðwÞ &gt; yðvÞ.</p><p>For a given choice of ranks, let NEðvÞ denote the size of the neighborhood that v needs to look for in order to find the connecting edge. NEðvÞ is a measure of the locality, and has a bearing on the time and message complexity. For arbitrary choices of ranks, the average neighborhood size could be ðnÞ; but it decreases significantly for Random-NNT.</p><p>Lemma 1. In the case of a random-NNT, for any node v, the probability that v connects to the ith NN is 1 iðiþ1Þ and E½NEðvÞ ¼ Âðln nÞ.</p><p>Proof. Let x 0 be the random number generated by v, and x i the random number generated by the ith NN of v. Then, the probability that v connects to the ith NN is equal to the probability that x i and x 0 are the largest and second largest, respectively, among ði þ 1Þ random numbers: x 0 ; x 1 ; . . . ; x i . This probability is 1 iðiþ1Þ . Now,</p><formula xml:id="formula_3">E½NEðvÞ ¼ P nÀ1 i¼1 i Á 1 iðiþ1Þ ¼ H n À 1 ¼ Âðln nÞ. t u</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DISTRIBUTED IMPLEMENTATION OF THE NNT SCHEME</head><p>In this section, we describe an algorithm to construct a spanning tree based on the NNT scheme. In this implementation, We assume that each node can communicate directly with all other nodes by suitably increasing its transmission radius. However, it turns out that most of the nodes need to communicate with only a small number of nearby neighbors, but some nodes may need to communicate with distant nodes. For the case where the maximum power level of the nodes is not large enough to reach another node at that distance, we provide an alternative implementation of the NNT scheme in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The NNT Algorithm</head><p>The algorithm consists of exchanging three types of messages: request, available, and connect among the nodes. Each node begins with broadcasting a request for connection message. Each node broadcasts request messages successively in phases to the distances 2 ffiffi n p ; 4 ffiffi n p ; 8 ffiffi n p ; . . . ; until it finds a node with a higher rank. The highest ranked node among all the nodes can never find a node with a higher rank. This node stops transmitting request message when it reaches the maximum possible distance between any two nodes. Considering a unit square, the maximum distance between any two nodes is ffiffi ffi 2 p</p><p>. A request message carries rank information (coordinates or random number). The other nodes who can hear the message send back an available message if their rank is higher. The sender of the request message selects the nearest node from the senders of available messages if more than one available message is received, and thus, it finds the nearest higher ranked node.</p><p>We assume that these phases are synchronized; i.e., all nodes begin phase i, for each i, simultaneously. The phases can easily be synchronized by making all nodes wait for T i time in phase i, where T i is the time required to complete exchanging the messages of phase i. In the proof of Theorems 6 and 10, for Random-NNT and Co-NNT, respectively, we show how T i can be calculated. If there is a node of higher rank within the transmission radius of phase i, the reply from that node is received by the end of the phase i.</p><p>When coordinates are not available (e.g., for Random-NNT), senders include the transmission power levels in the available messages and the recipient determine the relative distances of the senders from these power levels and the signal-strengths of the received messages. Finally, the node sends a connect message to the nearest higher ranked node, creating an edge between these two nodes. are Oðln nÞ and Oð1Þ, respectively. For both NNT algorithms, the expected number of messages is OðnÞ and the time complexity is Oðln 3 nÞ WHP. The following lemmas and theorems prove these claims. We prove the bounds on work and message complexity assuming that each message is transmitted successfully in one attempt. Then, we provide a protocol for scheduling messages and resolving conflicts, and show that with this protocol, the bounds can only be increased by a constant factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Analysis of Random-NNT</head><p>Theorem 2. E½Q ðRandom-NNTÞ is Oðln nÞ for ¼ 2, Oðn 1À=2 Þ for &lt; 2, and Oð1Þ for &gt; 2.</p><p>Proof. Consider an arbitrary node u, and concentric circles centered at u with radius r i ¼ 2 i ffiffi n p for i ¼ 1; 2; . . . ; m. Considering a unit square, the maximum distance between any two nodes is ffiffi ffi 2 p . Thus, r mÀ1 &lt; ffiffi ffi 2 p r m , i.e., the maximum number of circles m &lt; 1 2 lg n þ 3 2 . Let C i be the set of nodes in the circle with radius r i , R i ¼ C i À C iÀ1 for i ! 2, and R i ¼ C i for i ¼ 1. For a node v 2 R i , distance dðu; vÞ r i .</p><p>Let A i be the event that u connects to a node v 2 R i . By Lemma 1, the probability that u connects to any node between jth NN and ðk À 1Þst NN is</p><formula xml:id="formula_4">P kÀ1 i¼j 1 iðiþ1Þ ¼ 1 j À 1 k</formula><p>, where j k. For i ! 2, jC iÀ1 j ! 1 since C iÀ1 contains at least one node, which is u. Probability that a particular node, other than u, is in</p><formula xml:id="formula_5">C iÀ1 is p ! 1 4 r 2 iÀ1 ¼ 2 2i</formula><p>16n (for a node at the corner or next to the border, probability p can be as low as 1  4 of the area of the circle with radius r iÀ1 ). Thus, for i ! 2,</p><formula xml:id="formula_6">PrfA i g ¼ X n j¼1 X n k¼j 1 j À 1 k Pr jC iÀ1 j ¼ j ^jC i j ¼ k f g X n j¼1 1 j PrfjC iÀ1 j ¼ jg ¼ X n j¼1 1 j n À 1 j À 1 p jÀ1 ð1 À pÞ nÀj ¼ 1 np 1 À ð1 À pÞ n f g 1 np 16 2 2i ; E d ðu; vÞ ½ PrfA 1 gr 1 þ X m i¼2 PrfA i gr i r 1 þ X m i¼2 16 2 2i r i ¼ n À=2 2 þ 16 X m i¼2 2<label>ðÀ2Þi</label></formula><p>( )</p><formula xml:id="formula_7">:</formula><p>By linearity of expectation for n nodes</p><formula xml:id="formula_8">E½Q ¼ nE d ðu; vÞ ½ : When ¼ 2, E½Q 8 lg n þ 24 þ 4 ¼ Oðlg nÞ ¼ Oðln nÞ: When 6 ¼ 2, E½Q 2 À 2 2þ2 ð2 À 4Þ &amp; ' n 1À=2 þ 2 1þ5=2</formula><p>ð2 À 4Þ :</p><formula xml:id="formula_9">For &lt; 2, E½Q ¼ Oðn 1À=2 Þ; for &gt; 2, E½Q ¼ Oð1Þ. t u</formula><p>Theorem 3. The expected work complexity of Random-NNT algorithm E½W is Oðln nÞ for ¼ 2, Oðn 1À=2 Þ for &lt; 2, and Oð1Þ for &gt; 2.</p><p>Proof. Again, consider an arbitrary node u. First transmission radius for request message is r 1 ¼ 2 ffiffi</p><p>1 n q and for the</p><formula xml:id="formula_10">ith transmission, r i ¼ 2r iÀ1 ¼ 2 i ffiffi 1 n q .</formula><p>Then, the maximum number of transmissions, m &lt; 1 2 lg n þ 3 2 . Let C i be the set of nodes in the circle centered at u with radius r i and R i ¼ C i À C iÀ1 , the set of nodes in the ith ring. Let Aðv; u; iÞ be the event that v replies to u in phase i. For i ! 2, the event Aðv; u; iÞ occurs if and only if v 2 R i and rankðvÞ &gt; rankðuÞ &gt; rankðsÞ for all s 2 C iÀ1 . The probability that a particular node is in</p><formula xml:id="formula_11">C iÀ1 is p ! 2 2i</formula><p>16n , and Prfv 2 R i g 3p. Letting jC iÀ1 j ¼ k, we have</p><formula xml:id="formula_12">Prf8 s2CiÀ1 rankðvÞ &gt; rankðuÞ &gt; rankðsÞ ½ j v 2 R i g ¼ 1 kðk þ 1Þ : Then, for i ! 2, Pr Aðv; u; iÞ f g 3p X nÀ1 k¼1 1 kðk þ 1Þ n À 2 k À 1 p kÀ1 ð1 À pÞ nÀkÀ1 3 nðn À 1Þp 48 ðn À 1Þ2 2i ; Pr Aðv; u; 1Þ f g¼ Pr v 2 C 1 ; rankðvÞ &gt; rankðuÞ f g 4 n Á 1 2 ¼ 2 n :</formula><p>Potentially, there are n À 1 nodes that can reply to u. Thus, by linearity of expectation, the expected work done by the all replies to u is less than or equal to</p><formula xml:id="formula_13">ðn À 1Þ 2 n r 1 þ X m i¼2 48 ðn À 1Þ2 2i r i ( ) n À=2 22 þ 48 X m i¼2 2<label>iðÀ2Þ</label></formula><formula xml:id="formula_14">( ) :<label>ð1Þ</label></formula><p>Now, we calculate the work done by the request and connect messages. Let T i denote the event that u needs ith transmission. PrfT 1 g ¼ 1. For i ! 2, u needs ith transmission if and only if rank of u is the largest among all nodes in C iÀ1 . Thus</p><formula xml:id="formula_15">PrfT i g ¼ X n k¼1 1 k n À 1 k À 1 p kÀ1 ð1 À pÞ nÀk 16 2 2i :</formula><p>In each phase, there is one request message, and at most one connect message by u. Thus, expected work done by u for request and connect messages is</p><formula xml:id="formula_16">X m i¼1 PrfT i g2r i n À=2 2 Â 2 þ 32 X m i¼2 2<label>iðÀ2Þ</label></formula><formula xml:id="formula_17">( ) :<label>ð2Þ</label></formula><p>From (1) and ( <ref type="formula" target="#formula_6">2</ref>), the expected total work for node u</p><formula xml:id="formula_18">E½W u n À=2 2ð þ 1Þ2 þ 80 X m i¼2 2<label>iðÀ2Þ</label></formula><p>( )</p><formula xml:id="formula_19">:</formula><p>Expected work by the algorithm, E½W ¼ nE½W u . Thus,</p><formula xml:id="formula_20">E½W n 1À=2 2ð þ 1Þ2 þ 80 X m i¼2 2<label>iðÀ2Þ</label></formula><formula xml:id="formula_21">( ) :<label>ð3Þ</label></formula><p>This gives the desired result stated in the theorem. t u Corollary 4. For i ! 2, the expected number of nodes that needs ith transmission is n PrfT i g 16n 4 i , and the expected number of required transmissions by a node to find a higher ranked node is</p><formula xml:id="formula_22">P m i¼1 PrfT i g 1 þ 4 3 ð1 À 1 2n Þ 1 þ 4 3 &lt; 1:425. Theorem 5.</formula><p>The expected message complexity of Random-NNT algorithm is OðnÞ.</p><p>Proof. If we consider work needed for every message is 1, i.e., when ¼ 0, the total work is simply the number of messages, M, exchanged in the algorithm. Thus, from (3), putting ¼ 0 in the right-hand side, we get</p><formula xml:id="formula_23">E½M n 2ð þ 1Þ þ 80 X m i¼2 2<label>À2i</label></formula><p>( )</p><formula xml:id="formula_24">¼ OðnÞ: t u</formula><p>Scheduling messages and resolving collisions. Consider an arbitrary node u. Let k i be the number of messages (including the messages to be transmitted by u) that can potentially collide with u's messages in phase i of the algorithm. Note that u may have more than one among these k i messages. In the proof of the next theorem, we show how u can determine an upper bound on k i . Let F i be a time frame containing at least k i time slots. Each phase i of the algorithm contains Oðln nÞ such time frames F i . In the first time frame, for each message, u chooses a slot uniformly at random. If a message is in collision, u again picks a random slot in the next frame for this message, and so on. Now, assume k i ! 2. If k i 1, there is no collision. In an attempt, a particular message does not collide with probability at least 1 À 1=k i ð Þ k i À1 ! 1 e , using the known inequality ð1 þ t=kÞ k ! ð1 À t 2 =kÞe t with t ¼ À1. Thus, the expected number of retransmissions required for a message is at most e, meaning the bounds on the expected message and work complexity increase by a factor of at most e, a constant. Further, following Corollary 7 in <ref type="bibr" target="#b26">[26]</ref>, WHP, we have all k i messages successfully transmitted within Oðln nÞ time frames, i.e., WHP, the time to complete phase i is given by</p><formula xml:id="formula_25">T i ¼ Oðk i ln nÞ:<label>ð4Þ</label></formula><p>Theorem 6. The time complexity of Random-NNT algorithm is Oðln 3 nÞ WHP.</p><p>Proof. The radius of the first transmission by each node is r 1 ¼ 2 ffiffi n p . The expected number of nodes within this radius, E½jC 1 j r 2 1 n ¼ 4. Using the following standard Chernoff bound <ref type="bibr" target="#b27">[27]</ref> </p><formula xml:id="formula_26">Pr x ! ð1 þ Þ f g&lt; e ð1 þ Þ 1þ ! ; with x ¼ jC 1 j, ¼ E½jC 1 j, and ¼ c ln n</formula><p>À 1, we can show that WHP, jC 1 j &lt; c ln n for sufficiently large constant c, and each node sends at most c ln n available messages. Thus, the total number of message by the nodes within the radius r 1 is k 1 ¼ ðc ln nÞ 2 ¼ Oðln 2 nÞ WHP. By (4), time to complete the first phase is at most T 1 ¼ Oðln 3 nÞ WHP. Now, consider an ith transmission phase to distance r i ¼ 2 i ffiffi n p . After the ði À 1Þst phase, the distance between any two unconnected nodes is at least r iÀ1 ; otherwise, one node has lower rank than the other and would connect to that in some previous phase. Thus, the maximum number of unconnected nodes in any circle with radius r i is Oð1Þ (this is the maximum number of nodes that can be packed in a circle with radius 2d, for any d, such that distance between any two nodes is at least d. Notice that there can be at most one node in any square with side d=2). Next, we show that each such unconnected node receives at most Oðln nÞ available messages WHP.</p><p>Consider an arbitrary node u. Let C i ¼ y. Assume that y ! 60 ln n. (If y &lt; 60 ln n, then u receives Oðln nÞ available messages with probability 1.) Let x denote the number of nodes in C iÀ1 . For any node v, Prfv 2 C iÀ1 jv 2 C i g ! 1   4   (inequality, instead of equality, comes from the fact that u can be close to the borders). Thus, E½x ! y=4 ! 15 ln n. Since the position of the nodes are independent and identically distributed, using the standard Chernoff bound with ¼ 1 2 and ¼ E½x, we have</p><formula xml:id="formula_27">Prfx &lt; y=8g Pr x &lt; ð1 À Þ f g &lt; e À ð1 À Þ 1À ! 1 n 2:3 :</formula><p>Let z ¼ jR i j ¼yÀx. Then, Prfz ! 7y=8g¼Prfx&lt; y=8g &lt; 1 n 2:3 . Since u is at the ith transmission phase, it is known that u has the largest rank among the x nodes in C iÀ1 . Now, u receives exactly t available messages if and only if exactly t out of z nodes in R i have higher ranks than u. The probability of such event is</p><formula xml:id="formula_28">z t t!ðy À t À 1Þ! y! z y t :</formula><p>Let A be the event that u receives more than 20 ln n available messages, and B be the event that z &lt; 7y=8. Then</p><formula xml:id="formula_29">PrfAg X z t¼d20 ln ne z y t y y À z z y 20 ln n PrfAjBg &lt; 8 n 2:6 PrfAg PrfAjBg þ Prf " Bg &lt; 1 n 2:3 þ 8 n 2:6 :</formula><p>Excluding the first phase, there are at most 1 2 ðlg n þ 1Þ phases. By the union bound (i.e., Boole's inequality <ref type="bibr" target="#b27">[27]</ref>), the probability that some of the n nodes receives more than 20 ln n replies in some phase is less than</p><formula xml:id="formula_30">1 2 ðlg n þ 1Þn 1 n 2:3 þ 8 n 2:6 ¼ O 1=n 1:2 À Á :</formula><p>Thus, to apply (4), we have k i ¼ Oðln nÞ and T i ¼ Oðln 2 nÞ WHP. Therefore, total time taken by all</p><formula xml:id="formula_31">1 2 ðlg n þ 1Þ phases is Oðln 3 nÞ. t u</formula><p>We note that only a very few nodes may need to go far to find a node of higher rank. Most of the nodes are connected to the closer neighbors. From Corollary 4, we see that the number of nodes that need ith transmission is decreasing exponentially with i. The average number of transmissions by a node is at most 1.425. Thus, almost all of the nodes get connected after the first few transmissions. The radii for the first few transmissions are 2 ffiffi n p , 4 ffiffi n p , etc., which are very small and decreasing with n. This shows that the proposed algorithm is highly scalable and local in nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Analysis of Coordinate NNT</head><p>Now, we show analogous theorems for Co-NNT. We further rearrange the cells in these columns, along with the nodes in it, in a single row as shown in Fig. <ref type="figure" target="#fig_3">1</ref>. The cells in the column containing u, Column k, are arranged in a different way than the cells in the other columns. First, we put the cell containing u, then one cell from above u and one cell from below u, by interleaving them. Then, we put the cells in Column k þ 1 in their original order beginning from the bottommost cell to the topmost cells, then the cells in Column k þ 2 in the same order, and so on. In this new arrangement, we are moving the nodes further away and increasing the distances among the nodes; and thus, increasing the length of the edges comparing to the original Co-NNT. As a result, the expected quality of the original Co-NNT is less than that of the Co-NNT in this new arrangement. Node u connects to a node in the ith next cell, if the next i À 1 cells are empty and there is a node in the ith next cell. The probability that the next i À 1 cells are empty is 1 À iÀ1 n À Á nÀ1 . Let P 0 be the probability that there is a node in the ith cell given that the first i À 1 cells are empty, and P i be the probability that u connects to a node v in the ith cell:</p><formula xml:id="formula_32">P i ¼ 1 À i À 1 n nÀ1 P 0 1 À i À 1 n nÀ1 e À iÀ1 n ðnÀ1Þ e À iÀ1 2 E d ðu; vÞ ½ X nÀ1 i¼1 ðibÞ P i X nÀ1 i¼1 i ffiffiffi n p e À iÀ1 2 E½Q ¼ nE d ðu; vÞ ½ n 1À=2 X nÀ1 i¼1 i 1 ffiffi ffi e p iÀ1 E½Q 1 ffiffiffi n p ffiffi ffi e p X nÀ1 i¼1 i 1 ffiffi ffi e p i ¼ Oð ffiffiffi n p Þ E½Q 2 ffiffi ffi e p X nÀ1 i¼1 i 2 1</formula><p>ffiffi ffi e p Proof. Again, we subdivide the area into cells and consider the rearrangement of the cells in a single row as described in the proof of Theorem 7. The transmission radius for ith phase is</p><formula xml:id="formula_33">2 i ffiffi n p . Length of each cell is b ¼ 1 ffiffi n p</formula><p>. Thus, a node u need ith transmission if the next 2 iÀ1 cells are empty. Let T i be the event that u needs ith transmission. PrfT 1 g ¼ 1 and for i ! 2</p><formula xml:id="formula_34">PrfT i g ¼ 1 À 2 iÀ1 n nÀ1 e À2 iÀ1 =2 :</formula><p>The number of available messages u receives in phase i is the number of nodes in 2 i À 2 iÀ1 ¼ 2 iÀ1 cells that are covered by the transmission i but not by transmission i À 1. For i ! 2, the expected number of such nodes in these 2 iÀ1 cells, given that the first 2 iÀ1 cells are empty, is</p><formula xml:id="formula_35">2 iÀ1 n À 2 iÀ1 ðn À 1Þ 2 iÀ1 n n À 2 iÀ1 ¼ 2 iÀ1 1 þ 2 iÀ1 n À 2 iÀ1 2 iÀ1 1 þ 2 iÀ1 À Á :</formula><p>The expected number of replies in the first phase is 2 n ðn À 1Þ 2. In addition, in each phase, there are at most one request message and one connect message by u. Thus, the expected work by u The total work by n nodes, E½W ¼ nE½W u . Thus</p><formula xml:id="formula_36">E½W u ð2 þ 2Þð2bÞ PrfT 1 g þ X dlg ne i¼2 2 þ 2 iÀ1 1 þ 2 iÀ1 À Á È É ð2 i bÞ PrfT i g 4 2 n =2 þ 2 n =2 X 1 i¼2 ð2 þ i þ i 2 Þi 1 ffiffi ffi e p i :</formula><formula xml:id="formula_37">E½W 2 n 1À=2 4 þ X 1 i¼2 ð2 þ i þ i 2 Þi 1 ffiffi ffi e p i ( ) :<label>ð5Þ</label></formula><p>Putting ¼ 1 and 2, we have the desired result. t u Theorem 9. The expected message complexity of Co-NNT algorithm is OðnÞ.</p><p>Proof. When ¼ 0, the total work is equal to the number of messages M. Thus, from (5), using ¼ 0, we have</p><formula xml:id="formula_38">E½M ¼ OðnÞ. t u</formula><p>Theorem 10. The time complexity of distributed Co-NNT algorithm is Oðln 3 nÞ WHP.</p><p>Proof. A part of the proof of this theorem is similar to the proof of Theorem 6. Using the same argument as in Theorem 6: 1) the running time for the first phase of Co-NNT algorithm is T 1 ¼ Oðln 3 nÞ WHP and 2) after ði À 1Þst phase, the maximum number of unconnected nodes in any circle of radius r i is constant, Oð1Þ. Next, we show that in phase i, each unconnected node receives Oðln nÞ available messages WHP. The number of unconnected nodes in C i and the number of available messages received by an unconnected node jointly determine the running time of ith phase. Assume a vertical line through node u (the dotted line in Fig. <ref type="figure" target="#fig_4">2</ref>), which divides the plane that contains the unit square into two half-planes. Let B i denote the common region (the shaded region in Fig. <ref type="figure" target="#fig_4">2</ref>) among the right half-plane, the disk with radius r i centered at u, and the unit square. Let a i be the area of the region B i . Using simple geometry, it can easily be shown that 2a iÀ1 a i 4a iÀ1 for any position of u in the unit square. Let n i be the number of nodes in B i excluding u. Now, we consider the following two cases.</p><p>Case a i 12 ln n nÀ1 : Then, E½n i 12 ln n. By Chernoff bound <ref type="bibr" target="#b27">[27]</ref> with ¼ E½n i and ¼ 36 ln n À 1, we have</p><formula xml:id="formula_39">Prfn i ! 36 ln ng ¼ Pr n i ! ð1 þ Þ f g &lt; e ð1 þ Þ Àð1þÞ e=ð1 þ Þ ð Þ<label>ð1þÞ</label></formula><formula xml:id="formula_40">1=n 3 :</formula><p>The number of replies u receives in phase i cannot be more than n i . Thus, the probability that u receives more than 36 ln n replies is at most 1=n 3 .</p><p>Case a i &gt; 12 ln n nÀ1 : Then, a iÀ1 ! a i 4 &gt; 3 ln n nÀ1 . In this case, the probability that u needs ith transmission, i.e., the probability that B iÀ1 is empty, is ð1 À a iÀ1 Þ nÀ1 e ÀðnÀ1ÞaiÀ1 &lt; 1=n 3 : Thus, with probability at least 1 À 1 n 3 , either u does not need phase i or the number of replies in phase i is Oðln nÞ. This statement holds simultaneously for all of Oðln nÞ phases for all n nodes with probability at least 1 À 1 n (by the union bound). Thus, by ( <ref type="formula" target="#formula_25">4</ref>), the running time of each phase i ! 2 is T i ¼ Oðk i ln nÞ ¼ Oðln 2 nÞ and the total time is Oðln 3 nÞ WHP.</p><p>t u</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NNT ALGORITHM FOR MULTIHOP WIRELESS NETWORKS</head><p>If the maximum power level of a node is not large enough to communicate directly with the other nodes, i.e., for the UDG model, we propose the following algorithm to construct an NNT, called UDG-NNT. Two nodes u and v can communicate directly (i.e., there is an edge between them), if and only if dðu; vÞ R. We assume R ¼ Âð ffiffiffiffiffi ffi</p><formula xml:id="formula_41">ln n n q Þ (see Section 1.3).</formula><p>Typically, in a sensor network, a special node called sink gathers data from the sensors and is the root of the tree. Thus, we assume that a special node s, the sink, is designated to be the root of NNT. <ref type="foot" target="#foot_3">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The UDG-NNT Algorithm</head><p>The algorithm is executed in two phases. In the first phase, the nodes choose their ranks randomly as follows: This phase is initiated by the sink s. The sink picks an arbitrary large number pðsÞ and sends this number along with its ID to its neighbors in one transmission. As soon as any other node u receives the first message from a neighbor v, it generates a random number pðuÞ 2 ½pðvÞ À 1; pðvÞÞ, and transmits pðuÞ and IDðuÞ to its neighbors. If u receives another message later from another neighbor v 0 , u simply stores pðv 0 Þ and IDðv 0 Þ, and does nothing else. Notice that at some point, every node in the graph, except s, receives a message from at least one of its neighbors if the given UDG is connected. Identifier IDðuÞ and random number pðuÞ constitute the rank of u. It is easy to see that at the end of the first phase: 1) each node knows the ranks of all of its neighbors, 2) each node u, except the sink s, has at least one neighbor v such that rankðuÞ &lt; rankðvÞ, and 3) the sink s has the highest rank.</p><p>In the second phase, each node u, except s, selects the nearest node w among its neighbors such that rankðuÞ &lt; rankðwÞ and sends a connect message to w to inform that ðu; wÞ is an edge in the NNT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis</head><p>1. Quality of UDG-NNT. Since each node has at least one neighbor with higher rank, the length of any edge of an NNT is at most R. Hence, that is,</p><formula xml:id="formula_42">Q ðNNT Þ ðn À 1ÞR ¼ Oðn 1À=2 ln =2 nÞ;</formula><formula xml:id="formula_43">E½Q 1 ðNNT Þ ¼ Âð ffiffiffiffiffiffiffiffiffiffiffi ffi n ln n p Þ and E½Q 2 ðNNT Þ ¼ Oðln nÞ. Since E½Q 1 ðMST Þ ¼ Âð ffiffiffi n p</formula><p>Þ and E½Q 2 ðMST Þ ¼ Âð1Þ, we have approximation ratio of Oð ffiffiffiffiffiffiffiffi ln n p Þ and Oðln nÞ for ¼ 1 and 2, respectively. 2. Message complexity. In each phase, each node transmits exactly one message. Thus, the total number of messages is at most 2n ¼ OðnÞ. 3. Work complexity. Each node transmits a message to a distance of at most R. Hence, the total work for transmitting at most 2n messages is</p><formula xml:id="formula_44">W 2nR ¼ Oðn 1À=2 ln =2 nÞ:</formula><p>Using ¼ 2, we have W ¼ Oðln nÞ. 4. Time complexity. Let D be the diameter of the given UDG. Using Chernoff bound, it can be shown that the number of nodes within distance R from any point is Oðln nÞ WHP. Since in each phase each node transmits at most one message, using (4), a node needs to wait at most Oðln 2 nÞ time to transmit its message. Further, the rank propagation messages from the sink s to any other node in the graph traverse at most D links, leading to the running time of OðD ln 2 nÞ for the first phase and Oðln 2 nÞ for the second phase WHP. Thus, the total time is OðD ln 2 nÞ WHP, which is optimal up to polylogarithmic factor; because to build any spanning tree requires ðDÞ time. By a simple analysis with the help of Chernoff bound, it can easily be shown that for the UDG model under consideration, D ¼ Âð1=RÞ ¼ Âð ffiffiffiffiffiffiffiffiffiffiffiffiffiffi n= ln n p Þ WHP, which implies a running time of Oð ffiffiffi n p Á ln 3=2 nÞ WHP. All of the above bounds hold even if a node u picks an arbitrary number (instead of a random number) pðuÞ &lt; pðvÞ after receiving the first message from a neighbor v. However, as indicated by the simulation results, the random choice may improve the bound on quality to Oð1Þ and Oðln ln nÞ for ¼ 1 and 2, respectively. Due to the dependencies among these random numbers, analyzing quality using this randomness seems to be difficult, which we leave for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LOWER BOUNDS ON EXPECTED WORK AND MESSAGE COMPLEXITY OF GHS ALGORITHM</head><p>We compare our NNT algorithm with a well-studied distributed MST algorithm, the GHS algorithm <ref type="bibr" target="#b0">[1]</ref>, which is message-optimal. The upper bounds on the message and time complexity of this algorithm have been shown in <ref type="bibr" target="#b0">[1]</ref>.</p><p>Here, we give lower bounds on the expected work and message complexity of implementing the GHS algorithm in our network model. We do not provide the details of the implementation of GHS algorithm here; instead, we refer to <ref type="bibr" target="#b0">[1]</ref> for a detailed description. Here, we focus on what is essential to show lower bounds on the expected work and message complexity.</p><p>We consider the radius of the neighborhood of each node to be Âð ffiffiffiffiffi ffi ln n n q Þ. Since each node sends at least one message to each of its neighbor (test message-to check if the neighbor is in the same fragment), work and the number of messages of GHS algorithm increases as the number of neighbors of the nodes increases. Here, we note that the way GHS algorithm works, it needs to test the neighbors sequentially. Thus, it cannot take the advantage of local wireless broadcasting. Even if we consider that a node tests all of its neighbors by broadcasting a single message to all of its neighbors, each neighbor must reply to this test message individually. Thus, the number of messages related to testing the neighbors is still no less than the number of neighbors. As a result, the best performance of the GHS algorithm can be achieved by keeping radius of neighborhood as small as possible; we choose Âð ffiffiffiffiffi ffi ln n n q Þ, the minimum required for connectivity <ref type="bibr" target="#b20">[21]</ref>. The expected number of neighbors of a node, i.e., the expected number of nodes within distance Âð ffiffiffiffiffi ffi ln n n q Þ is Âðln nÞ (in fact it is true WHP). Thus, each node exchanges at least ðln nÞ messages; that is, the total expected number of messages is ðn ln nÞ.</p><p>The following lemma is used to find the expected work complexity.</p><p>Lemma 11. Let n nodes are distributed uniformly at random in a unit square and r i be the distance of the ith NN for any arbitrary node. Then,</p><formula xml:id="formula_45">E½r 2 i ¼ ci n ¼ Â i n À Á for some constant c, where 1 c 2.</formula><p>Proof. To get the lower bound, consider any arbitrary node u in the unit square. Now, consider a circle centered at u with unit area, i.e., R 2 ¼ 1 where R is the radius of the circle. Let A sc be the region that is common to both the unit square and the circle (see Fig. <ref type="figure" target="#fig_5">3</ref>), A s the region in the square but not in the circle, and A c the region in the circle but not in the square. Since both the circle and the square have equal area (unit area), the area of A s is equal to the area of A c . Now, consider a rearrangement (repositioning) of the nodes: keep the nodes in A sc as they are and move all nodes in A s to A c ; place the moved nodes in A c randomly following the uniform distribution. Now, it is easy to see that the distance to the ith NN of u in the original arrangement of the nodes (i.e., unit square) is greater than or equal to that in the new arrangement (i.e., the ith NN in the circle centered at u). Now, the probability that a particular node (other than u) is within distance r from u (in the new  </p><formula xml:id="formula_46">) is r 2 R 2 ¼ r 2 R 2 .</formula><p>Then, the probability that there are at least i nodes within distance r</p><formula xml:id="formula_47">C i ðrÞ ¼ 1 À X iÀ1 k¼0 n À 1 k r 2 R 2 k 1 À r 2 R 2 nÀkÀ1 :</formula><p>The probability density function P i ðrÞ ¼ d dr C i ðrÞ, that is</p><formula xml:id="formula_48">P i ðrÞ ¼ À X iÀ1 k¼0 n À 1 k k 2r R 2 r 2 R 2 kÀ1 1 À r 2 R 2 nÀkÀ1 þ X iÀ1 k¼0 n À 1 k ðn À k À 1Þ 2r R 2 r 2 R 2 k 1 À r 2 R 2 nÀkÀ2 :</formula><p>Let T k be the first term inside the above sum, which is</p><formula xml:id="formula_49">nÀ1 k À Á k 2r R 2 r 2 R 2 kÀ1 1 À r 2 R 2 nÀkÀ1</formula><p>. Then,</p><formula xml:id="formula_50">T kþ1 ¼ n À 1 k þ 1 ðk þ 1Þ 2r R 2 r 2 R 2 k 1 À r 2 R 2 nÀkÀ2 ¼ n À 1 k ðn À k À 1Þ 2r R 2 r 2 R 2 k 1 À r 2 R 2 nÀkÀ2</formula><p>:</p><formula xml:id="formula_51">Now, T 0 ¼ 0, thus P i ðrÞ ¼ À P iÀ1 k¼0 ðT k À T kþ1 Þ ¼ T i . Then, E r 2 i Â Ã ! Z R 0 r 2 P i ðrÞdr ¼ iR 2 n À 1 i Z R 0 2r R 2 r 2 R 2 i 1 À r 2 R 2 nÀiÀ1 dr ¼ iR 2 n À 1 i X i k¼0 i k ðÀ1Þ k 1 k þ n À i :</formula><p>Since n À i &gt; 0, using the identity</p><formula xml:id="formula_52">P n k¼0 n k À Á ðÀ1Þ k kþx ¼ x À1 xþn n À Á À1 ([28, p. 188]) E r 2 i Â Ã ! iR 2 n À 1 i 1 ðn À iÞ n i À Á ¼ iR 2 n ¼ i n :</formula><p>To get the upper bound, we consider a node u in a corner of unit square and a circle centered at u and with radius R 0 ¼ ffiffi ffi 2 p , the length of a diagonal of the square. If we redistribute the nodes in this circle uniformly, the average distance to the ith NN can only increase. Thus,</p><formula xml:id="formula_53">E½r 2 i iR 02 n ¼ 2i n . t u</formula><p>Theorem 12. The expected work complexity of GHS algorithm is ðln 2 nÞ.</p><p>Proof. We analyze the work complexity for test, accept, and reject messages only <ref type="bibr" target="#b0">[1]</ref>. By the end of execution of the algorithm, each node tests all of its adjacent edges by using test/accept/reject messages through these edges one by one. The expected number of neighbors of each node is c ln n, for some constant c. Thus, each node sends test messages to or receives reply messages from these c ln n neighbors. Using Lemma 11, the expected work by a node is at least</p><formula xml:id="formula_54">P c ln n i¼1 i n ¼ ð ln 2 n n Þ.</formula><p>For n nodes, by linearity of expectation, the total work</p><formula xml:id="formula_55">W ¼ n Â ð ln 2 n n Þ ¼ ðln 2 nÞ. t u</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SIMULATION RESULTS</head><p>We performed extensive simulations of our algorithms to understand their empirical performance. Our experimental setup is the following: Number of nodes. Varying from 50 to 5,000. Node distributions. Uniform random distributions in the unit square and several realistic distributions of points in an urban setting obtained from TRANSIMS <ref type="bibr" target="#b21">[22]</ref>.</p><p>Number of runs. 50.</p><p>Measures. We compare the NNTs and the MST, with respect to the quality Q ðT Þ ¼ P ðu;vÞ2T d ðu; vÞ for ¼ 1 and 2 and the performance of the algorithms with respect to the following measures: 1) number of messages and 2) work, W ¼ P M i¼1 r i for ¼ 2. To be fair to GHS which does not exploit geometry per se (to compare with Co-NNT, which uses coordinate information of the nodes) we run the GHS algorithm on the Yao graph <ref type="bibr" target="#b29">[29]</ref>. Yao graph is constructed as follows: the 2 angle around each node u is divided into six wedges of equal size (see Fig. <ref type="figure" target="#fig_7">4</ref>), and the edge between u and the nearest node (if any) in each wedge is included in the Yao graph. A Yao graph is sparse (each node has degree at most 6) and contains the MST <ref type="bibr" target="#b29">[29]</ref>. Running GHS on Yao graph reduces its message complexity to Oðn ln nÞ. Note that GHS-Yao should be compared with Co-NNT only as both of them use coordinate information. On the other hand, Random-NNT and UGD-NNT, which do not use coordinate information, must be compared with GHS without Yao graph.</p><p>In our simulations, we ignore the effects of the MAC layer. Our main results are summarized below, which validate our theoretical results in earlier sections:</p><p>1. The Co-NNT algorithm always outperforms the Random-NNT algorithm, with respect to the quality, number of messages, and work. 2. For ¼ 1, all NNTs give a very good approximation to the MST; in particular, the cost of Co-NNT is always within about 10 percent of that of the MST. 3. For ¼ 2, Random-NNT does not give a very good approximation, but UDG-NNT and Co-NNT remains within a factor of 2. 4. The number of messages and the work done by both NNT algorithms are significantly smaller than that by GHS algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Quality of the Spanning Trees</head><p>We present the simulation results of quality Q ðT Þ for ¼ 1 and 2. As Fig. <ref type="figure" target="#fig_8">5</ref> shows, all NNTs compare very well with the MST. As shown earlier, the MST cost is Âð ffiffiffi n p Þ for ¼ 1, and the NNTs seems to be within a small , and the plot for the NNTs are straight lines. Fig. <ref type="figure" target="#fig_1">7</ref> shows Q 2 ðT Þ, the sum of squares of the edge lengths, for the NNTs and MST. Quality Q 2 for both the MST and Co-NNT are constant, and Q 2 ðCo-NNT Þ is within a factor of 2 of Q 2 ðMST Þ . However, Q 2 ðRandom-NNT Þ increases with n as the asymptotic bound is Oðln nÞ-this becomes clear from Fig. <ref type="figure" target="#fig_2">8</ref>. In Section 4, we showed that Q 2 ðUDG-NNT Þ ¼ Oðln nÞ. Fig. <ref type="figure" target="#fig_1">7</ref> shows that Q 2 for UDG-NNT is almost constant. In fact, by looking at the numerical data, we found that it is increasing but at a very slow rate (which is not visible in the figure). This data indicates that a tighter bound for Q 2 ðUDG-NNT Þ may exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Work and Message Complexities to Construct the Spanning Trees</head><p>In this section, we compare work W for ¼ 2 and the number of messages needed by the algorithms. The input to GHS algorithm must be a connected graph to obtain an MST. We consider the radius of the neighborhood to be 1:6 ffiffiffiffiffi ffi ln n n q , the minimum required for connectivity. To determine the neighbors, each node can broadcast a message to distance 1:6 ffiffiffiffiffi ffi ln n n q and consider another node as a neighbor if the node can hear the message from the other node. However, we did not incur any cost on GHS algorithm to find the neighbors (thus, favoring GHS)-for GHS algorithm, we assume that each node knows its neighbors and their distances. In addition, we also simulate GHS on the Yao graph. Each node finds its Yao neighbors first, then executes GHS algorithm.</p><p>Fig. <ref type="figure" target="#fig_11">9</ref> depicts the number of messages needed to construct the trees. We see that the number of messages for NNT algorithms is significantly smaller than that for GHS algorithm. Moreover, the number of messages for NNT algorithms increases linearly. On the other hand, the number of messages for GHS increases at a slightly higher rate. In fact, the message complexity for GHS is ðn ln nÞ.</p><p>The required work for NNT algorithms is also significantly less than that of GHS algorithm (Fig. <ref type="figure" target="#fig_3">10</ref>). In addition, with the number of nodes, work for NNT algorithms increases in a lower rate than that of GHS algorithm. In terms of both the number of messages and work, GHS with Yao graph is more efficient than GHS without Yao graph,    as expected. However, it is still much less efficient than the Co-NNT algorithm. Analytically, we know that for ¼ 2, the work complexities for Co-NNT, Random-NNT, UDG-NNT, and GHS algorithms are Oð1Þ, Oðln nÞ, Oðln nÞ, and ðln 2 nÞ, respectively. We can also observe these results from experimental data. Let work w ¼ c ln a n. Then, ln w ¼ ln c þ a ln ln n. Thus, if we plot ln w versus ln ln n, the graph is an straight line and the slope of the line is a, the power of log . In Fig. <ref type="figure" target="#fig_12">11</ref>, the slope for GHS is greater than 2 and for both Random-NNT and UDG-NNT, it is about 1. For Co-NNT, the slope is 0, which indicates the work is Oð1Þ, whereas for GHS-Yao, the slope is more than 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experiments on Real Data</head><p>We consider a distribution of points in a section of downtown Portland, OR, measuring 2:9 Â 2:95 km approximately 9 km 2 . The distribution of points, corresponding to cars on the roadway, was obtained from the TRANSIMS simulation <ref type="bibr" target="#b21">[22]</ref>, which does a very detailed modeling of urban traffic, combining a variety of data sources ranging from census data to activity surveys to land use data. We use three snapshots, at 1-minute intervals. The distribution of nodes at one of the snapshots is shown in Fig. <ref type="figure" target="#fig_13">12</ref>. The experimental results on these three snapshots are given in Table <ref type="table">2</ref>. The work is computed for ¼ 2.</p><p>We see that the number of messages and work are significantly larger for GHS algorithm. The work is about 10 times larger and the number of messages is about 5 times larger than those of NNT algorithms. On the other hand, both Q 1 and Q 2 for Co-NNT is within 2-approximation. Although approximation for Q 2 in Random-NNT is large, for Q 1 , Random-NNT also provides a close approximation. In these experiments, we only considered the Yao graph assuming that the nodes know their coordinates. If the coordinates are not available, for GHS algorithm, the input need to be a complete graph (each node is a neighbor of the others) to make sure connectivity since the points does not follow any particular (say, uniform) distribution. Thus, GHS algorithm would incur much larger work and messages. In that case, Random-NNT can still be a good choice over GHS, by sacrificing quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DYNAMIC ALGORITHM FOR NNT</head><p>The local nature of the NNT algorithms naturally allows for simple dynamic versions, where the goal is to maintain a tree of good quality, as nodes are added or deleted. As long as we maintain an NNT, the cost remains within the bounds proven in the previous theorems. The measure we focus on, in the dynamic setting, is the expected number of rearrangements, when a node is added or deleted. We define the term number of rearrangements to be the number of the edges to be deleted from the tree and added to the tree, to maintain NNT, due to addition or deletion of a node.</p><p>For the dynamic Random-NNT algorithm, each node v maintains two lists QðvÞ and LðvÞ, where QðvÞ is the set of nodes in closed ball Bðv; dðv; nntðvÞÞÞ and LðvÞ ¼ fujv 2 QðuÞg. After a node v is added to the network, there can be some nodes u such that rankðvÞ &gt; rankðuÞ and dðu; vÞ &lt; dðu; nntðuÞÞ. In that case, u must change its connection from previous nntðuÞ to v, the new nntðuÞ, and we say u is "affected" by v. The data structures QðvÞ and LðvÞ facilitate an efficient way to find the affected nodes. Let node v just joined the network, and consider a partitioning of the 2 angle around v into six equal wedges as shown in Fig. <ref type="figure" target="#fig_5">13</ref>. Let w 1 ; w 2 ; . . . ; w 6 be the closest nodes in these wedges; these nodes can be determined, for instance, by using directional antennas (such an assumption is made in several papers, e.g., <ref type="bibr" target="#b9">[10]</ref>). Using the triangle inequality, it is easy to see that only the nodes in Lðw i Þ can be affected. The details are given in Algorithm 3.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 2</head><p>Experiment Results for Snapshots 1, 2, and 3 Fig. <ref type="figure" target="#fig_5">13</ref>. Each wedge around node u is 60 degree. v 1 ; v 2 ; v 3 . . . are the nodes in one wedge in increasing order of distance from u.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 7 .</head><label>7</label><figDesc>The expected quality of Co-NNT for ¼ 1 and 2 are O ffiffiffi n p ð Þ and Oð1Þ, respectively. Proof. Consider an arbitrary node u and a vertical line through u (the thick leftmost vertical line shown in Fig. 1). This vertical line divides the given unit square into two rectangles. The left rectangle is not shown in the figure. Node u connects to the nearest node in the right rectangle, which is shown in Fig. 1. For the purpose of analysis, let us subdivide this right rectangle into square cells, where each side of each cell is b ¼ 1 ffiffi n p . If necessary, include empty space from the right-hand side of the unit square to make the cells in the rightmost column squares with sides b ¼ 1 ffiffi n p .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 8 .</head><label>8</label><figDesc>The expected work complexity of Co-NNT algorithm, for ¼ 1 and 2 are O ffiffiffi n p ð Þ and Oð1Þ, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The leftmost thick vertical line through node u divides the unit square into two rectangles. The right rectangle, which is shown in the figure, is subdivided into square cells with sides b ¼ 1 ffiffi n p , by adding empty space to the rightmost column if necessary. Here, x ffiffiffi n p and y ¼ ffiffiffi n p . Then, the cells are rearranged in a single row.</figDesc><graphic coords="8,29.48,69.17,244.46,63.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Three cases for a node u in the unit square. In phase i, the radius of the circle centered at u is r i ¼ 2 i = ffiffiffi n p ; only the nodes in the shaded region reply back to u.</figDesc><graphic coords="9,48.02,69.17,207.44,70.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration for Lemma 11.</figDesc><graphic coords="10,372.30,69.17,84.81,72.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>arrangement</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Construction of Yao graph. Each wedges is 60 degrees. Node u have an edge with the nearest node in each wedge.</figDesc><graphic coords="11,361.98,69.17,105.51,65.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Sum of the lengths of the edges, Q 1 ðT Þ, for MST, Random-NNT, UDG-NNT, and Co-NNT.</figDesc><graphic coords="12,53.80,239.19,195.87,138.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Sum of the lengths of the edges, Q 1 ðT Þ, plotted with ffiffiffi n p .</figDesc><graphic coords="12,53.80,402.07,195.87,140.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Q 2 ðT Þ for Random-NNT and UDG-NNT with respect to ln n.</figDesc><graphic coords="12,316.80,233.52,195.87,140.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Number of messages needed to construct the spanning trees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Slope of the lines indicates the powers of log in work complexity.</figDesc><graphic coords="13,53.80,605.99,195.87,140.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The distribution of nodes in one of the snapshots. Fig. 10. Work done by the algorithms. In the figure, the lines for Random-NNT and UDG-NNT almost merged together.</figDesc><graphic coords="13,53.80,69.17,195.87,141.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1</head><label>1</label><figDesc>Performance of GHS and NNT Algorithmsboth Random-NNT and Co-NNT is Oðln 3 nÞ WHP,3 while the running time of GHS is Oðn ln nÞ.</figDesc><table><row><cell>UDG-NNT is Oð</cell><cell>ffiffiffi n p</cell><cell>The running time of Á ln 3=2 nÞ WHP, which is time optimal up</cell></row><row><cell cols="3">to a polylogarithmic factor (see Section 4).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The details are given in Algorithm 2. / and coordinates ðx u ; y u Þ for Co-NNT i i þ 1 until (receipt of an available message) or ðr i ¼ 'Þ For all v, upon receipt of request; v; rankinfo messages M, and the time complexity of NNT algorithms. Although our analysis generalizes to any , for clarity, we consider ¼ 1 and 2. It is known that E½Q 1 ðMST Þ is asymptotically Âð ffiffiffi n p Þ, and E½Q 2 ðMST Þ is asymptotically Âð1Þ [24], [25]. We show that for Co-NNT, E½Q 1 ¼ Oð ffiffiffi n p Þ and E½Q 2 ¼ Oð1Þ, giving an approximation factor of Oð1Þ for both of them. For Random-NNT, E½Q 1 ¼ Oð ffiffiffi n p Þ and E½Q 2 ¼ Oðln nÞ, giving approximation factors of Oð1Þ and Oðln nÞ, respectively. The expected work complexities for Random-NNT and Co-NNT (for ¼ 2)</figDesc><table><row><cell>Algorithm 2: Distributed NNT algorithm for wireless networks /* The algorithm is executed by each node u independently and simultaneously. Messages are written in the format msg name; sender; ½recipient; ½other info h i . When a message is broadcasted, the recipient is not specified. ' is the maximum possible distance between any two nodes.*/ i 1 Repeat Set transmission radius (power level) r i 2 h if rankðvÞ &gt; rankðuÞ, set transmission radius to distanceðu; vÞ i do send available; u; v h ito v Upon receipt of "available" message(s): Select the nearest node v from the senders Send connect; u; v h ito v 3.2 Analysis of the NNT Algorithms We measure the quality of the tree produced by NNT, Q ðT Þ ¼ P ðu;vÞ2T d ðu; vÞ, the work complexity w ¼ P M i¼1 r i , the number of</cell></row></table><note><p>i ffiffi n p If r i &gt; ', set r i ' Broadcast request; u; rankinfo h i // rankinfo is the random number // pðuÞ &amp; IDðuÞ for Random-NNT /</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Both are well motivated: when nodes do not know their geometric coordinates, Random-NNT is natural in contrast to most previous work (e.g.,<ref type="bibr" target="#b4">[5]</ref> and<ref type="bibr" target="#b5">[6]</ref> assume that nodes know their coordinates or their relative locations) but if nodes know their coordinate location (say, using GPS), then Co-NNT is more suitable.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>That is, with probability at least 1 À 1=n ð1Þ .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, VOL. 20, NO. 1, JANUARY 2009</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>If no such node is designated, a leader election algorithm can be executed before running the distributed NNT algorithm.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors are grateful to the referees for the careful reading and detailed comments that helped greatly in improving this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm 3: Dynamic Random-NNT If a node v is added: 1) Node v chooses a random rank, and creates two lists of nodes, QðvÞ and LðvÞ, which are initially empty. 2) Node v checks its neighbors v 1 ; v 2 ; . . . in nondecreasing order of dðv; v i Þ, till it finds the closest neighbor v j of higher rank. Then v adds each such v i , i j, in QðvÞ and sends a message to v i to add it in Lðv i Þ. 3) Node v finds the closest node in each of the 6 wedges.</p><p>For each of these closest nodes w, v sends an UPDATE message to each u 2 LðwÞ. Node u, upon receipt of this message, does the following: a) Let u 1 ; u 2 ; . . . be the neighbors of u in non decreasing order of dðu; u i Þ, and u k be nntðuÞ. b) If dðu; vÞ dðu; u k Þ and rankðvÞ &gt; rankðuÞ, u removes u ' from QðuÞ and itself from Lðu ' Þ, 8j &lt; ' k, where v ¼ u j . Further u connects to v, instead of u k , and adds v to QðuÞ and itself to LðvÞ. c) If dðu; vÞ dðu; u k Þ and rankðvÞ &lt; rankðuÞ, u adds v to QðuÞ and itself to LðvÞ. If a node v is deleted: 1) v sends a message to each u 2 QðvÞ. Node u, after receiving this message, removes v from LðuÞ. 2) v also sends a message to each u 2 LðvÞ. Node u, upon receipt of this message, removes v from QðuÞ. If nntðuÞ ¼ v, u checks the neighbors v i beginning from distance dðu; vÞ onward until it finds the new nearest node of higher rank, adds each such v i in QðvÞ, and sends a message to v i to add u in Lðv i Þ.</p><p>It is also easy to see that the lists Lð:Þ and Qð:Þ of the nodes are correctly updated after addition and deletion of a node. Since u 2 LðvÞ if and only if v 2 QðuÞ, and the algorithm always updates LðvÞ and QðuÞ or LðuÞ and QðvÞ in pairs, it is sufficient to show that LðvÞ and QðvÞ are updated correctly when node v is added or deleted. When v is added, QðvÞ is created in step 2 following its definition straightforwardly. For LðvÞ, notice that if u 2 LðvÞ, then u 2 Lðw i Þ for some w i , by the triangle inequality. Thus, steps 3b and 3c correctly update LðvÞ. When v is deleted, again, the consistency of LðvÞ and QðvÞ follows directly from their definitions. Thus, Algorithm Dynamic Random-NNT works correctly.</p><p>Next, we analyze the number of rearrangements needed for each insertion and deletion. The complexity of a rearrangement depends on the model of the network and communication. For the purpose of analysis, for any node v, we say that a charge of 1 is placed on every node u in closed ball Bðv; dðv; nntðvÞÞÞ. First, we show the following lemma, which bounds the charge placed on any node.</p><p>Lemma 13. For any sequence of n node insertions and deletions, the total charge on any node u is Oðln nÞ WHP.</p><p>Proof. Consider any point u, and partition the 2 angle around u into six cones, each of angle =3. Consider one such cone. We prove that the total charge from points in this cone on u is Oðln nÞ, WHP. Order the points in the cone as v 1 ; v 2 ; . . . , based on increasing distance from u (Fig. <ref type="figure">13</ref>). Node v i places a charge on u only if rankðv i Þ &gt; rankðv j Þ, for all 1 j &lt; i. The probability of this event to occur is at most 1=i (the probability that a particular number is the largest among i identical random numbers is 1=i). Thus, the total expected charge on u from these points is at most P nÀ1 i¼1 ð1=iÞ ln n. In order to bound the maximum charge on any node, we use a variant of Chernoff bound (Lemma 14) that holds in the presence of dependencies among the variables. Lemma 14 <ref type="bibr">([30]</ref>). Let X 1 ; X 2 ; . . . ; X l 2 f0; 1g be random variables such that for all i, and for any S fX 1 ; . . . ; X i g,</p><p>Let EðvÞ be the event that node v places a charge on u. In order to use the Chernoff bound, we need to show that, for any i, and any subset S &amp; fv 1 ; . . . ; v i g, Pr½Eðv iþ1 Þj V w2S</p><p>EðwÞ Pr½Eðv iþ1 Þ. First, suppose dðw; v iþ1 Þ ! dðw; uÞ for each w 2 S. Then, the events V w2S EðwÞ do not place any constraint on rankðv iþ1 Þ, relative to rankðv j Þ; j i, and therefore, Pr½Eðv iþ1 Þj V w2S EðwÞ ¼ Pr½Eðv iþ1 Þ. Next, suppose dðw; v iþ1 Þ &lt; dðw; uÞ for some w 2 S. Then, occurrence of the event EðwÞ implies that rankðwÞ &gt; rankðv iþ1 Þ. Further, dðv iþ1 ; wÞ &lt; dðw; uÞ dðv iþ1 ; uÞ. Therefore, Pr½Eðv iþ1 Þj V w2S EðwÞ ¼ 0 Pr½Eðv iþ1 Þ. Next, we apply the Chernoff bound with ¼ 5 ln n À 1, where is the expected charge on u. Since ln n, we have &gt; 0. Let X be the total charge on u. Then</p><p>Thus, with probability at least 1 À 1 n 3 , charge on u is Oðln nÞ. Using the union bound, it holds simultaneously for all n steps of addition and deletion of nodes with probability at least </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUDING REMARKS AND FURTHER WORK</head><p>The NNT paradigm is a simple and local scheme for constructing and maintaining low-cost trees in an ad hoc network setting. It does not require any complex synchronization and is naturally robust. We study various properties, such as quality, degree, and dynamic complexity for different NNTs where the nodes are uniformly distributed in two-dimensional plane, and it shows very promising results. Among the questions for further work, the most interesting ones are:</p><p>1. analyze the NNT algorithms for arbitrary point distributions; 2. quantify the tradeoff between the amount of local information needed and the quality of the tree produced; 3. obtain a tighter bound for quality of UDG-NNT; and 4. determine whether it is possible to design a distributed exact MST algorithm with better work complexity than GHS, and obtain a lower bound on work complexity. . For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Distributed Algorithm for Minimum-Weight Spanning Trees</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gallager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Humblet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="77" />
			<date type="published" when="1983-01">Jan. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Impact of Data Aggregation in Wireless Sensor Networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Krishnamachari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second Int&apos;l Workshop Distributed Event-Based Systems (DEBS &apos;02)</title>
		<meeting>Second Int&apos;l Workshop Distributed Event-Based Systems (DEBS &apos;02)</meeting>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unconditional Lower Bounds on the Time-Approximation Tradeoffs for the Distributed Minimum Spanning Tree Problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36th ACM Symp. Theory of Computing (STOC &apos;04)</title>
		<meeting>36th ACM Symp. Theory of Computing (STOC &apos;04)</meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distributed Computing: A Locality-Sensitive Approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Localized Low-Weight Graph and Its Applications in Wireless Ad Hoc Networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithmic, Geometric and Graphs Issues in Wireless Networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Wireless Comm. and Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="140" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An Application-Specific Protocol Architecture for Wireless Microsensor Networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Heinzelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chandrakasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Wireless Comm</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="660" to="670" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Design and Analysis of an MST-Based Topology Control Algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Topology Control of Ad Hoc Wireless Networks for Energy Efficiency</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cardei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computers</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1629" to="1635" />
			<date type="published" when="2004-12">Dec. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed Topology Control for Power Efficient Operation in Multihop Wireless Ad Hoc Networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wattenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM &apos;01</title>
		<meeting>IEEE INFOCOM &apos;01</meeting>
		<imprint>
			<date type="published" when="2001-04">Apr. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Power Consumption in Packet Radio Networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kirousis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kranakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krizanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pelc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">243</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="289" to="305" />
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed Construction of Planar Spanner and Routing for Ad Hoc Wireless Networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Calinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sparse Power Efficient Topology for Wireless Networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 35th Ann. Hawaii Int&apos;l Conf. System Sciences (HICSS)</title>
		<meeting>35th Ann. Hawaii Int&apos;l Conf. System Sciences (HICSS)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Analysis of Several Heuristics for the Traveling Salesman Problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rosenkrantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="563" to="581" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic Steiner Tree Problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Imase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Waxman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Siam J. Discrete Math</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="369" to="384" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rivest</surname></persName>
		</author>
		<title level="m">Introduction to Algorithms</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An Optimal Bound for the MST Algorithm to Compute Energy Efficient Broadcast Trees in Wireless Networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ambuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 32nd Int&apos;l Colloquium on Automata, Languages and Programming (ICALP &apos;05)</title>
		<meeting>32nd Int&apos;l Colloquium on Automata, Languages and Programming (ICALP &apos;05)</meeting>
		<imprint>
			<date type="published" when="2005-11">Nov. 2005</date>
			<biblScope unit="page" from="1139" to="1150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Minimum-Energy Broadcasting in Static Ad Hoc Wireless Networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Calinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wireless Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="607" to="617" />
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the Complexity of Computing Minimum Energy Consumption Broadcast Subgraph</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clementi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Crescenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Penna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vocca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Ann. Symp. Theoretical Aspects of Computer Science (STACS &apos;01)</title>
		<meeting>18th Ann. Symp. Theoretical Aspects of Computer Science (STACS &apos;01)</meeting>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
			<biblScope unit="page" from="121" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Impact of Network Density on Data Aggregation in Wireless Sensor Networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Intanagonwiwat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heidemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Int&apos;l Conf. Distributed Computing Systems (ICDCS &apos;02)</title>
		<meeting>22nd Int&apos;l Conf. Distributed Computing Systems (ICDCS &apos;02)</meeting>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Critical Power for Asymptotic Connectivity in Wireless Networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Analysis, Control, Optimization and Applications: A Volume in Honor of W.H. Fleming</title>
		<imprint>
			<date type="published" when="1998-03">Mar. 1998</date>
			<biblScope unit="page" from="547" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<ptr target="http://transims.tsasa.lanl.gov" />
		<title level="m">Transportation Analysis Simulation System (TRANSIMS)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Protocols and Impossibility Results for Gossip-Based Communication Mechanisms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 43rd</title>
		<meeting>43rd</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Ann</forename></persName>
		</author>
		<title level="m">IEEE Symp. Foundations of Computer Science (FOCS &apos;02)</title>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Asymptotics for Euclidean Minimal Spanning Trees on Random Points</title>
		<author>
			<persName><forename type="first">J</forename><surname>Steele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probability Theory and Related Fields</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="247" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Minimum Spanning Tree Constant in Geometrical Probability and under the Independent Model: A Unified Approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Avram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsimas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="130" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple Distributed ðÁ þ 1Þ-coloring of Graphs</title>
		<author>
			<persName><forename type="first">O</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="229" to="232" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<title level="m">Randomized Algorithms</title>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Knuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Patashnik</surname></persName>
		</author>
		<title level="m">Concrete Mathematics: A Foundation for Computer Science</title>
		<imprint>
			<publisher>Addison-Wesley Publishing</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>second ed</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On Constructing Minimum Spanning Trees in k-Dimensional Spaces and Related Problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="721" to="736" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Randomized Distributed Edge Coloring via an Extension of the Chernoff-Hoeffding Bounds</title>
		<author>
			<persName><forename type="first">A</forename><surname>Panconesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Computing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="350" to="368" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
