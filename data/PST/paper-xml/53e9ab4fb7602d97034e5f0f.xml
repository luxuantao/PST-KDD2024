<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">N</forename><surname>Farvardin</surname></persName>
							<affiliation key="aff0">
								<address>
									<postCode>95052-8090</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Electrical Engineering Department and the Institute for Systems Research</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">94806CD88EC32AB7D44AD6A507DE6BF4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A Perceptually Motivated Three-Component Image Model-Part I: Description of the Model Xiaonong Ran, Member, IEEE and Abstract-In this paper, some psychovisual properties of the human visual system are discussed and interpreted in a mathematical framework. The formation of perception is described by appropriate minimization problems and the edge information is found to be of primary importance in visual perception. Having introduced the concept of edge strength, it is demonstrated that strong edges are of higher perceptual importance than weaker edges (textures). We have also found that smooth areas of an image influence our perception together with the edge information, and that this influence can be mathematically described via a minimization problem. Based on this study, we have proposed to decompose the image into three components: i) primary, ii) smooth, and iii) texture, which contain, respectively, the strong edges, the background, and the textures. An algorithm is developed to generate the three-component image model, and an example is provided in which the resulting three components demonstrate the specific properties as expected. Finally, it is shown that the primary component provides a superior representation of the strong edge information as compared with the popular Laplacian-Gaussian operator edge extraction scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>N most image compression systems, the primary objective I is that of a high fidelity reconstruction of the original image with as small a number of bits as possible. Clearly, the fidelity criterion used for the design of the compression system plays a significant role on the system performance. A commonly used fidelity criterion is the mean squarederror <ref type="bibr">(MSE)</ref>. The main attributes of the MSE are i) its mathematical tractability and ii) the fact that small values of MSE correspond to perceptually high quality reconstructed images. The latter fact is important since the human eye is commonly the final judge of the reconstructed image. With MSE and its variants as fidelity criterion, various image coding techniques such as adaptive transform coding, various forms of vector quantization, and subband coding have been studied <ref type="bibr">[ 11-[4]</ref>. While these techniques have led to relatively high quality reconstructed images at bit rates about 1.0 bit/pixel and above, they usually produce specific types of visible distortion (blockiness, blurred edges, jagged edges, etc.) at lower bit rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nariman Farvardin, Member, IEEE</head><p>Over the past decade, a new class of image coding schemes, generally referred to as second-generation techniques, has been developed [5]-[8]. These methods, which have exhibited improvements over the MSE-based schemes at very low bit rates, attempt to describe the image in terms of more nearly physical entities such as regions or contours for a more compact representation of the image and hence a higher compression ratio 161; this is in contrast with the waveform representation of the image in the MSE-based schemes.</p><p>In this paper, in an approach not unlike that of secondgeneration image coding techniques, we have developed a model for real-world imagery based on those features of the image signal that are of distinct significance to human perception. Specifically, we have formalized some previous psychovisual studies <ref type="bibr">[ 9 ]</ref> , [ 101 to characterize the features of the image signal that are responsible for the formation of perception in the human visual system (HVS). Some observations on the binocular nature of the human vision in <ref type="bibr">[9]</ref> are used to formulate the formation of perception as a minimization of the intensity variation energy; this has led to the notion of "strong edges," which apparently plays a significant role in perception. Additionally, we have used the psychovisual observations in [ 101 to mathematically formulate the interaction between the strong edges and areas of smooth intensity variation. To characterize the strong edges. we have introduced the concept of the "stressed image" and defined the strong edges as the high curvature energy pixels of the stressed image. The stressed image is generated by a space-variant lowpass filtering of the original image. The above formalism has led to a three-component image model consisting of i) the strong edge, ii) smooth intensity variation, and iii) texture components.</p><p>The three-component model developed here is quite general and might prove useful in various image processing situations. However, it was primarily developed for image coding applications where the different features of the image signal can be classified (according to the role they play in the formation of human perception), extracted, and treated separately for subsequent encoding. This idea is similar to the sketch-based image coding scheme of <ref type="bibr">[7]</ref> and [SI, which consists of two components: one is similar to the strong edge component of the three-component model developed here, and the other is simply the residual between the original image and an image obtained merely from the strong edge information. In the sketch-based scheme, the strong edges are extracted by the Laplacian-Gaussian operator (LGO) followed by a gradient operator. This edge extraction scheme suffers from certain drawbacks that will be discussed in detail. In addition, a careful comparison between the LGO-based method and the edge extraction scheme associated with the three-component model will be presented. The applications of the three-component image model in specific image coding schemes are presented in Part I1 of this paper <ref type="bibr">[ll]</ref>.</p><p>Part I is organized as follows. In Section 11, some psychovisual properties of the human perception are presented and discussed. This is followed by the characterization of the strong edge information in Section 111 and development of an algorithm for the extraction of strong edges along with the description of the three-component image model in Section IV. In Section V , an example of the three-component image model is provided and certain comparisons against the LGObased edge extraction scheme are presented. A summary and conclusions are provided in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">PSYCHOVISUAL ASPECTS OF THE HUMAN VISUAL SYSTEM</head><p>In this section, we describe some observations on psychovisual aspects of the human visual system. The objective is to extract and discriminate different properties of image signals that are of significance to our perception. Some interpretations in the context of image coding are provided to establish the connection to Part I1 of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Edge Itformation of Image Signals</head><p>As described in <ref type="bibr">[9]</ref>, in natural binocular vision, when two views are presented with two forms that are different (in the sense that they do not admit of being combined into the image of a single object), the images of both forms will generally be seen at the same time superposed on one another in the field of view. Usually, in some locations of the field of view, one image dominates the other, and vice versa in other parts of the field. When broad black-and-white figures are displayed to both views, the general rule is that the dominating image along an edge and in its vicinity will be the one that owns the edge. As an example, consider Fig. <ref type="figure">1</ref>, in which we have two bars, one vertical and one horizontal. When the vertical bar is seen by the left eye and the horizontal bar by the right eye, without devoting exclusive attention to any of the two,l the total effect will be an image similar to Fig. <ref type="figure">2</ref>. As shown in Fig. <ref type="figure">2</ref>, the perception will be a cross that is black over the center square; the background appears white. The four arms of the cross are perfectly black at their ends and almost entirely white near the center square, with transitions in between.</p><p>Based on this phenomenon, we may conclude that the collection of the individual pixel intensity values without any interaction between them (the most primitive property of the image) is not what produces the visual perception. For otherwise, the image in the field of view should be formed at each pixel with an intensity produced only by the two corresponding pixel intensities of the two images according to a certain law, and thus the perception should be a uniform combination of the two pictures. Obviously, the image shown in Fig. <ref type="figure">2</ref> cannot be constructed by a unform combination of the two images in Fig. <ref type="figure">1</ref>.</p><p>We conjecture that here it is the edge information (to be defined next) of the image signal that arouses our visual perception. For the images in Fig. <ref type="figure">1</ref>, the edge information is described by i) the locations of variations of intensity values and ii) the related inrensitv values at these locations. For example, in <ref type="bibr">Fig. l(a)</ref>, the locations of the intensity variations are along the border of the vertical black bar, and the related intensity values are those intensity values immediately inside and outside the border. The above actually describes what we generally refer to as an edge. This edge basically has two related intensity values, zero (255 corresponding to black (white), representing the intensity variation. We call the contour formed by the lower intensity value the lower edge brim and the contour formed by the higher intensity value the upper edge brim. In <ref type="bibr">Fig. l(a)</ref>, the rectangular contour of the lower edge brim is just inside the border, while the one for the upper edge brim is just outside. Since the locations and intensity values of the lower and upper edge brims completely define the corresponding edge, we may define an edge through its brims, which will be mathematically ch&lt;aracterized later in the paper.</p><p>We now go back to our conjecture that the edge information is responsible for the formation of the visual perception. Remarkably, this conjecture is verified in this case by actually producing Fig. <ref type="figure">2</ref> only from the knowledge of lower and upper edge brims of the two images in Fig. <ref type="figure">1</ref> by minimizing the variation in intensity values as described below.</p><p>Let a generic digital image of size M x A4 be denoted by an array of real numbers { x i , j , i , j = 0 , l . . . . , M -l}, where is the intensity value of the pixel on the ith row and jth column. Note that the image can be defined as a set X of triples: X = {(zlj,xi,j), i l j = 0 , 1 , . . . M -I} c R3. Then the lower and upper edge brims of an image X are a subset of X . Let the subsets of lower and upper edge brims of the images (a) and (b) in Fig. <ref type="figure">1</ref> be denoted by B, and a b , respectively. We combine the information in f?, and by forming a set f? from B, U f?b in the following way. We first define two projection functions, f1:R" -+ R2 where f l ( ( i , j * x ) )</p><p>= ( i , j ) , and f 2 :</p><p>R3 -+ R where f 2 ( ( i l j r x ) ) = x. We denote by fk(A) the image of a set A under f k , k = 1,2. For a set A c R3, we also define A(29.7) = {s:s E A and f l ( s ) = ( z , j ) } . Then the set B is defined as where %z,J is the average value of the elements of the set f 2 ( (B, U @,)("')). In other words, B is a "linear" combination of B, and f?b in the above sense.</p><p>Before describing how the image shown in Fig. <ref type="figure">2</ref>, denoted by X,, can be obtained from the edge information contained in B, we make the following definition. The variation energy of intensity values of an image X is defined as</p><formula xml:id="formula_0">i=o j = o</formula><p>Our objective is to generate an image X , solely from the information in B. In other words, we seek to find an image X , having minimum information while containing the information in B. We call this concept the minimum information principle.2 We quantify the information content of an image X by its variation energy V,u, and define X , = {(i:jlxS,j)} to be the solution of the minimization problem rnin Vk, subject to X n B = B (11.3) t G J 1 where X = { ( i , j , x i , j ) } . For example, an image with uniform intensity values has zero variation energy, and thus contains the smallest amount of information by the above definition. Because of the quadratic nature of the objective function V x , we may write it in matrix notation: xTLvx + xrHxa +</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X ~D X B ,</head><p>where x is a vector in RM2-lnl containing elements xi,j. (Ilj) 6 f l ( B ) in a certain order, xu is a vector in Rial with elements x,i,j1 ( i , j ) E f l ( B ) , the matrix LIT is a nonnegative definite (positive definite when B # 8) matrix, and the superscript indicates vector transpose. When B # 8, the unique solution of problem (11.3) is given by the vector x, 5 -Lv'Hx~/2. For the given example, the resulting *The term "minimum information principle" is motivated by a concept, referred to as "no news is good news," introduced in [ 121. image X, is shown in Fig. <ref type="figure">2</ref>; this image, obtained from our minimization problem, is very similar to the corresponding illustration shown in Fig. <ref type="figure">73</ref> of <ref type="bibr">[9]</ref>.</p><p>Therefore, in an image information system for which the human visual system is the final receiver, the necessary and sufficient information to be transmitted and/or stored for the images in Fig. <ref type="figure">1</ref> is the edge information.3</p><p>To summarize, we explain the phenomenon in Fig. <ref type="figure">2</ref> with a conjecture that the visual perception is derived from the edge information of the image. Furthermore, the perception can be illustrated by an image that is the solution of a minimization problem similar to (11.3). In this sense, we may take the mechanism govemed by this minimization problem as the one that forms our perception.</p><p>In the following subsection we address some issues on the relative perceptual importance of different types of edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Strong Edges and Textures</head><p>Shown in Fig. <ref type="figure">3</ref> are two images, (a) and (b), separately presented to the two eyes. Image (a), examined by the left eye, is a black cross, while image (b) for the right eye is a network of slanted black lines over a white background. Without any special attention to either image, the usual binocular perception would be similar to the image shown in Fig. <ref type="figure" target="#fig_2">4</ref>. That is, the image of the cross prevails along its edges; only at some distance from these edges does the network pattern become visible <ref type="bibr">[9]</ref>.</p><p>Clearly, the two images in Fig. <ref type="figure">3</ref> do not have edge information of the same importance; otherwise, in the vicinity of the 'It should he noted that the binocular vision is used in a unique way, viewing two unrelated images, to amve at some conclusions on how we perceive monocular images. is formed by solving a problem similar to (11.3) with 2 3 , as the fixed-point set; we call this image XA. For distances sufficiently far from B,, where the influence of the strong edge diminishes, the image for the perception is formed by solving a problem like (11.3) with B, as the fixed-point set; we call this image X B . In between these two extreme cases, the perception is formed according to AX, + (1 -X)XB where X decreases quadratically from 1 to 0 as a function of the distance from the strong edge. Our results indicate that this linear combination with the chosen weighting factor results in an image (shown in Fig. <ref type="figure" target="#fig_2">4</ref>) that agrees with our perception as well as the description given in pp. <ref type="bibr">496-497 of [9]</ref>.</p><p>We conclude that stronger edges are of higher importance to our perception. Therefore, to design an image information transmission system, one should treat edges In accordance with their strengths to achieve high efficiency. This concept is especially important for image transmission systems at low bit rates. edges of the cross, the network pattem should not disappear. Thus, in this case, we cannot combine the edge information "linearly" as in (11.1). We speculate that an edge has a strength associated with it. Edges of relatively high (low) strength have stronger (weaker) influence on our perception, and may be called stronger (weaker) edges. Weaker edges commonly correspond to textures in the usual sense, and thus are referred to as textures. As compared with textures, we may simply refer to stronger edges as strong edges.</p><p>Apparently, edges with larger intensity variations and shorter widths (distance between the corresponding edge brims) are relatively more significant to our perception, and are generally called sharp edges. However, edges do not individually influence our perception; rather, they locally interact with one another. For example, the edges in the network of Fig. <ref type="figure">3</ref>(b) actually have the same intensity variation and width as those of the cross, but they have less perceptual significance when compared with the edges of the cross. Based original strength that is proportional to i) the intensity variation edges interact with each other in an inhibitive way. The more closely two edges stand, the more severely their strengths are weakened. The resulting strength of an edge after it interacts with the neighboring edges will be called the strength of the edge. Thus stronger edges are those edges of higher intensity variation and shorter width that are relatively isolated, while weaker edges are those of lower intensity variation and longer width, being relatively crowded with other edges.</p><p>We now use this qualitative description of edge strength to explain the phenomenon of Fig. <ref type="figure" target="#fig_2">4</ref>. Let us denote the subsets of lower and upper edge brims of images (a) and (b) in Fig. <ref type="figure">3</ref> by B, and Bb, respectively, and combine the information in a, and Bl, based on the following arguments. In the neighborhood of weak edges, strong edges dominate: this domination will diminish gradually as a function of the distance from the stronger edge. After a certain distance from the stronger edge, weaker edges will show up and will eventually dominate at distances far enough from the stronger edge.</p><p>Our experiments indicate that the phenomenon for Figs. we conjecture that edge has an circular edges of the inner and outer disks in Fig. <ref type="figure">5</ref>(a). We between its two edge brims and ii) its width. Neighboring perception by X, = {(z,,j, . . ! , , )}.</p><p>Then, we that x,</p><formula xml:id="formula_1">M-1 hl-1 rriin x (yZ,] -s, J ) 2 + (11.4) J } a=O 3 x 0 subject to y n B = B</formula><p>, where 2 0 is a vveighting factor on the squared errors between X and y in the objective function, y = { ( z , ~. y ~, ~) } , and B # 0. Notice than when X = 0, X, would be an image of two disks with constiwlt intensity values for the inner disk and a linear transition of intensity values on the outer disk. When X gets larger. X, would be closer to X in the Euclidean sense, and would have larger variation energy than the case with X = 0. We summarize the psychovisual results described in the above three subsections by stating that basically the edge information in an image is responsible for our perception, stronger edges are of higher importance to our perception and the smooth areas influence our perception together with the edge informatlon.</p><p>In the next two sections, we will introduce a three-component image model based on these observatlons. In what follows, we provide a precise characterization of these edges that leads to the basic idea for extracting them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Description of Strong Edges</head><p>We first provide a mathematical description of edges, strong or weak, and then develop a scheme for the discrimination of strong edges.</p><p>In what follows, we briefly explain a traditional way of describing edges <ref type="bibr">[7]</ref>, [SI, <ref type="bibr">and [13]</ref>. For an image X = ((2, j , xi,:,), i , j = 0: 1: . . . , M -l}, we define the directional variations I I ; , ~ and w ; , ~ at pixel ( i , j ) vzr,j = x i , j -~; , j + l , i = 0,1,. . . , M -1:</p><formula xml:id="formula_2">j = 0 , 1 , . . ., M -2, W C . = xi,j -~; + l , j , i = 0 , 1 , . . . , M -2, (111.1) (111.2) 293 j = 0; 1:. . . , A4 -1.</formula><p>We define edges as those pixels where v;,,, and/or U&amp; assume large absolute values.4 More precisely, we say that there is an edge point at ( i , ~ + 0.5) if Iw;, , ~ &gt; Tu, and an edge point at ( i + 0.5.j) if I V, " , , , ~ &gt; Tu. for a positive threshold Tu. We then describe the corresponding edge at location ( i , j + 0.5) 4The actual schemes introduced in [7], [8] and <ref type="bibr">[13]</ref> are further extensions of the concept here: they are combined with techniques of Gaussian filtering and gradient operator, and will be briefly described in Section V.</p><p>or ( i + 0.5,j) by the intensity values of neighboring pixels, xi,j and xi,j+l, or, xi,j and zi+l,j, respectively. This scheme works well for edges that are one pixel wide, but not for edges of multi-pixel width as illustrated by the following example. In Fig. <ref type="figure">6</ref>(a), we have an image with an edge that has an intensity jump from 20 to 220, and a variablewidth: one pixel wide at the top and 10 pixels wide at the bottom. The intensity values associated with the 256th scanline (center row) in Fig. <ref type="figure">6</ref>(a) is shown in Fig. <ref type="figure">7</ref>(a). On this scanline, the edge is six pixels wide: from pixel <ref type="bibr">(256,</ref><ref type="bibr">255)</ref> to <ref type="bibr">(256,</ref><ref type="bibr">261)</ref>, where the intensity values change linearly from 20 to 220.</p><p>Notice that Ix256,j -z256,j+ll = (220-20)/6 for 2555 j 5 260. Whereas for T, 2 200/6, no point on this scanline will be identified as an edge point, for T, &lt; 200/6, the points (256,j+ O S ) , 2555 j 5 260 will all be taken as edge points.</p><p>Clearly, the latter corresponds to a redundant description of the edge as in this case the two intensity values at locations (256, 255) and (256, 261) completely define the edge. These two pixels, (256, 255, 20) and <ref type="bibr">(256,</ref><ref type="bibr">261,</ref><ref type="bibr">220)</ref>, were referred to as edge brim points in Section 11.</p><p>We now develop a new way of describing edges in the following. We define the second-order directional variations and D;,j for X at pixel ( i , j )  We note that definition (111.7) gives a set of edge brim points regardless of whether or not they correspond to strong edges. To circumvent this problem, we introduce the concept of a stressed image X" = {(z,j, K : , ] ) } , associated with the image X. We first state here the properties that the stressed image X" is required to possess, and then, in the next subsection, develop a scheme to generate the stressed image. We require that, at strong edges, the stressed image X" closely approximate the original image X, i.e., the squared-errors (z,,] -x ; S , ~) ~ be small at these pixels; the pixel curvature energies of X" of these pixels have no additional constraint. In other areas such as smooth and texture areas, we require the pixel </p><formula xml:id="formula_3">D T . = z ~ a.3 J '-1-2xi,j+~i,j+i, i = O , 1 ,..., M -1 , j = 1,. . . , M -2; (111.3) D C = ~i-l,j -2 ~i , , + ~i + l , j , i = 1,. . . ~ M -2, 2,3 j 0 , . . ., M -1 (111.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . Generating the Stressed Image</head><p>In this subsection, we consider the generation of a stressed image X" from an original image X. Since the main property of the stressed image X" is described in terms of i) the squared-errors (zi,j -~f ; ~) '  and ii) the pixel curvature energies of Xs, we consider the following quantity at pixel ( i , j ) Ez,j(A;,j, A&amp;, A;,j) = A 1 1 J .(Xi,?zs 2 J . ) 2 + .A2 ~, . 7</p><p>.C" 1.3 ' + A? w .c;3 , (111.8) are three nonnegative real where parameters Ai,j, A:,j, numbers. We define the summation of these Ei,, as M-1 hf-l</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E ( X " , X , A )</head><p>Ei,j(Af,,, A:, j, A;~j)</p><formula xml:id="formula_4">(111.9) i=o j = o</formula><p>where A represents the collection of the parameters At,j, A: , j and A: , j .</p><p>We then consider the following minimization problem for a given parameter set A: E R M 2 and [At,jxi,j] E RM2 contain elements yi,j and At,jxi,j, respectively, in a certain order (oneto-one function) T : {0,1, . . . ,111 -1} x {0,1, . . (111.15) we have that [y;,jlTL[yi.j] = 0 if and only if yi,j = 0 for all ( i , j ) , when &gt; 0 for all ( i , j ) (under the assumption that are nonnegative).</p><p>QED. From now on, we assume that the parameter set A is such that all are greater than zero, and therefore we will talk about the solution of problem (IILIO), which is L-l[A:,jxi,j]. The problem (111.10) is solved iteratively by the Gauss-Seidel iteration5 using the Multi-Grid technique to speed up the convergence. The Gauss-Seidel iteration and the Multi-Grid technique are well known <ref type="bibr">[15]</ref>. The details of the implementation of these two techniques are included in <ref type="bibr">[16]</ref>.</p><p>A&amp;, and on the solution Y* = { ( i , j , Y ~* , ~) } of problem (111.10). A close examination of (111.8) indicates that if is large compared with and</p><p>("ci,j -y:,j)2 would be small, and the constraint on the pixel curvature energies of y* would be loose; on the other hand, if are large as compared to Xi,?, the pixel curvature energies of Y* would be small, and the constraint imposed on the squared-error ( q j -yz*,j)2 would be relaxed. To make this observation more precise, of <ref type="bibr">[261, (161)</ref>.</p><p>We now consider the influence of the choices of we consider the relationship between the original image X and the solution Y* governed by the minimization problem (111.10) as a filtering operation with input X and output Y*. In the Appendix, we investigate the frequency response of this filter (in its continuous form for simplicity) and show that it is a space-varying lowpass filter with cutoff frequencies at ( i , j ) controlled by the parameters A!,j , and in such a way that larger values of give rise to higher cutoff frequencies in both directions, while larger values of and lead to lower cutoff frequencies in row-direction and column-direction, respectively. Note that it is not the absolute values of A!,j, and but rather the ratios X:,j/A,:,j and A: , /At,j that influence the solution Y *.</p><p>The minimization problem (111.10) actually has an interesting interpretation in that the solution y* can be thought of as the stable configuration of a mechanical structure, a part of which is depicted in Fig. <ref type="figure" target="#fig_9">8</ref>. In this structure, at each pixel location ( i , j ) , we have a vertical spring with both ends fixed on a floor (height = 0) and a ceiling (height = 255) and a cylinder fixed on it at height xi.j. This cylinder is constrained to move only in the vertical direction. For each row and column, there is a flexible bar of the shape shown in Fig. <ref type="figure" target="#fig_9">8</ref> with a slot in the middle. The cylinders associated with each ( i , j ) are fitted inside the corresponding column bars, and the column bars, in turn, are fitted inside row bars. Shown in Fig. <ref type="figure" target="#fig_9">8</ref> is the structure at pixel ( M -1, 0). We now suppose that this mechanical structure assumes a configuration described by the heights yi,j of the cylinders. Then the potential energy of this configuration {yi,j} is approximated by E ( y , X , A) defined in (111.9), where A t , j ( x i , J -y i , j ) 2 , X:,JCi:j, and X3 1-3 .CC z 7 3 approximate the potential energies of the spring, the row bar and the column bar at pixel ( i , j), respectively. The parameters control the rigidness of the spring, the row bar, and the column bar at pixel ( i 7 j ) <ref type="bibr">[17]</ref>.</p><p>To visualize the formation of the stable configuration for this mechanical structure, we note that if all the bars are taken out, the cylinders on the vertical springs for each pixel ( i , j ) will assume their stable positions at xi,j, i.e., this configuration represents the original image X. After we slide in all the row and column bars whose rigidness (or flexibility) are determined by the parameters and the configuration of the structure will change and will reach the final stable configuration { y:.J} that has the minimum potential energy, A$ and i.e., Y* is the solution of problem (111.10). Due to this analogy to the mechanical system, we refer to <ref type="bibr">(111.10)</ref> as an energy minimization model ( E M M ) problem.</p><p>To obtain the stressed image X" from the original image X, it suffices to solve the EMM problem with a proper parameter set A. namely, small ratios A$/X&amp; and X:,j/Al,j at locations of strong edges and larger ratios at other places. However, we cannot specify the parameter set A a priori since this requires the knowledge of the locations of strong edges-the very purpose of generating the stressed image.</p><p>We now explain qualitatively an approach for solving this problem with the help of the above mechanical structure. We assume that in the process of forming the stressed image X", Y 2 , and allow higher flexibility of the bars at places of large pixel curvature energies. We continue the process by repeating the above procedure. Notice that the textures are suppressed in the first configuration Y1, and will continue to be suppressed in later configurations, while the approximation of strong edges (corresponding to large pixel curvature energies) will become gradually better in later configurations as we change the flexibilities of the bars to better accommodate the strong edges.</p><p>To express the above idea mathematically, we start with a uniform parameter set A, i.e., parameter = X k for all ( i , j ) , k = 1, 2, 3 and solve problem (111.10) to get Y'. We then update the parameter set A by changing the ratios A t , j / A i , j and A:.j/Xk,j according to C t j and Ct,j of 7'. The updating strategy should be such that large values of C t j and C;lj give rise to small ratios, A:, j / A t , and /At, j , respectively. In the algorithm proposed here, we set A:,j/Xi,j and A:,j/X:,, to be inversely proportional to ( 7 : ; and CF.j, i.e.</p><p>A2 1.3 ./A1 2 , 3 . = /3/Clj and X&amp;/Xf,; = ,13/Ct,j</p><formula xml:id="formula_5">(111.16)</formula><p>where / 3 is a constant. Then, we solve problem (111.10) again with the new parameter set to obtain 7'. We repeat the above iteration until the relative variation of the objective function in (111.10) for the two consecutive iterations is smaller than a given threshold. The final solution y K , where K is the total number of iterations, will be called a stressed image (previously denoted by X") of the image X .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Iv. EXTRACTION OF STRONG EDGE INFORMATION AND THE THREE-COMPONENT IMAGE MODEL</head><p>As indicated before, the strong edge information can be extracted by identifying pixels with large curvature energy in the stressed image X", and is represented by &amp;(X") in (111.7). While generating BT (X") based on (111.7) is straightforward, the choice of the threshold T is crucial and its fine-tuning computationally expensive, To circumvent these difficulties, a further selection of the pixels in &amp; ( X S ) is made by identifying pixels of large local maximum curvature energy. Specifically, the definition of edge brim points in .(III.7) is modified as follows:</p><p>(Z&gt;j, z;,j) E B T ( X " ) if Dr . Dr . &lt; 0. DZp,jD;.,+l 5 0: and Cl' &gt; T ;</p><p>Z3J-1 %.Jor if Dl,j-lDl,j &gt; 0, Dl,jD:,j+l 5 0:</p><p>or if DF,j-lD[,j 5 0, DF,jD[,j+l &gt; 0 , or if Dr,j-lDL,,j &gt; 0, Dtr,jD;,J+l &gt; 0, or if DzC-l,jDi7j 5 0, DF,jD:+l;j 5 0: and C't,j &gt; T ;</p><p>or if D:-l,jDi,j &gt; 0, D.:,jDi+l,j 5 0, or if Dl-l,jDf,j 5 (I! D:,,jDt++l,j &gt; 0 , or if Dl-l,jDr,j &gt; 0; D.'.,jDi++l,j &gt; 0, and CL! &gt; max{ Cty, -1, T } ; and C l j &gt; m a x { C l j + l . T } ;</p><p>and Cl:j &gt; max{Cl,-l, C [ j + l , T } ; and Cz3 &gt; max{Ct._l,,i, T } ;</p><p>and Cl:j &gt; niax{C:-+l,,j, T } ;</p><p>and Cf,j &gt; max{C~~~l,,j:C,F+l,jlT}.</p><p>(IV.1) Therefore, the modified set contavns pixels not only of high curvature energy, but also of curvature energies larger than those of the neighboring pixels with the same sign of the second-order variations.</p><p>To complete the process of extracting smng edges, in what follows we consider the generation of edge brim contours from B , ( X S ) described in (IV.1). This problem is also important for coding of the strong edge information [ I l l , [ 161.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Generation of Edge Brim Contours</head><formula xml:id="formula_6">k = 0 , 1 , . . . , m -1}, such that</formula><p>We define a contour as a sequence: 6 E= { ( Z ~, ~~, X : ~&gt; ~~) .</p><p>(IV.2) l i k -1 -1:LI 5 1, 1 y -1j k l 5 1 and (Zk-',jk-') # ( i k . j k ) , for k = 1,. . . ~ m -1, and the maximum-variation of intensity values g-= -rriax lxfk,jk -31 5 T,</p><formula xml:id="formula_7">(IV.3) k = O . l , ..., m-1</formula><p>where T, 2 0, 3: is the average of the pixel intensity values on b, and m is called the length of the contour. This definition is different from previous contour definitions 1181 <ref type="bibr">-[20]</ref> in condition (IV.3); condition (IV.3) is introduced to prevent mixing of the upper and lower edge brims into one contour.</p><p>In the following, we will describe the details of the contour extraction procedure used here.</p><p>Let us first consider the so-called contour tracing problem [18]-[20], which ignores condition (IV.3) iind is solved by a local search algorithm. To describe this algorithm, consider Fig. <ref type="figure" target="#fig_11">9</ref> where a generic pixel ( i , ~) is circled, and its neighboring pixels are labeled by indices 0, 1. . , 7. Starting from a pixel ( i o , j " ) E f l ( &amp; ( X " ) ) , the tracing iilgorithm searches among its neighboring pixels (starting from 0 in the clockwise direction) for one in B,(X"). Upon finding such a pixel</p><formula xml:id="formula_8">(il,.jl) E fl(&amp;-(X'</formula><p>)), it moves the search center to ( i l , j l ) , and repeats the search again until the search fails. The resulting sequence of pixels, ( i o , j o , ~~o ~j o ) , ( i l &gt; j l , x : l , j l ) ,</p><p>. . . , defines the contour extracted. Suppose that we have extracted a contour satisfying (IV.2). While the entire contour may not satisfy (IV.3), for a given threshold T,, short segments of the contour are likely to satisfy this condition. Thus, the added constraint in (IV.3) essentially breaks the contour into segments, which leads to a problem similar to the straight-line-fitting problem in [21], with the exception that the straight-line-segments in [21] are replaced by constant-intensity curve-segments here.</p><p>The contour extraction algorithm actually implemented is a combination of Ihe above techniques and works as follows.</p><p>Starting from a pixel ( z o , j " , ~~o , J o )</p><p>E &amp;(XS), in its eight neighboring pixels we search for pixels in &amp; ( X S ) , among which we choose a pixel that gives the minimum maximumvariation; if this maximum-variation is lower than T,, we take this pixel as the next pixel ( i ' , j ' , ~: ~. ~~) on the contour.</p><p>Then, we move the search center to (,il,jl,x:l,jl), delete ( i " , , j 0 , ~: 9 ,</p><p>.") from B,(Xs), and repeat the above procedure again. The process stops when we cannot locate a pixel</p><p>in &amp; ( X S ) having maximum-variation lower than T, in the neighborhood of the current search center. This is the basic form of the algorithm.</p><p>Note that when we take an arbitrary pixel in B,(Xs) to begin a contour tracing, we might start in the middle of an actual contour, and would only get a portion of this contour using our basic algorithm. We circumvent this problem by introducing a flag such that when in the first search step we have more than one neighboring pixel in &amp;(X") giving maximum-variations lower than T,, this flag is set to "1," and otherwise, it is set to "0." When this flag is "1," we first trace to one end of the contour and then trace back to the other end.</p><p>Due to the iterative nature of the algorithm for generating the stressed image, it is possible that we lose a few pixels on some edge brim contours for a given threshold T,. Some of the missing pixels may be recovered by a predictive process based on the information of the generated contours. The details of the prediction can be found in [16].</p><p>Having determined all contours with the above algorithm, we eliminate those contours of length smaller than a certain threshold Ti. Since strong edges are represented by two 2 .3 contours, namely, lower and upper edge brims, we may use this pairing to further reduce spurious contours. More precisely, let us define the d-neighborhood of a pixel ( i . j , ~; 4 , ~) as {(i,j,.):max(li -ikI,Ijjkl) 5 d}, where d 2 0. We say that a pixel in L?,(Xs) is paired in distance d if its d- We will denote the final set of pixels on the remaining contours by &amp; ( X S ) again, and will refer to it as the collection of extracted strong edge brims.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . The Three-Component Decomposition</head><p>We now define an image P = { (i,j!pi,j), i,.j = 0,1,. . . , M -l}, solely from B T ( X ' ) , such that the difference image X 0 P { ( z , j , x ; : jp i , j ) } has no strong edges represented by &amp;(A''). We generate the image P based on the minimum information principle introduced in Section I1 <ref type="bibr">((11.3</ref>)) and call it the primary image (or primary component) of the original image X, since the strong edge information contained in image P is most important to the human visual system.</p><p>The stressed image X " , from which the set &amp;(XS) is derived, can be considered as the output of a space-variant filter with input X. This filter is basically low-pass except at locations of strong edges. Thus, the stressed image X s contains the low-frequency (smooth) component and the strong edge information of the image X. Therefore, the difference image X 8 ,Y" consists of the high-frequency component but without the strong edge information. We define 7 E X 8 Xy = { ( i , j . t i , j ) } = {(z,;j,xi,jz!,~)} and S</p><p>X " e P components, respectively. Thus, the image X can be expressed as = {(. z , ~, ' s;,j)} = { ( i , j , ~; , ~ -pi,,)} as the texture and smooth</p><p>In the sequel, this model will be referred to as the threecomponent image model.</p><p>In the next section, we present an example illustrating this image model and a comparison with the LGO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v. EXPERIMENTAL RESULTS AND COMPARISONS</head><p>Consider the 256 x 256 test image shown in Fig. <ref type="figure">10</ref> with a circular strong edge in the middle and textures or smooth areas in the rest of the image. A scanline (row 128) of the test image is plotted in Fig. <ref type="figure">11</ref>. There is a convex curve around the center of the scanline followed by a strong edge and an oscillatory waveform with linearly increasing frequency and amplitude on either side.</p><p>To get a clear picture of the location of the edge, we draw a grid in Fig. <ref type="figure" target="#fig_0">12</ref> with the intersections of vertical and horizontal lines indicating pixel locations; the actual upper and lower edge brims are indicated by small square-dots (Fig. <ref type="figure" target="#fig_0">12</ref> is only the center portion of the image). Two typical edge segments are shown in Fig. <ref type="figure">13</ref>. Note that the width of the edge is not limited to one pixel in contrast with the restriction in <ref type="bibr">[7]</ref>, <ref type="bibr">[8]</ref> (see Section V-B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. An Example of the Three-Component Image Model</head><p>The stressed image is generated using the scheme developed in Section 111. For simplicity, we assumed that A?,j = 3 Ai-j, for all ( z &gt; j ) . Thus, Ai,j/At,j is the only independent parameter, and instead of updating A&amp;, A:.j, we have simply updated A&amp; by the formula = y ( C l j + CF,j), (y is a constant), which is similar to <ref type="bibr">(111.16) [16]</ref>.</p><p>The stressed image is shown in Fig. <ref type="figure" target="#fig_2">14</ref>  15 and Fig. <ref type="figure" target="#fig_0">12</ref> to demonstrate the effectiveness of our scheme in locating the strong edge.</p><p>To better understand the behavior of the stressed image, we have plotted scanline 128 for the test image (solid curve) and stressed image (dotted curve) in Fig. <ref type="figure">17(a)</ref>. with vertical lines indicating the location of edge brims on this scanline in Fig. <ref type="figure">17(b</ref>). Note that the scanline associated with the stressed image is smooth except at strong edges where it matches the edge and that the locations of the detected edge brims coincide with the upper and lower edge brims of the strong edge.</p><p>The primary image associated with the extracted strong edge is shown in Fig. <ref type="figure" target="#fig_9">18</ref>. The other two components, namely, the smooth and texture components, are derived as in Subsection 1V.B and shown in Fig. <ref type="figure" target="#fig_11">19</ref>. Notice that the smooth and texture components are differences of two images. and thus may have negative intensity values. We have added constants to these two components to bring their intensity values in the displayable range: [0, 2551. As expected, the primary image contains the strong edge information, the smooth component provides the background slow intensity variations and the texture component contains all the textures. applications in the context of image coding <ref type="bibr">(71, [8]</ref>. Then, some limitations of LGO are illustrated by an example.</p><p>For simplicity, let us consider a function z ( t ) of a real variable t. The edge locations of x ( t ) are defined by the zero crossing points of its second derivative. To suppress weak edges, a Gaussian filter is used to smoothen z ( t ) before second derivative zero crossings are located. More precisely, a Gaussian kemel g,(t) is convolved with z ( t ) Some traces of bright pixels can be noticed at around the location of the circular edge in the texture image. The reason for this phenomenon is basically the orientation anisotropy of the EMM problem since there are only two directions for the bars and the discrete structure of the problem (Section 111). This orientation anisotropy can be most clearly seen for edge segments with an orientation slightly tilted away from the vertical or the horizontal directions. Since the primary image gives a perceptually good copy of the edge, these traces of brighter pixels can be treated as textures.</p><p>In what follows, we compare the performance of the strong edge extraction of the three-component image model with that of the LGO scheme. du (V.l) and the points at which y:(t) = 0 are defined as the edge locations. The standard deviation CT of the Gaussian kemel controls the strength of the extracted edges, i.e., larger values of cr correspond to higher edge strengths [13].</p><p>In the 2-D case, the edges of z ( t , s) are defined as the points where the Laplacian of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Laplacian-Gaussian Operator</head><p>The LGO scheme refers to an edge extraction scheme introduced by Marr and Hildreth 1131. In the following, we provide a brief description of LGO and discuss some of its To apply LGO to digital images, V2G,(r, 0) is discretized and convolved with the image { x i , j } . We denote the result of this convolution by {y;;j} and locate its zero crossings in the horizontal and vertical directions. For example, we say that there is a zero crossing at ( i , j + 0.5) if yi,jyi.j+l 5 0. As in</p><p>[7], we apply a gradient operator across each zero crossing; if the absolute value of the output of the gradient operator is above a certain threshold, the zero crossing is taken as an edge location.</p><p>As indicated above, the standard deviation (T of the Gaussian filter controls the strength of the extracted edges. Additionally, edge. Fig. <ref type="figure">21</ref> shows -&amp;(i) for B = 1 I. In this case, the zero crossing point is I = 177.5, which is clearly an inaccurate result. Thus, on one hand, small values of (T are needed to ensure accurate detection of the edge location and, on the other hand, large values of (T should be used for detection of "strong" edges. These requirements are conflicting and constitute a drawback of the LGO edge detection scherne. In addition, the LGO scheme implicitly assumes the edge is one sample wide. This is in contrast with real-world situations (especially for images) where edges are typically several pixels wide.</p><p>In what follows, we use the LGO scheme to detect the strong edge of the test image presented in Fig. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C . An Example Strong Edges Extraction Bused on LGO</head><p>We now present the results of the LGO-based edge detection for the test image with five different values of (T: I, 2, 3, 4 and 5 pixel widths. In each case, the threshold for the output of the gradient operator is determined ernpirically so as to keep the zero crossings of the strong edge and to suppress, as much as possible, those of the textures. The results are summarized in Fig. <ref type="figure">22</ref> in the form of images where a bright point at pixel ( i , j ) indicates a zero cros,sing at ( i , j + 0.5) and/or ( i + 0.5:j). The CPU times (in seconds) to do the convolution on a SPARCstation-1 are also included.</p><p>As shown in Fig. <ref type="figure">22</ref>, the result for (r = 5 pixel widths detects the strong edge only, while all other results contain zero crossings corresponding to the textures, as well. The enlarged picture of the zero crossing points with B =: 5 is shown in Fig. <ref type="figure" target="#fig_20">23</ref> (compared with the actual edge location in Fig. <ref type="figure" target="#fig_21">24</ref>), where the positions of the zero crossings are one half pixel width to the right or below the square-dots. Thus, ithe set of the edge brim points consists of the pixels on two circles. One circle is shown in Fig. <ref type="figure" target="#fig_20">23</ref>, and the other one (not shown) is one pixel away to the right and below of the first one. The primary image of these edge brim points is generated and shown in Fig. <ref type="figure" target="#fig_22">25</ref>. Notice that simply there is no edge in Fig. <ref type="figure" target="#fig_22">25</ref> as compared with Fig. <ref type="figure" target="#fig_9">18</ref>, obtained using the method propos'ed in this paper.</p><p>Therefore, the LGO edge extraction scheme gives location error, and, more seriously, fails to provide the correct intensity variation of the edge, while the strong edge extraction scheme  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SUMMARY AND CONCLUSION</head><p>We have discussed some important properties of the human visual system and attempted to describe them mathematically. In particular, strong edges and areas of smooth intensity variation are carefully studied and their effect as well as their interaction in formation of perception are described in terms of simple minimization problems. An algorithm, based on a space-variant lowpass filtering operation. is developed for generating the so-called stressed image from which the strong edges can be extracted. This has led to a three-component image model based on the i) strong edges, ii) areas of smooth intensity variation and iii) textures-the three components that apparently play different roles in the formation of perception.</p><p>In a specific comparison, we have shown the superiority of the strong edge extraction scheme developed here over the LGO-based edge extraction method. The three-component model was motivated by the need for subjective-based criteria for the design of low bit rate image coding systems in which the components of the model are treated based on their relative perceptual importance. Part I1 of the paper, which concentrates on this issue, will justify the usefulness of the model in the context of low rate coding. In addition, similar ideas used here have proven useful in planar curve representation-a problem that has applications in computer vision <ref type="bibr">[23]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. (a) Vertical bar for the left eye; (b) horizontal bar for the right eye.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 3. (a) A cross; (h) a network of lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Binocular perception of the two images in Fig 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>3 and 4 can be explained as follows. In the close neighborhood of the edges represented by U,, the image for the perception signals investigate the influence Of smooth Of an image on our perception. Smooth areas are characterized by 'low Let us consider Fig. 5(a) (also considered in [lo] and [ 121) where we have two concentric disks. with the intensity values along the diameter illustrated in Fig. 5(b). While the perception of the image in Fig. 5(a) varies from person to person, generally, one feels that it is a sm,all dark disk in the middle of a larger and brighter one. However, as shown in Fig. 5(b), in the regions near the center of the disks and the outer border of the bigger disk, the intensity values are, in fact, identical. To describe this phenomenon quantitatibely, we denote the set of lower and upper edge brims by 0 representing the two denote the image in Fig. 5(a) by X and the image of our is the solution of the follow,ng minimization problem: we in the intensity On this</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 5. of the disks. (a) Two concentric disk image; (b) intensity values along the diameter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>4)and use them to describe the edge brim points. More specifically, we define the pixel row-curvature energy C l j and the pixel column-curvature energy C&amp; by (D;,j)2 i = 0,1, ... , M -1 , j = l , . . . ! M -,j)2 i = 1 ,.", M -2 , j = 0 , 1 , . . . , M -1, will refer to them collectively as pixel curvature energies. We then define the set &amp;(X) of edge brim points of X as follows:(111.7)where T 2 0. We apply this characterization of edge brim points to the image in Fig.6(a) with a threshold T = 32; the detected edge brim points are indicated by bright points in Fig.6(b). We superimpose the image (b) on image (a) and show the result in image (c), where dark points are used for the upper edge brim points. These detected edge brim points are exactly at the places where the edge starts and ends. To demonstrate this, we repeat Fig.7(a) along with two vertical lines indicating the edge brim points in Fig. 7(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. 6. image (a) superimposed with image (b). (a) An edge of variant width; (b) lower and upper edge brims: (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Fig. 7. edge brims. (a) Scanline #256 of image (a) in Fig. 6; (b) with indications of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>j , yi,j)}. Note that the objective function E ( Y , X , A ) is a convex function of y , since each Ei,j(At,j.A:,j) is a convex function of {yi,j} [141. Therefore, {Y,",~} is a solution of this minimization problem if and only if it is a solution of the following system of linear equationsv { y L , J } E ( Y , J ) E ( Y , X , A) denotes the gradient of E ( Y , X , A)with respect to {yi,j}. The objective function in (111.10) can be written in matrix notation as[ ~i . j l ~~[ ? ~i , j I   -2 [ ~i , j x i , j l ~[ y i , j l + [ ~t , j x i , j l ~[ z i , j l (111.12)where vectors[ ~i , ~]    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>/Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Mechanical structure of EMM at pixel ( M -I , 0).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>the bars and springs first have uniform rigidness, and the stable configuration reached by the structure is a uniformly smoothed version, denoted by Y1 { ( Z * j , &amp; ) } , of the original image X . Then we allow the bars to have more flexibility at locations corresponding to large pixel curvature energies (where the bars are most severely bent), and let the structure stabilize to a new configuration, denoted by Y 2 {(Z,j,&amp;)}. Again, we measure the pixel curvature energies of this new configuration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Eight neighboring pixels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .FigFig. 11 .Fig. 12 .</head><label>131112</label><figDesc>Fig. 13. Typical segments of the edge in the test image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>(a). The CPU time used on a SPARCstation-1 is about 1400 s. Edge brim contours are extracted by the scheme introduced in Section IV, with T = 512, T, = 32, Te = 16, and d = 3. The resulting two contours are shown in Fig.14(b). An enlarged picture of these contours is shown in Fig.15. In Fig.16, we superimpose Fig.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Fig. 14. (a) Stressed image; (b) the picture of edge brim contours. The stressed image and the picture of edge brim contouis extracted for the test image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 .Fig. 18 .</head><label>1718</label><figDesc>Fig. 17. (a) Intensity values along scanline #I28 for the test image and the stressed image; (b) vertical lines indicating location of edge brim points on this scanline. Scanline #I28 of the test image and the stressed image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Superimposition of Figs. 15 and 12.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Fig. 19. (a) Smooth and (b) texture components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>(Fig. 20 .Fig. 21 .</head><label>2021</label><figDesc>Fig. 20. Example for the locational accuracy of LGO, IT = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>IO.    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Enlarged picture of the zero crossings for U = 5 pixel widths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. The superimposition of Figs. 23 and 12.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. The primary image of the neighboring pixels of zero crossings shown in Fig. 23.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. , 111 -1) ---f</figDesc><table><row><cell cols="2">{0,1, . . . M 2 -l}, i.e., the (r(i0,jO))th element in the vectors</cell></row><row><cell cols="2">[yi,j] and [ X i , j x ; , j ] are yiO,j, and A ~o ~j o x ~o , j o , respectively. The matrix L = [e,,,,,] is a nonnegative definite matrix, where</cell></row><row><cell cols="2">is the coefficient of the term yr-l(u)yr-l(,) when U. = v,</cell></row><row><cell cols="2">and half of the coefficient of the term yr-l(u) x ~~-l ( ~, ) when</cell></row><row><cell cols="2">With this matrix notation, (111.11)</cell></row><row><cell>simplifies to the following:</cell><cell></cell></row><row><cell>~[ y i , j ] = [~:,jxi,,j].</cell><cell>(111.13)</cell></row><row><cell cols="2">We now show the existence and uniqueness of the solution for</cell></row><row><cell>the minimization problem (111.10) when</cell><cell>&gt; 0 for all ( z ! j ) .</cell></row></table><note><p><p><p><p><p><p><p>U # 71, in E ( y . X , A ) .</p>Theorem ZII.1: The matrix L is positive definite if &gt; 0 for all (,i,j).</p>Proof: Setting xi,j = 0 for all ( i , j ) in the objective function (</p>111</p>.121, we have</p>E ( Y , 2, A) = [yi,jlTL[yi,j]</p>(111.14) where 2 = { ( i , j ; O ) } . While M-1 M-1 i=o j=o</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by National Science Foundation grants NSFD MIP-86-5731 1 and NSFD CD-88-03012. The associate editor coordinating the review of this paper and approving it for publication was Prof. Michel Barlaud. X. Ran is with the Systems Technology Department, National Semiconductor Corp.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX EMM-A SPACE-VARIANT FILTER</head><p>In this appendix, we will show that the EMM problem in (111.10) can be described as a space-variant filtering operation. For simplicity, we consider the continuous form of (111.10). Let Z ( U , U ) be a continuous function of variables 7 4 v defined on a simply-connected closed domain G c R2 with a piecewise smooth boundary C <ref type="bibr">[24]</ref> and consider the minimization problem</p><p>where X,(U,V) 2 0, z = 1, 2, 3, are functions of u.71 on G having continuous second-order partial derivatives, y( U. w) is an admissible function defined on G having continuous fourthorder partial derivatives with y, dy/du, dy/dv vanishing on the boundary C , and yUu(u. w) and y,,(u. 11) are second-order partial derivatives of y with respect to U and w, respectively.</p><p>All admissible functions form a linear space, denoted by D(G) endowed by a norm llyll defined as Thus, D(G) becomes a normed linear space <ref type="bibr">[24]</ref>.</p><p>We say J , has a minimum at y* E D ( G ) if and only if J ( y ) -J(y*) 2 0 for all y E D(G). Then, the necessary and sufficient condition for y* to be a minimum of J, is that <ref type="bibr">[16]</ref> for all h E D(G). By the Green's theorem [25], (A.3) reduces to <ref type="bibr">[16]</ref> for ( U , w) E G. Equation (A.4) is known as an Euler's equalion ~4 1 . Now, we show that at all ( U . U) E G satisfying X ~( U , U ) &gt; 0, the solution of the Euler's equation is unique. Let y1 and y 2 be two solutions of the Euler's equation; then, y1yz is a solution of the Euler's equation with z = 0, and thus, y1y 2 is a minimum point of Jo. Then yl(u, 71)yz(u, U ) = 0, for every ( w w ) such that X ~( U , w) : &gt; 0, for otherwise Now, we investigate the frequency domain behavior of the input-output relation governed by the aboke Euler's equation.</p><p>Let ( u 1 , q ) be an interior point in G, and A be an open neighborhood containing the point ( ~1 ,  w1 ). To further simplify the problem, we assume that the parameter functions, XI &gt; 0, As, A3, are constants on A (certainly when A is a small neighborhood, this is a reasonable assumption). Then, the above Euler's equation becomes</p><p>Jo(E(Y1 -Y2)) &lt; JO(Y1 -Y2) for any o&lt; f5 &lt; 1 . lead to lower cutoff frequencies in U and 11 directions, respectively.</p><p>Note that we have assumed that all admissible functions and their first-order partial derivatives vanish on the boundary C , while in the original case (111.10) we do not have any such constraint. This difficulty can be avoided by solving a slightly modified problem in which the boundary constraints are removed. The details of this are omitted here but can be found in [ 161. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive coding of monochrome and color images</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1285" to="1292" />
			<date type="published" when="1977-11">Nov. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Image coding using vector quantization: A review</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="957" to="971" />
			<date type="published" when="1988-08">Aug. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Subbanti coding of images</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>O'neil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust.. Speech. Signal Processi,tg</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1105" to="1106" />
			<date type="published" when="1986-11">Nov. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive cosine transform image coding with constant block distortion</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Pearlman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">M</forename><surname>Kunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ikonomopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. fEEE</title>
		<meeting>fEEE</meeting>
		<imprint>
			<date type="published" when="1985-04">May 1990. Apr. 1985</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="549" to="574" />
		</imprint>
	</monogr>
	<note>Second-generation image-coding techniques</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recent results in highcompression image coding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Benard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leonardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EEE Trans. Circuits Sysr</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1 1</biblScope>
			<biblScope unit="page" from="1306" to="1336" />
			<date type="published" when="1987-11">Nov. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sketched based coding of grey level images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Carlesson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SiRnal Processing</title>
		<imprint>
			<date type="published" when="1988-07">July 1988</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="57" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sketched based representation of grey value and motion information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Carlesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Reillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Zetterberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Pixels to Features</title>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Simon</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Perceprions of Vision</title>
		<author>
			<persName><forename type="first">H</forename><surname>Helmholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Treatise on Physiological Optics</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Southall</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">III</biblScope>
			<date type="published" when="1925">1925</date>
			<publisher>George Bonta</publisher>
			<pubPlace>Menasha, WI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Visual Perception</title>
		<author>
			<persName><forename type="first">T</forename><surname>Comsweet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Academic</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A perceptually-motivated three-component image model-Part 11: Applications to image compression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farvardin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Professing</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">75</biblScope>
			<date type="published" when="1992-07">July 1992</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. of Maryland</orgName>
		</respStmt>
	</monogr>
	<note>Also, SRC Tech. Rep. TR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Surface consistency constraints in vision</title>
		<author>
			<persName><forename type="first">W</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision, Graph., Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="28" to="51" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Theory of edge detection</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. Lnnd</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Linear and Nonlinear P ropamming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Luenberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Menlo Park, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multi-Grid Methods and Applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hackbusch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Vienna. New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A three-component image model for human visual perception and its application in image coding and processing</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992-08">Aug. 1992</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pagano</surname></persName>
		</author>
		<title level="m">Elasticity, Tensor, Dyadic, and Engineering Approaches</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coding of two-tone images</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">14061424</biblScope>
			<date type="published" when="1977-11">Nov. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image transmission by two-dimensional contour coding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1967-03">Mar. 1967</date>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page">336346</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the encoding of arbitrary geometric configuration</title>
		<author>
			<persName><forename type="first">H</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Trans. Electron. Comput</title>
		<imprint>
			<biblScope unit="page" from="26G" to="268" />
			<date type="published" when="1961-06">June 1961</date>
			<publisher>EC-IO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Encoding of images based on a twocomponent source model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sakrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1315" to="1322" />
			<date type="published" when="1977-11">Nov. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The curvature primal sketch</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Nalwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">0</forename><surname>Binford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Silverman</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="1986-01">Nov. 1986. Jan. 1986</date>
			<publisher>Calculus of Variations</publisher>
		</imprint>
	</monogr>
	<note>IEEE Trans. Pattern Anal. Machine Intell.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Advanced Calculus</title>
		<author>
			<persName><surname>Kaplan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952">1952</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Iterative Solution of Larxe Linear Systems</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967">1971. 1989. 1967</date>
			<publisher>Van Nostrand</publisher>
			<pubPlace>New York; Amsterdam, The Netherlands; New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Englewood</forename><surname>Cliffs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963">1963</date>
			<publisher>Prentice-Hall</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
