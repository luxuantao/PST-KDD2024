<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B4B11F116E48B11232A4B7D7B4457987</idno>
					<idno type="DOI">10.1109/TGRS.2014.2318058</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Classification</term>
					<term>hyperspectral image (HSI)</term>
					<term>multiscale adaptive sparse representation (MASR)</term>
					<term>multiscale spatial information</term>
					<term>sparse representation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sparse representation has been demonstrated to be a powerful tool in classification of hyperspectral images (HSIs). The spatial context of an HSI can be exploited by first defining a local region for each test pixel and then jointly representing pixels within each region by a set of common training atoms (samples). However, the selection of the optimal region scale (size) for different HSIs with different types of structures is a nontrivial task. In this paper, considering that regions of different scales incorporate the complementary yet correlated information for classification, a multiscale adaptive sparse representation (MASR) model is proposed. The MASR effectively exploits spatial information at multiple scales via an adaptive sparse strategy. The adaptive sparse strategy not only restricts pixels from different scales to be represented by training atoms from a particular class but also allows the selected atoms for these pixels to be varied, thus providing an improved representation. Experiments on several real HSI data sets demonstrate the qualitative and quantitative superiority of the proposed MASR algorithm when compared to several well-known classifiers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>F OR many years, classification of remote sensing images has played an essential role in several applications, including assessment of environmental damage, growth regulation, land-use monitoring, urban planning, and reconnaissance <ref type="bibr" target="#b0">[1]</ref>. Compared with high spatial resolution images (e.g., single-band panchromatic data), hyperspectral images (HSIs) have a much higher spectral resolution and thus give the possibility to detect and distinguish various objects with higher accuracy <ref type="bibr" target="#b1">[2]</ref>.</p><p>In HSIs, each pixel is a high-dimensional vector, whose entries denote the spectral response from hundreds of spectral bands, spanning from the visible to the infrared spectrum <ref type="bibr" target="#b2">[3]</ref>. The objective of HSI classification is to categorize each spectral L. Fang, S. Li, and X. Kang are with the College of Electrical and Information Engineering, Hunan University, Changsha 410082, China (e-mail: fangleyuan@gmail.com; shutao_li@hnu.edu.cn; xudong kang@163.com). J. A. Benediktsson is with the Faculty of Electrical and Computer Engineering, University of Iceland, 101 Reykjavk, Iceland (e-mail: benedikt@hi.is).</p><p>Color versions of one or more of the figures in this paper are available online at http://ieeexplore.ieee.org.</p><p>Digital Object Identifier 10.1109/TGRS.2014.2318058 pixel belonging to one of the classes based on the spectral information. To achieve this objective, many spectral pixelwise classifiers have been developed, including the support vector machine (SVM) <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>, support vector conditional random classifier <ref type="bibr" target="#b6">[7]</ref>, multinomial logistic regression <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, neural network <ref type="bibr" target="#b9">[10]</ref>, adaptive artificial immune network <ref type="bibr" target="#b10">[11]</ref>, and artificial deoxyribonucleic acid computing <ref type="bibr" target="#b11">[12]</ref>. In general, although these classifiers can make a full use of the spectral information of HSI, the spatial context is not considered by them. Therefore, the obtained classification maps often appear noisy. Recently, to enhance the classification performance, many attempts have been made to incorporate the spatial information of HSI, based on the assumption that pixels within a local region usually represent the same material and have similar spectral characteristics <ref type="bibr" target="#b12">[13]</ref>. In <ref type="bibr" target="#b13">[14]</ref>, the spatial coherence of pixels within a local region is utilized by including a postprocessing procedure for each individual label. In <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b15">[16]</ref>, the spectral and spatial information of each HSI pixel is combined via a composite kernel approach. In <ref type="bibr" target="#b16">[17]</ref>, the statistical dependence among neighboring pixels is exploited by a Bayesian-based approach. In addition, some other HSI classification works have focused on effective feature extraction or feature reduction approaches, including spectral-only based (e.g., principal components analysis <ref type="bibr" target="#b17">[18]</ref>, linear discriminative analysis <ref type="bibr" target="#b18">[19]</ref>, and clonal selection for feature selection <ref type="bibr" target="#b19">[20]</ref>) and spectral-spatial based (e.g., local Fisher's discriminant <ref type="bibr" target="#b20">[21]</ref> and extended morphological profiles (EMPs) <ref type="bibr" target="#b21">[22]</ref>). Moreover, multiple features extracted from different ways can be combined to further increase the robustness of classification <ref type="bibr" target="#b22">[23]</ref>.</p><p>Motived by the sparse coding mechanism of human vision systems <ref type="bibr" target="#b23">[24]</ref>, sparse representation <ref type="bibr" target="#b24">[25]</ref> has been demonstrated to be an extremely powerful tool in many signal processing applications, such as denoising <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, interpolation <ref type="bibr" target="#b27">[28]</ref>, and fusion <ref type="bibr" target="#b28">[29]</ref>. Recently, the sparse representation has also been extended to HSI classification <ref type="bibr" target="#b29">[30]</ref>- <ref type="bibr" target="#b32">[33]</ref> based on the observation that HSI pixels belonging to the same class often lie in a low-dimensional subspace, which is spanned by the dictionary atoms (training samples) of the same class. Thus, an unknown test pixel to be classified can be sparsely represented by a few atoms among the whole training dictionary. The class label of the test pixel can be determined by the recovered sparse coefficients, which contain the positions of the selected atoms and their weight values. Moreover, to further exploit the spatial context of HSI, a joint sparse representation model (JSRM) can be employed <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b33">[34]</ref>. The JSRM first defines a local region of fixed size for each test pixel and then simultaneously represents pixels within each local region by a set of common atoms.</p><p>Compared to the spectral-only pixelwise sparse representation approach, the JSRM can achieve a better HSI classification performance, in terms of accuracy. However, regions with different spatial structures in HSI should benefit from varied region sizes. For example, a small region size is appropriate for detailed or near-edge regions, while smooth areas require large region sizes. Therefore, the JSRM is sensitive to the size of regions, and it is very difficult to determine the optimal region size for the method.</p><p>For one specific test pixel, when its neighboring region scales (sizes) are selected differently, distinct structures and characteristics will be exhibited. Considering that neighboring regions of different scales correspond to the same test pixel, they should offer complementary yet correlated information for classification. Inspired by that, instead of selecting only a single region scale, an effective multiscale scheme called the multiscale adaptive sparse representation (MASR) is proposed in this paper to take advantage of correlations among multiple region scales for HSI classification. Motivated by works in <ref type="bibr" target="#b34">[35]</ref> and <ref type="bibr" target="#b35">[36]</ref>, the MASR simultaneously represents the pixels of multiple scales via an adaptive sparse strategy. More specifically, as pixels of different scales should belong to the same class, the adaptive sparse strategy first enforces pixels of multiple scales to be represented by atoms from the same class. In addition, since differences exist among varied scales, the adaptive sparse strategy allows pixels of different scales to adaptively choose their own appropriate atoms within each class. In this way, the MASR not only combines the information of different scales for discrimination but also achieves an effective representation for each scale. We should note that the multiscale scheme has been utilized in a sparse representation technique for restoration problems and a more accurately reconstructed image has been obtained <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. In addition, the multiscale information has also been used for some recognition tasks <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>. Different from the proposed MASR algorithm, the multiscale information was exploited by simply concatenating images of different scales into a long vector in <ref type="bibr" target="#b38">[39]</ref>, or adaptively fusing the result of each scale by a complex optimization method in <ref type="bibr" target="#b39">[40]</ref>.</p><p>The remainder of this paper is organized as follows: In Section II, the pixelwise sparse representation and single-scale JSRM techniques for HSI classification are briefly reviewed. Section III introduces the proposed multiscale MASR model for spectral-spatial HSI classification. In Section IV, experimental results on three test images are presented. Concluding remarks and future research directions are given in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SPARSE REPRESENTATION FOR HSI CLASSIFICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pixelwise Sparse Representation</head><p>The sparse representation classification (SRC) framework was first introduced for face recognition <ref type="bibr" target="#b40">[41]</ref>. Chen et al. extended the SRC to pixelwise HSI classification, which relied on the observation that spectral pixels of a particular class should lie in a low-dimensional subspace spanned by dictionary atoms (training pixels) from the same class. An unknown test pixel can be represented as a linear combination of training pixels from all classes. Concretely, let y ∈ R M ×1 be a pixel with M denoting the number of spectral bands and D = [D 1 , . . . , D c , . . . , D C ] ∈ R M ×N be a structural dictionary, where D c ∈ R M ×N c , c = 1, . . . , C is the cth class subdictionary whose columns (atoms) are extracted from the training pixels; C is the number of classes; N c is the number of atoms in subdictionary D c ; and N = C c=1 N c is the total number of atoms in D. The test pixel y can be sparsely expressed as</p><formula xml:id="formula_0">y = Dα<label>(1)</label></formula><p>where α ∈ R N ×1 is a sparse coefficient vector. Given the structural dictionaryD, the sparse coefficient α can be recovered by solving</p><formula xml:id="formula_1">α = arg min α y -Dα 2 subject to α 0 ≤ K (2)</formula><p>where K is a predefined upper bound on the sparsity level, representing the maximum number of selected atoms in the dictionary (also corresponding to the nonzero coefficients in α).</p><p>In general, ( <ref type="formula">2</ref>) is a nondeterministic polynomial-time hard (NPhard) <ref type="bibr" target="#b41">[42]</ref> problem. However, it can be solved approximately by the orthogonal matching pursuit (OMP) <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>. To be more specific, for a test pixel y, the OMP algorithm tends to find a representative atom at each iteration based on the correlation between the dictionary D and the residual vector R, where R = y -Dα. Basically, the OMP algorithm incoporates the following steps at each iteration:</p><p>1) Compute the following residue correlation vector E ∈ R N ×1 :</p><formula xml:id="formula_2">E = D T R.<label>(3)</label></formula><p>2) Select a new representative atom (index i) based on the current residual correlation vector</p><formula xml:id="formula_3">î = max E i , i = 1, . . . , N.<label>(4)</label></formula><p>3) Merge the newly selected atom's index î with the previously selected atom's index set I, i.e.,</p><formula xml:id="formula_4">I = I ∪ î.<label>(5)</label></formula><p>4) Estimate sparse coefficient α by projecting the test subject y on D I , i.e.,</p><formula xml:id="formula_5">α = D T I D I -1 D T I y<label>(6)</label></formula><p>where the subdictionary D I is constructed using the selected atoms.</p><p>Once the sparse coefficient vector α is obtained, the class label of the test pixel y can be determined by the minimal representation error between y and its approximation from the subdictionary of each class, i.e.,</p><formula xml:id="formula_6">ĉ = arg min c y -D c αc 2 , c= 1, . . . , C<label>(7)</label></formula><p>where αc contains the coefficients in α belonging to the cth class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. JSRM</head><p>In HSI, neighboring pixels that belong to the same material usually are strongly correlated with each other. In <ref type="bibr" target="#b29">[30]</ref>, the JSRM is introduced to capture such spatial correlations by assuming that neighboring pixels within a region of fixed size can be jointly represented by a few common atoms from a structural dictionary. Specifically, the size of a region centered at test pixel y 1 is denoted by W × W , and pixels within such a region are denoted by {y i } i=1,...,W ×W . These pixels can also be stacked into a matrix Y = [y 1 , y 2 , . . . , y W ×W ], of the size M × (W × W ). The matrix can be compactly represented as</p><formula xml:id="formula_7">Y = [y 1 , y 2 , . . . , y W ×W ] = [Dα 1 , Dα 2 , . . . , Dα W ×W ] = D[α 1 , α 2 , . . . , α W ×W ] = DA<label>(8)</label></formula><p>where </p><formula xml:id="formula_8">A = [α 1 , α 2 , . . . ,</formula><formula xml:id="formula_9">Â = arg min A Y -DA F subject to A row,0 ≤ K (9)</formula><p>where A row,0 denotes the joint sparse norm, which is used to select a number of the most representative nonzero rows in A, and • F is the Frobenius norm. A variant of the OMP algorithm called the simultaneous OMP (SOMP) <ref type="bibr" target="#b33">[34]</ref> can be used to efficiently obtain an approximate solution. Note that, enforcing the structured constraints (e.g., mixed L 1,2 <ref type="bibr" target="#b32">[33]</ref> and manifold <ref type="bibr" target="#b44">[45]</ref>) on ( <ref type="formula">9</ref>) may lead to a better sparse coefficients matrix, but also create a higher computational cost. After Â is recovered, the label of test pixel y 1 can be decided by the minimal total error, i.e.,</p><formula xml:id="formula_10">ĉ = arg min c Y -D c Âc F , c= 1, . . . , C<label>(10)</label></formula><p>where Âc denotes the rows in Â associated with the cth class. By incorporating spatial information of local regions, the JSRM can deliver much better classification results, in terms of accuracy, compared to the pixelwise SRC model. However, the region size (or, as we call it, the region scale) greatly affects the classification performance. Fig. <ref type="figure" target="#fig_1">1</ref> shows the classification results for the JSRM with varied region scales for three different data sets. As can be observed in Fig. <ref type="figure" target="#fig_1">1</ref>, different regions favor different region scales. Specifically, detailed or near-edge regions require a comparatively small region scale (e.g., ellipse regions in Fig. <ref type="figure" target="#fig_1">1</ref>) whereas large region scales are preferred for smooth areas (e.g., rectangle regions in Fig. <ref type="figure" target="#fig_1">1</ref>). Therefore, it is not trivial to determine an optimal region scale for the JSRM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED MASR FOR HSI CLASSIFICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiscale Spatial Information in HSI</head><p>Given one test pixel y 1 in HSI, its T neighboring regions are selected of different scales (sizes). Pixels within the se- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multiscale Spatial Information in HSI</head><p>Suppose that we have one structural dictionary D and the multiscale matrix [Y 1 , . . . , Y t , . . . , Y T ] for the test pixel y 1 . Then, all the sparse representation problems of T scales (9) can be rewritten together as</p><formula xml:id="formula_11">{ Ât } T t=1 = arg min {A t } T t=1 Y t -DA t F subject to A t row,0 ≤ K ∀ 1 ≤ t ≤ T (11)</formula><p>where  each scale [see Fig. <ref type="figure" target="#fig_2">2(a)</ref>]. However, this separate strategy does not consider the strong correlations among different scales. To combine the information from different scales for classification, the joint sparse constraint (norm) row,0 can also be applied to the multiscale sparse representation matrix A multiscale , which restricts that the sparse coefficients from different scales share the same sparsity pattern, i.e., the same set of atoms are selected to represent the pixels from different scales [see Fig. <ref type="figure" target="#fig_2">2(b)</ref>]. Under this assumption, the A multiscale can be jointly recovered by solving the following problem:</p><formula xml:id="formula_12">Âmultiscale = arg min A multiscale Y multiscale -DA multiscale F subject to A multiscale row,0 ≤ K. (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>The aforementioned joint approach can fuse information from different scales for classification. Nonetheless, the assumption that pixels from all scales share the same sparsity pattern is too restrictive, since structural features among different scales in HSI are varied. In other words, to achieve a better representation, pixels from each scale must have "freedom" to select different atoms that are appropriate for them. Furthermore, as all the multiscale information corresponds to the same test pixel y 1 , the "freedom" in selecting the atoms should be restricted within one class. Therefore, the desired sparse coefficients for pixels of multiple scales should favor the same class-level sparsity pattern but, at the same time, allow a distinct scale-level sparsity pattern within each class [see Fig. <ref type="figure" target="#fig_2">2(c)]</ref>.</p><p>According to the aforementioned idea, the MASR, which is a flexible model, is proposed here. Inspired by <ref type="bibr" target="#b34">[35]</ref> and <ref type="bibr" target="#b35">[36]</ref>, the MASR achieves a flexible selection process for atoms by introducing an adaptive sparse strategy. An important part of this strategy is the adoption of a collection of adaptive sets. Each adaptive set, L h , h = 1, 2, . . ., is denoted as the indexes of a set of nonzero scalar coefficients, which belong to the same class in the multiscale sparse matrix A multiscale . For columns within each scale (in A multiscale ), the indexes of the adaptive set L h lie in the same row [see Fig. <ref type="figure" target="#fig_2">2(c)</ref>]. This is achieved by applying the joint sparse regularization on pixels within each scale. In addition, indexes from different scales are allowed to be in different rows of A multiscale [see Fig. <ref type="figure" target="#fig_2">2(c)</ref>]. This means that pixels from different scales have freedom to select different atoms within each class. In this way, the sparse coefficients from different scales can be varied, but still belong to the same class, as shown in Fig. <ref type="figure" target="#fig_2">2(c)</ref>.</p><p>By combining the adaptive set with the row,0 norm, a new adaptive norm adaptive,0 is created on A multiscale , which can be used to select a small number of adaptive sets from A multiscale . Then, the A multiscale matrix can be recovered by applying the adaptive norm in <ref type="bibr" target="#b11">(12)</ref>, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Âmultiscale = arg min</head><formula xml:id="formula_14">A multiscale Y multiscale -DA multiscale F subject to A multiscale adaptive,0 ≤ K. (<label>13</label></formula><formula xml:id="formula_15">)</formula><p>To solve the problem in <ref type="bibr" target="#b12">(13)</ref>, the MASR algorithm is proposed, as detailed in Fig. <ref type="figure" target="#fig_3">3</ref>. Similar to the algorithm structure of the OMP <ref type="bibr" target="#b42">[43]</ref> and SOMP <ref type="bibr" target="#b33">[34]</ref>, at each iteration, the proposed MASR algorithm includes the following general steps: 1) compute the current residual correlation matrix; 2) select a new adaptive set based on the current residual correlation matrix; 3) merge the newly selected adaptive set with the previously selected adaptive sets; 4) estimate the sparse coefficients matrix based on the merged adaptive sets; and 5) update the residue. The procedure is iterated until the termination criterion is satisfied.</p><p>One of the key ingredients in the proposed MASR algorithm is the selection of the new adaptive set, which is based on the following steps: 1) find the best representation atom for each scale and each class; 2) combine the best atoms across the scales for each class into a cluster; and 3) choose the best cluster and record the indexes for the atoms in that cluster as one adaptive set.</p><p>After recovering the multiscale sparse representation matrix Âmultiscale , a single decision can be made on the test pixel </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Sets</head><p>To verify the effectiveness of the proposed MASR method, experiments are conducted on three hyperspectral data sets,<ref type="foot" target="#foot_0">1</ref> i.e., the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) Indian Pines data, the AVIRIS Salinas data, and the Reflective Optics System Imaging Spectrometer (ROSIS-03) University of Pavia data. The AVIRIS Indian Pines image was captured over the agricultural Indian Pine test site in northwestern Indiana. The image has 220 data channels across the spectral range from 0.2 to 2.4 μm, and each band is of size 145 × 145, with a spatial resolution of 20 m per pixel. In the experiments, 20 water absorption bands (no. 104-108, 150-163, and 220) were discarded <ref type="bibr" target="#b45">[46]</ref>. The reference map for Indian Pines contains 16 classes, most of which are different types of crops (e.g., corns, soybeans, and wheat). Fig. <ref type="figure" target="#fig_7">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Quantitative Metrics</head><p>Three objective metrics (i.e., overall accuracy (OA), average accuracy (AA), and the Kappa coefficient) are adopted in these experiments to evaluate the quality of classification results. The OA measures the percentage of pixels that are correctly classified. The AA represents the mean of the percentage of correctly classified pixels for each class. The Kappa coefficient estimates the percentage of classified pixels corrected by the number of agreements that would be expected purely by chance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison of Different Classifiers</head><p>Here, the proposed multi-scale MASR classifier is compared with the SRC-Pixel-wise <ref type="bibr" target="#b29">[30]</ref>, the JSRM <ref type="bibr" target="#b29">[30]</ref>, the singlescale adaptive sparse representation (SASR) as well as several widely used classification methods, including the pixelwise SVM <ref type="bibr" target="#b3">[4]</ref>, the EMP with SVM <ref type="bibr" target="#b46">[47]</ref>, the Logistic regression via variable splitting and augmented Lagrangian-multilevel logistic (LORSAL-MLL) <ref type="bibr" target="#b16">[17]</ref>, and the nonlocal weighting sparse representation (NLW-SR) <ref type="bibr" target="#b47">[48]</ref>. The SRC-Pixel-wise and the JSRM are two original sparse representation-based classifiers. The SRC-Pixel-wise only uses the spectral information for classification, whereas the JSRM utilizes the spatial context within one fixed single scale. The NLW-SR and SASR are also two single-scale sparse representation classifiers based on modifications of the JSRM algorithm. The NLW-SR is a nonlocal weighting approach, which assigns one dynamic weight to each pixel within a region. The weights consider not only the spectral similarity at the single pixel level but also the geometrical configuration of the whole neighborhood region. The SASR applies the adaptive atom selection strategy on the JSRM instead of using joint sparse regularization. The SVM classifier was implemented using the library for support vector machines library <ref type="bibr" target="#b48">[49]</ref> with Gaussian kernels. For the EMP and the LORSAL-MLL approaches, the spatial information of HSI was exploited by the adoption of the EMP and the multilevel logistic prior-based segmentation technique, respectively. In addition, two multiscale sparse representation-based classifiers were also considered for comparison: the multiscale separate sparse representation (MSSR) and multiscale joint sparse  <ref type="figure">(d</ref>) EMP <ref type="bibr" target="#b46">[47]</ref>, (e) LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, (f) SRC-Pixel-wise <ref type="bibr" target="#b29">[30]</ref>, (g) JSRM <ref type="bibr" target="#b29">[30]</ref>, (h) NLW-SR <ref type="bibr" target="#b47">[48]</ref>, (i) SASR, (j) MSSR, (k) MJSR, and (l) MASR. representation (MJSR). The MSSR solves the problem <ref type="bibr" target="#b10">(11)</ref> and utilizes <ref type="bibr" target="#b9">(10)</ref> to obtain the classification result for each scale. Then, the majority voting is applied to results of all scales for the final decision-making. The MJSR addresses the problem in <ref type="bibr" target="#b11">(12)</ref> and uses <ref type="bibr" target="#b13">(14)</ref> to get the final classification result.</p><p>In these experiments, we empirically selected the parameters for the MSSR, MJSR, and the proposed MASR method, and kept them unchanged for the three test data sets. For the MSSR, MJSR, and MASR methods, seven different scales were simultaneously adopted, and the selected region scales were as follows: 3 × 3, 5 × 5, 7 × 7, 9 × 9, 11 × 11, 13 × 13, and 15 × 15. Therefore, the number of scales T was set to seven. Since there is highly redundant information in the regions of large scales, we further subsampled the regions of large scales. Specifically, the subsampling factor was chosen to 2 for the region of size 13 × 13, while the subsampling factor was selected as 3, for region sizes that are larger than 13 × 13. The sparsity level K for the MSSR, MJSR, and MASR methods was chosen as 3. For the single-scale JSRM method, the region scales were selected differently for different test images (i.e., 7 × 7 for Indian Pines, 15 × 15 for Salinas, and 11 × 11 for University of Pavia), to reach the best classification results, in terms of accuracy. The parameters for the SASR were set to be the same as those of the JSRM, while the parameters for the NLW-SR were set differently for the three test images to achieve the best classification results. The parameters for the SRC-spectral method were set to be the same as in <ref type="bibr" target="#b29">[30]</ref>. The parameters for the SVM were obtained by fivefold crossvalidation. The parameters for the EMP and LORSAL-MLL were set to the default values reported in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b46">[47]</ref>.</p><p>The first experiment was performed on the Indian Pines data set. For each of the 16 classes, 10% of the labeled pixels were randomly sampled for training, while the rest 90% were used to test the classifiers (see Table <ref type="table" target="#tab_2">I</ref>). Fig. <ref type="figure" target="#fig_7">5</ref> illustrates the classification maps obtained by different classifiers on the Indian Pines image. As can be observed, the classification map of the SRC-Pixel-wise method has a very noisy appearance. By considering the single-scale spatial context, the JSRM classifier can deliver a comparatively smooth result, but still fail to detect some meaningful regions (e.g., the detailed or near-edge areas). Although the NLW-SR, SASR, MSSR, and MJSR algorithms show improvements on the detection of the details, some noisy behavior still exist on the obtained classification maps for these approaches. By contrast, the proposed MASR algorithm not only further reduces the noise but also preserves well useful information of HSI. In addition, compared to the SVM, EMP, and LORSAL-MLL methods, the proposed MASR algorithm can also provide a better classification map. The quantitative results averaged over ten runs for various methods are tabulated in Table <ref type="table" target="#tab_2">II</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II CLASSIFICATION ACCURACY (AVERAGED ON TEN RUNS WITH RANDOMLY SAMPLED TRAINING SAMPLES) OF THE INDIAN PINES IMAGE OBTAINED</head><p>BY SVM <ref type="bibr" target="#b3">[4]</ref>, EMP <ref type="bibr" target="#b46">[47]</ref>, LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, SRC-PIXEL-WISE <ref type="bibr" target="#b29">[30]</ref>, JSRM <ref type="bibr" target="#b29">[30]</ref>, NLW-SR <ref type="bibr" target="#b47">[48]</ref>, SASR, MSSR, MJSR, AND MASR Fig. <ref type="figure">6</ref>. Estimated sparse coefficients for one pixel [located at <ref type="bibr" target="#b38">(39,</ref><ref type="bibr" target="#b43">44)</ref>  method outperforms other compared approaches, in terms of OA, AA, and Kappa coefficients. Note that, the gains (in OA, AA, and Kappa coefficients) of the MASR are more than 2%, as compared to the MSSR and MJSR, which demonstrates the effectiveness of the proposed multiscale adaptive sparse strategy.</p><p>In addition, we randomly selected one pixel from the Indian Pines image and illustrated the estimated sparse coefficients for this pixel at seven different scales ranging from 3 × 3 to 15 × 15 in Fig. <ref type="figure">6</ref>. This pixel is located at <ref type="bibr" target="#b38">(39,</ref><ref type="bibr" target="#b43">44)</ref> in the Indian Pines image and belongs to the "Corn-no till" area (Class 2). As can be observed for the different scales in Fig. <ref type="figure">6</ref>, although the selected atoms are generally different, they are still restricted to belong to the same class. In particular, the main atoms for each scale are selected from the positions 110, 34, 98, 7, 7, 121, 32, respectively. In the dictionary, atoms from Class 2 are distributed in positions 6-148. Therefore, the selected atoms all belong to Class 2, which fits the assumption of the MASR model.</p><p>The second and third experiments are conducted on the Salinas and the University of Pavia images, respectively. To make the classification for the Salina image more challenging, only 1% of the labeled data were randomly selected as training samples and the remaining 99% of data as test samples (see Table <ref type="table" target="#tab_5">III</ref>). In the University of Pavia image, 300 pixels for each class were chosen for training, and the rest were used as   <ref type="table" target="#tab_6">IV</ref>). The classifications maps for various classifiers are shown in Figs. <ref type="figure" target="#fig_9">7</ref> and<ref type="figure" target="#fig_10">8</ref>, and the quantitative results averaged over ten runs are tabulated in Tables V and VI. As can be observed, the joint multiscale MJSR approach does not show any improvements over the separate multiscale MSSR and the single-scale JSRM methods in these two images. This is due to the fact that the joint sparsity pattern utilized the MJSR cannot cover well the differences among different region scales. By contrast, the proposed MASR, which utilizes the adaptive sparse pattern, consistently performs better than the single-scale JSRM and MJSR, as well as the NLW-SR, SASR, SVM, EMP, and LORSAL-MLL classifiers, in terms of visual quality of classification maps and quantitative metrics (e.g., OA, AA, and Kappa coefficients). This further demonstrates the advantage of the proposed method.</p><p>The run times of the proposed MASR method and other compared methods are tabulated in Table <ref type="table" target="#tab_8">VII</ref>. All the programs were executed in the environment of an Intel Corei7-3720 CPU 2.60 GHz and 16 GB of RAM. As can be observed, the multiscale MSSR, MJSR, and MASR methods required less computational time than the NLW-SR method, but more execution time than the other methods. In addition, the computation time of the MASR is close to that of MJSR, which shows that the dynamic atom selection process does not create much computational cost. The main computational cost of the MASR algorithm is caused by the inner product between the dictionary D and the multiscale matrix Y multiscale . As in <ref type="bibr" target="#b49">[50]</ref>   <ref type="bibr" target="#b46">[47]</ref>, (e) LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, (f) SRC-Pixel-wise <ref type="bibr" target="#b29">[30]</ref>, (g) JSRM <ref type="bibr" target="#b29">[30]</ref>, (h) NLW-SR <ref type="bibr" target="#b47">[48]</ref>, (i) SASR, (j) MSSR, (k) MJSR, and (l) MASR. and <ref type="bibr" target="#b50">[51]</ref>, progressive Cholesky factorization can be used to greatly reduce the computational cost involved in applying the inner product. In addition, it should be noted that our MASR algorithm was coded in MATLAB and was not optimized for speed. The running time is expected to be significantly further reduced by coding the MASR algorithm with C++ and adopting a general-purpose graphics processing unit (GPU).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Effects of Region Scales</head><p>Here, we will analyze the effect of the region scales on the performance of the single-scale JSRM and the multiscale MSSR, MJSR, and MASR algorithms. For the analysis, the number of training and test samples for the Indian Pines, Salinas, and University of Pavia images are chosen to the same as in the previous experiments. The experiment for each region scale and each of the test methods is repeated five times with different randomly selected samples to reduce the bias induced by random sampling. Fig. <ref type="figure" target="#fig_11">9</ref> shows the OA and AA of the single-scale JSRM on region scales ranging from 3 × 3 to 27 × 27 and the multiscale MSSR, MJSR, and MASR algorithms on combining different scales (from 3 × 3 to 27 × 27). For the multiscale algorithms (e.g., MSSR, MJSR, and MASR), each scale represents the  <ref type="bibr" target="#b46">[47]</ref>, (e) LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, (f) SRC-Pixel-wise <ref type="bibr" target="#b29">[30]</ref>, (g) JSRM <ref type="bibr" target="#b29">[30]</ref>, (h) NLW-SR <ref type="bibr" target="#b47">[48]</ref>, (i) SASR, (j) MSSR, (k) MJSR, and (l) MASR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE V CLASSIFICATION ACCURACY (AVERAGED ON TEN RUNS WITH RANDOMLY SAMPLED TRAINING SAMPLES) OF THE SALINAS IMAGE OBTAINED BY</head><p>SVM <ref type="bibr" target="#b3">[4]</ref>, EMP <ref type="bibr" target="#b46">[47]</ref>, LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, SRC-PIXEL-WISE <ref type="bibr" target="#b29">[30]</ref>, JSRM <ref type="bibr" target="#b29">[30]</ref>, NLW-SR <ref type="bibr" target="#b47">[48]</ref>, SASR, MSSR, MJSR, AND MASR combination of the current scale and its smaller scales. For example, region scale 9 × 9 for MSSR, MJSR, and MASR is actually a combination of 3 × 3, 5 × 5, 7 × 7, and 9 × 9. As can be observed in Fig. <ref type="figure" target="#fig_11">9</ref>, the single-scale JSRM algorithm reaches the best OA values when the region scale is set to 7 × 7, 15 × 15, and 11 × 11 for the Indian Pines, Salinas, and University of Pavia images, respectively. When the region scale further increases, the OA and AA of the single-scale JSRM algorithm will dramatically decrease. By contrast, the OA and AA of the multiscale MJSR and MASR algorithms generally increase or become comparatively stable, when more region scales are used. In addition, the proposed MASR algorithm generally outperforms the JSRM, MSSR, and MJSR on all the region scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Effects of Different Number of Training Samples</head><p>Here, the effects of different training samples to the SVM, EMP, SRC-Pixel-wise, single-scale JSRM and the proposed MASR classifiers are examined on the Indian Pines, Salinas, and University of Pavia images. For the Indian Pines and Salinas images, different percentages (from 2.5% to 40% for Indian Pines and from 0.25% to 4% for Salinas) of samples  <ref type="bibr" target="#b3">[4]</ref>, EMP <ref type="bibr" target="#b46">[47]</ref>, LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, SRC-PIXEL-WISE <ref type="bibr" target="#b29">[30]</ref>, JSRM <ref type="bibr" target="#b29">[30]</ref>, NLW-SR <ref type="bibr" target="#b47">[48]</ref>, SASR, MSSR, MJSR, AND MASR IMAGES BY THE SVM <ref type="bibr" target="#b3">[4]</ref>, EMP <ref type="bibr" target="#b46">[47]</ref>, LORSAL-MLL <ref type="bibr" target="#b16">[17]</ref>, SRC-PIXEL-WISE <ref type="bibr" target="#b29">[30]</ref>, JSRM <ref type="bibr" target="#b29">[30]</ref>, NLW-SR <ref type="bibr" target="#b47">[48]</ref>, SASR, MSSR, MJSR, AND MASR  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, a novel MASR model, the MASR, was proposed for spectral-spatial HSI classification. Unlike the single-scale JSRM method, the proposed MASR model simultaneously represents pixels of multiple scales via an adaptive sparse strategy. This adaptive sparse strategy not only exploits correlations among multiple scales but also allows pixels of each scale to be represented by an appropriate representation. Experiments on three real HSI data sets demonstrate that the proposed MASR method outperformed the single-scale JSRM approach and several other well-known classifiers, in terms of accuracy (based on three quantitative metrics) and visual comparison of classification maps.</p><p>The structural dictionary utilized in this paper is constructed by pixels directly extracted from HSI. Another method that will be explored by the authors in future work is to employ discriminative learning algorithms to train the structural dictionary, in order to make the dictionary more representative. In addition, one of our future research directions will combine advanced feature extraction techniques with the proposed MASR model to further enhance its performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Manuscript received October 11, 2013; revised January 12, 2014 and March 21, 2014; accepted April 12, 2014. This work was supported in part by the National Natural Science Foundation of China under Grant 61172161; by the National Natural Science Foundation for Distinguished Young Scholars of China under Grant 61325007; by the Fundamental Research Funds for the Central Universities, Hunan University; and by the Scholarship Award for Excellent Doctoral Student granted by the Chinese Ministry of Education.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Influence of region scales on the JSRM algorithm (Overall Accuracy values are given in percentage). (a) Classification results obtained by the JSRM algorithm on the Indian Pine image with region scales varying from 3 × 3 to 15 × 15. (b) Classification results obtained by the JSRM algorithm on the Salinas image with region scales varying from 3 × 3 to 15 × 15. (c) Classification results obtained by the JSRM algorithm on the University of Pavia image with region scales varying from 3 × 3 to 15 × 15. lected regions can be arranged to construct the corresponding multiscale matrix Y multiscale = [Y 1 , . . . , Y t , . . . , Y T ], where Y t includes pixels from the tth scale region. In HSI, regions of different scales usually exhibit distinct spatial structures and characteristics. Nonetheless, since all the different scales correspond to the same test pixel y 1 , they should provide complementary yet correlated information, which can be utilized to classify y 1 more accurately.</figDesc><graphic coords="3,302.75,70.01,246.14,321.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of different sparse models for multiscale (three scales) coefficients matrix A multiscale . Each column represents a sparse coefficient vector associated with one pixel, and each square block in the column is a coefficient value. White blocks denote zero values, whereas color blocks stand for nonzero values. Note that, sparse coefficients within each scale share the same sparsity pattern. (a) Separate sparse model: sparse coefficients of each scale are processed separately [see (11)]. (b) Joint sparse model: sparse coefficients of different scales share the same sparsity pattern [see (12)]. (c) Adaptive sparse model: sparse coefficients of different scales share the same sparsity pattern at the class level, while allowing the coefficients to be adaptively chosen for each scale within each class [see (13)].</figDesc><graphic coords="4,44.99,69.65,246.02,145.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. MASR algorithm.</figDesc><graphic coords="4,308.01,70.56,246.00,394.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Outline of the proposed MASR framework.</figDesc><graphic coords="5,39.71,70.13,246.14,98.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>y 1 based on the lowest total representation error ĉ = arg min c Y multiscale -D c Âmultiscale c F c = 1, . . . , C (14) where Âmultiscale c represents rows in Âmultiscale corresponding to the cth class. The outline of the whole MASR model is illustrated in Fig. 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) and (b) shows the color composite of the Indian Pines image and the corresponding reference data. The Salinas image was also acquired by the AVIRIS sensor over Salinas Valley, California. The image is of size 512 × 217 × 224 with a spatial resolution of 3.7 m per pixel. Similar to the Indian Pines image, 20 water absorption spectral bands (no. 108-112, 154-167, and 224) were removed and the reference image has 16 different classes. Fig. 7(a) and (b) show the color composite of the Salinas image and the corresponding reference data. The University of Pavia image, which captures an urban area surrounding the University of Pavia, Italy, was recorded by the ROSIS-03 sensor. The image is of size 610 × 340 × 115 with a spatial resolution of 1.3 m per pixel and a spectral coverage ranging from 0.43 to 0.86 μm. The 12 very noisy channels were discarded before the experiments, and nine information classes are considered for this image. Fig. 8(a) and (b) shows the color composite of the University of Pavia image and the corresponding reference data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Indian Pines image: (a) three-band color composite image; (b) reference image; and the classification results (OA in %) obtained by the (c) SVM [4], (d) EMP<ref type="bibr" target="#b46">[47]</ref>, (e) LORSAL-MLL<ref type="bibr" target="#b16">[17]</ref>, (f) SRC-Pixel-wise<ref type="bibr" target="#b29">[30]</ref>, (g) JSRM<ref type="bibr" target="#b29">[30]</ref>, (h) NLW-SR<ref type="bibr" target="#b47">[48]</ref>, (i) SASR, (j) MSSR, (k) MJSR, and (l) MASR.</figDesc><graphic coords="6,130.91,70.01,337.10,238.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Fig. 6. Estimated sparse coefficients for one pixel [located at (39, 44) in the Indian Pines image] at seven different scales by the MASR algorithm. (a) Sparse coefficient at scale 1 (3 × 3). (b) Sparse coefficient at scale 2 (5 × 5). (c) Sparse coefficient at scale 3 (7 × 7). (d) Sparse coefficient at scale 4 (9 × 9). (e) Sparse coefficient at scale 5 (11 × 11). (f) Sparse coefficient at scale 6 (13 × 13). (g) Sparse coefficient at scale 7 (15 × 15).</figDesc><graphic coords="7,64.19,304.85,459.50,266.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Salinas image: (a) three-band color composite image; (b) reference image, and the classification results (OA in %) obtained by the (c) SVM [4], (d) EMP<ref type="bibr" target="#b46">[47]</ref>, (e) LORSAL-MLL<ref type="bibr" target="#b16">[17]</ref>, (f) SRC-Pixel-wise<ref type="bibr" target="#b29">[30]</ref>, (g) JSRM<ref type="bibr" target="#b29">[30]</ref>, (h) NLW-SR<ref type="bibr" target="#b47">[48]</ref>, (i) SASR, (j) MSSR, (k) MJSR, and (l) MASR.</figDesc><graphic coords="8,307.91,70.49,246.14,346.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. University of Pavia image: (a) three-band color composite image; (b) reference image; and the classification results (OA in %) obtained by the (c) SVM [4], (d) EMP<ref type="bibr" target="#b46">[47]</ref>, (e) LORSAL-MLL<ref type="bibr" target="#b16">[17]</ref>, (f) SRC-Pixel-wise<ref type="bibr" target="#b29">[30]</ref>, (g) JSRM<ref type="bibr" target="#b29">[30]</ref>, (h) NLW-SR<ref type="bibr" target="#b47">[48]</ref>, (i) SASR, (j) MSSR, (k) MJSR, and (l) MASR.</figDesc><graphic coords="9,171.23,69.65,246.14,277.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Effect of the region scales on the single-scale JSRM algorithm and the multiscale MSSR, MJSR, and MASR algorithms for the (a) Indian Pines, (b) Salinas, and (c) University of Pavia images.</figDesc><graphic coords="10,44.99,327.65,246.02,237.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Effect of the number of training samples on the SVM, EMP, SRC-Pixel-wise, single-scale JSRM, and proposed multiscale MASR for the (a) Indian Pines, (b) Salinas, and (c) University of Pavia images.</figDesc><graphic coords="10,307.91,328.01,246.14,153.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I SIXTEEN</head><label>I</label><figDesc>REFERENCE CLASSES IN INDIAN PINES IMAGE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III SIXTEEN</head><label>III</label><figDesc>REFERENCE CLASSES IN SALINAS IMAGE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV NINE</head><label>IV</label><figDesc>REFERENCE CLASSES IN UNIVERSITY OF PAVIA IMAGE a test set (see Table</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI CLASSIFICATION</head><label>VI</label><figDesc>ACCURACY (AVERAGED ON TEN RUNS WITH RANDOMLY SAMPLED TRAINING SAMPLES) OF THE UNIVERSITY OF PAVIA IMAGE OBTAINED BY SVM</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VII RUN</head><label>VII</label><figDesc>TIME (SECONDS) AVERAGED OVER TEN REALIZATIONS FOR THE CLASSIFICATION OF THE INDIAN PINES, SALINAS, AND UNIVERSITY OF PAVIA</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Data sets were downloaded at: http://www.ehu.es/ccwintco/index.php/ Hyperspectral_Remote_Sensing_Scenes.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. J. Li of the University of Extremadura for providing the software for LORSAL-MLL on her website 2 and also the editors and all of the anonymous reviewers for their constructive suggestions, which greatly improved the paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Introduction to Remote Sensing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Campbell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Taylor and Francis</publisher>
			<pubPlace>London, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recent advances in techniques for hyperspectral image processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">S1</biblScope>
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Borengasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Hungate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Watkins</surname></persName>
		</author>
		<title level="m">Hyperspectral Remote Sensing-Principles and Applications</title>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral remote sensing images with support vector machines</title>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1778" to="1790" />
			<date type="published" when="2004-08">Aug. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A novel transductive SVM for semisupervised classification of remote-sensing images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marconcini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3363" to="3373" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semisupervised classification of hyperspectral images by SVMs optimized in the primal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1870" to="1880" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A support vector conditional random classifier with a Mahalanobis distance boundary constraint for high spatial resolution remotes sensing imagery</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1314" to="13330" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spectral-spatial hyperspectral image segmentation using subspace multinomial logistic regression and Markov random fields</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="809" to="823" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised hyperspectral image classification using soft sparse multinomial logistic regression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="318" to="322" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semisupervised neural networks for efficient hyperspectral image classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2271" to="2282" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An adaptive artificial immune network for supervised classification of multi-/hyperspectral remote sensing imagery</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="894" to="909" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Artificial DNA computing-based spectral encoding and matching algorithm for hyperspectral remote sensing data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4085" to="4104" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Advances in spectral-spatial classification of hyperspectral images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Tilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="652" to="675" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral imagery based on partitional clustering techniques</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2973" to="2987" />
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Composite kernels for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gomez-Chova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Muñoz-Marí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vila-Francés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Calpe-Maravilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="97" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalized composite kernel framework for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Marpu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4816" to="4829" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hyperspectral image segmentation using a new Bayesian approach with active learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<ptr target="http://www.lx.it.pt/~jun/" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3947" to="3960" />
			<date type="published" when="2002">Oct. 2011. 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Limitations of principal components analysis for hyperspectral target recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="629" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Double nearest proportion feature extraction for hyperspectral-image classification</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4034" to="4046" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dimensionality reduction based on clonal selection for hyperspectral imagery</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4172" to="4186" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Locality-preserving dimensionality reduction and classification for hyperspectral image analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1185" to="1198" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Classification and feature extraction for remote sensing images from urban areas based on morphological transformations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pesaresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Amason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1940" to="1949" />
			<date type="published" when="2003-09">Sep. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On combining multiple features for hyperspectral remote sensing image classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="879" to="893" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996-06">Jun. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From sparse solutions of systems of equations to sparse modeling of signals and images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="81" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An efficient dictionary learning algorithm and its application to 3-D medical image denoising</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="417" to="427" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast acquisition and reconstruction of optical coherence tomography images via sparse representation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2034" to="2049" />
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Remote sensing image fusion via sparse representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4779" to="4789" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification using dictionary-based sparse representation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3973" to="3985" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploiting sparsity in hyperspectral image classification via graphical models</title>
		<author>
			<persName><forename type="first">U</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="505" to="509" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification via kernel sparse representation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="217" to="231" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification based on structured sparse logistic regression and three-dimensional wavelet texture feature</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2276" to="2291" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Algorithms for simultaneous sparse approximation. Part I: Greedy pursuit</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="2006-03">Mar. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive sparse representations for video anomaly detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="631" to="645" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Joint dynamic sparse representation for multi-view face recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1290" to="1298" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning multiscale sparse representations for image and video restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="214" to="241" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sparsity based denoising of spectral domain optical coherence tomography images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="927" to="942" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sparse representation of (multiscale) histograms for face recognition robust to registration and illumination problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Image Process</title>
		<meeting>IEEE Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2441" to="2444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-scale patch based collaborative representation for face recognition with margin distribution optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Shiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Euro Conf. Comput. Vis</title>
		<meeting>Euro Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="822" to="835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adaptive greedy approximations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Avellaneda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Construct. Approx</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="98" />
			<date type="published" when="1997-03">Mar. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Matching pursuits with time-frequency dictionaries</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3397" to="3415" />
			<date type="published" when="1993-12">Dec. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Convex matching pursuit for large-scale sparse coding and subset selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1119" to="1125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sparse transfer manifold embedding for hyperspectral target detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="894" to="906" />
			<date type="published" when="2014-02">Feb. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Support vector machines for hyperspectral remote sensing classification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gualtieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Cromp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="221" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral data from urban areas based on extended morphological profiles</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Palmason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Sveinsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="480" to="491" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A nonlocal weighted joint sparse representation classification method for hyperspectral imagery</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSTARS.2013.2264720</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient Implementation of the K-SVD Algorithm Using Batch Orthogonal Matching Pursuit</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Dept</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Technion, Haifa, Israel</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Gradient pursuits</title>
		<author>
			<persName><forename type="first">T</forename><surname>Blumensath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal. Process</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2370" to="2382" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
