<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extending Autocompletion To Tolerate Errors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Surajit</forename><surname>Chaudhuri</surname></persName>
							<email>surajitc@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raghav</forename><surname>Kaushik</surname></persName>
							<email>skaushi@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Extending Autocompletion To Tolerate Errors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8CC33B87588639686BC0C397291A971A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.2 [Database Management]: Systems Design</term>
					<term>Algorithms</term>
					<term>Experimentation Autocompletion</term>
					<term>Edit Distance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Autocompletion is a useful feature when a user is doing a look up from a table of records. With every letter being typed, autocompletion displays strings that are present in the table containing as their prefix the search string typed so far. Just as there is a need for making the lookup operation tolerant to typing errors, we argue that autocompletion also needs to be error-tolerant. In this paper, we take a first step towards addressing this problem. We capture input typing errors via edit distance. We show that a naive approach of invoking an offline edit distance matching algorithm at each step performs poorly and present more efficient algorithms. Our empirical evaluation demonstrates the effectiveness of our algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Autocompletion is a ubiquitous feature found to be useful in several environments. As the user types, a list of appropriate completions is returned by such a feature. The goal is not only to reduce typing effort but also to help guide the user's typing.</p><p>Not surprisingly, autocompletion has found wide adoption as a feature in a variety of applications. This feature is available today in program editors such as Visual Studio, command shells such as the Unix Shell, search engines such as Google, Live and Yahoo, and desktop search. Autocompletion is also gaining popularity for mobile devices since it can assist the user in keying in contacts and text messages.</p><p>Autocompletion is also valuable in the database context as such a feature can help ensure data integrity by substantially reducing the probability of data entry errors. The specific scenario that is our focus is when a user is looking up a record from a table by entering a string, such as when a sales clerk is looking up a customer's name or one is looking up a product catalog online. For instance, http://www.amazon.com suggests completions when we are looking up a product item. Similarly, Yahoo Finance suggests completions when we are looking for a stock symbol or organization name.</p><p>One way of viewing autocompletion is as an online method of performing exact matching, since in the absence of autocompletion, a user would have to type out the string in its entirety and then match it against the table of records. In contrast to the online autocompletion process, we call the latter an offline lookup.</p><p>In an offline lookup setting, the data cleaning community has long recognized the need to go beyond exact matching. This is because the input string being typed can contain errors and differences in representation making exact matching inadequate. This observation has motivated the vast body of work on record matching <ref type="bibr" target="#b12">[12]</ref>.</p><p>In this paper, we argue that in the same way, the scope of autocompletion should be extended to tolerate errors and differences in representation. At first glance, this may not be obvious since even exact autocompletion does act as a hint in guiding the user's typing and to some extent reduces the likelihood of errors being committed in the first place. However, there are many important scenarios where errortolerant autocompletion would add significant value. For example, consider the name Schwarzenegger. It is quite likely that a user looking up this name is likely to start with the prefix Shwarz or Swarz instead of the correct prefix Schwarz. In this case, the only opportunity for an exact autocompletion approach to suggest the correct completion is when the prefix S has been entered; but at this point, the number of completions is likely to be too high to be useful in a database of any realistic scale.</p><p>This problem is only exacerbated in domains such as product model numbers where we cannot rely on phonetics and intuition to guess the correct spelling. Further, even if we knew the correct spelling of a string, we may still mistype, especially when typing fast. There is no reason to believe that such typing errors are less likely at the beginning of the string. Error-tolerant autocompletion is also useful in maintaining data integrity since being quickly able to browse approximate completions can reduce duplicate entries.</p><p>Motivated by these observations, we study the problem of error-tolerant autocompletion. We begin by laying out the framework for exact autocompletion (Section 2) which we then extend to tolerate errors (Section 3). Just as we view exact autocompletion as an online version of exact lookup, we model the error-tolerant autocompletion problem as an online version of error-tolerant lookup. As is standard in data cleaning, in order to define what it means to tolerate errors, we need to use a notion of string similarity. While there are several sophisticated ways of modeling errors in data <ref type="bibr" target="#b12">[12]</ref>, in this paper, we take a first step by adopting the classical edit distance as our measure of similarity between strings. We generalize the notion of the extension of a string to tolerate edit errors. We show that it is possible to implement this strategy by using an vanilla edit distance matching algorithm at each step and argue that this can be quite expensive (Section 3.4). Accordingly, we propose two improved edit-tolerant autocompletion algorithms. The first is based on the state-of-the-art q-gram based edit distance matching algorithms (Section 4). The second is a trie-based algorithm that is even more suited to autocompletion (Section 5).</p><p>Often, when only a few characters of the lookup string have been entered, there are too many completions for autocompletion to be useful. We thus consider an alternate buffered strategy that performs autocompletion only after a few input characters have been entered (Section 5.2). We use pre-computation to handle kick start the autocompletion. By hashing characters to a small number of bits and exploiting the fact that we are performing pre-computation only for short strings, we control the amount of state needed for pre-computation. We show that pre-computation coupled with the trie has formal guarantees for edit distance matching (Section 5.3). Not surprisingly, we find that precomputation further improves the performance of the triebased algorithm significantly.</p><p>Often, the records in the table being looked up have an application specific static score. For example, in a table of product records, the static score could be used to reflect the popularity of the product, say based on the number of recent purchases. It is natural to factor this in addition to the edit distance in ordering the autocompletion output. We show how to extend our algorithms to return only the top-l extensions exploiting such an ordering (Section 5.4).</p><p>We then conduct a detailed empirical evaluation of the techniques we propose over real data sets (Section 6). Among other things, we empirically show the effectiveness of error tolerant autocompletion by measuring the additional key strokes saved over and above exact autocompletion. By comparing edit-tolerant autocompletion with offline editdistance matching, we also study the additional overhead incurred in invoking an online approach to edit distance matching. We show that while our solution does impose an additional overhead as expected, this is substantially better than the additional overhead imposed by exact autocompletion when compared to exact string lookup.</p><p>We discuss related work in Section 7 and conclude in Section 8. Finally, we note that despite the availability of errortolerant autocompletion in a limited number of products, little is known about their underlying algorithms. To the best of our knowledge, this is the first piece of work that systematically studies error-tolerant autocompletion in the context of database lookups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">AUTOCOMPLETION: STATE OF THE ART</head><p>At its core, autocompletion is about suggesting valid completions of a partially entered lookup string with the intention of minimizing and guiding the user's typing. The concept of autocompletion is not new. There are various approaches studied in prior work on autocompletion. There is a vast body of work on predictive autocompletion <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b16">16]</ref> where the idea is to use information retrieval techniques, language models and learning to suggest potential completions.</p><p>In contrast, our focus is on the scenario where there is a table T of strings being looked up and thus completions are suggested based on matches in T . This is the form of autocompletion supported by http://www.amazon.com and Yahoo Finance for instance. The most common form of such autocompletion is based on exact matching. In this section, we formalize some of the key concepts involved in exact autocompletion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Autocompletion Interface</head><p>Autocompletion is an online problem where at any point, there is a partially typed string s that we call the lookup string. In response, the autocompletion produces a list C ompletions(s). The lookup string is modified via some user move. In general, the user can modify the string using any of a large space of moves -the user can append a character, insert or delete a character either at the end of the string or anywhere in the string, choose one of the suggested completions, and invoke a lookup. In this paper, we focus primarily on the following user moves.</p><p>• Append(c): append a character to the end of the lookup string s,</p><p>• C hoose(s ) where s ∈ C ompletions(s): choose one of the suggested completions.</p><p>We choose these moves since these are the most common moves made by the user. We defer a study of other moves to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Autocompletion Strategy</head><p>There are multiple ways in which exact autocompletion may be performed. We call these possibilities autocompletion strategies.</p><p>Perhaps the simplest strategy is to return all strings in T that are extensions of the lookup string. When the number of characters in the lookup string is very small -at the extreme case when only the first character has been entered -the number of extensions can be too large to be useful. This motivates an alternate strategy where we perform autocompletion only after a minimum number of characters have been input.</p><p>Another exact autocompletion approach is to return at each point all strings in T that contain the partially entered lookup string as a substring. This is the strategy supported by Yahoo Finance for instance. As with the prefix based approach above, we could consider doing this only after the lookup string has a minimum number of characters.</p><p>In general, the autocompletion strategy could be quite complex as illustrated by prior work on multi-word autocompletion <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b16">16]</ref>.</p><p>Often, we can order the completions by leveraging an application specific static score assigned to each string in T . For example, if T represents a table of products and we store a log of lookup queries posed against T , then we can use the static score to reflect the popularity of a product, say based on the number of recent purchases. Alternately, the static score can be used to bias the lookup toward newer products. Another example is when T consists of author names and we use the static score to bias one subject area over others -an application that is targeted toward database users can use the static score to assign a higher preference to database authors.</p><p>A given autocompletion strategy can be supported by a variety of algorithms. For instance, if our strategy is to return all extensions of the lookup string, we could (a) at each point issue an offline prefix lookup using say a B-Tree that finds all extensions in T , or (b) use a trie to find all extensions in an online fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Efficiency Considerations</head><p>An important goal of an autocompletion system is to be responsive -it must look instantaneous to the user. Prior work <ref type="bibr" target="#b14">[14]</ref> has shown that this implies a maximum response time of 100ms. In a client-server setting, this 100ms bound includes not only the autocompletion time, but other overheads such as the communication overheads. Thus, it is desirable to make the per-character autocompletion cost itself minimal.</p><p>As noted above, we view autocompletion as an online method of performing the underlying lookup. We expect the online algorithm to be slower than an offline lookup. For instance, finding an exact match by hashing a string in its entirety is substantially faster than looking up a trie character by character. Thus, the benefits of autocompletion come with the price of invoking an online algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">INCORPORATING ERROR TOLER-ANCE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This paper</head><p>Amazon.com Yahoo! Finance Our goal as argued in Section 1 is to extend autocompletion to be error tolerant. In Section 2, we considered various ways in which autocompletion could be performed. The question arises how error tolerance influences these options. In general, any of these methods can be extended to be errortolerant. As shown in prior work on record matching <ref type="bibr" target="#b12">[12]</ref>, error tolerance can be achieved in many ways, for example by choosing different similarity functions. Any of these similarity functions can be used to make autocompletion error-tolerant. This leaves us with a two-dimensional space of options plotted in Figure <ref type="figure">1</ref> In this paper, we focus on extending the prefix based approach to be error tolerant. The similarity function we choose is the classic edit distance. Even though our techniques generalize to also handle substring matching, we omit the details owing to a lack of space. In this section, we review the definition of edit distance, extend the concept of string extensions to tolerate string edits via the notion of k-Extensions. We then discuss some of the properties of k-Extensions which provide the basis for all algorithms we propose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Edit Distance Based Matching</head><p>We choose edit distance as our notion of tolerating errors in this paper. Given two strings s1 and s2, we are allowed to insert and delete characters as well as replace one character with a different one. The minimum number of moves we need to perform on s1 such that the result is equal to s2 is the edit distance between the two strings, denoted ed (s1, s2). We use the phrase "edit distance within k" to refer to the expression ed (s1, s2) ≤ k.</p><p>Example 1. The string Shwarzenegger has edit distance 1 to the string Schwarzenegger. In order to transform Shwarzenegger to Schwarzenegger, we need to insert character c after S.</p><p>2 Fix a string s and a threshold k. The (offline) edit lookup operation returns all strings r ∈ T that are within edit distance k in increasing order of edit distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">k-Extension</head><p>We now extend the concept of string extensions to be tolerant of string edits. Figure <ref type="figure">2</ref> shows an example of our intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Completions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: Error Tolerant Autocompletion</head><p>We formalize this intuition through the following definition.</p><p>Definition 1. A string s1 is defined to be a k-prefix of string s2, denoted s1 ≺ k s2 if there is some extension of s1 that is within edit distance k of s2. s2 is called a k-extension of s1. The smallest k such that s2 is a k-extension of s1 is called the extension distance of s2 given s1.</p><p>We illustrate this definition with an example.</p><p>Example 2. In Figure <ref type="figure">2</ref>, observe that each of the strings Ashwin Navin, Schwarzenegger, Arnold and Schwarz, Hermann is a 1-extension of Shw.</p><p>The extension of the input string that yields edit distance 1 to Schwarzenegger is Shwarzenegger. The extension distance of Schwarzenegger given Shwarz is 1.</p><p>2</p><p>If instead of using string extensions, we were to perform edit-tolerant substring matching, then in Figure <ref type="figure">2</ref>, we would return additional strings such as Graeme Swann.</p><p>We consider two autocompletion strategies in this paper. The first is as follows.</p><p>Definition 2. Fix an edit threshold k. The Full k-Extension Strategy is as follows: At each point as the lookup string is modified by appending characters, our goal is to return all k-extensions in the order of increasing extension distance.</p><p>Often, when only a few characters of the lookup string have been entered, there are too many completions for autocompletion to be useful. We therefore consider a Buffered Strategy where we are required to return the k-extensions, but only after the lookup string has a minimum number b of characters. We refer to this number b as the transition length.</p><p>As with exact autocompletion, we can leverage the application specific static score associated with each string in T , if available. We assume an overall scoring function that is monotonic <ref type="bibr" target="#b6">[6]</ref> in both the edit distance and the static score. We can return completions ordered by this overall scoring function, independent of the specific function chosen so long as it is monotonic.</p><p>Finally, as argued in Section 2.3, we expect online autocompletion to be slower than offline matching. However, our goal is to make this efficiency gap comparable to the case of exact autocompletion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Properties of k-Extensions</head><p>We now discuss some properties of k-Extensions. We first establish the relationship between extensions and prefixes when allowing for string edits. We use this relationship to show how to compute the pairwise extension distance defined above by adapting the classic dynamic programming based edit distance computation algorithm <ref type="bibr" target="#b17">[17]</ref>. This discussion forms the basis for all algorithms in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Relating Extensions to Prefixes</head><p>First we show the following equivalence which forms the basis for all algorithms we propose in this paper. Property 1. s1 ≺ k s2 if and only if there is some prefix s 2 of s2 such that s1 and s 2 are within edit distance k.</p><p>We illustrate this property with an example below.</p><p>Example 3. As noted earlier, the string Schwarzenegger is a 1-extension of Shwarz. In this case, the prefix Schwarz is within edit distance 1 of Shwarz. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Pairwise Extension Distance</head><p>We develop our algorithm to solve this problem by first considering the following more basic problems.</p><p>• Extension Distance: Given strings s1 and s2, compute the extension distance of s2 given s1.</p><p>• k-Extension Distance: Given strings s1 and s2, check if the extension distance of s2 given s1 is at most k and if so, compute the extension edit distance.</p><p>These problems can be solved by a straightforward adaptation of the standard dynamic programming algorithm for (0) J( <ref type="formula">1</ref>) o( <ref type="formula">2</ref>) h( <ref type="formula">3</ref>) n( <ref type="formula">4</ref>) n( <ref type="formula">5</ref>) y( <ref type="formula">6</ref></p><formula xml:id="formula_0">) (0) 0 1 2 3 4 5 6 J(1) 1 0 1 2 3 4 5 o(2) 2 1 0 1 2 3 4 n(3) 3 2 1 1 1 2 3 Figure 3: Pairwise Edit Distance</formula><p>computing the edit distance between s1 and s2 <ref type="bibr" target="#b17">[17]</ref>. We first review this algorithm. Suppose that the two strings under consideration are s1 and s2. We place the two strings on a matrix D with s1 top-down and s2 left-to-right, and incrementally compute the edit distance between all prefixes of s1 and s2. Figure <ref type="figure" target="#fig_8">3</ref> illustrates the dynamic programming matrix for the two strings s1="Jon" and s2="Johnny". Let i be the index of the rows in the dynamic programming matrix and j be the index of the columns. The row numbers increase as we go down whereas the column numbers increase from left to right. Both begin at 0. The numbers in parentheses in Figure <ref type="figure" target="#fig_8">3</ref> indicate the row and column numbers. The number entered in cell D(i, j) denotes the edit distance between the prefixes ending at i and j respectively. The recurrence relation that completes D is as follows <ref type="bibr" target="#b17">[17]</ref>.</p><formula xml:id="formula_1">D(i, j) = min(D(i -1, j) + 1, D(i, j -1) + 1, D(i -1, j -1) + δ(i, j))</formula><p>where δ(i, j) is 0 or 1 according as the i th character of s1 and the j th character of s2 are equal. For example,</p><formula xml:id="formula_2">D("Jo","Joh") = D(2, 3) = min(D(1, 3) + 1, D(2, 2) + 1, D(1, 2) + δ(2, 3)) = min(3, 1, 2) = 1</formula><p>Note that in this process, we find the edit distance between s1 and all prefixes of s2 -this is captured in the last row of D. We can then find the prefix of s2 with the smallest edit distance from s1 by finding the smallest entry in the last row. Using Property 1, we can see that this yields the extension distance. We can see from Figure <ref type="figure" target="#fig_8">3</ref> that even though the edit distance is 3, the extension distance is 1 for s1 and s2 as defined above. Now consider the k-Extension Distance problem. Intuitively, we can ignore parts of the matrix D where the value is guaranteed to be larger than k. The following property of matrix D follows from the recurrence relation above and lets us formalize this intuition.</p><formula xml:id="formula_3">Property 2. (1) D(i, 0) = i and D(0, j) = j, and (2) D(i, j) ≥ D(i -1, j -1).</formula><p>Now define the c-diagonal to be all cells such that i -j = c (c can be negative). By Property 2, it follows that we only need to track the entries of D in diagonals -k through k -all other cells in D are guaranteed to have values larger than k. For each cell in these diagonals, we need to store the edit distance only if it is at most k (otherwise we store ∞). The recurrence relation can be used to compute the edit distance so long as it is at most k. Then we read off the minimum value in the last row as before to compute the extension distance. Figure <ref type="figure" target="#fig_2">4</ref> illustrates this for the case k = 1. Observe that this algorithm takes O(kn) time where n is the length of s1.</p><p>Finally, we can see that the above algorithm is naturally incremental. Adding a new character to s1 corresponds to (0) J( <ref type="formula">1</ref>) o( <ref type="formula">2</ref>) h( <ref type="formula">3</ref>) n( <ref type="formula">4</ref>) n( <ref type="formula">5</ref>) y( <ref type="formula">6</ref> </p><formula xml:id="formula_4">) (0) 0 1 J(1) 1 0 1 o(2) 1 0 1 n(3) 1 1 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Baseline Algorithm for Edit-Tolerant Autocompletion</head><p>We can use Property 1 coupled with any offline edit distance matching algorithm to implement both the Full and Buffered strategies. We first introduce some notation to talk about the prefixes of strings. Given a string r, the set consisting of r and all its prefixes is denoted r. Given a table of strings T , the set of strings in T along with all their prefixes is denoted T .</p><p>We index all strings in T . At any point in the autocompletion, we invoke the offline algorithm to find matching strings in T and then return their corresponding extensions. We call this the baseline algorithm. It is sketched in Algorithm 3.1 for the Full strategy and can be trivially extended to handle the Buffered strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3.1 Baseline Algorithm</head><p>Input: String s input incrementally with new character being appended at each step and edit threshold k. Output: At each step, all k-extensions 1. Build an index for offline edit matching over all strings in T 2. For each character c of the input 3. Use the index to find all r ∈ T such that some prefix of r is within edit distance k of s</p><p>The baseline algorithm has serious shortcomings. If we performed no autocompletion, we would invoke offline matching on the entire lookup string. This matching would occur over the strings in T . In contrast, the baseline algorithm invokes offline matching on a much larger set, namely T . Further, this matching is performed for each character appended.</p><p>There is considerable room for improvement over this approach, by exploiting (1) the structure of the set of being indexed, namely T , and (2) the commonality among the successive lookups which only differ in one character. This is the focus of the next two sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Q-GRAM BASED ALGORITHM</head><p>We now discuss our q-gram based autocompletion algorithms. Q-gram based techniques constitute the state-ofthe-art algorithms for offline edit distance matching <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b21">21]</ref>. We first briefly review these algorithms before introducing our extensions for autocompletion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Review of Offline Q-Gram Based Lookup</head><p>A q-gram of a string s is a contiguous substring of s of length q. The q-gram set is the bag of all q-grams of s.</p><p>Intuitively, if the edit distance between two strings s and r is small, then the overlap between the corresponding qgram sets must be large. Formally if ed (r, s) ≤ k then the (bag) intersection between their q-gram sets must be at least (max (|r|, |s|)-q+1)-q•k where |r| and |s| denote the lengths of r and s respectively <ref type="bibr">[9]</ref>.</p><p>Example 4. The edit distance between Shwarzenegger and Schwarzenegger is 1. Consider their 1-gram sets which is the set of all characters in the strings. Their intersection size is 13 which is larger than or equal to (max <ref type="bibr" target="#b13">(13,</ref><ref type="bibr" target="#b14">14)</ref> </p><formula xml:id="formula_5">-1 + 1) -1 • 1 = 13.</formula><p>This relationship is used to invoke a set-similarity based matching. The detail of set-similarity matching that is relevant here is that most previously proposed algorithms are based on signature schemes <ref type="bibr" target="#b1">[1]</ref>. The idea is to create a set of signatures for each string based on its q-gram set. The signature scheme must have the property that whenever two strings are within edit distance k, they share at least one common signature. Examples of signature schemes are Prefix-Filter <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b21">21]</ref>, PartEnum <ref type="bibr" target="#b1">[1]</ref> and Locality Sensitive Hashing(LSH) <ref type="bibr" target="#b7">[7]</ref>. The index consists of an inverted list that maps a signature to all strings that generate this signature. At lookup time, signatures are generated for the lookup string and the union of all the corresponding rid-lists is taken. Each string in this union is then passed through a verification where we check whether its edit distance to the lookup string is indeed within k. This verification step is necessary since the signature lookup can generate false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Q-Gram Based Autocompletion</head><p>Fix a signature scheme Sig. Consider a string r ∈ T . Recall from Property 1 that we need to consider returning r whenever some prefix of r is within edit distance k of the lookup string.</p><p>We illustrate the problem of using the q-gram approach coupled with the baseline algorithm shown in Figure <ref type="figure" target="#fig_8">3</ref>.1 through an example. Suppose that T consists of the single string r = Schwarzenegger. Suppose also that the signature scheme Sig returns all 1-grams. We have one inverted list per character of the string Schwarzenegger. Each of these lists contains all prefixes of r that contain the respective character. For instance, the list for character 'S' contains all (non-empty) prefixes of r. This is shown in the column called "Baseline List" in Figure <ref type="figure" target="#fig_4">5</ref>  We improve upon this as follows. We modify the signature scheme to obtain a signature scheme Sig where Sig (r) = ∪ r ∈r Sig(r ). Since the strings in r have substantial overlap, they generate many common signatures.</p><p>Unlike the baseline approach, these common signatures are represented only once. We build an inverted index over the signatures generated by Sig . The inverted index for the character 'S' in our example above consists of the single string Schwarzenegger -this is shown in the column marked "Modified List" in Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>The verification phase can be optimized by exploiting the commonality among the strings in r. We noted in Section 3.3.2 that the k-Extension Distance computation between r and s actually performs the k-Extension Distance computation for all pairs of strings in r, s. By Property 1, we can perform verification in one invocation of the dynamic programming algorithm described in Section 3.3.2.</p><p>We can further optimize the q-gram based algorithm by exploiting the the fact that successive lookup strings only differ in one character. At each step, we avoid re-scanning the lists of signatures that we have already examined. For example, since the signatures for Sh and Shw contain the character 'S', the list for 'S' is accessed only once.</p><p>These optimizations lead to significant improvements in the running time of the q-gram based algorithm. However, despite these optimizations, the number of strings being retrieved at each step for verification can be significant leading to poor performance as we will see in Section 6. Ideally, we would like to "transition" from the results in one step to the results in the next. We achieve this in an automaton-style traversal over a trie.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">TRIE-BASED ALGORITHM</head><p>We now discuss our trie-based autocompletion algorithms. The idea is to transition from the k-extensions in one step to the next just as we do in an automaton. This also results in a novel trie-based algorithm for offline edit distance matching that processes the lookup string character by character (see Section 7 for a detailed discussion of related work).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Full k-Extension Strategy</head><p>We organize the set of strings in T as a trie. We represent the transitions as edge labels. Figure <ref type="figure">6</ref> shows an example trie. Owing to potential edit errors at any given time, we could be at multiple nodes in the trie. The algorithm maintains the set of all prefixes of the strings in the database that are within edit distance k. We call the corresponding nodes in the trie valid. It can be shown that for any k-extension of the lookup string, there at most 2k + 1 prefixes that are within distance k, and that these prefixes correspond to a contiguous path in the trie.</p><p>The pseudo-code is shown in Algorithm 5.1. As characters are appended to the input, we make transitions roughly corresponding to how we populate the edit matrix. We think of the input string as populating the rows of the edit matrix D. Before the next character is appended, we have the values for row i populated in the valid buffer in Algorithm 5.1. We are trying to populate the entries for the next row which is captured in the buffer new-valid.</p><p>Recall that the cells in row i + 1 are populated left to right. In the trie, this corresponds to a top-down traversal. Cell D(i + 1, j) is influenced by the values in D(i + 1, j -1), D(i, j -1) and D(i, j). In the trie, the value of D(i+1, j -1) is stored in new-valid whereas the value of D(i, j -1) is stored in valid. The influence of D(i + 1, j -1) and D(i, j - Add(valid, nd, i) 5. For each character c of the input Traverse the nodes in valid in queue order 6.</p><p>For each valid node nd 7.</p><p>Let lcurr = Distance(valid, nd) 8.</p><p>If lcurr + 1 ≤ k 9.</p><p>Add(new-valid, nd, lcurr + 1) 10.</p><p>If nd has a child nd through edge label c 11.</p><p>Add(new-valid, nd , lcurr) 12.</p><p>Let lnew = Distance(new-valid, nd) 13.</p><p>Let l = min(lcurr, lnew) 14.</p><p>If</p><formula xml:id="formula_6">l + 1 ≤ k 15.</formula><p>For each child nd of nd 16.</p><p>Add(new-valid, nd , l + 1) 17.</p><p>Swap new-valid and valid 18.</p><p>Clear new-valid 19.</p><p>Return Note that this procedure requires that we process the valid nodes in a top-down order where the parent of a node is processed before its children. The valid nodes are maintained in a buffer that has two components -a queue to maintain these nodes in top-down order, and a hash table to store the edit distance for each valid node. By the way Algorithm 5.1 operates, the top-down order is maintained without the need for an explicit sort.</p><p>The algorithm is initialized for the empty input string. This corresponds to marking the root and all nodes reachable within distance k from the root as valid (Steps 1-4). Finally, just as for the exact case, we return all leaf nodes reachable from the valid nodes. Note that the edit distance ordering can be ensured by sorting the node distances before retrieving the leaf nodes reachable from them.</p><p>Figure <ref type="figure">6</ref> illustrates how the algorithm operates on a database consisting of three strings -Johnny, Josef and Bond. The input string being entered is Jonn. The shaded nodes denote the valid nodes and the edit distances are shown beside them.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Buffered k-Extension Strategy</head><p>Efficiency-wise, one of the problems with the fullextension strategy above is that the number of valid nodes can be large. For instance, when the input string is empty, all nodes that are within distance k of the root of the trie are deemed valid.</p><p>We empirically study how the number of valid nodes changes as we progress in the lookup string. We work with an address data set consisting of 100 thousand strings (see Section 6 for more details of the experimental set up). We select lookup strings at random from the same database and compute the average number of valid nodes at any given lookup length, for various edit distance thresholds. The resulting plot is shown in Figure <ref type="figure" target="#fig_7">7</ref>. The X-axis shows the length of the lookup string and the Y-axis plots the number of valid nodes on a logarithmic scale. As we can see, the number of valid nodes rises sharply with the edit distance threshold reaching a maximum of close to 25% of the number of strings in the data for k = 4, but also drops rather quickly once some initial portion of the string has been processed. This sharp increase in the number of valid nodes leads to a significant increase in execution time.</p><p>In addition to the utility argument presented in Section 2, this observation further motivates us to consider the buffered autocompletion strategy. In order to use Algorithm 5.1 to support this strategy, we need a way to determine the set of valid nodes at the transition length. While we could accomplish this by performing the traversal in Algorithm 5.1, this would perform poorly as explained above.  We therefore maintain a separate index and invoke an offline edit distance matching algorithm at the transition length. The fact that the transition length is small can be used to pre-compute all edit distance matches. We reduce the alphabet size by hashing all characters to a small number of bits. Note that in this process, the edit distance between two strings can only decrease. In this hashed space, the number of strings of a small length is not very large. For instance, if we hash all characters to 4 bits and consider a transition length of 5, the number of possible hashed strings is 1 million. For each of these, we pre-compute all distance k neighbors from T . Note that at lookup time, we need to verify the strings returned from pre-computation to check whether they are within edit distance k in the original alphabet space (this can be achieved via the dynamic programming algorithm described in Section 3.3.2).</p><p>As can be seen from Figure <ref type="figure" target="#fig_7">7</ref>, the number of valid states drops sharply as the transition length increases. By setting an appropriate transition length, we can utilize precomputation to overcome the problem with short strings. This algorithm is outlined in Figure <ref type="figure" target="#fig_4">5</ref>.2. Indeed, we provide a formal basis for this intuition in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>We now formally analyze the trie-based algorithms proposed above. We first analyze them from the point of view of autocompletion, and then from the point of view of offline edit distance matching. Owing to lack of space, all proofs are omitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Autocompletion</head><p>For the Full k-Extension strategy, if we are required to output all k-extensions at each step, then Algorithm 5.1 in a sense does the minimal amount of work -the number of valid nodes at each point is at most 2k + 1 times the number of strings that are returned in this step. Algorithm 5.1 transitions from one set of valid nodes to the next in time linear in the number of such nodes. Suppose that the eventual lookup string s consists of m characters. Then, we perform autocompletion m times. Let the total output size of these completions across all m steps be ACOutput(s). We also count the running time of Algorithm 5.1 over all m character appends.</p><formula xml:id="formula_7">Lemma 1. Algorithm 5.1 runs in time O(k•ACOutput(s)).</formula><p>Note that this is the worst case. In practice, the number of valid states is likely to be much smaller since the trie compresses common prefixes.</p><p>For the Buffered strategy, a similar analysis holds after the transition length. At the transition length, since the output is pre-computed in the hashed space, there is additional work in verifying the edit distance condition in the original alphabet space. We therefore need to analyze the probability of false positives produced after hashing.</p><p>Let the original alphabet size be σ and the size of the hashed alphabet be γ. We can show the following result assuming a perfect hash function h. Given string s, we refer to its hash image as h(s).</p><p>Lemma 2. Suppose that ed (s1, s2) &gt; c • k and that both strings consist of unique characters from the alphabet Σ. Then the probability that ed (h(s1), h(s2)) ≤ k is at most</p><formula xml:id="formula_8">( 1 γ ) (c-1)k 6</formula><p>.</p><p>This result can be generalized to the case where each character appears at most a bounded number of times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Edit Distance Matching</head><p>Observe that by construction, both Algorithm 5.1 and Algorithm 5.2 are algorithms for edit distance matching. More precisely: Property 3. For a lookup string s, consider the set of active nodes after all characters of s have been consumed that also correspond to full strings in T . These full strings are exactly the set of strings within edit distance k of s.</p><p>We also analyze the running time of this algorithm viewed as an edit distance matching algorithm. The cost of Algorithm 5.1 is proportional to the total number of nodes in the trie that are considered valid in some iteration. At each step, the valid nodes are precisely those that are within edit distnace k of the string typed thus far. Based on this observation, we can show that: The question arises whether the buffered strategy can be shown to be formally better. Assuming that the transition length b &lt;&lt; m, the length of the entire lookup string, as is the case in practice, the worst case cost stays the same, which raises the question whether the running time is better on average. We perform an analysis for the case of a constant sized alphabet, since this assumption holds once the characters are hashed. (As noted above, the scope for an excessive number of hash collisions is low.) We obtain the following result. Here, Output(s) denotes the output of edit distance matching for string s.</p><p>Lemma 4. Suppose we are performing edit distance matching for a constant edit distance k. Suppose that the strings in T are generated as follows. We fix a skeleton of table T where for each string, its length is fixed. We then generate each string by choosing each character independently uniformly at random from an alphabet of constant size γ &gt; 1.</p><p>Consider Algorithm 5.2 with transition length O(log |T |). The lookup time for string s of length m is O(m+Output(s)) with high probability.</p><p>We note that the above analysis merely merely provides a principled basis for our approach. In particular, we do not necessarily choose the transition length in accordance with the above result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Top-l Semantics</head><p>As noted in Section 2 we can order the extensions even in the case of exact autocompletion via a static score associated with each string in T . This ordering can be used to return only the top-l extensions. This further helps in keeping the output size small.</p><p>In the presence of string edits, we similarly have the option of returning only the top-l extensions sorted by a ranking function S core which combines the edit distance with the static score of a string in a monotonic fashion (as described in Section 3.2). Finding all extensions and then sorting them by their score can be inefficient since the number of extensions can be large whereas we only want to return the top-l.</p><p>We address this by pre-computing the top-l completions by static score for each node in the trie. For exact autocompletion, we use this to simply read off the top-l extensions from the current node in the trie.</p><p>When allowing for edits, we have multiple valid nodes in the trie. Therefore we merge the sorted lists corresponding to each valid node to obtain the overall top-l. Since the overall score is monotonic in the static score and the edit distance, we can invoke any of the previously published algorithms such as the Threshold Algorithm <ref type="bibr" target="#b6">[6]</ref> that perform early termination when computing the top-l results.</p><p>We can extend this idea to the case of the q-gram based algorithms by viewing the q-gram technique as a way of obtaining the valid nodes in the trie at each step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTS</head><p>In this Section, we discuss our empirical study of errortolerant autocompletion. The goals of our study are: 1. To measure the effectiveness of incorporating error tolerance in autocompletion by studying the number of key strokes saved when typing.</p><p>2. To compare the performance of the Full and Buffered strategies for error-tolerant autocompletion.</p><p>3. To compare the performance of trie-based autocompletion with the q-gram based algorithms. 4. To compare the performance of online autocompletion against offline edit distance matching algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>To study the impact of data size on autocompletion performance.</p><p>We first discuss some details of our implementation and the experimental setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Implementation Details</head><p>Our prototype is implemented in managed code (C#). All of our implementation is in-memory. The trie is compressed in order to reduce its memory footprint. Specifically, we identify "chains" in the trie where no node has more than one child. These chains are compressed by creating only one node per chain that represents the entire chain. This technique yields significant compression since the trie of data sets we encounter in practice have a large number of chains. We store a separate table of the top-l completions at each node in a separate (in-memory) table. As noted in Section 5.1, the set of active nodes is maintained using a queue and a hash table. For the buffered autocompletion strategy, we consider various transition lengths up to 7 characters setting the hashed alphabet size appropriately so that the total number of strings for which we perform pre-computation is at most 2 million. We pick the best transition length. We refer to the trie-based algorithms as Trie in this section.</p><p>For the q-gram based algorithm, we study three of the state-of-the-art signature schemes -Locality Sensitive Hashing (LSH) <ref type="bibr" target="#b7">[7]</ref>, PartEnum (PE) <ref type="bibr" target="#b1">[1]</ref> and the improved Prefix Filtering (PF) technique proposed recently <ref type="bibr" target="#b21">[21]</ref>. LSH is an approximate technique that can miss some results with a tunable probability. We configure LSH so that this failure probability is 5%. In contrast, both PE and PF are accurate -they are guaranteed not to miss any results. For each of these signature schemes, we do not perform any set-based post-filtering once the signatures are looked up. This is because we require an edit distance check that incorporates prefixes and doing a set-based verification for all prefixes would be wasteful. Our implementation of the q-gram based indexes is also in-memory. Each of these signature schemes is parameterized. We manually choose these settings to obtain the best performance. We report the best results over all accurate and approximate signature schemes. We refer to these results as QGram Accurate and QGram Approx. respectively. Since accurate schemes are also approximate, the results for QGram Approx. can never be worse than those for QGram Accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Data</head><p>We report results over two real-world data sets. The first is a collection of author names from DBLP <ref type="bibr" target="#b5">[5]</ref> (DBLP). This data set has 550000 names and the average string length is 14. The second data set we use is a collection of proprietary addresses (Address) that has a total of 1.7 million addresses of average length 36. We use a subset of 500k addresses for most experiments.</p><p>Our experiments are run on a workstation running Microsoft Windows Server 2003 with a 3.6GHz Intel Xeon pro-  cessor and 8GB of main memory. Figure <ref type="figure" target="#fig_9">8</ref> reports the memory consumption of various techniques in MB. For the Trie algorithms, the memory consumed counts the space for precomputation. For the QGram techniques, we report the minimum memory consumed among all relevant signature schemes (for their best performing parameter choices). We find that the memory consumption of Trie is significantly better than either of the q-gram approaches. The space consumption of the online q-gram approaches is significantly higher because the number of signatures generated is much larger -we generate signatures not only for a string but also many of its prefixes. Thus, we find that the space consumption is worse when the strings are longer as is the case with addresses. As a point of comparison, we also report the memory consumption of offline techniques. We find that the memory consumption of Trie is comparable to the space consumed by the offline indexes for the Address data and substantially better for the DBLP data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Effectiveness of Error Tolerance in Autocompletion</head><p>In this experiment, we empirically study how critical error tolerance is when performing autocompletion. Our methodology is as follows. We fix a data set and a set of pairs of strings obtained by performing a separate "fuzzy" self-join on the data set at a small distance threshold. This represents pairs that that are different representations of the same underlying (author or address) entity.</p><p>For each of these pairs (s1, s2), we fix s1 as the lookup string and measure the total number of key strokes needed to find s2. In the absence of autocompletion, this number is the number of characters in s1. In the presence of autocompletion, we count the number of characters of s1 need to be entered before s2 appears in the top 10 results of autocompletion, and the number of key strokes needed to navigate the top 10 list before finding s2. The difference between the above yields the number of key strokes saved due to autocompletion. We measure this both for exact autocompletion and error-tolerant autocompletion for various settings of the autocompletion edit distance threshold, denoted k.    <ref type="figure" target="#fig_10">9</ref> reports the results of our study. We report the average number of key strokes saved per lookup string for various values of error threshold k. On the DBLP data set, we observe that in contrast with exact autocompletion (k = 0), 54.58% additional key strokes are saved when autocompletion is performed with threshold 2 for the DBLP data set. For the Address data set that consists of larger strings, more than 100% additional key strokes are saved. Even for k = 1, we find that close to 24% additional keystrokes are saved for DBLP and the corresponding number for Address is close to 39%. This indicates that tolerating errors when performing autocompletion significantly reduces the user's typing. We first compare the Full and Buffered strategies. The transition length used is 7 with all characters hashed to 3 bits. In order to make the comparison meaningful, we use the autocompletion algorithms to perform edit distance matching. We perform the comparison only for the Trie approach -the results are similar even for q-gram based approaches. Figure <ref type="figure" target="#fig_12">10</ref> reports the result of our study over the DBLP data set (the results look similar for the Address data). The X-axis shows the edit distance threshold used and the Y-axis reports the execution time for 1000 lookups in milli-seconds, on a log scale. We find that the full strategy is at least 5 times slower than the buffered strategy for k = 2 and k = 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Autocompletion Strategy</head><p>Recall from Section 5.2 that the primary reason for this disparity is that the number of valid nodes in the initial stages of autocompletion is extremely large for the Full strategy. This number sharply drops once a few characters of the input have been processed. Thus, the initial overhead incurred by the Full strategy is saved. Henceforth in this section, we do not consider the Full strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Efficiency: Trie Vs NGram</head><p>The rest of this section studies the overall efficiency of our autocompletion. We first compare the Trie and q-gram based autocompletion algorithms for the same (buffered) strategy. Figure <ref type="figure">11</ref> shows the comparison over both the data sets. We vary the edit threshold plotted on the X-axis and compute the lookup time aggregated over 1000 lookups, plotted on the Y-axis on a log scale. We find that the triebased Algorithm 5.2 significantly out-performs the ngram based algorithm, irrespective of the signature scheme chosen often by an order of magnitude. The primary reason for this is that Algorithm 5.2 pretty much navigates at each step from the previous answer set to the current answer set. Instead, the q-gram approach needs to access the rid-list corresponding to several q-grams. Over the course of a long string such as an address string, this can be quite expensive. Since the trie-based Algorithm 5.2 for the Buffered strategy is the most efficient, we only report for this algorithm in the rest of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Per-Character Response Time</head><p>Recall that in order to look instantaneous to the user, the response time must be less than 100ms. In a client-server setting, this 100ms bound includes not only the autocompletion time, but other overheads such as the communication overheads. Thus, it is desirable to make the autocompletion cost itself minimal. In this section, we report the average per-character execution time of the Trie-based Algorithm 5.2 for the Buffered strategy. We find the per-character response times to be 0.39ms for the DBLP data set and 0.32ms for the Address data set even when the edit distance threshold is 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Online Vs Offline</head><p>We next compare the performance of our algorithm to offline edit distance matching algorithms. As discussed in Section 2.3, we expect the offline algorithms to perform better and our goal is to measure the difference in performance and contrast this difference with the case of exact matching. Accordingly, we also measure the performance of trie-based exact autocompletion by setting the edit distance threshold to 0. We use hashing as our method of performing offline exact matching.</p><p>Figure <ref type="figure">12</ref> plots the results. The figure on the left reports the results for the Address data and the one on the right, for the DBLP data. The X-axis shows the edit distance threshold and the Y-axis plots the execution time (in milli-seconds) for 1000 lookups on a log scale. For this experiment, in addition to the q-gram based offline matching algorithms, we also consider previously proposed offline triebased pattern matching algorithms <ref type="bibr" target="#b18">[18]</ref>. As noted above, we only report the best running times over all offline algorithms we consider.</p><p>For the Address data, as expected, the offline algorithms out-perform the online algorithm described in this paper. The performance gap is close to an order of magnitude. However, this gap is worse for exact matching where the online approach is more than two orders of magnitude more expensive.</p><p>For the DBLP data, the Trie algorithm is much more competitive with the offline algorithms. When compared to the accurate offline algorithms, for k = 1, the online approach is about twice as worse, whereas for k = 2, 3, the gaps drop to 25% and 12% respectively. Only the QGram Approx. technique performs substantially better for k = 3, but this comes with the tradeoff that 5% of the results can be missed. The main reason for this smaller gap in the DBLP data is that the strings are much shorter compared to addresses. For the q-gram based approaches, the set-similarity threshold for the underlying set-similarity match is much lower for the same value of k, leading to a larger execution time for all of the signature schemes. In contrast, the gap between exact offline matching and exact autocompletion remains at more than two orders of magnitude for the DBLP data.</p><p>We recall that our goal as discussed in Section 2.3 is that the online vs. offline performance gap be comparable to the case of exact matching. We can see from the above discussion that we meet this goal on the data sets we study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Overhead of Error Tolerance</head><p>We can use the results in Figure <ref type="figure">12</ref> to also study the overhead of error tolerance in autocompletion. As expected, the greater the magnitude of error we wish to tolerate, the  greater is the price we pay. Performing autocompletion with k = 1 is a factor of 2 times worse than exact autocompletion (k = 0), whereas the gap between k = 3 and k = 0 (exact autocompletion) is close to two orders of magnitude for both the data sets. This is not very surprising. In the offline world, there is an even worse price to be paid for error tolerance -observe that the gap between edit distance 3 and exact matching is close to four orders of magnitude. We next study the effect of data size by choosing subsets of the address data of size 100k, 500k and 1 Million records. Figure <ref type="figure" target="#fig_15">13</ref> shows the results. For each data set, we compute the running time for edit thresholds 1 to 3. The X-axis shows varies the edit distance threshold. For each value of the threshold, we report the lookup time for the different subsets of the address data. Overall, we see that the execution time increases linearly with the data size. This is consistent with the analysis captured in Lemma 3 and Lemma 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">Effect of Data Size</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RELATED WORK</head><p>Autocompletion is a widely used mechanism to find information quickly. It has been adopted in a variety of applications including program editors such as Visual Studio, command shells such as the Unix Shell, search engines such as Google, Live and Yahoo, and desktop search. More recently, it is also gaining popularity for mobile devices such as cell phones. These applications often work over a predefined dictionary of strings over which autocompletion is performed. As noted in Section 1, despite the availability of variants of error-tolerant autocompletion in a limited number of these products, little is known about their underlying algorithms.</p><p>There is also a vast body of work on predictive autocompletion <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b16">16]</ref> where the idea is to use information retrieval techniques, language models and learning to suggest potential completions. While error tolerance is also applicable in these approaches, our paper focuses on the case where autocompletion is performed on the basis of matches in a pre-specified table.</p><p>There has been recent work in the research community on autocompletion. Bast and Weber <ref type="bibr" target="#b2">[2]</ref> propose an autocompletion method where we have an underlying document corpus and the goal is to return word-level completions such that the resulting multi-word query has non-empty results. Nandi and Jagadish <ref type="bibr" target="#b16">[16]</ref> propose a phrase prediction algo-rithm as a part of the MUSIQ project <ref type="bibr" target="#b11">[11]</ref>, targeting scenarios such as email composition and introduce the concept of a significant phrase for this purpose. To the best of our knowledge, none of the above bodies of work on autocompletion focus on systematically studying error-tolerant autocompletion in a database lookup scenario.</p><p>A functionality that is closely related to autocompletion and is also widely available is autocorrection where at the end of a string typed in, the system suggests corrections by matching it against a dictionary. This functionality is present in text editors such as Microsoft Word and is also offered recently by search engines. The key difference from autocompletion is that autocorrection and spelling suggestions are offered at the end of the input string, presumably through an offline error-tolerant match against a pre-defined dictionary. In contrast, autocompletion is online.</p><p>Another body of work that is closely related to this paper is the prior work on computing edit distance matches of a (small) pattern string P in a (large) piece of text T <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b20">20]</ref>. The goal is to find all substrings of T that are within a small edit distance of P . These algorithms can be divided into two parts -algorithms where there is no preprocessing of the text T <ref type="bibr" target="#b17">[17]</ref>, and algorithms where we are allowed to create an index over T to match the pattern string faster <ref type="bibr" target="#b18">[18]</ref>. The body of work that closely relates to this paper clearly is the latter class of algorithms. Some of these algorithms proceed over suffix tries/trees which is similar to our technique, but their basic approach is not online in the sense required by autocompletion. That is, they do not consume the pattern string character by character. In contrast, our algorithms process the lookup string incrementally.</p><p>Viewed purely as an edit distance matching algorithm the running time of our algorithm is O(m • min((m + 1) k (σ + 1) k , N )) where m is the size of the pattern string, k is the edit distance threshold and N is the size of the text string. This is identical to the worst case analysis for the algorithms proposed in <ref type="bibr" target="#b18">[18]</ref>. There is recent work that improves on this worst case. Specifically, Maaí and Nowak <ref type="bibr" target="#b13">[13]</ref> recently proposed the first linear time edit distance matching algorithm. However, this algorithm is not practical since the size of their data structure can be unbounded in terms of the input table size in the worst case.</p><p>Finally, there is also the body of work on edit distance matching using q-grams <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b21">21]</ref>. These algorithms are also "offline" in the sense they do not consume the lookup string character by character. We incorporate these techniques in our paper for autocompletion (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>We considered the problem of performing autocompletion when a record is being looked up against a database table. By viewing autocompletion as an "online" lookup, we argued that just as "offline" lookup needs to be error-tolerant, so does autocompletion. We took a first step in this paper in designing an error-tolerant autocompletion based on edit distance as our similarity function. We proposed algorithms for autocompletion using both on q-gram based techniques and trie traversal techniques coupled with pre-computation for short strings. Our empirical study indicated both the utility of error-tolerant autocompletion and the fact that we can perform error-tolerant autocompletion with performance trade offs similar to the case of exact autocompletion.</p><p>Autocompletion is used in a wide variety of applications depending on the nature of which, other issues need to be addressed such as performing autocompletion in a client-server setting. This paper however focuses on the algorithmic aspects of error-tolerant autocompletion which are relevant regardless of the specific application. The issue of performing error-tolerant autocompletion for other similarity functions also needs to be addressed. We hope to tackle these questions in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Autocompletion Methods</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>. The figure shows examples of prior work covering exact autocompletion approaches. Note that only one similarity function (edit distance) is shown in the Figure for illustration. In general, the space of similarity functions is much larger.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: 1-Extension Distance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Q-gram approach sider the lookup string Shwarz. Under the baseline algorithm, we consider each string in the inverted list of 'S' for verification. Thus, we invoke the k-Extension Distance algorithm discussed in Section 3.3.2 for every prefix of the string Schwarzenegger.We improve upon this as follows. We modify the signature scheme to obtain a signature scheme Sig where Sig (r) = ∪ r ∈r Sig(r ). Since the strings in r have substantial overlap, they generate many common signatures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 Figure 6 :</head><label>16</label><figDesc>Figure 6: Illustrating Algorithm 5.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Valid Nodes (log scale) Vs. Lookup Lengths and Edit Distance Thresholds</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Lemma 3 .</head><label>3</label><figDesc>Algorithm 5.1 adapted for edit distance matching of a string of length m runs in time O(m • min((m + 1) k (σ + 1) k , |T |)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Memory Consumption (MB)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Key Strokes Saved Per Lookup String</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure</head><label></label><figDesc>Figure9reports the results of our study. We report the average number of key strokes saved per lookup string for various values of error threshold k. On the DBLP data set, we observe that in contrast with exact autocompletion (k = 0), 54.58% additional key strokes are saved when autocompletion is performed with threshold 2 for the DBLP data set. For the Address data set that consists of larger strings,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Full Vs Buffered (log scale): DBLP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 11 :Figure 12 :</head><label>1112</label><figDesc>Figure 11: Efficiency of Trie Vs NGram: (a)Address, (b)DBLP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Increasing Data Size: Address</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1) is captured in Steps 12-16. The influence of D(i, j) is captured in Steps 8-9. Note that we only consider marking Algorithm 5.1 Trie-Based Autocompletion Input: String s input incrementally with new character being appended at each step and edit threshold k. Output: At each step, all k-extensions Let valid denote the buffer storing current valid nodes Let new-valid denote the buffer storing the next set of valid nodes Let root denote the root of the trie 1. Add(valid, root, 0) 2. For i = 1 . . . k 3. For each node nd at distance i from root 4.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>2</head><label></label><figDesc>Algorithm for Buffered k-Extension Strategy</figDesc><table><row><cell cols="2">Input: String s 1 input incrementally with new</cell></row><row><cell></cell><cell>character being appended at each step, edit threshold k and</cell></row><row><cell></cell><cell>transition length len.</cell></row><row><cell cols="2">1. Set current threshold = 0</cell></row><row><cell cols="2">2. For each character c of the input</cell></row><row><cell cols="2">3. if (length of s 1 is len)</cell></row><row><cell></cell><cell>RefreshValidNodes(l)</cell></row><row><cell></cell><cell>Return leaf nodes as in Algorithm 5.1</cell></row><row><cell cols="2">4. else</cell></row><row><cell>5.</cell><cell>Run Algorithm 5.1 with current threshold</cell></row><row><cell cols="2">Procedure RefreshValidNodes(l)</cell></row><row><cell cols="2">1. Match s 1 against pre-computed index</cell></row><row><cell cols="2">2. Mark nodes corresponding to output as valid</cell></row><row><cell cols="2">3. Set current threshold to k</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient exact set similarity joins</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Type Less, Find More: Fast Autocompletion Search with a Succinct Index</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A primitive operator for similarity joins in data cleaning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaushik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The reactive keyboard: a predictive typing aid</title>
		<author>
			<persName><forename type="first">J</forename><surname>Darragh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="41" to="49" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="http://dblp.uni-trier.de/" />
		<title level="m">Dblp</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Similarity search in high dimensions via hashing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sentence completion</title>
		<author>
			<persName><forename type="first">K</forename><surname>Grabski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scheffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th International Conference on Research and Developement in Information Retrieval</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Approximate string joins in a database (almost) for free</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Approximate string matching using compressed suffix arrays</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Hon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Making database systems usable</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elkiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jayapandian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Record linkage: similarity measures and algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Text indexing with errors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Maaí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nowak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Discrete Algorithms</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="662" to="681" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Response time in man-computer conversational transactions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AFIPS Fall Joint Computer Conference</title>
		<meeting>the AFIPS Fall Joint Computer Conference</meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Assisted querying using instant-response interfaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD Conference</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective phrase prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A guided tour to approximate string matching</title>
		<author>
			<persName><forename type="first">G</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="88" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Indexing methods for approximate string matching</title>
		<author>
			<persName><forename type="first">G</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sutinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tarhio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="19" to="27" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Faster approximate string matching over compressed text</title>
		<author>
			<persName><forename type="first">G</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shinohara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Compression Conference</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="459" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Approximate string-matching over suffix trees</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Combinatorial Pattern Matching</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="228" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ed-Join: An Efficient Algorithm for Similarity Joins With Edit Distance Constraints</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
