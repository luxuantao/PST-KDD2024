<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks</title>
				<funder ref="#_bPwUASf">
					<orgName type="full">U.S. Department of Energy&apos;s Office of Energy Efficiency and Renewable Energy</orgName>
					<orgName type="abbreviated">EERE</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-08-11">11 Aug 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dingyi</forename><surname>Zhuang</surname></persName>
							<email>dingyi@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Shenhao</forename><surname>Wang</surname></persName>
							<email>shenhao@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Haris</forename><forename type="middle">N</forename><surname>Koutsopoulos</surname></persName>
							<email>h.koutsopoulos@northeastern.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jinhua</forename><surname>Zhao</surname></persName>
							<email>jinhua@mit.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Florida Gainesville</orgName>
								<address>
									<settlement>Florida</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Northeastern University Boston</orgName>
								<address>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<region>Massachusetts</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">KDD &apos;22</orgName>
								<address>
									<addrLine>August 14-18</addrLine>
									<postCode>2022</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<address>
									<addrLine>9 pages</addrLine>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-08-11">11 Aug 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539093</idno>
					<idno type="arXiv">arXiv:2208.05908v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Spatial-temporal Sparse Data</term>
					<term>Uncertainty Quantification</term>
					<term>Graph Neural Networks</term>
					<term>Travel Demand</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Origin-Destination (O-D) travel demand prediction is a fundamental challenge in transportation. Recently, spatial-temporal deep learning models demonstrate the tremendous potential to enhance prediction accuracy. However, few studies tackled the uncertainty and sparsity issues in fine-grained O-D matrices. This presents a serious problem, because a vast number of zeros deviate from the Gaussian assumption underlying the deterministic deep learning models. To address this issue, we design a Spatial-Temporal Zero-Inflated Negative Binomial Graph Neural Network (STZINB-GNN) to quantify the uncertainty of the sparse travel demand. It analyzes spatial and temporal correlations using diffusion and temporal convolution networks, which are then fused to parameterize the probabilistic distributions of travel demand. The STZINB-GNN is examined using two real-world datasets with various spatial and temporal resolutions. The results demonstrate the superiority of STZINB-GNN over benchmark models, especially under high spatial-temporal resolutions, because of its high accuracy, tight confidence intervals, and interpretable parameters. The sparsity parameter of the STZINB-GNN has physical interpretation for various transportation applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Computing methodologies ? Neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>It has attracted a lot of attention to predict the Origin-Destination (O-D) matrices of travel demand <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b39">40]</ref>. This task is challenging because the characteristics of the demand data vary with mobility services. For example, the O-D matrices for the subway stations are generally dense and probably satisfy the continuous Gaussian distribution, which implicitly underlies deterministic deep learning models. But for ride-hailing or bike-sharing services, the O-D zones could be much more granular, which lead to sparse and discrete entries in the O-D matrices. This sparsity issue becomes even more severe in the O-D matrices with high spatial-temporal resolution, because the initially dense O-D matrices could become much more diluted. As the mobility companies are increasingly adopting real-time interventions, the accurate prediction of the sparse and discrete O-D matrices at a high spatial-temporal resolution could significantly improve the quality of mobility services.</p><p>Although the prediction of dense and low-resolution O-D matrices has been extensively studied using deep learning (DL) models, few studies addressed the sparsity issue in the high-resolution travel demand data. The continuous data entries in the dense O-D matrices could follow Gaussian distributions <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref>. However, a large number of zero entries in a sparse O-D matrix evidently deviate from the Gaussian assumption. When the O-D matrix is sparse and dispersed with integer values, discrete distributions like the negative binomial distribution, would be more appropriate. Moreover, an enormous number of zeros could naturally emerge when the data set has a high spatial-temporal resolution. These zeros are important for transportation management, because they indicate areas with particularly low demand. Therefore, a successful prediction model should capture explicitly the zeros in the sparse matrix and quantify their uncertainty, thus guiding the service allocation and management decisions.</p><p>To address sparsity, we propose a Spatial-Temporal Zero-Inflated Negative Binomial Graph Neural Network (STZINB-GNN) to quantify uncertainty and enhance prediction performance. We utilize zero-inflated negative binomial (ZINB) distributions to capture the enormous number of zeros in sparse O-D matrices, and the negative binomial (NB) distribution for each non-zero entry. Different from the variational autoencoder models, we design the spatialtemporal embedding with an additional parameter ? to learn the likelihood of the inputs being zero. Our model utilizes the representation power of spatial-temporal graph neural networks to fit the parameters of probabilistic distributions. We compare a variety of probabilistic layers to assess the effectiveness of ? in capturing sparsity. Empirically, we demonstrate the superiority of our model in the data set with fine-grained spatial-temporal resolution. Our main contributions include:</p><p>(1) We propose the STZINB-GNN to quantify the spatial-temporal uncertainty of O-D travel demand using a parameter ? to learn data sparsity (2) The parameters of the probabilistic GNNs successfully quantify the sparse and discrete uncertainty particularly in highresolution data sets (3) We demonstrate that the STZINB-GNN outperforms other models by using two real-world travel demand datasets with various spatial-temporal resolutions</p><p>The paper is organized as follows. Section 2 summarizes recent studies related to DL models for travel demand prediction, sparse data modeling, and uncertainty quantification. Section 3 defines the research question and develops the model. Section 4 introduces the dataset used for the case study, the evaluation metrics, and the experimental results. Section 5 concludes the paper and discuss future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LITERATURE REVIEW 2.1 Travel demand prediction with spatial-temporal deep learning</head><p>Travel demand prediction is a fundamental task in transportation applications. Based on the spatial division of the area of interest into zones, travel demand prediction is usually associated with the prediction of flow from the origin zone to the destination zone pairs, in the form of O-D matrices <ref type="bibr" target="#b11">[12]</ref>. The main challenges for O-D matrix prediction relate to time series prediction and spatial correlation detection. Recently these challenges have been addressed using spatial-temporal deep learning techniques. Convolution Neural Network (CNN) based techniques are applied to extract the spatial patterns because O-D matrices are usually modelled on urban grids <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref>. Noticeably, the CNN and its variants discover spatial patterns in Euclidean space <ref type="bibr" target="#b38">[39]</ref>. The O-D matrices naturally possess the graph structure where origin or destination regions are usually regarded as the nodes and the O-D pairs are the edges.</p><p>Recent work also applied graph neural networks (GNNs) on travel demand estimation to capture non-Euclidean correlations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>On the other hand, Ke et al. <ref type="bibr" target="#b11">[12]</ref> regarded O-D pairs, instead of origin and destination regions, as nodes and applied multi-graph convolutional network to predict ride-sourcing demand. Other studies used deep learning to predict the individual travel behavior by focusing on interpretation and architectural design <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34]</ref>. The power of deep learning arises from its representation learning capacity and its new statistical foundation <ref type="bibr" target="#b32">[33]</ref>. However, both CNN and GNN-based approaches treat the O-D matrix entries as continuous and only focus on coarse temporal resolutions, like 60 minutes. Very few studies discussed the challenge to analyze the sparse O-D matrices with high spatial-temporal resolution.</p><p>Sparse travel demand data are different from the missing data. Zeros in sparse data mean no trips, but the sensors work properly. Missing data, on the other hand, are unobservable, potentially due to sensor malfunction. Wang et al. <ref type="bibr" target="#b34">[35]</ref> applied the spatial-temporal Hankelization and tensor factorization to estimate traffic states using only 17% of the matrix entries. However, tensor factorization is a transductive method, which needs recalculation when new data come in. It is not suitable for short-term prediction. To differentiate our contributions from previous work, we will emphasize our model's spatial-temporal interpretability and uncertainty quantification in travel demand prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Uncertainty of sparse travel demand prediction</head><p>Besides the average value, it is widely acknowledged that models should also predict uncertainty <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b43">44]</ref>. The deterministic models that dominate the majority of the research implicitly assume homoskedasticity (i.e. common variance), which significantly simplifies the variance structure <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref>. However, it is also critical to capture uncertainty of sparse travel demand using deep learning. Rodrigues and Pereira <ref type="bibr" target="#b26">[27]</ref> explored uncertainty quantification by training a CNN-LSTM model to fit both the mean and the quantiles. They showed the power of combining the spatial and temporal embedding to predict various distributions, but they did not investigate the sparse scenario. In non-DL models, Jang <ref type="bibr" target="#b7">[8]</ref> showed that travel demand follows a zero-inflated negative binomial distribution. Rojas et al. <ref type="bibr" target="#b27">[28]</ref> also noted that using a zero-inflation model is promising for modeling intermittent travel demand. However, recent demand prediction papers sidestepped this challenge by choosing a low resolution, such as 60 minutes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. It is challenging to consider the higher resolution, such as 5min, because a deterministic DL model is no longer appropriate. Hence, it could be a viable alternative to combine the zero-inflated distribution and the deterministic DL to analyze the sparse O-D matrices.</p><p>It is also critical to design metrics to evaluate the quality of uncertainty quantification. Khosravi et al. <ref type="bibr" target="#b13">[14]</ref> proposed mean prediction interval width and prediction interval coverage probability to quantify data uncertainty. Sankararaman and Mahadevan <ref type="bibr" target="#b28">[29]</ref> introduced a likelihood-based metric, which is also an effective indicator to measure the alignment of the predicted and ground truth data distributions. Based on the existing research gap, our paper seek to design a model that formulates the sparse travel demand prediction problem with proper spatial-temporal pattern recognition and tight prediction interval bounds. Then ? ? ? N |? |?? denote the demand for all O-D pairs in the ? ?? time window, with ? ?? as its entry. Our goal is to leverage historical records ? 1:? as the data inputs to predict the distribution of ? ? :? +? (i.e. the demand for the next ? time windows), thus analyzing the expectation and confidence intervals of the future demand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Zero-Inflated Negative Binomial (ZINB) Distribution</head><p>We assume that the inputs follow the ZINB distribution <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b27">28]</ref>. A random variable that follows NB distribution has a probability mass function ? ? ? as:</p><formula xml:id="formula_0">? ? ? (? ? ; ?, ?) ? ?? (? = ? ? ) = ? ? + ? -1 ? -1 (1 -?) ? ? ? ? . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where ? and ? are the shape parameters that determine the number of successes and the probability of a single failure respectively. However, the real-world data often have many observations with zeros and overdispersion <ref type="bibr" target="#b17">[18]</ref>. The exploded number of zeros exacerbates the parameter learning of the NB distribution. A new parameter ? is therefore introduced to learn the inflation of zeros, leading to the ZINB distribution. Formally, its probability mass function can be described as:</p><formula xml:id="formula_2">? ? ? ? ? (? ? ; ?, ?, ?) = ? + (1 -?)? ? ? (0; ?, ?) if ? ? = 0 (1 -?)? ? ? (? ? ; ?, ?) if ? ? &gt; 0 .<label>(2)</label></formula><p>Two steps are needed to generate the distributions of the data: they are either zeros with probability ? or non zeros with probability 1 -? following the NB distribution. The parameters ?, ?, ? in the probability distributions are parameterized by spatial-temporal GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">STZINB-GNN</head><p>We introduce STZINB-GNN, a generalizable deep learning architecture, to capture spatial-temporal correlations ? = M (? </p><formula xml:id="formula_3">? ? ? ? ? (? ? +1:? +? |? ? +1:? +? , ? ? +1:? +? , ? ? +1:? +? ) = ? ? ? ? ? (? ? +1:? +? |M (? 1:? , ?)) = ? ? ? ? ? (? ? +1:? +? |? ).<label>(3)</label></formula><p>The overall architecture of the STZINB-GNN is shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>We convert a batch of size ? of input O-D-T tensor at ? ?? time window (4) Notice that the fused ? in Figure <ref type="figure" target="#fig_0">1</ref> can be interpreted as the parameter set of the future demand distribution. This procedure is similar to the variational autoencoders (VAEs) concept, where we learn the latent shape variables that formulate the distributions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>. The theory of VAEs is used to introduce deep learning techniques into the statistical domain of variational inference, which provides more powerful representation of latent variables. Our encoding component uses the spatial-temporal embedding architecture with an additional sparsity parameter and the decoding part is related to the probabilistic estimation of future demand.</p><formula xml:id="formula_4">? ?:?+? ? Z |? |??? into a tensor X ? ? Z |?</formula><p>To address the problem that zeros will give infinite values for the KL-divergence based variational lower bound, we directly use the negative likelihood as our loss function to better fit the distribution into the data. Let ? be the ground-truth values corresponding to one of the predicted matrix entries with parameters ?, ?, ? from ? . The log likelihood of ZINB is composed of the ? = 0 and ? &gt; 0 parts, and can be approximated as <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>:</p><formula xml:id="formula_5">?? ? = ? ? ? ? ? ? ? log ? + log (1 -?)? ? when ? = 0 log 1 -? + log ?(? + ?) -log ?(? + 1) -log ?(?) + ? log ? + ? log(1 -?) when ? &gt; 0 ,<label>(5)</label></formula><p>where ?, ?, ? are also selected and calculated according to the index of ? = 0 or ? &gt; 0, and ? is the Gamma function. The final negative log likelihood loss function is given by:</p><formula xml:id="formula_6">? ?? ?? ? ? ? ? = -?? ?=0 -?? ?&gt;0 .<label>(6)</label></formula><p>Note that our model can also be generalized to other distributions by modifying the probability layer into other distributions and using ? to represent the related shape parameter sets. For example, if we use Gaussian distribution as our model, we can parameterize the probability layer using the spatial and temporal embedding of the mean and variance, thus quantifying the data uncertainty that follows the Gaussian distribution. Using the flexibility of the probability layer, we design a variety of benchmark models to compare to the ZINB model. Our scripts can be found in Github 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Adjacency Matrix for O-D Pairs</head><p>This study uses O-D pairs as vertices, different from the previous GNN approaches that use regions as vertices <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b40">41]</ref>. Therefore, we need to model spatial correlations of O-D pairs and construct the adjacency matrix in a different way. Intuitively, the O-D pairs with similar origins or destinations are also close in a graph representation, because passengers are likely to transfer between adjoining O-D pairs rather than remote ones. Inspired by the work of Ke et al. <ref type="bibr" target="#b11">[12]</ref>, we formulate our adjacency matrix as:</p><formula xml:id="formula_7">? ? ?,? = ????????? (??? ? ? , ??? ? ? , ??? ? ? , ??? ? ? ) -1 , ??, ? ? ? ? ? ?,? = ????????? (??? ? ? , ??? ? ? , ??? ? ? , ??? ? ? ) -1 , ??, ? ? ? ? ?,? = ?? 1 2 ((? ? ?,? ) 2 + (? ? ?,? ) 2 ),<label>(7)</label></formula><p>1 https://github.com/ZhuangDingyi/STZINB where ??? ? ? , ??? ? ? , ??? ? ? , ??? ? ? are the longitudes and latitudes of the origins of O-D pair ?, ?, and ??? ? ? , ??? ? ? , ??? ? ? , ??? ? ? are for the destinations similarly. The function ????????? (?) takes the longitudes and latitudes of two geographical points and calculate their distance on Earth. The basic idea is to leverage the O-D pairs' geographical adjacency by averaging the origin and destination similarity. It is clear that the order of ?, ? does not affect the output of the ????????? function, which means ? is symmetric. The final adjacency matrix ? is the quadratic mean of ? ? and ? ? , where the distances between origins or destinations have the same influence in the adjacency matrix. Future studies can assign different weights to the origins or destinations in constructing the adjacency matrix, or even combine with demographic graphs to enrich the information of ?. Since this paper focuses on uncertainty quantification and interpretability of the model, we use a simple construction of ? to prevent any distraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Diffusion Graph Convolution Network</head><p>In order to capture the stochastic nature of flow dynamics among O-D pairs, we model the spatial correlations as a diffusion process <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b19">20]</ref>. Introducing the diffusion process facilitates the learning of the spatial dependency from one O-D pair to another. The process is characterized by a random walk on the given graph with a probability ? ? [0, 1] and a forward transition matrix W? = ?/??????(?) <ref type="bibr" target="#b36">[37]</ref>. After sufficiently large time steps, the Markovian property of the diffusion process guarantees it to converge to a stationary distribution P ? R |? |?|? | . Each row of P stands for the probability of diffusion from that node. The stationary distribution can be calculated in closed form <ref type="bibr" target="#b30">[31]</ref>:</p><formula xml:id="formula_8">P = ? ?? ?=0 ? (1 -?) ? (? -1 ? ?) ? , (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>where ? is the diffusion step, which is usually set to finite number ?. Variable ? is only reused for demonstration of the diffusion process. We can similarly define the backward diffusion process with backward transition matrix W? = ? ? /??????(? ? ). Since our adjacency matrix ? is symmetric, W? = W? . The forward and backward diffusion processes model the dynamics of passengers shifting from one O-D pair to another, like the shifting from schoolhome trip to home-market trip. The building block of DGCN layer can be written as <ref type="bibr" target="#b36">[37]</ref>:</p><formula xml:id="formula_10">? ?+1 = ? ( ? ?? ?=1 ? ? ( W? )? ? ? ? ? ,? + ? ? ( W? )? ? ? ? ?,? ),<label>(9)</label></formula><p>where ? ? represents the ? ?? hidden layer; the Chebyshev polynomial ? ? (? ) = 2?? ?-1 (? ) -? ?-2 (? ) is used to approximate the convolution operation in DGCN, with boundary conditions ? 0 (? ) = ? and ? 1 (? ) = ? (note that the Chebyshev polynomial is used to approximate the diffusion P instead of using the closed form); learned parameters of the ? ?? layer ? ? ? ,? and ? ? ?,? are added to control how each node transforms the received information; ? is the activation function (e.g. ReLU, Linear). In our model we stack 3 DGCN layers to better capture the O-D dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Temporal Convolutional Network</head><p>As Wu et al. <ref type="bibr" target="#b37">[38]</ref> point out, the advantages of TCNs compared with recurrent neural networks (RNNs) include: 1) TCNs can use the sequences with varying length as inputs, which is more adaptive to different time resolutions and scales; 2) TCNs have a lightweight architecture and fast training <ref type="bibr" target="#b2">[3]</ref>. The general idea of TCNs is to apply a shared gated 1D convolution with width ? ? in the ? ?? layer in order to pass the information from ? ? neighbors at the current time point. Each TCN layer ? ? receives the signals from the previous layer ? ?-1 and is updated using <ref type="bibr" target="#b18">[19]</ref>:</p><formula xml:id="formula_11">? ? = ? (? ? * ? ?-1 + ?),<label>(10)</label></formula><p>where ? ? is the convolution filter for the corresponding layer, * is the shared convolution operation, and ? stands for the bias. If previous hidden layer follows</p><formula xml:id="formula_12">? ?-1 ? R ?? |? |?? ? -1 , then the convolution filter is ? ? ? R ? ? ?? ? -1 so that ? ? ? R ?? |? |?? ? .</formula><p>If there is no padding in each TCN layer, it is clear that ? ? &lt; ? ?-1 . TCN is also a type of sequence-to-sequence model, which can directly output prediction for future target windows in a row. Furthermore, the TCN receptive field is flexible, which can be controlled by the number and kernels of ? ? . It is useful in our following discussion about scaling our model with different temporal resolutions. We also stack 3 TCN layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NUMERICAL EXPERIMENTS 4.1 Data</head><p>In this session, we assess the model performance using two realworld datasets from Chicago Data Portal (CDP) 2 and Smart Location Database (SLD) 3 . The CDP dataset contains the trip records of Transportation Network Providers (ride-sharing companies) in the Chicago area. The city of Chicago is divided into 77 zones and the trip requests with pick-up and drop-off zone are recorded every 15min. We use 4-month observations from September 1st, 2019 to December 30th, 2019. The dataset is divided into various spatial resolutions to facilitate the discussion of model performance. We randomly select 10 ? 10 O-D pairs with the same time period as spatially sparse data sample; The SLD dataset is also used in the work of Ke et al. <ref type="bibr" target="#b11">[12]</ref>. Specifically, we select the For-Hire Vehicle (FHV) trip records in the Manhattan area (divided into 67 zones by administrative zip codes) from January 2018 to April 2018. This SLD data have similar features as the CDP dataset, including timestamps, and pick-up and drop-off zone IDs. As the dataset includes the timestamps of the individual trip information, we vary the temporal resolution (5min, 15min, and 60min intervals) to test our model performance. In addition to the full O-D matrix (67 ? 67), we also sample 10 ? 10 small O-D pair samples to align with the CDP dataset. We use 60% of the data for training, 10% for validation, and the last 30% for testing. Table <ref type="table" target="#tab_2">1</ref> summarizes the data scenarios used in the analysis. The zero rate increases from 50% to 88% as the temporal resolution for SLD dataset increases from 60 minutes to 5 minutes. As shown in Figure <ref type="figure" target="#fig_2">2</ref>   larger than 8, but at 5min resolution, the lowest value is 3 trips within the 5-minute interval. Such sparse (and small value) O-D matrix is a challenge for most of the deterministic deep learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>We use the metrics for both the point estimate statistics and distributional characteristics to evaluate and compare the performance of the various models. The prediction accuracy of the expected median value (i.e. point estimate accuracy) is evaluated using the Mean Absolute Error (MAE):</p><formula xml:id="formula_13">MAE = 1 ? |? | ? |? | ?? ?=1 |? ? -x? | ,<label>(11)</label></formula><p>where x? and ? ? are the predicted and ground-truth values of ? ?? data point respectively. To evaluate the estimated uncertainty, we use Mean Prediction Interval Width (MPIW) on the 10%-90% confidence interval <ref type="bibr" target="#b13">[14]</ref>:</p><formula xml:id="formula_14">MPIW = 1 ? |? | ? |? | ?? ?=1 (? ? -? ? ). (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where ? ? and ? ? correspond to the lower and upper bound of the confidence interval for observation ?. The definition of MPIW can be extended to other quantiles of the data. Tighter (smaller) prediction intervals are more desirable. Apart from MPIW, we also use the Kullback-Leibler Divergence (KL-Divergence) to assess how close the model output distribution is to the test set distribution <ref type="bibr" target="#b16">[17]</ref>. We define the KL-Divergence as:   Since many ? ? and x? values are likely to be zeros, a small perturbation ? = 10 -5 is used to avoid numerical issue because of division by 0. Since the KL-Divergence measures the difference between two distributions, smaller values are desirable.</p><formula xml:id="formula_16">KL-Divergence = 1 ? |? | ? |? | ?? ?=1 ( x? log x? + ? ? ? + ? ),<label>(13)</label></formula><p>To compare the model performance on the discrete O-D matrix entries, we use the true-zero rate and F1-score measurements. The true-zero rate quantifies how well the model replicates the sparsity in the ground-truth data. The F1-score, on the other hand, measures the accuracy of discrete predictions. Even though the F1-score is designed for classification models, we can still consider the discrete values as multiple labels and define the precision and recall accordingly <ref type="bibr" target="#b24">[25]</ref>. Larger true-zero rate and F1-score values indicate better model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Comparison</head><p>In order to explore the advantages of the STZINB-GNN, we compare the STZINB-GNN results against three other models: (1) Historical Average (HA) serves as the statistic baseline. It is calculated by averaging the demand in the same daily time intervals (e.g. 8:00AM-8:15AM) from the historical data to predict the onestep ahead future demand. (2) Spatial-Temporal Graph Convolutional Networks (STGCN) <ref type="foot" target="#foot_0">4</ref> is the state-of-the-art deep learning model for traffic prediction <ref type="bibr" target="#b41">[42]</ref>. STGCN also uses graph convolution for spatial embedding and temporal convolution for temporal embedding. However, it fails to quantify the demand uncertainty and only produces point estimates; (3) Models with probabilistic assumptions in the spatial-temporal embedded probabilistic layer: negative binomial (STNB-GNN), Gaussian (STG-GNN), and truncated normal (STTN-GNN), as shown in Figure <ref type="figure" target="#fig_0">1</ref>. These three distributions have two parameters, less than the three parameters of STZINB-GNN. The other components and parameters are the same across these models.</p><p>STZINB-GNN outperforms other models when the O-D matrix resolution is high but performs worse when the resolution becomes coarser. Table <ref type="table" target="#tab_3">2</ref> highlights the fields in bold to indicate the best performance for each data set. For fair comparison, the outputs from the continuous-output models, including STG-GNN, STTN-GNN, HA, and STGCN, were rounded to the closest integer to compare to the STNB-GNN and STZINB-GNN. As shown in Table 2, when the spatial and temporal resolutions are low, like the CDP_SAMP10 and SLD_SAMP10 cases, STZINB-GNN performs similarly to STNB-GNN. In the sparsest scenario, SLD_5min (with 88% zeros), STG-GNN, STTN-GNN, and STGCN fail to effectively capture the skewed data distribution, leading to low true-zero rates and F1-scores. The STZINB-GNN, on the other hand, successfully learns the sparsity of the data. Its prediction has a very small MPIW, nearly 10 times smaller than the other models. When the temporal resolution decreases, the STNB-GNN, STTN-GNN, and STGCN start to outperform STZINB-GNN. In the SLD_60min case, STNB-GNN fits the data better than the STGCN. The STZINB-GNN, on the other hand, only predicts the true-zero entries better. No single model dominates others under all resolution levels <ref type="bibr" target="#b35">[36]</ref>.</p><p>The negative binomial distribution in the probability layer can effectively capture the discrete values of the travel demand. Figure <ref type="figure" target="#fig_4">3</ref> illustrates the predicted and ground-truth average travel demand in the SLD (New York) data for two consecutive days, with Figure <ref type="figure" target="#fig_4">3</ref>(a) for the SLD_15min and Figure <ref type="figure" target="#fig_4">3</ref>(b) for the SLD_60min. With finer resolutions, the STNB-GNN and STZINB-GNN models are more likely to accurately predict the average travel demand. When the resolution decreases, like in the 60min case, all the deep learning models deliver similar performance. This 60-min resolution is commonly used in the majority of the deep learning studies, but our results demonstrate the importance of discrete probabilistic assumptions when the temporal unit is shorter than 60 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Uncertainty Quantification</head><p>The STZINB-GNN provides superior performance in quantifying uncertainty, because it uses much narrower MPIW for a fixed probability coverage, particularly when the temporal resolution is high. Figure <ref type="figure" target="#fig_5">4</ref> visualizes the scatter plots for the MPIW and the groundtruth travel demand of the 4489 O-D pairs at three temporal resolutions. Figure <ref type="figure" target="#fig_5">4</ref>(a) demonstrates that the STZINB-GNN leads to significantly smaller MPIW than the other models in the granular 5min resolution case. This is because the average travel demand for each O-D pair is less than two in the SLD_5min case and most of them are zeros. The introduction of the sparsity parameter ? in STZINB-GNN effectively captures the zeros. The STG-GNN and STTN-GNN are not able to capture the skewness of the data distribution, leading to large MPIWs. However, when the temporal resolution decreases, the zero-inflation with the sparsity parameter ? becomes less important. STZINB-GNN has smaller MPIW only when the average travel demand is small. The STG-GNN and STTN-GNN outperform STZINB-GNN when the average demand is large. However, their output prediction distributions are not stable, because the same travel demand value corresponds to different MPIW with a large variance. The bottom row of Figure <ref type="figure" target="#fig_5">4</ref> compares the expectation and MPIW between STZINB-GNN and STNB-GNN for a specific O-D pair that has the largest demand flow in the selected time range. In the SLD_5min and SLD_15min cases, the STZINB-GNN provides more compact confidence intervals than the STNB-GNN, even when its point prediction is less accurate. The results are consistent with the results in Table <ref type="table" target="#tab_3">2</ref> and the MPIW comparison in the top row of Figure <ref type="figure" target="#fig_5">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Interpretation of the Sparsity Parameter ?</head><p>The sparsity parameter ? in the ZINB distribution measures how likely a zone has zero demand. Note that each of our predicted O-D pair has the parameter ?, which can capture the inflow and outflow sparsity level of a zone. Since O-D relationship is hard to illustrate in the map, we focus on a specific zone and project the O-D activities when the zone is selected as the origin or destination. Figure <ref type="figure" target="#fig_7">5</ref> shows the O-D activity (i.e. the parameter ?) heatmap of Time Square, during the morning and evening peaks of April 25, 2018. It can be found that spatial locality exists, where communities are more likely to commute to their neighbors. Moreover, the temporal patterns also vary. As shown in Figure <ref type="figure" target="#fig_7">5</ref>, many visitors explore the neighboring regions in the evening but are very inactive during the morning peak. Therefore, the sparsity parameter ? renders the STZINB-GNN highly interpretable. It is very important in the transportation decision-making or the operation manager to use the sparsity parameter ? to assign mobility service. Our framework has the potential extended to other prediction tasks that have many zeros and are sensitive to events, like incident precaution or paratransit service for the disabled people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose a generalizable spatial-temporal GNN framework to predict the probabilistic distribution of sparse travel demand and quantify its uncertainty. We introduce the zero-inflated negative binomial distribution with a sparsity parameter ?. We use spatial diffusion graph neural networks to capture spatial correlation and temporal convolutional networks to capture temporal dependency. The STZINB-GNN framework embeds the spatial and temporal representation of the distribution parameters respectively and fuses them to obtain the distribution for each spatial-temporal data point. The STZINB-GNN is evaluated using two real-world datasets with different spatial and temporal resolutions. We find that the STZINB-GNN outperforms the baseline models when the data are represented in high resolutions but performs worse when the resolution becomes coarser. This is also reflected in the prediction interval, where the STZINB-GNN has tight confidence intervals. Since the parameter ? has physical interpretation, our model could help transportation decision makers to efficiently assign mobility services to zero or non-zero demand areas. This framework has the potential to be extended to other prediction tasks that use  highly sparse data points, such as anomaly detection and accident prediction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Framework of STZINB-GNN model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, the distribution of O-D flows is quite skewed because most of the O-D flows are concentrated around small values. The O-D flows at a 60min resolution have several observations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of travel demand in the SLD dataset per 5, 15, and 60min intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Prediction results in the SLD_15min and SLD_60min scenarios. Results are averaged over the spatial dimension (i.e. all O-D pairs)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Model prediction uncertainty at various resolutions (SLD_5min to SLD_60min). The top row shows the MPIW needed to predict the demand of each O-D pair at different resolutions. The bottom row represents the prediction with uncertainty for a specific O-D pair, from Midtown Center to Union Square, in April 25 and 26, 2018. This O-D pair is selected because it has the largest trip flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Morning and evening peaks outflow from and inflow to Time Square. We project the O-D pairs into the map according to Time Square as the origin or the destination zone. Red zones stand for small ? values, meaning high possibility to have trips generated there and green regions otherwise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>|???? as the model input. We use Diffusion Graph Convolution Networks (DGCNs) to capture the spatial adjacency of O-D pairs, and use Temporal Convolutional Networks (TCNs) for temporal correlation. The outputs of the DGCNs and TCNs, including the spatial embedding ? ? , ? ? , ? ? and temporal embedding ? ? , ? ? , ? ? , are used to parameterize the ZINB distribution. These spatial and temporal embeddings contain the independent estimation of the ZINB parameters of their spatial and temporal locality. We then fuse the ? ? , ? ? , ? ? and ? ? , ? ? , ? ? into ? using the Hadamard product, which can be replaced by other non-linear operations like a fully-connected layer. By fusing the spatial and temporal embeddings of the distribution parameters, we obtain the final ZINB parameter set ? that fulfills ? ? ? ? ? (? ? +1:? +? |? ? +1:? +? , ? ? +1:? +? , ? ? +1:? +? ) = ? ? ? ? ? (? ? +1:? +? |? ).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Data division summary.</figDesc><table><row><cell cols="2">Name</cell><cell></cell><cell cols="5">Resolution # of O-D pairs</cell><cell></cell><cell cols="2">Data size</cell><cell>Zero rate</cell></row><row><cell cols="3">CDP_SAMP10</cell><cell cols="2">15min</cell><cell></cell><cell>10 ? 10</cell><cell></cell><cell></cell><cell cols="2">(100, 11521)</cell><cell>81%</cell></row><row><cell cols="3">SLD_SAMP10</cell><cell cols="2">15min</cell><cell></cell><cell>10 ? 10</cell><cell></cell><cell></cell><cell cols="2">(100, 11520)</cell><cell>54%</cell></row><row><cell cols="2">SLD_5min</cell><cell></cell><cell cols="2">5min</cell><cell></cell><cell>67 ? 67</cell><cell></cell><cell cols="3">(4489, 34560)</cell><cell>88%</cell></row><row><cell cols="2">SLD_15min</cell><cell></cell><cell cols="2">15min</cell><cell></cell><cell>67 ? 67</cell><cell></cell><cell cols="3">(4489, 11520)</cell><cell>70%</cell></row><row><cell cols="2">SLD_60min</cell><cell></cell><cell cols="2">60min</cell><cell></cell><cell>67 ? 67</cell><cell></cell><cell></cell><cell cols="2">(4489, 2880)</cell><cell>50%</cell></row><row><cell></cell><cell>80%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">SLD_60min</cell></row><row><cell>Percentage</cell><cell>40% 60%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">SLD_15min SLD_5min</cell></row><row><cell></cell><cell>20%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>&gt;=9</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">O-D flows (# of trips/time interval)</cell><cell></cell></row></table><note><p>2 https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p 3 https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Model comparison under different metrics. ? /? values correspond to the mean/median values of the distribution.</figDesc><table><row><cell>Data scenario</cell><cell>Metrics</cell><cell cols="2">STZINB-GNN STNB-GNN</cell><cell>STG-GNN</cell><cell>STTN-GNN</cell><cell>HA</cell><cell>STGCN</cell></row><row><cell></cell><cell>MAE</cell><cell>0.368/0.366</cell><cell>0.382/0.379</cell><cell>0.409/0.409</cell><cell>0.432/0.606</cell><cell>0.522</cell><cell>0.395</cell></row><row><cell></cell><cell>MPIW</cell><cell>1.018</cell><cell>1.020</cell><cell>2.407</cell><cell>2.089</cell><cell>/</cell><cell>/</cell></row><row><cell>CDP_SAMP10</cell><cell>KL-Divergence</cell><cell>0.291/0.424</cell><cell>0.342/0.478</cell><cell>0.435/0.435</cell><cell>1.058/0.928</cell><cell>1.377</cell><cell>0.897</cell></row><row><cell></cell><cell>True-zero rate</cell><cell>0.796/0.788</cell><cell>0.796/0.788</cell><cell>0.790/0.790</cell><cell>0.758/0.764</cell><cell>0.759</cell><cell>0.800</cell></row><row><cell></cell><cell>F1-Score</cell><cell>0.848/0.846</cell><cell>0.848/0.841</cell><cell>0.818/0.818</cell><cell>0.842/0.846</cell><cell>0.809</cell><cell>0.840</cell></row><row><cell></cell><cell>MAE</cell><cell>0.663/0.666</cell><cell>0.627/0.616</cell><cell>0.630/0.630</cell><cell>0.695/0.665</cell><cell>0.697</cell><cell>0.630</cell></row><row><cell></cell><cell>MPIW</cell><cell>1.310</cell><cell>3.628</cell><cell>2.604</cell><cell>1.931</cell><cell>/</cell><cell>/</cell></row><row><cell>SLD_SAMP10</cell><cell>KL-Divergence</cell><cell>0.518/0.507</cell><cell>0.980/1.662</cell><cell>1.022/1.022</cell><cell>3.578/3.052</cell><cell>0.978</cell><cell>0.768</cell></row><row><cell></cell><cell>True-zero rate</cell><cell>0.499/0.502</cell><cell>0.465/0.418</cell><cell>0.461/0.461</cell><cell>0.308/0.336</cell><cell>0.364</cell><cell>0.478</cell></row><row><cell></cell><cell>F1-Score</cell><cell>0.567/0.566</cell><cell>0.556/0.552</cell><cell>0.555/0.555</cell><cell>0.477/0.500</cell><cell>0.456</cell><cell>0.563</cell></row><row><cell></cell><cell>MAE</cell><cell>0.149/0.150</cell><cell>0.147/0.144</cell><cell>0.155/0.155</cell><cell>0.155/0.155</cell><cell>0.149</cell><cell>0.159</cell></row><row><cell></cell><cell>MPIW</cell><cell>0.094</cell><cell>1.249</cell><cell>0.922</cell><cell>0.741</cell><cell>/</cell><cell>/</cell></row><row><cell>SLD_5min</cell><cell>KL-Divergence</cell><cell>0.015/0.014</cell><cell>0.042/0.145</cell><cell>0.001/0.001</cell><cell>0.001/0.001</cell><cell>0.060</cell><cell>0.056</cell></row><row><cell></cell><cell>True-zero rate</cell><cell>0.879/0.879</cell><cell>0.875/0.866</cell><cell>0.877/0.877</cell><cell>0.877/0.877</cell><cell>0.874</cell><cell>0.874</cell></row><row><cell></cell><cell>F1-Score</cell><cell>0.882/0.882</cell><cell>0.880/0.878</cell><cell>0.879/0.879</cell><cell>0.879/0.879</cell><cell>0.876</cell><cell>0.879</cell></row><row><cell></cell><cell>MAE</cell><cell>0.370/0.372</cell><cell>0.351/0.342</cell><cell>0.356/0.356</cell><cell>0.365/0.356</cell><cell>0.418</cell><cell>0.373</cell></row><row><cell></cell><cell>MPIW</cell><cell>0.603</cell><cell>2.283</cell><cell>1.353</cell><cell>1.215</cell><cell>/</cell><cell>/</cell></row><row><cell>SLD_15min</cell><cell>KL-Divergence</cell><cell>0.167/0.156</cell><cell>0.357/0.704</cell><cell>0.353/0.353</cell><cell>1.445/1.211</cell><cell>0.445</cell><cell>0.395</cell></row><row><cell></cell><cell>True-zero rate</cell><cell>0.725/0.727</cell><cell>0.710/0.684</cell><cell>0.709/0.709</cell><cell>0.632/0.648</cell><cell>0.703</cell><cell>0.708</cell></row><row><cell></cell><cell>F1-Score</cell><cell>0.751/0.750</cell><cell>0.746/0.745</cell><cell>0.750/0.750</cell><cell>0.716/0.726</cell><cell>0.744</cell><cell>0.750</cell></row><row><cell></cell><cell>MAE</cell><cell>1.040/1.067</cell><cell>0.958/0.947</cell><cell>1.199/1.199</cell><cell>1.275/1.254</cell><cell>1.014</cell><cell>0.997</cell></row><row><cell></cell><cell>MPIW</cell><cell>3.277</cell><cell>5.753</cell><cell>2.282</cell><cell>1.592</cell><cell>/</cell><cell>/</cell></row><row><cell>SLD_60min</cell><cell>KL-Divergence</cell><cell>0.982/1.270</cell><cell>0.926/0.963</cell><cell>2.176/2.176</cell><cell>4.120/3.734</cell><cell>2.421</cell><cell>1.114</cell></row><row><cell></cell><cell>True-zero rate</cell><cell>0.458/0.476</cell><cell>0.443/0.425</cell><cell>0.390/0.390</cell><cell>0.288/0.308</cell><cell>0.447</cell><cell>0.438</cell></row><row><cell></cell><cell>F1-Score</cell><cell>0.536/0.537</cell><cell>0.538/0.534</cell><cell>0.479/0.479</cell><cell>0.407/0.423</cell><cell>0.490</cell><cell>0.538</cell></row><row><cell>0:00</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Apr</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>https://github.com/FelixOpolka/STGCN-PyTorch</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This material is based upon work supported by the <rs type="funder">U.S. Department of Energy's Office of Energy Efficiency and Renewable Energy (EERE)</rs> under the <rs type="grantName">Vehicle Technology Program Award Number</rs> <rs type="grantNumber">DE-EE0009211</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bPwUASf">
					<idno type="grant-number">DE-EE0009211</idno>
					<orgName type="grant-name">Vehicle Technology Program Award Number</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Diffusion-convolutional neural networks</title>
		<author>
			<persName><forename type="first">James</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Don</forename><surname>Towsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1993">2016. 1993-2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using an ARIMA-GARCH Modeling Approach to Improve Subway Short-Term Ridership Forecasting Accounting for Dynamic Volatility</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinxiao</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanru</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinkai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guizhen</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TITS.2017.2711046</idno>
		<ptr target="https://doi.org/10.1109/TITS.2017.2711046" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1054" to="1064" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spatiotemporal Multi-Graph Convolution Network for Ride-Hailing Demand Forecasting</title>
		<author>
			<persName><forename type="first">Yaguang</forename><surname>Xu Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33013656</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33013656" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3656" to="3663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multi-modal graph interaction for multi-graph convolution network in urban spatiotemporal forecasting</title>
		<author>
			<persName><forename type="first">Xiyu</forename><surname>Xu Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11395</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive Kalman filter approach for stochastic short-term traffic flow rate prediction and uncertainty quantification</title>
		<author>
			<persName><forename type="first">Jianhua</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Billy</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.trc.2014.02.006</idno>
		<ptr target="https://doi.org/10.1016/j.trc.2014.02.006" />
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="50" to="64" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph representation learning</title>
		<author>
			<persName><surname>William L Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Artifical Intelligence and Machine Learning</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="159" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Count data models for trip generation</title>
		<author>
			<persName><forename type="first">Tae</forename><surname>Youn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Transportation Engineering</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="444" to="450" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sparse estimation in high-dimensional zero-inflated Poisson regression model</title>
		<author>
			<persName><forename type="first">Mengmeng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Physics: Conference Series</title>
		<imprint>
			<biblScope unit="volume">1053</biblScope>
			<biblScope unit="page">12128</biblScope>
			<date type="published" when="2018">2018</date>
			<publisher>IOP Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning for short-term origin-destination passenger flow prediction under partial observability in urban railway systems</title>
		<author>
			<persName><forename type="first">Wenhua</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenliang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><surname>Haris N Koutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Joint predictions of multi-modal ride-hailing demands: a deep multi-task multigraph learning-based approach</title>
		<author>
			<persName><forename type="first">Jintao</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2011.05602" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting origin-destination ride-sourcing demand with a spatio-temporal encoder-decoder residual multi-graph convolutional network</title>
		<author>
			<persName><forename type="first">Jintao</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoran</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengfei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page">102858</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shortterm forecasting of passenger demand under on-demand ride services: A spatiotemporal deep learning approach</title>
		<author>
			<persName><forename type="first">Jintao</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiqun</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="591" to="608" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lower upper bound estimation method for construction of neural network-based prediction intervals</title>
		<author>
			<persName><forename type="first">Abbas</forename><surname>Khosravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeid</forename><surname>Nahavandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Creighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><forename type="middle">F</forename><surname>Atiya</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNN.2010.2096824</idno>
		<ptr target="https://doi.org/10.1109/TNN.2010.2096824" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="337" to="346" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<title level="m">Variational graph auto-encoders</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The annals of mathematical statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951">1951. 1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Zero-inflated Poisson regression, with an application to defects in manufacturing</title>
		<author>
			<persName><forename type="first">Diane</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="1992">1992. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Temporal convolutional networks for action segmentation and detection</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rene</forename><surname>Michael D Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Austin</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><surname>Hager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="156" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rose</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01926</idno>
		<title level="m">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Universal Framework of Spatiotemporal Bias Block for Long-Term Traffic Forecasting</title>
		<author>
			<persName><forename type="first">Fuqiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingyi</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Miranda-Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Contextualized spatial-temporal network for taxi origin-destination demand prediction</title>
		<author>
			<persName><forename type="first">Lingbo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="3875" to="3887" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling shark bycatch: the zero-inflated negative binomial regression model with smoothing</title>
		<author>
			<persName><forename type="first">Mihoko</forename><surname>Minami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cleridy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lennert-Cody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><surname>Rom?n-Verdesoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fisheries Research</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="210" to="221" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multilevel zero-inflated negative binomial regression modeling for over-dispersed count data with extra zeros</title>
		<author>
			<persName><forename type="first">Abbas</forename><surname>Moghimbeigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Reza Eshraghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazem</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Mcardle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1193" to="1202" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ga?l</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Uncertainty in travel demand forecasting models: Literature review and research agenda</title>
		<author>
			<persName><forename type="first">Soora</forename><surname>Rasouli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harry</forename><surname>Timmermans</surname></persName>
		</author>
		<idno type="DOI">10.3328/TL.2012.04.01.55-73</idno>
		<ptr target="https://doi.org/10.3328/TL.2012.04.01.55-73" />
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="55" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Beyond Expectation: Deep Joint Mean and Quantile Regression for Spatiotemporal Problems</title>
		<author>
			<persName><forename type="first">Filipe</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</author>
		<idno type="DOI">10.1109/tnnls.2020.2966745</idno>
		<ptr target="https://doi.org/10.1109/tnnls.2020.2966745" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Managing slow-moving item: a zero-inflated truncated normal approach for modeling demand</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Wanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuliani</forename><surname>Coluccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Vega-Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gonzalo</forename><forename type="middle">F</forename><surname>Huerta-Canepa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">298</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distribution type uncertainty due to sparse and imprecise data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sankararaman</surname></persName>
		</author>
		<author>
			<persName><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="182" to="198" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicting citywide crowd flows in irregular regions using multi-view graph convolutional networks</title>
		<author>
			<persName><forename type="first">Junkai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaofei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuwen</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scalable algorithms for data and network analysis. Foundations and Trends? in Theoretical</title>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="274" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep neural networks for choice analysis: Architecture design with alternative-specific utility functions</title>
		<author>
			<persName><forename type="first">Shenhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baichuan</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="234" to="251" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep neural networks for choice analysis: A statistical learning theory perspective</title>
		<author>
			<persName><forename type="first">Shenhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nate</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part B: Methodological</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="60" to="81" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep neural networks for choice analysis: Extracting complete economic information for interpretation</title>
		<author>
			<persName><forename type="first">Shenhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">102701</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuankai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingyi</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11335</idno>
		<title level="m">Low-Rank Hankel Tensor Completion for Traffic Speed Estimation</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">G</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Inductive Graph Neural Networks for Spatiotemporal Kriging</title>
		<author>
			<persName><forename type="first">Yuankai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingyi</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelie</forename><surname>Labbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4478" to="4485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Yuankai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingyi</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengying</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelie</forename><surname>Labbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12144</idno>
		<title level="m">Spatial Aggregation and Temporal Convolution Networks for Real-time Kriging</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="24" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dynamic origin-destination matrix prediction with line graph neural networks and kalman filter</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaan</forename><surname>Ozbay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">2674</biblScope>
			<biblScope unit="page" from="491" to="503" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep multi-view spatial-temporal network for taxi demand prediction</title>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jintao</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianfeng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitian</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinghua</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieping</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Spatio-Temporal Graph Convolutional Networks : A Deep Learning Framework For Traffic Forecasting</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<ptr target="https://aaafoundation.org/american-driving-survey-2014-2015/" />
	</analytic>
	<monogr>
		<title level="m">Pro-ceedLearningings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal residual networks for citywide crowd flows prediction</title>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dekang</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The propagation of uncertainty through travel demand models: An exploratory analysis</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kara</forename><surname>Maria Kockelman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s001680200072</idno>
		<ptr target="https://doi.org/10.1007/s001680200072" />
	</analytic>
	<monogr>
		<title level="j">Annals of Regional Science</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="145" to="163" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Equality of opportunity in travel behavior prediction with deep neural networks and discrete choice models</title>
		<author>
			<persName><forename type="first">Yunhan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page">103410</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">From compound word to metropolitan station: Semantic similarity analysis using smart card data</title>
		<author>
			<persName><forename type="first">Dingyi</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyu</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Der-Horng</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Gang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="322" to="337" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
