<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning similarity with cosine similarity ensemble</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-02-20">20 February 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Peipei</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Provincial Key Laboratory for Computer Information Processing Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<postCode>215006</postCode>
									<settlement>Suzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
							<email>zhangliml@suda.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Provincial Key Laboratory for Computer Information Processing Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<postCode>215006</postCode>
									<settlement>Suzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center of Novel Software Technology and Industrialization</orgName>
								<address>
									<postCode>210000</postCode>
									<settlement>Nanjing, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fanzhang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Provincial Key Laboratory for Computer Information Processing Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<postCode>215006</postCode>
									<settlement>Suzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Provincial Key Laboratory for Computer Information Processing Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<postCode>215006</postCode>
									<settlement>Suzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning similarity with cosine similarity ensemble</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-02-20">20 February 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">A790649EB56DF7A9F48A7E1D14BA8E3D</idno>
					<idno type="DOI">10.1016/j.ins.2015.02.024</idno>
					<note type="submission">Received 22 July 2014 Received in revised form 9 February 2015 Accepted 14 February 2015</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Similarity learning Cosine similarity Ensemble learning Selective ensemble Machine learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There is no doubt that similarity is a fundamental notion in the field of machine learning and pattern recognition. How to represent and measure similarity appropriately is a pursuit of many researchers. Many tasks, such as classification and clustering, can be accomplished perfectly when a similarity metric is well-defined. Cosine similarity is a widely used metric that is both simple and effective. This paper proposes a cosine similarity ensemble (CSE) method for learning similarity. In CSE, diversity is guaranteed by using multiple cosine similarity learners, each of which makes use of a different initial point to define the pattern vectors used in its similarity measures. The CSE method is not limited to measuring similarity using only pattern vectors that start at the origin. In addition, the thresholds of these separate cosine similarity learners are adaptively determined. The idea of using a selective ensemble is also implemented in CSE, and the proposed CSE method outperforms other compared methods on various data sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Similarity is a fundamental issue in classification and clustering tasks. The concept of similarity is related to the concept of distance. However, the concepts of similarity and distance are not exactly the same. For example, similarity is used to measure the common characteristics between two instances, and distance is adopted to indicate the differences between them. Still, there is still a strong link between similarity and distance. We can first calculate the distance between two instances and then set an appropriate threshold to decide whether they are similar or not. Two instances will be more similar as the distance between them decreases.</p><p>How to select a well-defined distance metric is often a huge challenge due to the absence of prior knowledge. Many problems in pattern recognition can be easily solved if a similarity metric can be well estimated from the known data. The Euclidean distance is usually considered the simplest measure of similarity in many machine learning and data mining tasks. However, this metric often fails to generate discriminative representations. For this reason, even state-of-the-art algorithms, such as K-nearest neighbors (KNN) <ref type="bibr" target="#b7">[8]</ref>, support vector machines (SVM) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b31">32]</ref> and artificial neural networks (ANN) <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b9">10]</ref> cannot achieve optimal performances. As a result, similarity learning, which attempts to learn similarity metrics adaptively for given tasks, has become an important research subject that has attracted considerable attention for the past decades.</p><p>Some similarity learning methods have been proposed that learn similarity functions directly from pairwise relationships, or constraints <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b19">20]</ref>. Phillips applied an SVM model to learn a similarity function in difference space <ref type="bibr" target="#b23">[24]</ref>, where the distance between two patterns is measured by the difference between them. Melacci et al. proposed a novel neural network model, called a similarity neural network (SNN), to learn similarity in 2008 <ref type="bibr" target="#b20">[21]</ref>. Kernel based methods also play an important role in this area of research. In these methods, the key point is to learn a feature mapping function and to then define an appropriate distance metric based on this mapping. Single kernel similarity learning methods were proposed in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref>. <ref type="bibr">Tang et al.</ref> presented a new multikernel similarity learning method that outperforms these single kernel approaches <ref type="bibr" target="#b26">[27]</ref>. For the multikernel method, a gradient descent algorithm is employed as a weak algorithm to generate the basic kernels. Because the gradient descent algorithm is relatively slow when the solution approaches the minimum <ref type="bibr" target="#b13">[14]</ref>, the multikernel method can be quite costly.</p><p>As mentioned before, the Euclidean distance is the most frequently used metric due to its simplicity. In the Euclidean space, the distance between two points is measured by the length of the line segment connecting them. Unfortunately, the Euclidean distance suffers from a high sensitivity to magnitudes. As an alternative, cosine similarity is another commonly used metric, which measures similarity as the angle between two vectors. For any two patterns, the patterns are considered less similar as the Euclidean distance between them increases, but they are considered more similar as the cosine similarity between them increases. The basic measure of cosine similarity is not sensitive to magnitudes. Unfortunately, this property is not always advantageous. For example, even two patterns with very different attribute values may have a very high similarity measure. This outcome is obviously undesirable. An adjusted cosine similarity metric <ref type="bibr" target="#b25">[26]</ref> can remedy this drawback easily by taking the different scales between the two patterns into consideration and subtracting the corresponding average from each pattern.</p><p>Both the basic and adjusted cosine similarity metrics focus on orientations. However, the data distribution is often unknown in real world problems. When the patterns are in a very dense distribution, the angles between them may be very small. In such cases, even if two patterns are dissimilar, a classifier based on cosine similarity is very likely to misclassify them as similar. How can one make the angle between dissimilar patterns larger in such cases? In this paper, a novel similarity learning method, a cosine similarity ensemble (CSE), is proposed, that makes a trade off between computability and flexibility. Our CSE method enlarges the angles between patterns by changing the initial point of these patterns. Usually, the origin is specified as the initial point of a vector. When the terminal points of two given vectors are held constant, the angle between these two vectors is entirely determined by their shared initial point. In CSE, different points are chosen as initial points in the feature space and then combined according to weighting factors.</p><p>Section 2 surveys related work in similarity learning. Section 3 introduces the proposed method, CSE, in detail. Section 4 presents our experiments and their results, and Section 5 presents our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>We first give a formal description of the problem in similarity learning and then review some representative work that is related to ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Problem formulation</head><p>Suppose the input space X is a d-dimensional space. x and x 0 are two arbitrary patterns in X , where x ¼ x 1 ; x 2 ; . . . ; x d ½ T and</p><formula xml:id="formula_0">x 0 ¼ x 0 1 ; x 0 2 ; . . . ; x 0 d Â Ã T .</formula><p>Let ðx; x 0 Þ be the pairwise-patterns constructed by x and x 0 . l x and l x 0 are class labels of x and x 0 , respectively. rðx; x 0 Þ 2 fþ1; À1g indicates whether x and x 0 are similar to each other. If x and x 0 are similar, rðx; x 0 Þ ¼ þ1; otherwise rðx; x 0 Þ ¼ À1. rðx; x 0 Þ can be described as:</p><formula xml:id="formula_1">rðx; x 0 Þ ¼ þ1; if l x ¼ l x 0 ; À1; otherwise: &amp;<label>ð1Þ</label></formula><p>The intrinsic model of a similarity learning problem can be defined as a map, x;</p><formula xml:id="formula_2">x 0 ð Þ# þ1; À1 f g . If x; x 0 ð Þ# þ 1,</formula><p>the model asserts that x and x 0 are similar. Otherwise, if x; x 0 ð Þ# À 1, the model asserts that x and x 0 are dissimilar. The objective of learning similarity is to develop a well-defined similarity metric which can fit the map well. Obviously, any arbitrary function fitting the map x; x 0 ð Þ# fþ1; À1g can be a similarity metric. However, which function is best among all possible similarity metrics? Let the best similarity metric be g. Ideally, gðx; x 0 Þ rðx; x 0 Þ for any two arbitrary patterns x and x 0 in X . Unfortunately, patterns with different labels may partially overlap in the input feature space. In addition, noise is unavoidable in real world problems. Hence, the best metric g that asserts similarity/dissimilarity correctly for all of the pairwise-patterns in a training set is likely to be an over-fitting one with poor generalization ability. In such case, the best similarity metric will not correctly indicate similarity/dissimilarity for unseen pairwise-patterns. For this reason, it is difficult to find the best similarity metric that also generalizes well to unseen data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Representative work</head><p>As described in Section 1, many different distance metrics can be directly applied to the problem of similarity learning. The further the distance between a pair of patterns, the less similar these patterns are to one another.</p><p>The Euclidean distance is regarded as the most commonly used and simplest distance metric. In Euclidean space, the distance between two points is the length of the line segment connecting them. For two patterns x and x 0 , the Euclidean distance d x; x 0 ð Þ between them is defined as:</p><formula xml:id="formula_3">d x; x 0 ð Þ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi X d i¼1 x i À x 0 i À Á 2 r<label>ð2Þ</label></formula><p>The similarity probability decreases as the Euclidean distance increases.</p><p>However, the Euclidean distance underperforms in some real world problems due to its sensitivity to magnitudes. For instance, the Euclidean distance is very sensitive to very small deformations in image classification tasks. Fig. <ref type="figure" target="#fig_0">1</ref> shows an intuitive example that illustrates this point. In Fig. <ref type="figure" target="#fig_0">1</ref>, the middle image is similar to the left one, and dissimilar to the right one. The Euclidean distance is 12.1780 between the similar pair, and 11.6482 between the dissimilar pair. <ref type="foot" target="#foot_0">1</ref> It is surprising to note that the Euclidean distance between the dissimilar pair of images is less than that between the similar pair of images! This outcome is not reasonable, intuitively. The reason such an outcome occurs is because images have inherent qualities. There are strong spacial relations between the pixels in an image. Thus, Wang et al. proposed IMED (Image Euclidean Distance) which alters the Euclidean distance metric for use specifically in classification tasks <ref type="bibr" target="#b28">[29]</ref>.</p><p>Cosine similarity is another metric that is commonly used, particularly in high-dimensional positive spaces, to perform tasks such as information retrieval <ref type="bibr" target="#b16">[17]</ref> and data mining <ref type="bibr" target="#b2">[3]</ref>. Unlike the Euclidean distance, which suffers from a high sensitivity to even a small deformations, cosine similarity pays more attention to directions. It measures similarity as the cosine of the angle between two vectors. Two similar vectors are expected to have a small angle between them. The cosine similarity of two patterns x and x 0 is defined by cosðhÞ ¼</p><formula xml:id="formula_4">P d i¼1 x i Â x 0 i ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P d i¼1 x 2 i q Â ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P d i¼1 x 02 i q<label>ð3Þ</label></formula><p>where h is the angle between x and x 0 . The similarity between these patterns increases as cos h ð Þ increases. However, the basic cosine similarity metric also suffers a serious disadvantage by focusing only on the orientation between patterns. It is well-known that lighting has a great amount of influence on a facial recognition. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates an example of a facial recognition task. In Fig. <ref type="figure" target="#fig_1">2</ref>, the two images show the same person with the same facial expression from the same point of view. The only difference between these images is due to light intensity. The cosine similarity of the two images, cos h ð Þ -1, indicates that the two images are not exactly the same. Apparently, this outcome depends on the light intensity. An adjusted cosine similarity metric can offset this drawback easily, taking the different scales between the two patterns into consideration by subtracting the corresponding average from each pattern. The adjusted cosine similarity of x and x 0 is expressed as:</p><formula xml:id="formula_5">cos 0 h ð Þ ¼ P d i¼1 x i À x ð ÞÂ x 0 i À x 0 À Á ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P d i¼1 x i À x ð Þ 2 q Â ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P d i¼1 x 0 i À x 0 À Á 2 q<label>ð4Þ</label></formula><p>where x ¼</p><formula xml:id="formula_6">1 d P d i¼1 x i and x 0 ¼ 1 d P d i¼1 x 0 i .</formula><p>In this way, the similarity between the two images in Fig. <ref type="figure" target="#fig_1">2</ref> equals one and is independent of light intensity. According to this adjusted cosine similarity metric these two images will be classified as completely the same, even under different light intensity conditions.</p><p>In 2010, Nguyen et al. proposed a new method, Cosine Similarity Metric Learning (CSML), for learning a distance metric in facial verification takes <ref type="bibr" target="#b22">[23]</ref>. CSML learns a linear transformation and then computes the cosine similarity in the transformed subspace. Let the linear transformation be A :</p><formula xml:id="formula_7">R d ! R d 0 d 0 ( d À Á</formula><p>, then the cosine similarity of x and x 0 in the transformed subspace can be defined as:</p><formula xml:id="formula_8">CS x; x 0 ; A ð Þ¼ Ax ð Þ T Ax 0 ð Þ Ax k k Ax 0 k k ¼ x T A T Ax 0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi x T A T Ax p ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi x 0 T A T Ax 0 p<label>ð5Þ</label></formula><p>CSML forms a simple but effective objective function that exploits the use of cosine similarity and its special properties. Kernel based methods are also very prevalent in similarity learning. In 2002, Chen et al. proposed a new kernel-based similarity measurement <ref type="bibr" target="#b5">[6]</ref>. The concepts of distance and similarity share the same meaning in <ref type="bibr" target="#b5">[6]</ref>. The proposed similarity metric is a standard distance metric which meets all of the requirements of a metric function; namely, this metric satisfies the requirements of non-negativity, minimality and symmetry, and it obeys the triangle inequality. In this approach, the measurement of similarity is defined as the distance between patterns in some feature space. Therefore, learning the metric is cast as a problem of learning a feature mapping function. The unknown mapping can map the input data x to the new feature space (of finite or infinite dimensionality) and has the form:</p><formula xml:id="formula_9">u x ð Þ : x ! y; x 2 R d ; y 2 R d 00<label>ð6Þ</label></formula><p>In the mapped feature space, the distance function can be expressed as:</p><formula xml:id="formula_10">d u y; y 0 ð Þ¼ y À y 0 k k<label>ð7Þ</label></formula><p>where y and y 0 are the points in the mapped space that correspond to the points x and x 0 in the input space. Hence, the metric function in the input space X is:</p><formula xml:id="formula_11">d x; x 0 ð Þ¼d u u x ð Þ; u x 0 ð Þ ð Þ ¼ d u y; y 0 ð Þ¼ y À y 0 k k ð<label>8Þ</label></formula><p>Experimental results show that the proposed kernel-based method may be a feasible approach to solving many recognition problems <ref type="bibr" target="#b5">[6]</ref>.</p><p>In 2011 Tang et al. learned similarity using a multikernel method that is motivated by geometric intuition and computability <ref type="bibr" target="#b26">[27]</ref>. In this method, similarity between patterns is measured by their included angle in a kernel-induced Hilbert space. In addition, the cosine of such an included angle can be represented by a normalized kernel. In this way, the task of learning similarity is equivalent to learning an appropriate normalized kernel. Moreover, this method shows that the optimal normalized kernel can be represented as a convex combination of basic normalized kernels. Based on such results, a boosting-style algorithm is developed to learn similarity using multikernel methods. Experimental results illustrate the effectiveness of the new multikernel method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning similarity with a cosine similarity ensemble</head><p>In this section, we introduce our cosine similarity ensemble (CSE) as a method for learning similarity. We describe CSE in terms of three parts: diversity and the combination rule, the algorithm, and the generalization bound for CSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Diversity and the combination rule for CSE</head><formula xml:id="formula_12">Let S ¼ x i ; x 0 i ; r i À Á È</formula><p>É n i¼1 be a training set of n triplets with pairwise-patterns ðx i ; x 0 i Þ and binary class labels r i 2 þ1; À1 f g , where r i indicates whether x i and x 0 i are similar. In cosine similarity, the similarity function has the following form:</p><formula xml:id="formula_13">f x i ; x 0 i À Á ¼ sign x T i x 0 i x i k k Á x 0 i À s !<label>ð9Þ</label></formula><p>where s 2 ½À1; þ1 is the threshold and signðÁÞ is the sign function. If f ðx i ; x 0 i Þ ¼ 1, the similarity function asserts that x i and x 0 i are similar. x i and x 0 i are expected to be dissimilar when f ðx i ; x 0 i Þ ¼ À1. Thus, the expected class label is ri ¼ f ðx i ; x 0 i Þ when using the basic cosine similarity metric.  Unfortunately, both the basic and the adjusted cosine similarity metrics are sometimes ineffective, even when they are used to perform some simple tasks. Fig. <ref type="figure" target="#fig_2">3</ref> provides a visual example where x 2 is similar to x 1 and dissimilar to x 3 . In this example it is clear that x 2 is much closer to x 1 than to x 3 . However, the included angle h 1 between x 2 and x 1 is much greater than the included angle h 2 between x 2 and x 3 . Thus, x 2 is more similar to x 3 than it is to x 1 according to the cosine similarity metric <ref type="bibr" target="#b2">(3)</ref>. The result would be the same even if the adjusted cosine similarity metric were used to measure similarity in this example <ref type="bibr" target="#b3">(4)</ref>. Imagining another circumstance, when patterns in different classes are close to one another or even slightly overlapping in the original input feature space, the angles between patterns from different classes might be quite small, resulting in misclassification of such patterns when using a cosine similarity metric to classify patterns. It is this problem that we try to solve in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Diversity for CSE</head><p>In most cases, the origin is used as the initial point of a vector. To address the problem mentioned above, we can specify alternate initial points for our input pattern vectors. For two given patterns, specifying a different initial points for the patterns, while holding the terminal points of the patterns constant, results in different included angles between the patterns (see Fig. <ref type="figure" target="#fig_3">4</ref>). In Fig. <ref type="figure" target="#fig_3">4</ref>, there are three initial points represented, m 1 , m 2 , and m 3 . x 1 and x 2 are patterns from class one and class two, respectively. h 1 ; h 2 and h 3 are three different included angles between x 1 and x 2 obtained by specifying different initial points for these patterns. In turn, different included angles lead to different performance results via cosine similarity learning. In ensemble learning, technical considerations dictate that individual learners should be as diverse as possible. Within CSE, the individual learners are the basic cosine similarity metrics, and their diversity is guaranteed by specifying different initial points for input pattern vectors to be used by different individual cosine similarity learners.</p><p>Next, we discuss how to choose initial points. The ideal initial point is one which makes the included angles of patterns in the same category small, while making the included angles of patterns from different categories larger at the same time. By geometric intuition, the included angle between two patterns is the largest, a straight angle, when the initial point is on the line segment connecting two patterns. The included angle between two patterns is the smallest when the initial point is infinitely far away.</p><p>The goal of similarity learning is to determine if pairwise input patterns are similar or not. In other words, there are only two possible cases: the pairwise-patterns are from the same category, or they are from different categories. Quite frequently, patterns in the same category are relatively crowded in the input feature space. It is usually fairly easy to find a new initial point to make the included angles between them small. The real challenge lies in finding out how to enlarge the angles between the pairwise-patterns that belong to different categories but that are still quite close to one another in the input feature space. In this case, geometric intuition motivates us to believe that the best initial point may be the central point between any two candidate categories whose members are being measured for similarity.</p><p>To guarantee the diversity of individual learners in CSE, the center points between every two categories are taken as a set of initial points. If the patterns are from c different categories, there are c Â ðc À 1Þ=2 different initial points in total. In Fig. <ref type="figure" target="#fig_3">4</ref>, m 1 ; m 2 , and m 3 are the center points between class one and class two, between class two and class three, and between class one and class three, respectively. Different included angles between x 1 and x 2 can be obtained by applying these different initial points. As we mentioned earlier, obtaining different included angles between a pair of pattern vectors results in different similarity measures between these pattern vectors. The diversity of CSE is assured in this way. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Combination rule for CSE</head><p>Which combination rule to use in combining results from individual learners is another important issue in ensemble learning. Many combination rules have been proposed, but all the combination rules proposed so far can be divided into two groups.</p><p>In the first group, the combination rules combine the results of all individual learners. In classification tasks, if the predicted class labels of individual classifiers are available, a simple (majority) voting (SV) rule can be used to obtain a final classification label <ref type="bibr" target="#b15">[16]</ref>. If continuous outputs such as posteriori probabilities are supplied, an average, linear or nonlinear combination rule can be employed to combine the outputs of all individual learners <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b11">12]</ref>. These combination rules come with two drawbacks: they have large memory requirements, and they are relatively slow compared with some other methods <ref type="bibr" target="#b18">[19]</ref>.</p><p>To remedy these drawbacks, Zhou et al. introduced the concept of a selective ensemble in 2002, standing by the claim, ''many could be better than all'' <ref type="bibr" target="#b33">[34]</ref>. This approach has attracted the interest of many researchers since then. Selective ensembles, also known as ''pruned ensembles'' <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b4">5]</ref> or ''sparse ensembles'' <ref type="bibr" target="#b32">[33]</ref> work very well in both theory and practice. The output of only a fraction of individual learners is selected and combined by simple or weighted voting in selective ensemble learning.</p><p>In CSE, the number of individual learners is quadratic to c, where c is the number of categories. To speed up CSE, selective ensemble is adopted to combine individual cosine metrics by weighted voting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Algorithm for CSE</head><formula xml:id="formula_14">Let z i ; l i ð Þ f g v i¼1 be a training set in the input feature space X . z i 2 R d is the ith pattern. l i 2 f1; 2; Á Á Á ; cg is the class label of z i .</formula><p>d is the dimensionality of the input space. v is the number of patterns, and c is the number of categories. Fig. <ref type="figure">5</ref> shows the framework of CSE in which there are four stages: data preprocessing, training individual learners, weighting individual learners and creating the selective ensemble. In the following sections, we describe the four stages in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Data preprocessing</head><p>In this stage, a set of initial points and a triplet training set are constructed for individual cosine similarity learners.</p><p>Center points between every two categories are taken as the new initial points of input vectors in CSE. Suppose that the class labels of patterns in the pth class are p; p 2 f1; 2; . . . ; cg. Let m j be the center point between the pth and qth classes. Namely, GðtÞ is a unit impulse function defined as:</p><formula xml:id="formula_15">m j ¼ 1 2 P v i¼1 z i Gðl i À pÞ P v i¼1 Gðl i À pÞ þ P v i¼1 z i Gðl i À qÞ P v i¼1 Gðl i À qÞ<label>ð10Þ</label></formula><formula xml:id="formula_16">GðtÞ ¼ 1; if t ¼ 0; 0; otherwise: &amp;<label>ð11Þ</label></formula><p>There are c Â ðc À 1Þ=2 center points in total; that is to say, there are c Â ðc À 1Þ=2 individual cosine similarity learners in CSE. Let N ¼ c Â ðc À 1Þ=2 and let the set of center points be denoted as M ¼ fm j g N j¼1 . Denote the triplet training set as</p><formula xml:id="formula_17">S ¼ x i ; x 0 i ; r i À Á È É n i¼1</formula><p>, where n is the number of triplets, x i and x 0 i are randomly selected copies of elements in fz i g v i¼1 , and r i indicates whether x i and x 0 i are from the same category. If x i and x 0 i have the same class label, then r i ¼ þ1; otherwise r i ¼ À1. Pos, the index set of similar pairwise-patterns, is defined as:</p><formula xml:id="formula_18">Pos ¼ fk r k ¼ þ1; k ¼ 1; . . . ; n j g<label>ð12Þ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Training individual learners</head><p>Given S and M, we can train N individual cosine similarity learners. The similarity function of the jth learner can be described as:</p><formula xml:id="formula_19">f j x i ; x 0 i À Á ¼ sign s j ðx i ; x 0 i Þ À s j À Á<label>ð13Þ</label></formula><p>where s j is the threshold in the jth learner, and s j ðx i ; x 0 i Þ is the similarity between x i and x 0 i with the form:</p><formula xml:id="formula_20">s j ðx i ; x 0 i Þ ¼ x i À m j À Á T x 0 i À m j À Á x i À m j x 0 i À m j<label>ð14Þ</label></formula><p>The only unknown variable in ( <ref type="formula" target="#formula_19">13</ref>) is the threshold s j , so the goal of training the jth learner is to determine s j . The simplest way is to set the threshold as a constant, such as 0. However, for different problems, the range of cosine similarity measures of within-group pairwise-patterns may vary widely. As a result, it is difficult to set a single threshold that is appropriate for all problem domains. In our strategy, the threshold is adaptively determined for given tasks.</p><p>It is necessary to notice that real world problems are usually multi-category problems. In these problems, the pairwisepatterns are quite imbalanced; i.e. similar pairwise-patterns are far less numerous than dissimilar ones. This is a betweenclass imbalance problem <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b12">13]</ref>. Moreover, the degree of imbalance is highly dependent on the scale of the values of the components of the pattern vectors in a category. Larger scale seems to create more serious imbalances. When dealing with between-class imbalance problems, we should pay more attention to the rare class, which is the class of similar pairwisepatterns in such problems.</p><p>Some similar pairwise-patterns can be easy to misclassify when there is a low degree of similarity between them. Sometimes the degrees of similarity between some similar patterns can be much smaller than the degrees of similarity between dissimilar patterns in certain individual learners. When this situation arises it can cause a large deviation in similarity measures within the set Pos. These types of similar pairwise-patterns can be regarded as noise and can be ignored in the relevant individual learners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weighting individual learners</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training individual learners</head><p>Data preprocessing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selective ensemble</head><p>Fig. <ref type="figure">5</ref>. Framework of CSE.</p><p>To address the above considerations, we determine the threshold s j over a subset of similar pairwise-patterns with high degrees of similarity. Denote Psim j as the index set for this subset of selected similar pairwise-patterns in the jth learner. Here</p><formula xml:id="formula_21">Psim j ¼ ijs j ðx i ; x 0 i Þ &gt; s j ; i 2 Pos È É<label>ð15Þ</label></formula><p>s j is the average similarity defined as:</p><formula xml:id="formula_22">s j ¼ 1 Pos j j X i2Pos s j ðx i ; x 0 i Þ<label>ð16Þ</label></formula><p>where Á j j is the number of elements in a set Á. Thus, the threshold s j can be adaptively determined as:</p><formula xml:id="formula_23">s j ¼ 1 Psim j X i2Psim j s j ðx i ; x 0 i Þ À stdðs j Þ<label>ð17Þ</label></formula><p>where stdðÁÞ is the standard deviation, and s j 2 R jPsim j j is the vector with element s j ðx i ; x 0 i Þ; 8i 2 Psim j . In doing so, we can obtain a set of thresholds fs j g N j¼1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Weighting individual learners</head><p>As the data distribution is unknown, different individual cosine similarity learners may perform differently when classifying patterns. The individual learners with better performance deserve more attention, and their outputs should be weighted more heavily. We measure the performance of individual learners by the training error on S which can be computed by:</p><formula xml:id="formula_24">err j ¼ P n i¼1 L r i ; f j ðx i ; x 0 i Þ À Á n ; j ¼ 1; . . . ; N<label>ð18Þ</label></formula><p>where err j is the training error of the jth learner, and Lðr; f ðx; x 0 ÞÞ is a loss function defined as Lðr; f ðx;</p><formula xml:id="formula_25">x 0 ÞÞ ¼ 1; if r -f ðx; x 0 Þ 0; otherwise &amp;<label>ð19Þ</label></formula><p>The weights of individual learners are set based on the training error according to:</p><formula xml:id="formula_26">a j ¼ log 1 À err j err j ; j ¼ 1; . . . ; N<label>ð20Þ</label></formula><p>where a j is the weight of the jth learner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">Selective ensemble</head><p>Thus far we have N individual learners with their corresponding weights a j ; j ¼ 1; . . . ; N. The last step in the CSE process is to generate a final cosine similarity metric. As mentioned above, in CSE we adopt the use of a selective ensemble and combine the outputs of only a subset of individual learners, instead of combining the outputs of all learners, to generate a final similarity metric. The individual learners whose weights are greater than the average weight of all learners are selected for inclusion in the final ensemble.</p><p>Let the index set of selected individuals be SI,</p><formula xml:id="formula_27">SI ¼ j a j &gt; a; j ¼ 1; . . . ; N È É<label>ð21Þ</label></formula><p>where</p><formula xml:id="formula_28">a ¼ 1 N P N</formula><p>j¼1 a j is the average weight of all individual learners.</p><p>To ensure that the final ensemble similarity metric is a convex combination of individual learners, we normalize the weights of the learners selected for inclusion in the final ensemble such that the sum of their weights is equal to one. For each j 2 SI, the normalization can be expressed by:</p><formula xml:id="formula_29">a j ¼ a j P k2SI a k<label>ð22Þ</label></formula><p>For an arbitrary pairwise-pattern ðx; x 0 Þ, its similarity prediction r can be determined by the final cosine similarity function described by:</p><formula xml:id="formula_30">r ¼ f x; x 0 ð Þ¼sign X j2SI a j s j x; x 0 ð ÞÀs j À Á !<label>ð23Þ</label></formula><p>(23) can also be rewritten as:</p><formula xml:id="formula_31">f x; x 0 ð Þ¼sign X j2SI a j s j x; x 0 ð ÞÀs 0 !<label>ð24Þ</label></formula><p>where s 0 ¼ P j2SI a j Â s j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Generalization bound for CSE</head><p>Given an arbitrary pairwise-pattern ðx; x 0 Þ 2 X 2 , x and x 0 are similar when f ðx; x 0 Þ ¼ 1 and dissimilar when f ðx; x 0 Þ ¼ À1. Thus, our goal is to find an optimal function f ðx; x 0 Þ from a given set of functions that best approximates the mapping from X 2 to fÀ1; þ1g. Selection of the optimal function is based on a triplet training set S ¼ fx i ; x 0 i ; r i g n i¼1 which consists of n independent and identically distributed (i.i.d.) observations drawn from an unknown probability measure Pðx; x 0 ; rÞ. <ref type="bibr" target="#b18">(19)</ref> defines the loss between the target r of the pairwise-pattern ðx; x 0 Þ and its estimated f ðx; x 0 Þ. Based on the expectation of the loss <ref type="bibr" target="#b18">(19)</ref>, the expected risk of estimating similarity can be described as:</p><formula xml:id="formula_32">Rðf Þ ¼ Z Lðr; f ðx; x 0 ÞÞdPðx; x 0 ; rÞ<label>ð25Þ</label></formula><p>Because the probability measure Pðx; x 0 ; rÞ is unknown, the expected risk cannot be directly obtained according to <ref type="bibr" target="#b24">(25)</ref>. However, Rðf Þ can be estimated by the empirical risk:</p><formula xml:id="formula_33">R emp ðf Þ ¼ X n i¼1 Lðr i ; f ðx i ; x 0 i ÞÞ<label>ð26Þ</label></formula><p>which is constructed based on the set S. Nest, we discuss the relationship between Rðf Þ and its estimator R emp ðf Þ based on the Rademacher complexity of a given set of functions <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b0">1]</ref>. The definition of Rademacher complexity follows below. Definition 1. Suppose that the set of pairwise-patterns fðx i ; x 0 i Þg n i¼1 consists of i.i.d. samples drawn from X 2 . Let F be a set of real-valued functions mapping from X 2 to R. Define the random variable:</p><formula xml:id="formula_34">Rn F ð Þ ¼ E sup f 2F 2 n X n i¼1 r i f x i ; x 0 i À Á " #<label>ð27Þ</label></formula><p>where r i ; i ¼ 1; . . . ; n are independent uniform fþ1; À1g-valued random variables. Then, the Rademacher complexity of F is:</p><formula xml:id="formula_35">R n F ð Þ ¼ E Rn F ð Þ h i<label>ð28Þ</label></formula><p>Based on the Rademacher complexity in Definition 1, the generalization bound of CSE can be estimated by the following Theorem 1.</p><p>Theorem 1. Let F be a set of þ1; À1 f g -valued functions defined on X 2 , and let S ¼ ðx i ;</p><formula xml:id="formula_36">x 0 i ; r i Þ È É n i¼1 &amp; X 2 Â þ1; À1 f gbe training</formula><p>triplets drawn according to the probability measure Pðx; x 0 ; rÞ n . Then, with probability at least 1 À dwith respect to S; 8f 2 F satisfies:</p><formula xml:id="formula_37">R f ð Þ 6 R emp f ð Þ þ R n F ð Þ 2 þ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi lnð1=dÞ 2n r<label>ð29Þ</label></formula><p>Theorem 1 is similar to Theorem 5(b) in <ref type="bibr" target="#b0">[1]</ref>. Thus, the proof of Theorem 1 is omitted here. The only difference between the two theorems is the formulation of functions F . In CSE, the similarity function f ðx; x 0 Þ 2 F takes two vectors x and x 0 as variables. In Theorem 5 of <ref type="bibr" target="#b0">[1]</ref>, f ðxÞ has one vector variable.</p><p>Similar to the expected risk of more widely used learners, such as support vector machines (SVM), the expected risk Rðf Þ of CSE is bounded by the empirical risk R emp ðf Þ and the complexity of a function set. When the size of the training triplets and the set of functions F are given, the last two items Rn F ð Þ 2 and ffiffiffiffiffiffiffiffiffiffi ffi lnð1=dÞ 2n q in (29) are both constants. R emp ðf Þ is the only term that can be controlled. Thus, the minimization of R emp f ð Þ is identical to that of Rðf Þ. In other words, the optimal similarity function can be regarded as optimizing the empirical risk R emp f ð Þ. It is well known that the optimal Bayesian classifier is constructed using all hypothesis functions weighted by their posterior probabilities. Similarly, it is reasonable to combine individual learners to achieve better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and results</head><p>To validate the effectiveness of the proposed method, we perform experiments on three benchmark databases: the Georgia Tech face database, the AT&amp;T face database and the COIL-100 database. Two subsections are included in this section. In the first subsection, our experimental settings are displayed. The second subsection describes our experimental results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Database and data preprocessing</head><p>All of the samples used in the experiments are from three benchmark databases: (1) the Georgia Tech face database, <ref type="foot" target="#foot_2">2</ref> (2) the AT&amp;T face database <ref type="bibr" target="#b24">[25]</ref>, <ref type="foot" target="#foot_3">3</ref> and (3) the COIL-100 database of photographs <ref type="bibr" target="#b21">[22]</ref>. <ref type="foot" target="#foot_4">4</ref> The Georgia Tech face database (GT face) contains 750 images of 50 people. All people in the database are represented by 15 color JPEG images with cluttered backgrounds taken at a resolution of 480 Â 640 pixels, with variations in facial expressions, lighting conditions and scale. The AT&amp;T database is composed of a total of 400 images with 10 images for each of the 40 distinct faces. Each image is a fixed size of 112 Â 92 pixels. For some subjects, the images were taken at different times, varying lighting, facial expressions and facial details. All of the images were taken against a dark homogeneous background with the subjects in an upright, frontal position. The COIL-100 database contains 7200 colorized images corresponding to 100 different objects seen from 72 different viewpoints.</p><p>The samples used in our experiments are generated by reducing the resolution of the images involved. From the GT face database, all images are converted to grayscale and downsampled from their original resolution to 60 Â 80 pixels. From the AT&amp;T face database, the resolution of the images is reduced to 56 Â 46 pixels by using 2 Â 2 subsampling. From the COIL-100 database, we gray all images and reduce the resolution to 32 Â 32 pixels. Some samples of these degraded images are illustrated in Fig. <ref type="figure" target="#fig_6">6</ref>. Table <ref type="table" target="#tab_0">1</ref> shows some information about the makeup of the samples after preprocessing has been performed. All images are treated as pixel vectors in both training and test stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Training and test sets</head><p>Training and test sets defined as described in Section 3.1, are generated in the following way. First, we split a database into two non-overlapping subsets, namely, SET1 and SET2. Any two patterns from a subset can be a pairwise-pattern that is labeled as +1 or À1 according to its class agreement. If the two patterns are selected from the same subject, they are similar and labeled as +1. Otherwise, they are dissimilar and labeled as À1. The pairwise-pattern and its binary label compose a triplet ðx i ; x 0 i ; r i Þ. The set of all triplets generated from the patterns in SET1 and SET2 are denoted as Trip1 and Trip2, respectively. The training set contains only a subset of patterns from Trip1, and the test set contains a subset of patterns from both Trip1 and Trip2. Note that the patterns in SET2 are unseen during the training stage. The similarity metric is only learned from the training set in SET1. By using only a subset of patterns from SET1 for training, we can verify the transferability of similarity learning and expect that the learned similarity function will achieve good performance on SET2 as well as on the test set in SET1.</p><p>The partition of datasets is discussed as follows. For the GT face database, SET1 contains 600 images of the first 40 people, and SET2 contains 150 images of the last 10 people. There are 9000 similar triplets and 351,000 dissimilar triplets in Trip1, and there are 2250 similar triplets and 20,250 dissimilar triplets in Trip2. We randomly choose 3500 triplets from Trip1 to use in our data set. 1000 of these triplets are used as the training set and the remaining 2500 triplets are used as a test set. 2500 triplets from Trip2 are randomly chosen and used as a second test set. For the other benchmark databases used in our experiment, the detailed description for generating a training set and a test set is omitted, and the overview is shown in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental results</head><p>First, we validate the feasibility of CSE on the GT face dataset. Then, we compare CSE with some related methods on the AT&amp;T face and the COIL-100 datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Georgia Tech face database</head><p>In CSE, the thresholds s j ; j 2 SI are adaptively determined, and only jSIj cosine similarity functions whose weights are greater than the average weight are selected for inclusion in the final ensemble. Section 3.2 mentions that the thresholds s j ; j 2 SI could be specified in advance to be a constant, and the final ensemble could include all cosine similarity functions. Thus, we check the settings of CSE in two ways. First, we compare the performance of the use of constant vs. adaptive thresholds within the framework of CSE using a selective ensemble. Next, we compare the performance of the use of selective vs. non-selective ensembles within the framework of CSE while using an adaptive threshold.</p><p>In the experiments on thresholds, s 0 can take on any value from the set f0:3; 0:4; 0:5; 0:6; 0:7; 0:8; 0:9g, or s 0 can be obtained adaptively. Suppose that s j in each individual cosine similarity metric is equal to a constant threshold, so let s 0 ¼ s j . We conduct 10 trials and report the average test errors in Table <ref type="table" target="#tab_2">3</ref>.</p><p>Table <ref type="table" target="#tab_2">3</ref>, shows that test error decreases as the threshold value increases, which supports the description in Section 3.2. As the value of s 0 increases more and more similar pairwise-patterns with low similarity are ignored. We can trust that the remaining similar pairwise-patterns are properly classified as similar. The test error obtained by setting threshold values   adaptively is competitive with the test error obtained using the best candidate among the constant thresholds tested. It is often necessary to set thresholds adaptively for different tasks, and to sum up, the adaptive threshold method is feasible within the framework of CSE.</p><p>In the experiments on ensemble methods, we compare the use of selective and non-selective ensembles. When using a non-selective ensemble, the final cosine similarity metric is generated by combining the cosine similarity metrics of all the individual learners. When using a selective ensemble, the final similarity function combines only the cosine similarity metrics of the subset of individual learners whose weights are greater than the average weight. The results shown in Table <ref type="table" target="#tab_3">4</ref> are averaged over 10 runs.</p><p>The results in Table <ref type="table" target="#tab_3">4</ref> show that selective ensembles outperform non-selective ensembles both in terms of test error and in terms of running time. More evidence to support these findings can be found in <ref type="bibr" target="#b33">[34]</ref>. When using selective ensembles, some individual learners that contribute less to the final similarity measure are abandoned. This practice not only reduces computational complexity, but it also improves overall performance. In a nutshell, using a selective ensemble is more effective than using a non-selective ensemble within the framework of CSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">AT&amp;T face database and COIL database</head><p>We compare CSE with some other related methods in this section. These methods include the basic cosine similarity method <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b2">3]</ref>, the adjusted cosine similarity method <ref type="bibr" target="#b25">[26]</ref>, the multikernel method from <ref type="bibr" target="#b26">[27]</ref>, two types of finite-dimensional nonlinear methods and the one-example in method from <ref type="bibr" target="#b6">[7]</ref>, the semantic distance method from <ref type="bibr" target="#b10">[11]</ref>, and the single-kernel method from <ref type="bibr" target="#b19">[20]</ref>.</p><p>Both the basic and the adjusted cosine similarity methods require a threshold similar to that required by CSE. In our experiments, the thresholds in both the basic and the adjusted cosine similarity methods are adaptively determined just as they are in CSE. The test errors and AUC (Area Under the Curve of the Receiver Operating Characteristic) of different methods are shown in Tables <ref type="table" target="#tab_4">5</ref> and<ref type="table">6</ref>. We replicate the basic cosine similarity method, the adjusted cosine similarity method and the multikernel methods to obtain the results in Table <ref type="table" target="#tab_4">5</ref> while the results in Table <ref type="table">6</ref> come from the corresponding references. Although the compared methods mentioned in Table <ref type="table">6</ref> are not replicated, the experimental settings in those references are exactly the same as ours. Note that the multikernel method appears in both Tables <ref type="table" target="#tab_4">5</ref> and<ref type="table">6</ref>. The results of the multikernel method from Table <ref type="table" target="#tab_4">5</ref> were obtained using our implementation, while the multikernel method results in Table <ref type="table">6</ref> are copied from <ref type="bibr" target="#b26">[27]</ref>. Fig. <ref type="figure" target="#fig_7">7</ref> illustrates the ROC (Receiver Operating Characteristic) curve of CSE. The reported results of CSE are competitive with those of the compared methods. The results in Table <ref type="table" target="#tab_4">5</ref> indicate that CSE outperforms both the basic and adjusted cosine similarity methods. This again shows that ensemble learning can achieve better performance than a single (best) learner. From Table <ref type="table">6</ref>, only two compared methods obtain lower test errors than CSE on the AT&amp;T face database. The test error of the single-kernel method is zero, and the test error of the multikernel method is 0.64% lower than the test error of CSE. It should be noted that the patterns from the AT&amp;T database are relatively small, clean and ''easy'' when compared with the patterns from the COIL-100 database. In other words, the patterns from the COIL-100 database are more complex than those from the AT&amp;T database. Thus, the results on the COIL-100 database input patterns are more conclusive than those gleaned from the AT&amp;T input patterns. CSE achieves more superior results than any other compared method on the COIL-100 database input patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We propose a cosine similarity ensemble method for learning similarity. CSE is based on multiple cosine similarity learners which are simple and effective, especially in high-dimensional space. As a result, CSE inherits the effectiveness of more simple cosine similarity learners. In ensemble learning, the two keys to success are diversity and the combination rule used. The diversity of CSE is guaranteed by using multiple cosine similarity learners that each use a different initial point for all input pattern vectors instead of using the origin as the sole initial point of all input pattern vectors. The combination rule of CSE is used to create a weighted selective ensemble. In experiments, we compare CSE with six related methods, such as the basic cosine similarity method and the multikernel method. Experimental results on two image datasets show that CSE outperforms the single learner cosine similarity methods(i.e., the basic and adjusted cosine similarity methods) when </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 6</head><p>References of some related methods on test error (%)/AUC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AT&amp;T COIL</head><p>Multikernel in <ref type="bibr" target="#b26">[27]</ref> 4.70/0.96 5.10/0.896 One-example in <ref type="bibr" target="#b6">[7]</ref> 6.00/0.94 None ⁄ Semantic distance in <ref type="bibr" target="#b10">[11]</ref> None 10.51/none Single-kernel in <ref type="bibr" target="#b19">[20]</ref> 0/0.997 9.10/0.997 Bold values denote the best results among those obtained by the compared methods.</p><p>⁄ None means no corresponding reports in the originals. measuring performance according to both test error and AUC. On the COIL-100 database, CSE outperforms the other five methods. In a nutshell, CSE is a promising methodology for similarity learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Similar and dissimilar images from the AT&amp;T face dataset.</figDesc><graphic coords="4,146.04,54.71,255.23,98.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Two face images with different light intensity from the AT&amp;T face dataset.</figDesc><graphic coords="4,177.22,191.23,195.18,116.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. An example for the cosine similarity, where x2 is similar to x1, and dissimilar to x3. h1 is the included angle between x1 and x2, and h2 is the included angle between x2 and x3. The dotted line is the decision boundary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Diversity for CSE. There are three categories, class one, class two and class three. x1 and x2 are respectively from class one and class two. m1; m2; m3 are three start points. h1; h2 and h3 are included angles between x1 and x2 by applying different start points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Some samples of the degraded images from Georgia Tech face database (a), AT&amp;T face database (b) and COIL-100 database (c).</figDesc><graphic coords="11,113.36,54.68,310.59,499.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. ROC curve obtained by CSE on the AT&amp;T face database (a) and the COIL-100 database (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Information of samples used in the experiments.</figDesc><table><row><cell></cell><cell>GT</cell><cell>AT&amp;T</cell><cell>COIL</cell></row><row><cell># Categories</cell><cell>50</cell><cell>40</cell><cell>100</cell></row><row><cell># Images</cell><cell>750</cell><cell>400</cell><cell>7200</cell></row><row><cell>Size of images</cell><cell>60 Â 80</cell><cell>56 Â 46</cell><cell>32 Â 32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>An overview of the generation of training set and test set.</figDesc><table><row><cell></cell><cell>GT</cell><cell>AT&amp;T</cell><cell>COIL</cell></row><row><cell># Categories in SET1</cell><cell>4 0</cell><cell>3 5</cell><cell>8 0</cell></row><row><cell># Images in SET1</cell><cell>600</cell><cell>350</cell><cell>5760</cell></row><row><cell># Categories in SET2</cell><cell>1 0</cell><cell>5</cell><cell>2 0</cell></row><row><cell># Images in SET2</cell><cell>150</cell><cell>50</cell><cell>1440</cell></row><row><cell># Training images from Trip1</cell><cell>1000</cell><cell>1000</cell><cell>1000</cell></row><row><cell># Test images from Trip1</cell><cell>2500</cell><cell>2500</cell><cell>0</cell></row><row><cell># Test images from Trip2</cell><cell>2500</cell><cell>2500</cell><cell>5000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Test errors on the GT face dataset with different thresholds.Bold values denote the best results among those obtained by the compared methods.</figDesc><table><row><cell></cell><cell>s 0</cell><cell>Test error (%)</cell></row><row><cell>#1</cell><cell>0.3</cell><cell>26.80 ± 0.60</cell></row><row><cell>#2</cell><cell>0.4</cell><cell>17.07 ± 0.54</cell></row><row><cell>#3</cell><cell>0.5</cell><cell>9.49 ± 0.35</cell></row><row><cell>#4</cell><cell>0.6</cell><cell>5.09 ± 0.22</cell></row><row><cell>#5</cell><cell>0.7</cell><cell>3.68 ± 0.24</cell></row><row><cell>#6</cell><cell>0.8</cell><cell>2.92 ± 0.17</cell></row><row><cell>#7</cell><cell>0.9</cell><cell>2.31 ± 0.23</cell></row><row><cell>#8</cell><cell>0.9066 ± 0.21</cell><cell>2.42 ± 0.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Performance comparison on the GT face database.</figDesc><table><row><cell></cell><cell>Running time (s)</cell><cell>Test error (%)</cell></row><row><cell>Non-selective ensemble</cell><cell>1030</cell><cell>4.59 ± 0.29</cell></row><row><cell>Selective ensemble</cell><cell>516</cell><cell>2.42 ± 0.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Comparison with related methods on test error (%)/AUC. Bold values denote the best results among those obtained by the compared methods.</figDesc><table><row><cell></cell><cell>AT&amp;T</cell><cell>COIL</cell></row><row><cell>Basic cosine</cell><cell>7.71/0.923</cell><cell>5.52/0.855</cell></row><row><cell>Adjusted cosine</cell><cell>7.10/0.930</cell><cell>5.11/0.880</cell></row><row><cell>Multikernel</cell><cell>5.32/0.95</cell><cell>5.35/0.882</cell></row><row><cell>CSE</cell><cell>5.34/ 0.983</cell><cell>2.98/0.921</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The left, middle and right images are s1 5, s1 3 and s2 8 from the AT&amp;T face database, respectively. P. Xia et al. / Information Sciences 307 (2015) 39-52</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>P. Xia et al. / Information Sciences 307 (2015) 39-52</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>http://www.anefian.com/research/face_reco.htm.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>http://www.cs.columbia.edu/CAVE/software/softlib/coil-100.php.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>P. Xia et al. / Information Sciences 307 (2015) 39-52</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank three anonymous reviewers and Editor W. Pedryca for their valuable comments and suggestions, which have significantly improved this paper. We are also grateful to Professor Song Y. Yan for checking this paper. This work was supported in part by the National Natural Science Foundation of China under Grant No. 61373093, by the Natural Science Foundation of Jiangsu Province of China under Grant Nos. BK20140008 and BK201222725, by the Natural Science Foundation of the Jiangsu Higher Education Institutions of China under Grant No. 13KJA520001, and by the Qing Lan Project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rademacher and gaussian complexities: risk bounds and structural results</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="463" to="482" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data mining for hypertext: a tutorial survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor. Newslett</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Editorial: special issue on learning from imbalanced datasets</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kolcz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor. Newslett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Predictive ensemble pruning by expectation propagation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tin ˇo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="999" to="1013" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Kernel-based similarity learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn. Cybernet</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2152" to="2156" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nearest neighbor pattern classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
		<respStmt>
			<orgName>Support Vector Machine</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Artificial neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dayhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Deleo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer</title>
		<imprint>
			<biblScope unit="issue">S8</biblScope>
			<biblScope unit="page" from="1615" to="1635" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pattern recognition from one example by chopping</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Blanchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="page" from="371" to="378" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A theoretical and experimental analysis of linear combiners for multiple classifier systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fumera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="942" to="956" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1263" to="1284" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Methods of conjugate gradients for solving linear systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stiefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Res. Natl. Bur. Stand</title>
		<imprint>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Artificial neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Circ. Dev. Mag</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3" to="10" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On combining classifiers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hatef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P W</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="226" to="239" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On principal component analysis, cosine and euclidean measures in information retrieval</title>
		<author>
			<persName><forename type="first">T</forename><surname>Korenius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laurikkala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Juhola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="4893" to="4905" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pruning adaptive boosting</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Margineantu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Machine Learning</title>
		<meeting>the 14th International Conference on Machine Learning<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An analysis of ensemble pruning techniques based on ordered aggregation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Martínez-Munoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Suárez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="259" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning similarity with operator-valued large-margin classifiers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1049" to="1082" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A neural network approach to similarity learning, Artificial Neural Networks in Pattern Recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Melacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maggini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bianchini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Nene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Murase</surname></persName>
		</author>
		<idno>CUCS-006-96</idno>
		<title level="m">Columbia object image library (coil-100)</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Department of Comp. Science, Columbia University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cosine similarity metric learning for face verification</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ACCV 2010</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Support vector machines applied to face recognition</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="803" to="809" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parameterisation of a stochastic model for human face identification</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Samaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Harter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second IEEE Workshop on Applications of Computer</title>
		<meeting>the Second IEEE Workshop on Applications of Computer</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on World Wide Web</title>
		<meeting>the 10th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning similarity with multikernel method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybernet. B: Cybernet</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="138" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Optimal linear combination of neural networks for improving classification performance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="215" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the euclidean distance of images</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1334" to="1339" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mining with rarity: a unifying framework</title>
		<author>
			<persName><forename type="first">G</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor. Newslett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="19" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Artificial Neural Networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yegnanarayana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PHI Learning Pvt. Ltd</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Research on support vector machines and kernel methods</title>
		<meeting><address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Xidian University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Sparse ensembles using weighted combination methods based on linear programming, Pattern Recogn</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ensembling neural networks: many could be better than all</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="239" to="263" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
