<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Heterogeneous Spatiotemporal Network for Lightning Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yangli-Ao</forename><surname>Geng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing Key Lab of Traffic Data Analysis and Mining</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingyong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing Key Lab of Traffic Data Analysis and Mining</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tianyang</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Beijing Key Lab of Traffic Data Analysis and Mining</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>jzhang@bjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Beijing Key Lab of Traffic Data Analysis and Mining</orgName>
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liangtao</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory of Severe Weather</orgName>
								<orgName type="institution">Chinese Academy of Meteorological Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wen</forename><surname>Yao</surname></persName>
							<email>yaowen@cma.gov.cn</email>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory of Severe Weather</orgName>
								<orgName type="institution">Chinese Academy of Meteorological Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Zheng</surname></persName>
							<email>zhengdong@cma.gov.cn</email>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory of Severe Weather</orgName>
								<orgName type="institution">Chinese Academy of Meteorological Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weitao</forename><surname>Lyu</surname></persName>
							<email>wtlyu@cma.gov.cn</email>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory of Severe Weather</orgName>
								<orgName type="institution">Chinese Academy of Meteorological Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Heterogeneous Spatiotemporal Network for Lightning Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/ICDM50108.2020.00121</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>heterogeneous spatiotemporal data mining</term>
					<term>Gaussian diffusion</term>
					<term>Bayesian inference</term>
					<term>weather prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Lightning prediction is a complicated and challenging task requiring that meteorologists integrate information from multiple data sources to make decisions. Although some data-driven models have been proposed to make prediction automatically, most of them are based on a single data source or several basically-homogeneous data sources, making them hard to adapt to complex and diverse data in practice. In this work, we propose a heterogeneous spatiotemporal network (HSTN) for lightning prediction, aiming at mining knowledge from several heterogeneous spatiotemporal (ST) data sources. Specifically, HSTN comprises three modules: Gaussian diffusion module, ST encoder and ST decoder. Noting that most of meteorological data can be formatted into either a dense ST tensor or a sparse ST tensor, the ST encoder, with the help of the Gaussian diffusion module, is designed to extract information from both two types of tensors. On the other hand, ST decoder is responsible for merging all information from the other modules and generate the final prediction. By organically combining the three modules, HSTN can handle complex input with heterogeneity in both space and time domains. Besides, we propose a multi-scale pooling loss to deal with the short-sight problem caused by grid-wise losses. We conduct experimental evaluations on a real-world lightning dataset. The results demonstrate that HSTN achieves state-of-theart performance compared with several established baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Lightning is a naturally occurring electrostatic discharge with the release of massive energy, often accompanied by heavy rainfall, hail, and strong wind <ref type="bibr" target="#b0">[1]</ref>. It is a common but dangerous natural phenomenon, posing huge threats to human life, aviation and electrical infrastructures <ref type="bibr" target="#b1">[2]</ref>. The great harm of lightning has driven significant interest in the prediction of this natural hazard <ref type="bibr" target="#b2">[3]</ref>.</p><p>Traditional lightning prediction methods can be roughly divided into two major categories: extrapolation based nowcasting and numerical weather prediction (NWP) based forecasting. The extrapolation based nowcasting <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> first identifies thunderstorm area and tracks their movements from the past observations (e.g. satellite and radar images), and then makes a prediction based on the momentum of the thunderstorm track (i.e. extrapolation). Its prediction accuracy relies heavily on the consistency of the thunderstorm development before and after, prohibiting extrapolation based methods to be applied for a long-term (e.g. more than two hours) prediction. In contrast, the NWP based forecasting can simulate long-term weather evolution by solving complex atmospheric equations with the support of powerful computers. Then the lightning prediction is conducted by a series of empirical functions <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> with the simulated atmospheric parameters as input. However, since these methods are fully based on NWP simulations, their performance is bounded by the simulation quality.</p><p>In the past ten years, the success of machine learning has inspired some researchers applying data-driven models to weather predictions. Early works <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> usually treat machine learning as a black box, simply exploiting it to replace empirical functions in the prediction process. However, the performance of traditional machine learning models highly relies on the form of input features, and good results usually require appropriate feature engineering. This limits the application of these models to meteorology considering that meteorologists usually face massive heterogeneous noisy data. In recent years, this situation has improved as the development of deep neural networks (DNNs), whose high flexibility and strong modeling capacity rescue users from intricate feature engineering. Many researchers managed to apply DNNs to weather predictions <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b12">[13]</ref>. Among these works, Wang et al. <ref type="bibr" target="#b11">[12]</ref> and Geng et al. <ref type="bibr" target="#b12">[13]</ref> both propose to predict weather via DNN models combining historical observations and NWP simulations, which are meaningful attempts to enhance the weather prediction by fusing dual data sources with heterogeneity in time.</p><p>Back to the lightning prediction, we still need to overcome three difficulties. Firstly, given the complex and dynamic nature of thunderstorms <ref type="bibr" target="#b0">[1]</ref>, the performance of nowcasting methods based on past observations usually drop for a longperiod prediction. Secondly, as a basic tool, the NWP system usually produces simulations with deviations in both space and time domains, which introduces irreparable biases to the prediction methods based on them <ref type="bibr" target="#b12">[13]</ref>. Thirdly, despite the rich information sources for the lightning prediction, valuable knowledge is scattered among massive heterogeneous spatiotemporal (ST) data (an example is shown in Figure <ref type="figure">1</ref>), which is hard to extract to enhance the prediction quality.</p><p>To meet the above challenges, we propose a heteroge-Fig. <ref type="figure">1</ref>: The heterogeneous spatiotemporal structure of data in our task. On one hand, the (station and lightning) observation data and the (WRF) simulation data describe weather situations for different periods (the past and the future). On the other hand, the sparse structure of the station observation distinguishes it from the other data. We seek to extract information from these heterogeneous data and produce a lightning prediction.</p><p>neous spatiotemporal network (HSTN) for lightning predictions. Unlike previous prediction models learning from one data source or several basically-homegeneous data sources, HSTN aims at mining knowledge from several heterogeneous ST data sources, where the ST heterogeneity is an obvious characteristic of meteorological data. This designation helps to not only utilize complementary information in different data sources but also reduce the risk of errors from one single data source. Specifically, HSTN comprises three modules: Gaussian diffusion module, ST encoder and ST decoder. Considering that most of meteorological data can be formatted into either a dense ST tensor or a sparse ST tensor, the Gaussian diffusion module is responsible for converting a sparse ST tensor into a dense form, and then the ST encoder intends to extract task-related information from several dense ST tensors (maybe heterogeneous in time). Finally, the ST decoder seeks to fuse all information and produce the final prediction. By organically combining the three modules, HSTN can handle complex input with heterogeneity in both space and time domains. The contributions of this work are summarized as follows:</p><p>1) We propose HSTN for lightning predictions, which can mine knowledge from several heterogeneous ST data sources. 2) A Gaussian diffusion module is proposed to convert a sparse ST tensor into a dense form. It is computationefficient and completely compatible with the DNN framework. 3) We design a multi-scale pooling loss to deal with the short-sight problem (to be explained in Section IV-D) caused by grid-wise losses for lightning predictions.</p><p>The rest of this paper is organized as follows. In Section II, we discuss the related works. Section III introduces the preliminaries. Section IV details the proposed HSTN. Experimental results are demonstrated in Section V. Finally, we conclude this paper in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Lightning prediction. NWP based methods are now the mainstream for general lightning predictions. Here we focus on some classical works. As a pioneering work, Price and Rind <ref type="bibr" target="#b13">[14]</ref> bridge the relation between lightning frequency and maximum vertical velocity (or convective cloud top height), and propose the well-known PR92 lightning parameterization scheme. Many works have developed from PR92. Michalon et al. <ref type="bibr" target="#b14">[15]</ref> propose a new parameterization by combining PR92 and cloud droplet concentration. Mccaul et al. <ref type="bibr" target="#b1">[2]</ref> propose two approaches based on the upward fluxes of precipitating ice hydrometeors in the mixed-phase region and the vertically integrated amounts of ice hydrometeors, respectively. Qie et al. <ref type="bibr" target="#b15">[16]</ref> utilized an empirical formula with the ice-phase mixing ratio to connect the total lightning flash rate with icephase particles. Theoretically, the NWP based methods can achieve accurate long-term predictions provided high-grade NWP simulation. In practice, however, their performance is susceptible to the inevitable errors in the NWP process, which motivates us to synthesize multi-source data to produce a more robust prediction.</p><p>DNN based weather pattern mining. As a breakthrough work, Shi et al. <ref type="bibr" target="#b9">[10]</ref> develop the conventional LSTM and propose convolutional LSTM (ConvLSTM), with an application to precipitation nowcasting. ConvLSTM now has become a basic tool for ST data mining. Furthermore, they also proposed the Trajectory GRU model <ref type="bibr" target="#b16">[17]</ref> that improves ConvLSTM by actively learning the recurrent connection structure. Wang et al. <ref type="bibr" target="#b10">[11]</ref> presents a predictive recurrent neural network (PredRNN) in the light of the idea that ST predictive learning should memorize both spatial appearances and temporal variations in a unified memory pool. Schon et al. <ref type="bibr" target="#b0">[1]</ref> propose to nowcast lightning based on the error of two-dimensional optical flow algorithms applied to images of meteorological satellites, which provides a new view for nowcasting tasks. Wang et al. <ref type="bibr" target="#b11">[12]</ref> and Geng et al. <ref type="bibr" target="#b12">[13]</ref> propose to predict future weather by combining information from both historical data and NWP simulation, which shares a similar motivation with us. In our work, however, we consider a more challenging scenario-enhancing the weather prediction by mining knowledge from several heterogeneous ST data sources.</p><p>Deep ST model. Recently, some deep models are proposed to handle ST data, such as PredCNN <ref type="bibr" target="#b17">[18]</ref>, StepDeep <ref type="bibr" target="#b18">[19]</ref>, Hetero-ConvLSTM <ref type="bibr" target="#b19">[20]</ref>, DML <ref type="bibr" target="#b20">[21]</ref> and CoST-Net <ref type="bibr" target="#b21">[22]</ref>. Pred-CNN <ref type="bibr" target="#b17">[18]</ref> designs a cascade multiplicative unit and models the dependencies between the next frame and the ST inputs by an entirely CNN based architecture. StepDeep <ref type="bibr" target="#b18">[19]</ref> formulates the problem of mobility event predictions as an ST mining task and then designs a spatial-temporal progress cell to solve it. Hetero-ConvLSTM <ref type="bibr" target="#b19">[20]</ref> is the first work seeking to address the spatial heterogeneity of ST data, which introduces spatial graph features and spatial model ensemble on top of the basic ConvLSTM. DML <ref type="bibr" target="#b20">[21]</ref> proposes a meta graph attention module and a meta recurrent module to capture diverse spatial and temporal correlations, respectively, based on which a sequence-to-sequence network is built to deal with ST urban traffic data. CoST-Net <ref type="bibr" target="#b21">[22]</ref> decomposes each time slice of ST data into a combination of hidden spatial demand bases, and thus the combination weights instead of the raw slice are sent into a heterogeneous LSTM net to make a prediction. Based on the above works, we consider a more general problem-how to handle various ST data with heterogeneity in both space and time domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARY</head><p>We first introduce the heterogeneous ST data used in our work, and then define the problem to be solved. Throughout the paper, we use Italic lowercase (x), Italic capital (X), boldface lowercase (x), boldface capital (X) and Calligraphic (X ) symbols to denote scalars, tensors, vectors, matrices and general sets, respectively. I, 0 and 1 represent the identity matrix, the zero matrix and the all-one vector, respectively, whose dimensions are determined by the context. x and X denote the 2 vector norm of x and the 2 operator norm of X, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Heterogeneous Spatiotemporal Data</head><p>As illustrated in Figure <ref type="figure">1</ref>, the model inputs comprise several types of data, each of which possesses its own ST structure. Next, we separately introduce them according to their structures.</p><p>1) WRF Simulation: The Weather Research and Forecasting (WRF) Model <ref type="bibr" target="#b22">[23]</ref> is a next generation numerical weather prediction system designed for both atmospheric research and operational forecasting applications. The WRF model can provide abundant weather-parameter simulations for future several hours, with each parameter characterized by a fourdimensional tensor, where the four dimensions are longitude (x), latitude (y), altitude (z) and time scale (t), respectively. Specifically, for a simulation tensor X, X x,y,z t stores the simulation value in a grid with an ST coordinate (x, y, z, t), and X t (a three-dimensional tensor) denotes the slice at the t-th hour. Following <ref type="bibr" target="#b12">[13]</ref>, we choose simulated micro-physical parameters, radar reflectivity and maximum vertical velocity as our input. We concatenate all parameters along the z direction and form a comprehensive WRF tensor W</p><formula xml:id="formula_0">= [W t ] p−1 t=0</formula><p>, where p is the number of simulation hours and W t comprises the simulated parameters at the t-th hour.</p><p>2) Lightning Observation: Considering the temporal correlation of thunderstorms, we introduce past lightning observation data <ref type="bibr" target="#b12">[13]</ref> into the input. Following the structure of the WRF simulation data, we format the light observation records into a three-dimensional tensor L with indexes (x, y, t), where L x,y t is a binary value indicating whether lightning happened during the period of [t, t + 1) in (x, y). We exploit the past l hours observations (i.e.</p><formula xml:id="formula_1">L = [L t ] −1 t=−l ).</formula><p>3) Weather Station Observation: We further employ the observation data from weather stations, which are sparsely distributed in the spatial plane. Each station can provide single-point observations of various weather parameters for the past hours. We select three lightning-related parameters <ref type="bibr" target="#b2">[3]</ref> (i.e. average temperature, average relative humidity and precipitation) as our input. We use the observation for past s hours and denote it as S = [ St ] −1 t=−s . Different from the previous two data (W and L), S is a four-dimensional sparse tensor (as illustrated in Figure <ref type="figure">1</ref>), where the value of most grids is none (unobservable). Moreover, this data also faces a data missing challenge. Specifically, letting | • | denote the number of observable cells for a sparse tensor •, we may have</p><formula xml:id="formula_2">| St1 | = | St2 | for t 1 = t 2 .</formula><p>This raises the bar for our model. t=−s (real four-dimensional sparse tensor) for past s hours, our target is to predict the lightning occurrence L = [ Lt ] p−1 t=0 (binary three-dimensional tensor) for next p hours, where W , L, and L share the same x-y scope and resolution. Here we should emphasize the heterogeneous ST structure of our data, as illustrated in Figure <ref type="figure">1</ref>. On one hand, the simulation data (W ) and the observation data (L and S) describe weather situations for different periods (the past and the future). On the other hand, the sparse structure of ( S) distinguishes it from other dense tensors (W and L). We seek to mining knowledge from these heterogeneous data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Problem Definition</head><p>During the training stage, the ground-truth lightning occurrence L = [L t ] p−1 t=0 is known to us. Our task can be formulated as the following optimization problem:</p><formula xml:id="formula_3">min θ E (W,L, S,L )∼T loss( L, L ) s. t. L f θ (W, L, S), θ ∈ Θ,<label>(1)</label></formula><p>where T denotes the training set and f θ is a function characterized by θ constrained in Θ. In this paper, we exploit neural networks to model f θ , and thus θ denotes the network parameters.</p><p>IV. HETEROGENEOUS SPATIOTEMPORAL NETWORK This section presents the architecture of the proposed heterogeneous spatiotemporal network (HSTN), as illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. Section IV-A introduces the Gaussian diffusion module to convert the sparse tensor S into a dense form S. Section IV-B depicts the ST encoder, whose structure is shared by three components to process W , L and S, respectively. Section IV-A displays the ST decoder which merges all information and generates the lightning prediction. Finally, we detail the multi-scale pooling loss in Section IV-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gaussian Diffusion Module</head><p>This module receives the sparse tensor S and outputs a dense tensor S. If we treat this module independently of the others, the task is reduced into a tensor completion (or interpolation) problem. However, this isolation prohibits the module from communicating with the final loss. We design the Gaussian diffusion module to densify S in light of the final loss.</p><p>To begin with, let us consider a slice S:,:,k t (a sparse matrix, i.e. the k-th parameter of the t-th hour) of S. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, the shaded and the plain grids denote the observable and the unobservable grids, respectively. The intuition is that the value of each grid should be related to its neighbors. Specifically, for some grid s i (where i uniquely corresponds to a (x, y) and thus s i uniquely indicates a grid in S:,:,k t ), we model the relation from s i to its neighbors N (s i ) by the following Gaussian conditional probability distribution:</p><formula xml:id="formula_4">p (s i |N (s i )) 1 √ 2πσ i • exp − 1 2σ 2 i s i − sj ∈N (si) w ij s j 2 ,<label>(2)</label></formula><p>where w ij weights the neighbor s j and σ i adjusts the strength of the correlation. Next, considering the whole x-y space of S:,:,k t , let s o and s u be two vectors collecting all observable grids and unobservable grids of S:,:,k t , respectively. Following <ref type="bibr" target="#b23">[24]</ref>, we define the joint pseudo-likelihood of s o and s u as</p><formula xml:id="formula_5">p(s o , s u ) n i=1 p (s i |N (s i )) = 1 (2π) n/2 √ Σ exp − 1 2 (Ws−s) T Σ −1 (Ws − s) ,<label>(3)</label></formula><p>where n is the number of total grids of S:,:,k</p><formula xml:id="formula_6">t , s = [s o T , s u T ] T ∈ R n , W ∈ R n×n collects {w ij } j in its i- th row and Σ ∈ R n×n collects σ 2</formula><p>i as its i-th diagonal elements for 1 ≤ i ≤ n. Although p may not be properly normalized, previous work <ref type="bibr" target="#b24">[25]</ref> has shown that maximizing p is asymptotically consistent with the true maximum likelihood estimator. Based on (3), our goals become</p><formula xml:id="formula_7">• Estimation: Ŵ, Σ = arg max W,Σ ln p(s o |W, Σ) = arg max W,Σ ln su p(s o , s u |W, Σ).<label>(4)</label></formula><p>• Inference:</p><formula xml:id="formula_8">ŝu = arg max su ln p(s o , s u | Ŵ, Σ).<label>(5)</label></formula><p>We settle (5) first, and then (4) can be naturally solved by the EM algorithm. Solving ( <ref type="formula" target="#formula_8">5</ref>) is equivalent to maximizing</p><formula xml:id="formula_9">ln p(s o , s u | Ŵ, Σ) = − 1 2 Σ−1/2 ( Ŵ − I)s 2 + c = − 1 2 b − As u 2 + c,<label>(6)</label></formula><p>where c is a constant independent of s u ,</p><formula xml:id="formula_10">A = Σ−1/2 1 Ŵ12 Σ−1/2 2 ( Ŵ22 − I)<label>(7)</label></formula><p>and For simplicity, we only display the 3 × 3 neighbors, which can be extended according to requirements.</p><formula xml:id="formula_11">b = Σ−1/2 1 ( Ŵ11 − I)s o Σ−1/2 2 Ŵ21 s o .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Iteration</head><formula xml:id="formula_12">Input: s o , Ŵ, Σ Initialize s (0) u = 0 for i = 0, 1, . . . do s (i+1) u =s (i) u +α (i) [0 I] b − As (i) u =s (i) u +α (i) [0 I] Σ−1/2 Ŵ−I s (i) convolution locally-connected</formula><p>where</p><formula xml:id="formula_13">s (i) = [s o T , s (i) u T ] T . end for return [s T o , ŝT u ] T</formula><p>Maximizing (6) can be further simplified as</p><formula xml:id="formula_14">min su b − As u 2 ,<label>(9)</label></formula><p>which is a least square problem with the optimal solution s u = A † b. However, calculating the pseudo inverse A † is not only computation-consuming but also barely compatible with the DNN framework. Inspired by the Richardson method <ref type="bibr" target="#b25">[26]</ref>, we propose to solve (9) via an iteration method shown in Algorithm 1. The following proposition presents its convergence characteristics.</p><formula xml:id="formula_15">Proposition 1. Suppose that 0 &lt; α (i) ≤ 1 (i = 0, 1, . . . ), ∞ l=0 α (i) = a &lt; ∞, Σ−1/2 ≤ 1 and Ŵ ≤ 1 −</formula><p>, where is a small positive constant. The iteration in Algorithm (1)</p><formula xml:id="formula_16">will converge to ŝu with b − Aŝ u ≤ (1 + 2a) b − As u ,<label>(10)</label></formula><p>where s u is the optimal solution to (9).</p><p>Proof. See appendix.</p><p>The superiority of Algorithm 1 lies in that all its operations are simple matrix addition and multiplication, and thus completely compatible with the DNN framework. Specific to our task, W and Σ −1/2 are implemented as a 5 × 5 convolution layer and a 1 × 1 locally-connected layer with constraints, </p><p>The expectation in <ref type="bibr" target="#b10">(11)</ref> can be estimated as <ref type="bibr" target="#b23">[24]</ref>:</p><formula xml:id="formula_18">E p(su|so, Ŵ, Σ) ln p(s o , s u |W, Σ) ≈ ln p(s o , ŝu |W, Σ), (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where ŝu is provided by Algorithm 1. Thus we add the following objective function into the final loss:</p><formula xml:id="formula_20">d = − t,k ln p(s k t |W k , Σ k ),<label>(13)</label></formula><p>where s k t , W k , Σ k are defined in Algorithm 2. {W k } 3 k=1 and {Σ k } 3 k=1 will be optimized via backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. ST Encoder</head><p>Given a dense ST tensor, the ST encoder aims to extract the task-related knowledge from it. This task fits perfectly with the convolutional long short-term memory (ConvLSTM) <ref type="bibr" target="#b9">[10]</ref>, which has proven successful in processing ST tensors. Following the conventional notations, let X t , C t and H t denote the input, the cell state and the hidden state of ConvLSTM at the t-th moment, respectively. A ConvLSTM cell is characterized by the following equations:  Next, we build our ST encoder based on ConvLSTM. Specifically, for a given ST tensor (X = [X t ] τ2 t=τ1 ), we initialize all states of ConvLSTM as zero (i.e. C τ1−1 = 0 and H τ1−1 = 0), and then recurrently feed X t into the ConvLSTM as input for τ 1 ≤ t ≤ τ 2 . Finally, we return the cell state (C τ2 ) and the hidden state (H τ2 ) of the last step as the outputs of the ST encoder.</p><formula xml:id="formula_21">Z i t = σ(P xi * X t + P ci • C t−1 + P hi * H t−1 + B i ), Z f t = σ(P xf * X t + P cf • C t−1 + P hf * H t−1 + B f ), C t = Z f t • C t−1 + Z i t • tanh(P xc * X t + P hc * H t−1 + B c ), Z o t = σ(P xo * X t + P ho * H t−1 + P co • C t + B o ), H t = Z o t • tanh(C t ),</formula><p>The ST encoder provides an effective way to summarize information from ST tensors. We exploit it to process the WRF simulation W , the lightning observation L, and the densified weather station observation S. Specifically, their features are extracted by</p><formula xml:id="formula_22">C W , H W = ST encoder W (W ), C L , H L = ST encoder L (L),</formula><p>C S , H S = ST encoder S (S). These features will be fed into the ST decoder to produce lightning predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. ST Decoder</head><p>This module summarizes all state information come from the ST encoders and infer the prediction L. Following the same reason presented in Section IV-B, ConvLSTM also applies to the ST decoder. Before feeding all state tensors into a ConvLSTM, we perform a convolution operation with relu activation to transform them into a uniform state space:</p><formula xml:id="formula_23">Ck = Conv2D C,k (C k ) (k ∈ {"W ", "L", "S"}), Hk = Conv2D H,k (H k ) (k ∈ {"W ", "L", "S"}), C = Concatenate( CW , CL , CS ), H = Concatenate( HW , HL , HS ),</formula><p>where C and H encapsulate the information from three ST encoders, which will be set as the initial states of ConvLSTM. After that, we recurrently run ConvLSTM p steps: Finally, we employ a convolution layer with sigmoid activation to transform the outputs of ConvLSTM into the lightning prediction:</p><formula xml:id="formula_24">C −1 = C, H −1 = H, C t , H t =ConvLSTM(C t−1 , H t−1 ) (t = 0, . . . , p − 1).</formula><formula xml:id="formula_25">Lt = Conv2D L (H t ) (t = 0, . . . , p − 1)</formula><p>The difference between L and L will be measured by the proposed multi-scale pooling loss, detailed in Section IV-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Multi-scale Pooling Loss</head><p>Since lightning is a rare event compared to no lightning, the spatial distribution of lightning demonstrates sparsity, causing a short-sight problem to grid-wise measures. Taking Figure <ref type="figure" target="#fig_5">4</ref> as an example, the blue and the green grids represent the real-lightning and the predicted-lightning grids, respectively. We intuitively deem that the prediction in Figure <ref type="figure" target="#fig_5">4a</ref> is better than that in Figure <ref type="figure" target="#fig_5">4b</ref>, since the former is "closer" to the real-lightning area than the latter. However, we get the same grid-wise loss for both cases, i.e. no real-lightning grids are hit for both cases.</p><p>We propose the multi-scale pooling loss to meet this challenge. The idea is measuring the difference between the prediction and the groundtruth from multiple scales. A largescale loss tries to "pull" misplaced predictions closer to reallightning areas while a small-scale loss is responsible for adjusting the "contour" of predictions to fit the distribution of real-lightning. Furthermore, we choose the weighted cross entropy (mean weighted CE) to balance the quantity gap between lightning and no-lightning grids. We detail the multiscale pooling loss in Algorithm 3, in which {w k } 3 k=1 and {r k } 3 k=1 are the weights of positive grids and the ratios for three scales, respectively. Finally, we summarize the data flow of HSTN in Algorithm 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiments Setup</head><p>Parameter setting. We empirically determine the parameters of HSFN. For the parameters of the Gaussian diffusion module (cf. Section IV-A), the iteration number q is set to 20 and the decay factor α (i) is set to 0.95 i for 1 ≤ i ≤ q. The convolution kernel corresponding to W is constrained to be positive and hollow (i.e. diag(W) = 0), with sum equaling Algorithm 4 Heterogeneous ST network</p><formula xml:id="formula_26">Input: W, L, S, L 1: S = Gaussian diffusion( S) 2: d = − t,k ln p(s k t |W k , Σ k ) (cf. (<label>13</label></formula><formula xml:id="formula_27">)) 3: C W , H W = ST encoder W (W ) 4: C L , H L = ST encoder L (L) 5: C S , H S = ST encoder S (S) 6: L = ST decoder(C W , H W , C L , H L , C S , H S ) 7: m = Multi-scale pooling loss( L,L ) 8: return = λ d + (1 − λ) m</formula><p>TABLE I: The detailed information for three performance metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Equation Range Explanation</head><p>POD</p><formula xml:id="formula_28">n 1 n 1 +n 3 [0,1]</formula><p>The ratio of the number of hit lightnings to the number of observed lightnings. Larger is better. FAR</p><formula xml:id="formula_29">n 2 n 1 +n 2 [0,1]</formula><p>The ratio of the number of false alarm lightnings to the number of foretasted lightnings. Smaller is better. ETS</p><formula xml:id="formula_30">n 1 −r n−n 4 −r [− 1 3 , 1]</formula><p>The ratio of the number of hit lightnings to the number of events except for the correct rejections, and removed the contribution from hits by chance in random forecasts. Larger is better.</p><p>0.98 (i.e. W1 = 0.98 • 1). The diffusion variance Σ is set to the identity matrix. For the parameters related to the loss function (cf. Section IV-D), w 1 , w 2 , w 3 , r 1 , r 2 , r 3 and λ are set to 18, 6, 2, 0.6, 0.3, 0.1 and 0.05, respectively. We optimize the model by the Adam method <ref type="bibr" target="#b26">[27]</ref> with an initial learning rate 1×10 −4 . The batch size and epoch number are set to 8 and 30, respectively. Our code was released on GitHub.</p><p>Dataset. We consider a real lightning dataset of North China. Specifically, this region is a square with a center at 40°N and 116.2°E, which is divided into 159 × 159 grids and each grid has a resolution of 4km × 4km. The number of weather stations is 237, leading to a sparsity ratio 237/(159 × 159) ≈ 0.001. The number of input hours p, l and s (cf. Section III-B) are 6, 3 and 6, respectively. p = 6 implies that our task is to predict lightning for next six hours. The periods of data cover June to September in 2015, and May to September in both 2016 and 2017, 14 months in total. Following <ref type="bibr" target="#b12">[13]</ref>, we chronologically divide the total dataset by a ratio of 11:1:2 for training, validation and testing. Since there are too many samples containing no 318 lightning, which take little effect on our task, we remove them from the original dataset. As a result, the number of samples in the training set, the validation set and the test set becomes 3656, 449 and 236, respectively.</p><p>Baselines. We compare the proposed HSTN with the following baseline models: PR92 <ref type="bibr" target="#b27">[28]</ref>, LF1 <ref type="bibr" target="#b28">[29]</ref>, LF2 <ref type="bibr" target="#b28">[29]</ref>,</p><p>StepDeep <ref type="bibr" target="#b18">[19]</ref>, StepDeep+, LightNet <ref type="bibr" target="#b12">[13]</ref> and LightNet+, where the methods with suffix "+" mean that the bicubic interpolation of weather-station features are added into their input, to distinguish from the results only employing WRF simulation and light observation as reported in <ref type="bibr" target="#b12">[13]</ref>. Among these baselines, the first three are traditional lightning prediction methods and the others are DNN-based models. In addition, we also introduce two variants (HSTN-grid and HSTN-interp) of HSTN for comparison. They are formed by replacing the multi-scale pooling loss and the Gaussian diffusion module of HSTN by a grid-wise loss and bicubic interpolation, respectively. We repeatedly train each model three times and select the one with the best validation score.</p><p>Performance metric. We evaluate the prediction results by three metrics: probability of detection (POD), false alarm ratio (FAR) and equitable threat score (ETS), which have been widely applied in meteorology <ref type="bibr" target="#b29">[30]</ref>. Let n denote the total number of grids. Let n 1 , n 2 , n 3 and n 4 denote the number of true-positive, false-positive, false-negative and true-negative grids, respectively. Define the expectation of the number of hit lightnings in random forecasts as r = (n 1 + n 2 )(n 1 + n 3 )/n. The equations for the three metrics are detailed in Table <ref type="table">I</ref>. Following <ref type="bibr" target="#b12">[13]</ref>, we also calculate eight-neighborhood-based POD, FAR and ETS, where {n i } 4</p><p>i=1 is replaced by the eightneighborhood-based statistics {ñ i } 4 i=1 <ref type="bibr" target="#b29">[30]</ref>. We evaluate the prediction results over three periods, i.e. the first three hours, last three hours and all six hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Effect of data sources</head><p>The first experiment is to investigate whether exploiting heterogeneous data sources helps to achieve better prediction accuracy. We evaluate the performance of our HSTN model trained on different combinations of data sources including WRF simulation (WRF), lightning observation (LIG) and weather station observation (STA).</p><p>From the upper part of Table <ref type="table">II</ref>, we notice that all three single data sources obtain positive ETSs over all prediction periods, indicating each of them contains information conducive to the lightning prediction. Among them, LIG displays surprisingly better performance than the other two data sources, owing to the strong correlation between the past lightning and the future lightning. This correlation, however, becomes weaker and weaker as the prediction time goes by, causing a performance drop over last three hours. A similar phenomenon also applies to the STA prediction from first three hours to last three hours. In contrast, for WRF, the performance decay from first three hours to last three hours is much less obvious, since the simulation data is not as dependent on timeliness as the observation data.</p><p>As shown in the middle part of Table <ref type="table">II</ref>, the combinations of different sources boost the prediction accuracy more or less in most circumstances. Among the three combinations, WRF+LIG obtains very promising results, which are close to the best results by employing all data sources. Meanwhile, WRF+STA achieves obvious improvements in comparison with both WRF and STA over all prediction periods. The above two cases validate the effectiveness of the combination of simulation data and observation data, which contain complementary information about thunderstorms. On the other hand, although LIG+STA achieves much better results than TABLE II: Quantitative results (POD(%), FAR(%) and ETS) of HSTN on combinations of various data sources. The best performance is reported using bold red, and the second best is reported using bold blue. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Quantification Results</head><p>As show in Table <ref type="table" target="#tab_2">III</ref>, the upper, middle and lower parts report the results of three meteorologic methods, four DNNbased baselines and HSTN with its variations, respectively. We first notice a huge performance gap between the meteorologic methods and the DNN models. The poor performance of meteorologic baselines can be explained in two ways. Firstly, they are completely based on the WRF simulation, which usually have deviations in both space and time domains, introducing irreparable biases to these methods. Secondly, these methods are essentially some simple functions designed empirically, which can hardly model the complicated relations among various meteorologic parameters and benefit from massive historical data. In contrast, the DNN-based methods own much stronger modeling capabilities and can mine knowledge from training data, helping them achieve significantly higher prediction accuracy.</p><p>Among the DNN-based baselines, we observe that the models (StepDeep+ and LightNet+) with the weather-station input achieve overall better performance than those (StepDeep and LightNet) without it, validating the effectiveness of this newly added input. However, these improvements are limited and unstable since they just treat the weather-station observation as a new "channel" of the input tensor, without in-depth exploration of the special structure inside this feature.</p><p>In contrast, HSTN obtains overall better results than three interpolation-based methods (StepDeep+, LightNet+ and HSTN-interp), indicating that the proposed Gaussian diffusion module, which considers the prediction loss as a supervisor, extracts more informative representation than the plain unsupervised interpolation. Here we should emphasize that the lastthree-hour score is much more important than the first-threehour score, and improving the former is much harder than the latter. On the other hand, HSTN achieves better performance than HSTN-grid over all prediction periods, implying that multi-scale pooling loss is more effective than the grid-wise loss for the lightning prediction task. Next, we focus on the three representative methods (StepDeep+, LightNet+ and HSTN) and compare their performance for different prediction periods as follows:</p><p>1) First-three-hour prediction. Among the three models,</p><p>StepDeep+ and LightNet+ share similar FARs, but a higher POD brings LightNet+ a higher ETS than StepDeep+. In contrast, HSTN obtains the highest POD, while a high FAR lowers its ETS. In general, Light-Net+ achieves the best performance over this prediction period. But the performance gap is not large between LightNet+ and HSTN. 2) Last-three-hour prediction. Compared with the first three hours, prediction over this period is much harder since the pattern of thunderstorms becomes almost unforeseeable after a three-hour development. As a result, the performance indicators of all methods dropped significantly. In this case, HSTN surprisingly displays a much higher POD while a smaller FAR than the two other baselines. Specifically, the strict POD of HSTN is about 20% and 200% higher than the second place (LightNet+) and the third place (StepDeep+), respectively, which brings HSTN an absolute superiority in ETS over this period. These results indicate that HSTN learns a more longterm pattern of thunderstorms by synthesizing information in multi-source data. 3) Six-hour prediction. HSTN achieves the highest POD and ETS on both strict and neighborhood-based metrics, although its FAR is slightly higher than the second place, LightNet+. LightNet+ obtains a very competitive ETS, but it is at the expense of a lower POD, which is an undesirable thing in the prediction task. For StepDeep+, the poor results over the last three hours cause its unsatisfactory overall performance over the six hours.</p><p>In summary, HSTN demonstrates the overall best performance among all models under test. It achieves superior prediction accuracy over last three hours, though at the cost of a little high FAR over first three hours.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Visualization Results</head><p>Figure <ref type="figure" target="#fig_6">5</ref> visualizes four representative cases for StepDeep+, LihgtNet+ and HSTN. We observe that all methods make a better prediction for first three hours, which benefits from the trend information provided by the observation data. On the other hand, although the performance of all models drops over last three hours, HSTN displays a higher prediction accuracy than the other two baselines, which is consistent with the quantification results shown in Table <ref type="table" target="#tab_2">III</ref>. Specifically, StepDeep+ and LihgtNet+ tend to predict no lightning over last three hours, since for them the gain of POD fails to offset the drawback of FAR in this period. In contrast, HSTN captures the core thunder zone though at risk of a little high FAR. Particularly, Figure <ref type="figure" target="#fig_6">5d</ref> shows a case where thunderstorms gradually disappear. We find that HSTN anticipates the disappearing trend earlier than the other two baselines. The above results validate the superiority of HSTN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>This paper investigated to solve the lightning prediction problem via a DNN model (HSTN) extracting information from several heterogeneous ST data sources. Noting that most of meteorological data can be formatted into either a dense ST tensor or a sparse ST tensor, HSTN employs the Gaussian diffusion module to convert a sparse ST tensor into a dense form. Thus, all data sources can be unified into dense ST tensors, which can be effectively processed by the ST encoder and the ST decoder. Besides, we propose a multi-scale pooling loss by measuring the difference between a prediction and the groundtruth from multiple scales, which proves effective in solving the short-sight problem caused by grid-wise losses. Experimental results show state-of-the-art performance on a real-world lightning dataset, which demonstrates the effectiveness of HSTN in mining knowledge from heterogeneous ST data sources. Based on the assumptions α (i) &lt; 1, Σ −1/2 ≤ 1 and Ŵ ≤ 1− , we can infer 0 ≤ β (i) ≤ 1−γ, where γ is a small positive constant. Then we have </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Suppose the current moment is t = 0. Given the WRF simulation W = [W t ] p−1 t=0 (real four-dimensional tensor) for future p hours, the lightning observation L = [L t ] −1 t=−l (binary three-dimensional tensor) for past l hours, and the weather station observation S = St −1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: The architecture of HSTN. The Gaussian diffusion module converts the sparse tensor S into a dense form S. Three ST encoders extract information from W , L and S. The ST decoder merges all information and produces lightning prediction L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: (a) A sparse matrix S:,:,k t . (b) s i and its neighbors N (s i ). For simplicity, we only display the 3 × 3 neighbors, which can be extended according to requirements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 2</head><label>2</label><figDesc>Gaussian diffusion Input: S for k = 1, 2, 3 do Initialize W k and Σ k for t = −s, −s + 1, . . . , −1 do s o = vec( S:,:,k t ) (only observable grids); s k t = Iteration(s o , W k , Σ k ) (cf. Algorithm 1) S :,:,k t = ivec(s k t ) end for end for return [S t ] −1 t=−s respectively. The iteration will stop after q times. Based on Algorithm 1, our Gaussian diffusion module is presented in Algorithm 2, in which vec(•) flattens a matrix • into a vector and ivec(•) is its inverse operation. Utilizing this module, the weather observation sparse tensor S is transformed into a dense tensor S. Now we employ the EM algorithm to solve the remaining (4), which is equivalent to max W,Σ E p(su|so,W,Σ) ln p(s o , s u |W, Σ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>where * , • and σ(•) denote the convolution operator, the Hadamard product and the logistic sigmoid function, respectively. P • and B • are trainable parameters compatible with the corresponding operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Two cases of the lightning prediction: (a) and (b). Reallightning grids and predicted-lightning grids are colored by blue and green, respectively. Intuitively, (a) is better than (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Visualization of four representative cases. In each case, the left part is lightning observations for past three hours, and the right part is predictions for future six hours, where the predictions from top to bottom are made by StepDeep+, LightNet+ and HSTN. The observation, prediction and their intersection are marked by blue (•), dark green (•) and red (•), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>ACKNOWLEDGMENT</head><label></label><figDesc>This work is supported by the National Key Research and Development Program of China (No. 2017YFC1501503) and Beijing Natural Science Foundation (No. L191016).APPENDIXProof of Proposition 1We first derive the bound of s u − s(i+1) u : s u −s (i+1) u = s u −s (i) u −α (i) [0 I] (b−As (i) u ) ≤ s u +α (i) [0 I] (b−As u ) −s (i) u −α (i) [0 I] (b−As (i) u ) + α (i) [0 I] (b−As u ) = [0 I] (s −s (i) )+ +α (i) [0 I] Σ −1/2 (W−I) (s − s (i) ) + α (i) [0 I] (b−As u ) ≤ [0 I] (I+α (i) Σ −1/2 (W−I))(s −s (i) ) + α (i) b−As u ≤ I+α (i) Σ −1/2 (W−I) s −s (i) + α (i) b−As u =β (i) s −s (i) + α (i) b−As u =β (i) s u −s (i) u + α (i) b−As u .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>β</head><label></label><figDesc>(j) s u −s (0) u + i j=0 α (j) b−As u , implying s u −ŝ u = lim i→∞ s u −s (i+1) u ≤ a b−As u .(14)(14) paved the way to the desirable conclusion:b − Aŝ u = b − As u + A(s u − ŝu ) ≤ b − As u + A(s u − ŝu ) ≤ b − As u + 2a b−As u =(1 + 2a) b−As u .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-7.png" coords="3,62.16,56.37,488.83,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The last row of TableIIdemonstrates that the model with all data sources as input achieves the best performance over other models. The above results verify that the aggregation of heterogeneous data sources into our prediction model is helpful to learn more in-depth patterns of the development of thunderstorms.</figDesc><table><row><cell></cell><cell></cell><cell cols="4">First Three Hour Score</cell><cell></cell><cell></cell><cell cols="4">Last Three Hour Score</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Six Hour Score</cell><cell></cell><cell></cell></row><row><cell>Data Source</cell><cell></cell><cell cols="2">Strict Metric</cell><cell cols="3">Neighb.-Based Metric</cell><cell></cell><cell cols="2">Strict Metric</cell><cell cols="3">Neighb.-Based Metric</cell><cell></cell><cell cols="2">Strict Metric</cell><cell cols="3">Neighb.-Based Metric</cell></row><row><cell></cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell>POD</cell><cell>FAR</cell><cell>ETS</cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell>POD</cell><cell>FAR</cell><cell>ETS</cell></row><row><cell>WRF</cell><cell>13.7</cell><cell>84.7</cell><cell>0.074</cell><cell>31.0</cell><cell>60.1</cell><cell>0.207</cell><cell>13.1</cell><cell>88.9</cell><cell>0.059</cell><cell>31.1</cell><cell>68.5</cell><cell>0.180</cell><cell>17.4</cell><cell>80.0</cell><cell>0.095</cell><cell>35.1</cell><cell>52.7</cell><cell>0.244</cell></row><row><cell>LIG</cell><cell>64.1</cell><cell>79.9</cell><cell>0.174</cell><cell>82.9</cell><cell>51.3</cell><cell>0.433</cell><cell>18.7</cell><cell>85.0</cell><cell>0.086</cell><cell>37.3</cell><cell>63.3</cell><cell>0.221</cell><cell>46.1</cell><cell>75.5</cell><cell>0.180</cell><cell>67.7</cell><cell>44.8</cell><cell>0.425</cell></row><row><cell>STA</cell><cell>13.3</cell><cell>85.0</cell><cell>0.071</cell><cell>26.9</cell><cell>65.4</cell><cell>0.174</cell><cell>1.2</cell><cell>95.4</cell><cell>0.007</cell><cell>4.0</cell><cell>83.8</cell><cell>0.031</cell><cell>9.1</cell><cell>82.5</cell><cell>0.058</cell><cell>19.2</cell><cell>60.3</cell><cell>0.142</cell></row><row><cell>WRF+LIG</cell><cell>57.5</cell><cell>78.3</cell><cell>0.181</cell><cell>77.7</cell><cell>48.9</cell><cell>0.438</cell><cell>22.6</cell><cell>81.1</cell><cell>0.110</cell><cell>42.0</cell><cell>55.9</cell><cell>0.269</cell><cell>45.0</cell><cell>72.4</cell><cell>0.196</cell><cell>65.6</cell><cell>40.4</cell><cell>0.443</cell></row><row><cell>WRF+STA</cell><cell>24.9</cell><cell>85.9</cell><cell>0.093</cell><cell>48.8</cell><cell>62.9</cell><cell>0.260</cell><cell>16.6</cell><cell>86.8</cell><cell>0.074</cell><cell>35.5</cell><cell>65.6</cell><cell>0.206</cell><cell>26.1</cell><cell>79.8</cell><cell>0.119</cell><cell>47.5</cell><cell>52.4</cell><cell>0.301</cell></row><row><cell>LIG+STA</cell><cell>62.4</cell><cell>79.5</cell><cell>0.176</cell><cell>81.5</cell><cell>50.7</cell><cell>0.435</cell><cell>17.3</cell><cell>86.8</cell><cell>0.076</cell><cell>36.1</cell><cell>66.2</cell><cell>0.206</cell><cell>45.4</cell><cell>76.1</cell><cell>0.175</cell><cell>66.8</cell><cell>46.0</cell><cell>0.413</cell></row><row><cell>All</cell><cell>60.5</cell><cell>78.1</cell><cell>0.185</cell><cell>80.0</cell><cell>48.4</cell><cell>0.449</cell><cell>26.1</cell><cell>80.9</cell><cell>0.118</cell><cell>46.7</cell><cell>55.1</cell><cell>0.291</cell><cell>48.8</cell><cell>72.6</cell><cell>0.202</cell><cell>69.2</cell><cell>40.4</cell><cell>0.459</cell></row><row><cell cols="9">STA, its performance decreases slightly compared with LIG</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="9">over last three hours. This suggests that information hold by</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="9">STA may partly overlap with LIG, considering that both of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">them are observation data.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Illustration for quantitative results (POD(%), FAR(%), ETS). The best performance is reported using bold red, and the second best is reported using bold blue. "-" indicates that no reported results are available. The method with suffix "+" means that the bicubic interpolation of weather-station features are added into the input.</figDesc><table><row><cell></cell><cell></cell><cell cols="4">First Three Hour Score</cell><cell></cell><cell></cell><cell cols="4">Last Three Hour Score</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Six Hour Score</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell></cell><cell cols="2">Strict Metric</cell><cell cols="3">Neighb.-Based Metric</cell><cell cols="3">Strict Metric</cell><cell cols="3">Neighb.-Based Metric</cell><cell cols="3">Strict Metric</cell><cell cols="3">Neighb.-Based Metric</cell></row><row><cell></cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell>POD</cell><cell>FAR</cell><cell>ETS</cell><cell cols="2">POD FAR</cell><cell>ETS</cell><cell>POD</cell><cell>FAR</cell><cell>ETS</cell><cell>POD</cell><cell>FAR</cell><cell>ETS</cell></row><row><cell>PR92  *</cell><cell>18.0</cell><cell>96.9</cell><cell>0.019</cell><cell>52.1</cell><cell>88.5</cell><cell>0.094</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>23.2</cell><cell>95.2</cell><cell>0.027</cell><cell>54.7</cell><cell>86.1</cell><cell>0.110</cell></row><row><cell>LF1  *</cell><cell>15.6</cell><cell>97.1</cell><cell>0.018</cell><cell>45.3</cell><cell>86.2</cell><cell>0.100</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>18.8</cell><cell>93.8</cell><cell>0.037</cell><cell>47.4</cell><cell>88.0</cell><cell>0.109</cell></row><row><cell>LF2  *</cell><cell>15.0</cell><cell>94.5</cell><cell>0.035</cell><cell>37.7</cell><cell>82.8</cell><cell>0.126</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>19.1</cell><cell>92.0</cell><cell>0.048</cell><cell>39.5</cell><cell>80.5</cell><cell>0.139</cell></row><row><cell>StepDeep  *</cell><cell>42.7</cell><cell>74.1</cell><cell>0.187</cell><cell>67.4</cell><cell>40.2</cell><cell>0.458</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>26.3</cell><cell>70.9</cell><cell>0.152</cell><cell>48.1</cell><cell>35.2</cell><cell>0.373</cell></row><row><cell>StepDeep+</cell><cell>48.1</cell><cell>77.4</cell><cell>0.176</cell><cell>73.6</cell><cell>46.1</cell><cell>0.445</cell><cell>8.0</cell><cell>88.4</cell><cell>0.046</cell><cell>23.0</cell><cell>64.8</cell><cell>0.157</cell><cell>34.2</cell><cell>74.5</cell><cell>0.162</cell><cell>58.9</cell><cell>41.7</cell><cell>0.404</cell></row><row><cell>LightNet  *</cell><cell>59.8</cell><cell>77.7</cell><cell>0.187</cell><cell>80.2</cell><cell>47.4</cell><cell>0.458</cell><cell>22.3</cell><cell>82.8</cell><cell>0.102</cell><cell>42.3</cell><cell>59.1</cell><cell>0.257</cell><cell>46.5</cell><cell>73.3</cell><cell>0.194</cell><cell>68.0</cell><cell>41.3</cell><cell>0.449</cell></row><row><cell>LightNet+</cell><cell>58.6</cell><cell>77.3</cell><cell>0.189</cell><cell>78.7</cell><cell>46.3</cell><cell>0.461</cell><cell>20.4</cell><cell>81.8</cell><cell>0.102</cell><cell>39.0</cell><cell>57.1</cell><cell>0.252</cell><cell>45.9</cell><cell>72.2</cell><cell>0.199</cell><cell>66.6</cell><cell>39.3</cell><cell>0.454</cell></row><row><cell>HSTN-grid</cell><cell>59.7</cell><cell>78.2</cell><cell>0.184</cell><cell>79.2</cell><cell>48.7</cell><cell>0.444</cell><cell>23.0</cell><cell>80.8</cell><cell>0.112</cell><cell>42.3</cell><cell>55.4</cell><cell>0.272</cell><cell>47.3</cell><cell>72.6</cell><cell>0.200</cell><cell>67.5</cell><cell>40.9</cell><cell>0.449</cell></row><row><cell>HSTN-interp</cell><cell>59.9</cell><cell>78.3</cell><cell>0.183</cell><cell>79.8</cell><cell>48.6</cell><cell>0.447</cell><cell>23.6</cell><cell>81.9</cell><cell>0.109</cell><cell>43.7</cell><cell>56.7</cell><cell>0.272</cell><cell>47.6</cell><cell>72.8</cell><cell>0.199</cell><cell>68.4</cell><cell>40.3</cell><cell>0.457</cell></row><row><cell>HSTN</cell><cell>60.5</cell><cell>78.1</cell><cell>0.185</cell><cell>80.0</cell><cell>48.4</cell><cell>0.449</cell><cell>26.1</cell><cell>80.9</cell><cell>0.118</cell><cell>46.7</cell><cell>55.1</cell><cell>0.291</cell><cell>48.8</cell><cell>72.6</cell><cell>0.202</cell><cell>69.2</cell><cell>40.4</cell><cell>0.459</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* Results are reported in<ref type="bibr" target="#b12">[13]</ref>.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The error is the feature: How to forecast lightning using a model prediction error</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schön</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2979" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Forecasting lightning threat using cloudresolving model simulations</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Mccaul</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Weather and Forecasting</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="709" to="729" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Predicting lightning activity in greece with the weather research and forecasting (WRF) model</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Giannaros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric Research</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cell-tracking with lightning data from LINET</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Betz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Geosciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="55" to="61" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nowcasting thunderstorms in the mediterranean region using lightning data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric Research</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="489" to="502" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predicting the potential for lightning activity in mediterranean storms based on the weather research and forecasting (WRF) model dynamic and microphysical fields</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geophysical Research: Atmospheres</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">D4</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evaluating a lightning parameterization based on cloudtop height for mesoscale numerical model simulations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geoscientific Model Development</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="429" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Field identification of a unique globally dominant mechanism of thunderstorm electrification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Latham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of the Royal Meteorological Society</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">627</biblScope>
			<biblScope unit="page" from="1453" to="1457" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Time series prediction using support vector machines: a survey</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Sapankevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="38" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional LSTM network: A machine learning approach for precipitation nowcasting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xingjian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
				<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Predrnn: Recurrent neural networks for predictive learning using spatiotemporal lstms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
				<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="879" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep uncertainty quantification: A machine learning approach for weather forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2087" to="2095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lightnet: A dual spatiotemporal encoder network model for lightning prediction</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2439" to="2447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A simple lightning parameterization for calculating global lightning distributions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geophysical Research: Atmospheres</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">D9</biblScope>
			<biblScope unit="page" from="9919" to="9933" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contribution to the climatological study of lightning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Michalon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysical research letters</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="3097" to="3100" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Application of total-lightning data assimilation in a mesoscale convective system based on the WRF model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric research</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="255" to="266" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning for precipitation nowcasting: A benchmark and a new model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
				<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5617" to="5627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Predcnn: Predictive learning with cascade convolutions</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
				<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2940" to="2947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stepdeep: A novel spatial-temporal mobility event prediction framework based on deep neural network</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="724" to="733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hetero-convlstm: A deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="984" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Urban traffic prediction from spatio-temporal data using deep meta learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1720" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Co-prediction of multiple transportation demands based on deep spatio-temporal neural network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM KDD</title>
				<meeting>ACM KDD</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="305" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A description of the Advanced Research WRF Version 3</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Skamarock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Center for Atmospheric Research</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">GMNN: Graph Markov neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="5241" to="5250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pseudolikelihood EM for within-network relational learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICDM</title>
				<meeting>IEEE ICDM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1103" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The approximate arithmetical solution by finite differences of physical problems involving differential equations, with an application to the stresses in a masonry dam</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London. Series A</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="issue">459-470</biblScope>
			<biblScope unit="page" from="307" to="357" />
			<date type="published" when="1911">1911</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
				<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluation of lightning forecasting based on one lightning parameterization scheme and two diagnostic methods</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmosphere</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">99</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An investigation of the parameterized prediction of lightning in cloud-resolved convection and the resulting chemistry</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Cummings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<pubPlace>College Park</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neighborhood-based verification of precipitation forecasts from convection-allowing ncar WRF model simulations and the operational nam</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Weather and Forecasting</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1495" to="1509" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
