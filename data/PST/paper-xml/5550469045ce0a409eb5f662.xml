<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Skin Buttons: Cheap, Small, Low-Power and Clickable Fixed-Icon Laser Projections</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gierad</forename><surname>Laput</surname></persName>
							<email>gierad.laput@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Human-Computer Interaction Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">Xiao</forename><surname>Xiang '</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human-Computer Interaction Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><forename type="middle">'</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human-Computer Interaction Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
							<email>scott.hudson@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Human-Computer Interaction Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Harrison</surname></persName>
							<email>chris.harrison@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Human-Computer Interaction Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Skin Buttons: Cheap, Small, Low-Power and Clickable Fixed-Icon Laser Projections</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">43503650E7F568ED4F73EF4F489F1321</idno>
					<idno type="DOI">10.1145/2642918.2647356</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ACM Classification: H.5.2 [Information interfaces and presentation]: User Interfaces -Input devices and strategies Wearable devices</term>
					<term>around device interaction</term>
					<term>sensors</term>
					<term>ADI</term>
					<term>on-body computing</term>
					<term>mobile computing</term>
					<term>interaction techniques</term>
					<term>touch input</term>
					<term>smartwatch</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Smartwatches are a promising new interactive platform, but their small size makes even basic actions cumbersome. Hence, there is a great need for approaches that expand the interactive envelope around smartwatches, allowing human input to escape the small physical confines of the device. We propose using tiny projectors integrated into the smartwatch to render icons on the user's skin. These icons can be made touch sensitive, significantly expanding the interactive region without increasing device size. Through a series of experiments, we show that these "skin buttons" can have high touch accuracy and recognizability, while being low cost and power-efficient.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Smartwatches are an emerging computational form factor, made commercially viable by recent advances in miniaturization and battery technology. However, because they are small and our fingers are relatively large, their interfaces tend to be simplistic. Touchscreen smartwatches allow the watch face to be used for a multitude of interfaces, providing flexibility that physical buttons cannot, but suffer from lack of tactile feedback and finger occlusion. These issues would be partially mitigated if we could simply provide more space for interaction. However, simply making smartwatches larger is not an option, as this would make them more obtrusive. Thus one possible approach is to appropriate surface area around the watch for interaction.</p><p>To achieve this, we propose using tiny projectors that can be integrated into a smartwatch. These render icons onto the user's skin -for example, notification icons could be projected for missed calls or new messages (Figure <ref type="figure" target="#fig_0">1</ref>). Infrared (IR) proximity sensors complement these projectors to enable touch sensitivity. For example, tapping a pulsating text message icon could allow users to quickly jump to that message. In addition to providing a projection surface, the skin also provides useful tactile feedback.</p><p>We make the following contributions: <ref type="bibr" target="#b0">(1)</ref> an approach providing around-device, on-body input with projected, graphical feedback, which augments a smartwatch's small screen with lightweight peripheral icons; (2) the design and implementation of the prototype hardware system and icon set; <ref type="bibr" target="#b2">(3)</ref> an evaluation of the system's feasibility: power consumption, size, and cost; and (4) a user study of its usability: recognizability, visibility, and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Enabling rich interactions on small devices has been a stubborn HCI problem, leading to a wide variety of approaches being considered. One strategy is to make better use of limited screen real estate through better software and interaction techniques (e.g., <ref type="bibr" target="#b7">[8]</ref>). Alternatively, other parts of the watch itself can be used for input, such as the bezel <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20]</ref>, band <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24]</ref>, underside <ref type="bibr" target="#b2">[3]</ref>, and face <ref type="bibr" target="#b28">[29]</ref>.</p><p>More related to this work are approaches that provide input beyond the physical confines of the device. For example, Nenya <ref type="bibr" target="#b0">[1]</ref> and iRing <ref type="bibr" target="#b21">[22]</ref> proposed using rings as an interactive accessory, capturing input such as rotation on the finger. Abracadabra <ref type="bibr" target="#b8">[9]</ref> used a finger-worn magnet and magnetometer for in-air finger tracking and gesturing. Ges-tureWatch <ref type="bibr" target="#b14">[15]</ref> use IR proximity sensors to sense gestures above the display. SideSight <ref type="bibr" target="#b3">[4]</ref> used IR proximity sensors along the sides of the device to detect the position of one or more proximate fingers, enabling peripheral multitouch </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Novel Hardware II</head><p>UIST'14, October 5-8, 2014, Honolulu, HI, USA actions, such as pan, zoom and rotate. These free-space interactions often fall under the category of "around device" interaction, which has evolved into a significant area of study (see e.g., <ref type="bibr" target="#b12">[13]</ref>).</p><p>Lastly, our work was also inspired by research into wearable and "on-body" systems. A wide variety of sensing techniques have been evaluated, from bioacoustics <ref type="bibr" target="#b10">[11]</ref> and electromyography (EMG) <ref type="bibr" target="#b24">[25]</ref>, to computer vision <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b29">30]</ref> and ultrasound. Of note, SonarWatch <ref type="bibr" target="#b16">[17]</ref> and PUB <ref type="bibr" target="#b17">[18]</ref> used oblique ultrasonic rangefinders to localize finger inputs on the forearm. SenSkin <ref type="bibr" target="#b20">[21]</ref> measures shear forces using two armbands to enable trackpad-like interactions on the skin. Another approach entirely is for interfaces to be implanted under the skin <ref type="bibr" target="#b11">[12]</ref>. Finally, there is a growing body of literature that looks at how to design touch interfaces and gestures for the skin <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IMPLEMENTATION</head><p>Our prototype smartwatch contains four fixed-icon laser projectors, described subsequently, with accompanying infrared proximity sensors. These are connected to a Femtoduino board, which communicates over USB with a host computer. Similarly, a 1.5-inch, 280x220 TFT LCD display is driven from the host computer. We used an external computer to facilitate prototyping, though a commercial implementation would be self-contained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fixed-Icon Laser Projectors</head><p>We chose 5 mW red laser diodes (650 nm) for our projectors (Figure <ref type="figure">2</ref>). We removed the collimating lens, enabling the diodes to output a cone of light (Figure <ref type="figure" target="#fig_1">3</ref>). By using lasers (i.e., coherent light), we achieve focus-free projection, which is crucial as the oblique angle of the emitter produces widely variable distances to the skin surface. Further, this eliminated the need for lenses, which reduced size, cost and complexity. The laser diodes were driven by standard automatic power control (APC) circuitry, with brightness controlled using pulse width modulation (PWM). This allows for a wide range of expressive light behaviors <ref type="bibr" target="#b9">[10]</ref>.</p><p>To create static image projections, we rendered icons to photographic film at 5780 DPI (an "8K process"). The best results were achieved by using black-and-white film stock (Figure <ref type="figure" target="#fig_2">4</ref>). These films are placed 3mm in front of the laser emitter aperture (Figure <ref type="figure">2</ref>). Our 3D printed enclosure contains precise openings for our emitters and icon films, ensuring correct and stable projection geometry (Figure <ref type="figure" target="#fig_1">3</ref>). The resulting field of view is 62° horizontally and 17° vertically, which is ideal for short range, oblique projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surface Calibration</head><p>The projectors are mounted in the smartwatch chassis at 20º from horizontal. The light from the laser diode first passes through a circular aperture 4 mm in diameter (Figure <ref type="figure">2</ref>). This circle of light expands broadly across the skin surface, resulting in a parabolic cone of light (Figure <ref type="figure" target="#fig_1">3</ref>). The film, placed between the diode and the aperture, must be carefully designed so that the projected icon will appear correct on the skin surface, taking into account the oblique projection angle and the curvature of the arm (Figures <ref type="figure" target="#fig_2">4</ref> and<ref type="figure">5</ref>).</p><p>To generate the perspective-corrected images on our film, we performed a calibration procedure to establish the projector pose relative to the skin. We used a mannequin arm (Figure <ref type="figure">5</ref>) to model a human arm and provide a fixed calibration target. We repeated the procedure for all four projectors, producing films specific to each.</p><p>The calibration process models the appearance of the icon onto the skin as a projective transformation. Rays are imagined casting out from the projector, through the film, and onto a resulting point on the skin. To establish the initial correspondence between skin points and film points, we printed a film containing an evenly spaced 5x5 grid of points. The resulting pattern projection was measured to derive "skin coordinates" corresponding to the film's grid points. These coordinate pairs were fed into OpenCV's camera calibration routine, which provided the pose, focal and nonlinear distortion parameters of the projector. Finally, we used these parameters to transform the icon images from skin coordinates to film coordinates. A comparison of calibrated and uncalibrated icons is shown in Figures <ref type="figure" target="#fig_2">4</ref> and<ref type="figure">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Luminance Correction</head><p>Our current films are binary in nature, in that they are either clear or opaque to the laser light. Because our laser light is not collimated, it diminishes in intensity as the square of the distance, producing widely variable luminance across the skin. We therefore experimented with gradated (grayscale) films, in which we selectively darken regions of the film to produce a more even luminance distribution. We measured the approximate visual intensity of the laser light at each point on the skin using a camera, and then darkened the film correspondingly to balance the intensity. The resulting icons from this process can be seen in Figure <ref type="figure" target="#fig_2">4</ref>, bottom-right.</p><p>Unfortunately, we found the results to be suboptimal. The icons were substantially dimmer, as the light was attenuated over the majority of the icon. This made icons less visible, requiring more power output to achieve equivalent brightness. Additionally, from a visual perception standpoint, humans are generally less sensitive to smooth changes in luminance <ref type="bibr" target="#b27">[28]</ref>. Instead, the hard edges between lit and unlit areas (i.e., icon edges) are most noticeable, and so we found it more desirable to exaggerate this difference by employing maximum illumination, regardless of luminance regularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Touch Sensing</head><p>To capture touch events, we use a Fairchild QRD1114 phototransistor/emitter (Figure <ref type="figure">2</ref>), which measures the intensity of reflected infrared light from proximate surfaces up to 3 cm away. Infrared proximity sensing of this type has been used in many applications, including input devices (see e.g. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref>). For our purposes, these sensors are paired with a laser projector and oriented obliquely to the skin. To compensate for ambient infrared light, we capture two sensor values, once with the IR emitter active and once without. These values are then subtracted to get a better estimate of proximate reflections. Additionally, to help reject false positives, we also use an accelerometer, which disables touch sensing while the arms are in significant motion.</p><p>Although this infrared sensing approach is not novel, we are not aware of any work that uses such sensors on the skin in this fashion. SideSight <ref type="bibr" target="#b3">[4]</ref> is most similar from a configuration perspective, using oblique infrared proximity sensing to detect fingers on either side of a device when situated on a table. Also related is Digits <ref type="bibr" target="#b13">[14]</ref>, which used an oblique infrared line laser and 2D camera to estimate 3D hand pose.</p><p>Compared with mechanical buttons, skin buttons could be made very small (potentially a single IC), yet still provide large, comfortable input. Conversely, mechanical buttons cannot provide notifications (no output), are not solid state (durability issues), and must be large enough for fingers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Size, Weight and Cost</head><p>We built our Skin Button projectors from off-the-shelf components costing roughly $5 each. In volume, we antici-pate the price to be $1 or less. Our prototype projector, seen in Figure <ref type="figure">2</ref>, is approximately 8x10x19 mm, occupies less than 0.4 cm 3 of space, and weighs less than 3 g. With tighter integration, we do not foresee significant obstacles to shrinking this by a factor of two or more. The biggest gains to be made are by moving the laser driver onto the smartwatch mainboard PCB, sharing some components, and switching to surface mount components. In the future, a single dedicated IC could handle all of the sensors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ICON SET DESIGN STRATEGIES</head><p>Over the course of several months of ideation, development and user testing, it became clear that skin button icon sets fell into one of three primary use strategies. In the next section, we offer an example application for each approach.</p><p>Application Centric -This approach dedicates Skin Buttons for key applications or actions, such as launching the phone app or triggering a voice search (example set in Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>Navigation Centric -Skin Buttons could also be used primarily for navigation. For example: up, down, select, and back (Figure <ref type="figure" target="#fig_3">6</ref>). This is also the (physical) button set used in the Pebble Smartwatch. The general nature of these buttons means they could be used for input across a wide variety of applications, from music players to contact lists.</p><p>Screen-Coupled -It is also possible to associate Skin Buttons with on-screen labels (Figure <ref type="figure" target="#fig_4">7</ref>), enabling flexible and fully generalized use, more akin to a touchscreen. Actions could range from app launching on the home screen to playback controls in a music app. Importantly, these labels could be much smaller than an equivalent on-screen touch button, allowing more of the screen to be used for content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXAMPLE APPLICATIONS</head><p>To demonstrate the immediate potential of our approach, we created three proof-of-concept applications, seen in Figures <ref type="figure" target="#fig_3">1, 6</ref> and<ref type="figure" target="#fig_4">7</ref> (see also Video Figure). These illustrate the three strategies described in the previous section.</p><p>Today's smartwatches are used extensively for notifications. Additionally, most devices have a "home" screen, from which to access key functionality. Application-centric Skin Buttons could augment both of these features by offering easily accessible application icons. As an example, we fitted our prototype with four application icons: email, notifications, music player, and favorites (Figure <ref type="figure" target="#fig_0">1</ref>). These Figure <ref type="figure">5</ref>. A mannequin was used for rapid prototyping. Note that the top-left icon ("music") is perspective-corrected while the bottom-left icon is not, leading to distortion.</p><p>icons can be tapped to quickly launch the corresponding application. Additionally, icons can pulse, flash or have other light behaviors <ref type="bibr" target="#b9">[10]</ref> to indicate that e.g., a missed phone call, or that a text message has been received.</p><p>We also created a music player that used our navigationcentric icon set (Figure <ref type="figure" target="#fig_3">6</ref>). 'Up' and 'down' buttons are used to scroll, the 'select' button enters a sub-list (e.g., playlist or album) or activates an item (e.g., play a song), and 'back' traverses up through the hierarchical interface.</p><p>Finally, as a demonstration of application-specific, screencoupled Skin Buttons, we created a clock application. When in the clock mode, buttons allow the user to customize the 'watchface', toggle the 'alarm', set the 'alarm time', and enter 'stopwatch' mode (Figure <ref type="figure" target="#fig_4">7</ref>). When in stopwatch mode, there are buttons to 'start', 'pause/resume', 'reset', and go 'back' to clock mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EVALUATION</head><p>To assess the performance of Skin Buttons, we ran a series of small, targeted experiments, which took approximately 30 minutes in total. We recruited 20 participants (7 female, mean age 24), who were given $10 for their involvement in the study. To assess if posture had an effect on use, ten participants completed the study standing, while the other ten were seated. The experiment was performed under normal office ambient lighting conditions. For the experiment, we used email, up-arrow, music, and heart icons.</p><p>As our prototype was calibrated assuming the watch was worn on the left wrist, only participants who reported they would wear a watch in this fashion were recruited. In addition to standard demographics information, participants also completed the Fitzpatrick Scale questionnaire <ref type="bibr" target="#b5">[6]</ref>, which provides a schema for skin color (types I to VI, ranging from lightest to darkest skin color). We had the following breakdown: Type II, III, IV, V and VI had 4, 4, 7, 2, and 3 participants respectively, representing almost the entire spectrum of skin tones. The experimenter also recorded hairiness and any other notable skin features (e.g., wrinkliness, freckle density) for later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Projected Icon Recognizability</head><p>Our first experiment sought to assess if icons had enough fidelity to be recognizable when projected on the skin. After participants put on our smartwatch prototype, all four Skin Buttons were illuminated at an intensity determined to be comfortable in piloting. The experimenter then announced the icon names (e.g. "the email icon") in random order, asking the participant to point out each icon as it was announced. For the arrow icon, the experimenter additionally asked the participant to identify the direction it was facing.</p><p>Out of 80 recognition trials, participants pointed to the wrong target two times, yielding an overall recognition accuracy of 98%. All participants correctly identified the arrow icon, but two misidentified the direction. We believe these results suggest our prototype icon design and projection fidelity is reasonably robust. Following the recognition trials, we asked participants two Likert-scale questions: "I could easily recognize the different projected icons" and "After a few days of use, I believe I could easily recognize the different projected icons" (1-Strongly disagree, 5-Strongly agree). These elicited average scores of 3.7 and 4.6 respectively (SD=1.0 and 0.49).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Projection Visibility</head><p>Next, we wished to investigate the more general question of visibility. Put simply: at what level of brightness can the projection be seen and what level is sufficient to enable reliable use in typical lighting conditions? To answers these questions, we allowed participants to adjust the brightness of the Skin Buttons using arrow keys on a laptop. Participants were asked to find three levels of brightness:</p><p>• "I can just barely see that the icons are active at this level of brightness" (barely) • "I can comfortably see that the icons are active at this level of brightness" (comfortable) • "I would generally never need an icon to be stronger than this level of brightness" (high)</p><p>Participants were able to adjust and revisit the three questions until they were satisfied with their selected levels of brightness. When participants indicated they were done, our software recorded the corresponding duty cycles of the laser projectors. We found that barely visible icons required an average duty cycle of 10.0% (SD=3.6%), comfortable visibility required 17.3% (SD=6.2%), and high visibility required 27.9% (SD=10.7%).  To assess the touch sensing accuracy of our approach, we had our participants "click" our four Skin Buttons 25 times each in a random order. Participants were told to simply "click the icon" without any further guidance. Before performing the trials, participants practiced with the system for two minutes. There were two possible error modes: 1) another skin button was inadvertently triggered or 2) the click was not detected. In the latter case, the experimenter recorded the false negative and the participant clicked again. In total, our 20 participants provided 2000 click trials, of which 2.8% (56 trials) had false negatives. When a finger tap was detected, the system was 96.9% accurate in triggering the intended button. Anecdotally, 99%+ accuracy appears achievable if people can use the device for a longer than the study permitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Power Consumption</head><p>Our approach has to two distinct processes that consume power: touch sensing and projection. For reference, the Samsung Galaxy Gear (2013) contains a 1200 mWh battery.</p><p>As noted previously, the touch-sensing scheme we employ takes two samples, one with and one without IR illumination. This process takes approximately 40 µs. Our prototype smartwatch polls these sensors at 50 Hz, resulting in 1.0 mW of power draw per sensor. Even if active continually for 24 hours, this would drain less than 2% of the battery.</p><p>The power draw of our projectors depends on their intensity, which we vary using pulse width modulation (PWM). In our projection visibility experiment, we found that 17.3% was the mean duty cycle (SD=6.2%) needed to achieve a "comfortable" level of brightness. This equates to a power consumption of 19.9 mW when active, including both the laser diode and driver circuitry. In other words, each hour, a projected icon would consume roughly 1.7% of a Galaxy Gear's battery. Icons that are "barely" visible require roughly half the power, only 11.5 mW. Pulsing or flashing an icon could cut power consumption in half or more.</p><p>Importantly, if Skin Buttons allow interactions to proceed without turning on the main display (e.g., by flashing the phone icon to convey a "missed call" instead of activating the LCD), they have the potential to extend battery life. It should also be noted that these numbers should be treated as an upper bound, as tighter integration and further refinement would undoubtedly reduce power consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Skin Color and Other Effects</head><p>There were no statistically significant effects regarding gender, age, hairiness, skin color, or standing vs. sitting. As such, the above experimental results were combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interview</head><p>At the end of the study, we conducted an open-ended interview with participants to elicit their feedback. Overall, we found that participants found the concept compelling and useful. Seven had tried smartwatches in the past; all but two had discontinued use due to a poor user experience. With respect to touching the skin for interaction, users generally thought Skin Buttons were "cool" and "satisfyingly responsive." One participant mentioned that "touching buttons on her skin" made the smartwatch experience "more intimate." Several participants commented on the visual appearance of icons, suggesting the recognizability was affected by "negative space", "simplicity of shape", "exaggerated features", "brightness", and good "reuse [of] symbolic conventions."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LIMITATIONS AND FUTURE WORK</head><p>The major limitation of our current prototype is the use of fixed projected icons. Dynamic projection is certainly more desirable, and so we performed an early experiment to explore this approach. We repurposed a small LCD module with an active area consisting of four 1.8x2.2 mm 3x5 pixel arrays (Figure <ref type="figure" target="#fig_5">8</ref>). Using an LED as a light source, we were able to project various icons. Due to the limited resolution, these are not perspective-corrected. Small, high-resolution LCDs (e.g. 32x32) could allow for perspective-corrected, high-resolution, dynamic icons in the near future.</p><p>Diffraction gratings are another option for static icon projection. We experimented with these early on, but found the output to be poor at short throw distances. We hope to design our own diffraction gratings in the future -these have high setup costs, but are very low cost to manufacture in volume. Additionally, our current prototype is monochromatic (red); moving to full color is interesting, but comes at the cost of increased size. Regarding size, we believe further miniaturization is possible (see "implementation").</p><p>The use of fixed icons also means that projection calibrations must be "one-size-fits-all". We noted during our experiments that the icon appearances were primarily affected by the projection angle, rather than the curvature of the arm. Nevertheless, there may well be incompatible arm geometries; e.g. icon sets would have to be modified for watches that are worn on the right arm.</p><p>There are also challenges in achieving high fidelity projected output on the skin. Foremost, light hitting the skin causes subdermal light scattering <ref type="bibr" target="#b15">[16]</ref>, which increases local illumination, thus decreasing contrast. Additionally, at the scales at which we are operating, the fine details in our icons can produce light interference effects. Moreover, laser light tends to produce a speckle pattern, which can make the icons appear to "sparkle", reducing the visibility and identifiability of the icon <ref type="bibr" target="#b4">[5]</ref>. Despeckling methods exist that can reduce this effect (see e.g., <ref type="bibr" target="#b22">[23]</ref>), but future work is needed to see if these techniques are compatible with small devices. Finally, the IR proximity sensors we use can be inadvertently triggered by movement or flexing of the arm and wrist, and also by proximate clothing and jewelry. We attempt to mitigate the former by using an accelerometer to reject touch input while in motion, but outside of the lab, this will be a greater challenge. Sensor fusion, e.g., by combining IR touch sensing with bio-acoustics, may be the best way forward, and we plan to explore this in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Skin Buttons are touch-sensitive projected icons. Here, application-centric buttons are projected: email, notification, music player and heart. Tapping an icon launches the corresponding application.</figDesc><graphic coords="1,315.12,159.60,240.96,137.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Internal view of our prototype. Note the projectors fitted into 20° angled ports on the sides of the enclosure. Also, note the extent of the projected light (no films inserted).Figure 2. Close-up of a single Skin Button projector.</figDesc><graphic coords="2,253.20,-22.56,390.96,254.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Left: Example icons: perspective-corrected, perspective-and luminance-corrected, and uncorrected. Right: icons rendered onto film (bottom row luminance corrected).Figure5. A mannequin was used for rapid prototyping. Note that the top-left icon ("music") is perspective-corrected while the bottom-left icon is not, leading to distortion.</figDesc><graphic coords="3,204.00,40.56,176.88,117.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Music Player application features a navigationcentric icon set. Clockwise from top right: up arrow, down arrow, circle (select), back arrow.</figDesc><graphic coords="4,54.00,34.56,242.40,161.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. In our clock app, users can set an alarm and change watch faces. In stopwatch mode, seen here, users can start, resume/pause, reset, or return to the clock.</figDesc><graphic coords="4,315.12,34.32,242.40,160.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. By substituting film for a very small liquid crystal display, it is possible to project primitive dynamic icons, including characters, symbols and system icons (e.g. a battery). Far right: the LCD we used, which contains four LCD blocks, each 3x5 pixels in resolution.</figDesc><graphic coords="5,315.12,61.44,242.64,54.96" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work was generously supported by grants from Yahoo! InMind, Google and NSF (IIS-1217929), as well as fellowships from Qualcomm, Disney and NSERC of Canada.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>Skin Buttons are low cost, very small projectors that can render a fixed image onto the skin at an oblique angle. These properties make them suitable for inclusion into smartwatches, where they can extend the interactive area beyond the small screen. We further added touch sensitivity through infrared proximity sensing, enabling interactive touch functionality. We described our proof-of-concept implementation and results from our study, which show that the projections are easily recognized, easily clicked, and have power requirements approaching commercial feasibility.</p><p>Novel Hardware II UIST'14, October 5-8, 2014, Honolulu, HI, USA</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Nenya: subtle and eyes-free mobile input with a magnetically-tracked finger ring</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ashbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;11</title>
		<meeting>CHI &apos;11</meeting>
		<imprint>
			<biblScope unit="page" from="2043" to="2046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An investigation into round touchscreen wristwatch interaction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ashbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Starner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MobileHCI &apos;08</title>
		<meeting>MobileHCI &apos;08</meeting>
		<imprint>
			<biblScope unit="page" from="311" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Back-of-device interaction allows creating very small touch devices</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;09</title>
		<meeting>CHI &apos;09</meeting>
		<imprint>
			<biblScope unit="page" from="1923" to="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SideSight: multi-&quot;touch&quot; interaction around small devices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;08</title>
		<meeting>UIST &apos;08</meeting>
		<imprint>
			<biblScope unit="page" from="201" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Laser Speckle and Related Phenomena</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dainty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Applied Physics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="1975">1975</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Soleil et peau</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Fitzpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal de Médecine Esthétique</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="33" to="34" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imaginary phone: learning imaginary interfaces by transferring spatial memory from a familiar device</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;11</title>
		<meeting>UIST &apos;11</meeting>
		<imprint>
			<biblScope unit="page" from="283" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Interacting with big interfaces on small screens: a comparison of fisheye, zoom, and panning techniques</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fedak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GI &apos;04</title>
		<meeting>GI &apos;04</meeting>
		<imprint>
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Abracadabra: wireless, highprecision, and unpowered finger input for very small mobile devices</title>
		<author>
			<persName><forename type="first">C</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;09</title>
		<meeting>UIST &apos;09</meeting>
		<imprint>
			<biblScope unit="page" from="121" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unlocking the Expressivity of Point Lights</title>
		<author>
			<persName><forename type="first">C</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Horstman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;12</title>
		<meeting>CHI &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="1683" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Skinput: appropriating the body as an input surface</title>
		<author>
			<persName><forename type="first">C</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;10</title>
		<meeting>CHI &apos;10</meeting>
		<imprint>
			<biblScope unit="page" from="453" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Implanted user interfaces</title>
		<author>
			<persName><forename type="first">C</forename><surname>Holz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;12</title>
		<meeting>CHI &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="503" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Around device interaction for multiscale navigation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sodhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Maciocci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MobileHCI &apos;12</title>
		<meeting>MobileHCI &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Digits: freehand 3D interactions anywhere using a wrist-worn gloveless sensor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oikonomidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Olivier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;12</title>
		<meeting>UIST &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Gesture Watch: A Wireless Contact-free Gesture based Wrist Interface</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Starner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISWC &apos;07</title>
		<meeting>ISWC &apos;07</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Biophysically-Based Spectral Model of Light Interaction with Human Skin</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krishnaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baranoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="331" to="340" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SonarWatch: appropriating the forearm as a slider bar</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Emerging Technologies, Article 5</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">PUB -point upon body: exploring eyes-free interaction and methods on an arm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;11</title>
		<meeting>UIST &apos;11</meeting>
		<imprint>
			<biblScope unit="page" from="481" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Facet: a multi-segment wrist worn system</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ashbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;12</title>
		<meeting>UIST &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interaction on the edge: offset sensing for small devices</title>
		<author>
			<persName><forename type="first">I</forename><surname>Oakley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;14</title>
		<meeting>CHI &apos;14</meeting>
		<imprint>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SenSkin: adapting skin as a soft interface</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sugiura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Imai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;13</title>
		<meeting>UIST &apos;13</meeting>
		<imprint>
			<biblScope unit="page" from="539" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">iRing: intelligent ring using infrared reflection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sugiura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Osawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Imai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;12</title>
		<meeting>UIST &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="131" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Speckle reduction and maintaining contrast in a LASER pico-projector using a vibrating symmetric diffuser</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Express</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="6464" to="6477" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">WatchIt: simple gestures and eyes-free interaction for wristwatches and bracelets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Perrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lecolinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guiard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;13</title>
		<meeting>CHI &apos;13</meeting>
		<imprint>
			<biblScope unit="page" from="1451" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Enabling always-available input with musclecomputer interfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Saponas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Landay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;09</title>
		<meeting>UIST &apos;09</meeting>
		<imprint>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Body-centric design space for multi-surface interaction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nancel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;13</title>
		<meeting>CHI &apos;13</meeting>
		<imprint>
			<biblScope unit="page" from="1299" to="1308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">More Than Touch: Understanding How People Use Skin as an Input Surface for Mobile Computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weigel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steimle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;14</title>
		<meeting>CHI &apos;14</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Kluender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bartoshuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Herz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Klatzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Lederman</surname></persName>
		</author>
		<title level="m">Sensation and Perception</title>
		<meeting><address><addrLine>Sunderland, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Sinauer Associates</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Laput</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;14</title>
		<meeting>CHI &apos;14</meeting>
		<imprint>
			<biblScope unit="page" from="193" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PALMbit: A Body Interface utilizing Light Projection onto Palms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jour. of The Inst. of Image Info. and Tele. Eng</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="797" to="804" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
