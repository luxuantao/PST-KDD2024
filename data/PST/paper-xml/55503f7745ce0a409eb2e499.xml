<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stream-based active learning for sentiment analysis in the financial domain</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jasmina</forename><surname>Smailovic</surname></persName>
							<email>jasmina.smailovic@ijs.si</email>
							<affiliation key="aff0">
								<orgName type="institution">Joz ˇef Stefan Institute</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Joz ˇef Stefan International Postgraduate School</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miha</forename><surname>Grc ˇar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Joz ˇef Stefan Institute</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Joz ˇef Stefan International Postgraduate School</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nada</forename><surname>Lavrac ˇa</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Joz ˇef Stefan International Postgraduate School</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Nova Gorica</orgName>
								<address>
									<addrLine>Vipavska 13</addrLine>
									<postCode>5000</postCode>
									<settlement>Nova Gorica</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><forename type="middle">Z</forename><surname>ˇnidaršic ˇa</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Joz ˇef Stefan International Postgraduate School</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Joz ˇef Stefan Institute</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stream-based active learning for sentiment analysis in the financial domain</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">78185453B38D7FF2021F999D809ECCF6</idno>
					<idno type="DOI">10.1016/j.ins.2014.04.034</idno>
					<note type="submission">Received 22 March 2013 Received in revised form 31 March 2014 Accepted 17 April 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Predictive sentiment analysis Stream-based active learning Stock market Twitter Positive sentiment probability Granger causality 2</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Studying the relationship between public sentiment and stock prices has been the focus of 29 several studies. This paper analyzes whether the sentiment expressed in Twitter feeds, 30 which discuss selected companies and their products, can indicate their stock price 31 changes. To address this problem, an active learning approach was developed and applied 32 to sentiment analysis of tweet streams in the stock market domain. The paper first presents 33 a static Twitter data analysis problem, explored in order to determine the best Twitter-spe-34 cific text preprocessing setting for training the Support Vector Machine (SVM) sentiment 35 classifier. In the static setting, the Granger causality test shows that sentiments in stock-36 related tweets can be used as indicators of stock price movements a few days in advance, 37 where improved results were achieved by adapting the SVM classifier to categorize Twitter 38 posts into three sentiment categories of positive, negative and neutral (instead of positive 39 and negative only). These findings were adopted in the development of a new stream-40 based active learning approach to sentiment analysis, applicable in incremental learning 41 from continuously changing financial tweet streams. To this end, a series of experiments 42 was conducted to determine the best querying strategy for active learning of the SVM clas-43 sifier adapted to sentiment analysis of financial tweet streams. The experiments in analyz-44 ing stock market sentiments of a particular company show that changes in positive 45 sentiment probability can be used as indicators of the changes in stock closing prices.</p><p>46</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Predicting the value of stock market assets is a challenge investigated by numerous researchers. One of the reasons for addressing this challenge is the controversy of the efficient market hypothesis <ref type="bibr" target="#b17">[18]</ref>, which claims that stocks are always traded at their fair value. Based on this market theory, claiming that it is not possible for investors to buy undervalued stocks or sell stocks for overestimated prices, it is impossible for traders to consistently outperform the average market returns. This hypothesis is based on the assumption that financial markets are informationally efficient (i.e., that stock prices always reflect all the relevant information at investment time). The unpredictable nature of stock market prices was first investigated by Regnault <ref type="bibr" target="#b52">[53]</ref> and later by <ref type="bibr">Bachelier [4]</ref>. Fama <ref type="bibr" target="#b17">[18]</ref>, who proposed the efficient market hypothesis, also claimed that stock price movement is unpredictable and that past price movements cannot be used to forecast future stock prices.</p><p>However, as the efficient market hypothesis is controversial, researchers from various disciplines (including economists, statisticians, finance experts, and data miners) have been investigating the means to predict future stock market prices.</p><p>The findings vary: from those claiming that stock market prices are not predictable to those presenting opposite conclusions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">35]</ref>. This paper addresses the described challenge in the context of the explosive growth of social media and user-generated content on the Internet. Through blogs, forums, and social networking media, more and more people share their opinions about individuals, companies, movements, or important events. Such opinions both express and evoke sentiments <ref type="bibr" target="#b50">[51]</ref>.</p><p>Recent research indicates that analysis of these online texts can be useful for trend prediction. For example, it was shown that the frequency of blog posts can be used to forecast spikes in online consumer purchasing <ref type="bibr" target="#b23">[24]</ref>. Moreover, it was shown by Tong <ref type="bibr" target="#b73">[74]</ref> that references to movies in newsgroups are correlated with their sales. Sentiment analysis of weblog data was successfully used to predict the financial success of movies <ref type="bibr" target="#b40">[41]</ref>. Twitter<ref type="foot" target="#foot_1">1</ref> posts were also shown to be useful for predicting box-office revenues of movies before their release <ref type="bibr">[3]</ref>.</p><p>Twitter is currently the most popular microblogging platform <ref type="bibr" target="#b46">[47]</ref> allowing its users to send and read short messages of up to 140 characters in length, known as tweets, via SMS, the Twitter website, or a range of applications for mobile devices.</p><p>Twitter gained global popularity very quickly with over 500 million active users in 2012, writing over 340 million tweets daily <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b41">42]</ref>. Twitter data (and data from other social network websites) are very interesting because of their large volume, popularity, and capability of near-real-time publishing of individuals' opinions and emotions about any subject. Given that this massive amount of user-generated content became abundant and easily accessible, many researchers became interested in the predictive power of microblogging messages, especially in the domain of stock market prediction, prediction of election results, or prediction of the financial success of movies or books. Many of these studies use sentiment analysis <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b76">77]</ref> as a basis for prediction. The term sentiment, used in the context of automatic analysis of text and detection of predictive judgments from positively and negatively opinionated texts, first appeared in the papers by Das and Chen <ref type="bibr" target="#b14">[15]</ref> and Tong <ref type="bibr" target="#b73">[74]</ref>,</p><p>where the authors were interested in analyzing stock market sentiment. Even though there are many studies on predicting the phenomenon of interest using sentiment analysis of online texts, there is still an urge to develop methods and tools for adaptive dynamic sentiment analysis of microblogging posts, which would enable handling changes in such data streams.</p><p>This field of research is still insufficiently explored and represents a challenge, which is addressed in this work through active learning <ref type="bibr" target="#b62">[63]</ref>.</p><p>This work contributes to sentiment analysis and to active learning research, and partly towards better understanding of phenomena in financial stock markets. While sentiment analysis is generally aimed at detecting the author's attitude, emotions or opinions expressed in the text, our study is concerned with the development of an approach to predictive sentiment analysis. With this term, we denote an approach in which sentiment analysis is used to predict a specific phenomenon or its changes, postulating that the proposed methodology for predictive sentiment analysis of streams of microblogging messages should be capable of predicting the financial phenomenon of interest. The indication that there may be a relationship between emotions and stock market prices relies on findings in psychological research which indicate that emotions are crucial to rational thinking and social behavior <ref type="bibr" target="#b13">[14]</ref>, and can influence the choice of actions. Given that the general mood of a society is propagated through social interactions, the collective social mood can be transferred through the investors to the stock market and consequently, the sentiment can be reflected in stock price movements. As a result, the stock market itself can be considered as a measure of social mood <ref type="bibr" target="#b44">[45]</ref>. It is, thus, reasonable to expect that the analysis of the public mood can be used to predict price movements in the stock market. We hypothesize that this assumption may hold in situations when people actually express positive or negative opinions about some topic concerning the stock market, whereas in situations when people do not express opinions, but mostly neutral facts, we anticipate finding no correlations. In accordance with this hypothesis, we propose a mechanism for distinguishing opinionated (positive and negative) from non-opinionated (neutral) tweets in Twitter data streams.</p><p>In an effort to build an active learning approach to sentiment analysis, applicable in incremental learning from continuously changing financial tweet data streams, we first addressed a static Twitter data analysis problem, which was explored in order to determine the best Twitter-specific text preprocessing setting for training the Support Vector Machine (SVM) sentiment classifier. In the static setting, the Granger causality test showed that sentiment in stock-related tweets can be used as an indicator of stock price movements a few days in advance, where improved results were achieved by adapting the SVM classifier to categorize Twitter posts into three sentiment categories of positive, negative and neutral (instead of positive and negative only). These findings were successfully used in the development of a new stream-based active learning approach to sentiment analysis, applicable in incremental learning from continuously changing financial tweet data streams.</p><p>Using stream data for sentiment analysis makes sense when the information about the changes in the sentiment is timecritical and a proper data flow is available, for example, in the analysis of streams of financial tweets in which people express their opinions about stocks in real time. The main idea of active learning <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b66">67]</ref>, adapted in this study for continuously updating the sentiment classifier from a tweet stream, is that the algorithm is allowed to select new examples to be labeled by the oracle (e.g., a human annotator) and added to the training set. It aims at maximizing the performance of the algorithm with as little human labeling effort as possible. The main challenge of active learning is the selection of the most suitable examples for labeling in order to achieve the highest prediction accuracy, while knowing that one cannot afford to label all the examples <ref type="bibr" target="#b87">[88]</ref>. For example, query algorithms based on uncertainty sampling select for labeling the examples for which the current learner has the highest uncertainty <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b74">75]</ref>. Similarly, algorithms based on query-by-committee use disagreement among an ensemble of learners to select new examples for labeling <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b67">68]</ref>. The active learning approach proposed in this paper combines uncertainty and random sampling and was developed by adapting the initial static sentiment analysis approach to deal with changes over time in a tweet stream. On the one hand, the use of active learning is a consequence of the scarcity of labeled tweets available for sentiment analysis, which prevents the use of conventional machine learning methods. It is namely very difficult and costly to obtain large hand-labeled datasets of tweets, especially if they are domain dependent. On the other hand, these datasets and the resulting models change with time and, consequently, soon become outdated. Thus, continuous learning that allows for adaptations to change in the modeled environment is inevitable to keep the models current.</p><p>In summary, the main contribution of this paper is a new methodology for stream-based active learning for tweet sentiment analysis in finance, which can be used on continuously changing tweet streams. A series of experiments was conducted to determine the best querying strategy for active learning of the SVM classifier, which was adapted to sentiment analysis of streams of financial tweets and applied to predictive stream mining in a financial stock market application. As a side effect, since there is no large labeled dataset of financial tweets publicly available, we have labeled and made publicly available a collection of financial tweets, making it the first large (in the sense of labeling effort) publicly available dataset of its kind. We used the dataset in the simulated active learning setting and in the evaluation of the results of tweet stream analysis.</p><p>The paper is structured as follows. Section 2 presents a brief overview of related work. Section 3 discusses Twitter-specific text preprocessing options, and presents the developed SVM tweet sentiment classifier, learned from adequately preprocessed Twitter data. Section 4 presents the dataset of financial tweets, which were collected for the purpose of the study, as well as the method and technology developed for enabling financial market predictions from Twitter data. The approach uses positive sentiment probability as a new indicator for predictive sentiment analysis in finance, proposed in our previous work <ref type="bibr" target="#b70">[71]</ref>. Furthermore, due to the fact that financial tweets do not necessarily express the sentiment, this section applies sentiment classification using the neutral zone, which allows classification of a tweet into the neutral category, thus improving the predictive power of the sentiment classifier compared to the SVM classifier categorizing Twitter posts into positive and negative sentiment categories only. Section 5 introduces incremental learning of the classifier on a stream of financial tweets. The general purpose classifier was incrementally updated in order to adapt to the changes in the data stream by using the active learning approach. The paper concludes with a summary of results and plans for further work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this section, we give an overview of related studies, which are focused on: (i) analyzing sentiment in Twitter data, (ii) sentiment analysis of social media as a predictor of the future stock market indicators, and (iii) active learning on data streams. Although these tasks have been well-studied separately, there is a lack of work which would combine them and propose a dynamic adaptive sentiment analysis methodology for microblogging stream posts, which would be able to handle changes in data streams-our work addresses this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Sentiment analysis and microblogging channels</head><p>In recent years, several studies have analyzed sentiments expressed in Twitter data in order to describe its content and study its relation to trends. O'Connor et al. <ref type="bibr" target="#b45">[46]</ref> analyzed several surveys on consumer confidence and political opinion, and found a correlation with sentiments in Twitter messages. Furthermore, Thelwall et al. <ref type="bibr" target="#b72">[73]</ref> analyzed 30 top events in Twitter over a one-month period and showed that popular events are associated with an increase in average negative sentiment strength. In <ref type="bibr" target="#b29">[30]</ref>, the authors addressed target-dependent sentiment classification and applied it to English tweets on popular topics. They incorporated target-dependent features and also took related tweets into consideration. <ref type="bibr">Asur et al. [3]</ref> constructed a model based on tweet-rate about particular topics for predicting box-office revenues of movies before their release. They further showed how sentiment extracted from Twitter posts can improve their forecasting power. In the context of the 2009 German federal elections, Tumasjan et al. <ref type="bibr" target="#b75">[76]</ref> showed that sentiment expressed in Twitter messages closely corresponds to the offline political landscape.</p><p>There has also been research exploring whether sentiment analysis of social media can be used to predict future stock market indicators. In <ref type="bibr" target="#b60">[61]</ref>, the authors analyzed sentiment in messages from the Yahoo! Finance website 2 and demonstrated that sentiment and stock values are closely correlated. They also showed that one can use sentiment analysis to make predictions about stock behavior over a short-term period. In <ref type="bibr" target="#b46">[47]</ref>, the authors analyzed sentiments in postings from stock microblogging channel, Stocktwits.com, 3 over a period of three months and found that stock microblog sentiments may predict future stock price movements. Additionally, they found that pessimistic information has higher predictive value as compared to optimistic information. Zhang et al. <ref type="bibr" target="#b86">[87]</ref> measured positive and negative emotions in tweets and analyzed the correlation 2 http://finance.yahoo.com. 3 http://www.stocktwits.com. between these measures and stock market indices such as Dow Jones, S&amp;P 500, NASDAQ, and VIX. The authors indicated that by inspecting Twitter for any kind of emotional outburst gives a predictor of how the stock market will perform the following day.</p><p>Bollen et al. <ref type="bibr" target="#b7">[8]</ref> measured mood in tweets in terms of six dimensions (calm, alert, sure, vital, kind, and happy) and showed that changes in calmness can predict daily up and down changes in the closing values of the Dow Jones Industrial Average Index (DJIA). Furthermore, Chen and Lazer <ref type="bibr" target="#b11">[12]</ref> confirmed the results of Bollen et al. <ref type="bibr" target="#b7">[8]</ref> and showed that even with much simpler sentiment analysis methods, a correlation between Twitter sentiment data and stock market movements can be observed. <ref type="bibr" target="#b39">[40]</ref> based their work for finding a correlation between public sentiment and the stock market on the approach of Bollen et al. <ref type="bibr" target="#b7">[8]</ref>. Their results <ref type="bibr" target="#b39">[40]</ref> are in some agreement with the results of Bollen et al. <ref type="bibr" target="#b7">[8]</ref>, but they indicate that not only the calm, but also the happy mood dimension has a good correlation with the DJIA values. The authors in <ref type="bibr" target="#b42">[43]</ref> calculated daily sentiment of aggregated data from multiple sources (Twitter, 11 online message boards, and Yahoo! Finance news stream), where the data was concerned with stocks of the S&amp;P 500 index during a six-month period. In their experiments, they showed that publicly available data in microblogs, forums, and news have predictive power for stock price changes on the following day.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mittal and Goel</head><p>Sprenger et al. <ref type="bibr" target="#b71">[72]</ref> analyzed about 250,000 stock-related tweets and found that the sentiments in tweets is associated with exceptional stock returns and that message volume predicts next-day trading volume. In addition, the authors showed that users that give above-average investment advice are retweeted more often and have more followers, which shows their influence in microblogging forums. Finally, Yu et al. <ref type="bibr" target="#b84">[85]</ref> studied the effect of social and conventional media on firm stock market performance and found that social media has a stronger impact. Nevertheless, the authors found that social and conventional media together do have an effect on the stock market. They also found that the effect of social media varies depending on its type.</p><p>The above literature overview confirms that sentiment analysis of social media contains predictive information about future stock market indicators, which is also the topic of this paper. Close to our research is the work of Sprenger et al. <ref type="bibr" target="#b71">[72]</ref>, which aims at finding associations among various values describing tweets and stocks. Also, a similar idea exists in <ref type="bibr" target="#b42">[43]</ref>, but the authors were interested in aggregating data from multiple sources, whereas we are specifically interested in adjusting our approach to microblogging data. In our previous studies, we used the volume and sentiments in stock-related tweets to identify important events, as a step towards the prediction of future movements of stock prices <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b70">71]</ref>. This paper substantially extends our previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Stream-based active learning</head><p>Active learning has been studied in three different scenarios: (i) membership query synthesis, (ii) pool-based sampling, and (iii) stream-based selective sampling <ref type="bibr" target="#b64">[65]</ref>. In the membership query synthesis scenario, the learner may select new examples for labeling from the input space or it can generate new examples itself. In the pool-based scenario, the learner may request labels for any example from a large pool of historical data. Finally, in the stream-based active learning scenario, examples are made available constantly from a data stream and the learner has to decide in real time whether to request a label for a new example or not.</p><p>Active learning on data streams has been a subject in many studies. One of the simplest ways to select the examples to be labeled is based on maximizing the expected informativeness of labeled examples. For example, the learner may find the examples with the highest uncertainty to be the most informative and request them to be labeled. Zhu et al. <ref type="bibr" target="#b87">[88]</ref> used uncertainty sampling to label instances within a batch of data from the data stream. Z ˇliobaite et al. <ref type="bibr" target="#b89">[90]</ref> proposed strategies that extend the fixed uncertainty strategy with dynamic allocation of labeling efforts over time and randomization of the search space. The latter approach was used also in some of our active learning strategies described in Section 5. These newly proposed active learning strategies explicitly handle concept drift and adapt the classifier to data distribution changes in data streams over time. In contrast to our approach, Z ˇliobaite et al. <ref type="bibr" target="#b89">[90]</ref> do not consider batches, but perform labeling decisions on every encountered data instance. Also, their labeling budget management is different, as they have a fixed overall budget and dynamically adapt the active learning rate according to the amount of budget left. This can be beneficial for flexible adaptation, but can disperse the labeling effort very unevenly. We opted for a fixed budget per batch, which enables the labeling effort to remain the same in each time period. This was perceived as a favorable approach from the user's point of view, as in our case the labeling cost is measured in human time, which is difficult to provide in unevenly dispersed bursts. Deciding which instances are the most suitable for labeling can be made by a single evolving classifier <ref type="bibr" target="#b89">[90]</ref> or by a classifier ensemble <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b87">88,</ref><ref type="bibr" target="#b88">89]</ref>. In classifier-ensemble-based active learning frameworks, a number of classifiers are trained from small portions of stream data. These classifiers construct an ensemble classifier for predictions <ref type="bibr" target="#b85">[86]</ref>, while our work is concerned with the development of a single evolving sentiment classifier for Twitter posts.</p><p>Active learning on stream data for sentiment analysis of tweets in financial domains is still insufficiently explored and represents a significant challenge. Our preliminary work on this topic was presented in <ref type="bibr" target="#b55">[56]</ref>. <ref type="bibr">Bifet and Frank [7]</ref> discuss the challenges posed by Twitter data streams, focusing on classification problems, and consider these streams for sentiment analysis, but they do not use the active learning approach. On the other hand, Settles <ref type="bibr" target="#b65">[66]</ref> has developed an active learning annotation tool, DUALIST; while he showed its potential by applying it to sentiment analysis of general tweets, his tool is not specifically adjusted to tweet analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INS 10845</head><p>No. of Pages 23, Model 3G</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Defining the best parameter setting for tweet preprocessing</head><p>Preprocessing is a necessary data preparation step to supervised machine learning when training a sentiment classifier.</p><p>We describe here the algorithm used in the development of the initial general tweet sentiment classifier, the dataset, different data preprocessing settings, and the experiments that led to the choice of the best tweet preprocessing setting.</p><p>In this work, classification refers to the process of categorizing a new tweet into one of the two categories or classes: the positive or the negative sentiment of a tweet. The classifier is trained to classify new instances based on a set of class-labeled training instances (tweets), each described by a vector of features (terms, formed from one or several consecutive words)</p><p>which have been pre-categorized manually or in some other presumably reliable way. Features are all the terms detected in the training dataset. The length of the feature vectors corresponds to the number of features. The approach to tweet preprocessing and classifier training was implemented using the LATINO 4 software library of text processing and data mining algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The algorithm used for sentiment classification</head><p>There are three common approaches to sentiment classification <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b72">73]</ref>: (i) machine learning, (ii) lexicon-based methods, and (iii) linguistic analysis. Linguistic analysis tends to be computationally demanding for use in a streaming near-real-time setting. Lexicon-based methods are faster, but are unable to adapt to changes in the modeled environment. In the analysis of dynamic concepts, such as public sentiment, this is a serious drawback. Namely, certain terms, such as company names, countries or phrases, can shift with time from one sentiment class to the other. Therefore, we have decided to use a machine learning approach to learn a sentiment classifier from a set of class-labeled examples.</p><p>An algorithm, standardly used in document classification, is the linear Support Vector Machine (SVM) <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b12">13]</ref>. The SVM algorithm has several advantages, which are important for learning a sentiment classifier from a large Twitter dataset.</p><p>For example, it is fairly robust to overfitting and it can handle large feature spaces <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b59">60]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The data used for initial classifier training</head><p>Since there is no publicly available large hand-labeled data set for sentiment analysis of Twitter data, we have trained the general purpose tweet sentiment classifier on an available large collection of 1,600,000 (800,000 positive and 800,000 negative) tweets collected and prepared by Stanford University <ref type="bibr" target="#b21">[22]</ref>, where the tweets were labeled based on a presence of positive and negative emoticons. Therefore, the emoticons approximate the actual positive and negative sentiment labels. This approach was proposed by Read <ref type="bibr" target="#b51">[52]</ref>. For example, if a tweet contains the '':)'' emoticon, it is labeled as positive, and if it contains the '':('' emoticon, it is labeled as negative. Tweets containing both positive and negative emoticons were not taken into account. The full list of emoticons used for labeling can be found in Table <ref type="table" target="#tab_0">1</ref>. Inevitably, this simple approach causes partially correct or noisy labeling. However, in Appendix A, we illustrate that smiley-labeled tweets are still a reasonable approximation for manually-annotated positive/negative sentiments of tweets. In the dataset, the emoticons were already removed from the tweets in order for the classifier to learn from the other features that characterize them. Note that the tweets from this set do not focus on any particular domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Data preprocessing</head><p>The data preprocessing step is important in sentiment analysis and with appropriate selection of preprocessing techniques, the classification accuracy can be improved <ref type="bibr" target="#b25">[26]</ref>. We apply both Twitter-specific and standard preprocessing on the data set. The Twitter-specific preprocessing is necessary, since the Twitter community has created its own specific lan- guage to post messages. Therefore, we first explored the unique properties of this language and experimented with the following options <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22]</ref> for Twitter-specific preprocessing to better define the feature space: Usernames: mentioning other users in a tweet in the form @TwitterUser was replaced by a single token named</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USERNAME.</head><p>Usage of web links: Web links pointing to different web pages were replaced by a single token named URL.</p><p>Letter repetition: repetitive letters with more than two occurrences in a word were replaced by a word with one occurrence of this letter (e.g., word loooooooove was replaced by love).</p><p>Negations: we replaced negation words (not, isn't, aren't, wasn't, weren't, hasn't, haven't, hadn't, doesn't, don't, didn't) with a unique token NEGATION. Using this approach, we do not lose information about a negation, but treat all negation expressions in the same way.</p><p>Exclamation and question marks: exclamation marks were replaced by a single token EXCLAMATION and question marks by a single token QUESTION.</p><p>In addition to Twitter-specific text preprocessing, other standard preprocessing steps were performed <ref type="bibr" target="#b18">[19]</ref> to define the feature space for tweet feature vector construction. These include text tokenization (text splitting into individual words/ terms), removal of stopwords (words carrying no relevant information, e.g., and, or, a, an, the, etc.), stemming (converting words into their root form), and N-gram construction (concatenating 1-N stemmed words appearing consecutively in the text, where N = 2) for feature space reduction. We also added the condition that a given term has to appear at least twice in the entire corpus, either twice in a given tweet or in two different tweets. The resulting terms were used as features in the construction of feature vectors representing the documents (tweets). In our experiments, we did not use a part of speech (POS) tagger, since it was indicated by Go et al. <ref type="bibr" target="#b21">[22]</ref> and Pang et al. <ref type="bibr" target="#b47">[48]</ref> that POS tags are not useful when using SVMs for sentiment analysis. Moreover, Kouloumpis et al. <ref type="bibr" target="#b35">[36]</ref> showed that POS features may not be useful for sentiment analysis in the microblogging domain.</p><p>The standard approach to feature vector construction is TF-IDF-based, where TF-IDF stands for the ''term frequencyinverse document frequency'' feature weighting scheme <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b83">84]</ref>. TF is the term frequency feature weighting scheme, where a weight reflects how often a word is found in a document, while TF-IDF is the term frequency-inverse document frequency feature weighting scheme, where a weight reflects how important a word is to a document in a document collection (TF-IDF increases proportionally to the number of times a word appears in the document, but decreases with respect to the number of documents in which the word occurs). We experimented with both schemes, TF-IDF-and TF-based, where for every document (tweet) TF weights were normalized to a range of [0, 1]. As shown in Table <ref type="table" target="#tab_1">2</ref>, the TF-based approach proved to outperform the TF-IDF-based approach to tweet preprocessing, which is expected in a classification setting <ref type="bibr" target="#b38">[39]</ref>. The significance of the finding is confirmed using the Wilcoxon's significance test <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b82">83]</ref>, which concluded that using TF is statistically significantly better than TF-IDF (with p &lt; 8:0 Â 10 À7 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Selecting the best preprocessing setting for classifier training</head><p>The experiments with different Twitter-specific preprocessing settings were performed to determine the best preprocessing options which were used in addition to the standard text preprocessing steps. The best preprocessing setting for a classifier<ref type="foot" target="#foot_2">5</ref> was chosen according to the F-measure (also known as F-score or F1 score) <ref type="bibr" target="#b77">[78]</ref>, determined using the ten-fold cross-validation method. <ref type="foot" target="#foot_3">6</ref> The F-measure was used for comparison of different preprocessing settings since later, in the active learning experiments, to compare different querying strategies, we calculate the F-measure of positive tweets as there is high three-class imbalance in batches from the data stream. In order to be consistent and allow the reader to compare results in our paper, we used the F-measure in all our experiments.</p><p>The experiments show that the best preprocessing setting is Setting 1 shown in the first row of Table <ref type="table" target="#tab_1">2</ref>. It is TF-based, uses maximum N-grams of size 2, words which appear at least two times in the corpus, it replaces links with the URL token, and replaces negations with the NEGATION token. This tweet preprocessing setting resulted in the construction of 1,288,681 features used for classifier training. Using the unpaired one-tailed homoscedastic t-test <ref type="bibr" target="#b53">[54]</ref>, we investigated whether the best preprocessing setting (Setting 1) is statistically significantly better than the other preprocessing settings. The results show that the best preprocessing setting is not significantly better than Settings 2-12,14, and 16, but it is significantly better than the remaining preprocessing settings (Setting 13, Setting 15, Settings 17-32) with a p-value lower than 0.05.</p><p>Since in these experiments the original dataset was pre-filtered and did not contain tweets with both positive and negative emoticons, the reported results may be somewhat overoptimistic (i.e., if the data were not pre-filtered and contained also tweets with mixed emoticons, the results in terms of the F-measure would probably be somewhat lower). Nevertheless, even if the reported results are overoptimistic, this property of the dataset does not affect the general conclusions concerning the choice of preprocessing settings, given that in all the settings the dataset was preprocessed in the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INS 10845</head><p>No. of Pages 23, Model 3G</p><p>From Table <ref type="table" target="#tab_1">2</ref>, it follows that replacing negation words is particularly beneficial since almost all settings which perform this replacement are placed in the upper part of the table. Replacing exclamation and question marks with a token does not seem to be helpful, since the five top settings do not employ this replacement. Regarding replacing usernames and URLs with a token, and removing letter repetition, one cannot draw general conclusion, since these preprocessing options are dispersed across the table. Nevertheless, the first setting employs replacing URLs with a token and we used it in the rest of our experiments. Interestingly, the setting which does not apply any of the preprocessing adjustments achieved the lowest performance, leading to the conclusion that, in general, it is beneficial to preprocess Twitter data.</p><p>In addition to the SVM algorithm, we also tested the k-nearest neighbor (KNN) and Naive Bayes classifiers on the same dataset. In this setting, the standard KNN algorithm proved to be too slow (in ten-fold cross-validation experiments for K = 5 and K = 10, the onefold experiment took more than 24 h on a standard desktop computer), and Naive Bayes had lower performance compared to the SVM (the ten-fold cross-validation achieved an F-measure of 0.73). We, thus, used the SVM classifier with preprocessing Setting 1 from Table <ref type="table" target="#tab_1">2</ref> for the rest of the study and analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Stock market analysis in a static predictive tweet analysis setting</head><p>Motivated by the earlier research and observation that the stock market itself can be considered as a measure of social mood <ref type="bibr" target="#b44">[45]</ref>, this section investigates whether sentiment analysis on Twitter posts can provide predictive information about the value of stock closing prices. We use a supervised machine learning approach to train a sentiment classifier, using a SVM algorithm. By applying the best setting for tweet preprocessing, as explained in Section 3.4, two sets of experiments were performed. In the first set of experiments, tweets were classified into two categories, positive or negative. In the second set of experiments, the SVM classification approach was advanced by taking into account the neutral zone, enabling us to identify neutral tweets (not clearly expressing positive or negative sentiments) as those, positioned a small distance from the SVM model hyperplane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The data used in the stock market application</head><p>A tweet dataset and stock closing prices of several companies were collected for our experiments. On the one hand, we collected 152,570 tweets discussing relevant stock information concerning eight companies (Apple, Amazon, Baidu, Cisco, Google, Microsoft, Netflix, and RIM) 7 in the nine-month time period from March 11 to December 9, 2011. On the other hand, we collected stock closing prices of these companies for the same time period.</p><p>The data source for collecting financial Twitter posts is the Twitter API 8 (i.e., the Twitter Search API), which returns tweets that match a specified query. By informal Twitter conventions, the dollar-sign notation is used for discussing stock symbols. For example, the $BIDU tag indicates that the user discusses Baidu stocks. This convention was used for the retrieval of financial tweets. 9 The stock closing prices of the companies for each day were obtained from the Yahoo! Finance website.</p><p>The time of tweets in our dataset is presented in UTC (Coordinated Universal Time) since the Twitter API stores and returns dates and times in UTC. On the other hand, Baidu is included in the NASDAQ-100 index, and this stock exchange works in the EST (Eastern Standard Time)/EDT (Eastern Daylight Time) timezone which is four to five hours behind UTC.</p><p>Therefore, compared to EST/EDT, there is an additional shift of four to five hours; thus, there is more of a time lag between the tweets of a previous day and the stock market activity and closing prices of the current day.</p><p>In the entire study, we focused on the analysis of financial tweets on the Chinese web search engine provider, Baidu, 10 in order to investigate relationships between the observed sentiments in the stock-related tweets and the corresponding stock price movements. The collection of Baidu tweets was manually labeled by the domain expert. The data of this Chinese web search engine provider was chosen for hand-labeling since the set of tweets related to Baidu was of a manageable size given the resources available (we collected and labeled approximately 11,000 tweets, compared to, for example, approximately 40,000 tweets that we collected for the Apple company). Even this hand-labeling effort took us over three months to ensure good quality of the labeled data.</p><p>In tweet labeling, we were faced with the problem of choosing a labeling strategy. Having discussed this issue at length with stock market financial experts, we opted for manual labeling of the tweets from the point of view of a particular company and not mainly on the sentiment-carrying words used. The reason for this decision is that our long-term intention is to construct classifiers that should distinguish between sentiments of tweets of different companies; hence, a companyfocused view is a necessity. The labels were given to instances according to their financial sentiment; that is, their impact on the perception of the company, its products, or its stock. For example, a tweet: I just love shorting CompanyX. What a nice day of profits, first of many. . .would be labeled as negative, since shorting means betting that the value of the stock will drop. Despite many positive sentiment words, such a tweet would be providing a message of a negative financial prospect for CompanyX. Another issue was that in the dataset there are many tweets that do not discuss Baidu stocks, although they do contain the $BIDU tag. These tweets may actually express an opinion about another company, such as the tweet, ''Apple is great $BIDU'', and reflect a positive tweet sentiment, but do not discuss the Baidu company at all. Again, these kinds of tweets were labeled from the point of view of the Baidu company, and not mainly on the sentiment-carrying words used. Therefore, the mentioned tweet would be labeled as neutral.</p><p>Therefore, in Baidu sentiment labeling, the annotator was instructed to focus on the following question:</p><p>''What would someone who knows what Baidu is and shares in general, think of Baidu and its shares after he sees this tweet?'', or in other words, ''Is this tweet positive, negative, or neutral concerning Baidu and/or the price of its shares?''</p><p>The resulting hand-labeled dataset consists of 11,389 Baidu financial tweets (4,861 positive, 1,856 negative, and 4,672 neutral tweets). 11 In this dataset, neutral tweets are those that contain no sentiment about Baidu, contain both positive and negative sentiments about Baidu, as well as those that do not discuss Baidu even if they are positively or negatively oriented (as discussed above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Correlation between tweet sentiment and stock closing price</head><p>Given the time series of tweet sentiments and the time series of stock closing prices, the question addressed is whether one time series is useful in forecasting another. We applied a statistical test to determine whether sentiments expressed in tweets contain predictive information about the future values of stock closing prices. To this end, we performed a Granger causality analysis test, which is a statistical hypothesis test for discovering whether one time series is effective for forecasting another time series <ref type="bibr" target="#b22">[23]</ref>. Since we have the tweets time series on the one hand and the stock closing price time series on the other hand, this test suits our needs to check whether there is a predictive relationship between sentiments in tweets and stock closing prices. If time series X is said to Granger-cause Y, then the information in past values of X helps predict values of Y better than only the information in past values of Y. Therefore, the lagged values of X will have a statistically significant correlation with Y.</p><p>7 Tweet IDs of our datasets are available on: http://streammining.ijs.si/TwitterStockSentimentDataset/TwitterStockSentimentDataset.zip. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INS 10845</head><p>No. of Pages 23, Model 3G</p><p>Granger causality analysis is based on linear regression modeling of stochastic processes and it is usually done using a series of t-tests and F-tests on lagged values of X (combined also with lagged values of Y). The test expects that the time series data is covariance stationary and that it can be represented by a linear model. Complex implementations for nonlinear cases exist; nevertheless, they are often more challenging to apply in practice <ref type="bibr" target="#b61">[62]</ref>.</p><p>The output of the Granger causality test is the p-value, which takes values in the [0, 1] interval. In statistical hypothesis testing, the p-value is a measure of how much evidence we have against the null hypothesis <ref type="bibr" target="#b56">[57]</ref>. If the p-value is lower than the selected significance level, for example 5% (p &lt; 0:05), the null hypothesis is rejected and the result is statistically significant. On the other hand, a large p-value represents weak evidence against the null hypothesis; thus, the null hypothesis cannot be rejected. The Granger causality test that we used is based on Free Statistics Software <ref type="bibr" target="#b81">[82]</ref>.</p><p>To enable in-depth analysis, we calculated a sentiment indicator for predictive sentiment analysis in finance, named positive sentiment probability: p sp , which was proposed in our previous work <ref type="bibr" target="#b70">[71]</ref>. Positive sentiment probability is computed for a day d of a time series by dividing the number of positive tweets N pos by the number of all tweets on that day N d .</p><formula xml:id="formula_0">p sp ðdÞ ¼ N pos ðdÞ=N d ðdÞ<label>ð1Þ</label></formula><p>This ratio is used to estimate the probability that the sentiment of a randomly selected tweet on a given day is positive.</p><p>To test whether one time series is useful in forecasting another, using the Granger causality test, we first calculated positive sentiment probability for each day when the stock market was open. We then calculated two ratios 12 to meet the Granger causality test condition that the time series data needs to be stationary:</p><p>Daily change of the positive sentiment probability D sent : positive sentiment probability today positive sentiment probability yesterday.</p><p>D sent ðdÞ ¼ p sp ðdÞ À p sp ðd À 1Þ</p><p>Daily return in stock closing price D price : (closing price today closing price yesterday)/closing price yesterday. 13     D price ðdÞ ¼ priceðdÞ</p><formula xml:id="formula_2">À priceðd À 1Þ priceðd À 1Þ<label>ð3Þ</label></formula><p>We applied the Granger causality test to test the following null hypothesis:</p><p>''sentiment in tweets does not predict stock closing prices'' (when rejected, meaning that the sentiment in tweets Granger-causes the values of stock closing prices).</p><p>We performed tests on the entire nine-month time period (from March 11 to December 9, 2011), as well as on individual three-month periods (corresponding approximately to March-May, June-August, and September-November). Results for Baidu are shown in the first column of Table <ref type="table" target="#tab_3">3</ref>. In Granger causality testing, we considered lagged values of time series for one, two, and three days.</p><p>Since in our experiments we compute the p-value repetitively and do multiple comparisons of p-values for different experimental settings, we used the Bonferroni correction <ref type="bibr" target="#b0">[1]</ref> to neutralize the problem of multiple comparisons. This correction is considered very conservative. It makes adjustments to a critical p-value by dividing it by the number of comparisons being made. In our case, we divided the p-value of 0.1 by 4, as this is the number of time periods (whole nine months and three three-month periods) which we consider to be a family of tests. We compare the p-values which came from the Granger causality test with 0.1/4 = 0.025 and reject the null hypothesis if the value is lower than 0.025. After applying the Bonferroni correction, the results of the Granger analysis indicated that in this particular setting there are no significant results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experiments in a three-class setting with the neutral zone</head><p>In the previous section, we classified financial tweets into one of the two categories, positive or negative, and therefore assumed that every tweet contains an opinion. This is, however, sometimes an unrealistic assumption, since a tweet can be objective and without any opinion about a given company (i.e., without expressed sentiment). Considering this, a tweet should also have the possibility of being classified as either neutral or weakly opinionated. In this section, we address a three class problem of classifying tweets into the positive, negative, and neutral categories.</p><p>Our training data does not contain any neutral tweets for the classifier to learn from. Therefore, we define a tweet, which is projected into an area close to the SVM model's hyperplane, as neutral. We define this area as the neutral zone, which is parameterized by value t, where t represents the positive and Àt the negative border of the neutral zone. If a tweet x is projected into this zone, that is, Àt &lt; dðxÞ &lt; t, then rather than being assigned to one of the two sentiment classes, it is assumed 12 The ratios were defined in collaboration with the domain experts from the Stuttgart Stock Exchange (see Acknowledgments). 13 The same transformation of the price time series was used in <ref type="bibr" target="#b54">[55]</ref>.</p><p>to be neutral. Note that our ''neutral zone'' does not denote only the ''neutral tweets'', such as tweets which would be labeled as neutral by a human annotator. Instead, the neutral zone contains also the tweets which are either positive or negative but close to the SVM hyperplane which separates the positives from the negatives. Thus, the neutral zone includes tweets containing mixed sentiments, weakly opinionated positive/negative tweets, as well as tweets containing terms which were not observed during the training phase (if human annotated neutral tweets were available, they would have been included in the neutral zone as well). For a greater t (i.e., greater size of the neutral zone), the classifier is more confident in its classification decision for positive and negative tweets. Our definition of the neutral zone is simple, but allows fast computation.</p><p>We repeated our experiments on classifying financial tweets, but now also took into account the neutral zone. Our aim was to investigate whether the introduction of the neutral zone would improve the predictive capabilities of tweets. Therefore, every tweet which mentioned the Baidu company was classified into one of the three categories: positive, negative, or neutral. Then, we applied the same processing of data as before (count the number of positive, negative, and neutral tweets, calculate positive sentiment probability, calculate daily changes of the positive sentiment probability and the daily return of the stocks' closing price) and performed the Granger analysis test. We varied the t value from 0 to 1 (where t = 0 corresponds to classification without the neutral zone) and again calculated the p-value for the separate day lags (1, 2, and 3). The results are shown in Table <ref type="table" target="#tab_3">3</ref>. The first column, where the size of the neutral zone is 0, represents the classification without the neutral zone, where financial tweets were classified into one of the two categories, positive or negative. All the remaining columns contain p-values for various sizes of the neutral zone. In Appendix B, we also report the results of the Granger causality correlation between positive sentiment probability and closing stock price for the rest of the companies (Apple, Amazon, Cisco, Google, Microsoft, Netflix, and RIM), whose tweets we collected. The results show that for several other companies,</p><p>the learned classifier has the potential to be useful for stock price prediction in terms of Granger causality.</p><p>Values which are lower than a p-value of 0.1, after applying the Bonferroni correction, are marked in bold in Table <ref type="table" target="#tab_3">3</ref>. The highest number of significant values was obtained with t values of 0.5 and 0.6 for the border distance of the neutral zone from the SVM hyperplane. Therefore, by introducing the neutral zone, we improved the predictive power of our classifier.</p><p>From Table <ref type="table" target="#tab_3">3</ref> it follows that for the June-August time period we achieved the best results and relationships between sentiments in tweets and stock closing prices. Therefore, we investigated in more detail the Baidu data and public web media from this time period to find possible reasons for this. Fig. <ref type="figure">1</ref> shows a screenshot from the Google Finance<ref type="foot" target="#foot_5">14</ref> web page displaying stock price and news media coverage for Baidu in 2011. From the figure, it can be observed that most of the key events in 2011 happened in the period from June to August. Note that this period is also characterized by the highest number of press releases <ref type="foot" target="#foot_6">15</ref> for Baidu in 2011. We hypothesize that this resulted in higher media exposure and, consequently, enabled speculations about price movements in social media. However, further studies are required to confirm or reject this claim.</p><p>In addition, we explored whether there is evidence for the reversed causality (that the price movements may influence the public sentiment). The results show that, after making adjustments to the critical p-value by applying the Bonferroni correction, no significant results were left for the reverse direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Summary of the proposed methodology for static predictive tweet analysis</head><p>We proposed a new methodology for determining the correlation between sentiments in tweets that discuss a company's relevant stock information and stock closing prices of the company to determine whether tweet sentiment contains predictive information about the value of the stock closing price. The methodological steps are presented in Fig. <ref type="figure">2</ref>. As follows from Fig. <ref type="figure">2</ref>, one should first provide a time series collection of tweets discussing relevant stock information concerning a company of interest. Tweets are then adequately preprocessed (see Section 3). Furthermore, tweets are classified as being positive, negative, or neutral, where tweet labels depend both on the output of the classifier and the size of the neutral zone. Moreover, for every day of a time series, positive sentiment probability is computed by dividing the number of positive tweets per day by the total number of tweets in that day. Last, daily changes of the positive sentiment probability are calculated.</p><p>On the other hand, the stock closing prices of the selected company for each day should be collected, which is publicly available information. Daily returns in the stock closing price are then calculated.</p><p>Given the daily changes of the positive sentiment probability time series and the daily returns in the stock closing price time series, Granger causality analysis is performed (considering lagged values of time series for one, two, and three days) to test whether tweet sentiment is useful for forecasting the movement of prices on the stock market and how significant the results are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Active learning on financial tweet streams for stock market analysis</head><p>In the previous section, we classified financial tweets by using a static classifier, which was learned from smiley-labeled general purpose tweets. A significant correlation between the sentiment in financial tweets in the static tweet analysis setting motivated further advances. We focused on three goals: to make the classifier more domain-specific in order to better classify financial tweets; to extend the approach with a capability of continuous updating of the classifier in order to adapt to sentiment vocabulary changes in a data stream; and, in addition to smiley-labeled tweets, to also use hand-labeled financial tweets in the training phase. The crucial element of addressing these challenges was the use of the active learning approach.</p><p>In active learning, the learning algorithm interactively queries for manual labels of selected data items. Typically, the active learning algorithm first learns from a small labeled dataset. According to this initial model and the characteristics Fig. <ref type="figure">1</ref>. Screenshot from the Google Finance web page showing stock prices and key events. It can be observed that most of the key events in 2011 happened in the period from June to August. We hypothesize that this resulted in a higher media exposure and, consequently, enabled speculations about price movements in social media.</p><p>Fig. <ref type="figure">2</ref>. Methodological steps for predictive sentiment analysis applied to determine the correlation between tweets sentiment and stock closing prices.</p><p>of the newly observed unlabeled data instances, the algorithm selects a set of new instances to query an expert for their manual labels. This process is repeated until some threshold (e.g., time limit, labeling quota, or target performance) is reached or, as it is the case in stream data, it continues as long as the application is active. This approach largely decreases the number of data instances that need to be manually labeled.</p><p>In our experiments, the active learning algorithm first learns from the Stanford smiley-labeled dataset. According to this initial model, the algorithm selects a set of financial tweets from a first batch of data from a data stream to query for their manual labels. Based on these hand-labeled financial tweets, the model is updated and the process is repeated for the next batch of financial tweets. This process is repeated until the end of our simulated data stream is reached. In this way, with time and by updating the model with hand-labeled financial tweets, the sentiment classifier is improved and made more domain specific. Since we use the machine learning approach, sentiment discovery based on tweets may change over time.</p><p>If we used an approach based on a sentiment lexicon, incremental active learning would not make sense since sentimentbearing words (senti-words) typically do not change over time (e.g., the word ''excellent'' surely would not change its sentiment over time). However, taking as a basis the Bag-of-Words document representation, our approach is different, and not based solely on words that explicitly bear sentiment. The classifier takes into account all the terms appearing in tweets including those representing names of people, products, technologies, countries, etc., whose impact on sentiment may change over time and can even completely shift their sentiment polarity (consider terms like ''Ireland,'' whose sentiment has changed in recent history due to the developments of the current financial crisis).</p><p>Since it is very difficult and costly to obtain hand-labeled datasets of tweets, especially if they are domain dependent, an active learning approach is highly suitable for our task. The learning algorithm is able to interactively query the expert to obtain the manual labels as new financial tweets come from a data stream. Consequently, the sentiment classifier is more domain specific, it is updated in time in order to detect the changes in sentiment and handle concept drift, and it is improved using highly reliable hand-labeled tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental setting</head><p>To address the challenging task of stream-based sentiment analysis, we employed and tested a selection of active learning strategies and settings. The proposed learning algorithm interactively queries the user to obtain the labels of the tweets which are the closest to the boundaries of the neutral zone. With this approach, with time, the classifier learns how to better distinguish between the neutral and the opinionated (positive/negative) tweets. Note that when the size of the neutral zone is 0, the querying algorithm represents the standard uncertainty sampling approach. We test this hypothesis against the random strategy, and also combine these two strategies. In all the experiments, we varied the size of the neutral zone in order to find the best one.</p><p>In our implementation of the active learning approach, we used the Pegasos SVM <ref type="bibr" target="#b68">[69]</ref> learning algorithm from the sofiaml (Suite of Fast Incremental Algorithms for Machine Learning) library <ref type="bibr" target="#b58">[59]</ref>. We adjusted this learning algorithm to our active learning experiments. To construct the initial sentiment model for active learning experiments, we used 1,600,000</p><p>Stanford general purpose smiley tweets <ref type="bibr" target="#b21">[22]</ref>.</p><p>For the evaluation of the algorithms, we used the holdout evaluation approach [5], where classifier evaluation is performed using a separate unseen holdout set of test examples (in our case: tweets) <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref> We evaluated our classification model in two different settings: after every 50 and 100 tweets which come from the data stream and represent a batch. After the testing of a batch is completed, the algorithm selects 10 tweets for hand-labeling.</p><p>Then, only positive and negative labeled tweets are used for additional training, while neutral ones are discarded. We implemented the following strategies for the selection of tweets for labeling as part of the active learning process:</p><p>Active closest to the neutral zone: The algorithm selects 10 tweets that are closest to the boundaries of the neutral zone to be labeled by the human annotator. Out of the selected 10 tweets, at most, five are positive and five are negative, based on positive/negative labeling by the classifier.</p><p>Active combination: This strategy combines the other two strategies in order to better explore the SVM space. We experimented with two combinations: 80% ''Closest to the neutral zone'' and 20% random strategy (Active combination 20% random) and 50% ''Closest to the neutral zone'' and 50% random strategy (Active combination 50% random). In the combination strategies, the maximum number of positive/negative tweets selected for hand-labeling from a batch with ''Closest to the neutral zone'' is five.</p><p>Active random 100%: The algorithm randomly selects 10 tweets from a batch of tweets from the data stream.</p><p>To compare different querying strategies, for every batch in the stream, we calculated the F-measure of positive tweets.</p><p>The reason for using the F-measure is the unbalanced class distribution in batches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INS 10845</head><p>No. of Pages 23, Model 3G</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Determining the best active learning setting</head><p>To identify the best active learning setting in terms of the active learning strategy, the batch size, and the size of the neutral zone, we calculated the average F-measure for every strategy at different sizes of the neutral zone (see Table <ref type="table" target="#tab_4">4</ref>). The three active learning strategies introduced in Section 5.1 were compared together with the algorithm which did not use the active learning approach (i.e., it did not update the sentiment classifier with time).</p><p>In terms of exploring the best size of the neutral zone, we experimented with all the active learning strategies. The results in Table <ref type="table" target="#tab_4">4</ref> indicate that, in general, the active learning approach improves the performance of the classifier compared to the strategy, which does not use active learning. The table allows for some other observations as well. For example, in all the strategies, the results show that in terms of the F-measure, it is better to have no neutral zone or a very small one (0.0001). Moreover, one can observe that the random component of the querying strategies has mixed effects.</p><p>To test the significance of the differences between the multiple settings, we followed the procedure recommended in <ref type="bibr" target="#b15">[16]</ref>.</p><p>Namely, we first used the Friedman test <ref type="bibr" target="#b20">[21]</ref> with the Iman-Davenport improvement <ref type="bibr" target="#b28">[29]</ref> to check whether the difference in performance is statistically significant, and then the Nemenyi post hoc test <ref type="bibr" target="#b43">[44]</ref> to search where the significant differences appear.</p><p>The Friedman test ranks the algorithms for each dataset separately, where the best performing algorithm gets the rank of 1, the second best rank 2, etc. In the case of ties (we used the F-measure computed to a precision of three decimal points), average ranks are assigned. The Friedman test then compares the average ranks of the algorithms. The null hypothesis states that all the performance of the algorithms is equal and, thus, their ranks should be equal. If the null hypothesis is rejected, we can proceed with a post hoc test. The Nemenyi test <ref type="bibr" target="#b43">[44]</ref> needs to be used since all the settings must be compared to each other. The Nemenyi test computes the critical distance between the different strategies, and concludes that the differences between the F-measures are statistically significant if the corresponding average ranks of the corresponding algorithms differ by at least the critical distance.</p><p>The results of the significance post hoc tests are graphically represented using critical diagrams. Fig. <ref type="figure" target="#fig_4">3</ref> shows the results of the analysis of the F-measures from Table <ref type="table" target="#tab_4">4</ref>. On the axis of each diagram, we plot the average rank of the settings. The lowest (best) ranks are to the right. We show the critical distance on the top, and connect the settings that are not significantly different. From the results we can draw several conclusions. ''Select 10 of 100'' batch selection is better than ''Select 10 of 50'' batch selection, but not significantly better. Settings without the active learning approach showed poor performance compared to the settings with the active learning approach. Overall, the best setting for active learning is to choose 10 tweets in each batch of 100 tweets and use the querying strategy ''Closest to the neutral zone''. This setting is significantly better than ''Select 10 of 50'' batch selection without active learning.</p><p>Next, we applied the Friedman test with the Iman-Davenport improvement <ref type="bibr" target="#b28">[29]</ref> and its corresponding post hoc Nemenyi test <ref type="bibr" target="#b43">[44]</ref> on individual batch selection strategies. In Fig. <ref type="figure" target="#fig_2">4</ref>, the results of the test on the case ''Select 10 of 50'' batch selection can be seen. Similarly, Fig. <ref type="figure" target="#fig_3">5</ref> shows results of the ''Select 10 of 100'' batch selection. From both figures it follows that strategies with the active learning approach are significantly better than the strategy without the active learning approach.</p><p>Additionally, we performed another experiment where incremental active learning was performed from Baidu data only;</p><p>that is, the active learning algorithm first learns from the 100 positive and 100 negative tweets chosen from the first 1000 hand-labeled financial tweets from the Baidu dataset. According to this initial model, the algorithm selects a set of financial tweets from a first batch of data from the Baidu tweet data stream to query for their labels. Based on these hand-labeled financial tweets, the model is updated and the process is repeated for the next batch of Baidu tweets. This process is repeated until we reach the end of our simulated data stream. For this experiment, we used the ''Combination 50% random'' active learning approach with the size of the neutral zone 0.001 and ''Select 10 of 100'' batch selections. The results indicate that the classifier learned on such a small initial dataset, although hand-labeled and specific for the financial domain, is highly unstable. The sentiment classifier learned on this dataset classified all tweets at the beginning of the data stream as negative. Then, as a consequence of active learning and improving the classifier with new labeled tweets, the classifier improved and started to classify new tweets as positive or negative. This improvement lasted for several batches, and then the classifier classified all new coming tweets as positive. This behavior indicates that the classifier was highly unstable since incremental learning introduced significant changes into the model with the occurrence of every new labeled tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Stock market analysis with active learning</head><p>Our active learning experiments showed that the best setting for learning from financial Twitter stream data is to divide tweets from the data stream into batches of 100 tweets out of which 10 tweets from each batch are selected for hand-label-    <ref type="table" target="#tab_4">4</ref>.</p><p>ing based on a querying strategy. In order to provide better randomization of the search space, we chose the strategy which combines 50% ''Closest to the neutral zone'' and 50% random strategy. We repeated the Granger causality analysis in order to see if this strategy improved the predictive power of financial tweets to predict the stock closing price of the Baidu company.</p><p>The results can be seen in Table <ref type="table" target="#tab_5">5</ref>.</p><p>Since in our experiments we compute the p-value repetitively and make multiple comparisons of p-values, we applied the Bonferroni correction <ref type="bibr" target="#b0">[1]</ref> to neutralize the problem of multiple comparisons. As in the static part of our paper (Section 4), we divide the critical p-value of 0.1 by 4, as this is the number of time periods (whole nine-month and three three-month periods) which we consider to be a family of tests. The p-values that remain significant after this correction are marked in bold in the table. As can be seen from Table <ref type="table" target="#tab_5">5</ref>, the best correlations were obtained for the June-August time period as in the static approach.</p><p>Additionally, we explored whether there is evidence for the reversed causality (that the price movements may influence the public sentiment). The results show that there is some causality in that direction, but after making adjustments to the critical p-value by applying the Bonferroni correction, no significant results were left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Simulation of online experiments</head><p>Here we present a simulation of online experiments to test whether the sentiments in tweets can predict stock prices in real time and consequently provide returns. This experimental simulation is provisional and not exhaustive, since we only experimented with a selection of basic trading strategies, but it provides an indication of the real-world value of the proposed methodology. The simulation was based on a Baidu dataset from March 14 to December 9, 2011, and the results (money + stocks' value per day) are plotted in Fig. <ref type="figure">6</ref>. In every strategy, an investor had US$100,000 at the start. He buys 100 stocks on the first day. Buying and selling decisions for the following days depend on a selected trading strategy. The size of the neutral zone is 0.001. We experimented with three trading strategies:  Random: Every day the investor randomly chooses whether to buy or sell one stock.</p><p>In the first three columns of form Strategy 2 and remained better until the end of the simulation. In the figure, the period where the first change in performance of these two strategies occurs is zoomed in. For this experiment, we used the ''Combination 50% random'' active learning approach and ''Select 10 of 100'' batch selections with neutral zone 0.001.</p><p>Therefore, the simulation of online experiments indicates that our approach is useful for online stock trading. The lowest performance was observed with the random strategy, while the best performance was obtained with the strategy which uses the active learning approach.</p><p>5.5. Summary of the proposed methodology for stream-based active learning for Twitter sentiment analysis in finance</p><p>The proposed methodology for stream-based active learning for Twitter sentiment analysis in finance consists of the sequence of methodological steps presented in Fig. <ref type="figure" target="#fig_6">7</ref>. Components which are specific to the stream-based setting and not present in the static setting (Fig. <ref type="figure">2</ref>) are colored gray.</p><p>As can be seen from the figure, one should first provide a stream of financial tweets discussing stock relevant information concerning a company of interest. The algorithm then collects a batch of examples from the stream and conducts preprocessing on them. After classification of tweets as positive, negative, or neutral, based on a querying strategy, the algorithm selects tweets for hand-labeling. With this new labeled data, the model is updated. These steps are repeated for all batches in the data stream. For every day of a time series, the positive sentiment probability is computed by dividing the number of positive tweets per day by the total number of tweets in that day. Lastly, daily changes of the positive sentiment probability are calculated.</p><p>On the other hand, the stock closing prices of a selected company for each day should be collected. The daily returns in the stock closing price are then calculated (as presented in Section 4) in order to satisfy stationary conditions demanded by the Granger causality test.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INS 10845</head><p>No. of Pages 23, Model 3G</p><p>Given the daily changes of the positive sentiment probability time series and the daily returns in the stock closing price time series, Granger causality analysis is performed (considering lagged values of time series for one, two, and three days) to test whether tweet sentiment is useful for forecasting the movement of prices in the stock market and how significant the results are.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Predicting future values of stock prices is an interesting task, commonly connected to the analysis of public mood. Given that more and more personal opinions are made available online, various studies indicate that these kinds of analyses can be automated and can produce useful results. This paper investigates whether Twitter feeds are a suitable data source for predictive sentiment analysis. The study indicates that sentiment analysis of public mood derived from Twitter feeds can be used to eventually forecast movements of individual stock prices. Additionaly, the SVM neutral zone gave us the ability to classify tweets into the neutral category and proved to be useful for improving the predictive power by strengthening the correlation between the opinionated tweets and the stock closing price.</p><p>Furthermore, the methodology was adapted to a stream-based setting using the incremental active learning approach, which provides the algorithm with the ability to choose new training data from a data stream for hand-labeling. A series of experiments was conducted to find the best querying strategy for financial Twitter data. The experiments indicate that by using the active learning approach, the prediction power of the sentiment classifier in the stock market application is further improved. With our study, we introduced stream-based active learning for sentiment analysis of microblogging messages in the financial domain, which contributes both to sentiment analysis and the active learning research area, since this issue is still insufficiently explored.</p><p>Our approach seems to be useful also for online stock trading. We presented initial experimental results of a simulation where we tested whether the sentiments in tweets can predict values of future stock prices in real time and, consequently, provide returns. Initial results indicate that by augmenting a trading strategy with consideration of the changes in the values of positive sentiment probability one could improve the returns.</p><p>In further work, we plan to expand the number of companies to further test our stream-based methodology for sentiment analysis of microblogging messages in the financial domain. Moreover, our work would benefit from using other (preferably hand-labeled) datasets in order to obtain more realistic performance estimates in tests of preprocessing settings and an even better initial sentiment classifier. Since in this study we used a rather simple neutral zone, we plan to improve its sophistication and adaptability with time. Finally, we plan to improve our methodology by developing techniques of specific tweet concept drift detection and by tackling the detection of irony and sarcasm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Uncited references</head><p>[6,25] Q3 .</p><p>negation words (e.g., ''not,'' ''isn't,'' ''aren't,'' ''wasn't,'' etc.) is associated with negative emoticons, and probably negative feelings.</p><p>To address this concern even further, we conducted an additional experiment: we obtained a manually-labeled collection (subset) of smiley-labeled tweets and computed how accurate emoticons are as labels. Their accuracy on 1500 positive and negative manually-labeled tweets was 86.40%. This result provides an error estimate and illustrates that smiley-labeled tweets are a reasonable approximation for manually-annotated positive/negative sentiment of tweets.</p><p>Furthermore, using the best preprocessing setting, as explained in Section 3.4, we trained a classifier and classified the Baidu tweets with the learned SVM classifier into one of two categories (positive or negative), counted the number of positive and negative tweets for each day of the time series, and plotted them together with their difference, the moving average of the difference (averaged over five days), and the stock closing price per day. The visual presentation of the sentiment time series for Baidu can be seen in Fig. <ref type="figure" target="#fig_7">8</ref>. The peaks show the days when people intensively tweeted about the stocks. In the experiments for the visualization, we classified only the tweets whose dates corresponded to the dates when the stock market was open. The rest of the tweets (e.g., tweets which were written on weekends or non-working days of the stock market) were discarded and not analyzed.  In order to inspect how accurate the smiley-based sentiment classifier is, we calculated the F-measure on all of the handlabeled tweets from the Baidu dataset using the sentiment classifier learned on the Stanford smiley-labeled dataset. In this experiment we achieved an F-measure of 0.517 (baseline is 0.33). We have also calculated the F-measure on the positive and negative hand-labeled Baidu tweets and achieved an F-measure of 0.671. Additionally, we employed ten-fold cross-validation experiments, using SVM on the all (positive, negative and neutral) hand-labeled tweets from the Baidu dataset and achieved average F-measure of 0.645.</p><p>Given the manually labeled 11,389 Baidu tweets, we were able to plot a figure also for this data (see Fig. <ref type="figure" target="#fig_8">9</ref>) based on true positive and negative labels. Additionally, we plotted a graph (see Fig. <ref type="figure" target="#fig_9">10</ref>) which presents the moving average of the sentiment difference (averaged over five days) for hand-labeled positive and negative tweets and the ones classified as positive or negative by our SVM sentiment classifier. As it can be seen from the figure, the biggest peaks of differences and general trend remain basically the same which leads to conclusion that classification obtained with our classifier learned on smiley-labeled tweets is comparable with manual labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B</head><p>This appendix reports experimental results of Granger causality correlation between positive sentiment probability and closing stock price for 8 companies (Apple, Amazon, Baidu, Cisco, Google, Microsoft, Netflix and Research In Motion). Results are shown in Table <ref type="table" target="#tab_9">8</ref>.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>. Based on a set of training examples, labeled as belonging to one of the two classes, an SVM algorithm represents the examples as points in the space and separates them by a hyperplane. The aim of the SVM is to place this hyperplane in such a way that examples of the two classes are divided by a gap that is as wide as possible. New examples are then mapped into that same space and classified based on the side of the hyperplane in which they reside. For training the tweet sentiment classifier, we used the SVM perf [32-34] implementation of the SVM algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>. In dynamic environments, where new examples come from a data stream and concept drift is assumed, an algorithm can collect a batch of examples from the data stream and use them to evaluate the model. The examples in the batch have not yet been used for training. The evaluation is repeated periodically for new batches of examples which come from the stream. After testing of a batch is complete, the algorithm selects the most suitable examples from the batch and asks an oracle to label them. The labeled examples are then used for additional training of the algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visualization of Nemenyi post hoc tests for the ''Select 10 of 50'' batch selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization of Nemenyi post hoc tests for the ''Select 10 of 100'' batch selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visualisation of Nemenyi post hoc tests for the active learning strategies on data from Table4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Strategy 1 :Strategy 2 :</head><label>12</label><figDesc>If the daily sentiment change of the previous day was above 0, the investor buys one stock. If the daily change was below 0 and he has at least one stock, he sells it. If the daily sentiment change of the previous day was above 0.05, the investor buys one stock. If the daily change was below 0.05 and he has at least one stock, he sells it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7. Methodological steps for stream-based active learning for Twitter sentiment analysis in finance. Components which are specific to the stream-based setting and not present in the static setting (Fig.2) are colored gray.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. Number of tweet posts classified as positive or negative, their difference, the moving average of the difference (averaged over 5 days), and the stock closing price per day for Baidu.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Number of hand-labeled positive and negative tweet posts, their difference, the moving average of the difference (averaged over 5 days), and the stock closing price per day for Baidu.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. The moving average of the difference (averaged over 5 days) for hand-labeled positive and negative tweets and the ones classified as positive or negative by the SVM sentiment classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,56.69,54.71,424.46,142.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>List of emoticons used for labeling the training set.</figDesc><table><row><cell>Positive emoticons</cell><cell>Negative emoticons</cell></row><row><cell>:)</cell><cell>: (</cell></row><row><cell>:-)</cell><cell>:-(</cell></row><row><cell>:)</cell><cell>: (</cell></row><row><cell>:D</cell><cell></cell></row><row><cell>=)</cell><cell></cell></row></table><note><p>4 LATINO (Link Analysis and Text Mining Toolbox) is open-source (mostly under the LGPL license) and is available at http://latino.sourceforge.net/.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Classifier performance evaluation for various preprocessing settings.</figDesc><table><row><cell>ID Usernames</cell><cell>URLs to</cell><cell>Remove</cell><cell>Negations</cell><cell>Exclamation and</cell><cell>Avg. F-measure ten-fold</cell></row><row><cell>to a token</cell><cell>a token</cell><cell>letter</cell><cell>to a token</cell><cell>question marks to</cell><cell>cross-val. ± std. dev. (TF)</cell></row><row><cell></cell><cell></cell><cell>repetition</cell><cell></cell><cell>tokens</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Statistical significance (p-values) of Granger causality correlation between positive sentiment probability and closing stock price for Baidu, while changing the size of the neutral zone (i.e., the t value from 0 to 1). Values which are lower than a p-value of 0.1, after applying the Bonferroni correction, are marked in bold.</figDesc><table><row><cell cols="2">Size of the neutral zone (t value)</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell>Time period</cell><cell>Lag</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell>1</cell><cell>0.066</cell><cell>0.373</cell><cell>0.417</cell><cell>0.228</cell><cell>0.318</cell><cell>0.504</cell><cell>0.213</cell><cell>0.217</cell><cell>0.549</cell><cell>0.585</cell><cell>0.905</cell></row><row><cell>March-May</cell><cell>1</cell><cell>0.403</cell><cell>0.306</cell><cell>0.463</cell><cell>0.359</cell><cell>0.439</cell><cell>0.367</cell><cell>0.542</cell><cell>0.864</cell><cell>0.970</cell><cell>0.896</cell><cell>0.614</cell></row><row><cell>June-August</cell><cell>1</cell><cell>0.069</cell><cell>0.124</cell><cell>0.203</cell><cell>0.070</cell><cell>0.164</cell><cell>0.392</cell><cell>0.157</cell><cell>0.068</cell><cell>0.240</cell><cell>0.376</cell><cell>0.340</cell></row><row><cell>September-November</cell><cell>1</cell><cell>0.061</cell><cell>0.399</cell><cell>0.420</cell><cell>0.377</cell><cell>0.372</cell><cell>0.243</cell><cell>0.193</cell><cell>0.673</cell><cell>0.838</cell><cell>0.792</cell><cell>0.969</cell></row><row><cell>9 Months</cell><cell>2</cell><cell>0.047</cell><cell>0.301</cell><cell>0.337</cell><cell>0.262</cell><cell>0.249</cell><cell>0.383</cell><cell>0.299</cell><cell>0.388</cell><cell>0.540</cell><cell>0.518</cell><cell>0.830</cell></row><row><cell>March-May</cell><cell>2</cell><cell>0.470</cell><cell>0.403</cell><cell>0.534</cell><cell>0.414</cell><cell>0.380</cell><cell>0.133</cell><cell>0.033</cell><cell>0.041</cell><cell>0.357</cell><cell>0.163</cell><cell>0.107</cell></row><row><cell>June-August</cell><cell>2</cell><cell>0.050</cell><cell>0.038</cell><cell>0.033</cell><cell>0.039</cell><cell>0.020</cell><cell>0.012</cell><cell>0.004</cell><cell>0.010</cell><cell>0.122</cell><cell>0.140</cell><cell>0.311</cell></row><row><cell>September-November</cell><cell>2</cell><cell>0.069</cell><cell>0.591</cell><cell>0.641</cell><cell>0.572</cell><cell>0.593</cell><cell>0.445</cell><cell>0.383</cell><cell>0.864</cell><cell>0.759</cell><cell>0.639</cell><cell>0.742</cell></row><row><cell>9 Months</cell><cell>3</cell><cell>0.041</cell><cell>0.295</cell><cell>0.386</cell><cell>0.299</cell><cell>0.323</cell><cell>0.424</cell><cell>0.359</cell><cell>0.367</cell><cell>0.543</cell><cell>0.515</cell><cell>0.830</cell></row><row><cell>March-May</cell><cell>3</cell><cell>0.664</cell><cell>0.613</cell><cell>0.756</cell><cell>0.661</cell><cell>0.568</cell><cell>0.203</cell><cell>0.050</cell><cell>0.104</cell><cell>0.511</cell><cell>0.340</cell><cell>0.197</cell></row><row><cell>June-August</cell><cell>3</cell><cell>0.098</cell><cell>0.076</cell><cell>0.059</cell><cell>0.100</cell><cell>0.050</cell><cell>0.021</cell><cell>0.011</cell><cell>0.029</cell><cell>0.199</cell><cell>0.171</cell><cell>0.293</cell></row><row><cell>September-November</cell><cell>3</cell><cell>0.028</cell><cell>0.277</cell><cell>0.341</cell><cell>0.264</cell><cell>0.343</cell><cell>0.437</cell><cell>0.471</cell><cell>0.790</cell><cell>0.877</cell><cell>0.805</cell><cell>0.898</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Values of average F-measure ± std. deviation for different strategies, while changing the size of the neutral zone (i.e., the t value).</figDesc><table><row><cell>Size of the neutral zone (t value)</cell><cell>0.0000</cell><cell>0.0001</cell><cell>0.001</cell><cell>0.01</cell></row><row><cell>Select 10 of 100</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Active closest to the neutral zone</cell><cell>0.5410 ± 0.1106</cell><cell>0.5403 ± 0.1104</cell><cell>0.5256 ± 0.1076</cell><cell>0.4314 ± 0.1016</cell></row><row><cell>Active combination 20% random</cell><cell>0.5413 ± 0.1108</cell><cell>0.5402 ± 0.1106</cell><cell>0.5249 ± 0.1076</cell><cell>0.4312 ± 0.1015</cell></row><row><cell>Active combination 50% random</cell><cell>0.5412 ± 0.1109</cell><cell>0.5396 ± 0.1104</cell><cell>0.5243 ± 0.1074</cell><cell>0.4309 ± 0.1013</cell></row><row><cell>Active random 100%</cell><cell>0.5411 ± 0.1109</cell><cell>0.5392 ± 0.1096</cell><cell>0.5246 ± 0.1079</cell><cell>0.4317 ± 0.1013</cell></row><row><cell>No active learning</cell><cell>0.5351 ± 0.1102</cell><cell>0.5334 ± 0.1098</cell><cell>0.5200 ± 0.1089</cell><cell>0.4284 ± 0.1011</cell></row><row><cell>Select 10 of 50</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Active closest to the neutral zone</cell><cell>0.5394 ± 0.1325</cell><cell>0.5380 ± 0.1330</cell><cell>0.5276 ± 0.1310</cell><cell>0.4310 ± 0.1299</cell></row><row><cell>Active combination 20% random</cell><cell>0.5390 ± 0.1327</cell><cell>0.5380 ± 0.1330</cell><cell>0.5273 ± 0.1314</cell><cell>0.4310 ± 0.1299</cell></row><row><cell>Active combination 50% random</cell><cell>0.5387 ± 0.1325</cell><cell>0.5369 ± 0.1328</cell><cell>0.5258 ± 0.1309</cell><cell>0.4313 ± 0.1294</cell></row><row><cell>Active random 100%</cell><cell>0.5372 ± 0.1327</cell><cell>0.5368 ± 0.1326</cell><cell>0.5248 ± 0.1310</cell><cell>0.4304 ± 0.1297</cell></row><row><cell>No active learning</cell><cell>0.5298 ± 0.1331</cell><cell>0.5280 ± 0.1329</cell><cell>0.5141 ± 0.1345</cell><cell>0.4232 ± 0.1302</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Statistical significance (p-values) of Granger causality correlation between positive sentiment probability and the closing stock price for Baidu using active learning, while changing the size of the neutral zone (i.e., the t value). The combined strategy for selecting 10 of 100 tweets for labeling is presented. Values which are lower than a p-value of 0.1, after applying the Bonferroni correction, are marked in bold. Simulation of online experiments. The time period between June 24 and August 1 for Strategy 2 and Strategy 2 + AL is zoomed in, since in this time period, Strategy 2 + AL started to outperform Strategy 2 as a consequence of using the active learning approach.</figDesc><table><row><cell>Size of the neutral zone (t value)</cell><cell></cell><cell>0</cell><cell>0.0001</cell><cell>0.001</cell><cell>0.01</cell></row><row><cell>Select 10 of 100, combined 50% random</cell><cell>Lag</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell>1</cell><cell>0.0619</cell><cell>0.0611</cell><cell>0.0509</cell><cell>0.5883</cell></row><row><cell>March-May</cell><cell>1</cell><cell>0.8499</cell><cell>0.6551</cell><cell>0.6638</cell><cell>0.3617</cell></row><row><cell>June-August</cell><cell>1</cell><cell>0.0116</cell><cell>0.0075</cell><cell>0.0086</cell><cell>0.2732</cell></row><row><cell>September-November</cell><cell>1</cell><cell>0.9403</cell><cell>0.9572</cell><cell>0.9230</cell><cell>0.7565</cell></row><row><cell>9 Months</cell><cell>2</cell><cell>0.0275</cell><cell>0.0326</cell><cell>0.0309</cell><cell>0.1745</cell></row><row><cell>March-May</cell><cell>2</cell><cell>0.4685</cell><cell>0.4390</cell><cell>0.5721</cell><cell>0.5757</cell></row><row><cell>June-August</cell><cell>2</cell><cell>0.0176</cell><cell>0.0163</cell><cell>0.0127</cell><cell>0.3677</cell></row><row><cell>September-November</cell><cell>2</cell><cell>0.4807</cell><cell>0.4661</cell><cell>0.4010</cell><cell>0.2200</cell></row><row><cell>9 Months</cell><cell>3</cell><cell>0.0699</cell><cell>0.0826</cell><cell>0.0800</cell><cell>0.3177</cell></row><row><cell>March-May</cell><cell>3</cell><cell>0.3587</cell><cell>0.3886</cell><cell>0.5656</cell><cell>0.4772</cell></row><row><cell>June-August</cell><cell>3</cell><cell>0.0380</cell><cell>0.0372</cell><cell>0.0389</cell><cell>0.5708</cell></row><row><cell>September-November</cell><cell>3</cell><cell>0.3113</cell><cell>0.3292</cell><cell>0.2576</cell><cell>0.0868</cell></row><row><cell>Fig. 6.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table 6, we present average daily values (money + stocks value) for Strategy 1, Strategy 2, and the Random strategy. From Fig. 6 and the average daily values in Table 6, it follows that Strategy 2 outperforms Strategy 1and the Random strategy. Therefore, we combined the active learning algorithm with Strategy 2 to check whether the active learning approach could further improve this strategy. It turned out that, indeed, active learning improves the results as it can be observed in the time series ''Strategy 2 + AL'' of Fig.6and in the fourth column of Table6. At the beginning of the simulation, Strategy 2 and Strategy 2 + AL had the same performance. At the end of June, Strategy 2 + AL started to outper-</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6</head><label>6</label><figDesc>Average daily values (money + stocks value) for every strategy.</figDesc><table><row><cell>Strategy 1</cell><cell>Strategy 2</cell><cell>Random strategy</cell><cell>Strategy 2 + AL</cell></row><row><cell>101205.24</cell><cell>101214.42</cell><cell>101007.43</cell><cell>101269.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7</head><label>7</label><figDesc>The most relatively positive and negative sentiment-bearing terms from the smiley-labeled Stanford dataset.</figDesc><table><row><cell>Positive terms Document frequency difference Negative terms Document frequency difference '@' INS 10845 No. of Pages 23, Model 3G</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8</head><label>8</label><figDesc>Statistical significance (p-values) of Granger causality correlation between positive sentiment probability and closing stock price for 8 companies, while changing the size of the neutral zone, i.e., the t value from 0 to 1. Values which are lower than p-value of 0.1 are marked with bold.</figDesc><table><row><cell>INS 10845</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">No. of Pages 23, Model 3G</cell></row><row><cell cols="2">Size of neutral zone (t value)</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell>Time period</cell><cell>Lag</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Apple</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.7446</cell><cell>0.9211</cell><cell>0.6220</cell><cell>0.4407</cell><cell>0.3576</cell><cell>0.4793</cell><cell>0.4235</cell><cell>0.3455</cell><cell>0.4696</cell><cell>0.4415</cell><cell>0.5168</cell></row><row><cell>March-May</cell><cell></cell><cell>0.4480</cell><cell>0.5921</cell><cell>0.3978</cell><cell>0.6687</cell><cell>0.6496</cell><cell>0.7556</cell><cell>0.3841</cell><cell>0.3485</cell><cell>0.2970</cell><cell>0.1969</cell><cell>0.2378</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7307</cell><cell>0.5956</cell><cell>0.9755</cell><cell>0.6513</cell><cell>0.7153</cell><cell>0.9270</cell><cell>0.8409</cell><cell>0.9704</cell><cell>0.8173</cell><cell>0.8370</cell><cell>0.8726</cell></row><row><cell>September-November</cell><cell></cell><cell>0.5228</cell><cell>0.7405</cell><cell>0.7477</cell><cell>0.5463</cell><cell>0.3463</cell><cell>0.2288</cell><cell>0.2625</cell><cell>0.2773</cell><cell>0.3874</cell><cell>0.5021</cell><cell>0.6250</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.8440</cell><cell>0.9694</cell><cell>0.9154</cell><cell>0.5005</cell><cell>0.5766</cell><cell>0.6619</cell><cell>0.3964</cell><cell>0.3187</cell><cell>0.4171</cell><cell>0.5550</cell><cell>0.7341</cell></row><row><cell>March-May</cell><cell></cell><cell>0.0085</cell><cell>0.2395</cell><cell>0.2613</cell><cell>0.1452</cell><cell>0.2879</cell><cell>0.2202</cell><cell>0.0707</cell><cell>0.1157</cell><cell>0.0927</cell><cell>0.2053</cell><cell>0.2636</cell></row><row><cell>June-August</cell><cell></cell><cell>0.5560</cell><cell>0.6098</cell><cell>0.8244</cell><cell>0.9440</cell><cell>0.8974</cell><cell>0.8375</cell><cell>0.9658</cell><cell>0.9921</cell><cell>0.9389</cell><cell>0.9234</cell><cell>0.9437</cell></row><row><cell>September-November</cell><cell></cell><cell>0.8773</cell><cell>0.9781</cell><cell>0.9881</cell><cell>0.6626</cell><cell>0.4476</cell><cell>0.4147</cell><cell>0.3597</cell><cell>0.2557</cell><cell>0.4301</cell><cell>0.5279</cell><cell>0.6131</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.9307</cell><cell>0.9421</cell><cell>0.9291</cell><cell>0.8461</cell><cell>0.8695</cell><cell>0.9567</cell><cell>0.8628</cell><cell>0.7414</cell><cell>0.7986</cell><cell>0.7271</cell><cell>0.7277</cell></row><row><cell>March-May</cell><cell></cell><cell>0.0917</cell><cell>0.3378</cell><cell>0.4054</cell><cell>0.3662</cell><cell>0.5031</cell><cell>0.5769</cell><cell>0.3614</cell><cell>0.5064</cell><cell>0.4660</cell><cell>0.3180</cell><cell>0.4197</cell></row><row><cell>June-August</cell><cell></cell><cell>0.6805</cell><cell>0.7147</cell><cell>0.6528</cell><cell>0.8010</cell><cell>0.7286</cell><cell>0.6720</cell><cell>0.5144</cell><cell>0.4786</cell><cell>0.5496</cell><cell>0.4397</cell><cell>0.3039</cell></row><row><cell>September-November</cell><cell></cell><cell>0.9054</cell><cell>0.9874</cell><cell>0.9887</cell><cell>0.7135</cell><cell>0.5025</cell><cell>0.4639</cell><cell>0.3932</cell><cell>0.2521</cell><cell>0.4951</cell><cell>0.6118</cell><cell>0.7319</cell></row><row><cell>Amazon</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.6345</cell><cell>0.9798</cell><cell>0.9552</cell><cell>0.9362</cell><cell>0.6590</cell><cell>0.7368</cell><cell>0.3633</cell><cell>0.4433</cell><cell>0.7776</cell><cell>0.8148</cell><cell>0.6641</cell></row><row><cell>March-May</cell><cell></cell><cell>0.9912</cell><cell>0.7029</cell><cell>0.5652</cell><cell>0.5190</cell><cell>0.4136</cell><cell>0.4510</cell><cell>0.8119</cell><cell>0.7580</cell><cell>0.5641</cell><cell>0.6111</cell><cell>0.5377</cell></row><row><cell>June-August</cell><cell></cell><cell>0.3837</cell><cell>0.6021</cell><cell>0.8388</cell><cell>0.5821</cell><cell>0.9085</cell><cell>0.9921</cell><cell>0.5518</cell><cell>0.7976</cell><cell>0.8120</cell><cell>0.6791</cell><cell>0.9950</cell></row><row><cell>September-November</cell><cell></cell><cell>0.9036</cell><cell>0.7460</cell><cell>0.4902</cell><cell>0.8200</cell><cell>0.8425</cell><cell>0.9537</cell><cell>0.5568</cell><cell>0.4676</cell><cell>0.7286</cell><cell>0.5466</cell><cell>0.6946</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.5635</cell><cell>0.9153</cell><cell>0.8843</cell><cell>0.7442</cell><cell>0.2989</cell><cell>0.3351</cell><cell>0.1557</cell><cell>0.2282</cell><cell>0.2816</cell><cell>0.2323</cell><cell>0.3285</cell></row><row><cell>March-May</cell><cell></cell><cell>0.4927</cell><cell>0.2821</cell><cell>0.3812</cell><cell>0.4562</cell><cell>0.4542</cell><cell>0.4483</cell><cell>0.5508</cell><cell>0.9571</cell><cell>0.8094</cell><cell>0.8909</cell><cell>0.8664</cell></row><row><cell>June-August</cell><cell></cell><cell>0.5519</cell><cell>0.7992</cell><cell>0.9382</cell><cell>0.8123</cell><cell>0.6380</cell><cell>0.8333</cell><cell>0.8178</cell><cell>0.9929</cell><cell>0.8619</cell><cell>0.8835</cell><cell>0.8987</cell></row><row><cell>September-November</cell><cell></cell><cell>0.9756</cell><cell>0.8713</cell><cell>0.6644</cell><cell>0.1261</cell><cell>0.0334</cell><cell>0.0231</cell><cell>0.0042</cell><cell>0.0143</cell><cell>0.0458</cell><cell>0.0166</cell><cell>0.0232</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.7602</cell><cell>0.9759</cell><cell>0.9614</cell><cell>0.8624</cell><cell>0.5145</cell><cell>0.5477</cell><cell>0.3060</cell><cell>0.3685</cell><cell>0.4925</cell><cell>0.4106</cell><cell>0.4868</cell></row><row><cell>March-May</cell><cell></cell><cell>0.4056</cell><cell>0.2370</cell><cell>0.1970</cell><cell>0.1338</cell><cell>0.1336</cell><cell>0.1831</cell><cell>0.4617</cell><cell>0.8733</cell><cell>0.8205</cell><cell>0.6032</cell><cell>0.9265</cell></row><row><cell>June-August</cell><cell></cell><cell>0.8305</cell><cell>0.9054</cell><cell>0.9227</cell><cell>0.9161</cell><cell>0.7835</cell><cell>0.9103</cell><cell>0.8925</cell><cell>0.9998</cell><cell>0.7835</cell><cell>0.7259</cell><cell>0.4328</cell></row><row><cell>September-November</cell><cell></cell><cell>0.9838</cell><cell>0.8480</cell><cell>0.6074</cell><cell>0.1075</cell><cell>0.0344</cell><cell>0.0253</cell><cell>0.0070</cell><cell>0.0176</cell><cell>0.0475</cell><cell>0.0171</cell><cell>0.0291</cell></row><row><cell>Baidu</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0661</cell><cell>0.3726</cell><cell>0.4165</cell><cell>0.2280</cell><cell>0.3184</cell><cell>0.5041</cell><cell>0.2134</cell><cell>0.2171</cell><cell>0.5494</cell><cell>0.5845</cell><cell>0.9052</cell></row><row><cell>March-May</cell><cell></cell><cell>0.4035</cell><cell>0.3062</cell><cell>0.4633</cell><cell>0.3588</cell><cell>0.4391</cell><cell>0.3665</cell><cell>0.5424</cell><cell>0.8645</cell><cell>0.9701</cell><cell>0.8957</cell><cell>0.6142</cell></row><row><cell>June-August</cell><cell></cell><cell>0.0686</cell><cell>0.1243</cell><cell>0.2025</cell><cell>0.0697</cell><cell>0.1639</cell><cell>0.3923</cell><cell>0.1574</cell><cell>0.0681</cell><cell>0.2403</cell><cell>0.3761</cell><cell>0.3399</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0607</cell><cell>0.3992</cell><cell>0.4195</cell><cell>0.3766</cell><cell>0.3720</cell><cell>0.2428</cell><cell>0.1931</cell><cell>0.6731</cell><cell>0.8376</cell><cell>0.7920</cell><cell>0.9692</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0470</cell><cell>0.3006</cell><cell>0.3374</cell><cell>0.2620</cell><cell>0.2491</cell><cell>0.3826</cell><cell>0.2988</cell><cell>0.3877</cell><cell>0.5397</cell><cell>0.5178</cell><cell>0.8296</cell></row><row><cell>March-May</cell><cell></cell><cell>0.4704</cell><cell>0.4031</cell><cell>0.5336</cell><cell>0.4136</cell><cell>0.3805</cell><cell>0.1335</cell><cell>0.0332</cell><cell>0.0409</cell><cell>0.3572</cell><cell>0.1630</cell><cell>0.1073</cell></row><row><cell>June-August</cell><cell></cell><cell>0.0501</cell><cell>0.0378</cell><cell>0.0327</cell><cell>0.0393</cell><cell>0.0200</cell><cell>0.0116</cell><cell>0.0043</cell><cell>0.0101</cell><cell>0.1218</cell><cell>0.1401</cell><cell>0.3111</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0693</cell><cell>0.5913</cell><cell>0.6412</cell><cell>0.5719</cell><cell>0.5935</cell><cell>0.4454</cell><cell>0.3829</cell><cell>0.8635</cell><cell>0.7595</cell><cell>0.6386</cell><cell>0.7422</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0415</cell><cell>0.2945</cell><cell>0.3858</cell><cell>0.2988</cell><cell>0.3226</cell><cell>0.4245</cell><cell>0.3593</cell><cell>0.3673</cell><cell>0.5434</cell><cell>0.5150</cell><cell>0.8300</cell></row><row><cell>March-May</cell><cell></cell><cell>0.6636</cell><cell>0.6133</cell><cell>0.7557</cell><cell>0.6609</cell><cell>0.5678</cell><cell>0.2033</cell><cell>0.0503</cell><cell>0.1038</cell><cell>0.5105</cell><cell>0.3403</cell><cell>0.1969</cell></row><row><cell>June-August</cell><cell></cell><cell>0.0984</cell><cell>0.0759</cell><cell>0.0590</cell><cell>0.0995</cell><cell>0.0499</cell><cell>0.0208</cell><cell>0.0112</cell><cell>0.0291</cell><cell>0.1995</cell><cell>0.1708</cell><cell>0.2932</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0283</cell><cell>0.2774</cell><cell>0.3405</cell><cell>0.2644</cell><cell>0.3434</cell><cell>0.4368</cell><cell>0.4709</cell><cell>0.7899</cell><cell>0.8771</cell><cell>0.8048</cell><cell>0.8981</cell></row><row><cell>Cisco</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.3118</cell><cell>0.3725</cell><cell>0.3629</cell><cell>0.7742</cell><cell>0.9601</cell><cell>0.9658</cell><cell>0.9345</cell><cell>0.7237</cell><cell>0.3475</cell><cell>0.4044</cell><cell>0.4781</cell></row><row><cell>March-May</cell><cell></cell><cell>0.9664</cell><cell>0.3588</cell><cell>0.4149</cell><cell>0.3774</cell><cell>0.2866</cell><cell>0.1402</cell><cell>0.1928</cell><cell>0.1103</cell><cell>0.4691</cell><cell>0.6100</cell><cell>0.8670</cell></row><row><cell>June-August</cell><cell></cell><cell>0.6395</cell><cell>0.8037</cell><cell>0.5996</cell><cell>0.9649</cell><cell>0.5772</cell><cell>0.5328</cell><cell>0.5097</cell><cell>0.3414</cell><cell>0.1090</cell><cell>0.2052</cell><cell>0.2465</cell></row><row><cell>September-November</cell><cell></cell><cell>0.4107</cell><cell>0.5913</cell><cell>0.8078</cell><cell>0.9287</cell><cell>0.9568</cell><cell>0.9370</cell><cell>0.9931</cell><cell>0.9015</cell><cell>0.8982</cell><cell>0.8119</cell><cell>0.9346</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.2970</cell><cell>0.7836</cell><cell>0.6619</cell><cell>0.7989</cell><cell>0.7312</cell><cell>0.6285</cell><cell>0.7809</cell><cell>0.8541</cell><cell>0.6064</cell><cell>0.5774</cell><cell>0.6835</cell></row><row><cell>March-May</cell><cell></cell><cell>0.9149</cell><cell>0.3060</cell><cell>0.5873</cell><cell>0.6915</cell><cell>0.5558</cell><cell>0.3647</cell><cell>0.4760</cell><cell>0.3713</cell><cell>0.7580</cell><cell>0.9703</cell><cell>0.9714</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7471</cell><cell>0.9557</cell><cell>0.7590</cell><cell>0.6253</cell><cell>0.4594</cell><cell>0.4041</cell><cell>0.5016</cell><cell>0.5058</cell><cell>0.2081</cell><cell>0.3886</cell><cell>0.4378</cell></row><row><cell>September-November</cell><cell></cell><cell>0.3710</cell><cell>0.6240</cell><cell>0.8306</cell><cell>0.8808</cell><cell>0.9401</cell><cell>0.9636</cell><cell>0.9390</cell><cell>0.9507</cell><cell>0.9135</cell><cell>0.8185</cell><cell>0.8616</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.4299</cell><cell>0.9543</cell><cell>0.9225</cell><cell>0.8689</cell><cell>0.8052</cell><cell>0.6434</cell><cell>0.6323</cell><cell>0.8036</cell><cell>0.4910</cell><cell>0.3918</cell><cell>0.4664</cell></row><row><cell>March-May</cell><cell></cell><cell>0.9813</cell><cell>0.6299</cell><cell>0.7885</cell><cell>0.7101</cell><cell>0.5140</cell><cell>0.3389</cell><cell>0.4745</cell><cell>0.2374</cell><cell>0.3343</cell><cell>0.1625</cell><cell>0.3438</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7944</cell><cell>0.9506</cell><cell>0.7932</cell><cell>0.4264</cell><cell>0.2766</cell><cell>0.1812</cell><cell>0.2594</cell><cell>0.4166</cell><cell>0.1520</cell><cell>0.1781</cell><cell>0.1865</cell></row><row><cell>September-November</cell><cell></cell><cell>0.5070</cell><cell>0.7070</cell><cell>0.9287</cell><cell>0.9313</cell><cell>0.9693</cell><cell>0.9239</cell><cell>0.7458</cell><cell>0.8369</cell><cell>0.8635</cell><cell>0.7775</cell><cell>0.8375</cell></row><row><cell>Google</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.8868</cell><cell>0.5420</cell><cell>0.9140</cell><cell>0.9694</cell><cell>0.9395</cell><cell>0.9307</cell><cell>0.9332</cell><cell>0.9452</cell><cell>0.7282</cell><cell>0.9186</cell><cell>0.9919</cell></row><row><cell>March-May</cell><cell></cell><cell>0.0411</cell><cell>0.1051</cell><cell>0.0139</cell><cell>0.0193</cell><cell>0.0142</cell><cell>0.0290</cell><cell>0.0447</cell><cell>0.0497</cell><cell>0.0641</cell><cell>0.0498</cell><cell>0.0753</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7607</cell><cell>0.5689</cell><cell>0.6991</cell><cell>0.8971</cell><cell>0.8554</cell><cell>0.9389</cell><cell>0.9629</cell><cell>0.7535</cell><cell>0.5878</cell><cell>0.9496</cell><cell>0.7805</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0141</cell><cell>0.0116</cell><cell>0.0067</cell><cell>0.0014</cell><cell>0.0209</cell><cell>0.0314</cell><cell>0.0616</cell><cell>0.0833</cell><cell>0.1302</cell><cell>0.2168</cell><cell>0.4405</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.9518</cell><cell>0.8147</cell><cell>0.7848</cell><cell>0.9980</cell><cell>0.9790</cell><cell>0.9849</cell><cell>0.9708</cell><cell>0.9173</cell><cell>0.6978</cell><cell>0.7798</cell><cell>0.6635</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8</head><label>8</label><figDesc>(continued)    </figDesc><table><row><cell cols="2">Size of neutral zone (t value)</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell>Time period</cell><cell>Lag</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>March-May</cell><cell></cell><cell>0.0760</cell><cell>0.2664</cell><cell>0.0477</cell><cell>0.0653</cell><cell>0.0457</cell><cell>0.0653</cell><cell>0.0766</cell><cell>0.1059</cell><cell>0.1125</cell><cell>0.0867</cell><cell>0.1347</cell></row><row><cell>June-August</cell><cell></cell><cell>0.6283</cell><cell>0.5343</cell><cell>0.5107</cell><cell>0.6456</cell><cell>0.5366</cell><cell>0.6455</cell><cell>0.8501</cell><cell>0.6965</cell><cell>0.4376</cell><cell>0.7773</cell><cell>0.8606</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0138</cell><cell>0.0099</cell><cell>0.0246</cell><cell>0.0021</cell><cell>0.0277</cell><cell>0.0324</cell><cell>0.1072</cell><cell>0.0881</cell><cell>0.1812</cell><cell>0.3162</cell><cell>0.4338</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.6646</cell><cell>0.5766</cell><cell>0.6087</cell><cell>0.5101</cell><cell>0.4084</cell><cell>0.4739</cell><cell>0.7731</cell><cell>0.8193</cell><cell>0.5283</cell><cell>0.7775</cell><cell>0.7141</cell></row><row><cell>March-May</cell><cell></cell><cell>0.0990</cell><cell>0.1981</cell><cell>0.0534</cell><cell>0.1313</cell><cell>0.1428</cell><cell>0.1851</cell><cell>0.1940</cell><cell>0.1606</cell><cell>0.1845</cell><cell>0.1165</cell><cell>0.1159</cell></row><row><cell>June-August</cell><cell></cell><cell>0.4358</cell><cell>0.3669</cell><cell>0.3011</cell><cell>0.2063</cell><cell>0.1550</cell><cell>0.1852</cell><cell>0.4540</cell><cell>0.5222</cell><cell>0.2428</cell><cell>0.4229</cell><cell>0.5547</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0284</cell><cell>0.0187</cell><cell>0.0286</cell><cell>0.0025</cell><cell>0.0517</cell><cell>0.0568</cell><cell>0.1980</cell><cell>0.1729</cell><cell>0.2672</cell><cell>0.3963</cell><cell>0.4534</cell></row><row><cell>Microsoft</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.6679</cell><cell>0.3568</cell><cell>0.9189</cell><cell>0.9904</cell><cell>0.6432</cell><cell>0.5673</cell><cell>0.4413</cell><cell>0.1396</cell><cell>0.1362</cell><cell>0.1637</cell><cell>0.1617</cell></row><row><cell>March-May</cell><cell></cell><cell>0.6332</cell><cell>0.2487</cell><cell>0.4302</cell><cell>0.8703</cell><cell>0.8729</cell><cell>0.9392</cell><cell>0.5836</cell><cell>0.3472</cell><cell>0.4615</cell><cell>0.5502</cell><cell>0.5186</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7526</cell><cell>0.7787</cell><cell>0.7475</cell><cell>0.8899</cell><cell>0.5411</cell><cell>0.6378</cell><cell>0.7815</cell><cell>0.4765</cell><cell>0.2588</cell><cell>0.3150</cell><cell>0.3336</cell></row><row><cell>September-November</cell><cell></cell><cell>0.4650</cell><cell>0.7614</cell><cell>0.7444</cell><cell>0.6252</cell><cell>0.5487</cell><cell>0.7196</cell><cell>0.8068</cell><cell>0.9712</cell><cell>0.9020</cell><cell>0.9952</cell><cell>0.9776</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.9182</cell><cell>0.4222</cell><cell>0.7743</cell><cell>0.9600</cell><cell>0.6652</cell><cell>0.7169</cell><cell>0.7694</cell><cell>0.3678</cell><cell>0.2956</cell><cell>0.3127</cell><cell>0.3655</cell></row><row><cell>March-May</cell><cell></cell><cell>0.7817</cell><cell>0.0796</cell><cell>0.1162</cell><cell>0.2965</cell><cell>0.2726</cell><cell>0.6301</cell><cell>0.9859</cell><cell>0.7704</cell><cell>0.8678</cell><cell>0.8381</cell><cell>0.8103</cell></row><row><cell>June-August</cell><cell></cell><cell>0.8801</cell><cell>0.9219</cell><cell>0.7157</cell><cell>0.5411</cell><cell>0.4959</cell><cell>0.7137</cell><cell>0.4260</cell><cell>0.4561</cell><cell>0.2599</cell><cell>0.2092</cell><cell>0.3626</cell></row><row><cell>September-November</cell><cell></cell><cell>0.6129</cell><cell>0.4038</cell><cell>0.1949</cell><cell>0.3665</cell><cell>0.3150</cell><cell>0.3455</cell><cell>0.6157</cell><cell>0.7471</cell><cell>0.9247</cell><cell>0.8871</cell><cell>0.8367</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.1963</cell><cell>0.2644</cell><cell>0.8766</cell><cell>0.7262</cell><cell>0.4828</cell><cell>0.5401</cell><cell>0.7305</cell><cell>0.4060</cell><cell>0.2596</cell><cell>0.4274</cell><cell>0.4639</cell></row><row><cell>March-May</cell><cell></cell><cell>0.6349</cell><cell>0.2929</cell><cell>0.3842</cell><cell>0.6915</cell><cell>0.7104</cell><cell>0.8493</cell><cell>0.7085</cell><cell>0.7042</cell><cell>0.9156</cell><cell>0.8840</cell><cell>0.7872</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7867</cell><cell>0.8895</cell><cell>0.9172</cell><cell>0.7417</cell><cell>0.6345</cell><cell>0.9046</cell><cell>0.7276</cell><cell>0.7819</cell><cell>0.5362</cell><cell>0.5037</cell><cell>0.7192</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0769</cell><cell>0.1053</cell><cell>0.1184</cell><cell>0.2333</cell><cell>0.2847</cell><cell>0.3899</cell><cell>0.6335</cell><cell>0.5726</cell><cell>0.5449</cell><cell>0.6526</cell><cell>0.6384</cell></row><row><cell>Netflix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.9418</cell><cell>0.5072</cell><cell>0.5229</cell><cell>0.6627</cell><cell>0.7087</cell><cell>0.6704</cell><cell>0.5634</cell><cell>0.3848</cell><cell>0.2457</cell><cell>0.2784</cell><cell>0.1886</cell></row><row><cell>March-May</cell><cell></cell><cell>0.3323</cell><cell>0.2970</cell><cell>0.9020</cell><cell>0.9091</cell><cell>0.6241</cell><cell>0.1399</cell><cell>0.0695</cell><cell>0.1279</cell><cell>0.5991</cell><cell>0.9096</cell><cell>0.7988</cell></row><row><cell>June-August</cell><cell></cell><cell>0.2645</cell><cell>0.1996</cell><cell>0.1929</cell><cell>0.3070</cell><cell>0.0654</cell><cell>0.1364</cell><cell>0.2063</cell><cell>0.4115</cell><cell>0.9797</cell><cell>0.8229</cell><cell>0.7951</cell></row><row><cell>September-November</cell><cell></cell><cell>0.8447</cell><cell>0.8630</cell><cell>0.9653</cell><cell>0.9798</cell><cell>0.7571</cell><cell>0.5296</cell><cell>0.5541</cell><cell>0.4377</cell><cell>0.3088</cell><cell>0.3520</cell><cell>0.2598</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0025</cell><cell>0.0089</cell><cell>0.0162</cell><cell>0.0322</cell><cell>0.0573</cell><cell>0.0588</cell><cell>0.1097</cell><cell>0.2117</cell><cell>0.1163</cell><cell>0.0920</cell><cell>0.1188</cell></row><row><cell>March-May</cell><cell></cell><cell>0.6181</cell><cell>0.5854</cell><cell>0.9448</cell><cell>0.9558</cell><cell>0.8478</cell><cell>0.8944</cell><cell>0.7219</cell><cell>0.8333</cell><cell>0.9406</cell><cell>0.8737</cell><cell>0.7988</cell></row><row><cell>June-August</cell><cell></cell><cell>0.7579</cell><cell>0.6329</cell><cell>0.6350</cell><cell>0.7644</cell><cell>0.1848</cell><cell>0.2453</cell><cell>0.3260</cell><cell>0.3848</cell><cell>0.5909</cell><cell>0.5712</cell><cell>0.3979</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0005</cell><cell>0.0026</cell><cell>0.0067</cell><cell>0.0064</cell><cell>0.0054</cell><cell>0.0048</cell><cell>0.0134</cell><cell>0.0250</cell><cell>0.0199</cell><cell>0.0175</cell><cell>0.0174</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0026</cell><cell>0.0099</cell><cell>0.0145</cell><cell>0.0200</cell><cell>0.0292</cell><cell>0.0338</cell><cell>0.0791</cell><cell>0.1612</cell><cell>0.0969</cell><cell>0.0400</cell><cell>0.0543</cell></row><row><cell>March-May</cell><cell></cell><cell>0.5532</cell><cell>0.8481</cell><cell>0.9888</cell><cell>0.9874</cell><cell>0.8801</cell><cell>0.9556</cell><cell>0.8333</cell><cell>0.9016</cell><cell>0.8808</cell><cell>0.8962</cell><cell>0.7288</cell></row><row><cell>June-August</cell><cell></cell><cell>0.9717</cell><cell>0.8966</cell><cell>0.9062</cell><cell>0.9196</cell><cell>0.5645</cell><cell>0.6326</cell><cell>0.6748</cell><cell>0.6902</cell><cell>0.7521</cell><cell>0.5838</cell><cell>0.3437</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0007</cell><cell>0.0039</cell><cell>0.0080</cell><cell>0.0065</cell><cell>0.0042</cell><cell>0.0039</cell><cell>0.0155</cell><cell>0.0300</cell><cell>0.0270</cell><cell>0.0137</cell><cell>0.0168</cell></row><row><cell>Research in motion</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0467</cell><cell>0.1974</cell><cell>0.2492</cell><cell>0.4061</cell><cell>0.5319</cell><cell>0.4297</cell><cell>0.4333</cell><cell>0.3741</cell><cell>0.3235</cell><cell>0.0686</cell><cell>0.0222</cell></row><row><cell>March-May</cell><cell></cell><cell>0.1361</cell><cell>0.0965</cell><cell>0.0355</cell><cell>0.0386</cell><cell>0.0415</cell><cell>0.1453</cell><cell>0.1634</cell><cell>0.2533</cell><cell>0.3042</cell><cell>0.3317</cell><cell>0.3578</cell></row><row><cell>June-August</cell><cell></cell><cell>0.4033</cell><cell>0.3245</cell><cell>0.5356</cell><cell>0.9549</cell><cell>0.5168</cell><cell>0.8072</cell><cell>0.9564</cell><cell>0.7196</cell><cell>0.8101</cell><cell>0.2457</cell><cell>0.1698</cell></row><row><cell>September-November</cell><cell></cell><cell>0.2127</cell><cell>0.8165</cell><cell>0.8799</cell><cell>0.9744</cell><cell>0.5442</cell><cell>0.5476</cell><cell>0.9324</cell><cell>0.9327</cell><cell>0.7226</cell><cell>0.4989</cell><cell>0.1960</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.1076</cell><cell>0.2965</cell><cell>0.2422</cell><cell>0.4390</cell><cell>0.7683</cell><cell>0.5019</cell><cell>0.4867</cell><cell>0.3297</cell><cell>0.1858</cell><cell>0.1050</cell><cell>0.0257</cell></row><row><cell>March-May</cell><cell></cell><cell>0.3524</cell><cell>0.1979</cell><cell>0.1240</cell><cell>0.1237</cell><cell>0.1176</cell><cell>0.1639</cell><cell>0.2027</cell><cell>0.2781</cell><cell>0.3745</cell><cell>0.3021</cell><cell>0.2665</cell></row><row><cell>June-August</cell><cell></cell><cell>0.5624</cell><cell>0.4978</cell><cell>0.7891</cell><cell>0.9998</cell><cell>0.7448</cell><cell>0.7990</cell><cell>0.8972</cell><cell>0.9059</cell><cell>0.9779</cell><cell>0.2865</cell><cell>0.3614</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0859</cell><cell>0.1703</cell><cell>0.1436</cell><cell>0.3715</cell><cell>0.4917</cell><cell>0.1120</cell><cell>0.1502</cell><cell>0.0578</cell><cell>0.0368</cell><cell>0.0268</cell><cell>0.0221</cell></row><row><cell>9 Months</cell><cell></cell><cell>0.0609</cell><cell>0.1407</cell><cell>0.0512</cell><cell>0.2095</cell><cell>0.7124</cell><cell>0.4059</cell><cell>0.4169</cell><cell>0.3591</cell><cell>0.1648</cell><cell>0.0459</cell><cell>0.0138</cell></row><row><cell>March-May</cell><cell></cell><cell>0.5580</cell><cell>0.3390</cell><cell>0.1449</cell><cell>0.1117</cell><cell>0.0853</cell><cell>0.0572</cell><cell>0.0572</cell><cell>0.1329</cell><cell>0.4074</cell><cell>0.2432</cell><cell>0.4005</cell></row><row><cell>June-August</cell><cell></cell><cell>0.6641</cell><cell>0.6635</cell><cell>0.7495</cell><cell>0.9885</cell><cell>0.9445</cell><cell>0.9682</cell><cell>0.9852</cell><cell>0.9679</cell><cell>0.9522</cell><cell>0.3449</cell><cell>0.3866</cell></row><row><cell>September-November</cell><cell></cell><cell>0.0884</cell><cell>0.1365</cell><cell>0.0899</cell><cell>0.1989</cell><cell>0.4663</cell><cell>0.1926</cell><cell>0.2526</cell><cell>0.1356</cell><cell>0.0763</cell><cell>0.0419</cell><cell>0.0344</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Please cite this article in press as: J. Smailovic ´et al., Stream-based active learning for sentiment analysis in the financial domain, Inform. Sci. (2014), http://dx.doi.org/10.1016/j.ins.2014.04.034</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>www.twitter.com.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>Based on our previous experience in<ref type="bibr" target="#b70">[71]</ref>, the parameters for the SVM perf learner were set to ''-c 160000 -e 10''.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>The F-measure is a harmonic mean of precision and recall, and it reaches its best value at 1 and worst at 0. It is calculated as:F 1 ¼ 2 Â precision Â recall=ðprecision þrecallÞ. Precision is the fraction of all examples classified as positive which are correctly classified as positive, while recall is the fraction of all the positive examples that are correctly classified as positive.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Avg. F-measure ten-fold cross-val. ± std. dev. (TF-IDF) 1 X X 0.7937 ± 0.0059 0.7763 ± 0.0067 2 X X 0.7936 ± 0.0041 0.7779 ± 0.0061 3 X X X 0.7933 ± 0.0056 0.7756 ± 0.0051 4 X 0.7923 ± 0.0062 0.7801 ± 0.0055 5 X X X 0.7922 ± 0.0062 0.7786 ± 0.0053 6 X X X 0.7912 ± 0.0065 0.7774 ± 0.0033 7 X X X 0.7910 ± 0.0057 0.7755 ± 0.0047 8 X X X X 0.7907 ± 0.0064 0.7756 ± 0.0063 9 X X X X X 0.7906 ± 0.0055 0.7776 ± 0.0042 10 X X X 0.7904 ± 0.0052 0.7741 ± 0.0050 11 X X X 0.7903 ± 0.0073 0.7764 ± 0.0075 12 X X X X 0.7897 ± 0.0071 0.7759 ± 0.0069 13 X X 0.7897 ± 0.0042 0.7763 ± 0.0071 14 X X 0.7894 ± 0.0058 0.7716 ± 0.0055 15 X X 0.7894 ± 0.0050 0.7663 ± 0.0067 16 X X X X 0.7891 ± 0.0061 0.7752 ± 0.0051 17 X X 0.7885 ± 0.0064 0.7694 ± 0.0061 18 X X X 0.7882 ± 0.0063 0.7730 ± 0.0055 19 X X X X 0.7881 ± 0.0062 0.7740 ± 0.0059 20 X X 0.7878 ± 0.0055 0.7739 ± 0.0059 21 X X 0.7876 ± 0.0061 0.7697 ± 0.0072 22 X X X X 0.7874 ± 0.0046 0.7670 ± 0.0081 23 X X X 0.7862 ± 0.0062 0.7716 ± 0.0062 24 X</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_5"><p>https://www.google.com/finance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_6"><p>http://phx.corporate-ir.net/phoenix.zhtml?c=188488&amp;p=irol-news&amp;nyo=2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>J. Smailovic ´et al. / Information Sciences xxx (2014) xxx-xxx</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_8"><p>J. Smailovic ´et al. / Information Sciences xxx (2014) xxx-xxx INS 10845 No. of Pages 23, Model 3G</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p>J.Smailovic  ´et al. / Information Sciences xxx (2014) xxx-xxx</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_10"><p>134,856 'go' À74,192 '!' 77,611 'NEGATION' À69,678 'going' 55,777 'miss' À37,075 'thanks' 41,668 'work' À28,721 'love' 36,643 '.' À28,414 'good' 31,178 'sad' À28,144 'URL' 22,168 't' À27,682 'look' 21,239 't' À27,062 ',' 21,027 'want' À22,440 'great' 16,474 '. . .' À21,947 '-' 16,432 'feel' À21,684 '&amp;' 15,483 'wish' À18,981 'happy' 13,679 'looking' À17,395 ';' 13,040 'can' À17,048 'lol' 12,581 'bad' À16,580</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work presented in this paper was partially funded by the European Commission Q4 in the context of the FP7 projects FOC and FIRST (Grant Agreement Nos. 255987 and 257928, respectively), and the Ad Futura Programme of the Slovenian Human</p><p>Resources and Scholarship Fund. We are grateful to Ulli Spankowski and Sebastian Schroff for their kind cooperation as Q5 financial experts in the stock analytics application presented in this paper. We are also grateful to Dragi Kocev and Vladimir Kuzmanovski from Joz ˇef Stefan Institute, Ljubljana, Slovenia, for their help in the statistical evaluation of the results, and to Igor Mozetic ˇfor useful comments and suggestions. Finally, we are grateful to Martin Saveski for his help with the implementation of the active learning algorithms.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>In this appendix, we present some empirical support for considering smiley-labeled tweets as a reasonable approximation for manually-annotated positive/negative sentiments of tweets.</p><p>Table <ref type="table">7</ref> presents the most relatively positive and negative sentiment-bearing terms from the smiley-labeled Stanford dataset after replacing URLs and negation words with common tokens URL and NEGATION. Since some terms were presented in both positive and negative tweets, we took the 1000 terms with the highest document frequency in positive tweets, and the 1000 terms with the highest document frequency in negative tweets and calculated the difference between document frequencies of individual terms. From the table, it follows that positive/negative smiley-labeled tweets contain numerous common positive/negative sentiment-bearing words, such as ''thanks,'' ''love,'' ''good,'' and ''great'' for positive sentiments, and ''miss,'' ''sad,'' and ''bad'' for negative sentiments.</p><p>Interestingly, from the table it follows that mentioning other users (by writing the '@' sign and a username) and writing web URLs is associated with positive emoticons, and probably positive feelings. On the other hand, it seems that writing</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bonferroni and Šidák corrections for multiple comparisons</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Measurement and Statistics</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Salkind</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">752</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentiment analysis of twitter data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vovsha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Languages in Social 753 Media</title>
		<meeting>the Workshop on Languages in Social 753 Media</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Predicting the future with social media</title>
		<author>
			<persName><forename type="first">S</forename><surname>Asur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web 755 Intelligence and Intelligent Agent Technology</title>
		<meeting>the 2010 IEEE/WIC/ACM International Conference on Web 755 Intelligence and Intelligent Agent Technology</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="492" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Bachelier</surname></persName>
		</author>
		<title level="m">Théorie de la Spéculation</title>
		<imprint>
			<publisher>Gauthier-Villars</publisher>
			<date type="published" when="1900">1900</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Data Stream Mining: A Practical Approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kirkby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MOA: massive online analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kirkby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1601" to="1604" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sentiment Knowledge Discovery in Twitter Streaming Data</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">760</biblScope>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Twitter mood predicts the stock market</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Syntactic clustering of the web</title>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Glassman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International World Wide Web Conference</title>
		<meeting>the 6th International World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">762</biblScope>
			<biblScope unit="page" from="393" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficiency and inefficiency in thinly traded stock markets: Kuwait and Saudi Arabia</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Malaikah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bank. Finan</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="197" to="210" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol. (TIST)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sentiment analysis of twitter feeds for the prediction of stock market movement</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lazer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CS 229 Machine Learning: Final Project</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
		<title level="m">Descartes Error: Emotion, Reason, and the Human Brain</title>
		<meeting><address><addrLine>Harper Perennial</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Yahoo! for Amazon: extracting market sentiment from stock message boards</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th the Asia Pacific Finance Association Annual Conference (APFA)</title>
		<meeting>the 8th the Asia Pacific Finance Association Annual Conference (APFA)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Dugan</surname></persName>
		</author>
		<idno>01.02.13</idno>
		<ptr target="&lt;http://www.mediabistro.com/alltwitter/500-million-registered-users_b18842" />
		<title level="m">Twitter to surpass 500 million registered users on Wednesday</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Random walks in stock market prices</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Finan. Anal. J</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="55" to="59" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The Text Mining Handbook -Advanced Approaches in Analyzing Unstructured Data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sanger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Selective sampling using the query by committee algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="133" to="168" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A comparison of alternative tests of significance for the problem of m rankings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="1940">1940</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twitter Sentiment Classification Using Distant Supervision</title>
		<meeting><address><addrLine>Stanford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">224</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Project Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Investigating causal relations by econometric models and cross-spectral methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="424" to="438" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The predictive power of online chatter</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gruhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining</title>
		<meeting>the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using support vector machines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barnhill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="389" to="422" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The role of text pre-processing in sentiment analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Haddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Comp. Sci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="26" to="32" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning model trees from evolving data streams</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ikonomovska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>ˇeroski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Disc</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="168" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ikonomovska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Doctoral Dissertation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Approximations of the critical region of the Friedman statistic</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Iman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Davenport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Statist. -Theory Meth</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="571" to="595" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Target-dependent Twitter sentiment classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Text categorization with support vector machines: learning with many relevant features</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning</title>
		<meeting>the European Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 22nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>A support vector method for multivariate performance measures</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Training linear SVMs in linear time</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sparse kernel SVMs via cutting-plane training</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-N</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="179" to="193" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Kavussanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dockery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A multivariate test for stock market efficiency: the case of ASE</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="573" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Twitter sentiment analysis: the good the bad and the OMG!</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kouloumpis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>ICWSM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Sentiment Analysis and Opinion Mining</title>
		<imprint>
			<publisher>Morgan and Claypool Publishers</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">an improved feature space for sentiment analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tfidf</forename><surname>Delta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third AAAI International Conference on Weblogs and Social Media</title>
		<meeting>the Third AAAI International Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Stock Prediction Using Twitter Sentiment Analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goel</surname></persName>
		</author>
		<idno>12.08.13</idno>
		<ptr target="&lt;http://cs229.stanford.edu/proj2011/GoelMittal-StockMarketPredictionUsingTwitterSentimentAnalysis.pdf&gt;" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Predicting movie sales from blogger sentiment</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Symposium on Computational Approaches to Analysing Weblogs AAAI-CAAW</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="155" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Branding OHIO Through Social Media</title>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<idno>01.02.13</idno>
		<ptr target="&lt;http://www.ohio.edu/compass/stories/11-12/8/branding-ohio-social-media.cfm&gt;" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Predictive analytics on public data -the case of stock markets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krauss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schoder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of 21st European Conference on Information Systems</title>
		<meeting>eeding of 21st European Conference on Information Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Paper 116</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Distribution-Free Multiple Comparisons, Doctoral dissertation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Nemenyi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963">1963</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Social mood and financial economics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Nofsinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Behav. Finan</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="144" to="160" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">From tweets to polls: linking text sentiment to public opinion time series</title>
		<author>
			<persName><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM 2010)</title>
		<meeting>the International AAAI Conference on Weblogs and Social Media (ICWSM 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="122" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Investigating predictive power of stock micro blog sentiment in forecasting future stock price directional movement</title>
		<author>
			<persName><forename type="first">C</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R L</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Systems, ICIS</title>
		<meeting>the International Conference on Information Systems, ICIS</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Thumbs up? Sentiment classification using machine learning techniques</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the ACL-02 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Opinion mining and sentiment analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inform. Ret</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Diverse ensembles for active learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Prem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning-International Workshop then Conference</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">584</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sentiment topic models for social emotion mining</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wenyin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Sci</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Using emoticons to reduce dependency in machine learning techniques for sentiment classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Read</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Student Research Workshop</title>
		<meeting>the ACL Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Regnault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Calcul des Chances et philosophie de la Bourse</title>
		<meeting><address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page">1863</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rice</surname></persName>
		</author>
		<title level="m">Mathematical Statistics and Data Analysis</title>
		<meeting><address><addrLine>Duxbury Advanced</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Correlating financial time series with micro-blogging activity</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hristidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the fifth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="513" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Grc ˇar, Web services for stream mining: a stream-based active learning use case</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saveski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PlanSoKD Workshop at ECML PKDD</title>
		<meeting>the PlanSoKD Workshop at ECML PKDD</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">P values: what they are and what they are not</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Schervish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Statist</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="206" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Online active learning methods for fast label-efficient spam filtering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth Conference on Email and AntiSpam (CEAS)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Combined regression and ranking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual SIGKDD Conference on Knowledge Discover and Data Mining</title>
		<meeting>the 16th Annual SIGKDD Conference on Knowledge Discover and Data Mining</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Machine learning in automated text categorization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">SOPS: stock prediction using web sentiment</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sehgal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Charles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Data Mining Workshops</title>
		<meeting>the International Conference on Data Mining Workshops</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="21" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Granger</forename><surname>Causality</surname></persName>
		</author>
		<idno>27.08.13</idno>
		<ptr target="//www.scholarpedia.org/article/Granger_causality&gt;" />
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1667</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1070" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Active learning with real annotation costs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Friedland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS Workshop on Cost-Sensitive Learning</title>
		<meeting>the NIPS Workshop on Cost-Sensitive Learning</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Active Learning Literature Survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Madison</publisher>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Closing the loop: fast, interactive semi-supervised annotation with queries on features and instances</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1467" to="1478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">From theories to queries: active learning in practice</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Act. Learn. Experim. Des. W</title>
		<imprint>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Query by committee</title>
		<author>
			<persName><forename type="first">H</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Opper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual Workshop on Computational Learning Theory</title>
		<meeting>the Fifth Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="287" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Pegasos: primal estimated sub-gradient solver for SVM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning</title>
		<meeting>the 24th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Smailovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grc ˇar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Joz ˇef Stefan International Postgraduate School Students Conference</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="169" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Predictive sentiment analysis of tweets: a stock market application, in: Human-Computer Interaction and Knowledge Discovery in Complex, Unstructured, Big Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Smailovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grc ˇar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>ˇnidaršic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">ˇ</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lavraš</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">7947</biblScope>
			<biblScope unit="page" from="77" to="88" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Tweets and trades: the information content of stock microblogs</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Sprenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tumasjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sandner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Welpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Euro. Finan. Manage</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Sentiment in Twitter events</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thelwall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Paltoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Inform. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="406" to="418" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">An operational system for detecting and tracking opinions in on-line discussion</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of the ACM SIGIR 2001 Workshop on Operational Text Classification (OTC)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Support vector machine active learning for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Predicting elections with Twitter: What 140 characters reveal about political sentiment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tumasjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Sprenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sandner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Welpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Weblogs and Social Media (ICWSM-2010)</title>
		<meeting>the International Conference on Weblogs and Social Media (ICWSM-2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName><forename type="first">P</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Foundation of evaluation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Document</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="373" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">The Nature of Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley and Sons Inc</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Mining multi-label data streams using ensemble-based active learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SDM</title>
		<meeting>SDM</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1131" to="1140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Wessa</surname></persName>
		</author>
		<idno>01.02.13</idno>
		<ptr target="&lt;http://www.wessa.net/rwasp_grangercausality.wasp/&gt;" />
		<title level="m">Free Statistics Software</title>
		<imprint>
			<publisher>Bivariate Granger Causality</publisher>
			<date type="published" when="2008">v1.1.23-r7. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Individual comparisons by ranking methods</title>
		<imprint>
			<date type="published" when="1945">1945</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="80" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A re-examination of text categorization methods</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The impact of social and conventional media on firm equity value: a sentiment analysis approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dec. Supp. Syst</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="919" to="926" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Mining data streams with labeled and unlabeled training examples</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Data Mining ICDM&apos;09</title>
		<meeting>the International Conference on Data Mining ICDM&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="627" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Predicting stock market indicators through twitter I hope it is not as bad as I fear</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fuehres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Gloorm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc.-Soc. Behav. Sci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="55" to="62" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Active learning from data streams</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Data Mining ICDM&apos;07</title>
		<meeting>the International Conference on Data Mining ICDM&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Active learning from stream data using optimal weight classifier ensemble</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst, Man, Cybernet.: Part B</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1607" to="1621" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Active learning with evolving streaming data, Machine Learning and Knowledge Discovery in Databases</title>
		<author>
			<persName><forename type="first">I</forename><surname>Šliobaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">˙</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="597" to="612" />
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
