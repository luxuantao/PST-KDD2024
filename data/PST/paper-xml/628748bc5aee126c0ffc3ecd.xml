<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Unsupervised Multiple-Task and Multiple-Teacher Model for Cross-lingual Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhuoran</forename><surname>Li</surname></persName>
							<email>lizhuoranget@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SKLSDE</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chunming</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaohui</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SKLSDE</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Hangzhou Innovation Institute</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junfan</forename><surname>Chen</surname></persName>
							<email>chenjf@act.buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SKLSDE</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenyi</forename><surname>Qin</surname></persName>
							<email>wenyi.qin@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SKLSDE</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Richong</forename><surname>Zhang</surname></persName>
							<email>zhangrc@act.buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">SKLSDE</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Unsupervised Multiple-Task and Multiple-Teacher Model for Cross-lingual Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cross-lingual named entity recognition task is one of the critical problems for evaluating the potential transfer learning techniques on low resource languages. Knowledge distillation using pre-trained multilingual language models between source and target languages have shown their superiority in transfer. However, existing cross-lingual distillation models merely consider the potential transferability between two identical single tasks across both domains. Other possible auxiliary tasks to improve the learning performance have not been fully investigated. In this study, based on the knowledge distillation framework and multitask learning, we introduce the similarity metric model as an auxiliary task to improve the cross-lingual NER performance on the target domain. Specifically, an entity recognizer and a similarity evaluator are first trained in parallel as two teachers from the source domain. Then, two tasks in the student model are supervised by these teachers simultaneously. Empirical studies on the three datasets across 7 different languages confirm the effectiveness of the proposed model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition, NER in short, refers to identifying entity types, i.e. location, person, organization, etc., in a given sentence. The exploiting of deep neural networks, such as Bi-LSTM-CRF <ref type="bibr" target="#b7">(Lample et al., 2016)</ref>, Bi-LSTM-CNN <ref type="bibr" target="#b2">(Chiu and Nichols, 2016)</ref> makes this task achieve significant performances. However, since deep neural networks highly rely on a large amount of labelled training data, the annotation acquiring process is expensive and time consuming. This situation is more severe for zero-resource languages. With the help of transfer learning <ref type="bibr" target="#b13">(Ruder et al., 2019)</ref> and multilingual BERT (short as mBERT) <ref type="bibr">(Devlin et al</ref> 2019), it is possible to transfer the annotated training samples or trained models from a rich-resource domain to a zero-resource domain.</p><p>Many studies have been done to solve this crosslingual NER problem. Existing models can be separated into three categories, shared feature space based, translation based and knowledge distillation based. Shared feature space based models exploit language-independent features, which lacks the domain-specific features for the target language <ref type="bibr" target="#b16">(Tsai et al., 2016;</ref><ref type="bibr" target="#b20">Wu and Dredze, 2019;</ref><ref type="bibr" target="#b5">Keung et al., 2019)</ref>. Translation based models generate pseudo labeled target language data to train the cross-lingual NER model, but the noise from translation process restrains its performance. <ref type="bibr" target="#b9">(Mayhew et al., 2017;</ref><ref type="bibr" target="#b21">Xie et al., 2018;</ref><ref type="bibr" target="#b18">Wu et al., 2020b)</ref>. Knowledge distillation based models train a student model using soft labels of the target language <ref type="bibr">(Wu et al., 2020a,b;</ref><ref type="bibr" target="#b1">Chen et al., 2021;</ref><ref type="bibr" target="#b8">Liang et al., 2021)</ref>.</p><p>Although the above-mentioned models solve the cross-lingual NER problem to some extent, the auxiliary tasks, as in multi-task learning, have not been studied in this problem. Due to the distributed representation of natural languages, the relatedness among the embedding of target languages, which is measured by the similarity, can be utilized to further boost the learned encoder and improve the final NER performance on target languages.</p><p>Here we give a concrete example to illustrate the importance of similarity between every two tokens under the situation when only the English data is labeled. Given a Spanish sentence "Arévalo (Avila), 23 may (EFE).", the token "Arévalo" is recognized as ORG type using the learned model from the English domain. In the meantime, the token "Arévalo" has high similarity scores with the Spanish tokens "Viena" from sentence "Viena, 23 may (EFE).", and "Madrid" from sentence "Madrid, 23 may (EFE).". Also, the tokens "Viena" and "Madrid" are recognized correctly as LOC type using the same English model mentioned above. Then "Arévalo" can be recognized correctly as LOC type under the supervisory signal using the similarity between "Viena" and "Madrid".</p><p>To leverage the similarity between the tokens of the source languages, we design an multiple-task and multiple-teacher model (short as MTMT, as shown in Figure <ref type="figure">1</ref>), which helps the NER learning process on the target languages. Specifically, we first introduce the knowledge distillation to build entity recognizer and similarity evaluator teachers in the source language and transfer the learned patterns to the student in the target language. In the student model, we then borrow the idea of multitask learning to incorporate a similarity evaluation task as an auxiliary task into the entity recognition classifier. During the student learning process, we input unlabelled samples from the target languages into the entity recognizer and evaluator, and take output pesudo labels as supervisory signals for these two tasks in the student model. Note that a weighting strategy is also provide therein to take into consideration of the reliability of the teachers.</p><p>We validate the model performance on the three commonly-used datasets across 7 languages and the experimental results show the superiority of our presented MTMT model.</p><p>Our main contributions are as follows:</p><p>• We propose an unsupervised knowledge dis-tillation framework for cross-lingual named entity recognition and develop a teaching and learning procedure under this framework.</p><p>• We present a novel multiple-task and multipleteacher model that introduces an entity similarity evaluator to boost the performance of student recognizer on target languages.</p><p>• We conduct extensive experiments on 7 languages compared with state-of-the-art baselines and the results confirm the effectiveness of the presented model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our approach is closely related to the existing works on cross-lingual NER, knowledge distillation, and siamese network.</p><p>Cross-Lingual NER aims to extract entities from a target language but assumes only source language is annotated. The existing models can be categorized to a) Shared feature space based models, b) Translation based models, c) Knowledge distillation based models.</p><p>Shared feature space based models generally train a language-independent encoder using source and target language data <ref type="bibr" target="#b16">(Tsai et al., 2016)</ref>. Recently, the pre-trained multilingual language model is effective to address the challenge <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref>. Moreover, some research introduces new components on top of the mBERT by directly transferring the model learned from the labeled source language to that of target languages <ref type="bibr" target="#b5">(Keung et al., 2019)</ref>. The performance is still weak due to the lack of annotations of target languages.</p><p>Translation based models generally generate pseudo-labeled target data to alleviate target data scarcity. For example, <ref type="bibr" target="#b18">(Wu et al., 2020b;</ref><ref type="bibr" target="#b22">Zhang et al., 2021)</ref> gain an improvement by translating the labeled source language to the target language word-by-word. Our model achieves considerable improvement by learning entity similarity in target language data without translation.</p><p>Knowledge distillation based models include a teacher model and a student model <ref type="bibr" target="#b19">(Wu et al., 2020c)</ref>. The teacher model is trained on the labeled source language. The student model learns from the soft label predicted by the teacher model on unlabeled target language data. Therefore, the student model can capture the extra knowledge about target languages. In our work, the student model not only learns the recognizer teacher knowledge, but also learns the entity similarity knowledge inspired by multi-task learning.</p><p>Siamese Network is originally introduced by <ref type="bibr" target="#b0">(Bromley et al., 1994)</ref> to treat signature verification as a matching problem. It has been successfully applied to transfer learning such as one-shot image recognition <ref type="bibr" target="#b6">(Koch et al., 2015)</ref>, text similarity <ref type="bibr" target="#b10">(Neculoiu et al., 2016)</ref>. However, there is a dilemma to adapt the siamese network to tokenlevel recognition tasks such as NER. Siamese network assumes the input is a pair, and the output is a similarity score. To handle this issue, we reconstruct the data to pair format. To the best of our knowledge, we are the first to learn the entity similarity by siamese network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Framework</head><p>In this section, we introduce our framework and its detailed implementation. Our framework is consist of two models: teacher training model learned from the source language and teacher-student distillation learning model learned from the target language. In the teacher training model, there are two sub-models, i.e. an entity recognizer teacher and a similarity evaluator teacher. These two models are two parallel tasks, wherein the entity recognition teacher focuses on identifying the named entities and the similarity evaluator teacher is to decide if two tokens are in the same type.</p><p>We then present a teacher-student distillation learning model to learn from the two learned teacher models simultaneously. We note that, in this learning process, such a knowledge distillation makes the student model combine the advantages of both source language patterns of entity recognition and entity similarity evaluation. During the learning process, the samples from the target language are fed into the teacher model and the outputs are taken as the supervisory signal for two tasks in the student model. To guarantee the student learning performance, we assign weights for each supervisory signal correspond to the output confidence of teacher sub-models. We argue that the student entity recognition task and the student entity similarity evaluation task improve the representation learning of the student encoder in the siamese structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>Following standard practice, we formulate crosslingual NER as a sequence labeling task. Given a , where x i is the i-th token and y i is the corresponding label of x i . In the source language, we denote the labeled training data as D S train = {(x, y)} and test data as D S test . In the target language, we denote the unlabeled train data as D T train = {x} and the test data as D T test . Formally, our goal is to train a model with D S train and D T train to perform well on D T test .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Teacher Models</head><p>Here we first consider the training of two teacher models. For every two tokens, we define Entity Similarity Metric as a score which is the probability that two tokens belong to the same entity type. We aim to find entity similarity to help the crosslingual NER model in the target language. It is a non-trivial task since we lack golden labels to help us distinguish target named entities. To address this challenge, we propose a binary classifier called similarity evaluator to leverage the labeled source language data for similarity prediction. Our similarity evaluator model, inspired by siamese network <ref type="bibr" target="#b6">(Koch et al., 2015)</ref>, are able to acquires more powerful features via capturing the invariances to transformation in the input space. Figure <ref type="figure" target="#fig_0">2</ref> illustrated the two teacher models training. The following subsections will illustrate the two teacher models sequentially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Entity Recognizer</head><p>Since the cross-lingual NER task, we unitize multilingual mBERT <ref type="bibr" target="#b20">(Wu and Dredze, 2019)</ref> as basic sequence feature extractor backbone to derive the sequence embedding representation throughout this paper. And a linear classifier with softmax upon the pre-trained mBERT output. The model network structure could be formulated as,</p><formula xml:id="formula_0">h = mBERT(x) ŷi = softmax(W h i + b)</formula><p>where h = {h i } L i=1 and h i denotes the output of the pre-trained mBERT that corresponds to the input token x i . ŷi denotes the predicted probability distribution for x i . W and b are trainable parameters. For some sentence sample (x, y) ∈ D S train and an entity token query index i, the loss function is,</p><formula xml:id="formula_1">L ER (x, y, i) = L CE (y i , ŷi )</formula><p>We train this entity recognition teacher model on the source lingual training corpus D S train = {(x, y)} directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Siamese Entity Similarity Evaluator</head><p>To leverage the entity similarity to boost the unsupervised cross-lingual NER performance, we will present our entity pairs construction method and the siamese network model in the following.</p><p>Entity Similarity Pairs Construction According to entity labels, we randomly select sentences pair &lt; x, x &gt; with their some token pair &lt; x i , x j &gt; and associated labels &lt; y i , y j &gt; in D S train , to form the siamese supervision training dataset, D S−siam train = {(x, x , i, j, t)} where the target t = 1 indicates y i = y j , and 0 otherwise. And the testing entity pairs D S−siam test is constructed likewisely.</p><p>Siamese Entity Similarity Network Our similarity backbone model is a siamese neural network with mBERT as feature extraction layer. Wherein h and h represent latent sequences encoding features derived by the two symmetric twins with respect to input sentence x and x respectively.</p><p>The inter-entities similarity is measured on the hidden representations h i and h j of the tokens queried by the entity indices &lt; i, j &gt; on the sequences representations. The cosine function operator is added to compute on the entity token latent vectors' distance, s to measure the similarity between each siamese twin, which is fed into a single sigmoid output unit for target t estimation.</p><p>More precisely, for a specific entity pair (x, x , i, j, t) ∈ D S−siam train , the siamese network could be formulated as,  where cos is the cosine similarity metric function, σ is the sigmoid activation function, t ∈ [σ(−1), σ(1)] denotes the predicted similarity of two queried tokens pair &lt; x i , x j &gt;. Larger t value indicates higher similarity between the two queried entities tokens.</p><formula xml:id="formula_2">h =mBERT(x), h = mBERT(x ) t(x, x , i, j) = σ(cos(h i , h j ))</formula><p>The loss function of the similarity prediction can be formulate as,</p><formula xml:id="formula_3">L SIM (x, x , i, j, t) = L BCE (t, t).</formula><p>Finally, we can train the siamese entity similarity evaluator on D S−siam train , and evaluate the performance on test dataset D S−siam test . Together with entity recognizer model, this entity similarity evaluator are used as teachers in following knowledge distillation learning process, and transfer knowledge from source to target lingual corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Teacher-student Distillation Learning</head><p>In this section, we consider transferring the named entity type and similarity knowledge learned on labeled source language corpus to unlabeled target language NER task. To this end, we propose a knowledge distillation learning process to train a target language student NER model with its supervisory signals mimicked by the entity type prediction probability by the entity recognizer teacher model and entity representation similarity target by the entity siamese similarity evaluator teacher model. Based on the original unlabeled target sentence training data D T train , we again construct unlabeled target-language siamese pairwise entity data D T −sim train = {(x T , x T , i, j)}, with the sentence pair &lt; x T , x T &gt; randomly sample from D T train and the entity token indices pair &lt; i, j &gt; uniformly sampled from the sentences therein.</p><p>The mBERT is also used as an encoder for the sentence siamese pair, and the entity token feature is queried from the latent sequence encoding representation. Specifically, for a sentence pair (x T , x T , i, j) ∈ D T −sim train , the student model transform them as follows,</p><formula xml:id="formula_4">h T = mBERT(x T ) ŷT i = softmax(W h T i + b) h T = mBERT(x T ) ŷ T j = softmax(W h T j + b) tT (x T ,x T , i, j) = σ(cos(h T i , h T j ))</formula><p>Then for a specific sentence pair sample in the target siamese dataset, the student loss function has three breaches, L ER (x T , y S , i), L ER (x T , y S , j), and L SIM (x T , x T , i, j, tS ). Note that supervision information y S , y S , and tS are taught by the three teacher models. Summering over all the samples in D T −sim train = {(x T , x T , i, j)}, the total student model training loss takes form,</p><formula xml:id="formula_5">L = γ (x T ,x T ,i,j)∈D T −sim train (α 1 L ER (x T , y S , i) +α 2 L ER (x T , y S , j) +βL BCE ( tT (x T , x T , i, j), tS ))</formula><p>where α 1 , α 2 , β, and γ are weights in loss function which are set to make the student model learns less noisy knowledge from teachers. The weights are set as follows: α 1 (α 2 ) is an increasing function concerning the output of the entity recognizer teacher as shown in Figure <ref type="figure" target="#fig_2">4</ref>. And β is set such that it is high when the output of the entity similarity teacher is close to 0 or 1, and it is low when the output is close to 0.5. γ indicates consistency level between the outputs from two teacher models, e.g. for two input tokens, if the output from entity similarity teacher is high, and the similarity level computed from the outputs of the entity recognizer teacher is low, then their consistency level is low. We want the student model to learn from the two teachers as follows: the higher the prediction of the entity recognizer teacher is (the further away from 0.5 the prediction of the entity similarity teacher is, the higher the consistency level is), the more accurate the prediction is, thus the more attention the student model pays attention to the input tokens, and vice versa. Therefore, we heuristically devises the three weights scheduling as functions of the inputs, </p><formula xml:id="formula_6">α (•) = (max(ŷ T i )) 2 β = (2 tT (x T , x T , i, j) − 1) 2 γ = 1 − |σ(cos(ŷ T i , ŷ T j )) − tT (x T , x T , i, j)|</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In this section, we evaluate our multiple-task and multiple-teacher model for cross-lingual NER and compare our model with a series of state-of-the-art models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We conducted experiments on three benchmark datasets: CoNLL2002 <ref type="bibr" target="#b14">(Tjong Kim Sang, 2002)</ref>, CoNLL2003 <ref type="bibr" target="#b15">(Tjong Kim Sang and De Meulder, 2003)</ref> and WikiAnn <ref type="bibr" target="#b12">(Pan et al., 2017)</ref>. CoNLL2002 includes Spanish and Dutch, CoNLL2003 includes English and German, and WikiAnn includes English and three non-western languages: Arabic, Hindi, and Chinese. Each language is divided into a training set, a development set and a test set. All datasets were annotated with four entity types: LOC, MISC, ORG, and PER. Following <ref type="bibr" target="#b20">(Wu and Dredze, 2019)</ref>, all datasets are annotated using the BIO entity labelling scheme. To imitate the zero-resource cross lingual NER case, following <ref type="bibr" target="#b20">(Wu and Dredze, 2019)</ref>, we used English as the source language and other languages as the target language. In cross-lingual NER, the training set without entity label of the target language is also available when training the model. We trained the model with the labeled training set of the source language and evaluated the model on the test set of each target language. Table <ref type="table" target="#tab_2">1</ref> and 2 shows the statistics of all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We use PyTorch 1. pre-trained mBERT model <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> in HuggingFace Transformer<ref type="foot" target="#foot_0">1</ref> , which has 12 Transformer blocks, 12 attention heads, and 768 hidden units.</p><p>We set our hyperparameters empirically following <ref type="bibr" target="#b19">(Wu et al., 2020c)</ref> with some modifications. We do not freeze any layers and we use the output of the last layer as our hidden feature vector. We set the batch size to be 32, maximum sequence length to be 128, dropout rate to be 0.2, and we use Adam as optimizer <ref type="bibr" target="#b6">(Kingma and Ba, 2014)</ref>. For the training of recognition teacher model and similarity teacher model, we set the learning rate to be 1e-5 and 5e-6 separately. For knowledge distillation, we use a learning rate of 1e-6 for the student models training. Note that if a word is divided into several subwords after tokenization, then only the first subword is considered in the loss function. Following <ref type="bibr" target="#b14">(Tjong Kim Sang, 2002)</ref>, we use the entity level F1-score as the evaluation metric. Moreover, we conduct each experiment 5 times and report the mean F1-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison</head><p>Table <ref type="table" target="#tab_4">3</ref> and 4 report the zero-resource cross-lingual NER results of different models on 6 target languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>de es nl Wiki <ref type="bibr" target="#b16">(Tsai et al., 2016)</ref> 48.12 60.55 61.56 WS <ref type="bibr" target="#b11">(Ni et al., 2017)</ref> 58.50 65.10 65.40 TMP <ref type="bibr" target="#b4">(Jain et al., 2019)</ref> 61.50 73.50 69.9 BERT-f <ref type="bibr" target="#b20">(Wu and Dredze, 2019)</ref> 69.56 74.96 77.57 AdvCE <ref type="bibr" target="#b5">(Keung et al., 2019)</ref> 71.90 74.3 77.6 TSL <ref type="bibr" target="#b17">(Wu et al., 2020a)</ref> 73.16 76.75 80.44 Unitrans <ref type="bibr" target="#b18">(Wu et al., 2020b)</ref> 74   TSL <ref type="bibr" target="#b19">(Wu et al., 2020c)</ref> proposes a teacher-student learning model for cross-lingual NER.</p><p>Unitrans <ref type="bibr" target="#b18">(Wu et al., 2020b)</ref> unifies a data transfer and model transfer for cross-lingual NER.</p><p>AdvPicker <ref type="bibr" target="#b1">(Chen et al., 2021)</ref> proposes a adversarial discriminator for cross-lingual NER. RIKD <ref type="bibr" target="#b8">(Liang et al., 2021)</ref> develops a reinforced iterative knowledge distillation for cross-lingual NER.</p><p>TOF <ref type="bibr" target="#b22">(Zhang et al., 2021)</ref> transfers knowledge from three aspects for cross-lingual NER.</p><p>It can be seen that our model outperforms the state-of-the-arts. Specifically, compared with the remarkable RIKD, AdvPicker, and Unitrans, which also use knowledge distillation but ignore the entity similarity knowledge, our model obtains significant and consistent improvements in F1-score ranging from 0.23 for German[de] to 6.81 for Arabic <ref type="bibr">[ar]</ref>. That demonstrates the benefits of our proposed MTMT model, compared to direct model transfer <ref type="bibr" target="#b20">(Wu and Dredze, 2019)</ref>.</p><p>Note that BERT-f performs better than our model on the Chinese dataset due to their re-tokenization of the dataset. Moreover, compared with the latest model TOF, RIKD, Unitrans, our model requires much lower computational costs for both translation and iterative knowledge distillation, meanwhile reaching superior performance. For a fair comparison, we compare our model against the version of TOF w/o continual learning <ref type="bibr">(Zhang et</ref>  2021), RIKD w/o IKD <ref type="bibr" target="#b8">(Liang et al., 2021)</ref> and Unitrans w/o translation <ref type="bibr" target="#b18">(Wu et al., 2020b)</ref> as reported in their paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>To demonstrate the effectiveness of our approach, we designed the following ablation studies. Table <ref type="table" target="#tab_6">5</ref> presents the results.</p><p>(1) MTST, which combines the multiple-teacher to single-teacher. That is, the teacher model has the same as the neural network structure of the student model. This causes a performance drop across all languages due to two single teachers cannot make a difference with the combination.</p><p>(2) MTMT w/o weighting, which set the α (•) , β and γ all to be 1 in the loss of student learning. It can be seen that the performance decrease in terms of F1-score ranges from 0.45 for Dutch(nl) to 0.98 for Spanish(es), which validates that weighting loss can bring more confident knowledge to the student model.</p><p>(3) MTMT w/o similarity, which removes the similarity teacher model. In this case, our approach degrades into the single teacherstudent learning model as in TSL <ref type="bibr" target="#b17">(Wu et al., 2020a)</ref>. Without the similarity knowledge fed into the student model, the performance drops significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Case Study</head><p>We give a case study to show that the failed cases of baseline models can be corrected by our model. We try to bring up insights on why the proposed multiple-task and multiple-teacher model works.</p><p>The proposed MTMT model can help to correct labels using the Entity Similarity defined in section 3.2. Specifically, if there is a set of tokens in which every two of them have a high Entity Similarity score, and one of the tokens is predicted to have a distinct label while other tokens have identical labels, then the one with the distinct label is predicted wrongly and is corrected by the student model to have the label of all other tokens. As shown in Table <ref type="table" target="#tab_7">6</ref>, in example #1, the entity recognizer teacher fails to identify "Arévalo" as B-ORG type, while the student model can correctly predict it. The reason lies in that the entity recognizer teacher predicts "Viena"('Madrid") as B-LOC type correctly, and the similarity evaluator teacher predicts "Viena"("Madrid") to have a high similarity score(0.7157, 0.7156) with "Arévalo". The student learns from both teachers and predict the correct label for "Arévalo". Examples #2 and #3 present the same results with different sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Embedding Distribution</head><p>This section investigates the effect of embeddings of the two different teacher models. It can be seen that the embedding distribution of the student model is close to similarity evaluator teacher, as illustrated in Figure <ref type="figure">5</ref>. We conjecture that the student model captures similarity knowledge from the similarity evaluator teacher, i.e. the same class of examples tend to cluster and the different class of examples tend to segregate in the embedding distribution. This validates the proposed MTMT model not only transfers cross-lingual NER knowledge from source language, but also learns the similarity knowledge of target language data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Effect of Weights</head><p>In this section, we evaluate the effectiveness of weight loss in student learning from a quantitative perspective. All of the following experiments are conducted on Spanish(es) data.</p><p>For α analysis, we calculate the F1-score in different probability intervals of entity recognizer teacher, we find that the recognizer teacher tends to predict more correct in higher probability interval, as illustrated in Figure <ref type="figure" target="#fig_5">6a</ref>. Therefore, the student model is better suited to the target language with learning fewer low-confidence misrecognitions for the target language.</p><p>For β analysis, we observe that F1-score are increasing with the entity similarity score from 0.5 to both sides 0 and 1 in Figure <ref type="figure" target="#fig_5">6b</ref>. The encoder of the student model obtains the clustering information of the target language with the help of β.</p><p>For γ analysis, we consider the consistency of recognition results and similarity score by teachers. The F1-score and similarity score of teachers are all higher in the higher γ intervals, as shown in Figure <ref type="figure" target="#fig_5">6c</ref>. The student model learns less from unreasonable results, and it can make more accurate entity recognition for the target language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose an unsupervised multipletask and multiple-teacher model for cross-lingual NER. The student model learns two source language patterns of entity recognition and entity similarity evaluation. Moreover, to guarantee the student learning performance, we also propose a weighting strategy to take into consideration the reliability of the teachers. Our experimental results show that the proposed model yields significant improvements on six target language datasets and outperforms the existing state-of-the-art approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The training process of teacher models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Teacher-student distillation learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Weights of loss. (a) indicates the weight α (•) of L ER . (b) indicates the weight β of L BCE .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>: Arévalo[B-ORG] (Avila[B-LOC]), 23 may (EFE[B-ORG]). Student: Arévalo[B-LOC] (Avila[B-LOC]), 23 may (EFE[B-ORG]). Entity Recognizer and Entity Similarity Evaluator Teachers: a. Viena[B-LOC, 0.7157] , 23 may (EFE[B-ORG]). b. Madrid[B-LOC, 0.7156] , 23 may (EFE[B-ORG]). #2 Dutch Entity Recognizer Teacher: Universiteit[B-ORG] Antwerpen[I-ORG] ( Ruca[B-LOC] )... Student: Universiteit[B-ORG] Antwerpen[I-ORG] ( Ruca[B-ORG] ) en De... Entity Recognizer and Entity Similarity Evaluator Teachers: a. ...voor[I-ORG] het[I-ORG] Preventiebeleid[I-ORG] ( VSPP[B-ORG,0.7134] ) is... b. Transparency[B-ORG] International[I-ORG] ( TI[B-ORG,0.7130] ), de onderhand... #3 German Entity Recognizer Teacher: Hessischen[B-ORG] Staatskanzlei[O] auf das Thema... Student: Hessischen[B-ORG] Staatskanzlei[I-ORG] auf das Thema... Entity Recognizer and Entity Similarity Evaluator Teachers: a. Internationalen[B-ORG] Bund[I-ORG] für[I-ORG] Sozialarbeit[I-ORG,0.7162] ... b. Kickers[B-ORG] Offenbach[I-ORG] II[I-ORG,0.7157] -Rotweiß[B-ORG] ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 5: t-SNE plot of embeddings of teacher and student models. (a) Entity recognizer teacher. (b) Entity similarity evaluator teacher. (c) Student.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Weights analysis of student learning. (a) α, F1-score in different probability interval. (b) β, F1-score in different similarity score interval. (c) F1-score of y S , y S , and tS in different γ interval.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of CoNLL.    </figDesc><table><row><cell>Language</cell><cell>Type Train Dev Test</cell></row><row><cell cols="2">English-en Sentence 14,987 3,466 3,684</cell></row><row><cell cols="2">(CoNLL-2003) Entity 23,499 5,942 5,648</cell></row><row><cell cols="2">German-de Sentence 12,705 3,068 3,160</cell></row><row><cell cols="2">(CoNLL-2003) Entity 11,851 4,833 3,673</cell></row><row><cell cols="2">Spanish-es Sentence 8,323 1,915 1,517</cell></row><row><cell cols="2">(CoNLL-2002) Entity 18,798 4,351 3,558</cell></row><row><cell>Dutch-nl</cell><cell>Sentence 15,806 2,895 5,195</cell></row><row><cell cols="2">(CoNLL-2002) Entity 13,344 2,616 3,941</cell></row><row><cell cols="2">Language Type Train Dev Test</cell></row><row><cell cols="2">English-en Sentence 20,000 10,000 10,000</cell></row><row><cell></cell><cell>Entity 27,931 14,146 13,958</cell></row><row><cell cols="2">Arabic-ar Sentence 20,000 10,000 10,000</cell></row><row><cell></cell><cell>Entity 22,500 11,266 11,259</cell></row><row><cell cols="2">Hindi-hi Sentence 5,000 1,000 1,000</cell></row><row><cell></cell><cell>Entity 6,124 1,226 1,228</cell></row><row><cell cols="2">Chinese-zh Sentence 20,000 10,000 10,000</cell></row><row><cell></cell><cell>Entity 25,031 12,493 12,532</cell></row></table><note>7.1 to implement our model. All of the feature encoders mentioned in this paper use</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Statistics of WikiAnn.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance comparisons on CoNLL.</figDesc><table><row><cell>.82 79.31 82.90</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance comparisons on WikiAnn.</figDesc><table><row><cell cols="4">Wiki (Tsai et al., 2016) introduces a language in-</cell></row><row><cell cols="4">dependent model building on cross-lingual wikifi-</cell></row><row><cell cols="2">cation for cross-lingual NER.</cell><cell></cell><cell></cell></row><row><cell cols="4">WS (Ni et al., 2017) presents two weakly super-</cell></row><row><cell cols="3">vised approaches for cross-lingual NER.</cell><cell></cell></row><row><cell cols="4">TMP (Jain et al., 2019) leverages machine transla-</cell></row><row><cell cols="4">tion to improve annotation projection approaches</cell></row><row><cell>to cross-lingual NER.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">BERT-f (Wu and Dredze, 2019) applys the mBERT</cell></row><row><cell>to cross-lingual NER.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">AdvCE (Keung et al., 2019) improves upon</cell></row><row><cell cols="4">mBERT via adversarial learning for cross-lingual</cell></row><row><cell>NER.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>de</cell><cell>es</cell><cell>nl</cell></row><row><cell>MTMT</cell><cell cols="3">76.80 81.82 83.41</cell></row><row><cell>MTST</cell><cell>74.11 (-2.69)</cell><cell>78.61 (-3.21)</cell><cell>81.97 (-1.44)</cell></row><row><cell>MTMT w/o weighting</cell><cell>76.08 (-0.72)</cell><cell>80.84 (-0.98)</cell><cell>82.96 (-0.45)</cell></row><row><cell>MTMT w/o similarity</cell><cell>73.82 (-2.98)</cell><cell>77.53 (-4.29)</cell><cell>80.82 (-2.59)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on cross-lingual NER.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Case study on cross-lingual NER. The GREEN (RED) highlight indicates a correct (incorrect) label. The real-valued numbers indicate the entity similarity score.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/huggingface/transformers</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>This work is supported partly by the Fundamental Research Funds for the Central Universities and by the State Key Laboratory of Software Development Environment.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Säckinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<publisher>Morgan-Kaufmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER</title>
		<author>
			<persName><forename type="first">Weile</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiqiang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianhui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Börje</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Guan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.61</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<title level="s">Long Papers</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="743" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional LSTM-CNNs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><surname>Nichols</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00104</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Entity projection via machine translation for cross-lingual NER</title>
		<author>
			<persName><forename type="first">Alankar</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhargavi</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1100</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1083" to="1092" />
		</imprint>
	</monogr>
	<note>Lipton</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adversarial learning with contextual embeddings for zero-resource cross-lingual classification and NER</title>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Keung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Bhardwaj</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1138</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1355" to="1360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>arxiv:1412.6980Comment</idno>
	</analytic>
	<monogr>
		<title level="m">the 3rd International Conference for Learning Representations</title>
				<meeting><address><addrLine>San Diego; Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014. 2015. 2015</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>ICML deep learning workshop</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1030</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reinforced iterative knowledge distillation for crosslingual named entity recognition</title>
		<author>
			<persName><forename type="first">Shining</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanli</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianglin</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3447548.3467196</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery amp; Data Mining, KDD &apos;21</title>
				<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery amp; Data Mining, KDD &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3231" to="3239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cheap translation for cross-lingual named entity recognition</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1269</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2536" to="2545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning text similarity with Siamese recurrent networks</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Neculoiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Versteegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Rotaru</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-1617</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Representation Learning for NLP</title>
				<meeting>the 1st Workshop on Representation Learning for NLP<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="148" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Crosslingual name tagging and linking for 282 languages</title>
		<author>
			<persName><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1178</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1946" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transfer learning in natural language processing</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-5004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials</title>
				<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING-02: The 6th Conference on Natural Language Learning</title>
				<imprint>
			<date type="published" when="2002">2002. 2002. CoNLL-2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
				<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cross-lingual named entity recognition via wikification</title>
		<author>
			<persName><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K16-1022</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</title>
				<meeting>The 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Single-/multisource cross-lingual NER via teacher-student learning on unlabeled data in target language</title>
		<author>
			<persName><forename type="first">Qianhui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijia</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Börje</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biqing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.581</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020a</date>
			<biblScope unit="page" from="6505" to="6514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unitrans : Unifying model transfer and data transfer for cross-lingual named entity recognition with unlabeled data</title>
		<author>
			<persName><forename type="first">Qianhui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijia</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Börje</forename><forename type="middle">F</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biqing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2020/543</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</title>
				<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</meeting>
		<imprint>
			<date type="published" when="2020">2020b</date>
			<biblScope unit="page" from="3926" to="3932" />
		</imprint>
	</monogr>
	<note>Main track</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Enhanced meta-learning for cross-lingual named entity recognition with minimal resources</title>
		<author>
			<persName><forename type="first">Qianhui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijia</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Börje</forename><forename type="middle">F</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biqing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020c</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9274" to="9281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT</title>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1077</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="833" to="844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural crosslingual named entity recognition with minimal resources</title>
		<author>
			<persName><forename type="first">Jiateng</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1034</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="369" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Target-oriented fine-tuning for zero-resource named entity recognition</title>
		<author>
			<persName><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.140</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
				<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1603" to="1615" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
