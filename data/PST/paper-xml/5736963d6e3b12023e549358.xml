<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Special Section on Processing Large Geospatial Data Distinctive 2D and 3D features for automated large-scale scene analysis in urban areas</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">M</forename><surname>Weinmann</surname></persName>
							<email>martin.weinmann@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Photogrammetry and Remote Sensing</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<addrLine>Englerstr. 7</addrLine>
									<postCode>76131</postCode>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Urban</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Photogrammetry and Remote Sensing</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<addrLine>Englerstr. 7</addrLine>
									<postCode>76131</postCode>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Hinz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Photogrammetry and Remote Sensing</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<addrLine>Englerstr. 7</addrLine>
									<postCode>76131</postCode>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">B</forename><surname>Jutzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Photogrammetry and Remote Sensing</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology (KIT)</orgName>
								<address>
									<addrLine>Englerstr. 7</addrLine>
									<postCode>76131</postCode>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Université Paris-Est</orgName>
								<orgName type="institution" key="instit2">IGN, SRIG</orgName>
								<orgName type="institution" key="instit3">MATIS</orgName>
								<address>
									<addrLine>73 Avenue de Paris</addrLine>
									<postCode>94160</postCode>
									<settlement>Saint-Mandé</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Special Section on Processing Large Geospatial Data Distinctive 2D and 3D features for automated large-scale scene analysis in urban areas</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5138550F0CF5B9EDF916C0320502A876</idno>
					<idno type="DOI">10.1016/j.cag.2015.01.006</idno>
					<note type="submission">Received 1 September 2014 Received in revised form 23 December 2014 Accepted 29 January 2015</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>3D scene analysis Point cloud Feature Classification Large-scale Urban</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new methodology for large-scale urban 3D scene analysis in terms of automatically assigning 3D points the respective semantic labels. The methodology focuses on simplicity and reproducibility of the involved components as well as performance in terms of accuracy and computational efficiency. Exploiting a variety of low-level 2D and 3D geometric features, we further improve their distinctiveness by involving individual neighborhoods of optimal size. Due to the use of individual neighborhoods, the methodology is not tailored to a specific dataset, but in principle designed to process point clouds with a few millions of 3D points. Consequently, an extension has to be introduced for analyzing huge 3D point clouds with possibly billions of points for a whole city. For this purpose, we propose an extension which is based on an appropriate partitioning of the scene and thus allows a successive processing in a reasonable time without affecting the quality of the classification results. We demonstrate the performance of our methodology on two labeled benchmark datasets with respect to robustness, efficiency, and scalability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The automated analysis of 3D point clouds has become a topic of great importance in photogrammetry, remote sensing, computer vision and robotics. One avenue of research directly addresses the analysis of urban environments, where recent investigations focus on 3D reconstruction <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>, consolidation of imperfect scan data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, object detection <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>, extraction of roads and curbstones or road markings <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>, urban accessibility analysis <ref type="bibr" target="#b12">[13]</ref>, recognition of power-line objects <ref type="bibr" target="#b13">[14]</ref>, extraction of building structures <ref type="bibr" target="#b14">[15]</ref>, vegetation mapping <ref type="bibr" target="#b15">[16]</ref>, large-scale city modeling <ref type="bibr" target="#b16">[17]</ref>, semantic perception for ground robotics <ref type="bibr" target="#b17">[18]</ref> and semantization of complex 3D scenes <ref type="bibr" target="#b18">[19]</ref>. A common task for many of these different applications consists of point cloud classification <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, where each 3D point is assigned a specific (semantic) class label.</p><p>Addressing the task of urban point cloud classificationwhere the spatial 3D data may be collected via dense matching as well as airborne, terrestrial and/or mobile laser scanningwe face a variety of challenges arising from the complexity of respective 3D scenes caused by an irregular sampling and very different types of objects. Since the results of urban 3D scene analysis may vary from one dataset to another, publicly available standard datasets are desirable in order to compare the performance of different methodologies. Consequently, there has been a steadily increasing availability of 3D point cloud datasets in recent years <ref type="bibr" target="#b21">[22]</ref>. However, urban point clouds with respective point-wise manual annotations in terms of semantic class labels are still rarely available, although this represents a prerequisite for supervised point cloud classification. One of the most widely used datasets is the Oakland 3D Point Cloud Dataset <ref type="bibr" target="#b22">[23]</ref> which, however, only contains approximately 1.6 million labeled 3D points. Hence, this dataset is not tailored to designing large-scale processing pipelines.</p><p>Due to the recent technological advancements, it is meanwhile possible to collect geospatial data in a fast and efficient way via terrestrial and mobile laser scanning. In order to foster research in advanced 3D point cloud processing, two labeled point cloud datasets representing densely sampled urban environments with a significantly higher number of 3D points have been presented recently <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. These can be considered as a first step towards large geospatial datasets in terms of city-scale or even larger. The availability of such datasets is important for comparing large-scale processing workflows which is the core issue of a recent benchmark <ref type="bibr" target="#b24">[25]</ref> and addressed in this paper.</p><p>In our work, we consider each individual 3D point and its local 3D neighborhood for extracting respective geometric features. By exploiting a fully generic approach for optimizing the neighborhood Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/cag size, our approach is generally applicable and not tailored to a specific dataset. Furthermore, our approach represents a basic requirement for either smooth labeling techniques or methods involving contextual information, since both of them are based on the results of individual point classification. In summary, our contributions extend <ref type="bibr" target="#b25">[26]</ref> and consist of a new methodology for large-scale urban 3D point cloud classification, an in-depth analysis of a powerful strategy for recovering individual 3D neighborhoods of optimal size, efficient feature extraction and classification, and an extension towards data-intensive processing.</p><p>In the following, we first reflect related work in Section 2 and provide an up-to-date view of approaches for processing 3D point cloud data in order to efficiently obtain significant information contained in the data. Subsequently, in Section 3, we present a methodology which is closely linked to recent investigations on 3D scene analysis involving optimal neighborhoods and different classifiers <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. Based on these investigations with a very detailed evaluation, we can directly select the most appropriate solution with respect to urban 3D scene analysis. The considered criteria address feasibility in terms of simplicity and reproducibility of the involved components as well as performance in terms of accuracy and computational effort. We further introduce an increase in efficiency resulting from efficient neighborhood recovery. In order to extend the applicability of the selected methodology towards huge datasets, in Section 4, an extension towards large-scale urban point cloud classification is presented which does not affect the quality of the results, but allows the successive processing of huge point clouds in a reasonable time. Afterwards, the datasets involved in our experiments and the experimental results are presented in Sections 5 and 6. The derived results are subsequently discussed in Section 7. Finally, in Section 8, concluding remarks are provided and suggestions for future work are outlined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Although modern devices nowadays allow the acquisition of additional information such as echo-based features or fullwaveform features <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> which may alleviate 3D scene analysis, we focus on the use of geometric features as most of the available point cloud datasets only contain spatial 3D information. Other features may however easily be appended to the feature vectors defined in the scope of our work. In the following, we first present fundamental concepts for defining appropriate features for 3D scene analysis. Subsequently, we discuss approaches for (i) optimizing the derived feature vectors by involving feature relevance or (ii) describing the local 3D structure either at a single, but optimized neighborhood or at multiple neighborhoods of different size. Finally, we briefly reflect related work on classification methods for 3D scene analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Feature design</head><p>A crucial issue for 3D scene analysis consists of designing appropriate features. For this purpose, numerous histogrambased methods have been proposed which accumulate information about the spatial 3D geometry into a histogram according to a specific quantized domain <ref type="bibr" target="#b30">[31]</ref>. A still popular approach has been presented with Spin Images <ref type="bibr" target="#b31">[32]</ref>, where 2D histograms are derived by spinning a 2D plane patch around the surface normal and counting the number of points falling into each bin of the 2D patch. Powerful alternatives have recently been presented with Point Feature Histograms (PFHs) <ref type="bibr" target="#b32">[33]</ref> and their modification denoted as Fast Point Feature Histograms (FPFHs) <ref type="bibr" target="#b33">[34]</ref>. Considering a point X and all points within its local neighborhood, these approaches first assign the respective surface normal to X and then sample geometric relations between the nearest neighbors in terms of angular variations and point distances into histograms. A different strategy has been presented with shape distributions <ref type="bibr" target="#b34">[35]</ref> which are based on the idea of randomly sampling simple geometric measures such as distances or angles in order to obtain a descriptor characterizing the neighborhood around a point X <ref type="bibr" target="#b35">[36]</ref>. Furthermore, a combination of histograms with signatures has been presented with the Signature of Histograms of OrienTations (SHOT) descriptor <ref type="bibr" target="#b30">[31]</ref> in order to achieve a better balance between descriptiveness and robustness. The performance of different histogram descriptors has been compared in <ref type="bibr" target="#b36">[37]</ref>. However, for all these approaches, single entries of the derived feature vectors are hardly interpretable.</p><p>Alternatively, the local 3D structure can be described by deriving the 3D covariance matrix from the spatial coordinates of a point X and its neighbors. Based on the respective eigenvalues, a direct scene analysis may be conducted <ref type="bibr" target="#b37">[38]</ref>, or a set of features may be defined <ref type="bibr" target="#b38">[39]</ref> which encapsulate geometric information about the local 3D structure. In particular the latter approach is nowadays commonly applied in lidar data processing, and the respective features or feature subsets are typically complemented with other geometric features <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. A specific advantage consists of the fact that the respective entries in the feature vector are interpretable as they address local 3D shape primitives. In contrast to 3D covariance matrices encoding the relationships among points within a local neighborhood, covariance matrices of higher dimension have been used to combine multiple features such as angular measures and point distances to a compact representation <ref type="bibr" target="#b43">[44]</ref>. Further information such as radiometric information may also be taken into account in this representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Feature relevance assessment</head><p>For compensating a lack of knowledge, often as many features as possible are extracted and involved in the classification process, although some of these features may be more and others less suitable. Consequently, investigations focusing on feature selection have also been introduced for 3D point cloud processing in order to improve the classification accuracy while simultaneously reducing both computational effort and memory consumption. Respective approaches allow a ranking of single features according to their relevance and the selection of a subset of the best-ranked features. Whereas the ranking can be obtained by involving a classifier <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b44">45]</ref>, classifier-independent approaches are in the focus of filter-based feature selection which offers both simplicity and efficiency. Herein, univariate filter-based feature selection methods rely on a score function which simply evaluates feature-class relations based on the training data. A general relevance metric composed of several score functions addressing different intrinsic properties of the given training data has recently been proposed <ref type="bibr" target="#b26">[27]</ref>. In contrast, multivariate filter-based feature selection methods rely on both feature-class and feature-feature relations in order to discriminate between relevant, irrelevant and redundant features <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Single-scale vs. multi-scale representation</head><p>The heuristic determination of local 3D neighborhoods is conducted either with respect to the absolute size <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46]</ref> or with respect to the scale parameter <ref type="bibr" target="#b26">[27]</ref>. However, in order to avoid heuristically determining a suitable neighborhood sizewhich may even be specific for each dataset and which may not be identical across all 3D points in considerationthere have been few attempts to automatically derive individual neighborhoods of optimal size. Respective approaches rely on the local surface variation <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>, a combination involving curvature, point density and noise of normal vector estimation <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b39">40]</ref>, dimensionality features <ref type="bibr" target="#b40">[41]</ref> or the measure of eigenentropy <ref type="bibr" target="#b27">[28]</ref>. The need for involving such techniques becomes for instance apparent when analyzing the behavior of features derived from the 3D structure tensor and shape distribution features across different scales <ref type="bibr" target="#b35">[36]</ref> or when observing a significant improvement in comparison to neighborhoods of fixed scale <ref type="bibr" target="#b27">[28]</ref>.</p><p>Instead of focusing on the concept of optimal neighborhoods, a consideration of features at multiple scales may be applied. For instance, it has been proposed to calculate features at different scales and involve a training procedure in order to define which combination of scales allows the best separation of different classes <ref type="bibr" target="#b49">[50]</ref>. Further approaches even extract features based on different entities such as points and regions <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Individual vs. contextual classification</head><p>When selecting an appropriate classifier, we may follow the strategy of individual point classification by exploiting respective feature vectors, where Support Vector Machines <ref type="bibr" target="#b52">[53]</ref>, Random Forests <ref type="bibr" target="#b28">[29]</ref>, AdaBoost <ref type="bibr" target="#b53">[54]</ref> or classical Maximum Likelihood (ML) classifiers exploiting Gaussian Mixture Models (GMMs) <ref type="bibr" target="#b39">[40]</ref> represent the most commonly applied approaches for point cloud classification. Alternatively, contextual learning approaches may be applied which address the idea that semantic labels of nearby 3D points tend to be correlated and hence involve relationships among 3D points within a local neighborhood in addition to the respective feature vectors. Respective approaches applied for point cloud classification are represented by Associative and non-Associative Markov Networks <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref>, Conditional Random Fields <ref type="bibr" target="#b20">[21]</ref>, multi-stage inference procedures focusing on point cloud statistics and relational information over different scales <ref type="bibr" target="#b50">[51]</ref>, and spatial inference machines modeling mid-and longrange dependencies inherent in the data <ref type="bibr" target="#b56">[57]</ref>.</p><p>When applying contextual learning approaches, it has to be taken into account that the relationships are inferred from the training data. Hereby, the local neighborhood is typically different from the neighborhood used for feature extraction. Furthermore, since the training data is limited, exact inference is computationally intractable and therefore either approximate inference techniques or smoothing techniques are commonly applied. The selection of an approximate inference technique remains challenging as there is no indication towards an optimal inference strategy, and such techniques quickly reach their limitations if the considered neighborhood becomes too large. In contrast, smoothing techniques enforce the desirable smooth labeling of nearby 3D points and may thus provide a significant improvement with respect to classification accuracy <ref type="bibr" target="#b57">[58]</ref>. Such smoothing techniques, however, exploit either the estimated probability of a 3D point belonging to each of the defined classes or the direct assignment of the respective label, and thus the results of an individual point classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>For 3D scene analysis in terms of uniquely assigning each 3D point a semantic label, we propose a fully automatic and generic methodology which consists of three successive steps (Fig. <ref type="figure" target="#fig_0">1</ref>). In the first step, each 3D point is characterized with an individual local 3D neighborhood of optimal size (Section 3.1). This allows an extraction of highly distinctive features which is pursued in the second step, where various geometric 3D and 2D features are taken into consideration (Section 3.2). Finally, in the third step, the distinctive features and a given set of training examples are provided to a supervised classification scheme (Section 3.3). The main focus of our investigations is put on feature design in terms of deriving distinctive geometric features from individual neighborhoods of optimal size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Neighborhood selection</head><p>Considering a point X in a point cloud P, the respective neighborhood selection generally involves (i) a suitable neighborhood definition, (ii) an efficient recovery of the local neighborhood and (iii) an optimal parameterization of the neighborhood in terms of neighborhood size. These aspects are addressed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Neighborhood definitions</head><p>In general, very different approaches may be applied in order to define the local 3D neighborhood N of a given 3D point X A R 3 . For instance, a spherical neighborhood definition may be applied, where the local neighborhood is formed by all 3D points in a sphere with a fixed radius <ref type="bibr" target="#b58">[59]</ref>. An alternative consists of applying a cylindrical neighborhood definition, where the local neighborhood is formed by all those 3D points whose 2D projections onto the ground plane are within a circle with a fixed radius <ref type="bibr" target="#b59">[60]</ref>. A further neighborhood definition involves a fixed number of k closest 3D points for a given query point <ref type="bibr" target="#b60">[61]</ref>, which results in spherical neighborhoods of variable absolute size. Note that all these neighborhood definitions rely on the specification of one free scale parameter.</p><p>Since we want to account for more flexibility in case of varying point density and thereby avoid including a-priori knowledge on the scene, we employ a neighborhood definition based on the k closest neighbors of a given 3D point. Consequently, the nearest neighbors have to be recovered and an appropriate k has to be selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Exact vs. approximate nearest neighbors</head><p>As a consequence of the selected neighborhood definition, a computationally quite expensive part consists of the calculation of</p><formula xml:id="formula_0">3D Point Cloud Labeled 3D Point Cloud Supervised Classification Feature Extraction … … … … … … … … …</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neighborhood</head><p>Selection * * the nearest neighbors for each 3D point. This nearest neighbor search can formally be described as follows: given a point set P ¼ X 1 ; …; X N f gin a 3-dimensional Euclidean vector space, those points X A P that are nearest to a given query point X Q should be recovered efficiently. The commonly used approach for nearest neighbor search is based on a Kd-tree <ref type="bibr" target="#b61">[62]</ref> which represents a compact, hierarchical data structure for point sets sampled from a K-dimensional manifold. A point in a Kd-tree with N points can thus be localized with an average complexity of Oðlog NÞ and, in the worst case, with a complexity of O(N) <ref type="bibr" target="#b62">[63]</ref>. In order to further increase efficiency, an approximate nearest neighbor search has been proposed <ref type="bibr" target="#b63">[64]</ref> which can be much faster than the exact nearest neighbor search with only little loss in accuracy since nonoptimal neighbors may be returned. For details on these approaches, we refer to an extensive survey on data structures <ref type="bibr" target="#b64">[65]</ref>. Addressing the criteria of query time and accuracy, a powerful approach with public availability and fully automatic parameter selection has been presented in the Fast Library for Approximate Nearest Neighbors (FLANN) <ref type="bibr" target="#b65">[66]</ref> which is based on either searching hierarchical K-means trees with a priority search order or using multiple randomized Kd-trees. Hence, we apply the FLANN for nearest neighborhood search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Optimal parameterization</head><p>Besides an efficient nearest neighbor search, it is desirable to automatically find the optimal parameterization for the selected neighborhood definition which is based on the k closest neighbors in our case. When addressing this issue, we may also take into account that the optimal choice of the parameter k (which is also commonly referred to as scale) may vary within a dataset since k certainly depends on the respective 3D structures and thus also on the respective class label.</p><p>Seminal work addressing the selection of an optimal value for the scale parameter k and thus the selection of the optimal neighborhood size is based on fundamental geometric properties of the point cloud data. For instance, the local surface variation (i.e. the change of curvature) may be exploited since a critical neighborhood size is indicated by a significant change of curvature when successively increasing the neighborhood by adding the next closest 3D point <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>. Furthermore, an iterative scheme involving curvature, point density and noise of normal vector estimation has been proposed <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b39">40]</ref>. Whereas these approaches are tailored for smoothly varying surfaces, they may face severe challenges when considering surfaces acquired with lidar systems or dense matching. Consequently, we focus on the use of multiple low-level geometric features which adequately capture the variability of natural environments.</p><p>Our approach is inspired by dimensionality based scale selection <ref type="bibr" target="#b40">[41]</ref>, where optimal neighborhood size selection is based on the idea that the optimal neighborhood size favors one dimensionality the most. More specifically, for describing the local 3D structure around a 3D point X ¼ X 0 , the dimensionality features of linearity L λ , planarity P λ and scattering S λ are derived from the set of neighboring 3D points X i with i ¼ 1; :::; k by considering the respective 3D covariance matrix</p><formula xml:id="formula_1">C ¼ 1 k þ 1 X k i ¼ 0 X i À X À Á X i À X À Á T<label>ð1Þ</label></formula><p>with</p><formula xml:id="formula_2">X ¼ 1 k þ 1 X k i ¼ 0 X i<label>ð2Þ</label></formula><p>which is also known as the 3D structure tensor. This 3D structure tensor C represents a symmetric positive-definite matrix. Consequently, its eigenvalues exist, are non-negative and correspond to an orthogonal system of eigenvectors. For the sake of generality, we assume that there might not necessarily be a preferred variation with respect to the eigenvectors. This results in the general case of a structure tensor with rank 3 as well as eigenvalues λ 1 , λ 2 and λ 3 with λ 1 ; λ 2 ; λ 3 A R and λ 1 Z λ 2 Zλ 3 Z 0.</p><p>Based on these eigenvalues, the dimensionality features are defined as</p><formula xml:id="formula_3">L λ ¼ λ 1 À λ 2 λ 1 P λ ¼ λ 2 À λ 3 λ 1 S λ ¼ λ 3 λ 1<label>ð3Þ</label></formula><p>and, as these features sum up to 1, they may be considered as the probabilities of a 3D point to be labeled as 1D, 2D or 3D structure <ref type="bibr" target="#b40">[41]</ref>. Favoring one dimensionality the most thus corresponds to minimizing a measure given by the Shannon entropy <ref type="bibr" target="#b66">[67]</ref> as</p><formula xml:id="formula_4">E D ¼ ÀL λ lnðL λ ÞÀP λ lnðP λ ÞÀS λ lnðS λ Þ ð<label>4Þ</label></formula><p>across different scales k, and the optimal neighborhood size corresponds to the respective k with the minimal Shannon entropy. Instead of directly varying the scale parameter k as later tested in <ref type="bibr" target="#b27">[28]</ref>, however, the respective radius has been taken into account in <ref type="bibr" target="#b40">[41]</ref>. Sampling the interval r 1 ; r 2 ½ between specified radii r 1 and r 2 into 16 scales, where the radii are not linearly increased since the radius of interest is usually closer to r 1 , the optimal neighborhood size corresponds to the radius yielding the minimal Shannon entropy. However, the two radii r 1 and r 2 depend on various characteristics of the given data and are therefore specific for each dataset <ref type="bibr" target="#b40">[41]</ref>.</p><p>In order to avoid strong assumptions on the presence of specific geometric structures in the scene and to get rid of heuristic parameter selection, a more general solution for optimal neighborhood size selection has been proposed very recently <ref type="bibr" target="#b27">[28]</ref> which has proven to outperform dimensionality based scale selection. Instead of exploiting the three dimensionality features, this approach directly exploits the eigenvalues of the 3D structure tensor which correspond to the principal components and thus span a 3D covariance ellipsoid. Normalizing the three eigenvalues λ 1 , λ 2 and λ 3 by their sum Σ λ yields normalized eigenvalues e 1 , e 2 and e 3 summing up to 1. Thus, in analogy to the dimensionality based scale selection, the measure of eigenentropy E λ given by the Shannon entropy according to</p><formula xml:id="formula_5">E λ ¼ Àe 1 lnðe 1 ÞÀe 2 lnðe 2 ÞÀe 3 lnðe 3 Þ ð<label>5Þ</label></formula><p>is calculated and minimized across different scales k which, in turn, relates to minimizing the disorder of points within a 3D covariance ellipsoid. The optimal neighborhood size finally corresponds to the respective k with the minimal eigenentropy. For our experiments, we consider relevant statistics to start with k 1 ¼ 10which is in accordance to <ref type="bibr" target="#b40">[41]</ref> and successively increase the scale parameter k with a step size of Δk ¼ 1 up to an upper bound of k 2 ¼ 100 as proposed in <ref type="bibr" target="#b27">[28]</ref>, which already represents a relatively high number. Note that k 2 can be arbitrary, and hence we will later focus on this issue in the experimental results. The resulting optimal neighborhood size thus depends on contextual information preserved in the spatial arrangement of neighboring 3D points and may even be different for each individual 3D point. Even though optimal neighborhood size selection causes a higher computational effort with respect to both processing time and memory consumption, it should be taken into consideration since the classification accuracy is significantly improved according to recent investigations <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature extraction</head><p>Since many of the publicly available 3D point cloud datasets only contain information about the spatial 3D geometry in terms of XYZ coordinates, we focus on the use of geometric features. Such geometric features typically rely on a local 3D neighborhood which has already been derived in the previous step. Involving the optimal neighborhood size for a respective 3D point, we may assume that highly distinctive geometric features can be derived from the set of 3D points within the neighborhood. Due to the high point density of recently published lidar point cloud datasets, the selected scale k tends to correspond to a relatively small absolute size, and the respective local 3D structure can therefore only be described with low-level geometric features. Such features show a specific behavior for planar patches, ridges, edges and vertices. By involving a 2D projection, we may also account for structures with larger extent, e.g. in the vertical direction.</p><p>In order to define adequate low-level geometric features, we follow the strategy involving a variety of geometric 3D and 2D features <ref type="bibr" target="#b26">[27]</ref>, but we additionally increase their distinctiveness by taking into account the optimal neighborhood size for each individual 3D point <ref type="bibr" target="#b27">[28]</ref>. In total, a set of 21 distinctive low-level geometric features is thus calculated for each 3D point. For the sake of clarity, we briefly describe the involved 3D and 2D features in the following subsections. The respective code (Matlab, C++ and binaries) is released with this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">3D features</head><p>Obviously, a variety of 3D features can directly be derived by describing basic geometric properties of the considered 3D neighborhood such as the absolute height Z of the considered 3D point X, the radius r k À NN of the sphere encompassing the local 3D neighborhood, the local point density D defined as number of points per unit volume and the verticality V which is based on the vertical component of the local normal vector. Hereby, the local normal vector is related to the eigenvector corresponding to the smallest eigenvalue of the respective 3D structure tensor. Furthermore, all 3D points within the neighborhood may be considered in order to calculate the maximum height difference ΔZ k À NN and the standard deviation σ Z;k À NN of height values.</p><p>Additionally, we take into account that the 3D structure tensor encodes the general distribution of 3D points within the local neighborhood. Consequently, the normalized eigenvalues e 1 , e 2 and e 3 of the 3D structure tensor may also be exploited to define local 3D shape features. Besides the aforementioned dimensionality features of linearity L λ , planarity P λ and scattering S λ , further features are represented by omnivariance O λ , anisotropy A λ , eigenentropy E λ , the sum Σ λ of eigenvalues and the local surface variation C λ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">2D features</head><p>Taking into account that urban areas are typically characterized by an aggregation of man-made structures, specific geometric relations in terms of symmetry and orthogonality are likely to occur. In particular, we may face a large number of structures which are oriented perpendicular to a horizontally oriented plane, e.g. building façades, traffic signs or curbstone edges. Consequently, a projection of the 3D point cloud onto a horizontally oriented plane might reveal additional information and possibly also clear evidence about the presence of specific structures in the observed scene. Respective features which are based on this 2D projection can easily be defined as 2D properties of the neighborhood such as the radius r k À NN;2D and the local point density D 2D .</p><p>Furthermore, the coordinates resulting from the 2D projection of all 3D points within the neighborhood may be exploited to derive the 2D covariance matrix also known as the 2D structure tensor. In analogy to the 3D case, the respective two eigenvalues may be used to define characteristic features such as the sum Σ λ;2D of the eigenvalues and their ratio R λ;2D .</p><p>Interestingly, the aforementioned 2D features are based on spherical neighborhoods of relatively small absolute metric size, whereas man-made structures tend to provide a similar behavior across different height levels, i.e. across several meters of height. Consequently, a discretization of the 2D projection in terms of a 2D accumulation map <ref type="bibr" target="#b67">[68]</ref> with discrete, quadratic bins (here with a side length of 0.25 m) may provide further interesting properties about local 3D structures which are not yet covered by the already defined features. Respective features based on the accumulation map have been proposed with the number M of points falling in the respective bin as well as the maximum height difference ΔZ and standard deviation σ Z of height values within the respective bin. Particularly, the feature M provides clear evidence on the existence of building façades and, if the point density is sufficiently high, also on the existence of curbstone edges. The detection of such man-made structures, in turn, is important for urban accessibility analysis which is one of the main intentions of current research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Supervised classification</head><p>For classification, we apply a standard supervised classification scheme involving a set of training examples which, in turn, encapsulate feature vectors as well as the respective class labels. An adequate choice among a variety of classification strategies and respective approaches, however, should directly address applicability, reproducibility, and scalability in order to facilitate 3D scene analysis in large-scale urban environments. In the following, we first motivate our choice for the classifier and subsequently address the issue of how to obtain suitable training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Classifier selection</head><p>Since we focus on the applicability and reproducibility of all involved components, the involved classification strategy should be easy-to-use without crucial parameter selection, and respective implementations should be available in different software packages. For this reason, we focus on individual point classification based on a set of derived features. With the intention of processing huge point clouds, it is mandatory to apply a powerful but still computationally efficient classifier. In particular for scalability towards huge datasets, combining a set of weak classifiers such as decision trees via bootstrap aggregating which is commonly referred to as bagging <ref type="bibr" target="#b68">[69]</ref> has proven to be successful. Using bootstrapped replica of the training data, i.e. subsets of the complete training data which are randomly drawn with replacement <ref type="bibr" target="#b69">[70]</ref>, diversity is obtained by training a weak learner of the same type for each subset of the training data.</p><p>The most popular example for bagging is represented by Random Forests <ref type="bibr" target="#b70">[71]</ref> which represent a modern discriminative method and provide efficiency in case of a large amount of input data. Efficiency in this context covers simplicity and a high degree of parallelization which results in a fast classification scheme. Additionally, robustness to outliers, noise and missing data is provided. More specifically, a Random Forest represents an ensemble of randomly trained decision trees and thus aggregates hypotheses derived via decision trees which, in turn, are trained over different distributions of the training data. Thereby, each decision tree is constructed based on a top-down strategy successively selecting the variable which best splits the respective training data. Consequently, a split function and a stopping criterion have to be defined. Since, in the training phase, individual decision trees are assumed to be trained on randomly selected subsets of the given training data, the trees may be expected to be randomly different from one another which results in a decorrelation between individual tree predictions and thus improved generalization and robustness <ref type="bibr" target="#b71">[72]</ref>. Once a Random Forest is trained, the classification phase consists of letting each decision tree vote for a single class and assigning the respective label according to the majority vote of all decision trees. The parameters to be specified are the number of involved decision trees and the tree depth. In the experiments, we use a Random Forest with 100 trees and a tree depth of ⌊ ffiffiffi d p c, where d equals the number of extracted features, i.e. d ¼21.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Training data</head><p>Given a set of training examples, we have to take into account that an unbalanced distribution of training examples across all classes may have a detrimental effect on the training process <ref type="bibr" target="#b71">[72]</ref>. Consequently, we involve a class re-balancing in terms of randomly selecting the same number of training examples for each class. Alternatively, the known prior class distribution of the training set could be used for weighting the contribution of each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Extension towards large-scale urban point cloud classification</head><p>Recent investigations clearly show that the use of individual neighborhoods with optimal size has a significant, beneficial impact on the classification results <ref type="bibr" target="#b27">[28]</ref>. However, the additional calculations cause a drastic increase in computational effort. Consequently, the described methodology is suited to process point clouds containing only up to a few millions of 3D points. When considering huge point clouds at city scale with possibly billions of pointswhich is the aim of recent effort in order to obtain an adequate 3D model of a whole city like Parisan extension of the presented methodology has to be introduced.</p><p>The extension described in this paper does not affect the quality of 3D scene analysis, but only the scalability of the methodology in order to process larger datasets. Specifically, it focuses on successively processing a huge point cloud by applying a 2D sliding window function which is shifted within a horizontally oriented plane in discrete steps and involves a small padding region in order to avoid discontinuities at its borders. The size of the window should be chosen in a way that, for each step, a still reasonable number of 3D points is in consideration since the window size is practically limited depending on the available memory size. The partial results are subsequently merged together to obtain the results for the full scene. Accordingly, the approach represents a partitioning of the scene into subparts which, in turn, are extended by small padding regions at the borders and can be processed in parallel. For the sake of simplicity, we focus on two specific scenarios and select the one which is suited best with respect to the given data:</p><p>For the more general scenario, we propose the use of a tiling approach. Taking a defined area within a horizontally oriented plane, e.g. a small quadratic area of 10 m Â 10 m, allows a successive processing of data and thus also the analysis of huge point clouds at city-scale, where directly applying the methodology is intractable due to the computational burden with respect to computational effort and memory consumption.</p><p>Without loss of generality, we may also take into account that the recently published benchmark datasets describe straight street sections with a length of approximately 160-200 m <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. Consequently, the tiling approach can be substituted by a slicing approach, where the slices have a specified width, e.g. a width of 10 m, along the street direction and infinite extent along the two perpendicular directions.</p><p>Note that for both partitioning schemes, those 3D points within the small padding around the considered tile or slice are also used if they are within the neighborhood of other 3D points within the considered part of the scene in order to avoid artifacts at boundaries between tiles or slices. Due to the high point density of recent point cloud datasets, a padding with a width of 0.50 m is considered to be sufficient. As alternative to scene partitioning, streaming methods could be applied <ref type="bibr" target="#b72">[73]</ref>.</p><p>Consequently, we may repeat the proposed workflow consisting of (i) optimal neighborhood selection, (ii) feature extraction and (iii) classification independently for each tile or for each slice. Thus, large-scale urban 3D scene analysis is composed of successive steps which exploit the same methodology and could be parallelized if respective hardware is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Datasets</head><p>Since we focus on the issue of urban 3D point cloud classification and want to facilitate an objective comparison to other methodologies, we consider two publicly available and labeled 3D point cloud datasets representing densely sampled urban environments. Both datasets have been acquired in the city of Paris, France, via mobile laser scanning (MLS) systems:</p><p>Paris-rue-Madame database 1 [24]: This 3D point cloud dataset has been acquired with the mobile laser scanning system L3D2 <ref type="bibr" target="#b73">[74]</ref> equipped with a Velodyne HDL32. It contains 20 million points corresponding to a digitized street section with a length of approximately 160 m. A respective annotation has been conducted in a manually assisted way and includes both point-wise labels (26 different classes) and segmented objects (642 objects in total). This annotation relies on an initial segmentation based on elevation images <ref type="bibr" target="#b8">[9]</ref> which is followed by a manual refinement <ref type="bibr" target="#b23">[24]</ref>.</p><p>Paris-rue-Cassette database <ref type="bibr" target="#b24">[25]</ref>: This point cloud dataset has been acquired with the mobile laser scanning system called Stereopolis II <ref type="bibr" target="#b74">[75]</ref> in January 2013. This system captures the local 3D geometry of the scene with two plane sweep lidars (Riegl LMS-Q120i) placed on each side of the vehicle in order to mainly observe the building façades with a centimeter accuracy and a 3D lidar (Velodyne HDL-64E) to observe the bottom part in between. The dataset contains 12 million points corresponding to a digitized street section with a length of approximately 200 m, and a manually assisted annotation is available which includes both point-wise labels and segmented objects. The respective annotation is based on recovering a regular 2D topology for the point cloud stream during data acquisition and an offline human interaction via a graph editing tool based on standard 2D image segmentation techniques <ref type="bibr" target="#b75">[76]</ref>. A further extension in the form of 10 different zones with a total number of about 100 million points has been released in the scope of a recent contest <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental results</head><p>In the following, we first provide an in-depth analysis addressing the results of optimal neighborhood size selection for both involved datasets. Afterwards, we focus on the respective results for individual point classification and, finally, we demonstrate the performance of the new approach with respect to computational effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Optimal neighborhood size selection</head><p>In order to obtain more insights into the process of optimal neighborhood size selection, we first focus on a detailed analysis of the respective results. Note that each 3D point is assigned an individual value for k and that all integer values in k 1 ; k 2 Â Ã with k 1 ¼ 10 and k 2 ¼ 100 are taken into consideration. Since the upper boundary k 2 has been selected for reasons of computational costs and may principally be set to an arbitrary value, we first consider the distribution of the parameter k across all 3D points. For this purpose, the respective distributions of the assigned optimal neighborhood size across all 3D points obtained for the Paris-rue-Madame database with 20 million 3D points and the Paris-rue-Cassette database with 12 million 3D points are visualized as histograms in Figs. <ref type="figure" target="#fig_1">2</ref> and<ref type="figure" target="#fig_2">3</ref>. These figures clearly reveal a trend towards small values of k. Since the last bin in the histograms ðk 2 ¼ 100Þ is likely to also represent those 3D points which might have a higher value than k 2 ¼ 100, a small increase can be observed. However, the percentage of 3D points which are assigned an optimal neighborhood with less than k 2 neighbors is 95.44% and 98.72% for the Paris-rue-Madame database and the Paris-rue-Cassette database, respectively. This shows that our selection of k 2 is appropriate.</p><p>A qualitative visualization of the distributions of the assigned optimal neighborhood size across all 3D points of both involved datasets is depicted in Figs. <ref type="figure" target="#fig_3">4</ref> and<ref type="figure" target="#fig_4">5</ref>. For the Paris-rue-Cassette database, a significantly smoother behavior can be observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Individual point classification</head><p>In order to assign a semantic label to each individual 3D point, we exploit only those 3D points with labels corresponding to the most dominant semantic classes façade, ground, cars, motorcycles/ 2 wheelers, traffic signs/road inventory, pedestrians and vegetation (Table <ref type="table" target="#tab_0">1</ref>), which represent a fraction of 99.81% of the Paris-rue-Madame database and 99.56% of the Paris-rue-Cassette database. All 3D points belonging to the other classes are removed since the respective number of samples per class is not considered to be representative. For training, we randomly select a small, balanced training set X with 1,000 training examples per class, and the remaining data is used as test set Y.</p><p>In order to allow a comparison to recent work, we design the evaluation scheme in analogy to <ref type="bibr" target="#b27">[28]</ref>. Thus, our evaluation is based on (i) overall accuracy which indicates the performance of the classifier on the test set, (ii) recall which represents a measure of completeness or quantity, (iii) precision which represents a measure of correctness or quality, (iv) F 1 -score which combines recall and precision with equal weights, (v) mean class recall which represents an averaged measure of completeness/quantity across all classes and (vi) a visual inspection of the derived results.</p><p>Evaluating our approach on both datasets, the overall accuracy is 88.82% for the Paris-rue-Madame database and 89.60% for the Paris-rue-Cassette database. The resulting recall and precision values as well as the corresponding F 1 -scores are provided in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_2">3</ref>. Accordingly, mean class recall values of 83.53% and 81.78% are obtained for the Paris-rue-Madame database and the Paris-rue-Cassette database, respectively. Finally, a visual impression on the quality of the derived results for individual point classification is depicted in Figs. <ref type="figure">6</ref> and<ref type="figure">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Computational effort</head><p>The experiments have been conducted on an Intel Core i7-3820 with 3.6 GHz and 64GB RAM. We use the proposed slicing approach,    where the slices have a width of 10 m and the padding has a width of 0.50 m. Whereas the prototype released with <ref type="bibr" target="#b27">[28]</ref> is based on a full and straightforward Matlab implementation, our investigations revealed that a significant speedup can be achieved in two ways. Firstly, for the considered small point sets formed by up to k 2 ¼ 100 neighboring 3D points, a considerable speedup in the calculation of the respective 3D covariance matrices results from simply replacing the internal Matlab function cov with the respective vectorized straightforward implementation. Secondly, our new optimized approach can be used which has been implemented in C++ and, for comparison, we used the respective binaries in the test environment in Matlab. We consider both approaches. For the example involving the Paris-rue-Cassette database, the respective speedup achieved with the latter implementation clearly becomes visible in Table <ref type="table" target="#tab_3">4</ref>, where the processing times for the different subtasks are listed. Since the training phase will not change with larger datasets, the respective classification will only remain a question of computational and not human effort.</p><p>Taking a tile of size as a reference area would even allow us to extrapolate the resulting computational effort for data processing (which also accounts for those points in the padding). Thus, we would even be able to extrapolate the computational effort to full cities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussion</head><p>In the experiments, it becomes apparent that particularly for the smaller classes a decrease in performance can be observed (Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_2">3</ref>). This might indicate that those classes are still not covered representatively for the complexity of urban 3D scenes. However, the derived mean class recall values for both datasets indicate that completeness/quantity across all classes is relatively high compared to other approaches focusing on individual point classification <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. Thus, the methodology is less prone to overfitting. Consequently, the decrease in performance might mainly arise from the similarity of local 3D structures belonging to respective classes. Additionally, for the Paris-rue-Cassette database, we can observe that vegetation is detected at the balconies   which is in contradiction to the reference labels, but maybe not always in contradiction to the real scene (Fig. <ref type="figure">7</ref>). Note that the Paris-rue-Madame database contains more noise than the Parisrue-Cassette database (Figs. <ref type="figure" target="#fig_3">4</ref> and<ref type="figure" target="#fig_4">5</ref>) which might be a further reason for relatively low precision values obtained for the respective smaller classes (Table <ref type="table" target="#tab_1">2</ref>). In order to increase the precision values, introducing further features and/or multi-scale considerations seem to be necessary. Furthermore, due to the individual point classification, a noisy labeling can be expected which indeed can be observed in Figs. <ref type="figure">6</ref> and<ref type="figure">7</ref>.</p><p>Concerning the computational complexity, we may consider the computation times required for processing different numbers of points. In Figs. <ref type="figure" target="#fig_7">8</ref> and<ref type="figure" target="#fig_8">9</ref>, this is done for the separate slices (with the respective padding) as well as separately for optimal neighborhood size selection and feature extraction. It becomes apparent that optimal neighborhood size selection has a linear complexity for increasing numbers of considered 3D points, whereas feature extraction shows a non-linear dependency. In this case, we have a superposition of (i) a linear behavior for calculating 3D features in terms of basic geometric properties or eigenvalue-based features, (ii) a linear behavior for 2D features in terms of basic geometric properties or eigenvalue-based features and (iii) a non-linear behavior for 2D features based on the accumulation map.</p><p>The most crucial issue of the whole methodology remains an appropriate selection of the scale parameter k. The motivation of the applied approach is to avoid the use of empiric or heuristic knowledge on the scene with respect to neighborhood size and to obtain an automated, appropriate selection instead. Consequently, the approach is generally applicable and not tailored to a specific dataset. The consideration of individual neighborhoods even accounts for the idea that an optimal neighborhood size depends on the respective 3D structure and thus varies within a dataset. In order to provide further insights in addition to the clear trend of the scale parameter towards smaller values (Figs. <ref type="figure" target="#fig_1">2</ref> and<ref type="figure" target="#fig_2">3</ref>), the behavior for the different classes is visualized in Fig. <ref type="figure" target="#fig_9">10</ref>. Even though the analysis per class reveals a slight difference between the different classes, there is no clear indication of a characteristic which is specific for a certain class. Furthermore, we may state that the behavior of individual neighborhoods across a dataset indicates the quality of a dataset, since a much smoother behavior can be observed for the dataset with less noise (Figs. <ref type="figure" target="#fig_3">4</ref> and<ref type="figure" target="#fig_4">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusions</head><p>In this paper, we have presented a methodology for automated 3D scene analysis and its extension towards huge point clouds. The methodology generally requires a higher computational effort due to the consideration of individual 3D neighborhoods of optimal size which, in turn, is justified as it significantly improves the classification results in comparison to state-of-the-art approaches <ref type="bibr" target="#b27">[28]</ref> and furthermore avoids human interaction guided by empiric or heuristic knowledge. Specifically, involving such optimal neighborhoods for feature extraction results in distinctive low-level geometric 3D and 2D features as important prerequisites for obtaining appropriate classification results. The further extension towards data-intensive processing via scene partitioning overcomes the limitation with respect to the computational burden and also allows large-scale 3D scene analysis. For two recently published point cloud datasets captured in urban areas, the derived results clearly reveal the potential of our methodology. For future work, we plan to involve spatial smoothing techniques,    since neighboring 3D points tend to have correlated labels. Furthermore, an extended analysis up to object level would be desirable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. The proposed methodology: after calculating an individual local 3D neighborhood of optimal size for each 3D point, highly distinctive 3D and 2D features are extracted and provided to a supervised classification scheme in order to obtain a semantically labeled 3D point cloud ( n The respective implementation (Matlab, C++ and binaries) is released with this paper and available at http://www.ipf.kit.edu/code.php).</figDesc><graphic coords="3,93.20,633.53,418.88,81.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Distribution of the assigned optimal neighborhood size for all 3D points in the Paris-rue-Madame database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. of the assigned optimal neighborhood size k for all 3D points in the Paris-rue-Cassette database.</figDesc><graphic coords="7,317.00,267.83,240.26,141.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Qualitative distribution of the assigned optimal neighborhood size k for all 3D points in the Paris-rue-Madame database.</figDesc><graphic coords="7,317.00,58.61,240.26,141.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Qualitative distribution of the assigned optimal neighborhood size k for all 3D points in the Paris-rue-Cassette database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Paris-rue-Madame database: classified point cloud with assigned semantic labels (façade: gray, ground: brown, cars: blue, motorcycles: yellow, traffic signs: red, pedestrians: pink). The points represented in cyan are those points which are not considered as the respective classes are not covered representatively. The noisy appearance results from individual point classification. (For interpretation of the references to color in this figure caption, the reader is referred to the web version of this article.)</figDesc><graphic coords="8,38.24,469.25,240.00,128.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>-Madame database Paris-rue-Cassette database</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. Required computation times per slice for optimal neighborhood size selection: a linear behavior can be observed for increasing numbers of points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Required computation times per slice for feature extraction: a non-linear behavior can be observed for increasing numbers of points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Distribution of the assigned optimal neighborhood size k for different classes of the Paris-rue-Cassette database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Number of points in the most dominant classes. These classes cover 99.81% of the Paris-rue-Madame database and 99.56% of the Paris-rue-Cassette database.</figDesc><table><row><cell>Class</cell><cell>Paris-rue-Madame</cell><cell>Paris-rue-Cassette</cell></row><row><cell></cell><cell>database [24]</cell><cell>database [25]</cell></row><row><cell>Façade</cell><cell>9,978,435</cell><cell>7,026,016</cell></row><row><cell>Ground</cell><cell>8,024,295</cell><cell>4,228,639</cell></row><row><cell>Cars</cell><cell>1,835,383</cell><cell>367,271</cell></row><row><cell>Motorcycles/</cell><cell>98,867</cell><cell></cell></row><row><cell>2 wheelers</cell><cell></cell><cell>39,331</cell></row><row><cell>Traffic signs/</cell><cell>15,480</cell><cell></cell></row><row><cell>road inventory</cell><cell></cell><cell>45,105</cell></row><row><cell>Pedestrians</cell><cell>10,048</cell><cell>22,999</cell></row><row><cell>Vegetation</cell><cell>-</cell><cell>211,131</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Recall, precision and F 1 -scores for the Paris-rue-Madame database.</figDesc><table><row><cell>Paris-rue-Madame</cell><cell>Recall</cell><cell>Precision</cell><cell>F 1</cell></row><row><cell>Façade</cell><cell>0.9527</cell><cell>0.9620</cell><cell>0.9573</cell></row><row><cell>Ground</cell><cell>0.8650</cell><cell>0.9782</cell><cell>0.9182</cell></row><row><cell>Cars</cell><cell>0.6476</cell><cell>0.7948</cell><cell>0.7137</cell></row><row><cell>Motorcycles</cell><cell>0.7198</cell><cell>0.0980</cell><cell>0.1725</cell></row><row><cell>Traffic signs</cell><cell>0.9485</cell><cell>0.0491</cell><cell>0.0934</cell></row><row><cell>Pedestrians</cell><cell>0.8780</cell><cell>0.0163</cell><cell>0.0320</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Recall, precision and F 1 -scores for the Paris-rue-Cassette database.</figDesc><table><row><cell>Paris-rue-Cassette</cell><cell>Recall</cell><cell>Precision</cell><cell>F 1</cell></row><row><cell>Façade</cell><cell>0.8721</cell><cell>0.9928</cell><cell>0.9285</cell></row><row><cell>Ground</cell><cell>0.9646</cell><cell>0.9924</cell><cell>0.9783</cell></row><row><cell>Cars</cell><cell>0.6112</cell><cell>0.6767</cell><cell>0.6423</cell></row><row><cell>2 wheelers</cell><cell>0.8285</cell><cell>0.1774</cell><cell>0.2923</cell></row><row><cell>Road inventory</cell><cell>0.7657</cell><cell>0.1495</cell><cell>0.2501</cell></row><row><cell>Pedestrians</cell><cell>0.8225</cell><cell>0.0924</cell><cell>0.1661</cell></row><row><cell>Vegetation</cell><cell>0.8602</cell><cell>0.2566</cell><cell>0.3953</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Computational effort for processing the Paris-rue-Cassette database: the required processing times t 1 for optimal neighborhood size selection, t 2 for feature extraction, t 3 for training on the small training set and t 4 for testing on the respective test set are listed for different approaches. Note that t 1 and t 2 correspond to a successive processing of all slices, and that t 3 and t 4 do not change since they are not affected by our optimization.</figDesc><table><row><cell>Time</cell><cell>Prototype [28]</cell><cell>Optimized Matlab version</cell><cell>Proposed approach</cell></row><row><cell>t 1</cell><cell>27.45 h</cell><cell>10.90 h</cell><cell>2.11 h</cell></row><row><cell>t 2</cell><cell>11.84 h</cell><cell>10.75 h</cell><cell>4.28 h</cell></row><row><cell>t 3</cell><cell>$ 1-2 s</cell><cell>$ 1-2 s</cell><cell>$ 1-2 s</cell></row><row><cell>t 4</cell><cell>$ 90 s</cell><cell>$ 90 s</cell><cell>$ 90 s</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Computers &amp; Graphics ∎ (∎∎∎∎) ∎∎∎-∎∎∎</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Please cite this article as: Weinmann M, et al. Distinctive 2D and 3D features for automated large-scale scene analysis in urban areas. Comput Graph (2015), http://dx.doi.org/10.1016/j.cag.2015.01.006i</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2"><p>Paris-rue-Madame database: MINES ParisTech 3D mobile laser scanner dataset from Madame street in Paris. ©2014 MINES ParisTech. MINES ParisTech created this special set of 3D MLS data for the purpose of detection-segmentation-classification research activities, but does not endorse the way they are used in this project or the conclusions put forward. The database is publicly available at http://cmm.ensmp.fr/ $ serna/rueMadameDataset.html (last access: 30 August</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>2014).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The project was partially supported by KIT-GRACE, the Graduate School for Climate and Environment at the Karlsruhe Institute of Technology (KIT), and by the FP7 project IQmulus (FP7-ICT-2011-318787). Furthermore, a funding for a stay abroad of the first author was provided by the Karlsruhe House of Young Scientists (KHYS) at KIT in order to support the collaboration.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey of urban reconstruction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Musialski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Aliaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Purgathofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="146" to="177" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Complete residential urban area reconstruction from dense aerial lidar point clouds</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graph Model</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="118" to="125" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Surface reconstruction through point set structuring</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alliez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="234" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Non-local scan consolidation for 3d urban scenes</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Article no. 94</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Coupled structure-from-motion and 3d symmetry detection for urban facades</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Oude Elberink S. Recognizing basic structures from mobile laser scanning data for road inventory studies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rutzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="28" to="39" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Implicit shape models for object detection in 3d point clouds</title>
		<author>
			<persName><forename type="first">A</forename><surname>Velizhev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shapovalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="179" to="184" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Eigenvalue and graph-based object extraction from mobile laser scanning point clouds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rutzinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="55" to="60" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detection, segmentation and classification of 3d urban objects using mathematical morphology and supervised learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Serna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="243" to="255" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extracting roads from dense point clouds in large scale urban environment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2" to="12" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mapping curbstones in airborne and mobile laser scanning data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Appl Earth Obs Geoinf</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="293" to="304" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using mobile laser scanning data for automated extraction of road markings</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="93" to="107" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Urban accessibility diagnosis from mobile laser scanning data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Serna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Random forests based multiple classifier system for powerline scene classification</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="253" to="258" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic extraction of Manhattan-world building masses from 3d laser range scans</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Vanegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Aliaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Benes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Vis Comput Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1627" to="1637" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identifying vegetation from laser data in structured outdoor environments</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Wurm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kretzschmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kümmerle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stachniss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot Auton Syst</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="675" to="684" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Creating large-scale city models from 3d-point clouds: a robust approach with hybrid representation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Comput Vis</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="85" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic perception for ground robotics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bajracharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Matthies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mianzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE 8387, unmanned systems technology XIV</title>
		<meeting>SPIE 8387, unmanned systems technology XIV</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">83870</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantizing complex 3d scenes using constrained attribute grammars</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Houllier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tournaire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="33" to="42" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient 3-d scene analysis from streaming data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation</title>
		<meeting>the IEEE international conference on robotics and automation</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2297" to="2304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Contextual classification of lidar data and building object detection in urban areas</title>
		<author>
			<persName><forename type="first">J</forename><surname>Niemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rottensteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Soergel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="152" to="165" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Robotic 3D scan repository</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nüchter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lingemann</surname></persName>
		</author>
		<ptr target="http://kos.informatik.uni-osnabrueck.de/3Dscans/" />
		<imprint>
			<date type="published" when="2011">2011. 2014</date>
		</imprint>
		<respStmt>
			<orgName>Jacobs University Bremen gGmbH and University of Osnabrück</orgName>
		</respStmt>
	</monogr>
	<note>last access: 30 August</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contextual classification with functional max-margin Markov networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vandapel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="975" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Paris-rue-Madame database: a 3d mobile laser scanner dataset for benchmarking urban detection, segmentation and classification methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Serna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Deschaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on pattern recognition applications and methods</title>
		<meeting>the international conference on pattern recognition applications and methods</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="819" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">IQmulus &amp; TerraMobilita contest -analysis of mobile laser scans (MLS) in dense urban environments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paparoditis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Serna</surname></persName>
		</author>
		<ptr target="http://data.ign.fr/benchmarks/UrbanAnalysis/" />
	</analytic>
	<monogr>
		<title level="m">French National Mapping Agency (IGN) and Center for Mathematical Morphology (CMM)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>MINES ParisTech. last access: 30 August</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Describing Paris: automated 3d scene analysis via distinctive low-level geometric features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weinmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jutzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IQmulus workshop on processing large geospatial data</title>
		<meeting>the IQmulus workshop on processing large geospatial data</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Feature relevance assessment for the semantic interpretation of 3d point cloud data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weinmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jutzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="313" to="318" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semantic 3d scene interpretation: a framework combining optimal neighborhood size selection with relevant features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weinmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jutzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="181" to="188" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Airborne lidar feature selection for urban classification using random forests</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chehata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="207" to="212" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Relevance assessment of fullwaveform lidar data for urban area classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bretar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Soergel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Heipke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="71" to="84" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unique signatures of histograms for local surface description</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Stefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision</title>
		<meeting>the European conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="356" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Using spin images for efficient object recognition in cluttered 3d scenes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="433" to="449" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Persistent point feature histograms for 3d point clouds</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on intelligent autonomous systems</title>
		<meeting>the international conference on intelligent autonomous systems</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast Point Feature Histograms (FPFH) for 3d registration</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation</title>
		<meeting>the IEEE international conference on robotics and automation</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="3212" to="3217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Shape distributions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Osada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chazelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dobkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="807" to="832" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Shape distribution features for point cloud analysis -a geometric histogram approach on multiple scales</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blomley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weinmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leitloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jutzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Performance of histogram descriptors for the classification of 3d laser range data in urban environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Steinhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation</title>
		<meeting>the IEEE international conference on robotics and automation</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="4391" to="4398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Nearest neighbour classification on laser point clouds to gain object structures from buildings</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jutzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">XXXVIII-</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Context-driven automated target detection in 3-d data</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pothier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Triscari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Iverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of SPIE</title>
		<imprint>
			<biblScope unit="volume">5426</biblScope>
			<biblScope unit="page" from="133" to="143" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Scale selection for classification of point-sampled 3d surfaces</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Lalonde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Unnikrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vandapel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on 3-D digital imaging and modeling</title>
		<meeting>the international conference on 3-D digital imaging and modeling</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="285" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dimensionality based scale selection in 3d lidar point clouds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demantké</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="97" to="102" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Classification of airborne laser scanning data using JointBoost</title>
		<author>
			<persName><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="124" to="136" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Automated classification of airborne laser scanning point clouds</title>
		<author>
			<persName><forename type="first">C</forename><surname>Waldhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Otepka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pfeifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghuffar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Korzeniowska</surname></persName>
		</author>
		<editor>Koziel S, Leifsson L, Yang XS</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="269" to="292" />
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
	<note>Solving computationally expensive engineering problems</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Compact covariance descriptors in 3d point clouds for object recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sivalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nickolay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Morellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papanikolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation</title>
		<meeting>the IEEE international conference on robotics and automation</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1793" to="1798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Role of dimensionality reduction in segment-based classification of damaged building roofs in airborne laser scanning data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Khoshelham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oude</forename><surname>Elberink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on geographic object based image analysis</title>
		<meeting>the international conference on geographic object based image analysis</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="372" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Conditional random fields for lidar point cloud classification in complex urban areas</title>
		<author>
			<persName><forename type="first">J</forename><surname>Niemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rottensteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Soergel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="263" to="268" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multi-scale feature extraction on point-sampled surfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="289" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Classification and segmentation of terrestrial laser scanner point clouds using local variance information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Belton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lichti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="44" to="49" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Estimating surface normals in noisy point cloud data</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual symposium on computational geometry</title>
		<meeting>the annual symposium on computational geometry</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="322" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">3d terrestrial lidar data classification of complex natural scenes using a multi-scale dimensionality criterion: applications in geomorphology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brodu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="121" to="134" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">3-d scene analysis via sequenced predictions over points and regions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation</title>
		<meeting>the IEEE international conference on robotics and automation</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2609" to="2616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multiple-entity based classification of airborne laser scanning data in urban areas</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oude</forename><surname>Elberink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J Photogramm Remote Sens</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Tree detection in urban regions using aerial lidar and image data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Secord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci Remote Sens Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="196" to="200" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Aerial lidar data classification using AdaBoost</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Lodha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Helmbold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on 3-D digital imaging and modeling</title>
		<meeting>the international conference on 3-D digital imaging and modeling</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="435" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Non-associative Markov networks for 3d point cloud classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shapovalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Velizhev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Barinova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="103" to="108" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Non-associative higherorder Markov networks for point cloud classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taghavi</forename><surname>Namin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision</title>
		<meeting>the European conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="500" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Spatial inference machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shapovalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2985" to="2992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An overview and comparison of smooth labeling methods for land-cover classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Geosci Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4534" to="4545" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Perceptual organization of 3d surface points</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="193" to="198" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Neighborhood systems for airborne laser data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Filin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pfeifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm Eng Remote Sens</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="743" to="755" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Local versus global triangulations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Linsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prautzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of eurographics</title>
		<meeting>eurographics</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="257" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An algorithm for finding best matches in logarithmic expected time</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Finkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Math Softw</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Visualisation and structuring of point clouds</title>
		<author>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Airborne and terrestrial laser scanning</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Maas</surname></persName>
		</editor>
		<meeting><address><addrLine>Dunbeath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Whittles Publishing</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="45" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">An optimal algorithm for approximate nearest neighbor searching in fixed dimensions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Mount</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Netanyahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="891" to="923" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Foundations of multidimensional and metric data structures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>St. Louis, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Fast approximate nearest neighbors with automatic algorithm configuration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Muja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on computer vision theory and applications</title>
		<meeting>the international conference on computer vision theory and applications</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst Tech J</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Trees detection from laser point clouds acquired in dense urban areas by a mobile mapping system</title>
		<author>
			<persName><forename type="first">F</forename><surname>Monnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Soheilian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Ann Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="245" to="250" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Bootstrap methods: another look at the jackknife</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Stat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Decision forests for computer vision and medical image analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
	<note>Advances in computer vision and pattern recognition</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">A streaming framework for seamless building reconstruction from large-scale aerial lidar data</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2759" to="2766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">An integrated on-board laser range sensing system for on-the-way city and road modelling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nashashibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Abuhadrous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ammoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laurgeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int Arch Photogramm Remote Sens Spat Inf Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Stereopolis II: a multi-purpose and multi-sensor 3d mobile mapping system for street visualisation and 3d metrology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paparoditis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Papelard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cannelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Devaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Soheilian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev Fr Photogramm Télédétect</title>
		<imprint>
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">TerraMobilita/ IQmulus urban point cloud classification benchmark</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brédif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Serna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Paparoditis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IQmulus workshop on processing large geospatial data</title>
		<meeting>the IQmulus workshop on processing large geospatial data</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
