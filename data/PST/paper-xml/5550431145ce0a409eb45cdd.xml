<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">From Heuristic Optimization to Dictionary Learning: A Review and Comprehensive Comparison of Image Denoising Algorithms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-06-12">June 12, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Ling</forename><surname>Shao</surname></persName>
							<email>ling.shao@sheffield.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Ruomei</forename><surname>Yan</surname></persName>
							<email>r.yan@sheffield.ac.uk</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Xuelong</forename><surname>Li</surname></persName>
							<email>xuelongli@opt.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Electronic and Information Engineer-ing</orgName>
								<orgName type="institution">Nanjing University of Information Science and Technology</orgName>
								<address>
									<postCode>210044</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronic and Electri-cal Engineering</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<postCode>S1 3JD</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic and Electrical Engineering</orgName>
								<orgName type="institution">Uni-versity of Sheffield</orgName>
								<address>
									<postCode>S1 3JD</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Center for OPTical IMagery Analysis and Learning</orgName>
								<orgName type="department" key="dep2">Xi&apos;an Institute of Optics and Precision Mechanics</orgName>
								<orgName type="laboratory">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">University of Hong Kong Polytechnic</orgName>
								<address>
									<addrLine>Hung Hom</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">From Heuristic Optimization to Dictionary Learning: A Review and Comprehensive Comparison of Image Denoising Algorithms</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-06-12">June 12, 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">155B65D63B563A0226B2286411906D5C</idno>
					<idno type="DOI">10.1109/TCYB.2013.2278548</idno>
					<note type="submission">received January 21, 2013; revised June 15, 2013; accepted August 6, 2013. Date of publication August 29, 2013; date of current version</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adaptive filters</term>
					<term>dictionary learning</term>
					<term>evaluation</term>
					<term>image denoising</term>
					<term>sparse coding</term>
					<term>spatial domain</term>
					<term>survey</term>
					<term>transform domain</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image denoising is a well explored topic in the field of image processing. In the past several decades, the progress made in image denoising has benefited from the improved modeling of natural images. In this paper, we introduce a new taxonomy based on image representations for a better understanding of state-of-the-art image denoising techniques. Within each category, several representative algorithms are selected for evaluation and comparison. The experimental results are discussed and analyzed to determine the overall advantages and disadvantages of each category. In general, the nonlocal methods within each category produce better denoising results than local ones. In addition, methods based on overcomplete representations using learned dictionaries perform better than others. The comprehensive study in this paper would serve as a good reference and stimulate new research ideas in image denoising.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>I MAGE DENOISING is an important research area serving as the actual foundation for many applications, such as object recognition, digital entertainment, and remote sensing imaging. As the number of image sensors per unit area increases, camera devices tend to be more sensitive to noise. Denoising techniques have become a critical step for improving the final visual quality of images <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>.</p><p>Denoising is the process of reconstructing the original image by removing unwanted noise from a corrupted image. It is designed to suppress the noise, while preserving as many image structures and details as possible. The main challenge is to design noise reduction filters that provide a compromise between these two. Suppose that we have such an image formation model as</p><formula xml:id="formula_0">v(x) = u(x) + n(x) x ∈ X, X ⊂ Z 2 (1)</formula><p>where x denotes the 2-D spatial coordinates of pixels in an image, u is the true image, and n indicates the independent additive noise, which we assume is normally distributed with a standard deviation σ and a zero mean. In real camera systems, the noise may come from different sources such as photon noise, thermal noise, and quantization noise. Thermal noise is present in the analog circuitry and follows a zeromean Gaussian distribution. Since it is the most common one encountered in real applications, the additive Gaussian noise is used as the noise model in this paper. Generally, image denoising approaches can be categorized as spatial domain, transform domain, and dictionary learning based according to the image representation. Spatial domain methods include local and nonlocal filters, which exploit the similarities between either pixels or patches in an image. Both transform domain and dictionary learning based methods consider transforming images into other domains, in which similarities of transformed coefficients are employed. The difference between them is that transform domain approaches usually apply fixed basis functions to represent images, but learning-based methods use sparse representations on a redundant dictionary. Spatial domain methods attempt to utilize the correlations, which exist in most natural images <ref type="bibr" target="#b3">[4]</ref>. For a given patch (pixel), a series of candidates will be used in the filtering process. According to the selection of candidates, spatial filters can be categorized as local and nonlocal filters. A filter is considered to be local if the filter support is a spatial neighborhood of the candidate pixel and the filter coefficients are restricted by the spatial distance. A large number of local filtering algorithms have been designed for noise reduction such as Gaussian filter <ref type="bibr" target="#b4">[5]</ref>, Wiener filter <ref type="bibr" target="#b5">[6]</ref>, least mean squares filter <ref type="bibr" target="#b6">[7]</ref>, trained filter (TF) <ref type="bibr" target="#b7">[8]</ref>, bilateral filter <ref type="bibr" target="#b8">[9]</ref>, anisotropic filtering <ref type="bibr" target="#b9">[10]</ref>, steering kernel regression (SKR) 2168-2267 c 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.</p><p>See http://www.ieee.org/publications standards/publications/rights/index.html for more information. <ref type="bibr" target="#b10">[11]</ref>, metric Q for tuning parameters in SKR (MSKR) <ref type="bibr" target="#b11">[12]</ref>, and kernel-based image denoising employing semiparametric regularization (KSPR) <ref type="bibr" target="#b12">[13]</ref>. Local methods are effective in terms of time complexity. However, when the noise level is high, these methods cannot perform very well because the correlations between neighboring pixels have been corrupted by the severe noise. On the contrary, the nonlocal filters make use of the self-similarity of natural images in a nonlocal manner. Nonlocal means (NLM) <ref type="bibr" target="#b13">[14]</ref> obtain a denoised patch by weighted averaging all other patches in the same image.</p><p>Since NLM was proposed, many improvements on it have been developed. Some of them are focused on the acceleration of NLM <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b19">[20]</ref>. Others are adopted for enhancing the denoising performance <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Recently, a considerable amount of research in image denoising has been shifted from local to nonlocal filters <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b26">[27]</ref>. The idea of nonlocal has been expanded to transform domain <ref type="bibr" target="#b27">[28]</ref> and learning-based methods <ref type="bibr" target="#b28">[29]</ref>. Even though they are better than local filters for dealing with high noise levels. The major drawback of nonlocal spatial filters is that they still tend to bring artifacts such as over-smoothing <ref type="bibr" target="#b29">[30]</ref>.</p><p>The second category is transform domain methods. The image patches are represented by the orthonormal basis (e.g., wavelets <ref type="bibr" target="#b30">[31]</ref>, curvelets <ref type="bibr" target="#b31">[32]</ref>, contourlets <ref type="bibr" target="#b32">[33]</ref>, and bandelets <ref type="bibr" target="#b33">[34]</ref>) with a series of coefficients. The smaller coefficients are the high frequency part of the input image which are related to image details and noise. After the smaller coefficients are adjusted, the reconstructed image could have less noise. In this paper, wavelet-based denoising methods are discussed as an instance due to its popularity <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref>. Wavelet-based methods achieve better performance <ref type="bibr" target="#b37">[38]</ref> compared to spatial domain methods, because they have superior properties such as sparsity and multiresolution <ref type="bibr" target="#b38">[39]</ref>. However, the intrascale and interscale correlations of the wavelet coefficients have not been fully explored.</p><p>As an emerging machine learning technique, sparse representations have become a trend and are used for restoration problems <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>. The general idea of dictionary learning based methods in this paper is that they perform denoising by learning a large group of patches from an image dataset such that each patch in the estimated image can be expressed as a linear combination of only few patches from this redundant dictionary. Representative dictionary learning based methods are the K-clustering with singular value decomposition (K-SVD) <ref type="bibr" target="#b41">[42]</ref>, learned simultaneous sparse coding (LSSC) <ref type="bibr" target="#b28">[29]</ref>, and clustering-based sparse representation (CSR) <ref type="bibr" target="#b42">[43]</ref>. Although most of the dictionary learning based methods have achieved competitive performance compared to the stateof-the-art, the sparse model is computationally expensive <ref type="bibr" target="#b43">[44]</ref>.</p><p>Vladimir et al. <ref type="bibr" target="#b44">[45]</ref> classified denoising filters according to local/nonlocal and pointwise/multipoint. In this paper, a novel taxonomy of the denoising methods has been proposed, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Learning-based approaches have been introduced, which is the progress made in the past several years in denoising <ref type="bibr" target="#b43">[44]</ref>. Furthermore, the comprehensive analysis, comparative evaluation of prevailing classical methods, and recent promising techniques will serve as a good reference and provide insights for future research in denoising. The reasons for choosing a method are either that it is representative within a category or it is the best version in the variants of a popular method.</p><p>The remainder of this paper is organized as follows. Section II reviews spatial domain methods. Section III summarizes recent transform domain techniques. Dictionary learningbased approaches are presented in Section IV. To compare the performance of different denoising methods, we evaluate them in Section V both quantitatively and qualitatively. Finally, the conclusion is drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Spatial Domain Methods</head><p>Spatial domain filters exploit spatial correlations in images. In this paper, the spatial filters are classified into two categories: local and nonlocal filters. A filter is local if the candidate selection process used for filtering is restricted by the spatial distance. A filter is nonlocal if the candidate selection depends only on the similarity and is not restricted by the spatial distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Local Filters</head><p>Since the Gaussian filter <ref type="bibr" target="#b4">[5]</ref> was applied to image denoising, many local filters have been proposed to improve it and provide better edge-preserve ability. The anisotropic filter <ref type="bibr" target="#b45">[46]</ref> was designed to avoid the blurring effect of Gaussian by smoothing the image only in the direction that is orthogonal to the gradient direction. The method in <ref type="bibr" target="#b46">[47]</ref> utilizes the total variation minimization technique to smooth the homogenous regions of the image but not its edges. Similarly, for better edge preserving, the smallest univalue segment assimilating nucleus (SUSAN) filter can average all pixels in the local neighborhood which are from the same spatial region as the central pixel <ref type="bibr" target="#b47">[48]</ref>. In contrast to the above parametric methods, SKR <ref type="bibr" target="#b10">[11]</ref> adapts and expands the kernel regression idea to denoising for removing artifacts. The intuition for developing SKR is: if a pixel is located near an edge, pixels on the same side of the edge will have much stronger influence on the filtering of this pixel than those on the other side of the edge. The recent local filters that produce impressive results are mostly nonparametric or semiparametric. They are summarized as follows.</p><p>TF: similar to the idea of early local filters <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b47">[48]</ref>, a weighted averaging scheme is adopted to perform image denoising in the trained filter <ref type="bibr" target="#b7">[8]</ref>. The difference is that the trained filter adopts the nonparametric process in which the weights are obtained from the offline training on a large number of images. In the training step, the classification process ensures best adaptation for local image patterns by changing fixed kernel coefficients into trained coefficients. The classification is based on adaptive dynamic range coding (ADRC), in which image patterns are encoded as class indexes. In the filtering process, the same classification is applied to each input noisy aperture, and accordingly filter coefficients are obtained from a look-up table (LUT) stored in the previous training process.</p><p>The advantage of the trained filter is that the training process is offline and the LUT only has to be trained once. Thus, the filtering process is so efficient that it can be used in real-time denoising applications. The framework is also applicable to other image enhancement tasks, for example, coding artifact reduction. Moreover, it improves the adaptivity of the local neighborhood filtering by exploring the sparsity in the dataset, which is similar to the learning-based denoising methods. The disadvantage of this method is that ADRC is very vulnerable to severe image degradations (e.g., high noise levels), and same ADRC codes sometimes cannot properly represent same patch textures.</p><p>MSKR: the aim of the MSKR is to improve SKR from the perspective of parameter selections by maximizing the metric Q. The process of the tuning is as follows.</p><p>1) The anisotropic patch set of the input noisy image is first detected and serves as the input of the metric Q calculation.</p><p>2) The maximization of the metric Q is iteratively carried out and the denoised image also acts as the input of the metric Q calculation.</p><p>3) The parameters in SKR are adjusted according to the results of the metric Q optimization. A no-reference image content metric Q, based on singular value decomposition (SVD) of the local image gradient matrix, was proposed in <ref type="bibr" target="#b11">[12]</ref> </p><formula xml:id="formula_1">Q = s 1 s 1 -s 2 s 1 + s 2 .</formula><p>Here, s 1 and s 2 are dominant singular values acquired from the singular value decomposition of the gradient matrix G.</p><p>For a noisy image patch, the estimated values ŝ1 and ŝ2 can be approximately calculated as <ref type="bibr" target="#b11">[12]</ref> ŝ1</p><formula xml:id="formula_2">≈ s 2 1 + ξNσ 2 ŝ2 ≈ s 2 2 + ξNσ 2 (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where N is the number of patches in the noisy image, ξ is the parameter for choosing which filter to use, and σ 2 is the local noise variance. The new metric can provide a better measure of the image content compared to previous no-reference metrics such as the Stein's unbiased risk estimate (SURE) and the cross-validation.</p><p>This approach has several advantages such as: 1) it has low complexity; 2) it works well when the noise is not Gaussian <ref type="bibr" target="#b11">[12]</ref>; and 3) the SVD is more robust in the presence of noise compared to most features for noisy images, which is important for image noise level estimation because it can be used as a good texture strength measure <ref type="bibr" target="#b48">[49]</ref>. The limitation of this algorithm is: it cannot handle images with too many homogeneous regions very well, because the metric Q is only sensitive to structured regions.</p><p>KSPR: the main idea of this method is to transfer the model between the noisy and its corresponding clean image into a reproducing kernel Hilbert space (RKHS) <ref type="bibr" target="#b12">[13]</ref>. In this space, the noise-free image can be modeled as a linear combination of the reproducing kernels, which is different from the kernels in SKR (weights in the Taylor approximation). In this model, a property of RKHS, called representer theorem, has been explored. Meanwhile, a semiparametric variant of the representer theorem has been used to learn the edge models. Thus, the modeling in this algorithm is a L 1 norm optimization problem, with a set of basis functions to model the edge adaptively. The insight of this method is that different regions in an image should be represented by different kernels. In homogenous regions, higher weights are assigned for kernel smoothing. However, in texture regions, the sparse representation based on the basis functions is applied to edges. To distinguish different regions, images are segmented in the preprocessing stage through the mean gradient in each region.</p><p>This method can be applied to different additive noise models, especially the impulse noise. The semiparametric formulation enables the method's good edge-preserving ability. However, when the noise model is additive Gaussian, the denoising result is worse than that of the state-of-the-art methods. Moreover, the mean gradient is not very reliable for measuring the smoothness in the presence of noise, especially Gaussian noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Nonlocal Filters</head><p>Representative nonlocal filters <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b25">[26]</ref> make use of the weighted averaging idea in a nonlocal manner. In <ref type="bibr" target="#b22">[23]</ref>, Lebesgue's perspective was proposed to improve Gaussian and median filters. The weights of the filter are determined by the patches whose pixel values are similar to target patches. Kervrann et al. <ref type="bibr" target="#b23">[24]</ref> proposed a neighborhood filter, which is similar to NLM but the weights are determined by the intensity difference of patches. Similar patches are identified not only from spatial distances but also through different orientations and scales in <ref type="bibr" target="#b24">[25]</ref> and <ref type="bibr" target="#b25">[26]</ref>.</p><p>The original NLM was proposed in <ref type="bibr" target="#b13">[14]</ref>, and many improvements on NLM have been developed afterward.</p><p>1) Acceleration: From the perspective of refining candidate patches, preselection of contributing neighborhoods by calculating mean and gradient values was proposed to accelerate NLM <ref type="bibr" target="#b14">[15]</ref>. Similarly, local variance <ref type="bibr" target="#b15">[16]</ref> and SVD <ref type="bibr" target="#b16">[17]</ref> were introduced to eliminate dissimilar pixels. Fast Fourier transform was used to accelerate the weight calculation <ref type="bibr" target="#b17">[18]</ref>, which makes the algorithm 50 times faster than the original one. The method in <ref type="bibr" target="#b18">[19]</ref> (INLM) exploits the symmetry in the weight function, and computes the Euclidean distance by a recursive moving average filter symmetrically, which also considerably improves the efficiency of NLM. Pang et al. <ref type="bibr" target="#b19">[20]</ref> utilized several critical pixels in the center instead of all pixels in the neighborhood.</p><p>2) Improvement of Quantitative and Qualitative Results: Tuning the smoothing parameters was proposed in <ref type="bibr" target="#b15">[16]</ref>. In <ref type="bibr" target="#b20">[21]</ref>, a family of nonlocal image smoothing algorithms were designed, which approximate the application of diffusion partial differential equations on a specific Euclidean space of image patches. In order to increase the number of candidates for target patches, Sven et al. <ref type="bibr" target="#b21">[22]</ref> designed a rotationally invariant block-matching for NLM. In this section, the original NLM and one of the best variants of NLM are outlined as follows.</p><p>NLM: the idea of NLM is based on the assumption that every patch in an image has many similar patches within the same image <ref type="bibr" target="#b13">[14]</ref>. Given a noisy image v = {v i |i∈ }, ⊂ R 2 , the restored intensity of the pixel ûi is a weighted average of all intensity values within the neighborhood I in the noisy image ûi = j∈I w(i, j)v j .</p><p>(</p><p>The weights can be calculated by <ref type="bibr" target="#b13">[14]</ref> w</p><formula xml:id="formula_5">(i, j) = 1 Z(i) exp - v N i -v N j 2 2,a h 2<label>(4)</label></formula><p>where N i denotes a patch of fixed size and it is centered</p><formula xml:id="formula_6">at pixel i. The similarity v N i -v N j 2</formula><p>2,a is measured as a decreasing function of the weighted Euclidean distance. a &gt; 0 is the standard deviation of the Gaussian kernel, Z(i) is the normalization constant with Z(i) = j w(i, j), and h acts as a filtering parameter.</p><p>NLM is the first filter that considers the self-similarity in the entire image. It is an extension of the bilateral filter by the means of replacing the Euclidean distance between two pixels with the weighted Euclidean distance between two patches. The nonlocal means filer is also a variation of the neighborhood filter <ref type="bibr" target="#b23">[24]</ref>. It substitutes the Euclidean distance in the weight function with a Gaussian, as shown in <ref type="bibr" target="#b3">(4)</ref>. The flip side of NLM is: when the noisy image is short of similar patches within itself, it produces severe artifacts and the performance degrades dramatically, which can be observed in Table <ref type="table" target="#tab_1">II</ref>.</p><p>INLM: Goossens et al. <ref type="bibr" target="#b18">[19]</ref> improved the original NLM in four aspects.</p><p>1) They proposed to record the noise variance at every location in the image and use a postprocessing routine to remove the extra noise after the main steps.</p><p>2) The whole algorithm is iterative, which assumes that the later iterations could have better grouping results based on the preprocessed results.</p><p>3) The Euclidean distance is replaced by the bisquare robust function, which has improved the similarity term. 4) This INLM algorithm is also applicable to remove noise in color images. Weight calculation is very important in NLM. As it is compared in <ref type="bibr" target="#b18">[19]</ref>, modified bisquare is the most robust loss function. The drawback of this method is that the postprocessing local filter tends to blur details though it is effective for removing extra noise.</p><p>Discussions on spatial domain methods: Spatial domain methods discussed above can be considered the variants of the Gaussian filter. Modeling the statistics of natural images as Gaussian distribution is problematic <ref type="bibr" target="#b49">[50]</ref> because the local image structures cannot be well described by Gaussian. This results in two deficiencies in the Gaussian filter: 1) the filtering weights are not adaptive enough to the image contents, and 2) the edges are usually oversmoothed in the denoised images. On the one hand, in order to obtain adaptive weights for a linear filter, TF learns individual weights for various image patches, whose structures are coded by ADRC and saved in an LUT. NLM and INLM exploit the image self-similarity to assign adaptive weights for every patch in the image. On the other hand, SKR and MSKR avoid the denoising artifacts by circumventing the edges when filtering the image. KSPR applies different filters to homogeneous regions and texture regions, which has improved the results of SKR and MSKR.</p><p>Local filers can preserve edges well but they rely too much on the texture classification methods (ADRC in TF, the mean gradient in KSPR). Nonlocal filters can achieve better denoising results most of the time except when the image selfsimilarity assumption fails.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Transform Domain Methods</head><p>Transform domain methods have been researched in the context of image denoising for decades <ref type="bibr" target="#b50">[51]</ref>. Although there are a large number of variations in this category, such as discrete cosine transform (DCT), wavelets <ref type="bibr" target="#b50">[51]</ref>, wedgelets <ref type="bibr" target="#b51">[52]</ref>, curvelets <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref>, bandlets <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b54">[55]</ref>, contourlets <ref type="bibr" target="#b55">[56]</ref>, and steerable wavelets <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref>, wavelets based methods are still dominant.</p><p>The wavelets <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b59">[60]</ref> had a strong impact on noise reduction problems. Denoising methods based on wavelets usually transform the image content into multiple subbands at different orientations and resolution scales. Large coefficients represent the important low-frequency information. Noise and details exist in the high-frequency subbands. Thus, thresholding and various filters can be applied to the small coefficients. Finally, the image is reconstructed by inverse transforming these wavelet coefficients back to the spatial domain. Many different kinds of wavelet thresholding methods have been proposed, for example, SureShrink <ref type="bibr" target="#b60">[61]</ref> and VisuShrink <ref type="bibr" target="#b61">[62]</ref>. The interscale and intrascale correlations of the wavelet coefficients have been considered in a few state-of-the-art denoising methods, which are introduced as follows.</p><p>BLS-GSM: Since critically sampled <ref type="bibr" target="#b34">[35]</ref> wavelet coefficients may cause disturbing visual artifacts, overcomplete wavelets are exploited in the Bayes least squares-Gaussian scale mixture (BLS-GSM) to improve this. The intuition of this method is: the neighborhoods of coefficients at adjacent positions and scales are modeled as the Gaussian scale mixture. The wavelet coefficients are updated by the Bayesian leastsquares estimation. The procedure for denoising is as follows.</p><p>1) The noisy image is transformed into the wavelet domain.</p><p>2) It is assumed that the Gaussian scale mixture model can be applied to each local neighborhood <ref type="bibr" target="#b34">[35]</ref> </p><formula xml:id="formula_7">v = √ zu + n (5)</formula><p>where v is a neighborhood of observed coefficients of the pyramid representation, √ z is an independent positive scalar random variable, and u and n are zero-mean Gaussian vectors. Based on this model, the center of the neighborhood can be estimated as <ref type="bibr" target="#b34">[35]</ref> </p><formula xml:id="formula_8">E(u c |y) = ∞ 0 p(z|v)E(u c |v, z)dz (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where E(u c |v, z) is the local Wiener estimate and p(z|v) is the posterior density.</p><p>3) The last step is to transform the denoised wavelet subbands into the spatial domain. The main contributions of this method are two-fold. First, the full optimal local Bayesian least-squares solution is computed for estimating coefficients. Second, the vectorial form of the linear least squares is exploited to take full advantage of the information provided by the covariance modeling of the signal and noise.</p><p>On the one hand, the pyramidal representation in the local model for spatial neighbors makes this algorithm efficient. On the other hand, BLS-GSM requires an accurate estimation of the original power spectrum density, which makes this algorithm not adaptive <ref type="bibr" target="#b62">[63]</ref>.</p><p>BM3D: inspired by the nonlocal grouping in NLM (the image self-similarity) and the redundant representation in BLS-GSM (the interscale and intrascale correlations of the wavelet coefficients), Dabov et al. <ref type="bibr" target="#b27">[28]</ref> proposed a blockmatching and 3-D filtering method that achieves remarkable performance. BM, which refers to block-matching, is the process that separates the 2-D noisy image patches into the 3-D data groups, in which group patches have similar local structures. 3-D refers to the 3-D transform, which includes the 2-D transform (DCT, DFT, or periodized wavelets) within a group and the 1-D transform (Haar wavelets) across groups. BM3D is realized by two steps. In each step, the 3-D transformation of groups, the shrinkage of the transform spectrum, and the inverse 3-D transformation are sequentially performed. The difference between these two steps lies in the ways of shrinking the transform spectrum. In the first step, it is hard thresholding, and in the second Wiener filtering. In each step, the aggregation is performed as a weighted averaging filter to fuse the multiple estimates of each patch.</p><p>In NLM, better weighted averaging results can be achieved if more reliable candidates for the target patch can be found (the size of the similar patch group is larger) <ref type="bibr" target="#b16">[17]</ref>. BM3D expands such 2-D self-similarity by exploiting the sparsity between grouped patches. This guarantees sufficient reliable candidates for the target patch. However, when there are unique patches, which have few similar patches in the image, BM3D produces suboptimal results. Also, the wavelet transform has the advantage that noise reduction can be applied to different subbands, which enables adaptive denoising for spatially localized details.</p><p>Exploiting the similarity of overlapping patches and the correlation of wavelet coefficients makes BM3D one of the dominant denoising methods. It is proved in <ref type="bibr" target="#b63">[64]</ref> that BM3D is approaching optimality when the noise level is not very high. When the noise level is above 40, the denoising performance has a very sharp drop due to the ineffective patch grouping. Although there is a prefiltering technique in BM3D, it cannot improve the grouping. This can cause insufficient redundancy in a patch group, which has been considered by other learningbased methods. Meanwhile, the DCT transform will unavoidably cause periodic artifacts because the fixed basis functions of an image representation are not adaptive enough for all kinds of natural images.</p><p>LPG-PCA: to overcome the drawbacks of the fixed basis functions, the principal component analysis (PCA) was employed in <ref type="bibr" target="#b36">[37]</ref> to build adaptive basis functions. In this LPG-PCA framework, each pixel and its nearest neighbors in a noisy image are locally grouped (block-matching) into a vector variable. Then, the vector is PCA transformed and in the PCA domain the noise can be removed by shrinkage. The same procedure is repeated in the second stage, which boosts the performance.</p><p>The frameworks of LPG-PCA and BM3D are similar. The differences are as follows.</p><p>1) The basis functions of the image representations are different. The fixed basis functions (DCT or wavelets) are used in BM3D, which are less adapted to the local geometry of the image to process. LPG-PCA relies on locally data-adaptive basis functions. Therefore, it outperforms BM3D by better preserving fine-grain edges, which are prone to have incorrect nonlocal information in BM3D. 2) In BM3D, the second stage has the 3-D groups built with the original noisy image patches using the patch distances from the filtered image in the first round.</p><p>In LPG-PCA, the input of the second stage is filtered patches from the first stage, and the operations are entirely the same except that the noise levels are different. This actually is not very ideal because the denoising for the first stage might contain errors, i.e., grouping errors due to the noise. The denoising applied on the errors would decay the final denoising accuracy.</p><p>Discussion on transform domain methods: Several properties of wavelets have made it the most popular method for transformation <ref type="bibr" target="#b38">[39]</ref>. 1) Multiresolution: different subbands contain different information, for instance, low frequency or high frequency information. This allows different operations on different subbands to have better precision. 2) Sparsity: due to the multiresolution characteristic, most of the wavelet coefficients are small and only the lowfrequency parts remain large. 3) Edge detection: large wavelet coefficients usually locate at low-frequency subbands and they contain the most important information (e.g., image edges <ref type="bibr" target="#b38">[39]</ref>).</p><p>Since <ref type="bibr" target="#b60">[61]</ref> and <ref type="bibr" target="#b61">[62]</ref>, wavelet domain denoising has become prevalent in the light of the above advantages of wavelet transforms <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b59">[60]</ref>. However, transform domain methods also have shortcomings. For instance, DCT is not effective in representing sharp transitions or singularities, and wavelets cannot represent smooth transitions very well. Since the basis functions for most transform domain methods are fixed, they have difficulties in characterizing natural images with various patterns. Furthermore, the number of coefficients used to represent a image patch is equal to the pixel number of this patch, which tends to result in artifacts such as the ringing artifact. So a redundant dictionary is important for coping with the deficiency of wavelets. For instance, BLS-GSM outperforms previous methods by the redundant dictionary in local spatial neighborhoods. Furthermore, BM3D aims at exploring more redundancy by not just redundancy in the transform domain but also nonlocal grouping in the spatial domain, which accomplishes brilliant denoising results. However, when the nonlocal image selfsimilarity assumption cannot be guaranteed well, denoising artifacts are unavoidable. In such cases, transforms such as PCA are better choices because they are adaptive to local structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Dictionary Learning-Based Methods</head><p>Since sparse modeling was proposed by Olshausen and Field <ref type="bibr" target="#b64">[65]</ref>, training an overcomplete dictionary for the patch representation has been extensively explored in many research fields <ref type="bibr" target="#b65">[66]</ref>- <ref type="bibr" target="#b69">[70]</ref>. In the past decade, it has been successfully applied to denoising problems <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b70">[71]</ref>. K-SVD <ref type="bibr" target="#b41">[42]</ref> achieves good denoising results by adaptive learning of a dictionary. Each patch can be represented by a series of patches from the dictionary. Rather than learning a single dictionary for the entire image in KSVD, classification based on the SKR is exploited in order to avoid patches with different structures being considered similar patches in locally learned dictionaries (K-LLD) <ref type="bibr" target="#b71">[72]</ref>. Recently, a structured dictionary learning method (LSSC) has been proposed by Mairal et al. <ref type="bibr" target="#b28">[29]</ref>. The dictionary learning part exploits the local sparsity within a neighborhood, and the NLM framework makes use of the nonlocal sparsity. It is observed in <ref type="bibr" target="#b44">[45]</ref> that nonlocal methods obtain better results than local methods. LSSC <ref type="bibr" target="#b28">[29]</ref> merges a better representation with the nonlocal framework, and therefore it is slightly superior to the state-ofthe-art methods such as BM3D under certain noise levels (as shown in the experiment section). The other similar framework was presented by Dong et al. <ref type="bibr" target="#b42">[43]</ref> for incorporating dictionary learning and sparse codes clustering, which in some cases achieves even better results than LSSC <ref type="bibr" target="#b28">[29]</ref>. The recent dictionary learning based methods are described as follows.</p><p>K-SVD: Early dictionary learning methods have the limitation that they cannot handle images of arbitrary sizes. Similar to the BLS-GSM, Elad et al. <ref type="bibr" target="#b41">[42]</ref> embedded the local overcomplete dictionary into a global Bayesian estimator. Compared to previous image priors, image examples (dictionaries) are better because they are more adaptive to natural images.</p><p>The optimization process of K-SVD is iterative, and within each iteration there are two parts.</p><p>1) Sparse coding step: the initial dictionary is used for computing sparse approximations of all patches. The optimization process <ref type="bibr" target="#b41">[42]</ref> is as follows:</p><formula xml:id="formula_10">min α i ∈R k α i 0 s.t. v i -Dα 2 2 ≤ ε (7)</formula><p>where α i denotes the sparse representation code for each patch v i ∈ R m , and D ∈ R m×k is the current dictionary; 2) Dictionary update: in this step the dictionary is updated to increase the quality of the sparse approximation. For an image, a dictionary adapted to the overlapping patches is learned by min</p><formula xml:id="formula_11">D∈C,A α i 0 s.t. v i -Dα i 2 2 ≤ ε (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where C is the set of matrices in R m×k with unit l 2 -norm columns, and</p><formula xml:id="formula_13">A = [α 1 , ..., α n ] is a matrix in R k×n .</formula><p>Once, the dictionary is optimized, the output image û can be updated as <ref type="bibr" target="#b41">[42]</ref>.</p><p>K-SVD successfully introduced the idea of example learning into the denoising field, which updates the image representation with a more adaptive model. For a single patch, several similar dictionary atoms could be used for its reconstruction and they will be updated with the information from the noisy image during the approximation process. However, the dictionary used in this method is still unstructured and it requires a considerable number of computations. Due to this computational burden, it is not very likely to use KSVD for large patches in the denoising process (the size of the dictionary is very limited).</p><p>LSSC: although K-SVD builds a redundant dictionary for patch representation, the searching within the dictionary is not very reliable because even a slight change in the input patch might lead to very different dictionary atoms, which is not desirable. Mairal et al. <ref type="bibr" target="#b28">[29]</ref> proposed a novel improvement to K-SVD by a combination of the NLM framework and modified sparse coding. Considering that similar patches in an image should have similar sparse decompositions, introducing the NLM framework into sparse coding would significantly speed up the process of searching for candidate atoms in an unstructured dictionary. The simultaneous sparse coding can be formulated as <ref type="bibr" target="#b28">[29]</ref> min</p><formula xml:id="formula_14">(A i ) n i=1 ,D∈C n i=1 A i p,q |S i | p s.t. ∀i j∈S i v j -Dα ij 2 2 ≤ ε i (<label>9</label></formula><formula xml:id="formula_15">)</formula><p>where S i represents the clusters after k-means clustering, each of which contains similar patches. D is updated while the denoised image is estimated.</p><formula xml:id="formula_16">A i = [α i j] j∈S i ∈ R k×|S i | .</formula><p>This clustering before sparse coding significantly speeds up the whole algorithm, and it guarantees that each patch in the current image can exploit the sparsity in the cluster or the training dataset. The output of each denoised pixel is calculated as a weighted average in each cluster</p><formula xml:id="formula_17">û = diag( n i=1 j∈S i R j 1 m ) -1 n i=1 j∈S i R j Dα ij (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>where R j in R m×n is the binary matrix that places patch number i at its proper position in the image. 1 m is a vector composed of ones and its size is m. LSSC slightly outperforms BM3D by exploiting adaptive basis functions for image representation. It can solve the issue that the unique patches in an image cannot have proper grouping. It also achieves better results compared to K-SVD because: 1) LSSC includes a patch clustering process, which exploits the sparsity from the image self-similarity, and 2) only l 0 norm is used in both the learning and reconstruction processes. This method has been applied to other restoration applications such as image deblurring <ref type="bibr" target="#b72">[73]</ref>, which indicates the general applicability of this sparse coding model. However, LSSC still has the similar unstructured dictionary as K-SVD, which is very prone to the reconstruction artifacts.</p><p>CSR: it <ref type="bibr" target="#b42">[43]</ref> was designed to connect dictionary learning (e.g., K-SVD) with structural clustering (e.g., BM3D) to exploit two kinds of sparsity. The sparse codes are encoded with respect to the average, which builds up an connection between clustering and sparsity. The optimization process can be described as <ref type="bibr" target="#b42">[43]</ref> </p><formula xml:id="formula_19">A = arg min A 1 2 v -DA 2 2 + λ 1 A 1 +λ 2 K k=1 i∈C k α i -β k (<label>11</label></formula><formula xml:id="formula_20">)</formula><p>where A is the sparse matrix, β denotes sparse coefficients for the centroid vectors, v is the noisy image, and D is the learned redundant dictionary. K is the number of the clusters, and C k is the number of elements in each cluster. The first difference between CSR and LSSC is that CSR does not need any initial dictionary (K-SVD adopts DCT as the initial dictionary, LSSC uses a learned dictionary from a dataset as the initial dictionary). The pure online training process is performed on the input noisy image and the dictionary is updated by k-means clustering and PCA. The second difference between CSR and LSSC is: l 1 norm is used in CSR to characterize nonlocal sparsity rather than l 2 norm.</p><p>Discussions on dictionary learning-based methods: overcomplete dictionaries learned from clean or noisy image patches provide adaptive representations for image denoising. Earlier sparse coding based methods (e.g., K-SVD) search for the optimal decomposition of a patch in the whole dictionary while updating the dictionary with the information from the input. Although most of them <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b71">[72]</ref> managed to achieve satisfactory denoising results, they have a disadvantage that similar patches might have very different sparse decompositions <ref type="bibr" target="#b41">[42]</ref>. LSSC improves this situation by applying clustering in sparse decompositions. However, its performance largely depends on the initial dictionary trained offline on high quality images and the nonlocal grouping results. Later, CSR uses a similar framework but reduces the computational complexity significantly.</p><p>One major shortcoming of this whole category is the computational complexity. First, these algorithms always undergo several denoising iterations. For example, l 0 norm related optimization is nondeterministic polynomial-time hard. Second, their dictionaries are unstructured, which further causes a computational burden <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b70">[71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Performance Comparison of Representative Image Denoising Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Image Database</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Source Image Content:</head><p>The image database was derived from a set of source images that reflects adequate diversity in complexity of image content. These images include pictures of human faces, natural scenes, and man-made objects. Most of them are extensively used by researchers in the field of image denoising. The first dataset (200 images) we use is the Berkeley segmentation dataset. <ref type="foot" target="#foot_0">1</ref> The resolution of these images is either 481 × 321 or 321 × 481. The other dataset we employ contain the standard test images<ref type="foot" target="#foot_1">2</ref> as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. The size of these images is either 512 × 512 or 256 × 256. Moreover, some large images are selected from flickr <ref type="foot" target="#foot_2">3</ref> to test the scalability of all the algorithms. Typically, we used test images with the resolution of 2048 × 1361, 721 × 1024, and 800 × 600.</p><p>2) Image Degradation Model: Additive white Gaussian noise with standard deviations σ = 10, 20, 25, 35, 75 was added to the testing images (We cannot show the full results here due to the space limit). Figs. <ref type="figure" target="#fig_2">3(b</ref>) and 4(b) illustrate the distortion on an image after adding Gaussian noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Test Methodology and Discussion</head><p>In this section, several criteria have been used to compare the above methods: peak signal-to-noise ratio (PSNR) (mathematical distance formulations), the structural similarity (SSIM) <ref type="bibr" target="#b73">[74]</ref> (strucutural), visual information fidelity (VIF) <ref type="bibr" target="#b74">[75]</ref>, and visual quality of the reconstructed images.</p><p>The algorithms are selected to provide a comprehensive comparison among different categories. From the spatial filters, TF <ref type="bibr" target="#b7">[8]</ref>, MSKR <ref type="bibr" target="#b11">[12]</ref>, KSPR <ref type="bibr" target="#b12">[13]</ref>, NLM <ref type="bibr" target="#b13">[14]</ref>, and INLM <ref type="bibr" target="#b18">[19]</ref> are chosen. Among transform domain methods, BM3D <ref type="bibr" target="#b27">[28]</ref>, BLS-GSM <ref type="bibr" target="#b34">[35]</ref>, and LPG-PCA <ref type="bibr" target="#b36">[37]</ref> are included. In the dictionary learning based category, we select K-SVD <ref type="bibr" target="#b41">[42]</ref>, LSSC <ref type="bibr" target="#b28">[29]</ref>, and CSR <ref type="bibr" target="#b42">[43]</ref>. The implementations by the respective authors are used for all experiments. However, as all the codes are written in MATLAB and run very slowly, we revised the main denoising functions into C and compiled them (MSKR, NLM, CSR) into Mex functions. This helps the later time complexity comparison in the following section.</p><p>1) Quantitative Comparison-PSNR and SSIM Comparisons: PSNR is employed to provide quantitative evaluations of the denoising results. PSNR is defined as</p><formula xml:id="formula_21">PSNR = 10 log 10 ( L 2 MSE ) (<label>12</label></formula><formula xml:id="formula_22">)</formula><p>where L is the dynamic range of the image and MSE is the mean squared error between the original and the reconstructed image. SSIM <ref type="bibr" target="#b73">[74]</ref> is a quality metric more correlated to human perception. SSIM is calculated within local windows using 2 are constants to avoid instability when μ x 2 + μ y 2 or σ x 2 + σ y 2 is too close to zero <ref type="bibr" target="#b73">[74]</ref>. L is the dynamic range of the intensity values, and K 1 1, K 2 1 are small constants. μ x and μ y are the mean intensities. σ x and σ y are standard deviations.</p><formula xml:id="formula_23">SSIM(x, y) = (2μ x μ y + C 1 )(2σ xy + C 2 ) (μ 2 x + μ 2 y + C 1 )(σ 2 x + σ 2 y + C 2 ) . (<label>13</label></formula><formula xml:id="formula_24">)</formula><formula xml:id="formula_25">C 1 = (K 1 L) 2 , C 2 = (K 2 L)</formula><p>All methods have been tested with the optimum parameters mentioned in the original papers. From the quantitative results, one can see that, in the spatial domain, the overcomplete kernel based method (KSPR) outperforms the other local filters in high noise levels. One can also see that image self-similarity is a sparse model for most natural images, which makes nonlocal methods perform better than local counterparts. When the image contains enough self-similarity (e.g., squares), NLM can be comparable to BM3D and the dictionary learningbased techniques. However, when the standard deviation of the Gaussian noise is high, the performance of NLM drops dramatically due to the difficulty of utilizing self-similarity. The preprocessing in INLM overcomes this drawback, and INLM is the best performing one among the spatial domain methods. In the wavelet domain, BLS-GSM adopts overcomplete wavelets and improves over the critically sampled wavelet method (e.g., SURE-LET). BM3D employs not only overcomplete basis functions but also nonlocal grouping, which contributes to their better performance. LPG-PCA tends to generate better results than BLS-GSM when the noise level is low, for instance, 20, and when the image contains many repetitive patterns (e.g., squares). This is due to the fact that the nonlocal clustering requires the structures in an image not totally corrupted. BLS-GSM outperforms LPG-PCA in high noise levels because the multiresolution structures in wavelets are still functioning. In the dictionary learning-based category, the nonlocal grouping and the redundant, adaptive dictionary in LSSC make it the best performing method, and slightly outperform BM3D. K-SVD is inferior to LSSC because its dictionary is a global model and the sparsity in the image itself is not adopted. At almost all noise levels, CSR is better than BM3D when the image contains many repetitive patterns. This is because the iterations in CSR yield better grouping on the previous denoised images.</p><p>The results of SSIM (shown in Table <ref type="table" target="#tab_1">II</ref>) are mostly consistent with those of PSNR (shown in Table <ref type="table" target="#tab_1">II</ref>). However, there is an exception that: the SSIM of the denoising results from spatial filters drops more dramatically than PSNR in high noise levels.</p><p>Summary: from the above results, several conclusions can be drawn as follows.</p><p>1) Nonlocal methods are better than local methods in quantitative results because image self-similarity is more helpful to average out the additive Gaussian noise compared to local kernels or polynomial approximations (NLM outperforms local methods). 2) Adaptive basis functions in a transform are better than the fixed basis for representing an image (LSSC sometimes outperforms BM3D). 3) Multiresolution representations are better than single resolution ones (BM3D is better than LPG-PCA in most cases). 4) Overcomplete image models are better (KSPR is better than MSKR at high noise levels). 5) The combination of 1, 2, 3 makes the state-of-the-art algorithms (LSSC, CSR, BM3D). These conclusions we obtain are inline with the previous qualitative analysis in Section IV.</p><p>As is mentioned in <ref type="bibr" target="#b75">[76]</ref>, good quantitative results do not guarantee good visual quality of the reconstructed images. So in real applications, the visual quality is still an important metric.</p><p>2) Subjectively Quality Comparison: VIF is an information fidelity criterion that quantifies the Shannon information which is shared between the reference and distorted images because this image information is an aspect of fidelity that correlates well with visual quality. The whole VIF is built on natural scenes statistics, distortion, and human visual system modeling <ref type="bibr" target="#b74">[75]</ref>. As is shown in Sheikh's evaluation work <ref type="bibr" target="#b76">[77]</ref>, VIF performs the best among all the image quality metrics</p><formula xml:id="formula_26">VIF = j∈subbands I( -→ C N,j ; -→ F N,j |s N,j ) j∈subbands I( -→ C N,j ; -→ E N,j |s N,j )<label>(14)</label></formula><p>where -→ C N,j represent N elements of the random field that describes the coefficients from subband j.</p><p>-→ E N,j and -→ F N,j denote the visual signal at the output of the human visual system model from the reference and the test images, respectively. s N,j is the random field of positive scalars. Fig. <ref type="figure" target="#fig_2">3</ref> depicts the comparison of VIF results using different methods. Compared to the previous quality metrics, VIF is the closest to human perception. For example, the average PSNR and SSIM of KSPR is higher than those of TF and MSKR. But if we examine the visual results in Fig. <ref type="figure" target="#fig_2">3</ref>, it can easily be seen that there are more artifacts in KSPR than in TF and MSKR.</p><p>In our experiments, the differences in visual quality between the various denoising methods can be inspected in the examples shown in Figs. <ref type="figure" target="#fig_2">3</ref> and<ref type="figure" target="#fig_3">4</ref>. From those figures, one can observe that in spatial domain methods local filters achieve good visual results, but still blur the image details too much. Among them, KSPR keeps much details, but introduces some artifacts. MSKR fails to denoise images corrupted by high level noises because the intrinsic idea of SKR is to denoise according to the direction of the edge. When high level noises destroy the edges of images, MSKR cannot perform well. Among all the local spatial filters, at the low noise level, TF generates the best visual results because of its adaptive representations. Nonlocal means has the best visual results among spatial domain methods because it fully exploits the sparsity in an image. In wavelet-based methods, BLS-GSM can effectively remove noise, but the artifacts are quite noticeable. LPG-PCA does not introduce new artifacts, but the entire image is a bit oversmoothed. BM3D is the best among them that can well retain edges and details. However, when the noise level is above 50 (Fig. <ref type="figure" target="#fig_3">4</ref>), BM3D generates relatively good results but brings significant amounts of artifacts. The details and edges are well preserved in the results of dictionary learning-based methods, even though the use of the sparsity constraint in the regularization term causes ringing effects at some noise levels.</p><p>Summary: in most cases, higher quantitative results yield better visual results. However: 1) in terms of the edge preserving ability, dictionary learning methods achieve best results; 2) for certain textures (oscillatory patterns), waveletbased methods work better than the other two categories; for instance, the separation of diagonal orientations in BLS-GSM helps remove the noise in diagonally oriented image regions; 3) regarding the highly corrupted images, learningbased methods work better; this shows even more obviously in visual results than the quantitative results; and 4) basis functions vary from pixel to pixel are helpful to preserve fine details in images compared to global models and models learned for each cluster. This is not shown in those PSNR or SSIM values directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Execution Time</head><p>The computation times of representative denoising methods are also evaluated in this section from a practical point of Compared to the critically sampled wavelet transforms, the dictionary learning based overcomplete representations make algorithms less efficient. Also, the local spatial filters shown in the table have many iterations, which makes them comparatively slow.</p><p>Summary: under the same image resolution, the most efficient denoising method in our evaluation is TF. The reason is that the offline learning in this algorithm accomplishes most of the denoising task to save time in the online testing. Then, the next efficient algorithms are transform domain methods (BM3D, BLS-GSM) due to the multiresolution structure of wavelets. All the other methods that involve iterations run quite slowly (MSKR, LSSC, CSR). Also, the pixel-by-pixel model selection is very time consuming as well (KSPR, LPG-PCA). The nonlocal methods in the spatial domain are also expensive because of their high searching complexity.</p><p>Considering the scalability of all approaches, most methods, such as TF, BLS-GSM, and BM3D, scale linearly with the increase of the image size. However, LSSC, LPG-PCA, and CSR slow down dramatically due to that the optimization of the regularization is highly affected by the image size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Conclusion</head><p>In this paper, we reviewed and compared representative denoising methods both qualitatively and quantitatively. These methods have been divided into three categories: spatial domain, transform domain, and dictionary learning based. Extensive experiments were conducted to evaluate the performance of all the algorithms.</p><p>Through analytical comparison, it was found that image representations with overcomplete basis functions improve the performance within each category. In spatial filters, KSPR improves kernel regression based methods in high noise levels. In the transform domain, overcomplete wavelets are used in BLS-GSM to overcome the shortcomings of critically sampled wavelets. In dictionary learning based algorithms, it has been proved that the redundant dictionary based K-SVD outperforms the DCT based K-SVD <ref type="bibr" target="#b41">[42]</ref>. In general, overcomplete basis functions are more adaptive to image contents, which can bring better denoising results. The major disadvantage of overcomplete representations is that they usually result in computational burden. Another interesting trend observed in these results is the importance of nonlocal grouping. In each category, the performance of the methods with nonlocal grouping is significantly better than that of the methods without nonlocal grouping. For instance, NLM outperforms TF, BM3D surpasses BLS-GSM, and LSSC enahnces K-SVD. In addition, adaptive basis functions in image representations contribute better to edge-preserving, which has been proved in our evaluation that dictionary learning based methods generally produce better visual results. Moreover, multiresolution structures in the transform domain benefit the edge/detail preserving.</p><p>It is clear from the comparison in this paper that all three categories are important denoising techniques for various applications. In applications that require high efficiency, some of the local spatial filters or transform domain filters are more appropriate, because nonlocal spatial filters lead to high searching complexity. If the memory and complexity were not a major concern for the users, dictionary learning based methods would be more applicable because the online training and iterations are not practical in real time systems but they significantly boost the performance. Moreover, algorithms containing multiresolution structures tend to be more efficient than single resolution ones.</p><p>Dictionary learning based methods have produced the competitive denoising results compared to the state-of-the-art both objectively and subjectively so far. Therefore, the future research in denoising can be focused on improving the applicability of the learning based techniques in the following aspects: 1) more accurate sparse decompositions; 2) more structured dictionaries; and 3) more efficient optimization processes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Taxonomy of state-of-the-art denoising methods.</figDesc><graphic coords="2,320.52,54.12,237.60,172.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Standard testing images used in the experiment. (a) Man. (b) Squares. (c) Barbara. (d) House. (e) Peppers. (f) Lena. (g) ZeldaG. (h) Cameraman.</figDesc><graphic coords="8,329.52,53.72,219.36,102.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Average VIF comparison.</figDesc><graphic coords="10,57.50,53.68,237.60,185.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Denoising results on Barbara with σ = 20. (a) Original image. (b) Noisy image. (c) TF. (d) MSKR. (e) KSPR. (f) NLM. (g) INLM. (h) BLS-GSM. (i) BM3D. (j) LPG-PCA. (k) K-SVD. (l) LSSC. (m) CSR.</figDesc><graphic coords="10,370.52,53.44,137.64,540.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Comparison of visual results on Castle from the Berkeley dataset with σ = 75. (a) Original image. (b) Noisy image. (c) TF. (d) MSKR. (e) KSPR. (f) NLM. (g) INLM. (h) BLS-GSM. (i) BM3D. (j) LPG-PCA. (k) K-SVD. (l) LSSC. (m) CSR.</figDesc><graphic coords="11,100.22,54.24,147.36,541.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I</head><label>I</label><figDesc>Relative Computation Time of Representative Denoising Algorithms (in Minutes)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II</head><label>II</label><figDesc>PSNR and SSIM Comparison. In Each Row of ThisTable, the Upper One Is PSNR (dB) Value and the Other One Is SSIM Value. All the Results Reported Are Average Values Over Five Experiments, Having Different Realizations of the Noise</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Available at http://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The eight images are Man, Squares, Barbara, House, Peppers, Lena, ZeldaG, Cameraman.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Available at http://www.flickr.com.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This work was supported in part by the National Basic Research Program of China (973 Program) under Grant 2012CB316400, in part by the University of Sheffield, in part by the China Scholarship Council, in part by the National Natural Science Foundation of China under Grant 61125106 and Grant 91120302, and in part by the Shaanxi Key Innovation Team of Science and Technology under Grant 2012KCT-04. This paper was recommended by Associate Editor J. Basak.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A novel evolutionary approach to image enhancement filter design: Method and applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1446" to="1457" />
			<date type="published" when="2009-12">Dec. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Histogram-based fuzzy filter for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="230" to="238" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Genetic-based fuzzy image filter and its application to image processing</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="694" to="711" />
			<date type="published" when="2005-08">Aug. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A multi-frame image superresolution method</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="405" to="414" />
			<date type="published" when="2010-02">Feb. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Computer Vision</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stockman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Wiener</surname></persName>
		</author>
		<title level="m">Extrapolation, Interpolation, and Smoothing of Stationary Time Series</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Least-Mean-Square Adaptive Filters</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Wiley-IEEE</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An overview and performance evaluation of classification-based least squares trained filters</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Haan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1772" to="1782" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Comput. Vision</title>
		<meeting>6th Int. Conf. Comput. Vision</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structure adaptive anisotropic filtering</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Firmin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Underwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess<address><addrLine>Edinburgh, U.K</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="717" to="721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Kernel regression for image processing and reconstruction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="366" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic parameter selection for denoising algorithms using a no-reference measure of image content</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3116" to="3132" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adaptive kernel-based image denoising employing semiparametric regularization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bouboulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slavakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Theodoridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1465" to="1479" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A nonlocal algorithm for image denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vision Pattern Recognit</title>
		<meeting>IEEE Int. Conf. Comput. Vision Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast image and video denoising via nonlocal means of similar neighborhoods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mahmoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="839" to="842" />
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An optimized blockwise nonlocal means denoising filter for 3-D magnetic resonance images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Coupe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kervrann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="425" to="441" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improved image denoising with adaptive nonlocal means (ANLmeans) algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Thaipanich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Byung Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ping-Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Daru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C J</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Consum. Electron</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2623" to="2630" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast nonlocal algorithm for image denoising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1429" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An improved non-local denoising algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Goossens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pizurica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Local Non-Local Approximation Image Process</title>
		<meeting>Int. Workshop Local Non-Local Approximation Image ess</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A fast NL-means method in image denoising based on the similarity of spatially sampled pixels</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jingjing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Workshop Multimedia Signal Process</title>
		<meeting>IEEE Int. Workshop Multimedia Signal ess</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Non-local image smoothing by applying anisotropic diffusion PDE&apos;s in the space of patches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tschumperle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2957" to="2960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rotationally invariant similarity measures for nonlocal image denoising</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Joachim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Visual Commun. Image Representation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="130" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lebesgue anisotropic image denoising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Imag. Syst. Tech</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="73" />
			<date type="published" when="2005-07">Jul. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Local adaptivity to variable smoothness for exemplar-based image denoising and representation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kervrann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boulanger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-07">Jul. 2005</date>
			<biblScope unit="volume">5624</biblScope>
			<pubPlace>Paris Cedex, France</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
	<note>INRIA</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonlocal similarity image filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCLA Comput. Appl. Math</title>
		<imprint>
			<biblScope unit="page" from="8" to="26" />
			<date type="published" when="2008-04">Apr. 2008</date>
			<pubPlace>LA, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A rotationally invariant block matching strategy improving image denoising with non-local means</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Didas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Local Non-Local Approximation Image Process</title>
		<meeting>Int. Workshop Local Non-Local Approximation Image ess</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improved nonlocal means based on preclassification and invairant block matching</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Cvetkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klijn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE / OSA J. Display Technol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="212" to="218" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vision</title>
		<meeting>IEEE Int. Conf. Comput. Vision</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2272" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Noise reduction filters for dynamic image sequences: A review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Brailean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Kleihorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Efstratiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Lagendijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1995-09">Sep. 1995</date>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="1272" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Noise removal via Bayesian wavelet coring</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="379" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The curvelet transform for image denoising</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="670" to="684" />
			<date type="published" when="2002-06">Jun. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The contourlet transform: An efficient directional multiresolution image representation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2091" to="2106" />
			<date type="published" when="2005-12">Dec. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sparse geometric image representations with bandelets</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="423" to="438" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Image denoising using scale mixtures of Gaussians in the wavelet domain</title>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A new SURE approach to image denoising: Interscale orthonormal wavelet thresholding</title>
		<author>
			<persName><forename type="first">F</forename><surname>Luisier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="593" to="606" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Two-stage image denoising by principal component analysis with local pixel grouping</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1531" to="1549" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SURE-let for orthonormal waveletdomain video denoising</title>
		<author>
			<persName><forename type="first">F</forename><surname>Luisier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="913" to="919" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A review of wavelet denoising in MRI and ultrasound brain imaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pizurica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Aleksandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Med. Imag. Rev</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="247" to="260" />
			<date type="published" when="2006-05">May 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-scale dictionary for single image super-resolution</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vision Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vision Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1114" to="1121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Nonlocal hierarchical dictionary learning using wavelets for image denoising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint/>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sparsity-based image denoising via dictionary learning and structural clustering</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vision Pattern Recognit</title>
		<meeting>IEEE Int. Conf. Comput. Vision Pattern Recognit<address><addrLine>Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A review of adaptive image representations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Peyre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="896" to="911" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">From local kernel to nonlocal multiple-model image denoising</title>
		<author>
			<persName><forename type="first">K</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alessandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Karen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaakko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scale space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990-07">Jul. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Total variation based image restoration with free local constraints</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Susan: A new approach to low level image processing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="78" />
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Noise level estimation using weak textured patches of a single noisy image</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="665" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Image denoising using the higher order singular value decomposition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rajwade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="849" to="862" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">A Wavelet Tour of Signal Processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Academic</publisher>
			<pubPlace>London, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Wedgelets: Nearly-minimax estimation of edges</title>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="859" to="897" />
			<date type="published" when="1999-06">Jun. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Recovering edges in ill-posed inverse problems: Optimality of curvelet frames</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="784" to="842" />
			<date type="published" when="2002-06">Jun. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">New tight frames of curvelets and the problem of approximating piecewise c2 image with piecewise c2 edges</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="219" to="266" />
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bandelet image approximation and compression</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Pennec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Mul. Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="992" to="1039" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Frame pyramids</title>
		<author>
			<persName><forename type="first">M</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2329" to="2342" />
			<date type="published" when="2003-09">Sep. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Orthogonal bandlet bases for geometric images approximation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peyre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1173" to="1212" />
			<date type="published" when="2008-02">Feb. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The design and the use of steerable filters</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="891" to="906" />
			<date type="published" when="1991-09">Sep. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Ten Lectures on Wavelets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Wavelets and Subband Coding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kovacevic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Denoising by soft-thresholding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ideal spatial adaption via wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="425" to="455" />
			<date type="published" when="1994-09">Sep. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deblurring-by-denoising using spatially adaptive Gaussian scale mixtures in overcomplete pyramids</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guerrero-Colon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="625" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Natural image denoising: Optimality and inherent bounds</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lesage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bimbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benaroya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vision Pattern Recognit</title>
		<meeting>IEEE Int. Conf. Comput. Vision Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2833" to="2840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Emergence of simplecell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996-06">Jun. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Sparse coding with an overcomplete basis set: A strategy employed by v1 ?</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="311" to="325" />
			<date type="published" when="1996-12">Dec. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Method of optimal directions for frame design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Engan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hakon-Husoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. IEEE Int. Conf. Acoust. Speech Signal Process.</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2443" to="2446" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Dictionary learning algorithms for sparse representation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kreutz-Delgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Engan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neur. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="396" />
			<date type="published" when="2003-02">Feb. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Learning overcomplete representations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lewicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neur. Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="365" />
			<date type="published" when="2000-02">Feb. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Learning unions of orthonormal bases with thresholded singular value decomposittion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lesage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bimbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Benaroya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc. IEEE Int. Conf. Acoust. Speech Signal Process</title>
		<imprint>
			<biblScope unit="page" from="2272" to="2279" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Sparse representation for color image restoration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="69" />
			<date type="published" when="2008-01">Jan. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Clustering-based denoising with locally learned dictionaries</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1438" to="1451" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Task-driven dictionary learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="791" to="804" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Image information and visual quality</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="430" to="444" />
			<date type="published" when="2008-02">Feb. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A review of image denoising algorithm, with a new one</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Multiscale Model. Simul</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2006-07">Jul. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A statistical evaluation of recent full reference image quality assessment algorithms</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Sabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3440" to="3451" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
