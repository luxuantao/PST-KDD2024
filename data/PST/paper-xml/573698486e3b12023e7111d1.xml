<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HDRF: Stream-Based Partitioning for Power-Law Graphs *</title>
				<funder ref="#_Kc8KBD3">
					<orgName type="full">Italian Ministry of Education, University and Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
							<email>petroni@dis.uniroma1.it</email>
						</author>
						<author>
							<persName><forename type="first">Leonardo</forename><surname>Querzoni</surname></persName>
							<email>querzoni@dis.uniroma1.it</email>
						</author>
						<author>
							<persName><forename type="first">Khuzaima</forename><surname>Daudjee</surname></persName>
							<email>kdaudjee@uwaterloo.ca</email>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Cheriton School</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shahin</forename><surname>Kamali</surname></persName>
							<email>s3kamali@uwaterloo.ca</email>
						</author>
						<author>
							<persName><forename type="first">Giorgio</forename><surname>Iacoboni</surname></persName>
							<email>g.iacoboni@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Control and Management Engineering Antonio Ruberti</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Control and Management Engineering Antonio Ruberti</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Control and Management Engineering Antonio Ruberti</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">HDRF: Stream-Based Partitioning for Power-Law Graphs *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2806416.2806424</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph Partitioning</term>
					<term>Streaming Algorithms</term>
					<term>Distributed Graph-Computing Frameworks</term>
					<term>Replication</term>
					<term>Load Balancing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Balanced graph partitioning is a fundamental problem that is receiving growing attention with the emergence of distributed graph-computing (DGC) frameworks. In these frameworks, the partitioning strategy plays an important role since it drives the communication cost and the workload balance among computing nodes, thereby affecting system performance. However, existing solutions only partially exploit a key characteristic of natural graphs commonly found in the real-world: their highly skewed power-law degree distributions. In this paper, we propose High-Degree (are) Replicated First (HDRF ), a novel streaming vertex-cut graph partitioning algorithm that effectively exploits skewed degree distributions by explicitly taking into account vertex degree in the placement decision. We analytically and experimentally evaluate HDRF on both synthetic and real-world graphs and show that it outperforms all existing algorithms in partitioning quality.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The last few years have witnessed a huge growth in information production. Some corporations like IBM estimate that "2.5 quintillion bytes of data are created every day", amounting to 90% of the data in the world today having been created in the last two years <ref type="bibr" target="#b10">[10]</ref>. On the face of this growth, researchers from both academia and industry have focussed their efforts on the design of new, efficient, approaches for parallel data analysis able to withstand the deluge of data expected in forthcoming years.</p><p>Given the proliferation of data which can be represented as graphs of interconnected vertices, a graph-based computation paradigm provides a nice, suitable, abstraction to perform computation on it. Large amounts of data, particularly scale-free graphs or power-law graphs <ref type="foot" target="#foot_0">1</ref> , fall within this paradigm. An example is recommendation systems where the input data is usually provided in the form of votes (edges) that users (vertices) express on products (vertices). Additionally, graph-based computation finds application in many diverse and important fields such as social networks, computational biology, chemistry, and computer security. A key problem in graph computation is that it is often difficult to scale with increasing input data sizes as graphs are not easily partitionable into independent subgraphs that can be computed in parallel.</p><p>To be able to work on large datasets, distributed graphcomputing (DGC) frameworks (such as GraphLab <ref type="bibr" target="#b18">[18]</ref> or Pregel <ref type="bibr" target="#b20">[20]</ref>) forcibly partition the input graph by placing its constituting elements, be they either vertices or edges, in distinct partitions, one for each available computing resource. During the partitioning phase, data elements that share connections with other elements already placed in other partitions result in having remote connections amongst them. Since these partitions are usually placed on different machines, this can incur unnecessary or excessive network and computation costs. To address this issue, one frequently used technique is to create and locally place replicas of remotely connected data among these partitions. While this reduces the access cost, replicated data elements must be synchronized during computation so as to avoid replica states from diverging and generating meaningless computation results. This synchronization can significantly hinder performance as it forces replicas to coordinate and exchange data several times during computation.</p><p>The way the input dataset is partitioned has a large impact on the performance of the graph computation. A naive partitioning strategy may end up replicating a large fraction of the input elements on several partitions, severely hampering performance by inducing a large replica synchronization overhead during the computation phase. Furthermore, the partitioning phase should produce evenly balanced partitions (i.e. partitions with similar sizes) to avoid possible load skews in a cluster of machines over which the data is partitioned. Several recent approaches have looked at this problem. Here we focus our attention on stream-based graph partitioning algorithms, i.e. algorithms that partition incoming elements one at a time on the basis of only the current element properties and on previous assignments to partitions (no global knowledge on the input graph). Furthermore, these algorithms are usually one-pass, i.e. they refrain from changing the assignment of a data element to a partition once this has been done. These algorithms are the ideal candidates in settings where input data size and constraints on available resources restrict the type of solutions that can be employed.</p><p>Other characteristics of input data also play an important role in partitioning. It has been shown that vertex-cut algorithms are the best approach to deal with input graphs characterized by power-law degree distributions <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b12">12]</ref>. This previous work also clearly outlined the important role highdegree nodes play from a partitioning quality standpoint. Nevertheless, few algorithms take this aspect into account <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b24">24]</ref>. Understandably, this is a challenging problem to solve for stream-based approaches due to their one-pass nature.</p><p>In this paper, we leverage the idea that a partitioning algorithm should do its best to cut, i.e., replicate, highdegree vertices. In particular, we introduce High Degree (are) Replicated First (HDRF ), a stream-based graph partitioning algorithm based on a greedy vertex-cut approach that leverages information on vertex degrees. HDRF is characterized by the following desirable properties: (i) it outputs partitions with the smallest average replication factor among all competing solutions when applied on power-law graphs (Figure <ref type="figure" target="#fig_1">2</ref>) while (ii) providing close to optimal load balancing (Figure <ref type="figure" target="#fig_3">3</ref>). The former is obtained by greedily replicating vertices with larger degrees, while the latter is provided by a parametrizable balancing term whose impact can be tuned to adapt the algorithm behavior to any data input order. On the one hand, lowering the average replication factor is important to reduce network bandwidth cost, memory usage and replica synchronization overhead at computation time. A fair distribution of load on partitions, on the other hand, allows a more efficient usage of available computing resources. HDRF takes into account both of these aspects in an integrated way, significantly reducing the time needed to perform computations on large-scale graphs.</p><p>Summing up, this paper provides the following contributions:</p><p>? a novel stream-based graph partitioning algorithm, namely HDRF, that performs better than any competing solution (i.e. processes less vertex-cuts while balancing the load) when applied on power-law graphs;</p><p>? a theoretical analysis of HDRF that provides an averagecase upper bound for the vertex replication factor;</p><p>? a comprehensive experimental evaluation based both on simulations and on a working prototype integrated with GraphLab <ref type="bibr" target="#b19">[19]</ref> that shows how a system using HDRF achieves up to 2? speedup than adopting a standard greedy placement, and close to 3? speedup than using a constrained solution.</p><p>The rest of this paper is organized as follows: we define the problem in Section 2; we briefly describe existing solutions in Section 3; we introduce HDRF in Section 4; we show theoretical bounds for HDRF in Section 5; we present the results of an extensive experimental evaluation in Section 6 and we conclude the paper in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM DEFINITION</head><p>The problem of optimally partitioning a graph to minimize vertex-cuts while maintaining load balance is a fundamental problem in parallel and distributed applications as input placement significantly affects the efficiency of algorithm execution <ref type="bibr" target="#b25">[25]</ref>. An edge-cut partitioning scheme results in partitions that are vertex disjoint while a vertex-cut approach results in partitions that are edge disjoint. Both variants are known to be NP-Hard <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b2">2]</ref> but have different characteristics and difficulties <ref type="bibr" target="#b16">[16]</ref>; for instance, one fundamental difference between the two is that a vertex can be cut in multiple ways and span several partitions while an edge can only connect two partitions.</p><p>One characteristic observed in real-world graphs from social networks or the Web is their skewed power-law degree distribution: most vertices have relatively few connections while a few vertices have many. It has been shown that vertex-cut techniques perform better than edge-cut ones on such graphs (i.e., create less storage and network overhead) <ref type="bibr" target="#b12">[12]</ref>. For this reason modern graph parallel processing frameworks, like GraphLab <ref type="bibr" target="#b19">[19]</ref>, adopt a vertex-cut approach to partition the input data over a cluster of computing nodes. The focus of this paper is on streaming vertex-cut partitioning schemes able to efficiently handle graphs with skewed power-law degree distribution. Notation -Consider a graph G = (V, E), where V = (v1, ? ? ? , vn) is the set of vertices and E = (e1, ? ? ? , em) the set of edges. We define a partition of edges P = (p1, .., p k ) to be a family of pairwise disjoint sets of edges (i.e. pi, pj ? E, pi ? pj = ? for every i = j). Let A(v) ? P be the set of partitions each vertex v ? V is replicated. The size |p| of each partition p ? P is defined as its edge cardinality, because computation steps are usually associated with edges. Since we consider G having a power-law degree distribution, the probability that a vertex has degree d is P (d) ? d -? , where ? is a positive constant that controls the "skewness" of the degree distribution, i.e. the smaller the value of ?, the more skewed the distribution. Balanced k-way vertex-cut problem -The problem consists in defining a partition of edges such that (i) the average number of vertex replicas (i.e. the number of partitions each vertex is associated to as a consequence of edge partitioning) is minimized and (ii) the partition load (i.e. the number of edges associated to a partition) is within a given bound from the theoretical optimum (i.e. |E|/|P |) <ref type="bibr" target="#b2">[2]</ref>.</p><p>More formally, the balanced |P |-way vertex-cut partitioning problem aims at solving the following optimization problem:</p><formula xml:id="formula_0">min 1 |V | v?V |A(v)| s.t. max p?P |p| &lt; ? |E| |P |<label>(1)</label></formula><p>where ? ? 1 is a small constant that defines the system tolerance to load imbalance. The objective function (Equation ( <ref type="formula" target="#formula_0">1</ref>)) is called replication factor (RF ), which is the average number of replicas per vertex.</p><p>Streaming setting -Without loss of generality, here we assume that the input data is a list of edges, each identified by the two connecting vertices and characterized by some application-related data. We consider algorithms that consume this list in a streaming fashion, requiring only a single pass. This is a common choice for several reasons: (i) it handles situations in which the input data is large enough that fitting it completely in the main memory of a single computing node is impractical; (ii) it can efficiently process dynamic graphs; (iii) it imposes the minimum overhead in time and (iv) it's scalable, providing for straightforward parallel and distributed implementations. A limitation of this approach is that the assignment decision taken on an input element (i.e., an edge) can be based only on previously analyzed data and cannot be later changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">STREAMING ALGORITHMS</head><p>Balanced graph partitioning is a well known NP-hard problem with a wide range of applications in different domains. We do not discuss offline and edge-cut partitioning techniques since they are out of the scope of the paper. It is possible to divide existing streaming vertex-cut partitioning techniques in two main families: hashing and constrained partitioning algorithms and greedy partitioning algorithms.</p><p>Hashing and constrained partitioning algorithms -All of these algorithms ignore the history of the edge assignments and rely on the presence of a predefined hash function h : N ? N. The input of the hash function h can be either the unique identifier of a vertex or of an edge. All these algorithms can be applied in a streaming setting and achieve good load balance if h guarantees uniformity. Four well-known existing heuristics to solve the partitioning problem belong to this family: hashing, DBH, grid and PDS. The simplest solution is given by the hashing technique that (pseudo-)randomly assigns each edge to a partition: for each input edge e ? E, A(e) = h(e) mod |P | is the identifier of the target partition. This heuristic results in a large number of vertex-cuts in general and performs poorly on powerlaw graphs <ref type="bibr" target="#b12">[12]</ref>. A recent paper describes the Degree-Based Hashing (DBH ) algorithm <ref type="bibr" target="#b27">[27]</ref>, a variation of the hashing heuristic that explicitly considers the degree of the vertices for the placement decision. DBH leverages some of the same intuition as HDRF by cutting vertices with higher degrees to obtain better performance. Concretely, when processing edge e ? E connecting vertices vi, vj ? V with degrees di and dj, DBH defines the hash function h(e) as follows:</p><formula xml:id="formula_1">h(e) = h(vi), if di &lt; dj h(vj), otherwise</formula><p>Then, it operates as the hashing algorithm.</p><p>The grid and PDS techniques belong to the constrained partitioning family of algorithms <ref type="bibr" target="#b14">[14]</ref>. The general idea of these solutions is to allow each vertex v ? V to be replicated only in a small subset of partitions S(v) ? P that is called the constrained set of v. The constrained set must guarantees some properties; in particular, for each vi, vj ?</p><formula xml:id="formula_2">V : (i) S(vi) ? S(vj) = ?; (ii) S(vi) ? S(vj) and S(vj) ? S(vi); (iii) |S(vi)| = |S(vj)|.</formula><p>It is easy to observe that this approach naturally imposes an upper bound on the replication factor. To position a new edge e connecting vertices vi and vj, it picks a partition from the intersection between S(vi) and S(vj) either randomly or by choosing the least loaded one. Different solutions differ in the composition of the vertex constrained sets. The grid solution arranges partitions in a X ? Y matrix such that |P | = XY . It maps each vertex v to a matrix cell using a hash function h, then S(v) is the set of all the partitions in the corresponding row and column. It this way each constrained sets pair has at least two partitions in their intersection. PDS generates constrained sets using Perfect Difference Sets <ref type="bibr" target="#b13">[13]</ref>. This ensure that each pair of constrained sets has exactly one partition in the intersection. PDS can be applied only if</p><formula xml:id="formula_3">|P | = x 2 + x + 1,</formula><p>where x is a prime number.</p><p>Greedy partitioning algorithms -This family of methods uses the entire history of the edge assignments to make the next decision. The standard greedy approach <ref type="bibr" target="#b12">[12]</ref> breaks the randomness of the hashing and constrained solutions by maintaining some global status information. In particular, the system stores the set of partitions A(v) to which each already observed vertex v has been assigned and the current partition sizes. Concretely, when processing edge e ? E connecting vertices vi, vj ? V , the greedy technique follows this simple set of rules:</p><p>Case 1: If neither vi nor vj have been assigned to a partition, then e is placed in the partition with the smallest size in P . Case 2: If only one of the two vertices has been already assigned (without loss of generality assume that vi is the assigned vertex) then e is placed in the partition with the smallest size in A(vi). Case 3: If A(vi) ? A(vj) = ?, then edge e is placed in the partition with the smallest size in A(vi) ? A(vj). Case 4:</p><formula xml:id="formula_4">If A(vi) = ?, A(vj) = ? and A(vi)?A(vj) = ?, then</formula><p>e is placed in the partition with the smallest size in A(vi) ? A(vj) and a new vertex replica is created accordingly.</p><p>Symmetry is broken with random choices. An equivalent formulation consists of computing a score C greedy (vi, vj, p) for all partitions p ? P , and then assigning e to the partition p * that maximizes C greedy . The score consists of two elements: (i) a replication term C greedy REP (vi, vj, p) and (ii) a balance term C greedy BAL (p). It is defined as follows:</p><formula xml:id="formula_5">C greedy (vi, vj, p) = C greedy REP (vi, vj, p) + C greedy BAL (p)<label>(2)</label></formula><formula xml:id="formula_6">C greedy REP (vi, vj, p) = f (vi, p) + f (vj, p)<label>(3)</label></formula><formula xml:id="formula_7">f (v, p) = 1, if p ? A(v) 0, otherwise C greedy BAL (p) = maxsize -|p| + maxsize -minsize (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>where maxsize is the maximum partition size, minsize is the minimum partition size, and is a small constant value.</p><p>A recent paper <ref type="bibr" target="#b24">[24]</ref> proposes an hybrid solution that tries to combine both edge-cut and vertex-cut approaches together. The resulting heuristic, called Ginger, aims at optimizing the partitioning in a DGC framework. However, Ginger is not a streaming solution, since it needs extra reassignment phases after the original streaming graph partitioning.</p><p>We remark there are other facets of graph partitioning that may affect performance of a DGC framework and have been addressed in other works. For example, some applications are based on dynamic graphs and provided a hashingbased partitioning solution to manage such type of input <ref type="bibr" target="#b21">[21]</ref>. Another aspect is the use of other metrics for optimization. For example <ref type="bibr" target="#b28">[28]</ref> proposes a solution aimed at aggressively replicating vertices to improve the performance of queries on the graph and to keep them local to each single partition as much as possible. Further contributions along these lines are orthogonal and out of the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE HDRF ALGORITHM</head><p>In this section, we present HDRF, a greedy algorithm tailored for skewed power-law graphs.</p><p>In the context of robustness to network failure, Cohen et al. <ref type="bibr" target="#b7">[7,</ref><ref type="bibr">8]</ref> and Callaway et al <ref type="bibr" target="#b6">[6]</ref> have analytically shown that if only a few high-degree vertices (hubs) are removed from a power-law graph then it is turned into a set of isolated clusters. Moreover, in power-law graphs, the clustering coefficient distribution decreases with increase in the vertex degree <ref type="bibr" target="#b9">[9]</ref>. This implies that low-degree vertices often belong to very dense sub-graphs and those sub-graphs are connected to each other through high-degree vertices.</p><p>Our partitioning scheme leverages these properties by focusing on the locality of low-degree vertices. In particular, it tries to place each strongly connected component with lowdegree vertices into a single partition by cutting high-degree vertices and replicating them on a large number of partitions. As the number of high-degree vertices in power-law graphs is very low, encouraging replication for only these vertices leads to an overall reduction of the replication factor.</p><p>Concretely, when HDRF creates a replica, it does so for the vertex with the highest degree. However, obtaining degrees of vertices for a graph that is consumed in a streaming fashion is not trivial. To avoid the overhead of a preprocessing step (where the input graph should be fully scanned to calculate the vertex exact degrees), a table with partial degrees of the vertices can be maintained that is continuously updated while input is analyzed. As each new edge is considered in the input, the degree values for the corresponding vertices are updated in the table. The partial degree values collected at runtime are usually a good indicator for the actual degree of a vertex since it is more likely that an observed edge belongs to a high-degree vertex rather than to a low-degree one. <ref type="foot" target="#foot_1">2</ref>More formally, when processing edge e ? E connecting vertices vi and vj, the HDRF algorithm retrieves their partial degrees and increments them by one. Let ?(vi) be the partial degree of vi and ?(vj) be the partial degree of vj. The degree values are then normalized such that they sum up to one:</p><formula xml:id="formula_9">?(vi) = ?(vi) ?(vi) + ?(vj) = 1 -?(vj)<label>(5)</label></formula><p>As for the greedy heuristic, the HDRF algorithm computes a score C HDRF (vi, vj, p) for all partitions p ? P , and then assigns e to the partition p * that maximizes C HDRF . The score for each partition p ? P is defined as follows:</p><formula xml:id="formula_10">C HDRF (vi, vj, p) = C HDRF REP (vi, vj, p) + C HDRF BAL (p)<label>(6)</label></formula><p>C HDRF REP (vi, vj, p) = g(vi, p) + g(vj, p)</p><formula xml:id="formula_11">g(v, p) = 1 + (1 -?(v)), if p ? A(v) 0, otherwise C HDRF BAL (p) = ? ? C greedy BAL (p) = ? ? maxsize -|p| + maxsize -minsize<label>(7)</label></formula><p>The ? parameter allows control of the extent of partition size imbalance in the score computation. We introduced this parameter because the standard greedy heuristic may result in highly imbalanced partition sizes, especially when the input is ordered somehow. To see this problem note that C greedy BAL (p) (Equation <ref type="formula" target="#formula_7">4</ref>) is always smaller than one, while C greedy REP and C HDRF REP are either zero or greater than one. For this reason, the balance term CBAL in the greedy algorithm or when 0 &lt; ? ? 1 is used only to choose among partitions that exhibit the same value for the replication term CREP, thereby breaking symmetry.</p><p>However, this may not be enough to ensure load balance. For instance, if the stream of edges is ordered according to some visit order on the graph (e.g., breadth first search or depth first search), when processing edge e ? E connecting vertices vi and vj there is always a single partition p * with C greedy REP (vi, vj, p * ) ? 1 (resp. C HDRF REP (vi, vj, p * ) &gt; 1) and all the other partitions p ? P s.t. p = p * have C greedy REP (vi, vj, p) = 0 (resp. C HDRF REP (vi, vj, p) = 0). In this case, the balance term is useless as there is no symmetry to break, and the heuristic ends up placing all edges in a single partition p * . This problem can be solved by setting a value for ? &gt; 1. In our evaluation (Section 6), we empirically studied the trend of the replication factor and the load balance by varying ? (Figure <ref type="figure" target="#fig_7">6</ref>). Moreover, note that when ? ? ? the algorithm resembles a random heuristic, where past observations are ignored and it only matters to have partitions with equal size. The following summarizes the behavior of the HDRF algorithm with respect to the ? parameter:</p><formula xml:id="formula_13">? ? ? ? ? ? ? ? ? ? = 0,</formula><p>agnostic of the load balance 0 &lt; ? ? 1, balance used to break the symmetry ? &gt; 1, balance importance proportional to ? ? ? ?, random edge assignment When ? = 1 the HDRF algorithm can be represented by a set of simple rules, exactly as in greedy, with the exception of Case 4 that is modified as follows: HDRF can be run as a single process or in parallel instances to speed up the partitioning phase. As with greedy, HDRF also needs some state to be shared among parallel instances during partitioning. In particular, we noticed that sharing the values of A(v), ?v ? V is sufficient to let HDRF perform at its best. Note that optimizing the execution time of HDRF was a goal beyond the scope of this work; we will consider it as part of our future work.</p><formula xml:id="formula_14">Case 4 If A(vi) = ?, A(vj) = ? and A(vi) ? A(vj) = ?, then -if ?(vi) &lt; ?(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">THEORETICAL ANALYSIS</head><p>In this section we characterize the HDRF algorithm behavior from a theoretical perspective, focussing on the vertex replication factor. In particular we are interested in an average-case analysis of HDRF. A worst-case analysis would provide poor performance, as expected for any similar greedy algorithm, while failing to capture the typical behavior of HDRF in real cases. In the rest of this section we assume ? = 1 for the sake of simplicity.</p><p>Cohen et al. <ref type="bibr">[8]</ref> considered the problem of a scale-free network (characterized as a power-law graph) attacked by an adversary able to remove a fraction c of vertices with the largest degrees. In particular they characterized the approximate maximum degree M observable in the graph's largest component after the attack. If |V | 1/c this value can be approximated by the following equation:</p><formula xml:id="formula_15">M = mc 1/(1-?) (<label>9</label></formula><formula xml:id="formula_16">)</formula><p>where m is the (global) minimum vertex degree and ? is the parameter characterizing the initial vertex degree distribution.</p><p>Let us now consider the algorithm aHDRF as an approximation of HDRF : aHDRF performs exactly as HDRF, but for the fact that we assume it knows the exact degree of each input vertex (and not the observed degree as for HDRF ).</p><p>Theorem 1. Algorithm aHDRF achieves a replication factor, when applied to partition a graph with |V | vertices on |P | partitions, that can be bounded by:</p><formula xml:id="formula_17">RF ? ? |P | + 1 |V |(1 -? ) |V |(1-? )-1 i=0 1 + m ? + i |V | 1 1-? ? = |P | -1 m 1-?</formula><p>Proof. The replication factor bound is the sum of two distinct parts. The first part considers the fraction ? of vertices with the largest degrees in the graph, referred to as hubs. The worst case for hubs is to be replicated in all the partitions, with a corresponding replication factor of ? |P |. ? represents the fraction of vertices that must be removed from the graph such that the maximum vertex degree in the remaining graph is |P | -1; this value is obtainable through Equation ( <ref type="formula" target="#formula_15">9</ref>) by imposing M = |P | -1.</p><p>The second part of the equation consider the contribution to the replication factor from non-hub vertices, i.e. all vertices whose degree is expected to be smaller than |P | -1 after the ? vertices with the largest degrees have been removed from the graph (together with their edges). When aHDRF processes an edge connecting a hub vertex with a non-hub vertices, it always favors the replication the hub vertex (that has a larger degree) and replicates the non-hub vertex only if executes Case 1 or Case 2, that is only if it is the first time it observes that vertex. Since the degree of non-hub vertices, ignoring the connections with hub vertices, is bounded by m? 1/(1-?) , and since the connections with hub vertices can produce at most one replica, the worst case replication factor for non-hub vertices is bounded by:</p><formula xml:id="formula_18">1 |V |(1 -? ) 1 + m? 1 1-?</formula><p>This bound can be further improved by considering what happens to the graph once the non-hub vertex v0 with the largest degree is removed. The previous bound is valid for v0. However, the removal of v0 from the graph will change the degree distribution, thus also reducing the bound for the next non-hub vertex with the largest degree. Using this consideration, it is possible to iteratively bound the degree of each non-hub vertex vi with m(? + i/|V |) 1/(1-?) where 0 ? i ? |V |(1-? )-1. Hence, the total worst case replication factor for non-hub vertices, is bounded by:</p><formula xml:id="formula_19">1 |V |(1 -? ) |V |(1-? )-1 i=0 1 + m ? + i |V | 1 1-?</formula><p>If edges arrive in random order, aHDRF gives an approximation of HDRF. In this case, the observed values for vertex degrees are a good estimate for the actual degrees. We can conclude that, assuming random order arrival for edges, HDRF is expected to achieve a replication factor, when applied to partition a graph with |V | vertices on |P | partitions, of at most RF of Theorem 1.</p><p>For example, consider a graph with ? = 2.2, |P | = 128, m = 1 and 1M vertices. The average-case upper bound for the replication factor of HDRF is ? 5.12 while the actual result it achieves is ? 1.37. The bounds for DBH and hashing <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b27">27]</ref> with this configuration are respectively ? 5.54 and ? 5.88, while the actual results they achieve are ? 1.89 and ? 2.52.</p><p>The upper bound given by Theorem 1 cannot be extended to other algorithms (e.g., greedy). Informally, HDRF breaks network at hubs by replicating a small fraction of vertices with large degrees. In contrast, greedy and other algorithms are agnostic to the degree of vertices when replicating them. Intuitively, these algorithms try to break network by removing random vertices. Unfortunately, power-law graphs are resilient against removing random vertices (see <ref type="bibr" target="#b7">[7]</ref> for details). This implies that, in order to fragment a scale-free network, a very large number of random vertices should be removed. In other words, greedy and other algorithms tend to replicate a large number of vertices in different partitions. This intuition is verified in our experiments (see Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EVALUATION</head><p>This section presents experimental results for the HDRF partitioning algorithm. The evaluation was performed on real-world graphs by running the proposed algorithm both in a stand-alone partitioner (useful for scaling up to large partition numbers) and running an implementation of HDRF integrated into GraphLab 3 . The evaluation also reports experiments on synthetic graphs generated randomly with increasingly skewed distributions to study the extent to which HDRF performance is sensitive to workload characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Settings and Test Datasets</head><p>Evaluation Metrics -We evaluate the performance of HDRF by measuring the following metrics: Replication factor: is the average number of replicas per vertex. This metric is a good measure of the synchronization overhead and should be minimized.</p><p>Load relative standard deviation: is the relative standard deviation of the number of edges hosted in target partitions. An optimal partitioning strategy should have a value for this metric close to 0.</p><p>Max partition size: is the number of either vertices or edges hosted in the largest partition. We consider this metric with respect to both vertices and edges as each conveys different information. Edges are the main input for the computation phase, thus more edges in a partition mean more computation for the computing node hosting it; conversely, the number of vertices in the system, and, therefore, in the largest partition, also depends on the number of replicas generated by the partitioning algorithm.</p><p>Execution time: is the number of seconds needed by the DGC framework to perform the indicated computation on the whole input graph. Better partitioning, by reducing the number of replicas, is expected to reduce the synchronization overhead at runtime and thus reduce the execution time as well. Datasets -In our evaluation, we used as datasets both synthetic power-law graphs and real-word graphs. The former were used to study how HDRF performance vary when the degree distribution skewness of the input graph gradually increases. In particular, each synthetic graph was generated with 1M vertices, minimum degree of 5 and edges using a power law distribution with ? ranging from 1.8 to 4.0. Therefore, the number of edges in the graphs ranges 3 The stand-alone software and the GraphLab patch are available at https://github.com/fabiopetroni/VGP. from ? 60M (? = 1.8) to ? 3M (? = 4). Graphs were generated with gengraph <ref type="bibr" target="#b26">[26]</ref>. We also tested the performance of HDRF on real-world graphs: twitter-2010 from LAW (Laboratory for Web Algorithmics) <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b4">4]</ref>, Tencent Weibo from the KDD-Cup 2012 <ref type="bibr" target="#b22">[22]</ref>, Netflix from the Netflix Prize <ref type="bibr" target="#b3">[3]</ref> and MovieLens 10M from the GroupLens research lab (http://grouplens.org). Table <ref type="table" target="#tab_1">1</ref> reports some statistics for these 4 datasets. System Setup -We implemented a stand-alone version of a graph partitioner that captures the behavior of a DGC framework during the graph loading and partitioning phase. Within our partitioner, we implemented the five different algorithms described so far: hashing, DBH, grid, PDS, greedy and HDRF. Furthermore, we compared our solution against two offline methods: Ginger <ref type="bibr" target="#b24">[24]</ref> and METIS <ref type="bibr" target="#b15">[15]</ref>, a wellknown edge-cut partitioning algorithm. To compute the replication factor delivered by METIS, we used the same strategy of <ref type="bibr" target="#b12">[12]</ref>: every edge-cut forces the two spanned partitions in maintaining a replica of both vertices and a copy of the edge data. To run realistic tests needed to measure execution time, we implemented and integrated HDRF into GraphLab v2.2. Experiments with GraphLab where conducted on a cluster consisting of 8 machines with dual 16core Intel Xeon CPUs and 128GB of memory each. We experimented with 32, 64 and 128 partitions by running multiple instances on a single machine. Data input order -Since the input dataset is consumed as a stream of edges, the input order can affect the performance of the partitioning algorithm. We considered three different stream orders as in <ref type="bibr" target="#b25">[25]</ref>: random, where edges arrive according to a random permutation; BFS, where the edge order is generated by selecting a vertex uniformly at random and performing a breadth first search visit starting from that vertex; DFS, that works as BFS except for the visit algorithm that is depth-first search. All reported results are based on a random input order unless otherwise mentioned in the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance Evaluation</head><p>The experimental results reported in this section are organized as follows: we first report on experiments that show the ability of HDRF to deliver the best overall performance in terms of execution time with the smallest overhead (replication factor) and close to optimal load balance when executed on real-world graphs. We then study how HDRF performance is affected by changes in the characteristics of the input dataset and changes in the target number of partitions. Finally, the last set of results analyze the sensitivity of HDRF to input stream ordering.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Runtime comparison</head><p>We first measured HDRF performance against other streaming partitioning algorithms on our set of real-world graphs. These experiments were run by partitioning the input graphs on a set of target partitions in the range <ref type="bibr" target="#b3">[3,</ref><ref type="bibr">256]</ref> with our stand-alone partitioner. Figure <ref type="figure">1</ref> reports the replication factor that the considered partitioning algorithms achieve on different input graphs 4 . Moreover, Figure <ref type="figure" target="#fig_1">2a</ref> provides a snapshot of the evaluation, by setting the number of target partition to 133, a number compliant with PDS constraints. It can be observed that HDRF is the algorithm that provides the smallest replication factor for all the considered datasets.</p><p>In particular, for the Weibo dataset, characterized by large edge count differences among high-degree and low-degree vertices, it is possible to observe how HDRF and DBH are the best performers as they both exploit vertex degrees. In all the other datasets HDRF is always the best performer, albeit with larger absolute RF values. Summarizing, on the considered datasets HDRF achieves on average a replication factor about 40% smaller than DBH, more than 50% smaller than greedy, almost 3? smaller than PDS, more than 4? smaller than grid and almost 14? smaller than hashing. We experimented with other datasets as well (i.e. arabic-2005, uk-2002, indochina-2004 from LAW, and Yahoo! Music from the KDD-Cup 2011). In all our test HDRF outperforms competing solutions, simultaneously guaranteeing close to perfect load balance (results omitted due to space constraints).</p><p>Next, we compared HDRF against two offline partitioning algorithms: Ginger and METIS. Note that these offline solutions have full knowledge of the input graph that can be exploited to drive their partitioning choices. Figure <ref type="figure" target="#fig_1">2b</ref> compares the replication factor achieved by these two solutions and HDRF (we maintain |P | = 133 to be coherent with Figure <ref type="figure" target="#fig_1">2a</ref>). We do not report the results for the twitter-2010 dataset since METIS produced greatly unbalanced parti- 4 Due to specific constraints imposed by the PDS and grid algorithms on the total number of partitions, their data points are not aligned with those of the other algorithms.  tions <ref type="foot" target="#foot_2">5</ref> , making a comparison on this dataset unfair. The poor performance of METIS was an expected result since it has been proved that edge-cut approaches perform worse than vertex-cut ones on power-law graphs <ref type="bibr" target="#b12">[12]</ref>. However, HDRF outperforms Ginger as well, by reducing its replication factor by 10% on average. In addition, HDRF has the clear advantage of consuming the graph in a one-pass fashion while Ginger needs several passes over the input data to converge. These results show that HDRF is always able to provide a smaller average replication factor with respect to all other algorithms, both streaming and offline, when used to partition graphs with power-law degree distributions.</p><p>Figure <ref type="figure" target="#fig_3">3</ref> reports the load relative standard deviation produced by the tested streaming algorithms when run on the MovieLens 10M dataset with a variable number of target partitions (results for other datasets showed similar behavior so we omit them). The curves show that HDRF and greedy provide the best performance as the number of target partitions grows. As expected, hashing provides well bal- anced partitions, but it still performs worse that the other algorithms as its expected behavior with respect to load balancing is only probabilistic. Grid performs similarly, even if its more complex constraints induce some skew in load.</p><p>DBH and PDS are the worse performers, with load skew growing at a fast pace as the number of target partitions grows. Note that replication factor reflects communication cost, and edge-imbalance reflects workload-imbalance; providing good performance with these two metrics means that HDRF can provide partitioning results that make the execution of application algorithms more efficient.</p><p>To this end, we studied how much all of this translates to a performance improvement with respect to the execution time. Since a DGC framework has to periodically synchronize all the vertex replicas, having fewer replicas in the system is expected to provide an advantage and to speed up the execution time. To investigate the impact of the different partitioning techniques we ran the Stochastic Gradient Descent (SGD) algorithm for matrix completion <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23]</ref> on GraphLab, using the Tencent Weibo dataset and 100 latent factors, with 32, 64 and 128 partitions respectively. Figure <ref type="figure" target="#fig_4">4</ref> reports the measured speed-up, obtained by using HDRF to partition the input over greedy and PDS <ref type="foot" target="#foot_3">6</ref> . The SGD algorithm runs up to 2? faster using HDRF as input partitioner with respect to greedy, and close to 3? faster than PDS. The actual improvement is larger as the number of target partitions grows. Moreover, the speedup is proportional to the gain in RF (see Figure <ref type="figure">1a</ref>) and, as already shown in <ref type="bibr" target="#b12">[12]</ref>, halving the replication factor approximately halves runtime. Furthermore, having partitions with fewer replicas also help SGD to converge faster <ref type="bibr" target="#b23">[23]</ref>.</p><p>We tested the speedup for other datasets and algorithms as well, namely Single Source Shortest Path (SSSP), Weakly Connected Components (WCC), Page Rank (PR) and Alternating Least Squares (ALS). The results (not reported here due to space constraints) confirmed our intuitions: the speedup is proportional to both the advantage in replication factor and the actual network usage of the algorithm. The speedup it is larger for IO-intensive algorithms (e.g. SGD, ALS and PR) and smaller for algorithm with less network IO (SSSP and WCC). None of the tests we conducted with HDRF showed a slowdown with respect to other solutions.</p><p>Our results show that HDRF is the best solution to partition input graphs characterized by skewed power-law degree distributions. HDRF achieves the smallest replication factor with close to optimal load balance. These two characteristics combined make application algorithms execute more efficiently in the DGC framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Performance sensitivity to input shape</head><p>We next analyze how the input graph degree distribution affects HDRF performance. To this end, we used HDRF to partition a set of synthetic power-law graphs. In doing so, we experimentally characterize the sensitivity of the average replication factor on the power-law shape parameter ?, and on the number of partitions. Figure <ref type="figure" target="#fig_6">5a</ref>  (1) with highly skewed degree distributions (i.e. small values of ?), its performance is significantly better than greedy and other algorithms (with the exception of DBH); (2) with less skewed degree distributions, the performance of HDRF approaches that provided by greedy, while all the other solutions (including DBH ) perform worse. These results show how HDRF behavior approximates greedy's behavior as the number of high degree vertices in the input graph grows as in this case making a different partitioning choice on highdegree vertices is less useful (as there are a lot of them). Note that Gonzalez et al. <ref type="bibr" target="#b12">[12]</ref> showed that the effective gain of a vertex-cut approach relative to an edge-cut approach actually increases with smaller ?. Our solution boosts this gain, not only with respect to constrained techniques but also over the greedy algorithm. Figure <ref type="figure" target="#fig_6">5b</ref> reports the replication factor, and clearly shows that HDRF is able to outperform all competing algorithms for all values of ?. At the extremes, HDRF is better than DBH when ? is very small and performs slightly better than greedy when ? is very large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Performance sensitivity to input order</head><p>A shortcoming of the standard greedy algorithm is its inability to effectively handle streams of input edges when they are ordered. If the input stream is ordered such that two subsequent edges always share a vertex, greedy always places all the edges and their adjacent vertices in a single partition, whatever the target partition number is. The final result is clearly far from being desirable as all of the computation load will be incurred by a single node in the computing cluster.</p><p>To overcome this limitation, we explicitly introduced the parameter ? in the computation of the score for each partition in HDRF (Equations ( <ref type="formula" target="#formula_10">6</ref>) and ( <ref type="formula" target="#formula_12">8</ref>)), that defines the importance of the load balance in the edge placement decision (Section 4). Figure <ref type="figure" target="#fig_7">6</ref> shows the result of an experiment run on the Netflix dataset, where the input stream of edges is ordered according to either a depth-first-search (DFS) or a breadth-first-search (BFS) visit on the graph. The figure shows the average replication factor (Figure <ref type="figure" target="#fig_7">6a</ref>), the size of the largest partition expressed as number of contained edges (Figure <ref type="figure" target="#fig_7">6b</ref>) and the size of the largest partition ex-   <ref type="figure" target="#fig_7">6b</ref> and<ref type="figure" target="#fig_7">6c</ref>). For ? &gt; 1 the CBAL factor starts to play a fundamental role in balancing the load among the available partitions: the average replication factor for HDRF with both DFS and BFS inputs is just slightly larger than what is achievable with a random input <ref type="foot" target="#foot_4">7</ref> and still substantially lower than what is achievable with PDS or hashing (Figure <ref type="figure" target="#fig_7">6a</ref>). At the same time, the size of the largest partition drops to its minimum (Figures <ref type="figure" target="#fig_7">6b</ref> and<ref type="figure" target="#fig_7">6c</ref>) indicating that the algorithm immediately delivers close to perfect load balancing (i.e. |E|/|P | edges per partition), while the number of vertices hosted in the largest partition reaches its minimum. By further increasing ? toward larger values, the effect of CBAL dominates the HDRF score computation and the algorithms behavior quickly approaches the behavior typical of hashing: large average replication factor, with close to perfect load balancing.</p><p>These results show that i) the CBAL term in HDRF score computation plays an effective role in providing close-toperfect load balancing among partitions while keeping a low average replication factor, and ii) by setting the value of ? slightly larger than 1, it is possible to let HDRF work at a "sweet spot" where it can deliver the best performance, even when working on an ordered stream of edges. This last point makes HDRF particularly suitable for application settings where it is not possible to randomize the input stream before feeding it to the graph partitioning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>Distributed graph-computing frameworks provide programmers with convenient abstractions to enable computation on large datasets. In these frameworks, system performance is often determined by the graph data partitioning strategy, which impacts the communication cost and the workload balance among compute resources. In this paper, we pro-posed HDRF, a novel stream-based graph partitioning algorithm for distributed graph-computing frameworks. HDRF is based on a greedy vertex-cut approach that leverages information on vertex degrees. Through a theoretical analysis and an extensive experimental evaluation on real-world as well as synthetic graphs using both a stand-alone partitioner and implementation of HDRF in GraphLab, we showed that HDRF is overall the best performing partitioning algorithm for graphs characterized by power-law degree distributions. In particular, HDRF provides the smallest average replication factor with close to optimal load balance. These two characteristics put together allow HDRF to significantly reduce the time needed to perform computation on graphs and makes it the best choice for partitioning graph data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Replication factor (log scale) with |P | = 133. HDRF is compared against streaming (a) and offline (b) solutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Load relative standard deviation produced by different partitioning algorithms on the Movie-Lens 10M dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Speedup in the execution time for the SGD algorithm on the Tencent Weibo dataset by applying HDRF with respect to greedy and PDS, with 32, 64 and 128 partitions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>reports the replication factor improvement for HDRF with respect to other algorithms, expressed as a multiplicative factor, by varying ? in the range [1.8, 4.0] with |P | = 128 target partitions (|P | = 133 and |P | = 121 for PDS and grid respectively). The curves show two important aspects of HDRF behavior:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Replication factor improvement for HDRF in synthetically generated graphs (log-log scale). Figure (a) reports the replication factor increment and Figure (b) the actual replication factor when ? grows (|P | = 128 except for PDS, where |P | = 133, and grid, where |P | = 121). For Figure (a) HDRF represents the baseline.</figDesc><graphic url="image-3.png" coords="9,391.75,297.01,160.68,114.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: HDRF behavior on the Netflix dataset varying ?, with input edge stream either random or ordered (DFS or BFS graph visits). Reference grey lines represent greedy, hashing and PDS performance.</figDesc><graphic url="image-1.png" coords="9,57.28,298.43,160.68,112.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Figure 1: Replication factor varying the number of target partitions (log-log scale). Statistics for real-world graphs.</figDesc><table><row><cell cols="2">16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">16</cell><cell></cell><cell></cell><cell></cell></row><row><cell>replication factor</cell><cell>2 4 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>replication factor</cell><cell>2 4 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">PDS grid hashing DBH</cell><cell>replication factor</cell><cell>2 4 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">PDS grid hashing DBH</cell><cell>replication factor</cell><cell>4 8 2</cell><cell></cell><cell></cell><cell></cell><cell>PDS grid hashing DBH</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>greedy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>greedy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>greedy</cell></row><row><cell></cell><cell>1</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128 256</cell><cell>1</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128 256 HDRF</cell><cell></cell><cell>1</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128 256 HDRF</cell><cell></cell><cell>1</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128 256 HDRF</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">partitions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">partitions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">partitions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">partitions</cell></row><row><cell></cell><cell></cell><cell cols="6">(a) Tencent Weibo</cell><cell></cell><cell></cell><cell cols="3">(b) Netflix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">(c) MovieLens 10M</cell><cell></cell><cell></cell><cell cols="4">(d) twitter-2010</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Dataset |V |</cell><cell></cell><cell></cell><cell>|E|</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Tencent Weibo 1.4M</cell><cell></cell><cell cols="2">140M</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Netflix 497.9K 100.4M</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">MovieLens 10M 80.6K</cell><cell></cell><cell>10M</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">twitter-2010 41.7M</cell><cell></cell><cell cols="2">1.47B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use scale-free and power-law graphs synonymously.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>During experiments, we noticed no significant improvements in the algorithm performance when using exact degrees instead of their approximate values.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>Note that the scope of Metis is to balance vertex load among partitions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>We needed to use respectively 31, 57 and 133 partitions, to fit PDS constraints.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>The difference is due to HDRF 's usage of partial information on vertex degrees. Such values are not a good proxy of real vertex degrees if the input stream is not random.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>* This work has been partially supported by the <rs type="programName">TENACE PRIN Project</rs> (n. 20103P34XC) funded by the <rs type="funder">Italian Ministry of Education, University and Research</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Kc8KBD3">
					<orgName type="program" subtype="full">TENACE PRIN Project</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Error and attack tolerance of complex networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barab?si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">406</biblScope>
			<biblScope unit="issue">6794</biblScope>
			<biblScope unit="page" from="378" to="382" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Balanced graph partitioning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Andreev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>R?cke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual ACM Symposium on Parallelism in Algorithms and Architectures</title>
		<meeting>the 16th Annual ACM Symposium on Parallelism in Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The netflix prize</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lanning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD cup and workshop</title>
		<meeting>KDD cup and workshop</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Layered label propagation: A multiresolution coordinate-free ordering for compressing social networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World Wide Web</title>
		<meeting>the 20th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The webgraph framework i: compression techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on World Wide Web</title>
		<meeting>the 13th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Network robustness and fragility: Percolation on random graphs</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Strogatz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page">5468</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Resilience of the internet to random breakdowns</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ben-Avraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Havlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page">4626</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Breakdown of the internet under intentional attack</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ben-Avraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Havlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">3682</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evolution of networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Dorogovtsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in physics</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1079" to="1187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Understanding Big Data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eaton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Deroos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lapis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zikopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Mc Graw Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved approximation algorithms for minimum weight vertex separators</title>
		<author>
			<persName><forename type="first">U</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hajiaghayi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="629" to="657" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Powergraph: Distributed graph-parallel computation on natural graphs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th USENIX Symposium on Operating Systems Design and Implementation</title>
		<meeting>the 10th USENIX Symposium on Operating Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Perfect difference sets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Halberstam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Glasgow Mathematical Association</title>
		<meeting>the Glasgow Mathematical Association</meeting>
		<imprint>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graphbuilder: Scalable graph etl framework</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Willke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st International Workshop on Graph Data Management Experiences and Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A fast and high quality multilevel scheme for partitioning irregular graphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on scientific Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="359" to="392" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SBV-Cut: Vertex-cut based graph partitioning using structural balance vertices</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Candan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="285" to="303" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed graphlab: a framework for machine learning and data mining in the cloud</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="716" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graphlab: A new framework for parallel machine learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 26th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pregel: a system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">G</forename><surname>Malewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Austern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Dehnert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Leiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Czajkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD International Conference on Management of data</title>
		<meeting>the 2010 ACM SIGMOD International Conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Managing large dynamic graphs efficiently</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The tencent dataset and kdd-cup&apos;12</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalessandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Perlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hamner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD-Cup Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gasgd: stochastic gradient descent for distributed asynchronous matrix completion via graph partitioning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Querzoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Conference on Recommender systems</title>
		<meeting>the 8th ACM Conference on Recommender systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Powerlyra: Differentiated graph computation and partitioning on skewed graphs</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGOPS European Conference on Computer Systems</title>
		<meeting>the 10th ACM SIGOPS European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fennel: Streaming graph partitioning for massive scale graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tsourakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gkantsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Radunovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vojnovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM international conference on Web search and data mining</title>
		<meeting>the 7th ACM international conference on Web search and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient and simple generation of random simple connected graphs with prescribed degree sequence</title>
		<author>
			<persName><forename type="first">F</forename><surname>Viger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Latapy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing and Combinatorics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Distributed power-law graph computing: Theoretical and empirical analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards effective partition management for large graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2012 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
