<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FaiRR: Faithful and Robust Deductive Reasoning over Natural Language</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-19">19 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
							<email>soumyasa@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Harman</forename><surname>Singh</surname></persName>
							<email>harmansingh.iitd@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Delhi</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
							<email>xiangren@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FaiRR: Faithful and Robust Deductive Reasoning over Natural Language</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-19">19 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2203.10261v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Transformers have been shown to be able to perform deductive reasoning on a logical rulebase containing rules and statements written in natural language. Recent works show that such models can also produce the reasoning steps (i.e., the proof graph) that emulate the model's logical reasoning process. Currently, these black-box models generate both the proof graph and intermediate inferences within the same model and thus may be unfaithful. In this work, we frame the deductive logical reasoning task by defining three modular components: rule selection, fact selection, and knowledge composition. The rule and fact selection steps select the candidate rule and facts to be used and then the knowledge composition combines them to generate new inferences. This ensures model faithfulness by assured causal relation from the proof step to the inference reasoning. To test our framework, we propose FAIRR (Faithful and Robust Reasoner) where the above three components are independently modeled by transformers. We observe that FAIRR is robust to novel language perturbations, and is faster at inference than previous works on existing reasoning datasets. Additionally, in contrast to black-box generative models, the errors made by FAIRR are more interpretable due to the modular approach. 1 1 The source code of FAIRR has been made available at https://github.com/INK-USC/FaiRR. fact1: Charlie is blue. fact2: Charlie is round. fact3: Erin is kind. fact4: Dave is round. rule1: If someone is blue then they are kind. rule2: Round, kind people are white.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The field of AI has long pursued the goal of building systems that can automatically reason over some given explicit knowledge to generate conclusions and provide the reasoning steps involved in the process <ref type="bibr" target="#b14">(McCarthy, 1959;</ref><ref type="bibr" target="#b16">Newell and Simon, 1956)</ref>. Recently, <ref type="bibr" target="#b1">Clark et al. (2020)</ref> proposed a modern version of this problem, where the formal representation of knowledge is replaced by natural language statements in English. Further, conc2: Charlie is white.</p><formula xml:id="formula_0">fact1 rule1 fact2 conc1 rule2 conc2</formula><p>Figure <ref type="figure">1</ref>: Example of a theory, a statement, and a valid proof graph -An instance contains multiple facts and rules in blue and yellow respectively, followed by a statement in red. The proof graph describes the reasoning steps required to generate the statement.</p><p>they proposed a transformer-based model <ref type="bibr" target="#b29">(Vaswani et al., 2017)</ref> RuleTaker, that can predict if a candidate statement is entailed by the natural language statements, by emulating deductive reasoning. As shown in Figure <ref type="figure">1</ref>, in this deductive reasoning task, facts and rules from the rulebase are combined iteratively to generate intermediate inferences which eventually entails the statement. Note that the reasoning process implicitly involves two steps: determining which rules and facts to combine at each iteration, followed by using them to generate an intermediate conclusion.</p><p>While RuleTaker focuses on just predicting the statement entailment, some recent works <ref type="bibr" target="#b21">(Saha et al., 2020;</ref><ref type="bibr" target="#b27">Tafjord et al., 2021)</ref> have further developed systems that can also generate the reasoning steps (i.e., proof graph generation). However, these systems do not explicitly ensure the causality from the rule/fact selection to generating the intermediate inferences. Since these systems are inherently black-box models, it is unclear if such constraints are implicitly learned by the models without being enforced externally. This, in turn, questions the faithfulness of the model's internal reasoning process <ref type="bibr" target="#b10">(Lipton, 2018)</ref>. Because the model has access to the full theory at input, it might use additional parts of the theory, than just the predicted proof, to generate the inference.</p><p>In this paper, we address these shortcomings by developing a modularized framework to solve the deductive reasoning task. While existing methods generate both proofs and conclusions in a single step, in our framework we break this process into three steps: rule selection, fact selection, and knowledge composition. The rule selection step decides the relevant rule to use for an iterative inference step and fact selection uses this rule to select the relevant facts. Then, the knowledge composition step reasons using only the selected rule and facts to generate the next intermediate inference.</p><p>In Figure <ref type="figure" target="#fig_0">2</ref>, we show the model schematics for our system and contrast it with previous methods. Notably, we strictly restrict the information accessible at each step of our framework to make the reasoning process more faithful. For example, the fact selection step depends only on the selected rule, instead of all the rules in the rulebase. Additionally, the generated inference depends explicitly on the selected rule and facts, as opposed to all the rules and facts in prior works. This makes the proof graph a by-product of the selection steps as we don't need to generate any separate proofs. Since we constrain the inputs to each step, this also makes each subproblem easier to learn, leading to an overall more robust reasoning model.</p><p>To model these three steps, we develop FAIRR, in which each component is a transformer-based model learning to perform the modular tasks. Specifically, we use RoBERTa-based models <ref type="bibr" target="#b11">(Liu et al., 2019)</ref> for the two selection tasks and a T5based model <ref type="bibr" target="#b19">(Raffel et al., 2020)</ref> for the composition task. Similar to ProofWriter, we use synthetic rulebases to train FAIRR. To test the deductive reasoning capabilities in a more comprehensive way, we experiment with both existing deductive reasoning datasets and multiple newly-generated robustness dataset variants. Overall, we find that FAIRR is more robust to novel language perturbations than baselines. Additionally, our model is up to three times faster at inference due to the constrained input and outputs of different modules. Lastly, we find that the errors made by our model are more interpretable and easier to debug compared to baseline generative models. This further demonstrates the faithfulness of our modularized reasoning framework. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>Notations A theory T consists of a set of facts F = {f 1 , f 2 , . . . , f n } and rules R = {r 1 , r 2 , . . . , r m } expressed in natural language. An example of a theory is depicted in Figure <ref type="figure">1</ref>. Here, the sentences in the blue and yellow boxes are facts and rules, respectively. Further, a proof graph is a directed graph connecting facts and rules that describe how a specific inference can be obtained from the theory. In Figure <ref type="figure">1</ref>, the proof graph shows the steps involved in generating the inference "Charlie is white.". To generate the proof graph we may need to infer some intermediate conclusions c i . These inferences are considered as part of the extended facts in the theory. For example, in Fig. <ref type="figure">1</ref>, "Charlie is kind" is an intermediate inference required to generate the correct proof graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deductive Reasoning</head><p>The task of deductive reasoning is described as follows: given a theory T , and a statement s, predict if the theory supports the statement (entailment prediction) and if so, generate the proof graph that supports the statement (proof generation). For the example theory and statement in Figure <ref type="figure">1</ref>, we see that the statement is indeed entailed by the theory and the valid proof graph is shown for the same. The main goal of this task is to evaluate if a model can generate valid rea-soning chains in the form of proof graphs to justify its entailment prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reasoning Robustness</head><p>We consider an auxiliary task that evaluates the robustness of the reasoning abilities used by the model. Let P be a perturbation function that modifies a given theory T (statement s) to a theory T ′ (statement s ′ ), such that (T ′ , s ′ ) just has some surface changes in the natural language form but still requires the similar reasoning process as required for (T, s). A function that alters the subjects in the theory to unseen subjects is an example of such perturbation function. We perturb each theory statement pair (T, s) to create an equivalence set defined as the set</p><formula xml:id="formula_1">E (T,s) = {(T ′ 1 , s ′ 1 ) . . . (T ′ N , s ′ N )}, where each (T ′ k , s ′ k</formula><p>) is derived by perturbing the original theory, and N is the total such perturbations per theory. Note that it is possible to generate different</p><formula xml:id="formula_2">(T ′ k , s ′ k )</formula><p>pairs by controlling the stochasticity of P. The main goal of this task is to evaluate the consistency of the model's predictions with minimal variations in the input theory.</p><p>Evaluation Protocol We consider three main aspects for evaluating the model performance in our study: (1) Entailment accuracy measures how accurately the model is able to predict the true statement entailment. (2) Proof accuracy measures how accurately the model can predict a valid proof for the statement. Following <ref type="bibr" target="#b21">Saha et al. (2020)</ref>; <ref type="bibr" target="#b27">Tafjord et al. (2021)</ref>, we use the strict metric for proof evaluation, i.e., for a match to count, both the predicted proof should exactly match a gold proof and the entailment should be correctly predicted. (3) Consistency measures if the models are consistent in the entailment and proof prediction for different perturbation functions. For a theory statement pair (T, s) and its corresponding equivalence set E (T,s) , consistency is defined as</p><formula xml:id="formula_3">C = 1 N ∑ N k=1 1[f (T, s) = f (T k , s k )]</formula><p>, where f (⋅) is the model's prediction. We compute the average consistency for both entailment and proof predictions on an equivalence set and further average across the dataset to report the consistency.</p><p>3 The FAIRR Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Approach Overview</head><p>As illustrated by the example in Figure <ref type="figure">1</ref>, to reliably generate a proof graph through deductive reasoning, a model needs to generate multiple one-hop intermediate conclusions. This is the major limitation of models that use the theory to directly predict the proof (Figure <ref type="figure" target="#fig_0">2</ref> (a)), thus questioning the trustworthiness of the reasoning process. Next, it is also intuitive to see that in order to faithfully generate these intermediate inferences, a model should first determine the proof (i.e., know the rules and facts to use) and then use them to infer the conclusion. That is, there is a causal relation from determining the proof to then generating the conclusion. We note that ProofWriter ("Iter") lacks in this aspect. As shown in Figure <ref type="figure" target="#fig_0">2</ref> (b), it first generates the conclusion and then the corresponding proof.</p><p>Motivated by these points, we propose our causal reasoning framework which breaks the reasoning process into three desirable steps. As shown in <ref type="bibr">Figure 2 (c)</ref>, in our framework, first a rule r is selected using the rules and facts in the theory. Following that, some relevant facts are selected from the fact list based on the selected rule r. This step does not use the other rules R\{r} in the theory. Finally, the selected rule and facts are jointly used to generate a new conclusion c i . In this framework, the one-step proof is explicitly determined first via the selection steps followed by the inference generation, making the proof a by-product of the whole process. In contrast, prior works learned to generate the proof along with intermediate conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">FAIRR Modules</head><p>At a high level, FAIRR is an iterative model in which the one-hop intermediate conclusions are generated step-by-step. To model our framework described in Sec. 3.1, we have four components in FAIRR as follows.</p><p>Rule Selector (RS) The rule selector is a RoBERTa-based <ref type="bibr" target="#b11">(Liu et al., 2019)</ref>  </p><formula xml:id="formula_4">[CLS] s [SEP ] r [[SEP ] f i ] n [SEP ] ,</formula><p>where s is the statement, r is the selected rule, and {f i } is the i th fact in the theory containing n total facts. Note that facts also include any previously generated intermediate conclusions. [ ] n denotes continued concatenation. The output is generated by classifying each <ref type="bibr">[SEP]</ref> token embedding in front of a fact using a linear layer, to determine if the corresponding fact is selected or not. An example input and output for the fact selector is depicted in Figure <ref type="figure" target="#fig_1">3</ref>. We note that it is possible to have some rules that can reason over multiple facts jointly to generate a conclusion. An example of such a rule is "rule2" in Figure <ref type="figure">1</ref>. Hence, this component has the ability to select multiple facts.</p><p>Knowledge Composer (KC) The knowledge composer is a generative text-to-text transformer T5 <ref type="bibr" target="#b19">(Raffel et al., 2020</ref>) (T5-large) that can compose a set of facts and a rule to output a novel conclusion. The input to the model is the selected facts and rule concatenated together, and the output is the intermediate conclusion. An example input and output for knowledge composer is shown in Fig. <ref type="figure" target="#fig_1">3</ref>.</p><p>Solver The final component is the solver that operates after all iterations have finished (i.e., once the rule selector selects the [CLS] token indicating to stop the iterative inference generation process). Similar to ProofWriter, our solver currently searches for the statement in the generated intermediate inferences (string matching). If found, it predicts that the statement is entailed by the theory. It also search for the negation of the statement<ref type="foot" target="#foot_0">2</ref> , and if found, it predicts not entailed. If none of these are present, it predicts "Unknown" since it cannot prove or disprove the statement. The proof graph is constructed by using the one-hop proofs generated by the selected rule and facts at each step. For example, in Figure <ref type="figure">1</ref>, the red dotted boxes (onehop proofs) are stitched together to assemble the complete proof. For cases where the entailment is "Unknown", the proof returned is "None", since no proof for note that our solver is not a learnable module.</p><formula xml:id="formula_5">[CLS] s [SEP] f 1 f 2 f 3 [SEP] r 1 [SEP] r 2 [SEP] 0 1 0 Rule Selector [CLS] s [SEP] r 1 [SEP] f 1 [SEP] f 2 [SEP] f 3 [SEP] 1 1 0 Fact Selector f 1 f 2 r 1 &lt;eos&gt; c 1 Knowledge Composer</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training and Inference</head><p>Each component of our model (except the solver, which is deterministic) is trained separately. We use the same dataset as ProofWriter to train these models, but process it such that each model receives only the relevant inputs according to our causal framework. More concretely, suppose for a given theory T = R + F , a possible intermediate inference is c obtained by using a rule r and a fact f . Then, a training instance of ProofWriter, which is a T5 <ref type="bibr" target="#b19">(Raffel et al., 2020)</ref> model, uses the input {R, F } and output {c, r, f }. We process the same instance to generate three training instances, one for each of rule selector, fact selector, and knowledge composer, respectively, as follows:</p><formula xml:id="formula_6">RS Input = {R, F }; RS Output = {r}, F S Input = {r, F }; F S Output = {f }, KC Input = {r, f }; KC Output = {c}.</formula><p>Our selector models have the statement s as input to the model. Also, the outputs of rule selector and fact selectors are converted to class labels instead of text since our selectors are classification models. We use cross entropy loss to train the rule selector, and binary cross entropy loss to train the fact selector. The knowledge composer is trained on language modeling loss.</p><p>At inference time, the rule selector selects a rule to be used for generating one-step conclusions. Then, the fact selector selects some facts based on the selected rule, which is then collectively passed on to the knowledge composer to generate a conclusion. This three-step pipeline is run iteratively until the rule selector predicts a stop signal by selecting the [CLS] token which exits the iteration. Once the iteration finishes, the solver uses the generated intermediate inferences to decide if the statement is entailed or not, and generates a proof accordingly.</p><p>Remark on Computational Complexity A practical limitation of ProofWriter is that it performs an exhaustive forward search by enumerating all possible inferences from a given theory. This leads to redundant inferences being generated for proving a particular statement. Additionally, using a text-to-text transformer model adds to the problem since it is usually quite expensive to run at inference time. In FAIRR, we alleviate this by introducing two changes. First, our causal framework allows only selected rule and facts as input to the knowledge composer, thus restricting the input length significantly. Second, augmenting the question to our selector inputs helps reduce the candidate space because these models can learn to prioritize the selection based on the relevance to both the question and the theory. This ensures that FAIRR does not perform an exhaustive forward search and prioritizes generating relevant inferences over the others. Both these changes lead to an overall improvement in inference speed. We perform more quantitative analysis on this later in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>Datasets Following <ref type="bibr" target="#b27">(Tafjord et al., 2021;</ref><ref type="bibr" target="#b1">Clark et al., 2020)</ref>, we use the D* datasets for our experiments. These are a set of multiple datasets -namely D0, D1, D2, D3, D0-D3, and D5. The theory in these datasets are synthetically generated with increasing reasoning depths. For example, D3 dataset contains statements that require at most 3-hop reasoning steps. The D0-D3 contains all theories in D3 plus ∼ 20% of the D0-D2 training set theories. We also use the ParaRules dataset <ref type="bibr" target="#b1">(Clark et al., 2020)</ref> that contains around 2k theories expressed in paraphrased natural language.</p><p>Additionally, we generate three datasets that evaluate the robustness of the reasoning models as follows:</p><p>• Subject robustness: Here, subjects in a theory are perturbed by using some out-ofdistribution proper and common names. For example, in Figure <ref type="figure">1</ref>, "Charlie" can be replaced with "Paul" which is not used in the D* datasets. We generate five new theories corresponding to each theory of the D3 dataset, by repeatedly perturbing all the proper and common names in the theory. • Attribute robustness: Here we sample outof-distribution attributes. For example, "blue" in Figure <ref type="figure">1</ref> can be replaced with "soft". As above, we generate five new theories for each theory of the D3 dataset. • Subject+Attribute robustness: This is a combination of subject and attribute robustness to study model performance when most of the training vocabulary is replaced by outof-distribution words. Each theory has both novel subject and attribute.</p><p>We include more details on the perturbation sets used in our experiments in Appendix B.</p><p>Baselines We compare FAIRR with two variants of ProofWriter <ref type="bibr" target="#b27">(Tafjord et al., 2021)</ref>: All-at-once (PW ("All")) and Iterative (PW ("Iter")), wherever applicable<ref type="foot" target="#foot_1">3</ref> . The PW ("All") model is trained to predict the entailment and generate proof graph directly from the theory and statement in a single step. The PW ("Iter") generates one-step inferences and corresponding proofs iteratively, until all possible inferences are generated, and then stitches the proof graph similar to our method. If not mentioned otherwise, ProofWriter uses a T5-large <ref type="bibr" target="#b19">(Raffel et al., 2020)</ref> model. We omit comparisons with PRover since it was trained on a different dataset that adds specific constraints on the proof graph. Please refer to Appendix J for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment Results</head><p>We compare FAIRR with ProofWriter variants on three settings: generalization on D* datasets, robustness to perturbed theories, and efficiency in inference computation. We further conduct qualitative analysis to understand the inference errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Performance on Same Depth Reasoning</head><p>In this setting, we train and test both models on D0-D3 dataset. Note, D0-D3 contains statements with reasoning depths up to 3. This compares the ability of the models to generalize to seen reasoning depths at train time. The results with increasing depths of reasoning are shown in Table <ref type="table">1</ref>. Here, depth "N/A" refers to statements that cannot be proven and hence don't have an exact proof depth associated with it. We observe that overall both FAIRR and ProofWriter ("Iter") performs comparably (last row with depth 'All'). Further, we find that our model's performance is lower on d = 3, indicating that our models tend to perform weaker with increasing depths. This happens majorly because the rule selector in FAIRR tends to incorrectly select the Table <ref type="table">3</ref>: Comparison of FAIRR with ProofWriter ("Iter") trained on D0-D3 and tested on subject robustness dataset. Baseline results are generated using the checkpoint provided by the authors. For more details please refer to Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Robustness to Perturbed Theories</head><p>In this section, we test the robustness of ProofWriter ("Iter") and FAIRR on different perturbed theories. Since FAIRR focuses on making deductive reasoning more robust and faithful, performance on these robustness experiments are the main results of our work. As described in Section 4, we test the robustness on three different perturbations: subject, attribute, and subject+attribute. We compare the performance of both models after training on D0-D3 dataset. The consolidated results are shown in Table <ref type="table">2</ref> and depth-wise results for subject robustness are shown in Table <ref type="table">3</ref>. We report the entailment accuracy, proof accuracy, and consistency as defined in Section 2. Please refer to appendix D for the depth-wise breakdown of all the datasets. We observe that on subject and subject+attribute robustness, our models are consistently better than ProofWriter whereas on attribute robustness both models perform similarly. Further, we find that on average, FAIRR is both more accurate and consistent than the baseline. From this, we conclude that our model relies less on spurious correlations based on the subject while both models likely suffer from similar issues on attribute perturbations. Since ProofWriter uses the theory to generate the intermediate conclusion and proofs, it has the capacity to exploit some spurious patterns that can inflate performance. In contrast, our causal framework restricts this capacity by constraining the inputs to each component as described in Section 3.1. Hence, these robustness evaluations demonstrate one of the prime benefits of our causal and modular approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Study on Inference Efficiency</head><p>Here we perform several analyses to evaluate the computational benefits of our method as described in Section 3.3. Inference efficiency is an important aspect of this problem for real-world scenarios where compute can be limited. In Figure <ref type="figure">4</ref>, we plot the precision and recall for both FAIRR and ProofWriter ("Iter") with increasing reasoning depths. We find that our model has close to 1.0 precision at all depths, whereas ProofWriter has low precision. This demonstrates that our model is able to successfully prune the candidate inference space to generate relevant candidate inferences almost perfectly. In contrast, we see that with increasing depths, our model's recall reduces from close to 1.0 to ≈ 0.95 whereas ProofWriter has a perfect recall at all depths. While the drop is not very drastic, it indicates that our model fails to generate some essential inferences at higher depths. This is mainly because our rule selector decides to stop early and not generate further relevant inferences for some provable statements. Overall, we conclude that FAIRR always generates inferences that are relevant to solving the instance, although at higher depths it can miss some relevant conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevance of generated inferences</head><p>Performance under inference budget constraints We analyze the performance of FAIRR and ProofWriter under a fixed inference budget constraint by restricting the total number of conclusions that can be generated. We perform this analysis for different reasoning depths and depict the results in Figure <ref type="figure">5</ref>. We observe that FAIRR consistently outperforms ProofWriter on lower budgets. This shows that FAIRR performs a prioritized generation of conclusions that are relevant to the statement, which can be useful in scenarios with limited inference budgets. See Appendix G for more comparisons.</p><p>Inference runtime analysis We next compare the time taken by both the models to solve the complete D5 dev set. Although FAIRR has three separate modules that run sequentially, it is 3.5 times faster than ProofWriter ("Iter") at inference time on average. We attribute this to the reduced inference candidate search space due to question augmentation, and smaller input size to the T5 component (refer to Section 3.3 for details). Please refer to Appendix H for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Error Analysis</head><p>We further analyze the different errors made by FAIRR and ProofWriter ("Iter") on 50 randomly sampled errors for each model, from the D0-D3 and the subject robustness dev splits. We manually inspect the proof inferences and compare it with the gold proof to classify the failures. The errors are broadly categorized as follows:</p><p>Early stop errors: This is the most frequent error type for both models, accounting for 80% and 50% errors in FAIRR and ProofWriter, respec- tively. This occurs when a model incorrectly generates the stop signal and fails to generate all the required inference to prove a statement. We find that our model makes the majority of the mistakes due to early stopping. This can be possibly fixed by improving the rule selector architecture to better model the stop criteria.</p><p>Wrong inference: This is the second error type, where the inferred conclusion is incorrect based on the predicted proof. This accounts for 20% and 30% errors in FAIRR and ProofWriter, respectively. We observe that our knowledge composer is makes lesser errors on average compared to the ProofWriter generative model.</p><p>Other generation errors: ProofWriter makes around 20% errors where the model generated output does not make sense. For example, it can hallucinate facts that are not present in the theory. Such errors are not interpretable and questions the model's inner-working. FAIRR shows no such error, since the proofs are always interpretable in our model due to the causal framework.</p><p>Overall, we find that the errors made by FAIRR are more interpretable than ProofWriter, since we can pin-point which module is at fault. Whereas, in ProofWriter, it is sometimes hard to understand the source of errors. This feature also makes our framework easier to debug to potentially fix some components with techniques like data augmentation. Please refer to Appendix I for more discussion and examples of errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">ProofWriter Input Ablation</head><p>A key goal of FAIRR is to explicitly ensure causality from the rule/facts selection step (proof generation) to the reasoning step (intermediate inference generation). This is essential for a reasoning method using forward chaining to solve a deductive reasoning task<ref type="foot" target="#foot_2">4</ref> . To understand if ProofWriter, which uses forward chaining, implicitly does this "select-then-reason" within the model, we perform the following case study: We sample theories from our subject perturbation dataset where ProofWriter made errors, and manually evaluate the model on inputs with all irrelevant rules/facts deleted.</p><p>Next we sequentially start adding back the deleted rules/facts to see if the output still remains valid.</p><p>As shown in Table <ref type="table" target="#tab_4">4</ref>, we see that ProofWriter generates a correct inference for the first row which uses just the essential part of the theory required to generate the conclusion, and starts making errors as more sentences are included. Some more examples are shown in Table <ref type="table" target="#tab_6">16</ref> in Appendix. This shows that internally ProofWriter is unable to faithfully perform the "select-then-reason" steps for larger theories. In contrast, FAIRR explicitly separates these steps, leading to a faithful reasoning model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Works</head><p>Reasoning in Text Reasoning in text is a well studied problem in NLP. Natural Language Inference (NLI) <ref type="bibr" target="#b2">(Dagan et al., 2006)</ref> is one of the most prominent tasks that require reasoning over text to answer if a statement is entailed, contradicted, or neutral, given a hypothesis. More recently, datasets like HotpotQA <ref type="bibr" target="#b35">(Yang et al., 2018)</ref>, bAbI <ref type="bibr" target="#b33">(Weston et al., 2016)</ref>, QuaRTz <ref type="bibr" target="#b28">(Tafjord et al., 2019)</ref>, ROPES <ref type="bibr" target="#b9">(Lin et al., 2019)</ref>, CLUTRR <ref type="bibr" target="#b25">(Sinha et al., 2019)</ref>, etc., have studied different aspects of reasoning over textual inputs. These tasks usually require implicit reasoning, where the model needs to internally infer the rules required to solve the task. In contrast, RuleTaker <ref type="bibr" target="#b1">(Clark et al., 2020)</ref> deals with explicit reasoning (also known as deductive reasoning).</p><p>Proof Generation Recently, some works have been addressing the problem of proof generation from an NL-based theory. Prover <ref type="bibr" target="#b21">(Saha et al., 2020)</ref> trains a RoBERTa-based model that predicts nodes and edges of the proof graph. ProofWriter <ref type="bibr" target="#b27">(Tafjord et al., 2021</ref>) is a T5-based <ref type="bibr" target="#b19">(Raffel et al., 2020)</ref> model, that iteratively generates one-hop conclusions and proofs from a theory. Another work Mul-tiProver <ref type="bibr" target="#b22">(Saha et al., 2021)</ref>, generates multiple possible proofs for a statement. While we study the same problem of proof generation similar to these works, we develop a more faithful and robust model designing a modular system for proof generation.</p><p>Formal Reasoning There are some prior works that try to solve the problem of entailment prediction by first parsing the formal language from text.</p><p>Neural Theorem Prover <ref type="bibr" target="#b20">(Rocktäschel and Riedel, 2017;</ref><ref type="bibr" target="#b32">Weber et al., 2019)</ref> uses neural networks to parse the formal logic from natural language and then reason over them. While this approach is more symbolic, it can lead to many challenges while parsing <ref type="bibr" target="#b8">(Kamath and Das, 2019)</ref>. The proof generation setting considered here bypasses this step and directly reasons over the given natural language text making it more useful in downstream applications.</p><p>Model Interpretability With the advent of pretrained language models (BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref>, RoBERTa <ref type="bibr" target="#b11">(Liu et al., 2019)</ref>, etc.), there has been an increasing trend on solving various reasoning tasks with high accuracy. Faithfulness of such models <ref type="bibr" target="#b7">(Jacovi and Goldberg, 2020)</ref> aims to understand whether the models are actually learning to solve the task or rather depending on some shortcut patterns. Saliency-based explanations <ref type="bibr" target="#b26">(Sundararajan et al., 2017;</ref><ref type="bibr" target="#b13">Lundberg and Lee, 2017;</ref><ref type="bibr" target="#b15">Murdoch et al., 2018;</ref><ref type="bibr" target="#b23">Sanyal and Ren, 2021)</ref> mainly focus on identifying the important phrases in the input text that helped the model in solving a task. In contrast, the task of proof generation focuses on generating a deductive chain of reasoning from the given theory to the concluded statement. Thus, proof chains are easier to understand for end users, making it more useful to debug any systematic model errors.</p><p>Causal Reasoning The study of causality and causal reasoning models <ref type="bibr" target="#b18">(Pearl, 2000</ref><ref type="bibr" target="#b17">(Pearl, , 2004;;</ref><ref type="bibr" target="#b24">Schölkopf, 2019)</ref> has been prevalent in machine learning. It has been applied in various domains such as algorithmic fairness <ref type="bibr" target="#b12">(Loftus et al., 2018)</ref>, gender bias mitigation <ref type="bibr" target="#b31">(Vig et al., 2020)</ref>, robustness from spurious correlations <ref type="bibr" target="#b0">(Bühlmann, 2020;</ref><ref type="bibr" target="#b30">Veitch et al., 2021)</ref>, counterfactual explanations <ref type="bibr" target="#b5">(Feder et al., 2021b)</ref>, etc. Causality in NLP is particularly important to learn models that go beyond exploiting correlations and to improve their overall faithfulness <ref type="bibr" target="#b4">(Feder et al., 2021a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we proposed FAIRR, a faithful and robust deductive reasoning model based on three modular components: rule selection, fact selection, and knowledge composition. FAIRR ensures causality from proof generation to entailment prediction by design. We established the effectiveness of our approach through experiments on testing robustness to language variations and demonstrating the interpretability of the errors made by our model. We also show that FAIRR is faster and more precise at deductive reasoning than prior baselines. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Depth Dataset Details</head><p>For training and evaluation of FAIRR and ProofWriter, we use the D* datasets and the ParaRules dataset <ref type="bibr" target="#b1">(Clark et al., 2020)</ref>. The statistics of these datasets are shown in Table <ref type="table" target="#tab_5">5</ref> which includes the number of theories, the total number of questions across all theories, and the number of conclusions per theory. The statistics are broken down split wise. We use the same splits of train/dev/test as provided in the original datasets <ref type="bibr" target="#b1">(Clark et al., 2020;</ref><ref type="bibr" target="#b27">Tafjord et al., 2021)</ref>. All the dataset sources are properly cited and used according to the release license.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Robustness Dataset Details</head><p>The robustness dataset is created by replacing all subjects (attributes, subject+attributes) in the D3 dataset with unseen subjects (attributes, sub-ject+attributes) to create the subject (attribute, sub-ject+attributes) robustness set. For this, we first curate new sets of subjects and attributes to be used as a global pool to sample from while replacing existing subjects and attributes from the theory. These  <ref type="bibr">'orange', 'cordial', 'friendly', 'adorable', 'old', 'soft', 'violent', 'intelligent', 'square', 'warm', 'large', 'cylindrical', 'spherical', 'tiny', 'microscopic', 'brilliant', 'noisy', 'playful', '</ref>tender', 'gracious', 'patient', 'funny', 'hilarious', 'thorny', 'sensitive', 'diplomatic', 'thoughtful'} Then, for each theory in the D3 dataset, we replace all the subjects in the theory with randomly sampled subjects (without replacement) from the candidate set to create a perturbed theory. We perform this replacement operation to generate five different perturbed theories. These perturbed theories are called equivalence set. Note that the only change in each theory in an equivalence set is the subjects being replaced by some randomly sampled subjects. For example, "cat" in the original theory might be replaced by "child" in one perturbation, and with "teacher" in yet another perturbation. We follow the same procedure to create attribute and Table <ref type="table">7</ref>: D5 dataset depth-wise performance comparison of FAIRR trained on D0-D3 with ProofWriter ("All") and ProofWriter ("Iter") trained on D3 and D0-D3 respectively. Baseline results are copied from <ref type="bibr" target="#b27">Tafjord et al. (2021)</ref>. Refer to Section 5.1 and Appendix C for more details.</p><p>subject+attribute robustness sets. The statistics for these robustness datasets are shown in Table <ref type="table" target="#tab_6">6</ref> which includes the dataset name depicting the perturbation type (subject, attribute or subject+attribute), number of theories, the total number of questions across all theories, and the number of conclusions per theory. Please note that one theory has multiple questions in general, and it is possible to have conclusions that are not a part of these questions, but can be deduced from the given theory. Each split of the original dataset is perturbed separately as described above, to create the new datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Generalization to Reasoning Depths</head><p>In this section, we experiment with a setting where models are trained on depths less than or equal to 3 (i.e., d ≤ 3) and tested on D5 dataset that contains statements that require reasoning up to depth 5 (i.e., d ≤ 5). Here, we test the generalization of the models to reasoning depths that are unseen at training time. These results are shown in Table <ref type="table">7</ref>. From this table, we observe that overall our model performs significantly better than ProofWriter ("All") on proof accuracy (+7.5%), but has a lower performance compared to ProofWriter ("Iter") (−3%). This shows that compared to ProofWriter ("Iter"), our models are weaker at generalizing to unseen reasoning depths. This happens majorly because our rule selector tends to stop the inference iterations earlier, which means some essential inferences are not generated by the model. Thus, this leads to lower performance with increasing reasoning depths.</p><p>But, we make another interesting observation here. The drops in entailment and proof accuracy with increasing depths are similar for FAIRR. For instance, considering the performance drops between d = 4 to d = 5, FAIRR has ∼ 9.5% drop in both entailment and proof accuracy. In contrast, ProofWriter ("All") and ProofWriter ("Iter") drops approximately 22% and 11%, respectively in proof accuracy for a mere 1% drop in entailment accuracy. This raises some concern on the causality of the proof generation process used for entailment prediction in these models, since it seems like the answer prediction and proof generation are not dependent via the same reasoning paths. In contrast, our causal framework grounds the entailment prediction to the proofs and this leads to more consistent performance variations in FAIRR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Robustness to Perturbed Theories</head><p>Here, we show the detailed depth-wise performance of FAIRR and ProofWriter ("Iter") trained on D0-D3 dataset and evaluated on different robustness datasets as described in Section 4. The results for subject, attribute, and subject+attribute  robustness evaluations are shown in Tables <ref type="table">8, 9</ref>, and 10, respectively. We observe that ProofWriter ("Iter") performs significantly worse compared to FAIRR on subject robustness. The results on sub-ject+attribute robustness are mostly comparable, while in attribute robustness our model performs worse. The drop in performance show that both the models are sensitive to attributes in the theory to varying degree. But the strong sensitivity of ProofWriter ("Iter") to the subject perturbations is questionable, since the causality of the model's reasoning process seems to be compromised because the model learns some spurious correlations using the subjects.</p><p>In another setting, we train different components of our model on the robustness data and check if that leads to some performance gains. These results are reported in Table <ref type="table">11</ref>. We find that it is indeed possible to improve the performance of individual components of our model by robust data augmentation. This also indicates that our individual components are flexible to intervention by data augmentation. Such abilities are lacking in ProofWriter. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Generalization to paraphrased theories</head><p>Here we test the ability of our model to generalize to unseen language in ParaRules by using limited training supervision. To test this, we first train our model on D0-D3 dataset and test it on the ParaRules dataset. This is a zero-shot evaluation on an unseen language form. In Figure <ref type="figure" target="#fig_3">6</ref> we observe that the performance is significantly worse on this setting as expected. We also evaluated a checkpoint of ProofWriter ("Iter") trained on D0-D3 which achieves a similar performance of 62.13% entailment accuracy<ref type="foot" target="#foot_3">5</ref> . Next, we gradually start adding portions of ParaRules, along with the D0-D3 data, to the training dataset. We find that FAIRR can quickly achieve reasonable performance using even 10% additional data. This shows that our modularized approach is also efficient in adapting to unseen theories with limited data supervision. For more comparisons with models trained on ParaRules, please refer to Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Results on ParaRules training</head><p>Following <ref type="bibr" target="#b27">(Tafjord et al., 2021)</ref>, we compare the performance of ProofWriter ("All") and FAIRR on the ParaRules dataset, when trained on a combined partition of D3 and ParaRules train set. The ParaRules dataset contains complex linguistic expressions in the theories that are more realistic than D* dataset theories, making it a more challenging dataset. These results are shown in Table <ref type="table">12</ref>, with a reasoning depth breakdown as before. We note that numbers for ProofWriter ("Iter") are not reported in the paper, and no trained checkpoint is available either, so we omit it from our comparisons. Also, the reported results for ProofWriter ("All") are from evaluating a T5-11B model while ours is a T5-large model. Here, we see that our model performs better at higher depths compared to the baseline which demonstrates that FAIRR is better at handling paraphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Inference Budget Analysis</head><p>In the inference budget analysis, we compare the performance of FAIRR and ProofWriter under an inference budget constraint, i.e., we restrict the total number of intermediate conclusions that can be produced by both models. We perform this analysis on three different depth datasets (d = {1, 3, 5}) and upper bound the number of inferences by B = {1, 3, 5, 7, 10}. We ensure that the budget is at least equal to the depth of the statements under consideration since proving a statement requires a model to generate inferences equal to at least the depth. From Figure <ref type="figure" target="#fig_4">7</ref> we observe that for all depths FAIRR consistently outperforms ProofWriter on lower budgets. Only when the budget increases to 10, ProofWriter compares with or sometimes outperforms our model. This analysis demonstrates that FAIRR performs a prioritized generation of conclusions that are relevant to the statement, which can be useful in scenarios with limited inference budgets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Runtime Analysis</head><p>For inference runtime analysis, we time the evaluation of both FAIRR and ProofWriter ("Iter") on D5 dev set. Note that D5 dataset contains statements that require at most five reasoning steps to generate an answer. The runtime for both methods are shown in Table <ref type="table" target="#tab_11">13</ref>. These results were obtained by running the inference algorithm on NVIDIA GeForce RTX 2080 Ti GPUs for both models. We observe that ProofWriter ("Iter") has an almost constant runtime since it always generates all possible inferences for a theory. In contrast, our runtime increases almost linearly with increasing depth. On average, FAIRR is 3.5 times faster at inference than ProofWriter ("Iter").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Error Analysis</head><p>This is a follow-up of Section 5.4, where we delve deeper into the error analysis by discussing different error examples and their potential reasons. First, the stop errors are easy to understand. These are cases where the model just decides to stop in- stead of generating any further conclusions. For our model, this can happen if the rule selector is under confident while selecting rules and it learns that a safer fallback is to stop generating rules. This aspect can probably be improved by a better modeling of the rule selector. We plan to explore this in future works.</p><p>Next we look at some of the wrong inferences generated by both models in Tables <ref type="table" target="#tab_5">14 and 15</ref>. We observe that errors made by FAIRR are rather naive with small mistakes in the final conclusion (shown in red in Table <ref type="table" target="#tab_5">15</ref>). In contrast, ProofWriter tends to generate an invalid conclusion with no relation to the generated proof (rows 1 and 2 in Table <ref type="table" target="#tab_4">14</ref>). It also makes many non-interpretable generation errors where the model's output format is completely violated or the model seems to hallucinate some facts (rows 3-6 in Table <ref type="table" target="#tab_4">14</ref>). Thus, we observe the benefit of our causal framework as the errors are interpretable and more believable. In contrast, errors made by ProofWriter clearly show that its inference reasoning process can often not rely on the proof at or, or even the generated proof sometimes doesn't make sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J Comparison with Baselines</head><p>In this work we compare FAIRR with baselines introduced by <ref type="bibr" target="#b27">(Tafjord et al., 2021)</ref>. We omit comparisons with both PRover <ref type="bibr" target="#b21">(Saha et al., 2020)</ref> and multiPRover <ref type="bibr" target="#b22">(Saha et al., 2021)</ref>, since they were trained on a different dataset that makes a closedworld assumption (CWA), whereas we use datasets that make an open-world assumption (OWA). One essential difference between these two datasets are that OWA allows for predicting the truth values as one of {True,False,Unknown} while in CWA, any fact that cannot be deduced from the theory is assumed to be false. As a result, in CWA, there are only two possible truth values {True,False} for a given statement. This CWA assumption also leads to a specific constraint in the generated proof graphs, where special N AF nodes need to be considered. Please refer to <ref type="bibr" target="#b21">Saha et al. (2020)</ref> for more details on this. Additionally, multiPRover <ref type="bibr" target="#b22">(Saha et al., 2021)</ref> has a goal that is different from ours. Specifically, their focus is on generating multiple possible proofs for a given rulebase, and for this their training examples contain multiple gold proofs per instance. In FAIRR and ProofWriter <ref type="bibr" target="#b27">(Tafjord et al., 2021)</ref>, only one gold proof needs to be generated, making the comparisons a bit unfair. Following <ref type="bibr" target="#b27">Tafjord et al. (2021)</ref>, we report single run numbers for every experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K Hyperparameters</head><p>We use RoBERTa-large models <ref type="bibr" target="#b11">(Liu et al., 2019)</ref> to model the rule selector and fact selector in FAIRR. For selecting the best hyperparameters for both these components, we selected the max training epochs in: {10, 15, 20}, warmup updates in: {0.05, 0.1}, weight decay in: {0.1, 0.01, 0.001}, learning rate in: {3e-6, 5e-6, 1e-6}, and batch size in {16, 32}.</p><p>We use T5 <ref type="bibr" target="#b19">(Raffel et al., 2020</ref>) (T5-large) to model the knowledge composer in FAIRR and train it using the default hyperparameters available in the Hugging Face transformers library <ref type="bibr" target="#b34">(Wolf et al., 2020)</ref>. All models were trained on Nvidia Quadro RTX 8000 GPUs. Training a FAIRR on a single GPU takes around 20 hours on average.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Reasoning process in different models. (a): ProofWriter ("All") directly output the entailment prediction and proof graph for given input. (b): ProofWriter ("Iter") iteratively generates the one-step intermediate conclusions and their proofs. (c): FAIRR selects a rule, then a fact, and finally combines them to generate an intermediate inference. Note that the proof is implicitly determined by the selection steps. Please refer to Section 3.1 for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of components of FAIRR -The rule selector and fact selectors are classification models whereas the knowledge composer is a generation model. The input tokens used for classification by the selectors are highlighted. Rule selector decides to stop based on the output prediction of [CLS] token (highlighted in green). Here, rule r 1 , and facts f 1 and f 2 are used to generate the conclusion c 1 . Please refer to Section 3.2 for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: Comparison of ProofWriter ("Iter") and FAIRR on precision and recall of generated inferences with increasing reasoning depths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Proof Accuracy of FAIRR when tested on ParaRules while using limited amount of ParaRules along with D0-D3 for training. See Appendix E for more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Depth-wise comparison of ProofWriter ("Iter") and FAIRR (both trained on D0-3 dataset) on limited inference budgets. Please refer to Appendix G for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Here, we study the relevance of the intermediate inferences generated by FAIRR and ProofWriter ("Iter"). Let T be the set of intermediate inferences required for generating the proof graph for the statement. Further, let G be the set of intermediate inferences actually generated by a model. Then, the precision and recall are defined as P =</figDesc><table /><note>|T ∩G| |G| , and R = |T ∩G| |T |</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>If someone is blue then they are quiet. s 2 : Chris is blue. s 3 : Steve is blue. Dave is quiet. (s 1 , s 2 ) s 1 : If someone is blue then they are quiet. s 2 : Quiet people are cold. s 3 : Chris is blue. s 4 : Steve is blue. s 5 : Chris is white. Examples of inferences made by ProofWriter. Blue text denotes incrementally added sentences in the theory and red text denotes an error. The (⋅) is the generated proof. Refer to Section 5.5 for more details.</figDesc><table><row><cell>Input</cell><cell>Output</cell></row><row><cell>s 1 : If someone is blue then they are quiet. s 2 :</cell><cell>Chris is quiet.</cell></row><row><cell>Chris is blue.</cell><cell>(s 1 , s 2 )</cell></row><row><cell cols="2">s 1 : Dave is quiet.</cell></row><row><cell></cell><cell>(s 1 , s 4 )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Statistics of datasets introduced by Tafjord et al., 2021 with the number of theories, questions and conclusions per theory for all three splits of each dataset. The splits are kept the same as the original dataset. Please refer to Appendix A for more details.</figDesc><table><row><cell cols="3">Dataset Split Number</cell><cell>Number</cell><cell>Number of</cell></row><row><cell></cell><cell></cell><cell>of The-</cell><cell>of</cell><cell>Conclusions</cell></row><row><cell></cell><cell></cell><cell>ories</cell><cell>Ques-</cell><cell>per Theory</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tions</cell><cell>(min/mean/max)</cell></row><row><cell></cell><cell>train</cell><cell>18889</cell><cell>69906</cell><cell>0/0.81/18</cell></row><row><cell>D0</cell><cell>dev</cell><cell>2700</cell><cell>10070</cell><cell>0/0.81/14</cell></row><row><cell></cell><cell>test</cell><cell>5389</cell><cell>20024</cell><cell>0/0.8/12</cell></row><row><cell></cell><cell>train</cell><cell>9008</cell><cell>69616</cell><cell>1/1.69/13</cell></row><row><cell>D1</cell><cell>dev</cell><cell>1318</cell><cell>10188</cell><cell>1/1.7/14</cell></row><row><cell></cell><cell>test</cell><cell>2607</cell><cell>20210</cell><cell>1/1.7/12</cell></row><row><cell></cell><cell>train</cell><cell>6330</cell><cell>70076</cell><cell>2/3.15/14</cell></row><row><cell>D2</cell><cell>dev</cell><cell>909</cell><cell>10094</cell><cell>2/3.09/12</cell></row><row><cell></cell><cell>test</cell><cell>1794</cell><cell>19840</cell><cell>2/3.11/14</cell></row><row><cell></cell><cell>train</cell><cell>4816</cell><cell>69388</cell><cell>3/4.81/16</cell></row><row><cell>D3</cell><cell>dev</cell><cell>719</cell><cell>10302</cell><cell>3/4.73/14</cell></row><row><cell></cell><cell>test</cell><cell>1405</cell><cell>20346</cell><cell>3/4.72/15</cell></row><row><cell></cell><cell>train</cell><cell>3322</cell><cell>69810</cell><cell>5/9.12/21</cell></row><row><cell>D5</cell><cell>dev</cell><cell>482</cell><cell>10190</cell><cell>5/9.13/21</cell></row><row><cell></cell><cell>test</cell><cell>948</cell><cell>20030</cell><cell>5/9.08/21</cell></row><row><cell></cell><cell>train</cell><cell>1681</cell><cell>28010</cell><cell>3/4.25/14</cell></row><row><cell cols="2">Pararules dev</cell><cell>240</cell><cell>4004</cell><cell>3/4.53/13</cell></row><row><cell></cell><cell>test</cell><cell>482</cell><cell>8008</cell><cell>3/4.24/11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Statistics of datasets introduced in this paper with the number of theories, questions and conclusions per theory for all three splits of each dataset. We use these datasets to quantify the robustness of FAIRR and compare it with baselines. Please refer to Appendix B for more details.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Split Number</cell><cell>Number</cell><cell>Number of</cell></row><row><cell></cell><cell></cell><cell>of The-</cell><cell>of</cell><cell>Conclusions</cell></row><row><cell></cell><cell></cell><cell>ories</cell><cell>Ques-</cell><cell>per Theory</cell></row><row><cell></cell><cell></cell><cell></cell><cell>tions</cell><cell>(min/mean/max)</cell></row><row><cell></cell><cell>train</cell><cell>28896</cell><cell>416328</cell><cell>3/4.81/16</cell></row><row><cell>Subject</cell><cell>dev</cell><cell>4314</cell><cell>61812</cell><cell>3/4.73/14</cell></row><row><cell></cell><cell>test</cell><cell>8430</cell><cell>122076</cell><cell>3/4.72/15</cell></row><row><cell></cell><cell>train</cell><cell>28866</cell><cell>415848</cell><cell>3/4.81/16</cell></row><row><cell>Attribute</cell><cell>dev</cell><cell>4314</cell><cell>61812</cell><cell>3/4.73/14</cell></row><row><cell></cell><cell>test</cell><cell>8415</cell><cell>121836</cell><cell>3/4.73/15</cell></row><row><cell></cell><cell>train</cell><cell>28866</cell><cell>415848</cell><cell>3/4.81/16</cell></row><row><cell>Subject+Attribute</cell><cell>dev</cell><cell>4314</cell><cell>61812</cell><cell>3/4.73/14</cell></row><row><cell></cell><cell>test</cell><cell>8415</cell><cell>121836</cell><cell>3/4.73/15</cell></row></table><note>sets are detailed below: Subject proper name pool: {'George', 'Paul', 'Ronald', 'Emma', 'Magnus', 'Timothy', 'Chris', 'Molly', 'Diana', 'Joseph', 'Becky', 'Kurt', 'Ivan', 'Steve', 'Laura', 'Oliver', 'Adam', 'Larry'} Subject common name pool: {'mother', 'father', 'baby', 'child', 'toddler', 'teenager', 'grandmother', 'student', 'teacher', 'alligator', 'cricket',  'bird', 'wolf', 'giraffe', 'dinosaur', 'thief', 'soldier',  'officer', 'artist', 'shopkeeper', 'caretaker', 'janitor', 'minister', 'salesman', 'saleswoman', 'runner', 'racer', 'painter', 'dresser', 'shoplifter'}   Attribute pool: {'maroon', 'brown', 'black',   </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 13 :</head><label>13</label><figDesc>Evaluation runtime (in hours) of FAIRR and ProofWriter ("Iter"). Please refer to Appendix H for more details.</figDesc><table><row><cell>d</cell><cell cols="2">ProofWriter ("Iter") FAIRR</cell></row><row><cell>0</cell><cell>1.01</cell><cell>0.12</cell></row><row><cell>1</cell><cell>1.01</cell><cell>0.20</cell></row><row><cell>2</cell><cell>1.00</cell><cell>0.28</cell></row><row><cell>3</cell><cell>1.01</cell><cell>0.36</cell></row><row><cell>4</cell><cell>1.01</cell><cell>0.46</cell></row><row><cell>Avg</cell><cell>1.01</cell><cell>0.28</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">Following ProofWriter, we perform regex to add/remove "not" which suffices for this dataset.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">The code to reproduce numbers of ProofWriter is not publicly available. We either copy results directly from the paper or run our own inference on model checkpoints made available by the authors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">Forward chaining is described as repeated application of modus ponens<ref type="bibr" target="#b6">(Hinkelmann, 2004)</ref>, which requires at least two premises to then logically conclude an inference.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">data-augmented training results for ProofWriter are not reported in the figure since the training code is not available</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via Contract No. 2019-19051600007, the DARPA MCS program under Contract No. N660011924033, the Defense Advanced Research Projects Agency with award W911NF-19-20271, NSF IIS 2048211, NSF SMA 1829268, and gift awards from Google, Amazon, JP Morgan and Sony. We would like to thank all the collaborators in USC INK research lab for their constructive feedback on the work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Error Type</head><p>Input ( format: complete theory)</p><p>Output ( format: $answer$ = conclusion ; $proof$ = # rule &amp; facts)</p><p>Wrong inference $answer$ ; $proof$ ; $question$ = What is one single-hop inference? ; $context$ = sent1 Wrong inference [the racer needs the janitor.], if someone needs the janitor then the janitor likes the racer.</p><p>the janitor likes the race.</p><p>Wrong inference [oliver is big.], big people are young. the oliver is young.</p><p>Wrong inference [the shoplifter needs the shoplifter., the shoplifter needs the dinosaur.], if something needs the dinosaur and it needs the shoplifter then it is round.</p><p>the shop is round. $answer$ = Dave is quiet. ; $proof$ = # sent1 sent4</p><p>Example 2</p><p>$answer$ ; $proof$ ; $question$ = What is one single-hop inference? ; $context$ = sent1: If someone likes the artist then they visit the grandmother. sent2: The grandmother likes the artist.</p><p>$answer$ = The grandmother visits the grandmother. ; $proof$ = # sent1 sent2 $answer$ ; $proof$ ; $question$ = What is one single-hop inference? ; $context$ = sent1: If someone is red and big then they like the grandmother. sent2: If someone visits the grandmother then they are red. sent3: If someone likes the artist then they visit the grandmother. sent4: The artist likes the grandmother. sent5: The grandmother eats the artist. sent6: The grandmother is big. sent7: The grandmother is cold. sent8: The grandmother likes the artist.</p><p>$answer$ = The artist visits the grandmother. ; $proof$ = # sent3 sent4</p><p>$answer$ ; $proof$ ; $question$ = What is one single-hop inference? ; $context$ = sent1: If someone likes the grandmother then the grandmother eats the artist. sent2: If someone eats the artist then the artist is young. sent3: If the artist eats the grandmother then the artist is cold. sent4: If someone eats the artist and the artist eats the grandmother then the grandmother eats the artist. sent5: If someone is red and big then they like the grandmother. sent6: If someone visits the grandmother then they are red. sent7: If someone is rough then they eat the grandmother. sent8: If someone likes the artist then they visit the grandmother. sent9: The artist likes the grandmother. sent10: The grandmother eats the artist. sent11: The grandmother is big. sent12: The grandmother is cold. sent13: The grandmother is young. sent14:</p><p>The grandmother likes the artist. sent15: The grandmother visits the artist. sent16: The artist is young.</p><p>$answer$ = The red sent6 sent15</p><p>Example $answer$ = Bob is nice. ; $proof$ = # sent2 &amp; sent11 sent16</p><p>Table <ref type="table">16</ref>: Some more examples of inference errors made by ProofWriter ("Iter"). We see that having extra information in the theory than what is required to prove the conclusion leads to errors (shown in red). Having limited information in the theory reduces errors. Sentences in blue depict the sentences which are added to the theory with respect to the row above. Please refer to Section 5.5 for more details.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Invariance, causality and robustness</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="404" to="426" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transformers as soft reasoners over language</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</title>
				<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3882" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment</title>
				<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Berlin Heidelberg</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Causal inference in natural language processing: Estimation, prediction, interpretation and beyond</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emaad</forename><surname>Manzoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zach</forename><surname>Wood-Doughty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno>CoRR, abs/2109.00725</idno>
		<imprint>
			<date type="published" when="2021">2021a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Causalm: Causal model explanation through counterfactual language models</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Oved</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="333" to="386" />
			<date type="published" when="2021">2021b</date>
		</imprint>
	</monogr>
	<note>Uri Shalit, and Roi Reichart</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Forward chaining vs. backward chaining</title>
		<author>
			<persName><forename type="first">Knut</forename><surname>Hinkelmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>School of Business</publisher>
		</imprint>
		<respStmt>
			<orgName>University of Applied Sciences Northwestern Switzerland</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Jacovi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.386</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4198" to="4205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A survey on semantic parsing</title>
		<author>
			<persName><forename type="first">Aishwarya</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Knowledge Base Construction (AKBC)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reasoning over paragraph effects in situations</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-5808</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering</title>
				<meeting>the 2nd Workshop on Machine Reading for Question Answering<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="58" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery</title>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queue</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du An</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Causal reasoning for algorithmic fairness</title>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">R</forename><surname>Loftus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Silva</surname></persName>
		</author>
		<idno>CoRR, abs/1805.05859</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Programs with common sense</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Tedding Conf. on the Mechanization of Thought Processes</title>
				<meeting>Tedding Conf. on the Mechanization of Thought esses</meeting>
		<imprint>
			<date type="published" when="1959">1959</date>
			<biblScope unit="page" from="75" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Beyond word importance: Contextual decomposition to extract interactions from lstms</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">James</forename><surname>Murdoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30">2018. April 30 -May 3, 2018</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The logic theory machine-a complex information processing system</title>
		<author>
			<persName><forename type="first">Allen</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbert</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Graphical models for probabilistic and causal reasoning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="70" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Causality: Models, Reasoning and Inference</title>
				<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-totext transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-toend differentiable proving</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PRover: Proof generation for interpretable reasoning over rules</title>
		<author>
			<persName><forename type="first">Swarnadeep</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.9</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="122" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">multiPRover: Generating multiple proofs for improved interpretability in rule reasoning</title>
		<author>
			<persName><forename type="first">Swarnadeep</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discretized integrated gradients for explaining language models</title>
		<author>
			<persName><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.805</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10285" to="10299" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Causality for machine learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno>CoRR, abs/1911.10500</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CLUTRR: A diagnostic benchmark for inductive reasoning from text</title>
		<author>
			<persName><forename type="first">Koustuv</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shagun</forename><surname>Sodhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1458</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4506" to="4515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Axiomatic attribution for deep networks</title>
		<author>
			<persName><forename type="first">Mukund</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiqi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017-08-11">2017. 2017. Australia, 6-11 August 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3319" to="3328" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ProofWriter: Generating implications, proofs, and abductive statements over natural language</title>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.317</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
				<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3621" to="3634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">QuaRTz: An open-domain dataset of qualitative relationship questions</title>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1608</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5941" to="5946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
				<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04">2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Counterfactual invariance to spurious correlations: Why and how to pass stress tests</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Amour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Yadlowsky</surname></persName>
		</author>
		<author>
			<persName><surname>Eisenstein</surname></persName>
		</author>
		<idno>CoRR, abs/2106.00545</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Causal mediation analysis for interpreting neural NLP: the case of gender bias</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharon</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nevo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><forename type="middle">M</forename><surname>Shieber</surname></persName>
		</author>
		<idno>CoRR, abs/2004.12265</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">NLProlog: Reasoning with weak unification for question answering in natural language</title>
		<author>
			<persName><forename type="first">Leon</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jannes</forename><surname>Münchmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Leser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1618</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6151" to="6161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>ICLR 2016</idno>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations</title>
				<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-02">2016. May 2-4, 2016</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
