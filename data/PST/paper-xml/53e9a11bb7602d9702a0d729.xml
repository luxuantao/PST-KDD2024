<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Support vector regression with chaos-based firefly algorithm for stock market price forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ahmad</forename><surname>Kazem</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering</orgName>
								<orgName type="institution">University of Tafresh</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ebrahim</forename><surname>Sharifi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering</orgName>
								<orgName type="institution">University of Tafresh</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Farookh</forename><forename type="middle">Khadeer</forename><surname>Hussain</surname></persName>
							<email>farookh.hussain@uts.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">School of Software</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering and Information Technology</orgName>
								<orgName type="institution">University of Technology Sydney</orgName>
								<address>
									<settlement>Ultimo</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Morteza</forename><surname>Saberi</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tafresh Branch</orgName>
								<orgName type="institution" key="instit1">Islamic Azad University</orgName>
								<orgName type="institution" key="instit2">Young Researchers Club</orgName>
								<address>
									<settlement>Tafresh</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Omar</forename><forename type="middle">Khadeer</forename><surname>Hussain</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="institution">Curtin University of Technology</orgName>
								<address>
									<settlement>Perth</settlement>
									<region>WA</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><surname>Model</surname></persName>
						</author>
						<title level="a" type="main">Support vector regression with chaos-based firefly algorithm for stock market price forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6057C8B1156C2BDE8935457C046E1452</idno>
					<idno type="DOI">10.1016/j.asoc.2012.09.024</idno>
					<note type="submission">ASOC 1750 1-12 Received 29 January 2012 Received in revised form 29 June 2012 Accepted 17 September 2012 ASOC 1750 1-12</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Support vector regression Firefly algorithm</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Due to the inherent non-linearity and non-stationary characteristics of financial stock market price time series, conventional modeling techniques such as the Box-Jenkins autoregressive integrated moving average (ARIMA) are not adequate for stock market price forecasting. In this paper, a forecasting model based on chaotic mapping, firefly algorithm, and support vector regression (SVR) is proposed to predict stock market price. The forecasting model has three stages. In the first stage, a delay coordinate embedding method is used to reconstruct unseen phase space dynamics. In the second stage, a chaotic firefly algorithm is employed to optimize SVR hyperparameters. Finally in the third stage, the optimized SVR is used to forecast stock market price. The significance of the proposed algorithm is 3-fold. First, it integrates both chaos theory and the firefly algorithm to optimize SVR hyperparameters, whereas previous studies employ a genetic algorithm (GA) to optimize these parameters. Second, it uses a delay coordinate embedding method to reconstruct phase space dynamics. Third, it has high prediction accuracy due to its implementation of structural risk minimization (SRM). To show the applicability and superiority of the proposed algorithm, we selected the three most challenging stock market time series data from NASDAQ historical quotes, namely Intel, National Bank shares and Microsoft daily closed (last) stock price, and applied the proposed algorithm to these data. Compared with genetic algorithm-based SVR (SVR-GA), chaotic genetic algorithm-based SVR (SVR-CGA), firefly-based SVR (SVR-FA), artificial neural networks (ANNs) and adaptive neuro-fuzzy inference systems (ANFIS), the proposed model performs best based on two error measures, namely mean squared error (MSE) and mean absolute percent error (MAPE).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Stock market price prediction is regarded as one of the most challenging tasks of financial time series prediction. The difficulty of forecasting arises from the inherent non-linearity and non-stationarity of the stock market and financial time series. In the past, Box-Jenkins models <ref type="bibr" target="#b0">[1]</ref>, such as the autoregressive (AR) model and the autoregressive integrated moving average (ARIMA) model, were proposed to tackle this problem. However, these models were developed based on the assumption that the time series being forecasted are linear and stationary. In recent years, nonlinear approaches have been proposed, such as autoregressive conditional heteroscedasticity (ARCH) <ref type="bibr" target="#b1">[2]</ref>, generalized autoregressive conditional heteroscedasticity (GARCH) <ref type="bibr" target="#b2">[3]</ref>, artificial neural networks ory <ref type="bibr" target="#b34">[35]</ref>. <ref type="bibr">Let</ref>  a phase space R d of the attractor can be reconstructed by using a delay coordinate defined as</p><formula xml:id="formula_0">X i = (x i , x i-, . . . , x i-(m-1) )<label>(1)</label></formula><p>where m is called the embedding dimension of reconstructed phase space and is the time delay constant. Choosing the correct embedding dimension is very important so that we can predict x t+1 <ref type="bibr" target="#b35">[36]</ref>.</p><p>Takens <ref type="bibr" target="#b34">[35]</ref> considered that the sufficient condition for the embedding dimension is m ≥ 2d + 1. However, too large an embedding dimension needs more observations and complex computation.</p><p>Moreover, if we choose too large an embedding dimension, noise and other unwanted inputs will be highly embedded with the real source input information, which may corrupt the underlying system dynamic information. Therefore, in accordance with <ref type="bibr" target="#b36">[37]</ref>, if the dimension of the original attractor is d then an embedding dimension of m = 2d + 1 will be adequate for reconstructing the attractor.</p><p>An efficient method of finding the minimal sufficient embedding dimension is the false nearest neighbors (FNN) procedure, proposed by Kennel et al. <ref type="bibr" target="#b37">[38]</ref>.  and sensitivity to initial conditions. A detailed explanation about chaotic properties can be found in <ref type="bibr" target="#b36">[37]</ref>.</p><formula xml:id="formula_1">R i = ||X i+1 -X j+1 || ||X i -X j ||<label>(2</label></formula><p>As we know, diversity in the initial solution of optimization algorithms such as genetic algorithms (GA) and firefly algorithms (FA) is vital for preventing premature phenomena. Logistic mapping can provide more diversity than randomly selected initial solutions and will therefore decrease the probability of premature occurrence <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Support vector regressions (SVR)</head><p>Suppose we are given a set of training patterns (x 1 , y 1 ), . . . , (x , y ), where x i ∈ R n , i = 1, 2, . . . , and y i ∈ R is the target value for each input vector x i . A regression model is trained by these patterns and used to predict the future target values. SVR is a non-linear kernel-based regression method which tries to find the best regression hyperplane with smallest structural risk in a so-called high dimensional feature space <ref type="bibr" target="#b26">[27]</ref>.</p><p>One of the most popular types of SVRs is ε-SVR which locates the hyperplane with an ε-insensitive loss function <ref type="bibr" target="#b23">[24]</ref>. The SVR function is formulated as follows:</p><formula xml:id="formula_2">f (x) = w T ϕ(x) + b<label>(5)</label></formula><p>where ϕ(x) is a nonlinear mapping from the input space to the feature space. w is a vector of weight coefficients and b is a bias constant. w and b are estimated by minimizing the following optimization problem: To cope with feasibility issues and to make the method more 152 robust, points from the ε-insensitive band are not eliminated.</p><formula xml:id="formula_3">minimize 1 2 ||w|| 2 subjected to y i -( w, ϕ(x i ) + b) ≤ ε ( w, ϕ(x i ) + b) -y i ≤ ε<label>(</label></formula><p>153</p><p>Instead, we penalize these points by introducing slack variables 159</p><formula xml:id="formula_4">154 i , * i [40]: 155 minimize 1 2 ||w|| 2 + C i=1 ( i + * i ) subjected to ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ y i -( w, ϕ(x i ) + b) ≤ ε + i ( w, ϕ(x i ) + b) -y i ≤ ε + * i i , * i ≥ 0 (7)</formula><p>After taking the Lagrangian and conditions for optimality, we can find a model solution in dual representation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b39">40]</ref>.</p><formula xml:id="formula_5">f (x) = i=1 (˛i -˛ * i )K(x i , x) + b<label>(8)</label></formula><p>In the above formulation, ˛i, ˛ * i are nonzero Lagrangian multipliers and the solution for the dual problem. K(x i , x) is the kernel function which represents the inner product ϕ(x i ), ϕ(x) . In this study, we use the radial basis function (RBF) as the kernel function because of its capabilities and simple implementation <ref type="bibr" target="#b35">[36]</ref>.</p><formula xml:id="formula_6">K(x i , x j ) = exp(-||x i -x j || 2 )<label>(9)</label></formula><p>where is the width parameter of RBF kernel and should be selected based on heuristics.</p><p>Please cite this article in press as: A.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Firefly algorithm (FA)</head><p>The firefly algorithm is a metaheuristic optimization algorithm inspired by the flashing behavior of fireflies <ref type="bibr" target="#b40">[41]</ref>. Fireflies use their natural glowing mechanism to attract other fireflies. In this algorithm, each firefly represents a possible solution and its light intensity is proportional to its objective function value. Fireflies with lower light intensity (fitness) move toward fireflies with higher light intensity by the following formulation:</p><formula xml:id="formula_7">x i = x i + ˇ(x j -x i ) + ˛(u -0.5)<label>(10)</label></formula><formula xml:id="formula_8">ˇ = ˇ0[exp(-• r 2 ij )]<label>(11)</label></formula><p>where x i is a firefly with higher light intensity, x j is a firefly with lower light intensity; is the absorption coefficient, r ij is the Euclidean distance between x i and x j ; ˇ0 is the maximum attractiveness value and ˛ is a trade-off constant which determines the random behavior of movement. u is a random number in the interval (0,1).</p><p>After such movements, all fireflies move toward the neighborhood of the best firefly, improving their personal fitness. The firefly with the highest light intensity moves randomly in the search space to improve global fitness. After reaching the defined maximum iterations, the firefly with the highest light intensity is considered as the best solution. The whole procedure of FA can be briefly explained as follows. First, initial positions of fireflies are generated randomly. Second, each firefly is evaluated by a given fitness function. Third, the fireflies with lower fitness values move toward the fireflies with higher fitness values by Eq. <ref type="bibr" target="#b9">(10)</ref>. For the firefly with the highest fitness value, the second part of Eq. ( <ref type="formula" target="#formula_7">10</ref>) becomes zero.</p><p>Therefore it moves randomly proportional to the coefficient ˛. The   Fourth, according to the optimum time delay and embedding 210 dimension, the time series phase space is reconstructed to reveal 211 its unseen dynamics. Then, we use Eq. ( <ref type="formula">12</ref>) to normalize the 212 data in the interval (0,1) and fit them for the RBF kernel function.</p><p>x new = x oldx min x maxx min <ref type="bibr" target="#b11">(12)</ref> Finally, the time series dataset is divided into two datasets, namely a training dataset and a testing dataset. Fig. <ref type="figure">1</ref> presents the data preprocessing procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Proposed chaotic firefly algorithm</head><p>Firefly algorithms (FAs), like other nature-inspired optimization algorithms, use a random approach to generate an initial solution. However, this approach has two major shortcomings, namely slow convergence and becoming trapped in local optima, caused by reduced population diversity. In this approach, the initial positions of fireflies are not necessarily fully diversified in the search space <ref type="bibr" target="#b31">[32]</ref>. To improve initial solution diversity and the quality of the initial population, a CMO (Eq. ( <ref type="formula" target="#formula_0">1</ref>)) is used instead of a random approach to generate an initial solution. 243</p><formula xml:id="formula_9">x (i) p = X (i) p -Min p Max p -Min p , p = C, , ε<label>(13)</label></formula><p>Then, adopt Eq. ( <ref type="formula">4</ref>) to compute the next iteration chaotic variable x by the following Eq. ( <ref type="formula" target="#formula_10">14</ref>)</p><formula xml:id="formula_10">X (i+1) p = Min p + x (i+1) p (Max p -Min p ) (<label>14</label></formula><formula xml:id="formula_11">)</formula><p>Step 2: Evaluate light intensity. Evaluate the light intensity (forecasting errors) of each firefly. In this study, we use a mean absolute percentage error (MAPE) as the fitness function.</p><p>The MAPE is calculated as Eq. ( <ref type="formula" target="#formula_12">15</ref>):</p><formula xml:id="formula_12">MAPE = 1 N N i=1 y i -f i y i (<label>15</label></formula><formula xml:id="formula_13">)</formula><p>where y i and f i represent the actual and forecast values, and N is the number of forecasting periods.</p><p>Step 3: Chaotic movement of fireflies. Fireflies with lower light intensity (fitness) move toward fireflies with higher light intensity and the positions of fireflies are updated. The firefly with the highest light intensity moves chaotically in the solution space using Eq. ( <ref type="formula" target="#formula_6">9</ref>). Instead of random component, ˛(u -0.5), we use a chaotic component, ı(x (n) ), where x (n) is a chaotic variable generated by Eq. ( <ref type="formula">3</ref>), and ı is the annealing operation resulting from Eq. ( <ref type="formula" target="#formula_10">14</ref>) <ref type="bibr" target="#b30">[31]</ref>:</p><formula xml:id="formula_14">ı = 1 - n -1 n v (<label>16</label></formula><formula xml:id="formula_15">)</formula><p>where n is the iteration number and v is an integer.</p><p>Step 4: Stopping condition. If the number of iterations is equal to a given scale, then the best fireflies (with highest light intensity) are presented as a solution; otherwise go back to step 2.</p><p>Fig. <ref type="figure">3</ref> shows the complete procedure of the proposed SVR-CFA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Case study</head><p>In this section, we test the proposed algorithm with three different daily stock market prices, namely Intel, National Bank shares and Microsoft. These datasets are selected from the numerous stocks available in the NASDAQ stock market due to their challenging behavior and many direction changes in the selected time span. The proposed algorithm is compared with SVR-GA, SVR-CGA,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data collection and performance evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>The optimal and m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intel</head><p>National Bank shares Microsoft  </p><formula xml:id="formula_16">MSE = 1 N N i=1 (y i -f i ) 2<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Parameter setting in CFA algorithm</head><p>The parameters of the CFA algorithm in the proposed model for three numerical examples are experimentally set. The number of fireflies is 20, the maximum number of iterations is 200, ˇ0 is 4, the constant of the annealing operator is 0.25 and the absorption coefficient is 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Phase space reconstruction</head><p>In the phase space reconstruction, we used Hao Cheng's Fractal MATLAB toolbox to select the optimal delay time and embedding dimension. Fig. <ref type="figure" target="#fig_0">4</ref>(a)-(c) shows the mutual function of each dataset, and Fig. <ref type="figure">5</ref>(a)-(c) shows FNN results for each dataset. Table <ref type="table">1</ref> shows the optimal m and .</p><p>These optimal embedding dimensions and delay times are used to construct the input matrix. The data were fed to SVR, and the hyperparameters of SVR were optimized by GA, CGA, FA and CFA. Table <ref type="table" target="#tab_4">2</ref> shows the optimized values of the hyperparameters for each algorithm.</p><p>We also fed the reconstructed phase space matrix into the ANN and ANFIS models. The best possible ANN and ANFIS structures were used for comparison with the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Performance comparison</head><p>The performance comparison of six models on two indices, MSE and MAPE are reported in Tables <ref type="table" target="#tab_6">3</ref> and<ref type="table">4</ref>   To discuss the results of the models in more detail, paired t-tests are performed to examine which model significantly outperforms the other models. The paired t-test is a parametric statistical test for two related numerical samples with a null hypothesis of equality in mean. A detailed explanation for the paired t-test is provided in <ref type="bibr" target="#b41">[42]</ref>. In this study, the residuals of each forecasting model are used to construct the t-test statistic and the p-value for each t-test on our three stock market datasets is then calculated and presented in Table <ref type="table" target="#tab_7">5</ref>. The tests are performed at a significance level of 95%, therefore p-values &lt;0.05 indicate models that vary significantly.</p><p>According to Table <ref type="table" target="#tab_7">5</ref>, based on the significance level of 95%, there is an almost-significant difference between the SVR-CFA model and other models. No statistically significant difference can be seen for the other three SVR-based models. The ANN and ANFIS models are significantly different from the SVR-based models. However, in most cases, there is no significant difference between the SVR-GA and ANN models. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The MI function of three stock market prices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>156</head><label></label><figDesc>where the cost constant C &gt; 0 determines the trade-off between 157 model complexity and training error is the number of training 158 patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. The embedding dimension of three stock market prices.</figDesc><graphic coords="5,48.51,56.35,239.40,636.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .Fig. 8 .200 3 .</head><label>783</label><figDesc>Fig. 7. The average of MAPE for all models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>203 3 . 1 .</head><label>31</label><figDesc>Data preprocessing 204 First, the MI function (Eq. (3)) is calculated for the financial 205 time series dataset. Second, the first delay time in which MI 206 function minimum value occurs is considered as the optimum 207 time delay. Third, the false nearest neighbors (FNN) method is 208 employed to find the minimum sufficient embedding dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>209</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .Step 1 :</head><label>81</label><figDesc>Fig. 8. (Continued)</figDesc><graphic coords="7,140.76,55.82,325.08,432.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Model forecasts on National Bank shares stock price.</figDesc><graphic coords="8,129.45,55.97,326.16,431.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>277</head><label></label><figDesc>SVR-FA, SVR-CFA, ANN and ANFIS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>278</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. (Continued)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. SVR model forecasts on Microsoft stock price.</figDesc><graphic coords="10,128.95,56.26,326.52,431.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. (Continued) respectively. This is the worst of all the models. Figs. 6 and 7 show the average MSE and MAPE values for all six models. To present a detailed view of the fitted values of the models against stock market values, the actual values and predicted values for all SVR models are shown in Figs. 8-10.</figDesc><graphic coords="11,140.26,55.99,325.80,429.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,140.26,56.07,326.16,419.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>)</figDesc><table><row><cell>104</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>105</cell><cell cols="5">If R i exceeds a given threshold R tol (say, 10 or 15), the point X j is</cell></row><row><cell>106</cell><cell cols="5">considered as a false nearest neighbor in dimension m. We can say</cell></row><row><cell>107</cell><cell cols="5">that the embedding dimension m is sufficiently high if the fraction</cell></row><row><cell>108</cell><cell cols="5">of points that have false nearest neighbors is zero or considerably</cell></row><row><cell>109</cell><cell>small.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>110</cell><cell cols="5">Estimation of time delay is another important issue. If is too</cell></row><row><cell>111</cell><cell cols="5">small, redundancy will occur and if is too large, it will probably</cell></row><row><cell>112</cell><cell cols="5">lead to a complex phenomenon called irrelevance. In this study, we</cell></row><row><cell>113</cell><cell cols="5">use the first minimum of mutual information (MI) function [39] to</cell></row><row><cell>114</cell><cell cols="3">determine as follows:</cell><cell></cell><cell></cell></row><row><cell>115</cell><cell>MI ( ) =</cell><cell>N-n=1</cell><cell>P(x n , x n+ ) log 2</cell><cell>P(x n , x n+ ) P(x n )P(x n+ )</cell><cell>(3)</cell></row><row><cell>116</cell><cell cols="5">where P(x n ) is the probability density of x n while P(x n , x n+ ) is the</cell></row><row><cell>117</cell><cell cols="4">joint probability density of x n and x n+ .</cell><cell></cell></row><row><cell>118</cell><cell cols="3">2.2. Logistic mapping</cell><cell></cell><cell></cell></row><row><cell>119</cell><cell cols="5">The simplest chaotic mapping operator (CMO), which was</cell></row><row><cell>120</cell><cell cols="5">brought to the attention of scientists in 1976, is logistic mapping</cell></row><row><cell>121</cell><cell>[32].</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>122</cell><cell cols="3">x n+1 = x n (1 -x n )</cell><cell></cell><cell>(4)</cell></row><row><cell>123</cell><cell cols="5">where x n is the nth chaotic number, n denotes the iteration number</cell></row><row><cell></cell><cell cols="2">and = 4.</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>124</p>Logistic mapping includes all the properties of chaotic sys-125 tems such as self-similarity, ergodicity, semi-random motion, 126</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>The optimal , C and ε.</figDesc><table><row><cell>Q3</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>C</cell><cell>ε</cell></row><row><cell>(a) Intel</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVR-GA</cell><cell>0.8291</cell><cell>5844.6</cell><cell>0.0719</cell></row><row><cell>SVR-CGA</cell><cell>5.6984</cell><cell>0.3109</cell><cell>0.0182</cell></row><row><cell>SVR-FA</cell><cell>0.1666</cell><cell>10,000</cell><cell>0</cell></row><row><cell>SVR-CFA</cell><cell>0.1011</cell><cell>8997.6</cell><cell>0</cell></row><row><cell>(b) National Bank shares</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVR-GA</cell><cell>0.2198</cell><cell>2528.7</cell><cell>0.0781</cell></row><row><cell>SVR-CGA</cell><cell>0.2325</cell><cell>9112.0</cell><cell>0.1033</cell></row><row><cell>SVR-FA</cell><cell>0.0001</cell><cell>8586.5</cell><cell>0.1037</cell></row><row><cell>SVR-CFA</cell><cell>0.2458</cell><cell>5830.9</cell><cell>0.1042</cell></row><row><cell>(c) Microsoft</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVR-GA</cell><cell>8.3900</cell><cell>934.2623</cell><cell>0.1321</cell></row><row><cell>SVR-CGA</cell><cell>5.6984</cell><cell>0.3109</cell><cell>0.0182</cell></row><row><cell>SVR-FA</cell><cell>0.0001</cell><cell>8058.0</cell><cell>0.0326</cell></row><row><cell>SVR-CFA</cell><cell>0.0047</cell><cell>7930.6</cell><cell>0.0415</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>Models' performance under MSE.</figDesc><table><row><cell>Model</cell><cell>Intel</cell><cell>National Bank shares</cell><cell>Microsoft</cell></row><row><cell>SVR-GA</cell><cell>0.00107575</cell><cell>0.00176314</cell><cell>0.00192163</cell></row><row><cell>SVR-CGA</cell><cell>0.00103765</cell><cell>0.00158184</cell><cell>0.00143307</cell></row><row><cell>SVR-FA</cell><cell>0.000988423</cell><cell>0.00161896</cell><cell>0.00110032</cell></row><row><cell>SVR-CFA</cell><cell>0.000959743</cell><cell>0.00157299</cell><cell>0.00106339</cell></row><row><cell>ANN</cell><cell>0.0010064</cell><cell>0.001607</cell><cell>0.00114</cell></row><row><cell>ANFIS</cell><cell>0.000998</cell><cell>0.001672</cell><cell>0.001212</cell></row><row><cell>Table 4</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Models' performance under MAPE.</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Intel</cell><cell>National Bank shares</cell><cell>Microsoft</cell></row><row><cell>SVR-GA</cell><cell>0.047385</cell><cell>0.049147</cell><cell>0.066795</cell></row><row><cell>SVR-CGA</cell><cell>0.046709</cell><cell>0.045997</cell><cell>0.061031</cell></row><row><cell>SVR-FA</cell><cell>0.045626</cell><cell>0.047267</cell><cell>0.052653</cell></row><row><cell>SVR-CFA</cell><cell>0.044594</cell><cell>0.045847</cell><cell>0.051907</cell></row><row><cell>ANN</cell><cell>0.047088</cell><cell>0.046742</cell><cell>0.054386</cell></row><row><cell>ANFIS</cell><cell>0.04635</cell><cell>0.047982</cell><cell>0.056344</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 p</head><label>5</label><figDesc>-Values for paired t-tests. Kazem et al. / Applied Soft Computing xxx (2012) xxx-xxx Overall, based on MSE and MAPE measures, we conclude that 347 SVR-CFA performs best in terms of prediction accuracy. In addition, 348 its implementation is much easier than that of traditional models 349 such as ANFIS and ANN.</figDesc><table><row><cell>Models</cell><cell>SVR-FA</cell><cell>SVR-CGA</cell><cell>SVR-GA</cell><cell>ANN</cell><cell>ANFIS</cell></row><row><cell>Intel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVR-CFA</cell><cell>0.039</cell><cell>0.240</cell><cell>0.058</cell><cell>0.026</cell><cell>0.043</cell></row><row><cell>SVR-FA</cell><cell></cell><cell>0.009</cell><cell>0.557</cell><cell>0.171</cell><cell>0.00</cell></row><row><cell>SVR-CGA</cell><cell></cell><cell></cell><cell>0.199</cell><cell>0.00</cell><cell>0.031</cell></row><row><cell>SVR-GA</cell><cell></cell><cell></cell><cell></cell><cell>0.678</cell><cell>0.026</cell></row><row><cell>ANN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.00</cell></row><row><cell cols="2">National Bank shares</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVR-CFA</cell><cell>0.00</cell><cell>0.00</cell><cell>0.006</cell><cell>0.001</cell><cell>0.00</cell></row><row><cell>SVR-FA</cell><cell></cell><cell>0.047</cell><cell>0.377</cell><cell>0.190</cell><cell>0.109</cell></row><row><cell>SVR-CGA</cell><cell></cell><cell></cell><cell>0.205</cell><cell>0.154</cell><cell>0.00</cell></row><row><cell>SVR-GA</cell><cell></cell><cell></cell><cell></cell><cell>0.012</cell><cell>0.00</cell></row><row><cell>ANN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.002</cell></row><row><cell>Microsoft</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVR-CFA</cell><cell>0.029</cell><cell>0.00</cell><cell>0.005</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>SVR-FA</cell><cell></cell><cell>0.00</cell><cell>0.011</cell><cell>0.004</cell><cell>0.00</cell></row><row><cell>SVR-CGA</cell><cell></cell><cell></cell><cell>0.211</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>SVR-GA</cell><cell></cell><cell></cell><cell></cell><cell>0.115</cell><cell>0.495</cell></row><row><cell>ANN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.009</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<title level="m">Time Series Analysis: Forecasting and Control</title>
		<meeting><address><addrLine>Englewood Cliffs, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>third 383 ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Autoregressive conditional heteroscedasticity with estimates of the 385 variance of United Kingdom inflation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Engle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="987" to="1008" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalized autoregressive conditional heteroscedasticity</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bollerslev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jour-387 nal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="307" to="327" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural networks and traditional time series methods: a 389 synergic combination in state economic forecasts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural</title>
		<imprint>
			<biblScope unit="volume">390</biblScope>
			<biblScope unit="page" from="863" to="873" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Genetic algorithms approach to feature discretization in arti-392 ficial neural networks for the prediction of stock price index, Expert Systems 393 with Application</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A hybrid neurogenetic approach for stock forecasting</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">395</biblScope>
			<biblScope unit="page" from="851" to="864" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Trend time series modeling and forecasting with 397 neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Qui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="808" to="816" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discovering golden nuggets: data mining in financial applica-400 tions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications 401 and Reviews</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="513" to="522" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A neural-network-based nonlinear meta modeling 403 approach to financial time series forecasting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="563" to="574" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A TSK type fuzzy rule based system for stock price predic-406 tion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="135" to="144" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Genetically optimized fuzzy polynomial neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="125" to="144" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A type-2 fuzzy rule based expert system model for stock price analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H F</forename><surname>Zarandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rezaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Turksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Neshat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Application of type-2 neuro-fuzzy modeling in stock price prediction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1348" to="1358" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E H</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Financial forecasting using support vector machines</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="184" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Support vector machine with adaptive parameters in financial time series forecasting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E H</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1506" to="1518" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Estimating GARCH models using support vector machines</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A R</forename><surname>Julio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Javier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Finance</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="163" to="172" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Financial time series prediction using least squares support vector machines within the evidence framework</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Gestel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A K</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Baestaens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lambrechts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vandaele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="809" to="821" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A hybrid ARIMA and support vector machines model in stock price forecasting</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Omega: The International Journal of Management Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="497" to="505" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Application of support vector machines in financial time series forecasting</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E H</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Omega: The International Journal of Management Science</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="309" to="317" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Support vector machine as an efficient framework for stock market volatility forecasting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Valeriy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Supriya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Management Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Support vector machine regression for volatile stock market prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Third International Conference on Intelligent Data Engineering and Automated Learning</title>
		<meeting>The Third International Conference on Intelligent Data Engineering and Automated Learning</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="391" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Financial time series forecasting using support vector machines</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="307" to="319" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning and Soft Computing: Support Vector Machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kecman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks and Fuzzy Logic Models</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">The Nature of Statistical Learning Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A multiple-kernel support vector regression approach for stock market price forecasting</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2177" to="2186" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An Introduction to Support Vector Machines and Other Kernel-based Learning Methods</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A multiple-kernel support vector regression approach for stock market price forecasting</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2177" to="2186" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Choosing multiple parameters for support vector machines</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="131" to="159" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evaluation of simple performance measures for tuning SVM hyperparameters</title>
		<author>
			<persName><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Poo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="41" to="59" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The evidence framework applied to support vector machines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T Y</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1162" to="1173" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimizing hydropower reservoir operation using hybrid genetic algorithm and chaos</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Water Resource Management</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="895" to="909" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SVR with hybrid chaotic genetic algorithms for tourism demand forecasting</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1881" to="1890" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Housing price forecasting based on genetic algorithm and support vector regression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jirong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mingcang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liuguangyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="3383" to="3386" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A hybrid stock selection model using genetic algorithms and support vector regression</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="807" to="818" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Detecting strange attractors in turbulence</title>
		<author>
			<persName><forename type="first">F</forename><surname>Takens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Mathematics</title>
		<imprint>
			<biblScope unit="volume">898</biblScope>
			<biblScope unit="page" from="366" to="381" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Chaos-based support vector regressions for exchange rate forecasting</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="8590" to="8598" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Yorke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Casdagli</surname></persName>
		</author>
		<author>
			<persName><surname>Embedology</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Physics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">579</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Determining embedding dimension for phase space reconstruction using geometrical construction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kennel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D I</forename><surname>Abarbanel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Reviews A</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="3403" to="3411" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Analysis of Observed Chaotic Data</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D I</forename><surname>Abarbanel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Tutorial on Support Vector Regression</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuro COLT Technical Report</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Inspired Metaheuristic Algorithms</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Luniver Press</publisher>
			<pubPlace>Frome, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Probability and Statistics for Engineers and Scientist</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Elsevier Academic Press</publisher>
			<pubPlace>Burlington, MA</pubPlace>
		</imprint>
	</monogr>
	<note>fourth ed.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
