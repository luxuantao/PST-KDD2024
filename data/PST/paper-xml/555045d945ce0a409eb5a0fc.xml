<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Menpo: A Comprehensive Platform for Parametric Image Alignment and Visual Deformable Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Joan</forename><surname>Alabort-I-Medina</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing</orgName>
								<orgName type="department" key="dep2">Imperial College London 180 Queens Gate</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Epameinondas</forename><surname>Antonakos</surname></persName>
							<email>e.antonakos@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing</orgName>
								<orgName type="department" key="dep2">Imperial College London 180 Queens Gate</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Booth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing</orgName>
								<orgName type="department" key="dep2">Imperial College London 180 Queens Gate</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Snape</surname></persName>
							<email>p.snape@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing</orgName>
								<orgName type="department" key="dep2">Imperial College London 180 Queens Gate</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
							<email>szafeiri@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computing</orgName>
								<orgName type="department" key="dep2">Imperial College London 180 Queens Gate</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Menpo: A Comprehensive Platform for Parametric Image Alignment and Visual Deformable Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F283EAD8A18A0ABB22112A986F9D0B9B</idno>
					<idno type="DOI">10.1145/2647868.2654890</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.5.4 [Pattern Recognition]: Applications-computer vision</term>
					<term>D.0 [Software]: General Algorithms</term>
					<term>Design</term>
					<term>Experimentation Active Appearance Models</term>
					<term>Constrained Local Models</term>
					<term>Supervised Descent Method</term>
					<term>Regression</term>
					<term>Python</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Menpo Project, hosted at http://www.menpo.io, is a BSD-licensed software platform providing a complete and comprehensive solution for annotating, building, fitting and evaluating deformable visual models from image data. Menpo is a powerful and flexible cross-platform framework written in Python that works on Linux, OS X and Windows. Menpo has been designed to allow for easy adaptation of Lucas-Kanade (LK) parametric image alignment techniques, and goes a step further in providing all the necessary tools for building and fitting state-of-the-art deformable models such as Active Appearance Models (AAMs), Constrained Local Models (CLMs) and regression-based methods (such as the Supervised Descent Method (SDM)). These methods are extensively used for facial point localisation although they can be applied to many other deformable objects. Menpo makes it easy to understand and evaluate these complex algorithms, providing tools for visualisation, analysis, and performance assessment. A key challenge in building deformable models is data annotation; Menpo expedites this process by providing a simple web-based annotation tool hosted at http://www.landmarker.io. The Menpo Project is thoroughly documented and provides extensive examples for all of its features. We believe the project is ideal for researchers, practitioners and students alike.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Rigid and non-rigid image alignment and the closely related field of visual deformable models (i.e., models of nonrigid visual objects, such as human faces) are all well-studied areas of computer vision, which have created a wealth of scientific research and countless applications. Despite this, there is still a noteworthy lack of high quality open source software in this area. Most existing packages are encrypted, compiled, non-maintained, badly structured or difficult to modify, all characteristics which make them unsuitable for adoption in cutting edge scientific research. Furthermore, the lack of an open source package that implements the most important techniques of the field in a unified manner obstructs the possibility to fairly assess the various methods against one another. We believe that the qualities and characteristics of the Menpo Project make it a suitable candidate to fill this existing gap.</p><p>Among the previously mentioned parametric image alignment algorithms, Lucas-Kanade (LK) <ref type="bibr" target="#b1">[1]</ref> is arguably the most popular. Active Appearance Models (AAMs) <ref type="bibr" target="#b2">[2]</ref> are an extension of LK to the problem of generative deformable model fitting that have recently been shown to achieve stateof-the-art results <ref type="bibr" target="#b3">[3]</ref>. Similar performance has been achieved with discriminative part-based model techniques such as Constrained Local Models (CLMs) <ref type="bibr" target="#b4">[4]</ref> and the recently proposed Supervised Descent Method (SDM) <ref type="bibr" target="#b5">[5]</ref>.</p><p>Some implementations of the above methods are publicly available. Various implementations of LK are provided in <ref type="bibr" target="#b1">[1]</ref> and an implementation of AAM building and fitting is given in <ref type="bibr" target="#b6">[6]</ref>. To the best of our knowledge, for the recent state-of-the-art LK <ref type="bibr" target="#b7">[7]</ref>, AAMs <ref type="bibr">[8,</ref><ref type="bibr" target="#b9">9]</ref>, CLMs <ref type="bibr" target="#b4">[4]</ref> and SDMs <ref type="bibr" target="#b5">[5]</ref>, only compiled, encrypted, or pre-trained implementations exist (some are provided by our group<ref type="foot" target="#foot_0">1</ref> ). In particular, it should be noted that whilst many packages provide fitting algorithms, few provide training code.</p><p>Menpo provides robust open source implementations of all the above algorithms and is designed and developed to be flexible and simple to use. One of Menpo's most powerful features is the unification of the algorithms within a single framework, which enables easier investigation of new research areas. Furthermore, it provides implementations of many powerful features and descriptors used in computer vision, such as Local Binary Patterns <ref type="bibr" target="#b10">[10]</ref>, Histogram of Oriented Gradients (HOGs) <ref type="bibr" target="#b11">[11]</ref> and Image Gradient Orientations (IGOs) <ref type="bibr" target="#b7">[7]</ref>, all of which can be employed in the deformable model algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ARCHITECTURE</head><p>Choice of programming language. Menpo is primarily written in Python. The use of Python was motivated by its free availability on all platforms, unlike its major competitor in computer vision, Matlab. We believe this is hugely important for reproducible open science. Python provides a very flexible environment for performing research, and recent innovations such as the IPython notebook <ref type="bibr" target="#b13">[13]</ref> have made it incredibly simple to provide documentation via examples. The vast majority of the execution time in Menpo is actually spent in highly efficient numerical libraries and bespoke C++ code, allowing us to achieve sufficient performance for real time facial point tracking whilst not compromising on the huge flexibility that Menpo offers.</p><p>Importing assets. Menpo can ingest a large range of 2D and 3D asset and annotation formats, and normalises differences between formats to provide consistent data to users. All major image types are supported, along with a number of common annotation formats used within the computer vision community. Because Menpo has been built with extensibility in mind, adding support for new asset formats is very simple. Since deformable modelling commonly requires pre-annotated data, Menpo will automatically import all annotation formats that have the same name as an importable file. For example, importing an entire facial database of images along with their annotations is as simple as: import menpo.io as mio images = list(mio.import_images("./trainset/*"))</p><p>High-level types. At Menpo's core are powerful Image and PointCloud classes. All types support rich introspection and visualisation, which is of huge benefit when working interactively in an IPython Notebook. The Transform subclasses in Menpo provide a simple interface for manipulating data inside container types. All Menpo container types are transformable, and when a transform is applied on a container, all attached data is transformed too. For example, when rotating an image any attached landmarks are also rotated.</p><p>Vector representation. Computer vision algorithms are frequently formulated as linear algebra problems in high dimensional spaces, where each image is stripped into a vector form. Unfortunately, it is rare for the complete problem to be formulated in such a manner, as some operations still need to be applied in the image domain (e.g. calculating the gradient). Menpo bridges this gap by supporting bidirectional vectorisation of data through its Vectorizable interface. Through this, any type can be safely and efficiently converted to a vector form and back again, allowing for algorithms to be efficiently marshaled into vector and matrix forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ALGORITHMS</head><p>Menpo contains at its core two major families of algorithms: generative LK techniques, including AAMs, and discriminative part-based models, which consist of CLMs and SDMs. For all algorithms training and fitting implementations are provided, something which uniquely differentiates Menpo from other packages.</p><p>Lucas-Kanade. The LK family of algorithms seek to minimise the discrepancies between a given input image and either a template image (LK) or an appearance model (AAM). This is achieved in a generative manner, whereby parameters are computed in order to correctly warp one of the images into the reference frame of the other. Optimisation of these parameters is usually achieved via a Gauss-Newton approximation and a number of formulations of the cost function have been proposed. Within Menpo, we have implementations of all major LK algorithms <ref type="bibr" target="#b1">[1]</ref> (forward additive/compositional, inverse additive/compositional) and all major AAM algorithms (project-out <ref type="bibr" target="#b1">[1]</ref> and alternating <ref type="bibr" target="#b9">[9]</ref>). Building and fitting an AAM is extremely simple, requiring only 4 lines of code: from menpo.fitmultilevel.aam import * aam = AAMBuilder().build(images) # Build aam_fit = LucasKanadeAAMFitter(aam) # Fit result = aam_fit.fit(test_image, initial_shape) CLMs are part-based deformable models that fit global parametric models of shape to images by maximising the joint probability of their landmarks being correctly aligned. To this end, a set of individual discriminative classifiers that model the probability of each landmark being correctly aligned are learnt from the local appearance region around each landmark. Fitting consists of maximising the joint probability of each classifier whilst ensuring that the final shape is highly plausible under the global parametric shape model. Menpo has an implementation of the well-known Regularized-Landmark Mean-Shift algorithm proposed by Saragih et. al in <ref type="bibr" target="#b4">[4]</ref>. The obvious advantage of Menpo's implementation with respect to other existing implementations is the ease with which new appearance representations and different discriminative classifiers can be incorporated in to the existing framework.</p><p>Regression-based techniques aim at solving the same type of problem solved by deformable models such as AAMs </p><formula xml:id="formula_0">C++ Academic - + + - - - - Intraface [5] C++/Matlab Academic - - - - - - + FaceTracker [4] C++ Academic - - - - + - - DRMF [12] Matlab Academic - - - - + - - VOSM 2 C++ LGPL - + + - - - - [1] Matlab - + - - - - - -</formula><p>Figure <ref type="figure">2</ref>: Performance comparison between some of Menpo's basic methods (SDM, CLMs, HOG and IGO AAMs) and two other available packages (Intraface <ref type="bibr" target="#b5">[5]</ref> and DRMF with CLMs <ref type="bibr" target="#b12">[12]</ref>) on AFW database.</p><p>or CLMs; i.e. finding the optimal position of the set of landmarks describing the shape of an object of interest in an image. These techniques attempt to solve the problem by generally learning a cascade of functional mappings (commonly referred to as a cascade of regressors) between the object appearance and the optimal landmark configuration. Due to the availability of high quality annotated data in some areas of computer vision (such as non-rigid face alignment), these techniques have become effective and extremely attractive due to their extremely low computational fitting complexity. Menpo provides a complete framework for developing cascade-regression methods for object landmark localisation. More specifically, Menpo provides a flexible implementation of the popular Supervised Descent Method (SDM) <ref type="bibr" target="#b5">[5]</ref>, and cascade-regression implementations for fitting Deformable Models that are the direct application of the Supervised Descent approach to CLMs (similar to <ref type="bibr" target="#b12">[12]</ref>) and AAMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FITTING PERFORMANCE</head><p>Due to the rich functionality of Menpo, several experiments could be run to assess performance. However, due to lack of space, we restrict the performance evaluation to the problem of non-rigid face alignment "in-the-wild".</p><p>The experiment of Figure <ref type="figure">2</ref> compares the fitting accuracy of four representative algorithms implemented in Menpo against two publicly available but closed-source implementations of state-of-the-art methods using two popular "in-the-wild" face databases. The four Menpo algorithms under test are as follows: (1) the Alternating Inverse Compositional algorithm for fitting AAMs using IGO features (Menpo IGO-AAMs) <ref type="bibr">[8]</ref> and (2) HOG features (Menpo HOG-AAMs) <ref type="bibr" target="#b3">[3]</ref>, (3) the Regularised Landmark Mean-Shift <ref type="bibr" target="#b4">[4]</ref> algorithm for CLMs fitting using HOG features (Menpo CLMs) and ( <ref type="formula">4</ref>) the Supervised Descent Method <ref type="bibr" target="#b5">[5]</ref> using HOG features (Menpo SDMs). All algorithms were trained using the same 811 annotated training images of the publicly available LFPW database <ref type="bibr" target="#b14">[14]</ref> provided by the 300W Challenge<ref type="foot" target="#foot_2">3</ref>  <ref type="bibr" target="#b15">[15]</ref>.</p><p>We test against: (1) the DRMF Matlab implementation provided by <ref type="bibr" target="#b12">[12]</ref> <ref type="foot" target="#foot_3">4</ref> and (2) the SIFT-SDMs Matlab implementation of <ref type="bibr" target="#b5">[5]</ref> <ref type="foot" target="#foot_4">5</ref> . Due to the closed source nature of these implementations it is impossible to know what data was used to train the models, however through personal communication with the authors we know several thousand images were employed.</p><p>Results are reported for the 337 annotated images from the Annotated Faces in the Wild (AFW) database 3 <ref type="bibr" target="#b16">[16]</ref>. All methods were initialised using the publicly available bounding box face detections 3 . Note that these initialisations are particularly challenging, and so the experiment emphasises the robustness of the techniques. For each method, the Cumulative Error Distribution (CED) curves over 49 landmark points is reported in Fig. <ref type="figure">2</ref>. The results indicate that on the whole Menpo is comparable to state-of-the-art, even given the deficiencies in training data used. Menpo HOG-AAM is by far the most accurate technique, although it is admittedly much slower than the SDM family of methods.</p><p>It should be noted that due to the fact that the third-party techniques tested do not provide training implementations it is impossible to guarantee a fair test. The aim of the experiment is rather to demonstrate that Menpo's open-source implementations can compete against the state-of-the-art. We choose to train our techniques with a fairly small cohort of publicly available images due to the considerable computational requirements of the training process. It is hoped that this decision ensures that the results reported here are readily reproducible by the interested reader.</p><p>One of the aims of Menpo is to promote open, reproducible science. To that end, the full code for reproducing the results reported here will be made available before publication on the Menpo website. Going forwards we intend to maintain a standardised suite of tests based around the experiments performed in this paper for the community to have a single </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">APPLICATIONS</head><p>Building Menpo on top of Python makes it extremely easy to integrate into different applications. Currently the Menpo Project hosts two applications built on top of Menpo.</p><p>Web based landmarker http://www.landmarker.io is a web application for annotating 2D and 3D data. It has no dependencies beyond a modern web browser such as Google Chrome and is designed to be trivial to use. Most importantly, the decentralisation of the landmarking software means researchers can recruit annotators by simply directing them to the website. The annotations and assets themselves are served to the client from a separate server component which is run by the user. This allows researches to benefit from the web-based nature of the tool without having to compromise privacy or security. The server utilises Menpo to import assets and save out annotations. An example screenshot is given in Figure <ref type="figure" target="#fig_0">3</ref>. In the future, the tool will use Menpo to provide initial estimations of the correct points for the images and meshes of interest.</p><p>Real-time tracker Menpo-Tracker is an experimental application for detecting and tracking object landmarks in real-time on a standard laptop. It defines a general framework for tracking deformable objects (it is not specifically tailored to faces) using SDM objects built using Menpo. This tracking application is implemented in Python and utilises OpenCV for video acquisition. We have high hopes that due to the accessibility of Python and it's widespread user base, Menpo-Tracker will attract users from communities outside of computer vision. We have plans for Menpo-Tracker to be able to track object landmarks in real-time using GPU-based implementations of AAMs and CLMs built using future iterations of Menpo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>We present Menpo, the first, to the best of our knowledge, complete platform for parametric image alignment and deformable model construction, fitting and performance evaluation. Menpo is flexible and there are many interesting areas where it can be extended to provide further state-ofthe-art implementations. Currently, we are working on implementing construction and fitting of 3D Morphable Models (a lot of work has already been done towards this direction -Menpo includes an off-screen OpenGL rasterizer for the purpose, and all the tools necessary to visualise and work with 3D triangular meshes). Most importantly, we wish for Menpo to become an important set of reference implementations for researchers interested in the parametric image alignment and deformable modelling fields.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An example screenshot of the web based landmarking software.</figDesc><graphic coords="4,64.56,53.80,217.59,156.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of existing implementations. No other package provides implementations of training and fitting for the AAM, CLM and regression-based methods.</figDesc><table><row><cell>Tool</cell><cell>Environment</cell><cell>License</cell><cell cols="7">LK Image Alignment Train Fit Train Fit Train Fit AAM CLM Regression</cell></row><row><cell>Menpo</cell><cell>Python</cell><cell>BSD</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>+</cell></row><row><cell>DeMoLib [6]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We have recorded more than 10K downloads for our implementations of some of the above techniques in the past couple of years.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.visionopen.com/downloads/ open-source-software/vosm/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://ibug.doc.ic.ac.uk/resources/300-W/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://sites.google.com/site/akshayasthana/ clm-wild-code</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>http://www.humansensing.cs.cmu.edu/intraface/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGMENT</head><p>The work of Joan Alabort-i-Medina and Patrick Snape was funded by the Qualcomm Innovation Fellowship and by an EPSRC DTA from Imperial College London. The work of James Booth was funded by an EPSRC DTA from Imperial College London. The work of Epameinondas Antonakos and Stefanos Zafeiriou was partially supported by the EPSRC project EP/J017787/1 (4DFAB).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lucas-kanade 20 years on: A unifying framework</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="255" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active appearance models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hog active appearance models</title>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deformable model fitting by regularized landmark mean-shift</title>
		<author>
			<persName><forename type="first">J</forename><surname>Saragih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="215" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning aam fitting through simulation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pat. Rec</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2628" to="2636" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust and efficient parametric face alignment</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generic active appearance models revisited</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="650" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive and constrained algorithms for inverse compositional active appearance model fitting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maragos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust discriminative response map fitting with constrained local models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3444" to="3451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">IPython: a system for interactive scientific computing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CiSE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="21" to="29" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Localizing parts of faces using a consensus of exemplars</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">300 faces in-the-wild challenge: The first facial landmark localization challenge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV-W 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="397" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Face detection, pose estimation, and landmark localization in the wild</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
