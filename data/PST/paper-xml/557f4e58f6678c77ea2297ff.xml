<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analysis of the Combined Effects of Finite Samples and Model Errors on Array Processing Performance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member-, IEEE</roleName><forename type="first">Mats</forename><surname>Viberg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">A</forename><forename type="middle">Lee</forename><surname>Swindlehurst</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Electronics</orgName>
								<orgName type="institution">Chalmera University of Technology</orgName>
								<address>
									<settlement>Gothenburg</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Brigham Young University</orgName>
								<address>
									<postCode>84602</postCode>
									<settlement>Provo</settlement>
									<region>UT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Analysis of the Combined Effects of Finite Samples and Model Errors on Array Processing Performance</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5429DF786BFE7EA872ABE560A6EFE97</idno>
					<note type="submission">received December 3, 1992; revised May 10, 1994.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The principal sources of estimation error in sensor array signal processing applications are the finite sample effects of additive noise and imprecise models for the antenna array and spatial noise statistics. While the effects of these errors have been studied individually, their combined effect has not yet been rigorously analyzed. In this paper, we undertake such an analysis for the class of so-called subspace Jitfing algorithms. In addition to deriving first-order asymptotic expressions for the estimation error, we show that an overall optimal weighting exists for a particular array and noise covariance error model. In a companion paper, the optimally weighted subspace fitting method is shown to be asymptotically equivalent with the more complicated maximum a posteriori estimator. Thus, for the model in question, no other method can yield more accurate estimates for large samples and small model errors. Numerical examples and computer simulations are included to illustrate the obtained results and to verify the asymptotic analysis for realistic scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>URING the past decade, a number of so-called "high-D resolution" subspace-based algorithms for array signal processing and parameter estimation have been introduced. Most of these techniques are presented in the context of estimating the directions-of-arrival (DOA's) of multiple cochannel signals using an array of sensors. In recent years, attention has shifted from new algorithm development to algorithm performance analyses and comparisons. A number of research contributions have considered the asymptotic effects of additive noise on DOA estimation performance, assuming that the array response and noise model are perfectly known [ 11- <ref type="bibr" target="#b3">[4]</ref>. Conversely, others have investigated the effects of an imprecisely known array response and noise model, while ignoring the finite sample effects of noise [5]- <ref type="bibr" target="#b7">[8]</ref>. The combined effects of additive noise and modelling errors are considered in <ref type="bibr" target="#b8">[9]</ref> and [ 101 but only for the high signal-to-noise ratio (SNR) case.</p><p>In any practical situation, all of the above error sources will be present simultaneously. Not only is one forced to estimate the DOA's using only a finite amount of noisy data, but the ar-ray does not respond as expected, and the spatial characteristics of the noise field are not well understood. More precisely, the array element positions may not be accurately known, the gain and phase response of a given sensor may vary as a function of its surroundings, imprecise interpolation techniques must be used with arrays calibrated at discrete angles, the noise field may change with time, reverberation, channel cross-talk, or spatially distributed sources may be present, etc. Together with the noise itself, these sources of error will obviously degrade algorithm performance, although the amount of degradation will depend on the relative contribution of the noise and model errors.</p><p>Some approaches have been proposed in the literature to mitigate the effects of modeling errors. Optimal techniques assuming unstructured perturbations and an infinite number of snapshots are derived in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b7">[8]</ref>. In [ 111 and [ 121, a method that is robust against an unknown noise field is suggested, assuming that no information about the perturbation structure is available. Examples of techniques for structured perturbation models include the so-called auto-calibration techniques considered in [ 131-[ 151 and the maximum a posteriori (MAP) approach [ 161, [ 171. The methods considered herein belong to the class of signal subspace fitting (SSF) algorithms <ref type="bibr" target="#b3">[4]</ref>. These methods have been shown to be first-order equivalent to many other parametric techniques for particular choices of a certain weighting matrix. Optimal choices of the weighting matrix have been derived in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b7">[8]</ref> for cases involving finite sample effects (FSE) or modeling errors (ME), respectively, and the resulting SSF techniques have been shown to give the best possible performance of any estimator under their respective assumptions.</p><p>The goal of this paper is to extend earlier results on algorithm performance analysis to the more realistic case where both modeling errors and finite sample effects are present. Not surprisingly, it is found that the estimation error covariance is, up to first order, a sum of the individual contributions from the two types of errors. It is shown that an overall optimal subspace weighting for the SSF class of methods exists for a particular class of modeling errors. This model assumes 1) additive random array response errors that are statistically uniform from sensor to sensor, but possibly correlated between different DOA's (with known correlation), and 2) additive random perturbations to the noise covariance that are independent from element to element. The SSF method using the overall optimal weighting will outperform all other SSF techniques when considering both modeling errors and finite sample effects. Indeed, in the companion IOS3-.587X/94$04.00 0 1994 IEEE paper <ref type="bibr" target="#b15">[17]</ref>, the optimally weighted SSF technique is found to be asymptotically equivalent with the more complicated MAP estimator <ref type="bibr">[16]</ref> for the problem at hand. Thus, the covariance of the asymptotic distribution of the estimation error coincides with the Cram&amp;-Rao bound (CRB) for Gaussian signals, perturbations, and noise, and hence, no other technique can give lower first-order error variance.</p><p>We begin in the next section by introducing the details of the problem considered, including the nominal data model as well as the models used for the array response and noise covariance errors. The class of SSF methods is also briefly reviewed. Section I11 contains the combined performance analysis, and Section IV presents the optimal SSF weightings. Some numerical examples and computer simulations are included in the final section. The performance of the overal optimal SSF method is compared with that resulting from the FSEand MEonly optimal weightings. Comparisons with the appropriate CRB are also made for a particular case involving nonuniform sensor position errors (a simulated towed array).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">PROBLEM FORMULATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Nominal Data Model</head><p>Consider an array of rn sensors having arbitrary positions and characteristics. Impinging on the array are the waveforms of d far-field, narrow-band point sources, where d &lt; m.</p><p>The vector of complex sensor outputs is denoted x(t) and is modeled by the following familiar equation:</p><formula xml:id="formula_0">x(t) = [a(&amp;)l . . . la(&amp;)] [ : ] 1: (] + n(t) = A(O)s(t) + n(t).</formula><p>(1)</p><p>The columns of the ni x d matrix A are the so-called array propagation vectors, which are denoted .(e,), 2. = 1, . . . , d. These vectors are functions of the signal parameters and describe the array response to a unit waveform with parameter(s) O1. Although not necessary, we shall assume that 19~ is a real-valued scalar referred to as the rth DOA. The components of the d-vector 6 are the model DOA's, whereas the vector 60 contains their true values. It is assumed that 60 is an inner point of the parameter set of interest and that A(6) is differentiable over this set.</p><p>The d-vector s ( t ) is composed of the complex emitter waveforms received at time t , and the m-vector n(t) accounts for additive measurement noise. The array output is assumed to be sampled at N distinct time instants. Based on the measurements x(l), . . . . x ( N ) , the problem of interest is to determine the DOA's of all emitters. The number of signals d is assumed to be known. The signal waveforms are regarded as deterministic (i.e., fixed) sequences such that the following limit exists:</p><formula xml:id="formula_1">4 'V lim I s ( t ) s * ( t ) = P. ~-+ m N t = l</formula><p>where X* denotes the complex conjugate transpose of X. On the contrary, the noise term n(t) is modeled as a stationary, complex Gaussian random process that is uncorrelated with the signals. The noise has zero mean and is assumed to be both spatially and temporally white, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>~[ n ( t ) n * ( s ) ]</head><p>= 021St,,</p><formula xml:id="formula_2">~[ n ( t ) n ~( s ) ] = o (4)<label>(3)</label></formula><p>where bt,, is the Kronecker delta.</p><p>It should be noted that the analysis performed under the above model remains valid if the signal waveforms happen to be realizations of some stochastic process. The corresponding stochastic limit in ( 2 ) is then required to hold with probability one. See Chapter 2 of [18] for more details on this topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . Perturbation Models</head><p>The exact parametrization of the array propagation vectors is unknown in any practical situation. Thus, the available model a(6) may differ from the "true" propagation vector. It will be assumed that the data have actually been generated by the equation</p><formula xml:id="formula_3">X ( t ) = [a(h) + a(61)l.. . I . ( &amp;) + a(&amp;)] [ ; ; ? : ' I + n(t)</formula><p>( 5 ) <ref type="bibr" target="#b5">(6)</ref> In some applications, it is conceivable that the physical origin of the array model uncertainty could be precisely characterized. The perturbations may be due to sensor position errors, gain errors, phase errors, mutual coupling between sensors, receiver fluctuations due to temperature and humidity, quantization effects, etc. It is, in principle, possible to explain the effect of each of these error sources from physical insight, thus leading to a model where the propagation vectors are parametrized by the DOA's along with a set of extra "perturbation parameters." However, in a practical application, all of the above-mentioned phenomena (along with several others) are likely to be present simultaneously. Clearly, a model based on physical insight is impractical in such a case.</p><p>A pragmatic remedy to this situation is simply to assume that the array response is a random quantity, whose mean value is the known nominal model. Thus, we assume herein that the array propagation errors are random with zero mean and second-order moments</p><formula xml:id="formula_4">= (A + A)s(t) + n(t). E[a(O,)a*(Q,)] = vtJB (7) E[a(e,)a7eJ)] = 0. (<label>8</label></formula><formula xml:id="formula_5">)</formula><p>The sensor-to-sensor covariances are collected in the matrix</p><formula xml:id="formula_6">Y = { v t J } .</formula><p>Both B and Y are assumed to be available to the user, e.g., from system performance specifications.</p><p>Note that the error model <ref type="bibr" target="#b6">(7)</ref> allows for direction-dependent modeling errors, but the sensor-to-sensor correlation (if any) is independent of 6.</p><p>Perturbation models similar to <ref type="bibr" target="#b6">(7)</ref> and (8) have been used by a number of others, primarily in the analysis of adaptive beamforming algorithms [ 191-[21]. The model presented here is actually somewhat more general than what was assumed in these papers since we allow for some degree of angle-to-angle and sensor-to-sensor correlation. To connect the nonphysical model of ( <ref type="formula">7</ref>) and (8) with the more intuitive idea of gain and phase perturbations to the array, let the nominal response of the lcth sensor in the direction B be a n ( @ ) = P A , and let j , and d k represent the corresponding gain and phase perturbation$. Then, to first order, we have where If we let 092 and 0; represent the variances of ,&amp; and &amp;, respectively, and if we assume that the gain and phase perturbations are zero-mean and independent, then Thus, the model of ( <ref type="formula">7</ref>) and <ref type="bibr" target="#b7">(8)</ref> simply amounts to assuming that vii = 0; + 0 : for the ith DOA and that the gain and phase errors are roughly "of the same order" (0,: and 0; are equal). A similar result also holds for correlations between the errors on different sensors and in different directions.</p><p>The reason for a random perturbation model as opposed to a deterministic one lies in the consideration of how one chooses to quantify the effects of the perturbation. In a given fixed scenario, of course, the presence of array errors will introduce a bias in the DOA estimates. Presumably, if one wanted to measure the magnitude of this bias, it would simply be a Eatter of directly computing the limiting ( Nx ) estimate H and then subtracting 00. This procedure would obviously have to be repeated for each perturbation scenario considered since the bias would be different in each case. The advantage of using a random model is that one can obtain a measure of the average effect of the array errors on estimation performance, which is measured now in terms of variance rather than hius, without being forced to adopt a particular perturbation scenario (which may be no more representative than any other similar perturbation).</p><p>The covariance structure in <ref type="bibr" target="#b6">(7)</ref> and ( <ref type="formula" target="#formula_4">8</ref>) also allows one to optimize performance for the proposed SSF estimation method. However, as will be demonstrated in Section V, one can often use the resulting optimized SSF approach to also improve the performance for more complicated perturbation models. More precisely, Example 5.2 shows how the sensitivity to underestimation of the number of signals can be reduced, and Example 5.3 deals with the case of unknown sensor positions. We should also remark that ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_4">8</ref>) is indeed a reasonable model in the common case of an experimentally calibrated array, where the sources of error may be quantization errors in collecting the calibration data, interpolation errors in using a calibration grid, etc.</p><p>The effects of errors in the noise model on algorithm performance will also be studied. As with the array errors, we will model the perturbation to the noise covariance as a random variable with given moments. It is most convenient to specify the conditional mean and covariances of the noise given 2, the perturbation' Other than being Hermitian, % is treated as a random matrix with independent elements iri, of equal variance: Thus, the real diagonal elements of % are independent of all other elements, whereas the off-diagonal terms are correlated only with their conjugate image. The off-diagonal elements are assumed to be circularly symmetric, i.e., the real and imaginary parts are uncorrelated and of equal variance p 2 / 2 . It is assumed that p2 is known, whereas o2 may be unknown. Note from (11) and ( <ref type="formula">12</ref>) that</p><formula xml:id="formula_7">E[n(t)n*(s)] = E E n(t)n*(s) I %}] = 021&amp;,,<label>(14)</label></formula><p>[ { i.e., the total covariance matrix of the noise is identical to the nominal spatially white covariance. However, the higher order moments of the noise are altered by the perturbation model, which will be seen to affect the behavior of the estimation techniques under consideration. The perturbations of the nominal array propagation and noise models introduce a bias in the estimates. In other words, it is not possible to determine the DOA's exactly even from an infinite collection of observation vectors, i.e., as N + m.</p><p>However, the goal of our study is to make a mathematically consistent first-order analysis of the DOA estimation error in the presence of hnrh finite sample and model errors. Thus, the size of the perturbations relative to the number of available snapshots plays a crucial role. The variances of the estimated DOA's are known to be proportional to 1/N in the finitesample-only case, whereas they are proportional to v,, + in the model-error-only case. To make the relative contribution of the two error sources of comparable magnitude, we introduce the artifice of expressing the array perturbation variances as</p><formula xml:id="formula_8">Y = Y/N (15)</formula><p>where r is independent of N , and similarly An asymptotic performance analysis is then carried out assuming N + x. This leads to expressions for the asymptotic covariance matrix of the limiting distribution of the estimation error involving the combined effects of finite samples and modeling errors.</p><p>One could alternatively assume that N is "large" and that 11,; + p2 is "small" and perform a first-order analysis in 1/N 'The model used here is slightly different but no less general than that assumed in 161 and 181, where the conditional covariance of the noise in <ref type="bibr">(11)</ref> was assumed to be v2( I + C ) . and U;; + p2 simultaneously. This approach can be shown to yield results identical to those obtained with the more artificial assumption that Y and p are independent of N . However, such a first-order perturbation analysis is quite heuristic and does not allow for mathematically precise statements involving the limiting distribution (or second-order moments) of the estimation error since this distribution necessarily depends on the relative sizes of the different sources of errors. Indeed, if Y and p2 are both o(l/N), the limiting distribution is independent of the modeling errors, and the analysis of <ref type="bibr" target="#b3">[4]</ref> applies. On the other hand, if 1/N &lt;&lt; ~: ~+ p ' , the finite sample errors are irrelevant, and the analysis of [8] is applicable. By adopting the assumptions in (15) and ( <ref type="formula">16</ref>), we are simply restricting ourselves in this paper to the "in between" cases where neither finite sample effects or model errors dominate. Further comments on this issue are provided in Remark 3.1 of Section 111-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Subspace Fitting Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>surements only through the sample covariance matrix</head><p>Most parametric estimation methods depend on the mea- where A, is a diagonal matrix containing the d' largest eigenvalues, and the columns of E, are the corresponding eigenvectors. Similarly, A, and E, are composed of the smallest eigenvalues and their corresponding eigenvectors.</p><formula xml:id="formula_9">1 " R = -C x ( t ) x * ( t ) .</formula><p>From (22), it is easy to see that the m-d' columns of E, are all orthogonal to the matrix A P A " , and they correspond to the multiple eigenvalue 0 2 , i.e., A, = 021. Since E, and E, are orthogonal, it follows that there exists a full rank d x d' matrix T such that E, = A(00)T.</p><p>(</p><p>Equation ( <ref type="formula" target="#formula_10">24</ref>) is the key observation for all subspace-based techniques, including those that fall in the class of signal subspace fitting (SSF) methods <ref type="bibr" target="#b3">[4]</ref>. In the SSF approach, an estimate of E, is obtained from the eigendecomposirion of the sample covariance matrix <ref type="figure">A,</ref><ref type="figure">E;</ref><ref type="figure">+ E,</ref><ref type="figure">A,</ref><ref type="figure">E;</ref><ref type="figure"></ref> (25) and the following weighted least-squares problem based on ( <ref type="formula" target="#formula_10">24</ref>) is solved to estimate 0: <ref type="bibr" target="#b24">(26)</ref> The weighting matrices W, and W, are assumed to be positive definite and Hermitian. Roughly speaking, the role of the weighting matrices is to whiten the equation error Es -AT. The row weighting W, takes care of nonuniform modeling errors (it does not appear in the finite-sample-only case), whereas the column weighting W, essentially contains the inverse variances of the eigenvector estimates. The SSF minimization of ( <ref type="formula">26</ref>) is often written in a more compact form by solving for the linear parameter T: yield an algorithm that is asymptotically (large N ) equivalent to the maximum likelihood method, assuming stochastic Gaussian emitter signals. Hence, the DOA estimates obtained from (28) using the weighting matrices (31) and (32) asymptotically achieve the CramCr-Rao bound and thus have minimum variance. In a similar fashion, different sets of optimal weighting matrices have been derived assuming array and noise model errors are present and N -i cc <ref type="bibr" target="#b7">[8]</ref>. The development of an optimal SSF algorithm that takes both finite sample effects and model errors into account requires a combined performance analysis that assumes both error sources are present. Such an analysis is conducted in the next section. Optimal weighting matrices are then derived in Section IV for the combined case.</p><formula xml:id="formula_11">R = E,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">PERFORMANCE ANALYSIS</head><p>It is well known that in the absence of modeling errors, the SSF estimate obtained from <ref type="bibr" target="#b26">(28)</ref> converges to the true value (w.p.1) as N + CO. The convergence of the SSF estimate when both N + 03 and U , , + p 2 + 0 readily follows. Thus, we conclude that the estimate is strongly consistent under the mathematical assumptions ( 15) and (1 6). A useful measure for predicting the accuracy in "large enough" sample sizes (and, in this case, assuming "small enough" modeling errors) is the asymptotic covariance matrix of the parameter estimates. Under mild conditions, this is the same as the covariance of the limiting distribution of the estimation error. Note that this distribution is not necessarily Gaussian since no assumptions on the distributions of the perturbation terms are made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Asymptotic Accuracy</head><p>Let 4 minimize the criterion function <ref type="bibr" target="#b26">(28)</ref>. Then. V'(8) = 0, where V' denotes the gradient. Since the estimate is consistent, a standard Taylor series expansion of this equation yields</p><formula xml:id="formula_12">0 = V'(8) N V'(0,) + V''(Bo)(8 -B o ) N V'(B0) + H e (34)</formula><p>where H denotes the limiting (N -+ cc) Hessian H = lini V"(0,) (w.p.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N + m (35)</head><p>We use the symbol N to specify that terms of order op (1/ fi) are neglected. The notation O,(.) and op(.) represent "in probability" counterparts of the corresponding deterministic notation (see Section 2.9 of [22]!. From (34), the estimation error can be expressed as 8 = 0 -Bo N -H-'V'. Let Q denote the limiting normalized covariance of the gradient</p><formula xml:id="formula_13">Q = lim NE[V'(&amp;)V"(B")].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N -x</head><p>Then, the covariance of the asymptotic distribution of the estimation error is</p><formula xml:id="formula_14">E[6eT] = C/N (37) c = H -~Q H -~. (<label>33</label></formula><formula xml:id="formula_15">)</formula><p>The asymptotic Hessian depends only on the limiting sample covariance and its eigendecomposition and is obtained as in the separate error source cases <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>: Next, note that only the ith column of G i , which is equal to W,.d,, is nonzero. This observation gives L : 2 -2 Re{dfW,IILW,E,W,E:W,{Gt*}.i} <ref type="bibr">(46)</ref> where {Gt*}.; = G{(G*G)-'}.i is the ith column of Gt*. The first-order relation between the estimated signal eigenvectors and the sample covariance matrix is (e.g., see <ref type="bibr" target="#b7">[8]</ref>) where the approximate derivative of the criterion function is expressed as the sum of three terms, the first stemming from the array modeling errors and the last two from the effects of noise. These terms take the form where m b i ( 2 , and B, are the deterministic vectors It is not difficult to see that the expected values of the crossterms (E[V,lVJ*], etc.) are zero, and hence, they do not contribute to Q. The terms E[VLkVJk] are evaluated in Appendix A, leading to the following result.</p><formula xml:id="formula_16">H = 2 R</formula><p>Theorem 1: Let B be obtained from <ref type="bibr" target="#b26">(28)</ref>, and let the perturbation models of Section 11-B hold. The covariance of the asymptotic distribution of the estimation error is then the sum of the error covariances derived in <ref type="bibr" target="#b3">[4]</ref> and [XI for each of the three sources of error considered separately. For large N, we have An expression for the asymptotic Hessian matrix H is given in (39). The effects of array perturbations (AP), noise covariance Proofi This result is also a straightforward application of It is interesting to see how (68) "interpolates" between the optimal weighting matrices for the individual AP, NP, and FS cases. Unfortunately, no overall optimal choice of weighting matrices has been derived in the general case for arbitrary array and noise model errors. However, one may still suggest reasonable choices that normally lead to improved performance, even if it is not proven to be optimal. A possible extension of Theorem 4 when ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_4">8</ref>) holds is simply to use (67) and (68) as is, even if B # I. Another interesting possibility, which has been motivated by the form of (68), is to modify the row weighting as Lemma A.2 of <ref type="bibr" target="#b25">[27]</ref>.</p><formula xml:id="formula_17">0 W, = (B + d-"' (69)</formula><p>where Q is a scaling that controls the relative contribution of the AP optimal row weighting W, = B-'12 and the NP + FS choice W, = I. Briefly, (Y should be small if array perturbations are the major source of error (high SNR and/or large N ) , whereas it should be chosen large if noise modeling errors and/or finite sample effects dominate. In more general cases, where <ref type="bibr" target="#b6">(7)</ref> and <ref type="bibr" target="#b7">(8)</ref> and/or (13) do not hold as stated, one can still use the above results to generate weighting matrices that improve performance, even if not proven to be optimal. This possiblility is further investigated in Examples 5.2 and 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Using Estimated Weighting Matrices</head><p>A difficulty with the implementation of the optimal SSF technique is that the weighting matrices depend, in general, on unknown quantities. A natural approach is to replace these by consistent estimates, but one may wonder if this approach leads to any performance loss. To verify that estimated weighting matrices do not deteriorate the asymptotic estimation accuracy, we shall first show the following more general result.</p><p>Lemma 1: Let d be obtained by minimizing the criterion function V(O,q), where the dependence on the parameter of interest, 0 and a nuisance parameter 77 has been stressed. The true values of 0 and 77 are assumed to be inner points of their respective definition sets, and the criterion function is assumed to be differentiable with respect to both arguments. Express the estimate of 0 as a function of 7). 6 = TI). and assume that the estimate is root-N consistent for all choices of 7). i.e., &amp;) -00 = O , ( l / J N ) (70) for all q. Then, q can be replaced by any (weakly) consjstent estimate without affecting the asymptotic properties of 8, i.e.</p><p>(71) i ( 7 , ) = e($ + o ? , ( l / J N ) .</p><p>Proof: The mean-value theorem implies that for some fj. However, the assumption (70) readily implies that U 8 8 = O , ( l / f l ) for all 71, and the result follows.</p><p>The weighting matrices of interest herein are restricted to be Hermitian and positive definite. To apply Lemma 1, we can, for example, parametrize W, using its Cholesky decomposition where Wf12 is lower triangular. The parameters qi of Lemma 1 can then be chosen as the real and imaginary parts of the elements of the nonzero part of W;I2. Since this parametrization clearly satisfies the requirements of the lemma, the following results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary I :</head><p>The weighting matrices of Theorems 2 4 can be replaced by consistent estimates without affecting the asymptotic optimality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXAMPLES</head><p>In this section, some numerical examples are presented to illustrate our results. Computer simulations are also included to investigate the applicability of the first-order expressions to realistic scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Example 5.1 : Unstructured Array and Noise Model Errors</head><p>In this scenario, the wavefield of two Gaussian signal sources is recorded using a perturbed uniform linear array (ULA) of 711 = 6 sensors with half-wavelength interelement spacing. The emitters are located at 6' = [O". 5"] relative to array broadside, which corresponds to an angle separation of a quarter of the Rayleigh beamwidth. The array response is perturbed according to the model ( <ref type="formula">7</ref>) and (8), with B = I and 1.0 0.7 = O.Ool [".7 1.01 A nondiagonal Y is assumed here since the DOA's are closely spaced so that some correlation between the perturbations is expected (it should be mentioned that this does not drastically affect the performance of any of the methods). The covariance of the additive noise is also assumed to be slightly perturbed from its nominal value a21. The noise model errors are generated according to the model ( <ref type="formula">12</ref>) and (13), with p2 = 0.001. The baseband signals are zero-mean Gaussian, 90% correlated, and of equal power, and the noise is assumed to have unit power (a2 = 1).</p><p>A batch of N = 100 snapshots is generated for a variety of SNR's, and the SSF technique of Section II-C is applied to each data set using W, = I and three different column weighted subspace fitting (WSF) <ref type="bibr" target="#b3">[4]</ref> to as robust subspace fitting (RSF) <ref type="bibr" target="#b7">[8]</ref>   The empirical RMS errors agree well with the theoretically predicted values for this case. Note also that, as expected, WSF is optimal for low SNR, RSF is optimal for high SNR, whereas OSF provides overall optimal estimates.</p><p>The previous example serves as an illustration of the performance improvement offered by the proposed method when the fairly restrictive perturbation model of Section 11-B holds exactly. A perhaps more interesting question in practice is whether the OSF weightings also can be used to reduce the sensitivity under more physically motivated error models. The next two examples address this point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . Example 5.2: A Weak Unmodeled Source</head><p>An important source of errors in the covariance matrix of the noise is the presence of (weak) undetected signal sources. This type of error gives rise to a highly directional perturbation that does not fit the model of ( <ref type="formula">12</ref>) and (13). Nevertheless, as illustrated in this example, the optimal weighting as derived in the previous section can be used to potentially reduce the sensitivity to such a perturbation. The scenario used here is as in Example 5.1 but without the unstructured array and noise perturbations. The SNR of the two signals is fixed to 10 dB, and an additional emitter of -10 dB SNR, uncorrelated with the signals of interest, is located at a varying DOA, ranging from 10 to 50". The probability of detecting the weak source using the technique proposed in <ref type="bibr" target="#b26">[28]</ref> is less than 30% for all cases. The empirical RMS error of the OSF (using (66) with p 2 / c 2 = 0.1) and WSF estimates is shown in Fig. <ref type="figure" target="#fig_7">2</ref>. Both methods were applied assuming d = 2 signals. In this case, only the results for $2 are shown; the performance difference for 01 is smaller in this scenario. This example suggests that by taking noise model errors into account, one can obtain an estimator that is less sensitive to the presence of weak undetected sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.rample 5.3: Antenna Position Errors</head><p>This example involves a ten-element, nominally uniform linear array with perturbed sensor positions. The standard deviation of the position errors in the direction perpendicular to the array is assumed to vary quadratically from X/3000 at one end of the array to X/30 at the other end, whereas the errors in the direction parallel to the array are assumed to be independent and a factor of smaller. This is similar to an example in <ref type="bibr" target="#b5">[6]</ref> that attempts to model the nonlinearity of an underwater towed array. This type of array perturbation leads to values for Y and B that are angle-dependent (see equation (37) of <ref type="bibr" target="#b5">[6]</ref>), and hence, no combined optimal weighting is possible. However, in an attempt to find a weighting that, at least heuristically, balances the two types of errors, we choose to use the weighting scheme (cf. (68) and (69) and note that , U = 0 in this example):</p><p>(74) </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Nt=l</head><label></label><figDesc>Under the stated assumptions, R takes the form R = (A+A)P(A+A)*+(A+A)z+z*(A+A)*+I= (18) As N -i 30, R converges (with probability 1) in the absence of model errors to the limit R = APA' + 021. (22)The rank of the signal covariance matrix P is denoted d'. Let the eigendecomposition of R be given by m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>T) = argrninllWr[E, -A(0)T]Wk/211$. e ,T 6 = arg miri V ( O ) V ( 0 ) = Tr{II*WrEsWcEzWr} (28) where I I l denotes the projector onto the nullspace of the matrix (W,A)*, i.e., I I ~ = I -nP = I -G ( G * G ) -~G * = I -G G ~ (29) G = W,A. (30)As detailed in<ref type="bibr" target="#b3">[4]</ref>, a number of important algorithms can be cast in the SSF framework by making appropriate choices for W, and W,. In particular, it has been shown that for the finite-sample-only case, the weighting matrices W</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>e { ( D * W , I I l W , D ) 0 ( T W , T * ) T } (39) where Re{} denotes the real part. (i! means elementwise multiplication, and (40) D = [d,. . . . . d,l] 36), the derivative of the criterion function is first calculated. Following [4], we have G t * } ] . (44) where G; is the derivative of G with respect to 6'; and Since IILW,.E, = 0, we have IILW,Es cv O , ( l / n ) , Gt* = G ( G * G ) -l . which gives V, 2 -2 Re[Tr{G:IILW,E,W,E:W,Gt*}]. (45)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>cv ITL W,RE,A-'. Using (18) and noting that ITLW,A = 0 and Z N O p ( l / f i ) , (47) leads to IILW,E, N I I l W , ( A P A * + Z*A* + E)E,A-'. (48) Inserting (48) into (45) gives</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>weighting matrices: W, = A2A;' (finite sample errors only), referred to as W, = (T*YTT)-' (array perturbations only), referred W, = ( T * Y ~T + / L 2 A p 2 + -A -2 ~s ) -' (overall optimal weighting), referred to as optimal subspace fitting (OSF).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Theoretical and empirical RMS error versus SNR for the SSF technique using different column weighting matrices, and perturbations in both the array and noise models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 depicts the results of a Monte-Carlo simulation involving 256 independent trials for each SNR. The lines represent the error predicted by the theoretical expressions of Section 111, whereas the symbols indicate the empirically calculated RMS errors. Only the results for the estimation of 81 = 0" are shown, where the results for 82 are similar.The empirical RMS errors agree well with the theoretically predicted values for this case. Note also that, as expected, WSF is optimal for low SNR, RSF is optimal for high SNR, whereas OSF provides overall optimal estimates.The previous example serves as an illustration of the performance improvement offered by the proposed method when the fairly restrictive perturbation model of Section 11-B holds exactly. A perhaps more interesting question in practice is whether the OSF weightings also can be used to reduce the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Empirical RMS error versus the location of a weak (-10 dB) undetected signal source.</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The assosciate editor coordinating the review of this paper and approving it for publication was Prof. Daniel Fuhrmann. This work was supported by the National Science Foundation under grant MIP-9110112. by the SDIOflST Program managed by the Army Research Office under Contract DAAL03-90-G-0108, and by the Advanced Research Projects Agency of the Department of Defense monitored by the Air Force Office of Scientific Research under Contract F49620-9 1 -C-0086.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The fact that C is written as a sum of the individual error covariances is independent of the specific models used in Section 11-B; in fact, the above result would hold for any of the error models CAP and CNP described in [SI. In addition, even though our results have been derived specifically for certain multidimensional SSF algorithms, expressions identical to (56) and (57) hold for the MUSIC algorithm <ref type="bibr">[23]</ref> if one replaces the individual error covariances with those derived in <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b5">[6]</ref> and for the ESPRIT algorithm <ref type="bibr" target="#b22">[24]</ref> if one uses the results of <ref type="bibr">[25]</ref> and <ref type="bibr" target="#b24">[26]</ref>.</p><p>Remark 1: The precise mathematical meaning of Theorem 1 is that the covariance matrix of the estimation error in the limiting distribution is given by (55). However, a pragmatic use of the result for finite N is, of course, to substitute Y = N T in (58) and p 2 = Np' in (59) and to use the resulting matrix C/N to predict the covariance matrix of the estimation error itself (rather than the covariance of the distribution). If N is "large enough" and v:, i = 1, . . . . d and p2 are "small enough," the theoretical results do indeed agree well with empirical observations obtained via simulations, as demonstrated in Section V.</p><p>We also note that with the substitutions Y = N Y and ,!i2 = N p 2 , the covariance C/N does not go to zero as N 4 30 but rather converges to the expression obtained in <ref type="bibr" target="#b7">[8]</ref> for model errors only. Similarly, for fixed N , letting T ---f 0 and p -+ 0 in C/N yields the covariance for the finite sample only case considered in <ref type="bibr" target="#b3">[4]</ref>. Thus, even though our analysis was conducted assuming U,?, + p2 cv 0(1/N), the results of Theorem 1 can be applied to the limiting cases as well. 0 Appendix A. U</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OPTIMALLY WEIGHTED SUBSPACE FITTING</head><p>The expression for the asymptotic variance of the DOA estimates derived in the previous section is useful for predicting algorithm performance. This can be done by simply substituting into the error expressions the appropriate error model, error variances, and weighting matrices corresponding to the algorithm of interest. Another important problem is selecting the weighting matrices W, and W, so that the resulting estimation error is minimized. Because of the nature of the expressions (58)-(60), it is convenient to first consider the case of array perturbations only and then noise covariance perturbations plus finite sample effects separately. The weight optimization closely follows the corresponding results in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b7">[8]</ref>, and the proofs are therefore omitted. The expressions will be given using the original perturbation variances T and pz rather than the N-normalized quantities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Array Perturbations</head><p>This case is treated in <ref type="bibr" target="#b7">[ 8 ]</ref> , where the result is repeated below for reference. </p><p>for all possible W, &gt; 0 and W, &gt; 0. Here, the matrix inequality A 2 B means that the difference A -B is positive semidefinite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B . Noise Covariance and Finite Sample Effects</head><p>In this case, we have the following result:</p><p>Theorem 3: Assume that T = 0 so that only the effects of noise (including possibly an imprecisely known covariance matrix) contribute to the estimation error. Then, it holds that (64) Since a scaling does not affect the result, the optimal weighting matrices are</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W , = I (65)</head><p>Proof: This result follows by applying Lemma A.2 of <ref type="bibr" target="#b25">[27]</ref> to the expressions (39), (56), (59), and (60).</p><p>Note that the interesting quantity is the ratio of the variance of the noise covariance perturbation and the variance of the noise itself, i.e., the relative perturbation on each element of the noise covariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C . Combined Errors</head><p>For the special case of uniform array perturbations, the following result provides the overall optimal weighting matrices when all error sources are present.  The structure assumed for B in (79) is motivated by the covariance expressions given in equation (37) of <ref type="bibr" target="#b5">[6]</ref> for antenna position errors. The scaling term [j is used to guarantee that our heuristic weighting matrices converge to the WSF weightings when IlBll &lt;&lt; c r z / ( N ~~A s ~~) .</p><p>The performance of the SSF approach using these weighting matrices is compared with WSF and RSF for a scenario involving two uncorrelated, 20-dB emitters located at 10 and 15" relative to array broadside. A total of 1000 Monte-Carlo trials are conducted for various values of N , and the number of snapshots and the results are plotted in Fig. <ref type="figure">3</ref> along with the corresponding CRB <ref type="bibr">[16]</ref>. Here, OSF refers to the combined weighting matrices above. The lines in the figure correspond to our theoretical analysis, whereas the symbols represent the empirical results. The advantage of the combined weighting is clearly evident in these results, and the agreement with the theoretical curves is reasonably good. The slight discrepancy for N = 10,20 is due to the fact that our analysis is asymptotic in N . Despite this, the empirical results are within 5% of the theoretical predictions for N as small as 20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>found to accurately predict empirical mean-square errors down to the threshold region. The derivation of optimal weighting matrices required a fairly simplistic model of the array response and noise covariance perturbations. However, for more complicated models, heuristic weighting matrices based on our analysis will often lead to significantly improved performance as compared with not taking the model errors into account. This is illustrated by two examples involving underestimation of the number of signals and nonuniform sensor position errors.</p><p>Implementation of the overall optimal technique requires knowledge of the covariances of the perturbation terms. An interesting question not considered herein is the sensitivity to misspecifications of these quantities. However, we should point out that the first-order effect of such errors vanish (by Corollary 1 in Section IV). Moreover, if the misspecification is a small scaling error, the proposed optimal weighting matrix is still a reasonable interpolation between the optimal weightings designed for one error source (array errors, noise covariance errors, or finite sample errors) only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A P R O O F O F THEOREM 1</head><p>In this Appendix, the terms E[V&amp;V,k] are evaluated, where VLk is defined in (50)-( <ref type="formula">52</ref>  </p><p>where the expressions for the matrices involved are as given in ( 5 8)-( 60).  <ref type="bibr">[1985]</ref><ref type="bibr">[1986]</ref><ref type="bibr">[1987]</ref><ref type="bibr">[1988]</ref>, and during that time, he was affiliated with the Information Systems Laboratory at Stanford University. From 1986-1990, he was also employed at ESL, Inc., of Sunnyvale, CA, where he was involved in the design of algorithms and architectures for a variety of radar and sonar signal processing systems. He joined the faculty of the Department of Electrical and Computer Engineering at Brigham Young University in 1990. where he is currently an Assistant Professor. His research interests include sensor array signal processing, detection and estimation theory, system identification, and control.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analysis of the asymptotic relative efficiency of the MUSIC algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Porat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Friedlander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aumst. Speech Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="532" to="544" />
			<date type="published" when="1988-04">Apr. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MUSIC, maximum likelihood and Cramer-Rao bound</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nehorai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. IEEE Trans Acoust. Speech Signal Proc,essrng</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="720" to="741" />
			<date type="published" when="1989-05">May 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Performance of high resolution frequencies estimation methods compared to the Cramer-Rao bounds</title>
		<author>
			<persName><forename type="first">H</forename><surname>Clegeot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tressens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ouamri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. IEEE Trans. Amust. Speech Signal Proc.essin,q</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1703" to="1720" />
			<date type="published" when="1989-11">Nov. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sensor array processing based on subspace fitting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Viberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1110" to="1121" />
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sensitivity analysis of the maximum likelihood direction-finding algorithm</title>
		<author>
			<persName><forename type="first">Si</forename><forename type="middle">B</forename><surname>Friedlander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerospace Electron. Sysf</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="953" to="968" />
			<date type="published" when="1990-11">Nov. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A performance analysis of subspacebased methods in the presence of model errors-Part I: The MUSIC algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Swindlehurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1758" to="1774" />
			<date type="published" when="1992-07">July 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sensitivity analysis of DOA estimation algorithms to sensor errors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vaccaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerospace Electron Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="708" to="717" />
			<date type="published" when="1992-07">July 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A performance analysis of subspacebased methods in the presence of model errors-Part 11: Multidimensional algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Swindlehurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1277" to="1308" />
			<date type="published" when="1993-09">Sept. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Performance degradation of DOA estimators due to unknown noise fields</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Vaccaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP 91</title>
		<meeting>ICASSP 91<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-05">May 1991</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1413" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimation of the directions of amval of signals in unknown correlated noise, Parts I and 11</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2007" to="2028" />
			<date type="published" when="1992-03">Mar. 1992. Aug. 1992</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detection and localization of multiple sources in noise with unknown covariance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wax</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="245" to="249" />
			<date type="published" when="1992-01">Jan. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Array shape calibration using sources in unknown locations-Part I: Far-field sources</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rockah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Schultheiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">286299</biblScope>
			<date type="published" when="1987-03">Mar. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Array shape calibration using sources in unknown locations-A maximum likelihood approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Friedlander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust.. Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1958" to="1966" />
			<date type="published" when="1989-12">Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Observability conditions for multiple signal direction finding and array sensor location</title>
		<author>
			<persName><forename type="first">]</forename><forename type="middle">J T</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Marple</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2641" to="2650" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust signal parameter estimation in the presence of array perturbations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wahlberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Bayesian approach to autocalibration for parameteric array signal processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Viberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swindlehurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">IEEE Trans. Signal Processing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">System Identification: Theory for the User</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ljung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The effect of random steering vector errors in the Applebaum adaptive array</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Compton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerospace Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="392" to="400" />
			<date type="published" when="1982-09">Sept. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Error analysis of the optimal antenna array processors</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Godara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerospace Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">395409</biblScope>
			<date type="published" when="1986-07">July 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adaptive beamforming with the generalized sidelobe canceller in the presence of array imperfections</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Jablon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Antennas Propagat</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">9961012</biblScope>
			<date type="published" when="1986-08">Aug. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Mardia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bibby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariare Analysis</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Academic</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A signal subspace approach to multiple emitter location and spectral estimation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">0</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981-11">Nov. 1981</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D thesis</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ESPRIT-Estimation of signal parameters via rotational invariance techniques</title>
		<author>
			<persName><forename type="first">R</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech, Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="98" to="995" />
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Performance analysis of the total least squares ESPRIT algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1122" to="1135" />
			<date type="published" when="1991-05">May 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the sensitivity of the ESPRIT algorithm to non-identical subarrays</title>
		<author>
			<persName><forename type="first">A</forename><surname>Swindlehurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sridhanri. Acad. Proc. Eng. Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="197" to="212" />
			<date type="published" when="1990-11">Nov. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MUSIC, maximum likelihood and Cramer-Rao bound: Further results and comparisons</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nehorai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust., Speech Signal process in^</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2140" to="2150" />
			<date type="published" when="1990-12">Dec. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Detection and estimation in sensor arrays using weighted subspace fitting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Viberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kailath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">24362449</biblScope>
			<date type="published" when="1991-11">Nov. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
