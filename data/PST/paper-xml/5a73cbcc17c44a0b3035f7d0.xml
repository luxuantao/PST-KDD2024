<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VulDeePecker: A Deep Learning-Based System for Vulnerability Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-01-05">5 Jan 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">School of Cyber Security and Computer</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hebei University â€¡ Shenzhen Huazhong University of Science and Technology Research Institute</orgName>
								<orgName type="institution" key="instit2">University of Texas at San Antonio</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Deqing</forename><surname>Zou</surname></persName>
							<email>deqingzou@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shouhuai</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xinyu</forename><surname>Ou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hai</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sujuan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhijun</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuyi</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Services Computing Technology and System Lab, Big Data Technology and System Lab, Cluster and Grid Computing Lab</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">VulDeePecker: A Deep Learning-Based System for Vulnerability Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-01-05">5 Jan 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">B78F4BB39917FF20465EAF2009114ACA</idno>
					<idno type="DOI">10.14722/ndss.2018.23158</idno>
					<idno type="arXiv">arXiv:1801.01681v1[cs.CR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The automatic detection of software vulnerabilities is an important research problem. However, existing solutions to this problem rely on human experts to define features and often miss many vulnerabilities (i.e., incurring high false negative rate). In this paper, we initiate the study of using deep learning-based vulnerability detection to relieve human experts from the tedious and subjective task of manually defining features. Since deep learning is motivated to deal with problems that are very different from the problem of vulnerability detection, we need some guiding principles for applying deep learning to vulnerability detection. In particular, we need to find representations of software programs that are suitable for deep learning. For this purpose, we propose using code gadgets to represent programs and then transform them into vectors, where a code gadget is a number of (not necessarily consecutive) lines of code that are semantically related to each other. This leads to the design and implementation of a deep learning-based vulnerability detection system, called Vulnerability Deep Pecker (VulDeePecker). In order to evaluate VulDeePecker, we present the first vulnerability dataset for deep learning approaches. Experimental results show that VulDeePecker can achieve much fewer false negatives (with reasonable false positives) than other approaches. We further apply VulDeePecker to 3 software products (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which are not reported in the National Vulnerability Database but were "silently" patched by the vendors when releasing later versions of these products; in contrast, these vulnerabilities are almost entirely missed by the other vulnerability detection systems we experimented with.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Many cyber attacks are rooted in software vulnerabilities. Despite the effort that has been invested in pursuing secure programming, software vulnerabilities remain, and will continue, to be a significant problem. This can be justified by the fact Corresponding author that the number of vulnerabilities registered in the Common Vulnerabilities and Exposures (CVE) was approximately 4,600 in 2010, and grew to approximately 6,500 in 2016 <ref type="bibr" target="#b16">[4]</ref>. An alternate approach is to automatically detect vulnerabilities in software programs, or simply programs for short. There have been many static vulnerability detection systems and studies for this purpose, ranging from open source tools <ref type="bibr" target="#b17">[6]</ref>, <ref type="bibr" target="#b22">[11]</ref>, <ref type="bibr" target="#b62">[52]</ref>, to commercial tools <ref type="bibr">[2]</ref>, <ref type="bibr" target="#b15">[3]</ref>, <ref type="bibr" target="#b18">[7]</ref>, to academic research projects <ref type="bibr">[19]</ref>, <ref type="bibr" target="#b38">[28]</ref>, <ref type="bibr" target="#b42">[32]</ref>, <ref type="bibr" target="#b47">[37]</ref>, <ref type="bibr" target="#b48">[38]</ref>, <ref type="bibr" target="#b59">[49]</ref>, <ref type="bibr" target="#b69">[59]</ref>, <ref type="bibr" target="#b70">[60]</ref>. However, existing solutions for detecting vulnerabilities have two major drawbacks: imposing intense manual labor and incurring high false negative rates, which are elaborated below.</p><p>On one hand, existing solutions for vulnerability detection rely on human experts to define features. Even for experts, this is a tedious, subjective, and sometimes error-prone task because of the complexity of the problem. In other words, the identification of features is largely an art, meaning that the quality of the resulting features, and therefore the effectiveness of resulting detection system, varies with the individuals who define them. In principle, this problem can be alleviated by asking multiple experts to define their own features, and then select the set of features that lead to better effectiveness or use a combination of these features. However, this imposes even more tedious work. As a matter of fact, it is always desirable to reduce, or even eliminate whenever possible, the reliance on the intense labor of human experts. This can be justified by the trend of cyber defense automation, which is catalyzed by initiatives such as DARPA's Cyber Grand Challenge <ref type="bibr">[5]</ref>. It is therefore important to relieve human experts from the tedious and subjective task of manually defining features for vulnerability detection.</p><p>On the other hand, existing solutions often miss many vulnerabilities or incur high false negative rates. For example, two most recent vulnerability detection systems, VUDDY <ref type="bibr" target="#b38">[28]</ref> and VulPecker <ref type="bibr" target="#b42">[32]</ref>, respectively incur a false negative rate of 18.2% (when detecting vulnerabilities of Apache HTTPD 2.4.23) and 38% (when applied to 455 vulnerability samples). Our own independent experiments show that they respectively incur a false negative rate of 95.1% and 89.8% (see Table <ref type="table" target="#tab_10">V</ref> in Section IV). Note that the large discrepancy between the false negative rates reported in <ref type="bibr" target="#b38">[28]</ref>, <ref type="bibr" target="#b42">[32]</ref> and the false negative rates derived from our experiments is caused by the use of different datasets. These high false negative rates may be justified by their emphasis on low false positive rates, which are respectively 0% for VUDDY <ref type="bibr" target="#b38">[28]</ref> and unreported for VulPecker <ref type="bibr" target="#b42">[32]</ref>. Our independent experiments show that their false positive rates are respectively 0% for VUDDY and 1.9% for VulPecker (see Table V in Section IV). This suggests that VUDDY and VulPecker are designed to achieve low false positive rates, which appear to be inherent to the approach of detecting vulnerabilities caused by code clones; in contrast, when using this approach to detecting vulnerabilities that are not caused by code clones, high false negative rates occur.</p><p>It would be fair to say that vulnerability detection systems with high false positive rates may not be usable, vulnerability detection systems with high false negative rates may not be useful. This justifies the importance of pursuing vulnerability detection systems that can achieve low false negative rates and low false positive rates. When this cannot be achieved (because false positive and false negative are often at odds with each other), we may put emphasis on lowering the false negative rate as long as the false positive rate is not too high.</p><p>The aforementioned two limitations of existing solutions motivate the importance of designing the vulnerability detection system without asking human experts to manually define features and without incurring high false negative rate or false positive rate. In this paper, we propose a solution to the following vulnerability detection problem while bearing in mind with these limitations: Given the source code of a target program, how can we determine whether or not the target program is vulnerable and if so, where are the vulnerabilities?</p><p>Our contributions. The present paper represents a first step towards ultimately tackling the aforesaid problem. Specifically, we make three contributions.</p><p>First, we initiate the study of using deep learning for vulnerability detection. This approach has a great potential because deep learning does not need human experts to manually define features, meaning that vulnerability detection can be automated. However, this approach is challenging because deep learning is not invented for this kind of applications, meaning that we need some guiding principles for applying deep learning to vulnerability detection. We discuss some preliminary guiding principles for this purpose, including the representation of software programs to make deep learning suitable for vulnerability detection, the determination of granularity at which deep learning-based vulnerability detection should be conducted, and the selection of specific neural networks for vulnerability detection. In particular, we propose using code gadgets to represent programs. A code gadget is a number of (not necessarily consecutive) lines of code that are semantically related to each other, and can be vectorized as input to deep learning.</p><p>Second, we present the design and implementation of a deep learning-based vulnerability detection system, called Vulnerability Deep Pecker (VulDeePecker). We evaluate the effectiveness of VulDeePecker from the following perspectives:</p><p>â€¢ Can VulDeePecker deal with multiple types of vulnerabilities at the same time? This perspective is important because a target program in question may contain multiple types of vulnerabilities, meaning that a vulnerability detection system that can detect only one type of vulnerabilities would be too limited. Experimental results answer this question affirmatively. This can be explained by the fact that VulDeePecker uses vulnerability patterns (learned as deep neural networks) to detect vulnerabilities.</p><p>â€¢ Can human expertise help improve the effectiveness of VulDeePecker? Experimental results show that the effectiveness of VulDeePecker can be further improved by incorporating human expertise, which is not for defining features though. This hints that automatic vulnerability detection systems, while being able to relieve human experts from the tedious labor of defining features, may still need to leverage human expertise from other purposes. This poses an important open problem for future study.</p><p>â€¢ How effective is VulDeePecker when compared with other vulnerability detection approaches? Experimental results show that VulDeePecker is much more effective than the other static analysis tools, which ask human experts to define rules for detecting vulnerabilities, and the state-of-the-art code similaritybased vulnerability detection systems (i.e., VUDDY and VulPecker).</p><p>These questions may be seen as an initial effort at defining a benchmark for evaluating the effectiveness of deep learningbased vulnerability detection systems.</p><p>In order to show the usefulness of VulDeePecker, we further apply it to 3 software products (namely Xen, Seamonkey, and Libav). VulDeePecker is able to detect 4 vulnerabilities, which are not reported in the National Vulnerability Database (NVD) <ref type="bibr" target="#b21">[10]</ref> but were "silently" patched by the vendors when releasing later versions of these products. In contrast, these vulnerabilities are almost entirely missed by the other vulnerability detection systems we experimented with. More precisely, one of those vulnerability detection systems is able to detect 1 of the 4 vulnerabilities (i.e., missing 3 of the 4 vulnerabilities), while the other systems missed all of the 4 vulnerabilities. We will conduct more experiments to show whether or not VulDeePecker can detect vulnerabilities that have not been identified, including possibly 0-day vulnerabilities.</p><p>Third, since there are no readily available datasets for answering the questions mentioned above, we present the first dataset for evaluating VulDeePecker and other deep learningbased vulnerability detection systems that will be developed in the future. The dataset is derived from two data sources maintained by the National Institute of Standards and Technology (NIST): the NVD <ref type="bibr" target="#b21">[10]</ref> and the Software Assurance Reference Dataset (SARD) project <ref type="bibr" target="#b23">[12]</ref>. The dataset contains 61,638 code gadgets, including 17,725 code gadgets that are vulnerable and 43,913 code gadgets that are not vulnerable. Among the 17,725 code gadgets that are vulnerable, 10,440 code gadgets correspond to buffer error vulnerabilities (CWE-119) and the rest 7,285 code gadgets correspond to resource management error vulnerabilities (CWE-399). We have made the dataset available at https://github.com/CGCL-codes/VulDeePecker. Paper organization. The rest of the paper is organized as follows. Section II presents some preliminary guiding prin-ciples for deep learning-based vulnerability detection. Section III discusses the design of VulDeePecker. Section IV describes our experimental evaluation of VulDeePecker and results. Section V discusses the limitations of VulDeePecker and open problems for future research. Section VI describes the related prior work. Section VII concludes the present paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. GUIDING PRINCIPLES FOR DEEP LEARNING-BASED VULNERABILITY DETECTION</head><p>In this section, we propose some preliminary guiding principles for using deep learning to detect vulnerabilities. These principles are sufficient for the present study, but may need to be refined to serve the more general purpose of deep learning-based vulnerability detection. These principles are centered at answering three fundamental questions: (i) How to represent programs for deep learning-based vulnerability detection? (ii) What is the appropriate granularity for deep learning-based vulnerability detection? (iii) How to select a specific neural network for vulnerability detection?</p><p>A. How to represent software programs?</p><p>Since deep learning or neural networks take vectors as input, we need to represent programs as vectors that are semantically meaningful for vulnerability detection. In other words, we need to encode programs into vectors that are the required input for deep learning. Note that we cannot arbitrarily transform a program into vectors because the vectors need to preserve the semantic information of the program. This suggests us to use some intermediate representation as a "bridge" between a program and its vector representation, which is the actual input to deep learning. This leads to the following:</p><p>Guiding Principle 1: Programs can be first transformed into some intermediate representation that can preserve (some of) the semantic relationships between the programs' elements (e.g., data dependency and control dependency). Then, the intermediate representation can be transformed into a vector representation that is the actual input to neural networks.</p><p>As we will elaborate later, Guiding Principle 1 leads us to propose an intermediate representation dubbed code gadget. The term code gadget is inspired by the term of gadget in the context of code-reuse attacks (see, e.g., <ref type="bibr">[18]</ref>), because a code gadget is a small number of (not necessarily consecutive) lines of code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. What is an appropriate granularity?</head><p>Since it is desirable not only to detect whether a program is vulnerable or not, but also to pin down the locations of the vulnerabilities, a finer granularity should be used for deep learning-based vulnerability detection. This means that vulnerability detection should not be conducted at the program or function level, which are too coarse-grained because a program or function may have many lines of code and pinning down the locations of its vulnerability can be a difficult task by itself. This leads to:</p><p>Guiding Principle 2: In order to help pin down the locations of vulnerabilities, programs should be represented at a finer granularity than treating a program or a function as a unit.</p><p>Indeed, the aforementioned code gadget representation leads to a fine-grained granularity for vulnerability detection because a code gadget often consists of a small number of lines of code. This means that the code gadget representation naturally satisfies Guiding Principle 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. How to select neural networks?</head><p>Neural networks have been very successful in areas such as image processing, speech recognition, and natural language processing (e.g., <ref type="bibr" target="#b31">[21]</ref>, <ref type="bibr" target="#b40">[30]</ref>, <ref type="bibr" target="#b50">[40]</ref>), which are different from vulnerability detection. This means that many neural networks may not be suitable for vulnerability detection, and that we need some principles to guide the selection of neural networks that are suitable for vulnerability detection. Our examination suggests the following:</p><p>Guiding Principle 3: Because whether or not a line of code contains a vulnerability may depend on the context, neural networks that can cope with contexts may be suitable for vulnerability detection. This principle suggests that neural networks for natural language processing may be suitable for vulnerability detection because context is also important in natural language processing <ref type="bibr" target="#b43">[33]</ref>. Putting the notion of context into the setting of the present paper, we observe that the argument(s) of a program function call is often affected by earlier operations in the program and may also be affected by later operations in the program.</p><p>Since there are many neural networks for natural language processing, let us start with Recurrent Neural Networks (RNNs) <ref type="bibr" target="#b61">[51]</ref>, <ref type="bibr" target="#b63">[53]</ref>. These neural networks are effective in coping with sequential data, and indeed have been used for program analysis (but not for vulnerability detection purposes) <ref type="bibr" target="#b30">[20]</ref>, <ref type="bibr" target="#b58">[48]</ref>, <ref type="bibr" target="#b66">[56]</ref>, <ref type="bibr" target="#b67">[57]</ref>. However, RNNs suffer from the Vanishing Gradient (VG) problem, which can cause ineffective model training <ref type="bibr" target="#b26">[16]</ref>. Note that the VG problem is inherited by the Bidirectional variant of RNNs, called BRNNs <ref type="bibr" target="#b57">[47]</ref>. We would prefer neural networks that do not suffer from the VG problem.</p><p>The VG problem can be addressed with the idea of memory cells into RNNs, including the Long Short-Term Memory (LSTM) cell and the Gated Recurrent Unit (GRU) cell <ref type="bibr" target="#b27">[17]</ref>, <ref type="bibr" target="#b32">[22]</ref>. Since the GRU does not outperform the LSTM on language modeling <ref type="bibr" target="#b37">[27]</ref>, we select LSTM for vulnerability detection and defer its comparison with GRU to future work. However, even LSTM may be insufficient for vulnerability detection because it is unidirectional (i.e., from earlier LSTM cells to later LSTM cells). This is because the argument(s) of a program function call may be affected by earlier statements in the program and may be also affected by the later statements. This suggests that unidirectional LSTM may be insufficient and that we should use Bidirectional LSTM (BLSTM) for vulnerability detection.</p><p>Figure <ref type="figure">1</ref> highlights the structure of BLSTM neural network, which has a number of BLSTM layers, a dense layer, and a softmax layer. The input to the learning process is in a certain vector representation. The BLSTM layers have two directions, forward and backward. The BLSTM layers contain some complex LSTM cells, which are treated as black-boxes in the present paper and therefore deferred to Appendix A. The dense layer reduces the number of dimensions of the vectors received from the BLSTM layers. The softmax layer takes the low-dimension vectors received from the dense layer as input, and is responsible for representing and formatting the classification result, which provides feedback for updating the neural network parameters in the learning phase. The output of the learning phase is a BLSTM neural network with finetuned model parameters, and the output of the detection phase is the classification results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DESIGN OF VULDEEPECKER</head><p>Our objective is to design a vulnerability detection system that can automatically tell whether a given program in source code is vulnerable or not and if so, the locations of the vulnerabilities. This should be achieved without asking human experts to manually define features and without incurring high false negative rates (as long as the false positive rates are reasonable). In this section, we describe the design of VulDeePecker. We start with a discussion on the notion of code gadget, because it is crucial to the representation of programs. Then, we give an overview of VulDeePecker and elaborate its components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Defining code gadget</head><p>In order to represent programs in vectors that are suitable for the input to neural networks, we first propose transforming programs into a representation of code gadget, which is defined as follows:</p><p>Definition 1: (Code gadget) A code gadget is composed of a number of program statements (i.e., lines of code), which are semantically related to each other in terms of data dependency or control dependency.</p><p>In order to generate code gadgets, we propose the heuristic concept of key point, which can be seen as a "lens" through which we can represent programs from a certain perspective. Intuitively, the heuristic concept of key point can be seen as, in a sense, the "center" of a vulnerability or the piece of code that hints the existence of a vulnerability. For vulnerabilities that are caused by improper uses of library/API function calls, the key points are the library/API function calls; for vulnerabilities that are caused by improper uses of arrays, the key points are the arrays. It is important to note that a type of vulnerabilities may have multiple kinds of key points. For example, buffer error vulnerabilities may correspond to the following key points: library/API function calls, arrays, and pointers. Moreover, the same kind of key points may exist in multiple types of vulnerabilities. For example, both buffer error and resource management error vulnerabilities may contain the key points of library/API function calls. Precisely defining the heuristic concept of key point is beyond the scope of the present paper and is left as an interesting problem for future research; instead, we focus on using this heuristic concept as the "lens" to use deep learning to learn vulnerability patterns.</p><p>In this paper, we focus on using the particular key point of library/API function calls to demonstrate its usefulness in deep learning-based vulnerability detection. This is motivated by the observation that many vulnerabilities are related to library/API function calls. It is also an interesting future work to investigate the usefulness of other kinds of key points.</p><p>Corresponding to the key point of library/API function calls, code gadgets can be generated by the means of data flow or control flow analysis of program, for which there are well known algorithms <ref type="bibr" target="#b33">[23]</ref>, <ref type="bibr" target="#b60">[50]</ref> and readily usable commercial products such as Checkmarx <ref type="bibr">[2]</ref>. It is worth mentioning that Checkmarx also detects vulnerabilities based on some rules that are manually defined by human experts. However, we do not use its rules for vulnerability detection; instead, we will compare the effectiveness of VulDeePecker against it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Overview of VulDeePecker</head><p>As highlighted in Figure <ref type="figure" target="#fig_0">2</ref>, VulDeePecker has two phases: a learning (i.e., training) phase and a detection phase. The input to the learning phase is a large number of training programs, some of which are vulnerable and the others are not. By "vulnerable" we mean that a program contains one or multiple known vulnerabilities. The output of the learning phase is vulnerability patterns, which are coded into a BLSTM neural network.</p><p>1) The learning phase: As highlighted in Figure <ref type="figure" target="#fig_0">2</ref>(a), the learning phase has 4 steps.</p><p>Step I: Extracting the library/API function calls and the corresponding program slices. This has two sub-steps, which are highlighted below and elaborated in Section III-C.  <ref type="bibr" target="#b65">[55]</ref>.</p><p>Step II: Generating code gadgets and their ground truth labels</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Step III: Transforming code gadgets into vectors</p><p>Step II.2: Each code gadget is labeled as "1" or "0"</p><p>Step </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Output</head><p>Trained BLSTM neural network with fine-tuned model parameters</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step V: Transforming target programs into code gadgets and vectors</head><p>Step VI: Detection</p><p>Step Step II: Generating code gadgets of the training programs and their ground truth labels. This step has two sub-steps, which are highlighted below and elaborated in Section III-D. â€¢</p><p>Step II.2: Labeling the ground truth of code gadgets. This step labels each code gadget as "1" (i.e., vulnerable) or "0" (i.e., not vulnerable). The ground truth labels of code gadgets are available because we know whether a training program is vulnerable or not and if it is vulnerable, we also know the locations of the vulnerabilities.</p><p>Step III: Transforming code gadgets into vector representations. This step has two sub-steps, which are highlighted below and elaborated in Section III-E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>Step III.1: Transforming code gadgets into certain symbolic representations, which will be elaborated later. This step aims to preserve some semantic information of the training programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢</head><p>Step III.2: Encoding code gadgets in the symbolic representation obtained in Step III.1 into vectors, which are the input for training a BLSTM neural network. This is necessary in order to use neural networks in general.</p><p>Step IV: Training a BLSTM neural network. Having encoded the code gadgets into vectors and obtained their ground truth labels, the training process for learning a BLSTM neural network is standard.</p><p>2) The detection phase: Given one or multiple target programs, we extract library/API function calls from them as well as the corresponding program slices, which are assembled into code gadgets. The code gadgets are transformed into their symbolic representations, which are encoded into vectors and used as input to the trained BLSTM neural network. The network outputs which vectors, and therefore which code gadgets, are vulnerable ("1") or not ("0"). If a code gadget is vulnerable, it pins down the location of the vulnerability in the target program. As highlighted in Figure <ref type="figure" target="#fig_0">2</ref>(b), this phase has two steps.</p><p>Step V: Transforming target programs into code gadgets and vectors. It has five sub-steps.</p><p>â€¢ Step V.1: Extracting library/API function calls from the target programs (similar to Step I.1).</p><p>â€¢ Step V.2: Extracting program slices according to the arguments of the library/API function calls (similar to</p><p>Step I.2).</p><p>â€¢ Step V.3: Assembling the program slices into code gadgets (similar to Step II.1).</p><p>â€¢ Step V.4: Transforming the code gadgets to their symbolic representations (similar to Step III.1).</p><p>â€¢ Step V.5: Encoding the symbolic representations of code gadgets into vectors (similar to Step III.2).</p><p>Step VI: Detection. This step uses the learned BLSTM neural network to classify the vectors corresponding to the code </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Backward fu nction call</head><p>The backward function call strcpy has two arguments, buf and str, each of which leads to a backward slice. The slice corresponding to buf consists of statements belong ing to the user-defined function test (indicated by a dashed rectangle). The slice corresponding to str consists of statements scattered in two user-defined functions, main and test, which are also indicated by dashed rectangles. gadgets that are extracted from the target programs. When a vector is classified as "1" (i.e., vulnerable), it means that the corresponding code gadget is vulnerable and the location of the vulnerability is pinned down. Otherwise, the corresponding code gadget is classified as "0" (i.e., not vulnerable).</p><p>Steps I-III are respectively elaborated in the following subsections. Steps IV and VI are standard and Step V is similar to some of Steps I-III.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Step I: Extracting library/API function calls and program slices 1)</head><p>Step I.1: Extracting library/API function calls: We classify library/API function calls into two categories: forward library/API function calls and backward library/API function calls. Forward library/API function calls are the function calls that receive one or multiple inputs directly from the external input, such as the command line, a program, a socket, or a file. For example, the recv function call is a forward library/API function call because it receives data from a socket directly. Backward library/API function calls are the function calls that do not receive any external input directly from the environment in which the program runs. Figure <ref type="figure" target="#fig_5">3</ref> shows an example of a backward library/API function call strcpy (line 9). It is a backward library/API function call because it does not receive any external input directly.</p><p>We highlight a distinction between forward and backward library/API function calls. For forward library/API function calls, the statements influenced by the input arguments are critical because they may be vulnerable to improper (e.g., sophisticatedly crafted) argument values; for backward library/API function calls, the statements influencing the values of the arguments are critical because they could make the library/API function calls vulnerable. This insight will be leveraged to guide the heuristic padding of the vector representations of code gadgets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>Step I.2: Extracting program slices: This step generates program slices corresponding to the arguments of the library/API function calls that are extracted from the training programs. We define two kinds of slices: forward slices and backward slices, where a forward slice corresponds to the statements that are affected by the argument in question and a backward slice corresponds to the statements that can affect the argument in question. We take advantage of the commercial product Checkmarx <ref type="bibr">[2]</ref>, more specifically its data dependency graph, to extract these two kinds of slices. The basic idea is the following:</p><p>â€¢ For each argument in a forward library/API function call, one or multiple forward slices are generated, with the latter corresponding to the case that the slice related to the argument is branched at, or after, the library/API function call.</p><p>â€¢ For each argument in a backward library/API function call, one or multiple backward slices are generated, with the latter corresponding to the case that multiple slices related to the argument are merged at, or prior to, the library/API function call.</p><p>Note that a program slice consists of multiple statements that may belong to multiple user-defined functions. That is, a slice can go beyond the boundary of user-defined functions in question. Figure <ref type="figure" target="#fig_5">3</ref> shows an example program that contains the library function call strcpy, which has two arguments buf and str. Since strcpy is a backward function call, for each of its arguments we will generate a backward slice. For argument buf , the slice consists of three statements, namely lines 4, 5, and 9 of the program, which belong to the user-defined function test. For argument str, the slice consists of six statements, namely lines 13, 15, 18, 19, 2, and 9 of the program, where the first 4 belong to the user-defined function main and the last 2 belong to the user-defined function test.</p><p>The two slices are chains (i.e., a linear structure) because Checkmarx uses chains to represent slices, while noting that slices can also be represented by trees <ref type="bibr" target="#b33">[23]</ref>, <ref type="bibr" target="#b60">[50]</ref>. Since the linear structure can only represent one individual slice, a library/API function call often corresponds to multiple slices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.</head><p>Step II: Extracting code gadgets and labeling their ground truth 1) Step II.1: Assembling program slices into code gadgets:</p><p>The program slices generated in the previous step can be assembled into code gadgets as follows.</p><p>First, given a library/API function call and the corresponding program slices, we combine the statements (i.e., pieces of code) belonging to the same, user-defined function into a single piece according to the order of the statements' appearance in the user-defined function. If there is a duplication of any statement, the duplication is eliminated.</p><p>In the example shown in Figure <ref type="figure" target="#fig_5">3</ref>, three statements (i.e., lines 4, 5, and 9) belonging to the user-defined function test consists the program slice corresponding to the argument buf , and two statements (i.e., lines 2 and 9) belonging to the user-defined function test are a piece of the program slice corresponding to the argument str. Therefore, we need to assemble them into a single piece because they are related to the same function test. According to the line numbers of these statements' appearance in the function test, this would lead to 2 â†’ 4 â†’ 5 â†’ 9 â†’ 9. Since the statement corresponding to line 9 is duplicated, we eliminate the duplication to derive a piece of assembled statements 2 â†’ 4 â†’ 5 â†’ 9, which correspond to the function test.</p><p>Second, assembling the statements belonging to different, user-defined functions into a single code gadget. If there is already an order between two pieces of statements belonging to these user-defined functions, this order is preserved; otherwise, a random order is used.</p><p>In the example shown in Figure <ref type="figure" target="#fig_5">3</ref>, when assembling the piece of statements belonging to the user-defined function main (i.e., lines 13, 15, 18, and 19) and the assembled piece of statements belonging to user-defined function test (i.e., lines 2, 4, 5, and 9), we obtain 13 â†’ 15 â†’ 18 â†’ 19 â†’ 2 â†’ 4 â†’ 5 â†’ 9, which is a code gadget corresponding to the library function call strcpy. This code gadget preserves the order of user-defined functions that are contained in the program slice corresponding to the argument str.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>Step II.2: Labeling the ground truth: Each code gadget needs to be labeled as "1" (i.e., vulnerable) and "0" (i.e., not vulnerable). If a code gadget corresponds to a vulnerability that is known in the training dataset, it is labeled as "1"; otherwise, it is labeled as "0". In Section IV-C, we will discuss the labeling of ground truth in details, when dealing with programs related to specific vulnerability data sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.</head><p>Step III: Transforming code gadgets into vectors 1) Step III.1: Transforming code gadgets into their symbolic representations: This step aims to heuristically capture some semantic information in the programs for training a neural network. First, remove the non-ASCII characters and comments because they have nothing to do with vulnerability.</p><p>Second, map user-defined variables to symbolic names (e.g., "VAR1", "VAR2") in the one-to-one fashion, while noting that multiple variables may be mapped to the same symbolic name when they appear in different code gadgets. Third, map userdefined functions to symbolic names (e.g., "FUN1", "FUN2") in the one-to-one fashion, while noting that multiple functions may be mapped to the same symbolic name when they appear in different code gadgets. Figure <ref type="figure">4</ref> highlights the above process by using the code fragment generated by Step II.1 as shown in Figure <ref type="figure" target="#fig_5">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>Step III.2: Encoding the symbolic representations into vectors: Each code gadget needs to be encoded into a vector via its symbolic representation. For this purpose, we divide a code gadget in the symbolic representation into a sequence of tokens via lexical analysis, including identifiers, keywords, operators, and symbols. For example, a code gadget in the symbolic representation, "strcpy(VAR5, VAR2); " is represented by a sequence of 7 tokens: "strcpy", "(", "VAR5", ",", "VAR2", ")", and ";". This leads to a large corpus of tokens. In order to transform these tokens into vectors, we use the word2vec tool [14], which is selected because it is widely used in text mining <ref type="bibr" target="#b68">[58]</ref>. This tool is based on the idea of distributed representation, which maps a token to an integer that is then converted to a fixedlength vector <ref type="bibr" target="#b53">[43]</ref>.</p><p>Since code gadgets may have different numbers of tokens, the corresponding vectors may have different lengths. Since BLSTM takes equal-length vectors as input, we need to make an adjustment. For this purpose, we introduce a parameter Ï„ as the fixed length of vectors corresponding to code gadgets.</p><p>â€¢ When a vector is shorter than Ï„ , there are two cases: if the code gadget is generated from a backward slice or generated by combining multiple backward slices, we pad zeros in the beginning of the vector; otherwise, we pad zeros to the end of the vector.</p><p>â€¢ When a vector is longer than Ï„ , there are also two cases: if the code gadget is generated from one backward slice, or generated by combining multiple backward slices, we delete the beginning part of the vector; otherwise, we delete the ending part of the vector.</p><p>This ensures that the last statement of every code gadget generated from a backward slice is a library/API function call, and that the first statement of every code gadget generated from a forward slice is a library/API function call. As a result, every code gadget is represented as a Ï„ -bit vector. The length of vectors is related to the number of hidden nodes at each layer of the BLSTM, which is a parameter that can be tuned to improve the accuracy of vulnerability detection (see Section IV-C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND RESULTS</head><p>Our experiments are centered at answering the following three research questions (RQs):</p><p>â€¢ RQ1: Can VulDeePecker deal with multiple types of vulnerabilities at the same time? A vulnerability detection system should be able to detect multiple types of vulnerabilities at the same time, because multiple detection systems need to be maintained otherwise. For answering this question, we will conduct experiments involving one or multiple types of vulnerabilities.</p><p>â€¢ RQ2: Can human expertise (other than defining features) improve the effectiveness of VulDeePecker? For answering this question, we will investigate the effectiveness of using some manually-selected library/API function calls vs. the effectiveness of using all of the library/API function calls.</p><p>â€¢ RQ3: How effective is VulDeePecker when compared with other vulnerability detection approaches? For answering this question, will compare VulDeePecker with other approaches, including some static analysis tools and code similarity-based vulnerability detection systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Metrics for evaluating vulnerability detection systems</head><p>We use the widely used metrics false positive rate (F P R), false negative rate (F N R), true positive rate or recall (T P R), precision (P ), and F 1-measure (F 1) to evaluate vulnerability detection systems <ref type="bibr" target="#b49">[39]</ref>. Let TP be the number of samples with vulnerabilities detected correctly, FP be the number of samples with false vulnerabilities detected, FN be the number of samples with true vulnerabilities undetected, and TN be the number of samples with no vulnerabilities undetected. The false positive rate metric F P R = FP FP+TN measures the ratio of false positive vulnerabilities to the entire population of samples that are not vulnerable. The false negative rate metric F N R = FN TP+FN measures the ratio of false negative vulnerabilities to the entire population of samples that are vulnerable. The true positive rate or recall metric T P R = TP TP+FN measures the ratio of true positive vulnerabilities to the entire population of samples that are vulnerable, while noting that T P R = 1 -F N R. The precision metric P = TP TP+FP measures the correctness of the detected vulnerabilities. The F 1-measure metric F 1 = 2â€¢P â€¢T P R P +T P R takes consideration of both precision and true positive rate.</p><p>It would be ideal that a vulnerability detection system neither misses vulnerabilities (i.e., F N R â‰ˆ 0 and T P R â‰ˆ 1) nor triggers false alarms (i.e., F P R â‰ˆ 0 and P â‰ˆ 1), which means F 1 â‰ˆ 1. However, this is difficult to achieve in practice, and often forces one to trade the effectiveness in terms of one metric for the effectiveness in terms of another metric. In this study, we prefer to achieving low FNR and low FPR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Preparing input to VulDeePecker</head><p>Collecting programs. There are two widely used sources of vulnerability data maintained by the NIST: the NVD <ref type="bibr" target="#b21">[10]</ref> which contains vulnerabilities in production software, and the SARD project <ref type="bibr" target="#b23">[12]</ref> which contains production, synthetic, and academic security flaws or vulnerabilities. In the NVD, each vulnerability has a unique Common Vulnerabilities and Exposures IDentifier (CVE ID) and a Common Weakness Enumeration IDentifier (CWE ID) that indicates the type of the vulnerability in question. We collect the programs that contain one or multiple vulnerabilities. In the SARD, each program (i.e., test case) corresponds to one or multiple CWE IDs because a program can have multiple types of vulnerabilities. Therefore, programs with one or multiple CWE IDs are collected.</p><p>In the present paper, we focus on two types of vulnerabilities: buffer error (i.e., CWE-119) and resource management error (i.e., CWE-399), each of which has multiple subtypes. These vulnerabilities are very common, meaning that we can collect enough data for using deep learning. We select 19 popular C/C++ open source products, including the Linux kernel, Firefox, Thunderbird, Seamonkey, Firefox esr, Thunderbird esr, Wireshark, FFmpeg, Apache Http Server, Xen, OpenSSL, Qemu, Libav, Asterisk, Cups, Freetype, Gnutls, Libvirt, and VLC media player, which contain, according to the NVD, these two types of vulnerabilities. We also collect the C/C++ programs in the SARD that contain these two types of vulnerabilities. In total, we collect from the NVD 520 open source software programs related to buffer error vulnerabilities and 320 open source software programs related to resource management error vulnerabilities; we also collect from the SARD 8,122 programs (i.e., test cases) related to buffer error vulnerabilities and 1,729 programs related to resource management error vulnerabilities. Note that program containing a vulnerability may actually consist of multiple program files.</p><p>Training programs vs. target programs. We randomly choose 80% of the programs we collect as training programs and the remaining 20% as target programs. This ratio is applied equally when dealing with one or both types of vulnerabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learning BLSTM neural networks</head><p>This corresponds to the learning phase of VulDeePecker. We implement the BLSTM neural network in Python using Theano <ref type="bibr" target="#b34">[24]</ref> together with Keras <ref type="bibr" target="#b19">[8]</ref>. We run experiments on a machine with NVIDIA GeForce GTX 1080 GPU and Intel Xeon E5-1620 CPU operating at 3.50GHz.</p><p>Step I: Extracting library/API function calls and corresponding program slices. We extract C/C++ library/API function calls from the programs. There are 6,045 C/C++ library/API function calls that involve standard library function calls <ref type="bibr" target="#b13">[1]</ref>, basic Windows API and Linux kernel API function calls <ref type="bibr" target="#b20">[9]</ref>, <ref type="bibr" target="#b24">[13]</ref>. In total, we extract 56,902 library/API function calls from the programs, including 7,255 forward function calls and 49,647 backward function calls.</p><p>In order to answer the RQs, we also manually select 124 C/C++ library/API function calls (including function calls with wildcard) related to buffer error vulnerabilities (CWE-119) and 16 C/C++ library/API function calls related to resource management error vulnerabilities (CWE-399). These function calls are selected because the aforementioned commercial tool Checkmarx <ref type="bibr">[2]</ref> claims, using their own rules written by human experts, that they are related to these two types of vulnerabilities. The list of these function calls are deferred to Table <ref type="table" target="#tab_11">VII</ref>  Step II.1: Generating code gadgets. Code gadgets are generated from program slices. We obtain a Code Gadget Database (CGD) of 61,638 code gadgets, among which 48,744 code gadgets are generated from program slices of training programs, and 12,894 code gadgets are generated from program slices of target programs. The time complexity for generating gadgets mainly depends on the data flow analysis tool. For example, it takes 883 seconds to generate 2,494 code gadgets from 100 programs (99,232 lines) that are randomly selected the SARD, meaning an average of 354 milliseconds per code gadget. For answering the RQs mentioned above, we use the CGD to derive the following 6 datasets.</p><p>â€¢ BE-ALL: The subset of CGD corresponding to Buffer Error vulnerabilities (CWE-119) and ALL library/API function calls (i.e., extracted without human expert).</p><p>â€¢ RM-ALL: The subset of CGD corresponding to Resource Management error vulnerabilities (CWE-399) and ALL library/API function calls.</p><p>â€¢ HY-ALL: The subset of CGD corresponding to the HYbrid of (i.e., both) buffer error vulnerabilities (CWE-119) and resource management error vulnerabilities (CWE-399) and ALL library/API function calls. That is, it is the same as the CGD.</p><p>â€¢ BE-SEL: The subset of CGD corresponding to Buffer Error vulnerabilities (CWE-119) and manually SE-Lected function calls (rather than all function calls).</p><p>â€¢ RM-SEL: The subset of CGD corresponding to Resource Management error vulnerabilities (CWE-399) and manually SELected function calls.</p><p>â€¢ HY-SEL: The subset of CGD corresponding to the HYbrid of buffer error vulnerabilities (CWE-119) and resource management error vulnerabilities (CWE-399) and manually SELected function calls.</p><p>Table <ref type="table" target="#tab_6">I</ref> summarizes the number of code gadgets in these datasets.</p><p>Step II.2: Labeling code gadgets. Code gadgets are labeled as follows. For the code gadgets extracted from the programs of the NVD, we focus on the vulnerabilities whose patches involve line deletions or modifications. This process has two steps. In the first step, a code gadget is automatically labeled as "1" (i.e., vulnerable) if it contains at least one statement that is deleted or modified according to the patch, and labeled as "0" otherwise (i.e., not vulnerable). However, this automatic process may mislabel some code gadgets, which are not vulnerable, as "1". In order to remove these mislabels, the second step is to manually check the code gadgets that are labeled as "1" so as to correct the mislabels (if any).</p><p>Recall that each program in the SARD is already labeled as good (i.e., no security defect), bad (i.e., containing security defects), or mixed (i.e., containing functions with security defects and their patched versions) with corresponding CWE IDs. For the code gadgets extracted from the programs with respect to the SARD, a code gadget extracted from a good program is labeled as "0" (i.e., not vulnerable), and a code gadget extracted from a bad or mixed program is labeled as "1" (i.e., vulnerable) if it contains at least one vulnerable statement and "0" otherwise. Since we used heuristics in the labeling process for the SARD program, we looked at the labels of 1,000 random code gadgets and found that only 6 of them (i.e. 0.6%) were mislabeled. These mislabeled samples are caused by the fact that a statement in a piece of code that is not vulnerable is the same as a statement in a piece of code that is vulnerable. As the mislabeled code gadgets are very few and the neural networks are robust against a small portion of mislabeled samples, it is unnecessary to check manually all labels of the code gadgets that are extracted for the SARD programs.</p><p>It is possible to encounter the situation that the same code gadget is labeled with both "1" and "0" (i.e., conflicting labels). One cause of this phenomenon is the imperfection of the data flow analysis tool. In this case, we simply delete these code gadgets. As a result, 17,725 code gadgets are labeled as "1" and 43,913 code gadgets are labeled as "0". Among the 17,725 code gadgets labeled as "1", 10,440 code gadgets correspond to the buffer error vulnerabilities and 7,285 code gadgets correspond to the resource management error vulnerabilities. Table <ref type="table" target="#tab_6">I</ref> shows the number of code gadgets that are vulnerable (Column 3) and the number of code gadgets that are not vulnerable in each dataset (Column 4).</p><p>Step III: Transforming code gadgets into vectors. The CGD contains a total number of 6,166,401 tokens, of which 23,464 are different. After mapping user-defined variable names and function names to some symbolic names, the number of different tokens is further reduced to 10,480. These symbolic representations are encoded into vectors, which are used as the input for training a BLSTM neural network.</p><p>Step IV: Training BLSTM neural network. For each dataset described in Table <ref type="table" target="#tab_6">I</ref>, we adopt a 10-fold cross validation to train a BLSTM neural network, and select the best parameter values corresponding to the effectiveness for vulnerability detection. For example, we vary the number of hidden layers for each BLSTM neural network and observe the influence on the resulting F1-measure. When we adjust the number of hidden layers, we set the parameters to their default values when such default values are available, and set the parameters to the values that are widely used by the deep learning community otherwise. The number of tokens in the vector representation of code gadgets is set to 50, the dropout is set to 0.5, the batch size is set to 64, the number of epochs is set to 4, the minibatch stochastic gradient descent together with ADAMAX <ref type="bibr" target="#b39">[29]</ref> is used for training with the default learning rate of 1.0, and 300 hidden nodes are chosen.  Figure <ref type="figure" target="#fig_4">5</ref> plots the F1-measure of VulDeePecker with respect to the 6 datasets with different number of hidden layers, each of which leads to a different neural network. We observe that the F1-measure of the 6 BLSTM neural networks reaches the maximum at 2 or 3 layers, and the F1-measure of most of these BLSTM neural networks declines when the number of layers is greater than 6. Note that the other parameters of the BLSTM neural network can be tuned in a similar fashion.</p><formula xml:id="formula_0">( B E -S E L ) F 1 ( B E -A L L ) F 1 ( R M -S E L ) F 1 ( R M -A L L ) F 1 ( H Y -S E L ) F 1 ( H Y -A L L )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental results &amp; implications</head><p>1) Experiments for answering RQ1: In order to test whether VulDeePecker can be applied to multiple types of vulnerabilities, we conduct experiments on three datasets: BE-ALL, RM-ALL, and HY-ALL. This respectively leads to three neural networks, whose effectiveness is reported in Table <ref type="table" target="#tab_6">II</ref>. We observe that the neural network trained from the RM-ALL dataset outperforms the neural network trained from the BE-ALL dataset in terms of all five metrics. This can be explained by the fact that the number of library/API function calls that are related to resource management error vulnerabilities (i.e., <ref type="bibr" target="#b26">16</ref>) is far smaller than the number of library/API function calls that are related to buffer error vulnerabilities (i.e., 124). We also observe that, in terms of the FPR and P metrics, the neural network trained from the HY-ALL dataset is not as good as the neural network trained from the BE-ALL or RM-ALL dataset. We further observe that the TPR and FNR of the neural network trained from the HY-ALL dataset reside in between that of the neural network trained from the RM-ALL dataset and that of the neural network trained from the BE-ALL dataset. The F1-measure of the neural network trained from the HY-ALL dataset is 1.2% lower than that of the neural network trained from the BE-ALL dataset, and 9.6% lower than that of the neural network trained from the RM-ALL dataset. This can be explained by the fact that the number of library/API function calls that are related to the vulnerabilities of the hybrid dataset (i.e., 140) is larger than the number of library/API function calls that are related to a single type of vulnerabilities. We speculate this is caused by the following: it is more difficult to extract vulnerability patterns for a large number of library/API function calls that are related to vulnerabilities than to extract vulnerability patterns for a small number of library/API function calls that are related to vulnerabilities.</p><p>Table <ref type="table" target="#tab_6">III</ref> summarizes the training time and detection time corresponding to the HY-ALL dataset, where the second column represents the number of code gadgets for training (i.e., extracted from the training programs) and the third column represents the number of code gadgets for detection (i.e., extracted from the target programs). We observe that the training time of VulDeePecker, as implied by the deep learning technology in general, is large, but the detecting time is small. In summary, we answer RQ1 affirmatively with the following:</p><p>Insight 1: VulDeePecker can simultaneously detect multiple types of vulnerabilities, but the effectiveness is sensitive to the number of library/API function calls related to vulnerabilities (i.e., the fewer the better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Experiments for answering RQ2:</head><p>In order to answer whether VulDeePecker can be improved by incorporating human expertise, we conduct the experiment using all library/API function calls that are automatically extracted vs. using some library/API function calls that are manually selected under the guidance of vulnerability rules written by Checkmarx's human experts. As shown in Table <ref type="table" target="#tab_10">IV</ref>, the BLSTM network trained from the HY-SEL dataset is more effective than the BLSTM network trained from the HY-ALL dataset. Although the improvement in FPR is small (0.2%), the improvement in each of the other metrics is substantial: 10% in FNR and TPR, 5% in precision, and 7.5% in F1-measure. Moreover, Table <ref type="table" target="#tab_6">III</ref> shows that the training time of using manually selected library/API function calls can be smaller than that of using all library/API function calls, because a smaller number of code gadgets need to be processed. This leads to the following preliminary understanding regards the usefulness of human expertise in improving the effectiveness of deep learning-based vulnerability detection:</p><p>Insight 2: Human expertise can be used to select library/API function calls to improve the effectiveness of VulDeePecker, especially the overall effectiveness in F1measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Experiments for answering RQ3:</head><p>In order to answer RQ3, we compare the effectiveness of VulDeePecker with other pattern-based and code similarity-based vulnerability detection systems. We here report the comparison between their effectiveness in detecting buffer error vulnerabilities (i.e., BE-SEL dataset), while noting that a similar phenomenon is observed when comparing their effectiveness in detecting resource management error vulnerabilities (i.e., RM-SEL dataset) -the details are omitted due to the lack of space.</p><p>For comparison with other pattern-based vulnerability detection systems, which use rules defined by human experts, we consider a commercial product called Checkmarx <ref type="bibr">[2]</ref> and two open source tools called Flawfinder <ref type="bibr" target="#b17">[6]</ref> and RATS <ref type="bibr" target="#b22">[11]</ref>. These systems are chosen because we have access to them and to the best of our knowledge, they have been widely used. For comparison with code similarity-based vulnerability detection systems, which are mainly geared towards clonecaused vulnerabilities, we consider the two state-of-the-art systems called VUDDY <ref type="bibr" target="#b38">[28]</ref> and VulPecker <ref type="bibr" target="#b42">[32]</ref>. We use VUDDY's open service, and use the original implementation of VulPecker provided to us by its authors. For fair comparison, we need to address some subtle issues. We observe that VulPecker uses diffs as an input, where a diff describes the difference between a vulnerable piece of code and its patched version, we divide the BE-SEL dataset of target programs into two subsets, namely BE-SEL-NVD (266 samples derived from the NVD) and BE-SEL-SARD (the rest samples derived from the SARD). We use BE-SEL-NVD for the comparison study because VUDDY and VulPecker were designed to detect vulnerabilities with CVE IDs or vulnerabilities with diffs, but are unable to detect vulnerabilities in BE-SEL-SARD. Table V summarizes the comparison. We make the following observations. First, VulDeePecker substantially outperforms the other pattern-based vulnerability detection systems, because VulDeePecker incurs a FPR of 5.7% and a FNR of 7.0%, which are respectively much smaller than their counterparts in the other detection systems. By looking into the other systems, we find that Flawfinder and RATS do not use data flow analysis and therefore miss many vulnerabilities. Although Checkmarx does use data flow analysis, its rules for recognizing vulnerabilities are defined by human experts and are far from perfect. This further highlights the importance of relieving human experts from tedious tasks (similar to task of manually defining features). This observation leads to:  Second, for the BE-SEL-NVD sub-dataset, VUDDY and VulPecker trade high FNRs (95.1% and 89.8%, respectively) for low FPRs (0% and 1.9%, respectively), which lead to very low F1-measures (9.3% and 18.2%, respectively). The large FNRs can explained by the following facts: VUDDY can only detect the vulnerabilities related to functions, which are nearly identical to the vulnerable functions in the training programs (i.e., vulnerabilities caused by Types I and II code clones <ref type="bibr" target="#b52">[42]</ref>); VulPecker can only detect vulnerabilities caused by Type I, Type II, and some Type III code clones <ref type="bibr" target="#b52">[42]</ref> (e.g., deletion, insertion, and rearrangement of statements), which explains why VulPecker incurs a lower FNR than VUDDY. However, these systems cannot detect vulnerabilities that are not caused by code clones, which explains why they incur high FNRs.</p><p>In contrast, VulDeePecker has a much higher F1-measure (i.e., 80.8% vs. 9.3% for VUDDY and 18.2% for VulPecker) because it has a much higher TPR (i.e., much lower FNR), while noting that its FPR is 22.9% (vs. 0% for VUDDY and 1.9% for VulPecker). We suspect that this high FPR of 22.9% corresponding to the BE-SEL-NVD dataset is caused by a small number of training code gadgets from NVD. This can be justified by the small FPR of 3.4% corresponding to a large number of training code gadgets from SARD, which is about 18 times larger than the number of training code gadgets from NVD. Moreover, the FPR of 5.7% corresponding to the entire BE-SEL dataset resides some where in between them. The high FNR of 16.9% can be explained similarly.</p><p>The high FPR and FNR of VulDeePecker with respect to the BE-SEL-NVD sub-dataset should not be used as evidence against VulDeePecker, simply because for the BE-SEL-SARD sub-dataset, VulDeePecker incurs an even smaller FPR of 3.4% and a FNR of 5.1%, while noting that VUDDY and VulPecker are not applicable (i.e., not capable of detecting vulnerabilities in this sub-dataset). Moreover, VulDeePecker incurs a FPR of 5.7% and a FNR of 7.0% over the entire BE-SEL dataset, which is the more practical case because one would use all data available in practice.</p><p>Therefore, it is fair to say that VulDeePecker substantially outperforms two state-of-the-art code similarity-based vulnerability detection systems, simply because VulDeePecker incurs a FPR of 5.7% and a FNR of 7.0% over the entire dataset. Nevertheless, it is important to note that deep learning-based vulnerability detection largely rely on the amount of data. This leads to: Insight 4: VulDeePecker is more effective than code similarity-based vulnerability detection systems, which cannot detect vulnerabilities that are not caused by code clones and thus often incur high false negative rate. Nevertheless, the effectiveness of VulDeePecker is sensitive to the amount of data, which appears to be inherent to the nature of deep learning.</p><p>Using VulDeePecker in practice. In order to further show the usefulness of VulDeePecker, we collected 20 versions of 3 software products: Xen, Seamonkey, and Libav. These products are different from the target programs mentioned above. We use VulDeePecker and the other vulnerability detection systems to detect the vulnerabilities in those software products. As highlighted in Table VI, VulDeePecker detected 4 vulnerabilities that have not been published in the NVD. We manually checked and confirmed these vulnerabilities, and found that they have been published for other products and have been "silently" patched by the product vendors in the subsequent versions. In contrast, these vulnerabilities are missed by almost all of the other vulnerability detection systems mentioned above, except that Flawfinder detects the vulnerability corresponding to CVE-2015-4517 while missing the other three.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. LIMITATIONS</head><p>The present design, implementation, and evaluation of VulDeePecker have several limitations, which suggest interesting open problems for future research. First, the present design of VulDeePecker is limited to dealing with vulnerability detection by assuming source code of programs is available. The detection of vulnerabilities in executables is a different and more challenging problem.</p><p>Second, the present design of VulDeePecker only deals with C/C++ programs. Future research needs to be conducted to adapt it to deal with other kinds of programming languages.</p><p>Third, the present design of VulDeePecker only deals with vulnerabilities related to library/API function calls. We will investigate how to detect the other kinds of vulnerabilities by leveraging the other kinds of key points mentioned above.</p><p>Fourth, the present design of VulDeePecker only accommodates data flow analysis (i.e., data dependency), but not control flow analysis (i.e., control dependency), despite the fact that the notion of code gadgets can accommodate data dependency and control dependency. It is an important future work to improve the leverage of data flow analysis and accommodate control flow analysis to enhance vulnerability detection capabilities.</p><p>Fifth, the present design of VulDeePecker uses some heuristics in labeling the ground truth of code gadgets, transforming code gadgets into their symbolic representations, transforming variable-length vector representations of code gadgets into fixed-length vectors. While intuitive, further research needs to be conducted to characterize the impact of these heuristics on the effectiveness of VulDeePecker.</p><p>Sixth, the present implementation of VulDeePecker is limited to the BLSTM neural network. We plan to conduct systematic experiments with other kinds of neural networks that could be used for vulnerability detection.</p><p>Seventh, the present evaluation of VulDeePecker is limited because the dataset only contains buffer error vulnerabilities and resource management error vulnerabilities. We will conduct experiments on all available types of vulnerabilities. Although we further tested VulDeePecker against 3 software products (i.e., Xen, Seamonkey, and Libav) and found 4 vulnerabilities that were not reported in the NVD and were "silently" patched by the vendors when releasing later versions of these products, these vulnerabilities were known rather than 0-day ones. Extensive experiments need to be conducted against more software products to check whether VulDeePecker has the capability in detecting 0-day vulnerabilities. In principle, this is possible because VulDeePecker uses pattern-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORK</head><p>We classify the related prior work into two categories: vulnerability detection (in relation to the purpose of the present paper), and program analysis (in the relation to the means for vulnerability detection).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Prior work in vulnerability detection</head><p>Pattern-based approach. This approach can be further divided to three categories. In the first category, patterns are generated manually by human experts (e.g., open source tools Flawfinder <ref type="bibr" target="#b17">[6]</ref>, RATS <ref type="bibr" target="#b22">[11]</ref>, and ITS4 <ref type="bibr" target="#b62">[52]</ref>, commercial tools Checkmarx <ref type="bibr">[2]</ref>, Fortify <ref type="bibr" target="#b18">[7]</ref>, and Coverity <ref type="bibr" target="#b15">[3]</ref>). These tools often have high false positive rate or false negative rate. In the second category, patterns are generated semi-automatically from pre-classified vulnerabilities ( e.g., missing check vulnerabilities <ref type="bibr" target="#b72">[62]</ref>, taint-style vulnerabilities <ref type="bibr" target="#b71">[61]</ref>, and information leakage vulnerabilities <ref type="bibr" target="#b25">[15]</ref>) and a pattern is specific to a type of vulnerabilities. In the third category, patterns are generated semi-automatically from type-agnostic vulnerabilities (i.e., no need to pre-classify them into different types). These methods use machine learning techniques, which rely on human experts for defining features to characterize vulnerabilities <ref type="bibr">[19]</ref>, <ref type="bibr" target="#b47">[37]</ref>, <ref type="bibr" target="#b48">[38]</ref>, <ref type="bibr" target="#b59">[49]</ref>, <ref type="bibr" target="#b69">[59]</ref>, <ref type="bibr" target="#b70">[60]</ref>. Moreover, these methods cannot pin down the precise locations of vulnerabilities because programs are represented in coarse-grained granularity (e.g., program <ref type="bibr">[19]</ref>, package <ref type="bibr" target="#b47">[37]</ref>, component <ref type="bibr" target="#b48">[38]</ref>, <ref type="bibr" target="#b56">[46]</ref>, file <ref type="bibr" target="#b45">[35]</ref>, <ref type="bibr" target="#b59">[49]</ref>, and function <ref type="bibr" target="#b69">[59]</ref>, <ref type="bibr" target="#b70">[60]</ref>).</p><p>VulDeePecker falls into the pattern-based approach to vulnerability detection. In contrast to the studies reviewed above, VulDeePecker has two advantages. First, it does not need human experts to define features for distinguishing vulnerable code and non-vulnerable code. Second, it uses a fine-grained granularity to represent programs, and therefore can pin down the precise locations of vulnerabilities.</p><p>Code similarity-based approach. This approach has three steps. The first step is to divide a program into some code fragments <ref type="bibr" target="#b35">[25]</ref>, <ref type="bibr" target="#b38">[28]</ref>, <ref type="bibr" target="#b41">[31]</ref>, <ref type="bibr" target="#b51">[41]</ref>, <ref type="bibr" target="#b54">[44]</ref>. The second step is to represent each code fragment in the abstract fashion, including tokens <ref type="bibr" target="#b35">[25]</ref>, <ref type="bibr" target="#b38">[28]</ref>, <ref type="bibr" target="#b54">[44]</ref>, trees <ref type="bibr" target="#b36">[26]</ref>, <ref type="bibr" target="#b51">[41]</ref>, and graphs <ref type="bibr" target="#b41">[31]</ref>, <ref type="bibr" target="#b51">[41]</ref>. The third step is to compute the similarity between code fragments via their abstract representations obtained in the second step.</p><p>Compared with any pattern-based approach to vulnerability detection (including VulDeePacker), the code similarity-based approach has the advantage that a single instance of vulnerable code is sufficient for detecting the same vulnerability in target programs. But it can only detect vulnerabilities in the Type I and Type II code clones <ref type="bibr" target="#b52">[42]</ref> (i.e., identical or almostidentical code clones), and some Type III code clones <ref type="bibr" target="#b52">[42]</ref> (e.g., deletion, insertion, and rearrangement of statements). In order to achieve a higher effectiveness of vulnerability detection, human experts need to define features in order to automatically select the right code similarity algorithms for different kinds of vulnerabilities <ref type="bibr" target="#b42">[32]</ref>. However, even the enhanced approach with expert-defined features <ref type="bibr" target="#b42">[32]</ref> cannot detect vulnerabilities that are not caused by code clones. In contrast, VulDeePecker can detect vulnerabilities that may or may not caused by code clones, in an automatic fashion (i.e., no need of human expert to define features).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Prior work related to using deep learning for program analysis</head><p>To the best of our knowledge, we are the first to use deep learning to detect software vulnerabilities, as inspired by the success of deep learning in image processing, speech recognition, and natural language processing <ref type="bibr" target="#b31">[21]</ref>, <ref type="bibr" target="#b40">[30]</ref>, <ref type="bibr" target="#b50">[40]</ref>. In order to use deep learning for detecting software vulnerabilities, programs need to be represented in vectors. There are two approaches for this purpose. One is to map the tokens extracted from programs, such as data types, variable names, function names, and keywords, to vectors <ref type="bibr" target="#b67">[57]</ref>; the other is to map the nodes of abstract syntax trees extracted from programs, such as function definitions, function invocations, identifier declarations, and control flow nodes, to vectors <ref type="bibr" target="#b46">[36]</ref>, <ref type="bibr" target="#b64">[54]</ref>. VulDeePecker maps the tokens extracted from code gadgets to vectors, while taking it into consideration that the lines of code in the code gadget is not necessarily consecutive.</p><p>Somewhat related work is the use of deep learning for software defect prediction <ref type="bibr" target="#b64">[54]</ref>, <ref type="bibr" target="#b73">[63]</ref>. However, software defects are different from software vulnerabilities (i.e., methods for detecting defects cannot be used for detecting vulnerabilities in general) <ref type="bibr" target="#b44">[34]</ref>, and the file-level representation of programs in <ref type="bibr" target="#b64">[54]</ref> is too coarse-grained to pin down the locations of vulnerabilities. Moreover, the defect prediction method presented in <ref type="bibr" target="#b73">[63]</ref> is geared towards code changes rather than target programs as a whole. Remotely related work is the use of deep learning for purposes, like software language modeling <ref type="bibr" target="#b67">[57]</ref>, code cloning detection <ref type="bibr" target="#b66">[56]</ref>, API learning <ref type="bibr" target="#b30">[20]</ref>, binary function boundary recognition <ref type="bibr" target="#b58">[48]</ref>, and malicious URLs, file paths detection and registry keys detection <ref type="bibr" target="#b55">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>We have presented VulDeePecker, the first deep learningbased vulnerability detection system, which aims to relieve human experts from the tedious and subjective work of manually defining features and reduce the false negatives that are incurred by other vulnerability detection systems. Since deep learning is invented for applications that are very different from vulnerability detection, we have presented some preliminary principles for guiding the practice of applying deep learning to vulnerability detection. These principles should be further refined because deep learning has great potential in solving the problem of vulnerability detection. We have collected, and made publicly available, a useful dataset for evaluating the effectiveness of VulDeePecker and other deep learning-based vulnerability detection systems that will be developed in the future. Systematic experiments show that VulDeePecker can achieve much lower false negative rate than other vulnerability detection systems, while relieving human experts from the tedious work of manually defining features. For the 3 software products we experimented with (i.e., Xen, Seamonkey, and Libav), VulDeePecker detected 4 vulnerabilities, which were not reported in the NVD and were "silently" patched by the vendors when they released later versions of these products. In contrast, the other detection systems missed almost all of these vulnerabilities, except that one system detected 1 of these vulnerabilities and missed the other three vulnerabilities.</p><p>Open problems for future research are abundant, including the limitations of the present study discussed in Section V. In particular, precisely characterizing the capabilities and limitations of deep learning-based vulnerability detection is an exciting research problem. layer l at the time t is: The forget gate f l t and the input gate i l t of the layer l at the time t are calculated as follows:</p><formula xml:id="formula_1">h l t =</formula><formula xml:id="formula_2">f l t = Ïƒ(W l xf x l t + W l hf h l t-1 + W l cf c l t-1 + b l f ), i l t = Ïƒ(W l xi x l t + W l hi h l t-1 + W l ci c l t-1 + b l i )</formula><p>, where x l t is the input to layer l -1 (l &gt; 1) or the input of the network (l = 1), W l xi , W l xf , W l xo , W l xc are the weight matrices connecting x l t with the input gate, the forget gate, the output gate, and the LSTM cell input, W l hi , W l hf , W l ho , W l hc are the weight matrices connecting h l t-1 with the input gate, the forget gate, the output gate, and the LSTM cell input, and b l i , b l f , b l o , b l c are the bias items of the input gate, the forget gate, the output gate, and the LSTM cell input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Library/API function calls selected by Checkmarx</head><p>Table VII summarizes the C/C++ library/API function calls related to the two types of vulnerabilities, buffer error (CWE-119) and resource management error (CWE-399), where "*" represents the wildcard. These library/API function calls are generated by the commercial product Checkmarx <ref type="bibr">[2]</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure2. Overview of VulDeePecker: the learning phase generates vulnerability patterns, and the detection phase uses these vulnerability patterns to determine whether a target program is vulnerable or not and if so, the locations of the vulnerabilities (i.e., the corresponding code gadgets).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4 Figure 3 .</head><label>43</label><figDesc>Figure 3. Illustrating the extraction of library/API function calls (Step I.1) from a (training) program, which contains a backward function call (i.e., strcpy) that is also used as an example to demonstrate the extraction of program slices (Step I.2) and the assembly of program slices into code gadgets (Step II.1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 1 )Figure 4 .</head><label>14</label><figDesc>Figure 4. Illustration of Step III.1: transforming code gadgets into their symbolic representations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>b e r o f h i d d e n l a y e r s F 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. F1-measure of VulDeePecker for the 6 datasets with different number of hidden layers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Insight 3 :</head><label>3</label><figDesc>A deep learning-based vulnerability detection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>â€¢</head><label></label><figDesc>Step I.1: Extracting library/API function calls from the training programs, while noting that the current version of VulDeePecker focuses on vulnerabilities related to the key point of library/API function calls.</figDesc><table /><note><p>â€¢ Step I.2: Extracting one or multiple program slices for each argument (or variable) of a library/API function call that is extracted in Step I.1. In this paper, a program slice represents the statements of a program (i.e., lines of code) that are semantically related to an argument of a library/API function call, while noting that the notion of program slice was originally introduced to represent the statements of a program with respect to a program point or variable</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>in the Appendix B. Correspondingly, we extract 40,351 library/API function calls from the training programs, including 4,012 forward function calls and 36,339 backward function calls. For each argument of the library/API function calls, one or multiple program slices are extracted.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table I .</head><label>I</label><figDesc>DATASETS FOR ANSWERING THE RQS</figDesc><table><row><cell>Dataset</cell><cell>#Code gadgets</cell><cell>#Vulnerable code gadgets</cell><cell>#Not vulnerable code gadgets</cell></row><row><cell>BE-ALL</cell><cell>39,753</cell><cell>10,440</cell><cell>29,313</cell></row><row><cell>RM-ALL</cell><cell>21,885</cell><cell>7,285</cell><cell>14,600</cell></row><row><cell>HY-ALL</cell><cell>61,638</cell><cell>17,725</cell><cell>43,913</cell></row><row><cell>BE-SEL</cell><cell>26,720</cell><cell>8,119</cell><cell>18,601</cell></row><row><cell>RM-SEL</cell><cell>16,198</cell><cell>6,573</cell><cell>9,625</cell></row><row><cell>HY-SEL</cell><cell>42,918</cell><cell>14,692</cell><cell>28,226</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table V .</head><label>V</label><figDesc>RESULTS FOR ANSWERING RQ3: VULDEEPECKER ACHIEVES A MUCH SMALLER OVERALL FNR OF 7.0% CORRESPONDING TO THE ENTIRE BE-SEL DATASET (THE LARGER FNR OF 16.9% CORRESPONDING TO THE SMALL SUB-DATASET DERIVED FROM THE NVD AND THE SMALLER FNR OF 5.1% CORRESPONDING TO THE SUB-DATASET DERIVED FROM THE SARD), WHILE NOTING THAT THE OVERALL FPR OF 5.7% IS REASONABLY SMALL. "N/C" MEANS THAT THE SYSTEM IS NOT CAPABLE OF DETECTING VULNERABILITIES IN THE CORRESPONDING DATASET.</figDesc><table><row><cell>System</cell><cell>Dataset</cell><cell>FPR (%)</cell><cell>FNR (%)</cell><cell>TPR (%)</cell><cell>P (%)</cell><cell>F1 (%)</cell></row><row><cell cols="7">VulDeePecker vs. Other pattern-based vulnerability detection systems</cell></row><row><cell>Flawfinder</cell><cell>BE-SEL</cell><cell>44.7</cell><cell>69.0</cell><cell>31.0</cell><cell>25.0</cell><cell>27.7</cell></row><row><cell>RATS</cell><cell>BE-SEL</cell><cell>42.2</cell><cell>78.9</cell><cell>21.1</cell><cell>19.4</cell><cell>20.2</cell></row><row><cell>Checkmarx</cell><cell>BE-SEL</cell><cell>43.1</cell><cell>41.1</cell><cell>58.9</cell><cell>39.6</cell><cell>47.3</cell></row><row><cell>VulDeePecker</cell><cell>BE-SEL</cell><cell>5.7</cell><cell>7.0</cell><cell>93.0</cell><cell>88.1</cell><cell>90.5</cell></row><row><cell cols="7">VulDeePecker vs. Code similarity-based vulnerability detection systems</cell></row><row><cell>VUDDY</cell><cell>BE-SEL-NVD</cell><cell>0</cell><cell>95.1</cell><cell>4.9</cell><cell>100</cell><cell>9.3</cell></row><row><cell>VulPecker</cell><cell>BE-SEL-NVD</cell><cell>1.9</cell><cell>89.8</cell><cell>10.2</cell><cell>84.3</cell><cell>18.2</cell></row><row><cell>VulDeePecker</cell><cell>BE-SEL-NVD</cell><cell>22.9</cell><cell>16.9</cell><cell>83.1</cell><cell>78.6</cell><cell>80.8</cell></row><row><cell>VUDDY</cell><cell>BE-SEL-SARD</cell><cell>N/C</cell><cell>N/C</cell><cell>N/C</cell><cell>N/C</cell><cell>N/C</cell></row><row><cell>VulPecker</cell><cell>BE-SEL-SARD</cell><cell>N/C</cell><cell>N/C</cell><cell>N/C</cell><cell>N/C</cell><cell>N/C</cell></row><row><cell>VulDeePecker</cell><cell>BE-SEL-SARD</cell><cell>3.4</cell><cell>5.1</cell><cell>94.9</cell><cell>92.0</cell><cell>93.4</cell></row><row><cell cols="7">system can be more effective by taking advantage of the data</cell></row><row><cell cols="7">flow analysis. (This hints us to speculate that a system can be</cell></row><row><cell cols="7">even more effective by taking advantage of the control flow</cell></row><row><cell cols="7">analysis. It is an interesting future work to validate or invalidate</cell></row><row><cell cols="2">this speculation.)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table VI .</head><label>VI</label><figDesc>VULDEEPECKER DETECTED 4 VULNERABILITIES IN 3 PRODUCTS, WHICH ARE NOT PUBLISHED IN THE NVD BUT HAVE BEEN "SILENTLY" PATCHED BY THE VENDORS IN THE LATER RELEASES OF THESE PRODUCTS.THESE VULNERABILITIES ARE ENTIRELY MISSED BY THE OTHER VULNERABILITY DETECTION SYSTEMS, EXCEPT THAT FLAWFINDER DETECTED ONLY ONE VULNERABILITY WHILE MISSING THE OTHER THREE.</figDesc><table><row><cell>Target product</cell><cell>CVE ID</cell><cell>Vulnerable product published in the NVD</cell><cell>Vulnerability publish time</cell><cell>Vulnerable file in target product</cell><cell>Library/API function call</cell><cell>1st patched version of target product</cell></row><row><cell>Xen 4.6.0</cell><cell>CVE-2016-9104</cell><cell>Qemu</cell><cell>12/09/2016</cell><cell>.../qemu-xen/hw/9pfs/virtio-9p.c</cell><cell>memcpy</cell><cell>Xen 4.9.0</cell></row><row><cell>Seamonkey</cell><cell>CVE-2015-4517</cell><cell>Firefox</cell><cell>09/24/2015</cell><cell>.../system/gonk/NetworkUtils.cpp</cell><cell>snprintf</cell><cell>Seamonkey 2.38</cell></row><row><cell>2.31</cell><cell>CVE-2015-4513</cell><cell>Firefox</cell><cell>11/05/2015</cell><cell>.../protocol/http/Http2Stream.cpp</cell><cell>memset</cell><cell>Seamonkey 2.39</cell></row><row><cell>Libav 10.2</cell><cell>CVE-2014-2263</cell><cell>FFmpeg</cell><cell>02/28/2014</cell><cell>libavformat/mpegtsenc.c</cell><cell>strchr, strlen</cell><cell>Libav 10.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>o l t tanh(c l t ), where the output gate o l t of the layer l at the time t is:o l t = Ïƒ(W l xo x l t + W l ho h l t-1 + W l co c l t + b l o) and the state of LSTM cell c l t of the layer l at the time t is:</figDesc><table><row><cell>c l t = f l t</cell><cell>c l t-1 + i l t</cell><cell>tanh(W l xc x l t + W l hc h l t-1 + b l c ).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>, getenv s, wgetenv, wgetenv s, catgets, gets, getchar, getc, getch, getche, kbhit, stdin, getdlgtext, getpass, scanf, fscanf, vscanf, vfscanf, istream.get, istream.getline, istream.peek, istream.read*, istream.putback, streambuf.sbumpc, streambuf.sgetc, PostThreadMessage, recv, recvfrom, Receive, ReceiveFrom, ReceiveFromEx, Socket.Receive*, memcpy, wmemcpy, memccpy, memmove, wmemmove, memset, wmemset, memcmp, wmemcmp, memchr, wmemchr, strncpy, strncpy*, lstrcpyn, tcsncpy*, mbsnbcpy*, wcsncpy*, wcsncpy, strncat, strncat*, mbsncat*, wcsncat*, bcopy, strcpy, lstrcpy, wcscpy, tcscpy, mbscpy, CopyMemory, strcat, lstrcat, lstrlen, strchr, strcmp, strcoll, strcspn, strerror, strlen, strpbrk, strrchr, strspn, strstr, strtok, strxfrm, readlink, fgets, sscanf, swscanf, sscanf s, swscanf s, printf, vprintf, swprintf, vsprintf, asprintf, vasprintf, fprintf, sprint, snprintf, snprintf*, snwprintf*, vsnprintf, CString.Format, CString.FormatV, CString.FormatMessage, CStringT.Format, CStringT.FormatV, CStringT.FormatMessage, CStringT.FormatMessageV, syslog, malloc, Winmain, GetRawInput*, GetComboBoxInfo, GetWindowText, GetKeyNameText, Dde*, GetFileMUI*, GetLocaleInfo*, GetString*, GetCursor*, GetScroll*, GetDlgItem*, GetMenuItem* CWE-399 free, delete, new, malloc, realloc, calloc, alloca, strdup, asprintf, vsprintf, vasprintf, sprintf, snprintf, snprintf, snwprintf, vsnprintf</figDesc><table><row><cell>Table VII.</cell><cell cols="3">LIBRARY/API FUNCTION CALLS RELATED TO TWO TYPES</cell></row><row><cell></cell><cell cols="2">OF VULNERABILITIES</cell><cell></cell></row><row><cell>CWE ID</cell><cell cols="3">C/C++ library/API function calls related to vulnerabilities</cell></row><row><cell>CWE-119</cell><cell>cin, getenvstreambuf.sgetn,</cell><cell>streambuf.snextc,</cell><cell>streambuf.sputbackc,</cell></row><row><cell></cell><cell>SendMessage,</cell><cell>SendMessageCallback,</cell><cell>SendNotifyMessage,</cell></row><row><cell></cell><cell>PostMessage,</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>We thank the anonymous reviewers for their comments that helped us improve the paper, and Marcus Pendleton for proofreading the paper. This paper is supported by the National Basic Research Program of China (973 Program) under grant No.2014CB340600, the National Science Foundation of China under grant No. 61672249, the Shenzhen Fundamental Research Program under grant No. JCYJ20170413114215614, and the Natural Science Foundation of Hebei Province under grant No. F2015201089. Shouhuai Xu is supported in part by NSF Grant #1111925 and ARO Grant #W911NF-17-1-0566. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not reflect the views of the funding agencies.</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code gadget</head><p>Code gadget 1 Label 1 Code gadget 2 0 Code gadget 3 1 Code gadget 4 0 Code gadget 5 0</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. LSTM cells</head><p>The BLSTM layers in the BLSTM neural network contain a complex structure called LSTM cells, which are briefly reviewed below and referred to <ref type="bibr" target="#b32">[22]</ref> for greater details.</p><p>Let denote the element-wise multiplication, tanh denote the hyperbolic tangent function exp(x)-exp (-x)  exp(x)+exp(-x) , and Ïƒ denote the sigmoid function 1 1+exp(-x) . Each LSTM cell, denoted by c, uses an input gate i (i.e., the input data), a forget gate f (i.e., the state flow of the cell), and an output gate o (i.e., the output of module) to control the data flow through the neural network. The output h l t of the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">main(int argc, char **argv) 15 ch ar *userstr</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">userstr = argv</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">2 test(char *str</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">/*string copy*/ 13 main(int argc, ch ar **argv) 15 char</title>
		<idno>VAR1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">VAR1 = argv</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">FUN1(VAR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m">FUN1(char *VAR2) 4 int VAR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">13 main(int argc, char **argv) 15 char</title>
	</analytic>
	<monogr>
		<title level="j">VAR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">VAR1 = argv</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">2 test(ch ar *VAR2) 4 int</title>
	</analytic>
	<monogr>
		<title level="j">VAR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Inp ut: code gadget (from Step II.1) 13 main(int argc, char **argv) 15 ch ar *userstr</title>
		<imprint/>
	</monogr>
	<note>18 userstr = argv[1</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">2 test(char *str</title>
	</analytic>
	<monogr>
		<title level="j">MAXSIZE</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note>int MAXSIZE=40; 5 char buf</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="http://en.cppreference.com/w" />
		<title level="m">C/C++ standard library functions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><surname>Checkmarx</surname></persName>
		</author>
		<ptr target="https://www.checkmarx.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><surname>Coverity</surname></persName>
		</author>
		<ptr target="https://scan.coverity.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><surname>Cve</surname></persName>
		</author>
		<ptr target="http://cve.mitre.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><surname>Flawfinder</surname></persName>
		</author>
		<ptr target="http://www.dwheeler.com/flawfinder" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><surname>Hp Fortify</surname></persName>
		</author>
		<ptr target="https://www.hpfod.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><surname>Keras</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<ptr target="https://www.kernel.org/doc/htmldocs/kernel-api/" />
		<title level="m">Linux kernel API functions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><surname>Nvd</surname></persName>
		</author>
		<ptr target="https://nvd.nist.gov/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<ptr target="https://code.google.com/archive/p/rough-auditing-tool-for-security/" />
		<title level="m">Rough Audit Tool for Security</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<ptr target="https://samate.nist.gov/SRD/index.php" />
		<title level="m">Software Assurance Reference Dataset</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<ptr target="https://msdn.microsoft.com/en-us/library/windows/desktop/ff818516(v=vs.85" />
		<title level="m">Windows API functions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic discovery and quantification of information leaks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>KÃ¶pf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rybalchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th IEEE Symposium on Security and Privacy</title>
		<meeting>the 30th IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="141" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations and Trends in Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van MerriÃ«nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Code-reuse attacks and defenses</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Davi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Darmstadt University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Toward large-scale vulnerability discovery using machine learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Grieco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Grinblat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Uzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mounier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM Conference on Data and Application Security and Privacy</title>
		<meeting>the 6th ACM Conference on Data and Application Security and Privacy</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep API learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting>the 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="631" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>-R. Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Interprocedural slicing using dependence graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horwitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Binkley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems (TOPLAS)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="60" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Theano: A CPU and GPU math expression compiler</title>
		<author>
			<persName><forename type="first">B</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>FrÃ©dÃ©ric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pascal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Razvan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for Scientific Computing Conference (SciPy)</title>
		<meeting>the Python for Scientific Computing Conference (SciPy)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">ReDeBug: Finding unpatched code clones in entire OS distributions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brumley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33th IEEE Symposium on Security and Privacy</title>
		<meeting>the 33th IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="48" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deckard: Scalable and accurate tree-based detection of code clones</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Misherghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Glondu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Software Engineering</title>
		<meeting>the 29th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">VUDDY: A scalable approach for vulnerable code clone discovery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th IEEE Symposium on Security and Privacy</title>
		<meeting>the 38th IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">CBCD: Cloned buggy code detector</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Software Engineering</title>
		<meeting>the 34th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="310" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">VulPecker: An automated vulnerability detection system based on code similarity analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual Conference on Computer Security Applications</title>
		<meeting>the 32nd Annual Conference on Computer Security Applications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="201" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Augmenting WordNet-like lexical resources with distributional evidence. an application-oriented perspective</title>
		<author>
			<persName><forename type="first">S</forename><surname>Montemagni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pirelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL Workshop on Use of WordNet in Natural Language Processing Systems</title>
		<meeting>the COLING/ACL Workshop on Use of WordNet in Natural Language Processing Systems</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="87" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Challenges with applying vulnerability prediction models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Symposium and Bootcamp on the Science of Security</title>
		<meeting>the 2015 Symposium and Bootcamp on the Science of Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evaluating and comparing complexity, coupling and a new proposed set of coupling metrics in cross-project vulnerability prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moshtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual ACM Symposium on Applied Computing</title>
		<meeting>the 31st Annual ACM Symposium on Applied Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1415" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Building program vector representations for deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.3358</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The beauty and the beast: Vulnerabilities in Red Hat&apos;s packages</title>
		<author>
			<persName><forename type="first">S</forename><surname>Neuhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zimmermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 USENIX Annual Technical Conference</title>
		<meeting>the 2009 USENIX Annual Technical Conference</meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="527" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Predicting vulnerable software components</title>
		<author>
			<persName><forename type="first">S</forename><surname>Neuhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM conference on Computer and communications security</title>
		<meeting>the 14th ACM conference on Computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="529" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A survey on systems security metrics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pendleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia-Lebron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Detection of recurring software vulnerabilities</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the IEEE/ACM International Conference on Automated Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Software clone detection: A systematic review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1165" to="1199" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Distributed representations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sourcer-erCC: Scaling code clone detection to big-code</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sajnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Svajlenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering</title>
		<meeting>the 38th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1157" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">eXpose: A character-level convolutional neural network with embeddings for detecting malicious URLs, file paths and registry keys</title>
		<author>
			<persName><forename type="first">J</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Berlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08568</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Predicting vulnerable software components via text mining</title>
		<author>
			<persName><forename type="first">R</forename><surname>Scandariato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Walden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hovsepyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Joosen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="993" to="1006" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Recognizing functions in binaries with neural networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C R</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moazzezi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th USENIX Security Symposium. USENIX Associatioin</title>
		<meeting>the 24th USENIX Security Symposium. USENIX Associatioin</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="611" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Meneely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="772" to="787" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">System-dependencegraph-based slicing of programs with arbitrary interprocedural control flow</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Harrold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rothermel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 International Conference on Software Engineering</title>
		<meeting>the 1999 International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="432" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Lattice-based recurrent neural network encoders for neural machine translation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st AAAI Conference on Artificial Intelligence</title>
		<meeting>the 31st AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3302" to="3308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">ITS4: A static vulnerability scanner for C and C++ code</title>
		<author>
			<persName><forename type="first">J</forename><surname>Viega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kohno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mcgraw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual Computer Security Applications Conference</title>
		<meeting>the 16th Annual Computer Security Applications Conference</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="257" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Automatically learning semantic features for defect prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering</title>
		<meeting>the 38th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="297" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Program slicing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactioins on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep learning code fragments for code clone detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vendome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the 31st IEEE/ACM International Conference on Automated Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="87" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Toward deep learning software repositories</title>
		<author>
			<persName><forename type="first">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vendome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Linares-VÃ¡squez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Working Conference on Mining Software Repositories</title>
		<meeting>the 12th Working Conference on Mining Software Repositories</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="334" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Joint word2vec networks for bilingual semantic representations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hanani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dershowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Linguistics and Applications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="44" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Vulnerability extrapolation: Assisted discovery of vulnerabilities using machine learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th USENIX Conference on Offensive Technologies. USENIX Association</title>
		<meeting>the 5th USENIX Conference on Offensive Technologies. USENIX Association</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="13" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Generalized vulnerability extrapolation using abstract syntax trees</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lottmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual Computer Security Applications Conference</title>
		<meeting>the 28th Annual Computer Security Applications Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Automatic inference of search patterns for taint-style vulnerabilities</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gascon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE Symposium on Security and Privacy</title>
		<meeting>the 2015 IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="797" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Chucky: Exposing missing checks in source code for vulnerability discovery</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wressnegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gascon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security</title>
		<meeting>the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="499" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Deep learning for just-intime defect prediction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Software Quality, Reliability and Security</title>
		<meeting>the 2015 IEEE International Conference on Software Quality, Reliability and Security</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
