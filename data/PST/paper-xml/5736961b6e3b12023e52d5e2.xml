<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast Volume Reconstruction From Motion Corrupted Stacks of 2D Slices</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-08-28">August 28, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Bernhard</forename><surname>Kainz</surname></persName>
							<email>b.kainz@imperial.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Markus</forename><surname>Steinberger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wolfgang</forename><surname>Wein</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maria</forename><surname>Kuklisova-Murgasova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christina</forename><surname>Malamateniou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Keraudren</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Torsney-Weir</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mary</forename><surname>Rutherford</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Aljabar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Murgasova</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="laboratory">Biomedical Image Analysis Group</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Biomedical Image Analysis Group</orgName>
								<orgName type="department" key="dep2">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Perinatal Imaging and Health</orgName>
								<orgName type="department" key="dep2">Division of Imaging Sciences and Biomedical Engineering</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<postCode>WC2R 2LS</postCode>
									<settlement>London</settlement>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Institute for Computer Graphics and Vision</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">ImFusion GmbH and the Chair for Computer Aided Medical Procedures and Augmented Reality</orgName>
								<orgName type="institution">TU Munich</orgName>
								<address>
									<postCode>80992</postCode>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="laboratory">Visualization and Data Analysis Group</orgName>
								<orgName type="institution">University of Vienna</orgName>
								<address>
									<postCode>1090</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast Volume Reconstruction From Motion Corrupted Stacks of 2D Slices</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-08-28">August 28, 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">EAA31C3D9FBF8FA23A1F8B9472D98D93</idno>
					<idno type="DOI">10.1109/TMI.2015.2415453</idno>
					<note type="submission">received January 31, 2015; revised March 14, 2015; accepted March 16, 2015. Date of publication March 20, 2015; date of current version</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Motion correction</term>
					<term>magnetic resonance imaging</term>
					<term>freehand compound ultrasound</term>
					<term>fetal imaging</term>
					<term>GPU acceleration</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Capturing an enclosing volume of moving subjects and organs using fast individual image slice acquisition has shown promise in dealing with motion artefacts. Motion between slice acquisitions results in spatial inconsistencies that can be resolved by slice-to-volume reconstruction (SVR) methods to provide high quality 3D image data. Existing algorithms are, however, typically very slow, specialised to specific applications and rely on approximations, which impedes their potential clinical use. In this paper, we present a fast multi-GPU accelerated framework for slice-to-volume reconstruction. It is based on optimised 2D/3D registration, super-resolution with automatic outlier rejection and an additional (optional) intensity bias correction. We introduce a novel and fully automatic procedure for selecting the image stack with least motion to serve as an initial registration target. We evaluate the proposed method using artificial motion corrupted phantom data as well as clinical data, including tracked freehand ultrasound of the liver and fetal Magnetic Resonance Imaging. We achieve speed-up factors greater than 30 compared to a single CPU system and greater than 10 compared to currently available state-of-the-art multi-core CPU methods. We ensure high reconstruction accuracy by exact computation of the point-spread function for every input data point, which has not previously been possible due to computational limitations. Our framework and its implementation is scalable for available computational infrastructures and tests show a speed-up factor of 1.70 for each additional GPU. This paves the way for the online application of Manuscript</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>H IGH resolution 3D volumetric images are routinely used for clinical examinations but are vulnerable to artefacts caused by subject movement during acquisition, which may take several minutes for modalities such as Magnetic Resonance Imaging (MRI). In real-time modalities such as ultrasound (US), compounding can be effective for increasing the signal to noise ratio and overcoming artefacts such as shadowing and other types of localised data loss. Approaches for real-time compounding are also starting to find application in MRI, allowing snapshot images of single slices which can be acquired fast enough to 'freeze' subject movement, (i.e., where the effects of motion are negligible in any individual slice). Such images may be realigned and combined to provide motion corrected volumetric data. The task of realigning and then reconstructing or compounding scattered slice data together has so far been performed with CPU-based algorithms <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref> that are effective but slow, often taking hours to complete, even when they incorporate algorithmic simplifications and precomputed components. Precomputation requirements also limit the scalability of these methods, especially in terms of memory. Additionally, current slice-to-volume reconstruction (SVR) algorithms require manual input from an experienced user, such as the selection of a registration template <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref> or the definition of a spatial windowing function <ref type="bibr" target="#b3">[4]</ref>, along with the specification of numerous input dependent parameters.</p><p>There are a number of scenarios where individual 2D slices can be acquired fast enough to freeze motion within each image. Computed Tomography (CT), e.g., spiral CT sequences <ref type="bibr" target="#b7">[8]</ref>, can be made fast enough to sample whole stacks of such slices without severe motion artefacts. The associated radiation dose, however, limits the applicability of this modality. In other imaging modalities, image-based reconstruction methods have been developed separately for US <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b5">[6]</ref> and MRI <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref> to compensate for low temporal resolution, and hence for the motion between 2D slices. The general idea in such approaches is to oversample a target region by acquiring several intersecting 3D stacks of 2D slices. A volume with a higher resolution than can then be reconstructed. This can be achieved through super-resolution techniques to increase image resolution and to boost the signal-to-noise ratio of the reconstructed image volume.</p><p>A challenge for such methods is that the target subject is likely to move between the acquisition <ref type="bibr" target="#b8">[9]</ref> of single stacks and even between the acquisition of slices <ref type="bibr" target="#b8">[9]</ref>. The spatial relationship between image pixels and corresponding object points will therefore change over time. Longer acquisitions will therefore display higher amounts of motion. This implies that fast imaging protocols need to be used when employing image-based reconstruction approaches and retrospective motion-correction techniques that rely upon image registration to recover the relationship between object and scanner coordinates in the reconstruction volume.</p><p>None of the currently available motion compensation approaches consider the potential computational gains that can be made using modern single instruction, multiple data (SIMD) programming techniques. In particular, the slow execution time of current state-of-the art implementations <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref> makes it difficult to properly explore their parameter space or to apply them directly during an examination and this hinders their clinical translation. Additionally, current approaches often trade off computational accuracy against reduced runtime in order to keep execution times to an acceptable level.</p><p>Almost all aspects of retrospective reconstruction are parallelizable. The introduction of modern SIMD hardware and commodity graphics processing units (GPUs) has made it possible to accelerate their execution significantly and to use parallel computational power for highly accurate results. Current approaches make computational simplifications to support faster convergence for realistically large datasets, for example by linearly interpolating between a few samples of a pre-computed point-spread function (PSF) <ref type="bibr" target="#b4">[5]</ref>. A significant amount of manual intervention is also required and the lack of an ideal and uncorrupted registration target image means that the stack with least motion typically needs to be visually identified so that it may then be used as registration target. In summary, these issues can lead to lower image quality, missing details and a lower signal-to-noise ratio (SNR) in the resulting high resolution volumetric reconstruction. In this paper we propose a framework to address these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CONTRIBUTIONS</head><p>We present a SVR approach using GPU acceleration. Key features of the developed framework are:</p><p>1) The use of fully flexible and accurately evaluated PSFs without being limited by the amount of available memory. This means we are able to fully exploit the mathematical foundations of SVR methods. 2) Elimination of the need to manually prepare the data by developing an approach to estimate the amount of motion for stacks of corrupted images, and therefore to automatically select the stack with the least motion. 3) Scalability across multiple GPUs, leading to computation times significantly faster than those possible with available methods. The parameter space of the approach is evaluated using a phantom with simulated motion to give known ground truth data. These experiments are used to estimate the set of optimal parameters for the reconstruction algorithm.</p><p>We apply the proposed methods to motion corrupted slice data acquired using two examinations of freehand ultrasound of the adult liver and two MRI datasets of fetuses in-utero. In the latter case, the brain and lungs are reconstructed. Results are compared to reconstructions obtained from existing algorithms applied to the same data.</p><p>The source code of the approach is publicly available and free to use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BACKGROUND</head><p>Motion artefacts are usually caused by periodic organ movements such as respiration or spontaneous movements, e.g., bowel movements. Scanning subjects who are unable to cooperate, neonates and fetuses for example, poses significant challenges in this regard. Under extreme conditions, respiration can be controlled during the scan under general anaesthesia. However, this is only possible for major interventions and the risks of anaesthesia usually outweigh the benefits of a scan.</p><p>Inter-operator variabilities can also present a challenge, for example, in freehand US where a high level of anatomical detail is desired in a consistent 3D volume. While modern US scanners are able to acquire 3D volumes, a number of trade-offs need to be made affecting the voxel size, field-of-view, temporal resolution as well as the frequencies used and the penetration needed for the target. The spatial resolution in 3D US can be as fine as 0.05 mm, even at high frame rates but this would be associated with a very limited the field-of-view. To simultaneously allow a reasonable field-of-view and a small pixel size, stacks of high-resolution 2D slices typically need to be externally tracked and compounded in 3D. The resulting volume is usually corrupted by inconsistent probe pressure and natural patient movements <ref type="bibr" target="#b9">[10]</ref>. This necessitates motion modelling as well as image reconstruction techniques in order to obtain volumetrically consistent image data. US compounding methods <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b2">[3]</ref> are able to fill in gaps that result from the fan-like acquisition of tracked sweeps of 2D slices. However, time consuming manual exclusion of registration errors <ref type="bibr" target="#b0">[1]</ref> or additional scan modalities <ref type="bibr" target="#b10">[11]</ref> are required to fully account for motion. Image-based motion correction, especially without contextual information from other modalities remains a challenging problem <ref type="bibr" target="#b11">[12]</ref> and is not performed during examination due to the high computational demands.</p><p>Another important application area for motion tolerant reconstruction techniques is represented by fetal, neonatal and infant MRI. Fetal MRI in particular is increasingly used as a complementary diagnostic tool to US sonography. It has been successfully used for accurate prenatal diagnostics and to study detailed fetal development due to its high resolution and SNR. Currently, mainly the brain <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b4">[5]</ref>, thorax <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, and the whole fetus <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> are qualitatively examined using MRI in clinical practice. Fetal motion and its unpredictable nature, however, make the acquisition of 3D MR sequences very challenging. Therefore, fast MR sequences such as single shot fast spin echo (ssFSE) <ref type="bibr" target="#b17">[18]</ref> are often used in order to freeze motion within a single 2D image. Multiple overlapping stacks of 2D images can provide an oversampled 3D volume of a target region of interest. However, the stacks are often corrupted by motion artefacts as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Typically, six to twelve stacks need to be acquired to sufficiently oversample the 3D volume.</p><p>Motion correction techniques for MR imaging can be classified into prospective and retrospective methods as well as approaches to minimize motion artefacts with fast imaging sequences <ref type="bibr" target="#b8">[9]</ref>.</p><p>Prospective methods are often navigator-based <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> or self-navigated sequences <ref type="bibr" target="#b20">[21]</ref>. While the techniques presented by <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> have not been applied to fetal imaging, Bonel et al. <ref type="bibr" target="#b21">[22]</ref> explored a similar navigator echo method for fetal brain MRI imaging to trigger fast snapshot slice acquisition while the fetus is stationary. However this make scan times increase from less than 30 s to several minutes and the method is not always robust to extensive movements <ref type="bibr" target="#b21">[22]</ref>. Additionally, positioning a navigator requires a pilot scan and at least one test scan, which further increases the total scan time. Radial and spiral sampling of the k-space during MRI image acquisition are considered to be more motion robust compared to conventional Cartesian k-space sampling. For example, the PROPELLER imaging sequence <ref type="bibr" target="#b20">[21]</ref> exploits this strategy to correct for bulk in-plane motion. Such MR sequences, however, often fail in cases of through plane motion <ref type="bibr" target="#b22">[23]</ref> and many of them take significantly longer to acquire than conventional scans.</p><p>Retrospective methods are applied after image data have been acquired. These have a disadvantage in not being fully capable of correcting through-plane motion because of the spin history effect <ref type="bibr" target="#b8">[9]</ref>. Additionally, the algorithms may take several hours to reconstruct the final volume, depending on the size of the volume and the resolution required. However, shorter scan times and non-time critical post-processing have made these approaches popular in fetal imaging. The most promising approaches use a combination of 2D/3D registration, as well as robust statistics to exclude highly corrupted slices, along with regularized super-resolution <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b4">[5]</ref> or slice intersection-based optimization <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. METHOD</head><p>The method proposed in this paper consists of several steps. Fig. <ref type="figure" target="#fig_1">2</ref> gives an overview over the individual components of the approach. First, we describe a method for estimating the relative amount of motion per stack of images in Section IV.A. We then present a general model for the motion compensated transformation of scanned 2D slices into a reconstruction volume in Section IV.B.</p><p>The outlier removal and bias correction approaches employed are methodologically similar to <ref type="bibr" target="#b4">[5]</ref>. For completeness, these are briefly described in Section IV.C. Super-resolution reconstruction is described in Section IV.D. This has been extended with support for arbitrary PSFs compared to <ref type="bibr" target="#b4">[5]</ref>. Section IV.E briefly discusses the final step of slice-to-volume registration, which is methodologically similar to all SVR approaches. Finally, we discuss the parallelization and implementation of our method on GPU hardware in Section V and evaluate the method in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Surrogate Measure to Estimate Motion Within One Stack</head><p>Estimating the correct alignment between slices is a crucial step for all motion corrected reconstruction methods. Optimizing the intensity profiles of intersecting slices can be achieved without an initial registration template <ref type="bibr" target="#b3">[4]</ref>. However, this method is sensitive to confounding parts of the anatomy, e.g., maternal tissue during a fetal scan, which needs to be suppressed by a spatial mask during registration. The alternative is to use an approximate and often manual segmentation, and to align all stacks to an initial registration target using 3D-3D registration as a starting point for subsequent slice to volume image reconstruction <ref type="bibr" target="#b24">[25]</ref>. It is possible to automated the segmentation but available approaches provide either a very rough segmentation of the central slices of a stack <ref type="bibr" target="#b25">[26]</ref> or require stacks with very little motion to be accurate <ref type="bibr" target="#b26">[27]</ref>. Furthermore, they are only applicable specific regions for which training data are available, e.g., the fetal brain.</p><p>The initial target region segmentation and the 3D-3D registration would both benefit from a measurement of the relative motion within the stacks. This is so that the stack with least motion artefacts may be selected for the initial 3D-3D registration. We propose a fast fully automatic method to provide such a measure in this section.</p><p>We consider aligned 2D slices individually uncorrupted by motion through a stationary 3D object. The vec operator that transforms a -pixel image region into a vector of intensity values , allows us to define a matrix <ref type="bibr" target="#b0">(1)</ref> Given that, within a limited extent and when well aligned, the slices of an object should be linearly correlated, the data matrix for this area should be approximately low-rank. In practice, however, the slices are slightly different from each other, motion corrupted (i.e., mis-aligned), and subject to noise. Hence, an error needs to be incorporated. While can be considered to be low-rank, the observed data matrix will most likely be full rank. Experimentally, we found that the (mis)alignment of slices, i.e., the motion of the scanned object, has the highest contribution to when testing the centre slices of an image stack. Inspired by Peng et al. <ref type="bibr" target="#b27">[28]</ref>, we can use a low-rank approximation as a surrogate estimate for the extent to which a subset of anatomically similar (i.e., usually central) slices in the stack are mis-aligned. Peng et al. <ref type="bibr" target="#b27">[28]</ref> aim to align pictures of human faces, which show differences because of photographic effects and different poses. In our work, the data consists of slices within a stack. For these, variation will be due to neighbouring slices representing slightly different anatomy, as well as due to noise artefacts and mis-alignment.</p><p>As indicated by <ref type="bibr" target="#b27">[28]</ref>, the data matrix for a well-aligned set of images is better approximated by a rank deficient matrix compared with a badly aligned set. Indeed, the rank of the data is used to formulate an objective function that can be optimised to estimate the alignment parameters. While the rank does not provide a direct or intrinsic measure of the extent of motion, in our application it can provide a surrogate measure of motion, one that we can use to assign an ordering to the stacks, in terms of the alignment quality of their slice data.</p><p>The singular values for the data matrix with can be written as in descending order . The singular value decomposition of is a product of three matrices, and . contains the singular values on the diagonal, and and are both matrices with orthogonal sets of columns (of size and ). can be recovered exactly by . This decomposition can be used to provide low rank approximations of the original matrix . If we take the first columns of and and the top-left sub matrix of , denoting them as , and , then we can approximate with the matrix . Assuming is full-rank (i.e., of rank ), then will be of rank (i.e., it is rank-deficient). In fact among all rank-r matrices, is the one that provides the best approximation to <ref type="bibr" target="#b28">[29]</ref>.</p><p>The singular values that contributed to are the first singular values of the original matrix. To measure how well approximates , we use the Frobenius norm . Consequently, the matrix norms of and satisfy , and</p><p>. The relative error of the approximation can be given by <ref type="bibr" target="#b1">(2)</ref> Evaluating this for different values of , we can find the minimal rank for each stack that satisfies a given error threshold , i.e.,</p><p>. The resulting values of and can be combined into a surrogate measure for the amount of error within each stack, i.e., the stack's suitability as a 3D registration template. In practice we use <ref type="bibr" target="#b2">(3)</ref> to obtain the surrogate measure for the amount of motion.</p><p>Most parts of the scanned slices show significant correlation and this is the case in particular for fetal MRI, where maternal tissue with little movement occupies large areas of the 2D field-of-view. The movements of the fetus cause larger discrepancies between the slices, therefore the proposed measure is well-suited to estimate an expected amount of motion corruption per stack of fetal 2D images. The key aspect of the method is that, once the approximate rank is obtained for all stacks, it provides a relative ordering of the stacks in terms of their levels of motion corruption. This can be then used as a criterion for selecting a good initial reference. The approach can also be used to reject stacks with too much motion at an early stage of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Transformation of Slice Data</head><p>Considering one stack as a target template, we first perform 3D rigid volumetric registration between all stacks and the template stack to account for global transformations of the region of interest. From this point on we consider each image slice and their unknown motion transformation parameters to be arranged in lists for the image slices and for unknown rigid transformation matrices. Additionally, we define a list containing all image to world coordinate transformation matrices for all image slices. These transform the discrete coordinates of a pixel in a 2D or 3D image to continuous locations in world (or scanner) coordinates. Another image to world transformation matrix, , is used for the reconstructed target volume so that we can define the transformation between a voxel in and a pixel location in the th acquired slice as finding the nearest voxel centre in space of the destination image using <ref type="bibr" target="#b3">(4)</ref> and the inverse transformation <ref type="bibr" target="#b4">(5)</ref> To achieve a physically correct estimation of the image acquisition process and to model the actual appearance of data points in physical space, the intensities of voxels within each slice are defined as continuous point spread functions (PSFs). This means that our approach makes it possible to sample an exact value for every voxel of the target reconstruction volume (within the limits of computational accuracy). The Kuklisova-Murgasova et al. (KM) approach <ref type="bibr" target="#b4">[5]</ref> used pre-computed low resolution representations of the PSF per voxel and subsequent linear interpolation to acquire an approximation of the PSF value. This was carried out in order to avoid significant computation times.</p><p>Computing PSFs as exactly as possible is motivated by both imaging research and by clinical practice. Our results in Section VI.F and feedback from clinicians show that exact calculation of the PSF yields improved image contrast. This helps in both manual examination and in subsequent (semi-automatic) image segmentation methods. The exact shape of the PSF is acquisition dependent. Jiang et al. <ref type="bibr" target="#b29">[30]</ref> measured the PSF generated by the ssFSE sequences using a phantom and rotating imaging encoding gradients so that the image plane was perpendicular to the excited slice. The resulting PSF is given by a sinc function in-plane, and its shape in through-slice direction is given by the slice profile. An ideal rectangular profile has an extended spectrum and would require very dense and inefficient spatial sampling. Therefore, we use a Gaussian slice profile, with a full width at half maximum equal to the slice thickness to allow more practical sampling requirements. We can model the ssFSE sequence PSF by approximating it as a 3D Gaussian function <ref type="bibr" target="#b5">(6)</ref> where are the offsets from the centre of a reconstructed voxel. Alternatively, with our framework, it is also possible to evaluate the function <ref type="bibr" target="#b6">(7)</ref> which directly models the true PSF occurring in ssFSE MRI and where is the in-plane radial distance from the voxel centre. In practice, we apply a 2-D Bartlett window to the in-plane component of the function. Note that we implement the PSF as a continuous and precisely sampled function at all times during parallel computing. This is in contrast to the previous approach of using precomputed PSF matrices for each location that are discrete and truncated, and need to be transformed and linearly interpolated to acquire continuous values at arbitrary locations in the reconstruction. On SIMD architectures, the computational cost of calculating the PSF function on-the-fly is less than that needed by memory transfer and linear interpolation. Furthermore, this approach improves memory efficiency because there is no need to pre-compute PSF matrices <ref type="bibr" target="#b4">[5]</ref>. We evaluate the effects of different PSF definitions in Section VI.</p><p>PSF-Based Volume Update: To fill every voxel of at an arbitrarily chosen voxel size, we extend the spatial relationship between slice and volume voxels from (IV.B) and ( <ref type="formula">5</ref>). In general, and will not be perfectly aligned and, considering the physical properties of the image acquisition process, one will contribute to more than one . To correctly model this, we sample around every voxel in which has at least one corresponding pixel in and use the PSF function to correctly weight the pixel's contribution during each iteration with <ref type="bibr" target="#b7">(8)</ref> Coordinates in PSF space are transformed with the slice voxel dimensions. In order to provide an acceptable runtime to the algorithm, we sample the exact PSF value at the voxel center positions of a local neighbourhood in the target reconstruction volume, i.e., we sample the PSF with the desired resolution of the motion corrected volume, until the difference between successive estimates is less than a predefined small . The KM approach <ref type="bibr" target="#b4">[5]</ref> used a small number of voxels (four to eight) to define a local neighbourhood within the reconstruction volume instead of sampling the PSF space directly. In the proposed approach it is possible (1) to use an arbitrary PSF, hence to adjust the method easily according to the scanning device used and (2) to weight a theoretically infinite number of reconstructed voxels, thus providing infinite support of the PSF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Slice Simulation, Outlier Removal, and Bias Field Correction</head><p>Having established a spatial relationship between and we can also reverse this process and simulate the scan process using the PSF function and generate a list of simulated slices .</p><p>Comparing the information from the simulated slices to the real slices at the same position in world coordinates can be used to classify each slice voxel into inliers and outliers. In an approach similar to <ref type="bibr" target="#b4">[5]</ref>, we train an EM model with the probability density function for the inlier class as a zero-mean Gaussian distribution. Outliers are modelled by a uniform distribution with constant density. The likelihood images for the voxels in each slice to be inlier can be used to weight the super-resolution volume update. Additionally, individual slices are classified according to this scheme and the average of the individual slice pixel weights is used for another instance of the EM algorithm <ref type="bibr" target="#b4">[5]</ref>. This yields another list of scaling factors for each slice . A multiplicative bias field model yields the relationship between and (8) can be written as <ref type="bibr" target="#b8">(9)</ref> This is commonly used in SVR approaches <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Super-Resolution Volume Update</head><p>For the final step we aim to minimize the sum of squared differences of errors between the intensity corrected slice pixels and simulated slice values , <ref type="bibr" target="#b9">(10)</ref> and calculate the error <ref type="bibr" target="#b10">(11)</ref> Gradient descent is applied to optimise an objective function of the form . To restrict the effect of noise and to avoid local minima during optimisation iterations, we add the regularization term , with smoothing parameter , implemented as edge preserving smoothing. This extends (9) to an iterative update scheme for : <ref type="bibr" target="#b11">(12)</ref> For the regularization term we use a similar strategy as proposed in <ref type="bibr" target="#b4">[5]</ref> and formulate it with anisotropic diffusion <ref type="bibr" target="#b31">[32]</ref> and decreasing after each slice-to-volume registration iteration to avoid local minima. Therefore, considering the smoothing in direction , the regularization term can be written as ( <ref type="formula">13</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Slice-to-Volume Registration</head><p>We can consider as an approximate reconstruction of the volume of interest after the first iteration of <ref type="bibr" target="#b11">(12)</ref>. Therefore we can optimize each individual by registering each slice to the current rigidly <ref type="bibr" target="#b32">[33]</ref> using any voxel-based similarity measure. We use cross-correlation for MRI and normalised mutual information for US images and restart the super-resolution volume reconstruction with the resulting refined alignment of and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. IMPLEMENTATION</head><p>We have implemented the proposed algorithm using GPUs and Nvidia's Compute Unified Device Architecture (CUDA) <ref type="bibr" target="#b33">[34]</ref>. CUDA is a highly evolved SIMD programming language which allows a large part the proposed framework to be mapped onto GPU hardware. Currently, CUDA is the only high-level GPGPU language that provides, for example, bi-directional texture access via surfaces in a kernel, which is essential for the efficient implementation of certain parts our framework (for example the registration step). In this section we discuss the key implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parallelization</head><p>SVR methods offer two major opportunities for parallelization. First, individual slices can be treated separately for large parts of the reconstruction process. This allows the application of simple parallel computation schemes for multi-core CPUs. For comparison and evaluation we have implemented such a Multi-CPU version of the KM SVR method [5] using Intel's Threading Building Blocks <ref type="bibr" target="#b34">[35]</ref>.</p><p>A second layer of parallelization is given by the individual slice pixels and volume voxels . Most pixel/voxel based operations are independent of each other and calculations involving these can be executed in parallel on SIMD machines. When processing individual slices, it is certainly possible to parallelize computations on a per pixel level but this is unlikely to provide good performance on current hardware due to the small number of pixels in a single slice in comparison to the number of processors on a GPU, which would leave the GPU under-utilized. Parallelization over multiple slices and pixels within those slices is therefore desirable for slice-based operations. Kernel level parallelization enables us to implement our own efficient SVR method including flexible accurate evaluation of PSFs as discussed in Section IV.</p><p>a) Kernel Level Parallelization: We divide individual procedures, i.e., computing kernels, into three classes.</p><p>The first class maps volume data to volume data of the same size. Examples of such procedures are the edge preserving regularization used in <ref type="bibr" target="#b11">(12)</ref> and the bias-field correction illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. These procedures can be implemented using a three-dimensional computation grid starting one thread per voxel. Reading from and writing to memory is often a bottleneck when working with volume datasets To address this, we use CUDA textures for read-only volume data, and layered surfaces <ref type="bibr" target="#b33">[34]</ref> for modifiable slice data. Both storages go through texture cache and thus enable fast access and improved algorithm performance. The second class of procedures map pixels in the acquired slices to voxels in the target volume, e.g., when integrating slices to the accumulated volume. As pixels from different slices can map to the same voxel a straightforward parallelization over multiple slices is not possible. A naıüve alternative would be to apply a kernel to each of the slices individually. However, this would again lead to low GPU utilisation and disappointing performance gains. To avoid this bottleneck, we store all slices in a coalesced memory area with contiguous memory addresses. This storage forms a volume with an extent equal to the maximum occurrence slice dimensions in . The volume's depth is defined by the number of slices. To avoid race conditions when accessing voxels, we rely on atomic operations <ref type="bibr" target="#b33">[34]</ref>, e.g., in (9) when carrying out the mapping . Fig. <ref type="figure" target="#fig_2">3</ref> shows a schematic overview of the implementation of these types of procedure. Additionally, when volumes are used as input, parallelization across the three dimensions of the volume is straightforward although care must be taken in order to exclude voxels as determined by an optional manual mask. We achieve this by immediately terminating threads started for these voxels.</p><p>The third class of procedures maps multiple input pixels or voxels to a single output value. Summations and minimum/maximum operations over entire slices make up large parts of the slice-to-volume registration algorithm <ref type="bibr" target="#b32">[33]</ref> and such operations cannot be entirely parallelized. However, to avoid sequential execution, we apply parallel reductions <ref type="bibr" target="#b35">[36]</ref> in these parts. Again, a parallelization over individual slices would not be sufficient to fully utilise a GPU. Thus, we execute reductions for multiple slices in parallel. Reduction operations which are concurrently required for the same slices can be fused as they require the same input data. This reduces memory access to effectively one third, directly increasing performance by a factor of three.</p><p>b) Multi-GPU Parallelization: While kernel level parallelization yields speedups on single GPU machines, it is desirable to utilize the power of multi-GPU systems where available. To parallelize our method to multiple GPUs, we follow a similar idea to the multi-threaded parallelization for CPUs: we assign subsets of slices to each GPU. This idea not only leads to performance increases, but also allows larger datasets to be handled as data can be distributed over multiple GPUs. It is not possible, however, for the GPUs to work completely independently, as data need to be integrated into a common volume and error measurements need to be propagated. Essentially, after each SVR step, a synchronization among all GPUs is required to enable data transmission. To allow completely parallel execution within each step, we assign an individual worker thread to each GPU. These worker threads are controlled by a master thread which collects and distributes data, starting the execution of the individual steps. In this way, we can achieve good speed-ups when going from a single-to a multi-GPU setup and are able to scale the performance linearly with the number of available GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Motion Correction and Measurement</head><p>Registration is performed either on a CPU using multi-core rigid registration implemented within the IRTK<ref type="foot" target="#foot_1">1</ref> software package <ref type="bibr" target="#b32">[33]</ref>, or on a GPU using our own specially designed registration framework for optimal execution on GPUs with parallel reduction operations.</p><p>For our motion measurement approach from Section IV.A we make use of the GPU accelerated CULA library <ref type="bibr" target="#b36">[37]</ref>, which provides fast CPU and GPU methods for large matrix rank determination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EVALUATION AND RESULTS</head><p>We implemented the framework using Intel's Threading Building Blocks and Nvidia's CUDA. It has been tested on an Intel Xeon E5-2630 v2@2.60 GHz system with 16 GB RAM, an Nvidia Tesla K40 with 12 GB RAM and a Geforce 780 Graphics card with 6 GB RAM. We use real data from volunteer freehand ultrasound of the liver (Section VI.A) and fetal MRI data (Section VI.B). For quantitative evaluation used simulated data sets (Section VI.C) with known ground truth. We analyse the method's parameter space (Section VI.D) and quantify the performance of our template stack estimation approach in Section VI.E. Finally, we evaluate the effect of different PSFs in Section VI.F and give a detailed overview of the required computing time and memory footprint in Section VI.G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Freehand Compound Ultrasound</head><p>To demonstrate the effectiveness of our method we have applied it to freehand 3D ultrasound (US) scans of the liver from two volunteers. A regular 2D abdominal probe (Siemens S2000, 4C1-S) was used with a magnetic tracking system (Ascension 3D Guidance). The tracking information was calibrated to the US image space and used to establish the 3D location of every image frame. Three sweeps from different angles were used, where the original image frames with a resolution of 0.45 mm 0.45 mm were passed to our reconstruction framework. This was compared against compounded volumes from the individual sweeps, constructed as described in <ref type="bibr" target="#b2">[3]</ref>. Utilizing data from multiple freehand sweeps can provide more complete coverage of anatomic structures, such as fine hepatic vasculature. However, a simple averaging of the image data is not possible due to non-linear deformations of the liver (from respiratory or patient motion, as well as US probe pressure) as well as orientation-dependent artefacts, due to different angles of the acoustic windows and tracking errors. Fig. <ref type="figure" target="#fig_3">4</ref> shows the result of our reconstruction approach. This is compared to one of the original freehand US slices, as well as to the average intensity volume of all used sweeps <ref type="bibr" target="#b2">[3]</ref>.</p><p>Super-resolution approaches, such as the one proposed in this work, are difficult to apply to these types of data, because the input space is typically much larger than for the MRI case (Section VI.B). The required computation times are therefore often infeasible. One limitation of this experiment is, that we assume a Gaussian PSF with a constant slice thickness of 2.5 mm. This is of course not true for real US data and the consequences of an inhomogeneous PSF should be investigated in future work. Fig. <ref type="figure" target="#fig_3">4</ref> shows results from a volunteer experiment, and compares the average image data to the result of our proposed approach. Manual examination by clinical experts confirmed that our method leads to more accurate and faster (semi-automatic) image segmentation and is able to compensate for more rigid organ movements than standard methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Fetal MRI Data</head><p>Fetal MR datasets were acquired on a Philips Achieva 1.5 T (24 datasets) and 3 T scanner (5 datasets), with the mother lying at a 20 tilt on the left side to avoid pressure on the inferior vena cava. The study was approved by the local ethics committee at Imperial College London and the UK's NHS National Research Ethics Service. Single-shot fast spin echo (ssFSE) T2-weighted sequences with half Fourier acquisition <ref type="bibr" target="#b25">[26]</ref> and SENSE <ref type="bibr" target="#b21">[22]</ref> were used to acquire a stack of images of the mother's womb. Each acquisition of a 2D image takes approximately 200-800 ms, which is fast enough to freeze fetal motion in each image, but generally results in inconsistent anatomical positioning between slices. Visual inspection of the data confirmed that the scans contain small to medium amounts of motion of the fetus. Several of these image stacks are acquired in axial, coronal and sagittal planes with respect to the fetal anatomy. The 3D resolution of each stack is approximately 288 288 90 voxels with a size of 1.2 mm 1.2 mm 1.25 mm for both field strengths. We obtained measurements of from scanner calibration data as follows and <ref type="bibr" target="#b13">(14)</ref> where represents the chosen size of the slice voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Scan Simulation</head><p>To make our simulated images comparable and to be able to predefine known motion trajectories, we have developed a computer simulation using test data that comprise a 128 128 128 Shepp-Logan phantom <ref type="bibr" target="#b37">[38]</ref>, previously reconstructed fetal brain scans (140 140 100) and a T2 weighted artificial brain dataset (181 217 181) from the BrainWeb database <ref type="bibr" target="#b38">[39]</ref>. Maximal motion amplitude is expressed in cm/s. From fetal cine sequences <ref type="bibr" target="#b39">[40]</ref> we know that fetuses can move their heads randomly in any direction combined with a small omni-directional jitter caused by the baby and by maternal movements (breathing, digestive movements, etc.). The speed of head motion we have measured from these sequences was between 0.25 and 2.0 cm/s. To simulate the scan process we sample the data in parallel slices while transforming the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I INPUT PARAMETER RANGE FOR PARAMETER SPACE EXPLORATION AND EXAMPLE RUNTIME-OPTIMAL VALUES (222 S FOR THIS TEST CASE)</head><p>WITH A LOW AMOUNT OF MOTION CM/S) (OPT.) phantom according to this motion trajectory. Fig. <ref type="figure" target="#fig_4">5</ref> compares a real and a simulated motion corrupted dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Optimal Parameter Definition</head><p>Like most complex algorithms, our method has a number of possible parameters. Empirically determined parameter values of SVR methods have been reported such as the number of iterations and smoothing factors. For this paper, we make use of modern parameter space exploration methods and use Tuner, a tool for visual response surface exploration <ref type="bibr" target="#b40">[41]</ref>. We explore the input space for those parameters that have the most significant impact on the final reconstruction quality and the computation time. These are the number of motion estimation/registration iterations (outer loop in Fig. <ref type="figure" target="#fig_1">2</ref>) the number of super-resolution reconstruction iterations (inner loop in Fig. <ref type="figure" target="#fig_1">2</ref>) and the number of super-resolution iterations during the final loop, the number of stacks and the amount of motion. Motion generated by our simulation framework enables us to quantify its effect comprehensively. A summary of the evaluated input parameter range and their optimal values for a low amount of motion ( cm/s, shown by most of our datasets) is given in Table <ref type="table">I</ref>.</p><p>To avoid testing every single combination of parameter values, Tuner samples the input parameter space sparsely and estimates algorithm performance for untested areas using a Gaussian process model. Fig. <ref type="figure" target="#fig_5">6</ref> shows the decreasing PSNR with increasing (artificially added) motion for a real fetal brain  dataset while the remaining parameters are fixed (to the values shown in Table <ref type="table">I</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Motion Measurement</head><p>To evaluate the method to determine the stack least affected by motion (Section IV.A), we simulated motion at a variety of amplitudes using our scan simulation (Section VI.C) and compare the known motion amplitude to the surrogate measure provided through rank-approximation.</p><p>Note that it is only necessary to determine a relative estimate for the motion amplitude to define the best template stack. During our experiments using the central third of slices per stack and an error threshold of provided the best results to determine from (3). Fig. <ref type="figure" target="#fig_6">7</ref> illustrates the strong correlation between the amplitude of the known motion and the values of derived from the stack data matrices .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Choice of Point-Spread Function</head><p>With our approach it is possible to evaluate arbitrary PSFs accurately within a complete framework. Different PSFs influence the recovery of local details but do not significantly influence a global quality metric, such as PSNR. In our experiments the global PSNR was found to be around 40 dB for our phantom dataset with different realistic simulated motion corruption. In order to evaluate the influence of different PSF functions, a qualitative evaluation of local image details is required. Fig. <ref type="figure" target="#fig_7">8</ref> shows examples for local differences with (a) truncated pre-computed and interpolated Gaussian <ref type="bibr" target="#b4">[5]</ref>, (b) continuous Gaussian <ref type="bibr" target="#b5">(6)</ref>, and (c) continuous <ref type="bibr" target="#b6">(7)</ref>. Fig. <ref type="figure" target="#fig_7">8</ref>(d) shows a selected intensity profile of the resulting  reconstructions. Fig. <ref type="figure" target="#fig_8">9</ref> compares two such slice profiles with the originally acquired image and thus PSF at the shown position. seems to reconstruct slice profiles most similar to the originally acquired data.</p><p>To assess the influence of different PSFs on the accuracy of segmentations we chose an artificial brain dataset from the BrainWeb database <ref type="bibr" target="#b38">[39]</ref> and used the 0% noise 0% intensity non-uniformity data to generate a ground truth segmentation for the ventricles, the white matter and the grey matter. We use a semi-automatic segmentation method to define coarse foreground and background constraints for the target structure. The constraints can be used to obtain a full segmentation using the automatic Geodesic Image Segmentation method <ref type="bibr" target="#b41">[42]</ref>. We chose this algorithm, an exemplar of many standard methods for semi-automatic image segmentation, because we hypothesise that different point spread functions may result in different image gradient profiles and a geodesic contour approach may be sensitive to this. The scan simulation from Section VI.C was used to simulate six stacks of motion corrupted images at a maximum of 1.5 cm/s. These stacks were reconstructed to the original resolution of 1 mm isotropic voxel-size using different PSFs. After rigid 3D-3D registration to the ground truth image, which is necessary to compensate for potentially small offsets of the reconstruction caused by the artificial motion corruption, Geodesic Image Segmentation <ref type="bibr" target="#b41">[42]</ref> is applied with the same foreground and background constraint as defined for the ground truth segmentation. To evaluate the segmentation quality, we compare the results using the Dice metric in Table <ref type="table" target="#tab_0">II</ref>. While all PSFs perform similarly for high contrast structures like the ventricles, our approach of sampling the PSF leads to improved results for less well defined structures such as white matter and the cortex.</p><p>Our PSF sampling strategy was also confirmed by clinical partners to be beneficial for automatic image segmentation algorithms used in their clinical pipelines. There is no significant difference in runtime for the different PSFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Runtime</head><p>We have implemented the discussed algorithm for execution on a single GPU (1 GPU-one Nvidia Tesla K40) and on multiple GPUs (2 GPUs-one Nvidia Tesla K40 and one Geforce 780). For comparison we have implemented the KM algorithm <ref type="bibr" target="#b4">[5]</ref> using a single CPU (1xCPU) and we have parallelized it on the slice level using multiple CPU cores (12 CPU). We compare the runtimes of the individual parts and the overall time required for a full reconstructions in Table <ref type="table" target="#tab_1">III</ref>. The GPU implementations utilize multi-threaded CPU cores, multiple GPUs, and directly evaluated PSFs at full sampling resolution. Our GPU accelerated methods clearly outperform the CPU versions for reconstructions using an isotropic target voxel size of either 1.0 mm or 0.5 mm.</p><p>We compare the resulting image quality with the CPU versions of the KM algorithm and the most recent version of the Baby Brain Toolkit (BTK) <ref type="bibr" target="#b6">[7]</ref>, which is currently the only other publicly available framework for volumetric reconstruction from motion corrupted image stacks.</p><p>The results for the same datasets with similar parameters are shown in Fig. <ref type="figure" target="#fig_9">10</ref>. For this test we did not apply bias correction step (cp. Fig. <ref type="figure" target="#fig_1">2</ref>) to allow a fair comparison with BTK. The KM approach used a truncated and interpolated PSF while our method uses a precise definition of . Even though BTK does not use robust statistics and uses super resolution only once, the 2 GPUs-approach is still approximately four times faster for comparable reconstruction volumes while providing a better resulting image quality by integrating both outlier rejection and super resolution in the SVR computation. This was approximately three times faster with activated bias correction, depending on the number of slices (with more slices, a greater speed-up is possible with multi-GPU acceleration).</p><p>The KM algorithm yields a runtime and image quality comparable to our 12 CPU implementation. Our results from Fig. <ref type="figure" target="#fig_9">10</ref> were confirmed after correspondence with the authors of KM <ref type="bibr" target="#b4">[5]</ref> and BTK <ref type="bibr" target="#b6">[7]</ref>. We jointly concluded that the comparison to BTK is not entirely fair for the dataset shown in Fig. <ref type="figure" target="#fig_9">10(d</ref>) because BTK does not support outlier removal using robust statistics.</p><p>Table <ref type="table" target="#tab_1">III</ref> shows measured runtime for the most computationally expensive parts of our algorithm at the full PSF resolution. The upper section corresponds to steps of the outer (registration) loop, the middle section to parts of the inner (super-resolution) loop, and the lower section to the total runtime when configured for a real-world dataset. The values show results for a target resolution of 1.0 mm and 0.5 mm and for three and six input stacks. The total is given for a real scenario with a high amount of motion and aiming for a maximum reconstruction quality, i.e., executing the registration/outer loop eight times to compensate for a high amount of motion, executing the reconstruction/inner loop four times and 13 times during the final iteration as given by Table <ref type="table">I</ref>. Bias correction is optional and only required for MRI data. It is possible to approximate the required runtime by using the equation at the bottom of the table (where denotes the number of motion correction iterations, the number of super-resolution and robust statistics iterations, and the number of super-resolution and robust statistics iterations during the last iteration of , c.p. Table <ref type="table">I</ref>). The last row gives approximate values for the memory required memory for our framework's implementation, which is not currently memory optimized. The CPU methods were evaluated using precomputed and interpolated truncated PSFs, which leads to a significant reduction of computation time but also to increased memory requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. SOURCE CODE</head><p>The source code for the implementation of the SVR reconstruction is publicly available together with binaries for Windows and Ubuntu Linux. It is licensed under creative commons public license.</p><p>The proposed approach is currently deployed to the clinical research practice at St. Thomas Hospital London, King's College London, Imperial College London, Oxford University, UK, and Medical University of Vienna, Austria. It is publicly available on github<ref type="foot" target="#foot_2">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. LIMITATIONS</head><p>While our approach is fast and accurate it has certain limitations. Nvidia SIMD computing hardware is required to execute our tools. We have also tested our approach on a laptop equipped with a GeForce GTX 660 M and 16 GB RAM, which resulted in slower execution compared to 2 GPU in Table <ref type="table" target="#tab_1">III</ref>.  Additionally, the 2D/3D registration is only able to recover relatively limited rotations of the target object, i.e., it currently cannot recover sudden movements of more than . A limited number of these slices can be identified via robust statistics but if the initial reconstruction is already significantly corrupted, registration and reconstruction can fail. Therefore, manual inspection of the results by an expert user will remain necessary. Finally, for ultrasound, our approach requires a probe specific PSF distribution to be fully accurate. We are currently investigating how to measure this distribution of PSFs and will update the approach in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSION</head><p>We have presented a fully parallel SVR approach using accurately sampled and flexible PSFs for the reconstruction of high-resolution volumetric data from motion corrupted stacks of images. The implementation uses Nvidia CUDA and C++ and is publicly available. We have employed a quantitative approach (Tuner) to determine suitable model parameters. Our approach is approximately five to ten times faster than the fastest currently available multi-CPU frameworks. Since we do not need to precompute and interpolate the PSF, the method has a minimal memory footprint while maintaining maximum accuracy. The required runtime scales well with the number of input stacks due to the use of high occupancy SIMD techniques. Comparisons with state-of-the-art techniques show that our approach gains a higher reconstruction quality while maintaining flexibility. Additionally, our approach incorporates automatic selection of the template stack based on matrix low-rank approximation. Overall, our approach is fast and accurate enough to be applied directly during examination and this will form the next step in our deployment process. With the subject remaining present during examination, the online availability of motion corrected reconstructions will help to determine if and where more scanning is necessary. Online reconstructions will also, in the longer term, enable a feedback loop to the scanner for optimal data sample acquisition and minimal scan time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Top row: An example of three orthogonal views through a stack of 3T ssFSE MRI slices. Note the significant motion artefacts between the slices and the intensity bias. The left image shows an acquired ssFSE slice and the other two images orthogonal planes through a stack of these slices. Bottom row: The resulting reconstruction at 0.75 mm isotropic voxel size after applying the proposed method.</figDesc><graphic coords="3,40.98,66.12,246.00,184.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An overview of the proposed approach. Thick solid lines represent the program flow and thin dotted lines the most important data flow. Boxes in dotted lines are optional, e.g., bias field correction for MR data.</figDesc><graphic coords="4,45.00,64.14,504.00,205.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. 2D slices are arranged in a volumetric 3D computation grid to maximize SIMD occupancy (left). The grid spans the maximum slice size in x and y. Smaller slices are filled with zeros to reach the required grid size in x and y. Operations on the reconstruction volume are performed in a volume sized grid.</figDesc><graphic coords="7,40.98,64.14,246.00,135.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Results of the application of our method to three stacks of freehand 2D compound ultrasound (US). This dataset is reconstructed to 0.6 mm isotropic voxel size and contains 568 406 630 voxels. The investigated area in red shows the vessel tree of a volunteer's liver. (a)-(c) show a multi-planar reconstruction of the compounded average [3] of the input slices resampled in a joint volume with 0.6 mm isotropic voxel size. (d) gives an overview over two of the acquired 2D sweeps in 3D. (e) shows the original data, (f)-(k) show the resulting reconstruction in three orthogonal orientations comparing the average of the image data to the result of our super-resolution (SR) framework. (e) original slice, (f) average, (g) SR, (h) average, (i) SR, (j) average, (k) SR.</figDesc><graphic coords="8,45.00,64.14,504.00,210.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Examples of a typical real motion corrupted scan (a) and a synthetically motion corrupted reconstructed dataset (b). Note that the slices shown serve only as illustration for the motion corruption artefacts and are not meant to show the same slices and same corruption in the same subject.</figDesc><graphic coords="9,40.98,64.14,246.00,192.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Decreasing PSNR with artificially and randomly increasing motion tested on a real brain dataset. For this test we kept the number of iterations constant and used 4 stacks as proposed by Tuner.</figDesc><graphic coords="9,304.98,63.12,246.00,91.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Comparison of the surrogate motion estimates (3) and the amplitude actually used to simulate motion artefacts in a phantom dataset. The blue line shows the given, increasing motion amplitude and the connected dots show the result from our motion measurement approach.</figDesc><graphic coords="9,304.98,205.14,246.00,132.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Comparison of different types of point spread functions for a 0.75 mm voxel size reconstructed volume. (a) shows a slice through a reconstruction of a truncated and interpolated Gaussian weighted [5], (b) using an accurately sampled Gaussian weighted (6), (c) an accurately sampled Sinc/Gauss (7). (d) compared the intensity profile of the three PSFs at the line in (a)-(c). More distinct edges and finer details are provided by example (c). (a) , (b) , (c) , (d) profile.</figDesc><graphic coords="10,45.00,64.14,504.00,225.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Comparison between an originally acquired slice (a) and cutting planes through the reconstructed volume at the same position. The reconstructions (b), (d), and (e) have the same resolution as the input (1.18 mm voxel size) and use different point spread functions. Two rows in the images are selected (marked as white lines) and their intensity profiles are compared in (c) and (f). Note that using an accurately sampled allows improved recovery of smaller details like the pupil in the eye (e). The profiles are also closest to the originally measured slice profiles (blue vs. black curves). (a) original, (b) , (c) upper profile sample, (d) Gaussian , (e) Gauss-Sinc , (f) lower profile sample.</figDesc><graphic coords="10,45.00,353.10,504.00,210.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Qualitative comparison between BTK, KM, and the proposed approach: a fetal thoracic MR reconstruction (axial) and a reconstruction of the fetal brain (coronal), both acquired with a field strength of 3 Tesla. BTK's minimum voxel size is defined by the minimum pixel size of the input stacks, which has been fixed for all tests (1.18 mm isotropic). The brain dataset shows a significant amount of motion and a 3 T specific bias field, which causes a low reconstruction quality using BTK (d). The images show the same physical slices in world coordinates. (a) BTK, (b) KM, (c) Proposed, (d) BTK, (e) KM, (f) Proposed.</figDesc><graphic coords="12,45.00,252.12,504.00,99.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE II LEFT</head><label>II</label><figDesc>: EXAMPLE FOREGROUND (YELLOW) AND BACKGROUND (RED) CONSTRAINTS FOR THE SEGMENTATION OF THE VENTRICLES [42]. RIGHT: EVALUATING THE INFLUENCE OF DIFFERENT PSFS ON THE DICE COEFFICIENT FOR SEMI-AUTOMATIC SEGMENTATION COMPARED TO A GROUND TRUTH. WE EVALUATE THE ACCURACY OF VENTRICULAR, WHITE-MATTER, AND CORTICAL SEGMENTATION OF THE BRAINWEB DATASET AFTER APPLYING SIMULATED MOTION CORRUPTION AND RECONSTRUCTION USING EACH PSF</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE III RUNTIME</head><label>III</label><figDesc>AND MEMORY EVALUATION OF DIFFERENT SYSTEM CONFIGURATIONS AND TARGET VOLUME RESOLUTIONS</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This work is licensed under a Creative Commons Attribution 3.0 License. For more information, see http://creativecommons.org/licenses/by/3.0/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>Image Registration Toolkit (IRTK), https://github.com/BioMedIA/IRTK.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>https://github.com/bkainz/fetalReconstruction.git.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank volunteer subjects for their patience and the radiographers from St. Thomas Hospital London, especially J. Allsop and M. Fox, for the image acquisitions. The authors are grateful to F. Rousseau for testing our datasets with BTK and for the insightful discussion. The authors acknowledge the hard work invested into MITK <ref type="bibr" target="#b42">[43]</ref>, which we used to generate some of the figures. The Image Registration Toolkit was used under creative commons public licence from IXICO Ltd.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bernhard Kainz is supported by an EU Marie Curie Intra-European Fellowship (FP7-PEOPLE-2012-IEF F.A.U.S.T. 325661). This research was also supported by the Austrian Science Fund (FWF): P23329 as well as by the National Institute for Health Research (NIHR) Biomedical Research Centre based at Guy's and St Thomas' NHS Foundation Trust and King's College London. The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR or the Department of Health. Furthermore, this work was supported by Wellcome Trust and EPSRC IEH award [102431] for the iFIND project. Asterisk indicates corresponding author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Three-dimensional spatial compounding of ultrasound images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rohling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Berman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="177" to="193" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Registration-based approach for reconstruction of high-resolution in utero fetal MR brain images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rousseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1072" to="1081" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast hybrid freehand ultrasound volume reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karamalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Spie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Miga</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wong</surname></persName>
		</editor>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">7261</biblScope>
			<biblScope unit="page" from="726" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intersection based motion correction of multislice MRI for 3-D in utero fetal brain image formation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="158" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reconstruction of fetal brain MRI with intensity matching and complete outlier removal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuklisova-Murgasova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quaghebeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1550" to="1564" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An accurate and effective FMM-based approach for freehand 3D ultrasound reconstruction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Signal Process. Control</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="645" to="656" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BTK: An open-source toolkit for fetal brain MR image processing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rousseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="73" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pulmonary nodules: Detection with thick-section spiral CT versus conventional CT</title>
		<author>
			<persName><forename type="first">M</forename><surname>Remy-Jardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Remy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giraud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Marquette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="520" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Motion-compensation techniques in neonatal and fetal MR imaging</title>
		<author>
			<persName><forename type="first">C</forename><surname>Malamateniou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJNR Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1124" to="1136" />
			<date type="published" when="2012-05">May 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Freehand 3D ultrasound reconstruction algorithms: A review</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Solberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lindseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Torp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A N</forename><surname>Hernes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ultrasound Med. Biol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="991" to="1009" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonrigid registration of ultrasound and MRI using contextual conditioned mutual information</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rivaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Karimaghaloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="708" to="725" />
			<date type="published" when="2014-03">Mar. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Engineering a freehand 3D ultrasound system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Treece</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Berman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="757" to="777" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MR imaging methods for assessing fetal brain development</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allsop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Perkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hajnal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="700" to="711" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MRI of normal and pathological fetal lung development</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kasprian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Balassy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Radiol</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="270" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Motion corrected 3D reconstruction of the fetal thorax from prenatal MRI</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2014, Part II</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">G</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8674</biblScope>
			<biblScope unit="page" from="284" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fetal MRI: Techniques and protocols</title>
		<author>
			<persName><forename type="first">D</forename><surname>Prayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Prayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pediatric Radiol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="685" to="693" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fetal MRI: An approach to practice: A review</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Saleem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Adv. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="507" to="523" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fetal fast MR imaging: Reproducibility, technical quality, and conspicuity of anatomy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="549" to="554" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Respiratory motion of the heart: Kinematics and the implications for the spatial resolution in coronary imaging</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Riederer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Ehman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="713" to="719" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PROMO: Real-time prospective motion correction in MRI using image-based tracking</title>
		<author>
			<persName><forename type="first">N</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MR Med</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="105" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Motion correction with PROPELLER MRI: Application to head motion and free-breathing cardiac imaging</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Pipe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="963" to="969" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Prospective navigator-echo-based real-time triggering of fetal head movement for the reduction of artifacts</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bonel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Frei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Raio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer-Wittkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Remonda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wiest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Radiol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="822" to="829" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Brain imaging in the unsedated pediatric patient: Comparison of periodically rotated overlapping parallel lines with enhanced reconstruction and single-shot fast spin-echo sequences</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Pipe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Karis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Farthing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Heiserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="794" to="798" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust super-resolution volume reconstruction from slice acquisitions: Application to fetal brain MRI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gholipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Estroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1739" to="1758" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A novel approach to high resolution fetal brain MR imaging</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rousseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention MICCAI 2005, ser</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Duncan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Gerig</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3749</biblScope>
			<biblScope unit="page" from="548" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automated fetal brain segmentation from 2D MRI slices for motion correction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keraudren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="633" to="643" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast fully automatic brain detection in foetal MRI using dense rotation invariant image descriptors</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Symp. Biomed. Imag</title>
		<imprint>
			<biblScope unit="page" from="1230" to="1233" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2010 IEEE Conf. Comput. Vis</title>
		<meeting>2010 IEEE Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="763" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The approximation of one matrix by another of lower rank</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eckart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="218" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">MRI of moving subjects using multislice snapshot images with volume reconstruction (SVR): Application to fetal, neonatal, and adult brain studies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="967" to="980" />
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unified segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="839" to="851" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990-07">Jul. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A generic framework for non-rigid registration based on non-uniform multi-level free-form deformations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention MICCAI</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Niessen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2208</biblScope>
			<biblScope unit="page" from="573" to="581" />
			<date type="published" when="2001">2001. 2001</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">CUDA by Example: An Introduction to General-Purpose GPU Programming, 1st ed</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kandrot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Intel Threading Building Blocks, 1st ed</title>
		<author>
			<persName><forename type="first">J</forename><surname>Reinders</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Sebastopol, CA: O&apos;Reilly</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Optimizing parallel reduction in CUDA</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NVIDIA Develop. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">CULA: Hybrid GPU accelerated linear algebra routines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Humphrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Spagnoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Paolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Kelmelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Defense Security Symp</title>
		<imprint>
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Analytical form of Shepp-Logan phantom for parallel MRI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Guerquin-Kern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">I</forename><surname>Karahanoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V D</forename><surname>Ville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Pruessmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Biomed. Imag</title>
		<meeting>IEEE Int. Symp. Biomed. Imag</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="261" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">BrainWeb: Online interface to a 3D MRI simulated brain database</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Cocosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kollokian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>-S. Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Pike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">425</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Optimization and initial experience of a multisection balanced steady-state free precession cine sequence for the assessment of fetal behavior in utero</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T A</forename><surname>Hayat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJNR Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="331" to="338" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tuner: Principled parameter finding for image segmentation algorithms using visual response surface exploration</title>
		<author>
			<persName><forename type="first">T</forename><surname>Torsney-Weir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualizat. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1892" to="1901" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">GeoS: Geodesic image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV&apos;08, Part I, ser</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Lncs</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">H S</forename><surname>Forsyth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Torr</surname></persName>
		</editor>
		<editor>
			<persName><surname>Zisserman</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5302</biblScope>
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The medical imaging interaction toolkit</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="594" to="604" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
