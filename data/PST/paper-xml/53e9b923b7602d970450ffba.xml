<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Theory of Computing Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
							<email>gibbons@research.bell-labs.com</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Research Center</orgName>
								<orgName type="institution">Bell Laboratories (Lucent Technologies)</orgName>
								<address>
									<addrLine>600 Mountain Avenue</addrLine>
									<postCode>07974</postCode>
									<settlement>Murray Hill</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
							<email>matias@math.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Research Center</orgName>
								<orgName type="institution">Bell Laboratories (Lucent Technologies)</orgName>
								<address>
									<addrLine>600 Mountain Avenue</addrLine>
									<postCode>07974</postCode>
									<settlement>Murray Hill</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<settlement>Austin</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Theory of Computing Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2440E3C3A382159F4EAF9A7FCEB2F013</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There has been a great deal of interest recently in the development of general-purpose bridging models for parallel computation. Models such as the BSP and LogP have been proposed as more realistic alternatives to the widely used PRAM model. The BSP and LogP models imply a rather different style for designing algorithms when compared with the PRAM model. Indeed, while many consider data parallelism as a convenient style, and the shared-memory abstraction as an easyto-use platform, the bandwidth limitations of current machines have diverted much attention to message-passing and distributed-memory models (such as the BSP and LogP) that account more properly for these limitations.</p><p>In this paper we consider the question of whether a shared-memory model can serve as an effective bridging model for parallel computation. In particular, can a shared-memory model be as effective as, say, the BSP? As a candidate for a bridging model, we introduce the Queuing Shared-Memory (QSM) model, which accounts for limited communication bandwidth while still providing a simple shared-memory abstraction. We substantiate the ability of the QSM to serve as a bridging model by providing a simple work-preserving emulation of the QSM on both the BSP, and on a related model, the (d, x)-BSP. We present evidence that the features of the QSM are essential to its effectiveness as a bridging model. In addition, we describe scenarios</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A fundamental challenge in parallel processing is to develop effective models for parallel computation, at suitable levels of abstraction. Effective and widely used models would provide standards that could be relied upon by application programmers, algorithm designers, software vendors, and hardware vendors, making parallel machines cheaper to build and easier to use. Effective models must balance simplicity, accuracy, and broad applicability. In particular, a simple, "bridging" model, i.e., a model that spans the range from algorithm design to architecture to hardware, is an especially desirable one. A number of models for parallel computation have been proposed and studied in the last 20 years. Primary among them are the parallel random access machine (PRAM) model <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b64">[65]</ref>, in which processors execute in lock-step and communicate by reading and writing locations in a shared memory, and network-based models (hypercube, butterfly, arrays, etc. <ref type="bibr" target="#b50">[51]</ref>), in which processors communicate by sending messages to their neighbors in the given network. The PRAM model, although simple and well suited for developing parallel algorithms, is considered by many to be too high level, failing to model parallel machines accurately. Network-based models are considered by many to be too low level, failing to be broadly applicable, and not reflective of the current generation of parallel machines. Thus, a number of alternative, intermediate models have been proposed and studied in recent years. These abstract models differ in what aspects of parallel machines are exposed. Some focus on dealing with asynchrony in a shared-memory context (e.g., <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b56">[57]</ref>, and <ref type="bibr" target="#b60">[61]</ref>). Others focus on accounting for the overheads in accessing the shared memory <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b55">[56]</ref> or in sending messages <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b68">[69]</ref>. Several models are primarily concerned with the memory hierarchy, especially disk I/O <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b71">[72]</ref>). Others focus on contention at the memory location <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b35">[36]</ref> or memory module <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Finally, a few models incorporate powerful aggregate communication primitives <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>Given this plethora of models, it is natural to seek to distinguish a few models with the most promise, and concentrate on these models. Advocates such as Vishkin <ref type="bibr" target="#b70">[71]</ref>, Kennedy <ref type="bibr" target="#b49">[50]</ref>, Smith <ref type="bibr" target="#b66">[67]</ref>, and Blelloch <ref type="bibr" target="#b14">[15]</ref> have long presented arguments in support of the shared-memory abstraction. On the other hand, shared-memory models have been criticized for years for failing to model essential realities of parallel machines. In particular, the PRAM model has been faulted for completely failing to model bandwidth limitations of parallel machines. Until recently, there were few attractive alternatives, so shared-memory models such as the PRAM remained the most widely used models for the design and analysis of parallel algorithms (see, e.g., <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b47">[48]</ref>, and <ref type="bibr" target="#b64">[65]</ref>). However, in the last few years, new alternatives such as the BSP  <ref type="bibr" target="#b68">[69]</ref> and LogP <ref type="bibr" target="#b21">[22]</ref> models have gained considerable popularity. These abstract network models support point-to-point message-passing, can directly support a distributed-memory abstraction, and account for bandwidth limitations using a parameter, g ≥ 1, that reflects the gap between the local instruction rate and the communication rate. Given these new, more realistic models, there is a temptation to declare all shared-memory models too unrealistic, and not worthy of further study or consideration.</p><p>In this paper we challenge this perception and consider the question of whether a shared-memory model can in fact serve as an effective bridging model for parallel computation. In particular, can a shared-memory model be as effective as, say, the BSP? As a candidate for a bridging model, we introduce the Queuing Shared-Memory (QSM) model, which accounts for limited communication bandwidth while still providing a simple shared-memory abstraction. In a nutshell, the QSM model consists of processors with individual private memory as well as a global shared memory. Access to shared memory is more expensive than access to local memory or a computation step, as characterized by a gap parameter, g, reflecting bandwidth limitations. The choice of the QSM model is based on the observation that while overheads due to latency, synchronization, and memory granularity can be effectively diminished by using slackness and pipelining, the bandwidth overhead is inherent and hence should be accounted for directly. Thus, the QSM is envisioned as a "minimal" shared-memory model that can be competitive with the BSP. Similarly, the memory contention rule of the QSM is the queuing contention rule, as in the QRQW PRAM <ref type="bibr" target="#b35">[36]</ref>. This rule is strong enough to provide the QSM with an expressive power comparable with that of the BSP, but it is not too strong to prevent a fast and efficient emulation of the QSM on the BSP with the techniques we use.</p><p>As advocated in <ref type="bibr" target="#b68">[69]</ref>, <ref type="bibr" target="#b70">[71]</ref>, and elsewhere, one reasonable goal for a high-level, shared-memory model is that it allows for efficient emulation on lower-level, seemingly more realistic, models. If the overheads in the emulation are small, then the high-level model becomes an attractive general-purpose bridging model. We substantiate the ability of the QSM to serve as a bridging model by providing a simple work-preserving emulation of the QSM on both the BSP, and on a related model, the (d, x)-BSP <ref type="bibr" target="#b15">[16]</ref>, and arguing for the practicality of this emulation. Thus the QSM can be effectively realized on machines that can effectively realize the BSP, as well as on machines that are better modeled by the (d, x)-BSP. We also describe scenarios in which the high-level QSM is more suited for analyzing algorithms on certain machines than the more detailed BSP and LogP models, due to the fact that the memory layout is different than the one perceived by the BSP and LogP.</p><p>We present several algorithmic results for the QSM. We note that any EREW <ref type="bibr" target="#b47">[48]</ref> or QRQW PRAM algorithm can be mapped onto the QSM with a factor of g increase in time and work, where g is the bandwidth (gap) parameter of the QSM. We also show that for many linear-work QRQW PRAM algorithms, this increase in work in the QSM algorithm is unavoidable, and we present some other lower bounds for the QSM. We consider the mapping of the BSP onto the QSM when the bandwidth parameter, g, is the same for both models. We show that many, though not all, BSP algorithms map onto the QSM step-by-step, resulting in algorithms whose time and work bounds match the bounds on a BSP whose latency parameter, L, is set to 1. We also present a work-preserving randomized emulation of the BSP on the QSM with a logarithmic slowdown. This result implies that any n-processor BSP algorithm that takes time t (n) (when L is set to 1) can be mapped onto the QSM to run in time O(t (n) lg n) w.h.p. using n/lg n processors, and more generally on a p-processor QSM to run in time O(t (n) • (n/ p + lg n)) w.h.p.</p><p>Our main conclusion is that shared-memory models can potentially serve as viable alternatives to existing message-passing or distributed-memory bridging models. While this paper focuses on a shared-memory model that would be competitive with the BSP, a similar approach can be taken with regard to other message-passing bridging models mentioned above (or others), that may emphasize other features than the ones emphasized by the BSP.  The rest of the paper is organized as follows. Some advantages of shared-memory models as bridging models are discussed in Section 2. In Section 3 we describe the QSM model, and qualitatively compare it with previous models, and, in particular, with the BSP. In Section 4 we present work-preserving emulations of the QSM on the BSP and on the (d, x)-BSP, and discuss the practicality of these emulations. In Section 5 we provide a few scenarios where the QSM is a more accurate model than the more detailed BSP and LogP. Section 6 presents algorithmic results and issues related to algorithm design on the QSM. Section 7 explores the merits of incorporating into the QSM model distinct bandwidth gaps at the processors and the memories.</p><p>Finally, we refer the reader to the position paper <ref type="bibr" target="#b32">[33]</ref>, which provides a nontechnical overview of much of this work in arguing the importance of shared-memory models in general and the QSM model in particular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Advantages of Shared-Memory Models as Bridging Models</head><p>A bridging model should provide an abstraction that is on the one hand easy to use by algorithm designers and programmers, and on the other hand can be realized by hardware and system software at a variety of price versus performance points. In this section we describe several contexts under which the shared-memory abstraction is an attractive choice for a bridging model in this regard.</p><p>We consider a (pure) shared-memory model to be one in which the processors communicate by reading and writing locations in a shared memory that is equally accessible by all processors. The shared memory is viewed as a collection of independent cells: the contention encountered in accessing a shared memory cell is a function only of the number of processors also accessing the same cell. There is no visible partitioning of the memory, and no sources of contention due to such partitioning. The PRAM is a classic example of a shared-memory model.</p><p>The shared-memory abstraction refers to the interprocessor communication. As part of its local private state, a processor may have additional memory such as registers, buffers, cache, and local memory banks. A shared-memory model may be asynchronous. It may also have explicit charges for communication, modeling various overheads in reading or writing a shared memory that is not local to, and may be physically quite remote from, the processor requesting the read or write. Thus it is a mistake to view "shared-memory model" as a synonym for PRAM.  The shared-memory abstraction is arguably easier to use than a message-passing or distributed-memory abstraction, and, in certain important contexts, can be realized by a wider range of machines. In what follows, we elaborate on three of the advantages of the shared-memory abstraction over the message-passing and distributed-memory abstractions.</p><p>Smooth Transition from Sequential to SMP to MPP. The shared-memory abstraction is similar to the view of memory in sequential programming (the familiar read/write semantics). It is also the abstraction of choice for the small symmetric multiprocessors (SMPs) found in current microprocessors. There are high-performance parallel machines such as the Cray C90, Cray J90, and Tera MTA that also directly support a shared-memory abstraction. Thus as a bridging model, it provides for the smoothest transition from sequential programming to programming small SMPs to programming larger parallel machines (MPPs). Code can be debugged on a smaller, simpler, and cheaper machine, before running it on a larger, more expensive machine; this will often significantly reduce the overall debugging time. In short, the shared-memory abstraction offers ease of use in designing algorithms and programs that span a variety of machine sizes, and it has also been realized by machines that span a variety of machine sizes. This contrasts with message-passing and explicit distributed-memory, which are not directly supported by any sequential machine or SMP.</p><p>Portability Across Memory Architectures. The shared-memory abstraction is also attractive for developing algorithms that span a variety of memory architectures. Since the layout of memory is hidden in the model, the target machine can support the model in a variety of ways beyond that made visible in message-passing or distributed-memory machines. For example, the target machine may choose to map memory locations dynamically to processors as the computation proceeds, as in a cache-only memory architecture (COMA) <ref type="bibr" target="#b67">[68]</ref>. In general, the target machine is free to implement a variety of cache and memory consistency protocols (e.g., <ref type="bibr" target="#b30">[31]</ref>), since the model does not presuppose a particular memory layout. The shared-memory abstraction is more relevant to parallel machines, such as the Cray C90, Cray J90, SGI Power Challenge, and Tera MTA, that have many more memory banks than processors in order to compensate for the slow cycle times of memories. This point is addressed further later in the paper in Section 5.</p><p>Important Platform for Algorithmic Ideas. Finally, it is evident that a simple model with a shared-memory abstraction provides a useful platform for studying fundamental algorithmic issues. Many algorithms for more complex models are adaptations of algorithms first developed for a simple shared-memory model. There are numerous examples, covering a wide range of problem domains, including sorting <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b36">[37]</ref>, connected components <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b41">[42]</ref>, computational geometry <ref type="bibr" target="#b65">[66]</ref>, FFT <ref type="bibr" target="#b21">[22]</ref>, and string matching <ref type="bibr" target="#b23">[24]</ref>. Designing an algorithm directly for the more complex model is typically a more daunting task than first developing the algorithmic insights on a simple shared-memory model and only then adapting them to the more complex model. Note that for any algorithm designed for a high-level bridging model (whether shared-memory, message-passing or distributed-memory), it may be desirable to consider a more complex, lower-level model when making important performance-enhancing refinements. The shared-memory abstraction is desirable when such refinements are not necessary (i.e., whenever the algorithm performance is acceptable) since it is easier to use, and, as discussed above, it is still useful even if such refinements are necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The QSM Model</head><p>In this section we describe the QSM model, and elaborate on some of its features. Definition 3.1. The QSM (Queuing Shared-Memory) model consists of a number of identical processors, each with its own private memory, communicating by reading and writing locations in a shared memory. Processors execute a sequence of synchronized phases, each consisting of an arbitrary interleaving of the following operations:</p><p>1. Shared-memory reads: Each processor i copies the contents of r i shared-memory locations into its private memory. The value returned by a shared-memory read can only be used in a subsequent phase. 2. Shared-memory writes: Each processor i writes to w i shared-memory locations. 3. Local computation: Each processor i performs c i RAM operations involving only its private state and private memory.</p><p>Concurrent reads or writes (but not both) to the same shared-memory location are permitted in a phase. In the case of multiple writers to a location x, an arbitrary write to x succeeds in writing the value present in x at the end of the phase.</p><p>The restrictions that (i) values returned by shared-memory reads cannot be used in the same phase and that (ii) the same shared-memory location cannot be both read and written in the same phase reflect the intended emulation of the QSM model on a MIMD machine. In this emulation, the shared-memory reads and writes at a processor are issued in a pipelined manner, to amortize against the delay (latency) on such machines in accessing the shared memory, and could complete any time during the phase, although they are not guaranteed to complete until the end of the phase. Thus, we do not allow a value read from shared memory to be used during the phase since the value may not be available until the end of the phase. Also if we allow a shared-memory location to be both read and written in the same phase, then the value read could be either the initial value or the updated value since we make no assumption about when a read or write completes within the phase. On the other hand, each of the local compute operations are assumed to take unit time in the intended emulation, and hence the values they compute can be used within the same phase.</p><p>Each shared-memory location can be read or written by any number of processors in a phase, as in a concurrent-read concurrent-write PRAM model; however, in the QSM model, there is a cost for such contention. In particular, the cost for a phase will depend on the maximum contention to a location in the phase, defined as follows.</p><p>Definition 3.2. The maximum contention of a QSM phase is the maximum, over all locations x, of the number of processors reading x or the number of processors writing x. A phase with no reads or writes is defined to have maximum contention one.</p><p>One can view the shared memory of the QSM model as a collection of queues, one per shared-memory location; requests to read or write a location queue up and are serviced one at a time. The maximum contention is the maximum delay encountered in a queue. The cost for a phase depends on the maximum contention, the maximum number of local operations by a processor, and the maximum number of shared-memory reads or writes by a processor. To reflect the limited communication bandwidth on most parallel machines, the QSM model provides a parameter, g ≥ 1, that reflects the gap between the local instruction rate and the communication rate. Definition 3.3. Consider a QSM phase with maximum contention κ. Let m op = max i {c i } for the phase, i.e., the maximum over all processors i of its number of local operations, and let m r w = max{1, max i {r i , w i }} for the phase. Then the time cost for the phase is max m op , g • m r w , κ . <ref type="foot" target="#foot_0">1</ref> The time of a QSM algorithm is the sum of the time costs for its phases. The work of a QSM algorithm is its processor-time product.</p><p>Note that although the model charges g per shared-memory request at a given processor (the g•m r w term in the cost metric), it only charges 1 per shared-memory request at a given location (the κ term in the cost metric). <ref type="foot" target="#foot_1">2</ref> Note also that our model considers contention only at individual memory locations, not at memory modules. Even though both of these features give more power to the QSM than would appear to be warranted by current technology, our emulation results in Section 4 show that we can obtain a work-preserving emulation of the QSM on the BSP with only a modest slowdown. Thus, these features do capture the computational power achievable by current technology. The discussion in Section 4 provides some intuition for this rather surprising result.</p><p>The particular instance of the QSM model in which the gap parameter, g, equals 1 is essentially the queue-read queue-write (QRQW) PRAM model defined by the authors <ref type="bibr" target="#b35">[36]</ref>. Previous work on the QRQW PRAM <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b15">[16]</ref> has been focused primarily on contention issues, unlike this paper, which is primarily concerned with bridging models and bandwidth issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model Comparison</head><p>Table <ref type="table" target="#tab_0">1</ref> compares the QSM model with a number of other models in the literature. The first column of the table gives the name of the model. The second column indicates the synchrony assumption of the model: Lock-step indicates that the processors are fully synchronized at each step, with no cost for the synchronization. Bulk-synchrony indicates that there is asynchronous execution between synchronization barriers. Typically the barriers involve all the processors, although this is not necessarily required. Models that permit more general asynchrony are denoted as asynchronous.</p><p>The third column indicates the type of interprocessor communication assumed by the model. A model is considered to be shared memory only if it meets the standards for a pure shared-memory abstraction outlined in Section 2, i.e., that the memory is viewed as a collection of independent cells that are equally accessible by all processors. If the processors communicate by reading and writing locations in a memory that is partitioned, the model is considered to be a distributed-memory model. For example, the  <ref type="bibr" target="#b59">[60]</ref> Lock-step Distributed memory p LPRAM <ref type="bibr" target="#b2">[3]</ref> Lock-step Shared memory p, Phase LPRAM <ref type="bibr" target="#b31">[32]</ref> Bulk-synchrony Shared memory p, , s XPRAM <ref type="bibr" target="#b69">[70]</ref> Bulk-synchrony Message passing p, g, L Bulk-Synchronous Parallel (BSP) <ref type="bibr" target="#b68">[69]</ref> Bulk-synchrony Message passing p, g, L Postal model <ref type="bibr" target="#b9">[10]</ref> Asynchronous Message passing p, LogP model <ref type="bibr" target="#b21">[22]</ref> Asynchronous Message passing p, g, , o QRQW Asynchronous PRAM <ref type="bibr" target="#b34">[35]</ref> Asynchronous Shared memory p QRQW PRAM <ref type="bibr" target="#b35">[36]</ref> Bulk-synchrony Shared memory p Block Distributed Memory (BDM) <ref type="bibr" target="#b43">[44]</ref> Bulk synchrony Distributed memory p, g, L , B PRAM(m) model <ref type="bibr" target="#b55">[56]</ref> Lock-step Shared memory p, m Interval model <ref type="bibr" target="#b54">[55]</ref> Bulk synchrony Message passing p, I</p><p>Queuing Shared Memory (QSM) Bulk-synchrony Shared memory p, g * This column indicates the parameters of the model, where p is the number of processors, is the communication latency (i.e., the time to deliver a message point-to-point or to access the shared memory), s is the cost for a barrier synchronization among all the processors, L is a single parameter that accounts for the sum of and s, g is the bandwidth gap (i.e., the rate at which processors can perform local operations divided by the rate at which the processors can sustain interprocessor or processor-memory communication), o is the overhead at the processor to send or receive a message, B is the block size (i.e., the number of consecutive cells sent on a write or retrieved on a read), m is the number of shared-memory cells available for both reading and writing, and I is the maximum of , g, and s.</p><p>BDM model <ref type="bibr" target="#b43">[44]</ref> is distributed memory since the contention encountered by a read request depends on the number of other requests to the same memory module. The messagepassing models shown in this table deliver messages point-to-point: this abstraction hides the details of how the message is routed through the interprocessor communication network, and hence is similar to the distributed-memory abstraction.</p><p>The fourth column indicates the parameters in the model. The description of these parameters is given in the table footnote. Some models, such as the LPRAM model, account separately for computation steps and communication steps. This can be viewed as having a separate latency parameter, as indicated in the table.</p><p>Unlike the previous models shown in Table <ref type="table" target="#tab_0">1</ref>, the QSM provides bulk-synchrony, a shared-memory abstraction, and just two parameters. In all, the key features of the QSM that make it an attractive candidate for a bridging model are:</p><p>1. Shared-memory abstraction. The QSM provides the simplicity of a sharedmemory abstraction in which the shared memory is viewed as a collection of independent cells, nonlocal to the processors. The advantages of a shared-memory abstraction were discussed in Section 2. 2. Bulk-synchrony. The QSM supports bulk-synchronous operation, in which processors operate asynchronously between barrier synchronizations. As in models such as the PHASE LPRAM <ref type="bibr" target="#b31">[32]</ref>, the algorithm dictates the points at which barriers occur. This allows a QSM algorithm to synchronize less frequently than algorithms designed for a lock-step model, which makes for a more efficient mapping of the algorithm to MIMD machines. The model does not allow for general asynchronous algorithms. Permitting general asynchrony can lead to algorithms that run faster on MIMD machines. However, any asynchronous model that reasonably reflects real machines is considerably more difficult to use. 3. Few parameters. For simplicity, it is desirable for bridging models to have only a few parameters. As evidenced by <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b46">[47]</ref>, and elsewhere, having additional parameters in a model can make it quite difficult to obtain a concise analysis of an algorithm. On the other hand, it is desirable to have whatever parameters are essential for a desired level of accuracy in modeling machines realizing the bridging model. The QSM has only two parameters: one reflecting the number of processors and one reflecting the limited communication bandwidth. In the intended emulation of the model on MIMD machines, the latency of communication is hidden by having each physical processor emulate a number of QSM processors. Formally, we consider the emulation of higher-level models on lower-level models (such as the BSP), in order to make claims about the cost, or lack thereof, of ignoring certain parameters in the higher-level model. The results in the next section provide evidence that a parameter reflecting limited bandwidth should be in a high-level model, and that other communication parameters are not necessary. For this reason, we believe that g is a better choice for a second parameter than the , s, L, or I parameters found in other models. 4. Queue contention metric. The queue-read queue-write (QRQW) contention rule of the QSM model more accurately reflects the contention properties of parallel machines with simple, noncombining interconnection networks than either the well-studied exclusive-read exclusive-write (EREW) or concurrent-read concurrent-write (CRCW) rules. As argued in <ref type="bibr" target="#b35">[36]</ref>, the EREW rule is too strict, and the CRCW rule ignores the large performance penalty of high contention steps. Indeed, for most existing machines, including the Cray T3E, Cray C90, Cray J90, IBM SP2, Intel Paragon, MasPar MP-2 (global router), Tera MTA, and Thinking Machines CM-5 (data network), the contention properties of the machine are well approximated by the QRQW rule. The QRQW contention metric can lead to faster algorithms, since it does not ignore the aforementioned penalty for high contention steps and yet it allows for low-contention algorithms that are not permitted under the EREW rule. 5. Work-preserving emulation on BSP. The BSP is a distributed-memory, messagepassing model that is gaining acceptance as a bridging model for parallel computation. Thus a work-preserving emulation of the QSM on the BSP is a strong validating point for this shared-memory model. This key feature is discussed in Section 3.2. 6. Work-preserving emulation of BSP. In addition to the work-preserving emulation of QSM on BSP we observe that there is a work-preserving mapping in the reverse direction as well. Many BSP algorithms map onto the QSM in a step-bystep manner with performance corresponding to the case when the periodicity parameter on the BSP is set to 1. While it is possible for BSP algorithms not to have this property, we also present a work-preserving emulation of the BSP on the QSM with only a small slowdown. This emulation holds for all BSP algorithms. This is discussed in more detail in Sections 3.2 and 6.</p><p>The PRAM(m) model shares many of the same goals as the QSM model. As shown in the table, the PRAM(m) provides a shared-memory abstraction and just two parameters: one for the number of processors and one that captures the limited communication bandwidth (g = p/m). However, the PRAM(m) model is suitable only for lower bounds. First, having only m &lt; p shared-memory locations is a large burden on the algorithm designer; no machines provide this restriction. Second, the model assumes that input is in a read-only memory that can be accessed by all processors without any bandwidth limitations; this undercharges the cost of such accesses for existing machines. Third, the model provides unlimited contention to the m shared-memory locations at no extra charge; this too is unrealistic for existing machines. Due to these features, the model does not seem to have an efficient emulation on lower-level models such as the BSP. The model is intended for lower bounds, and indeed lower bounds proved for the PRAM(m) model imply lower bounds for a large number of other models.</p><p>Mapping Parameters to Machines. There have been several papers reporting values for various model parameters on existing parallel machines. For example, Martin et al. <ref type="bibr" target="#b57">[58]</ref> reported values for the g, , and o parameters from the LogP model on three platforms: the Berkeley NOW cluster, the Intel Paragon, and the Meiko CS-2. On the Berkeley NOW cluster, g = 5.8 microseconds (µs), = 5.0 µs, and o = 2.9 µs. On the Intel Paragon, g = 7.6 µs, = 6.5 µs, and o = 1.8 µs. On the Meiko CS-2, g = 13.6 µs, = 7.5 µs, and o = 1.7 µs. Since the local instruction rate at a processor is tens of nanoseconds per instruction or faster, the normalized values for these parameters are in the hundreds to a few thousand. In contrast, Blelloch et al. <ref type="bibr" target="#b16">[17]</ref> considered two shared-memory vector multiprocessors, reporting (normalized) gap parameter values of g = 1.2 for the Cray C90 and g = 1.8 for the Cray J90.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Comparison with BSP</head><p>In this section we compare the QSM and the BSP in terms of their effectiveness as a bridging model for parallel computation. We choose to compare the QSM with the BSP rather than the LogP model since the QSM is a bulk-synchronous model like the BSP (and unlike the LogP) model.</p><p>The BSP (Bulk-Synchronous Parallel) model <ref type="bibr" target="#b68">[69]</ref>, <ref type="bibr" target="#b69">[70]</ref> consists of p processor/memory components communicating by sending point-to-point messages. The interconnection network supporting this communication is characterized by a bandwidth parameter g and a latency parameter L. A BSP computation consists of a sequence of "supersteps" separated by bulk synchronizations. In each superstep the processors can perform local computations and send and receive a set of messages. Messages are sent in a pipelined fashion, and messages sent in one superstep will arrive prior to the start of the next superstep. The time charged for a superstep is calculated as follows. Let w i be the amount of local work performed by processor i in a given superstep. Let s i (r i ) be the number of messages sent (received) by processor i. Let w = max p i=1 w i , and h = max p i=1 (max(s i , r i )). Then the cost, T , of a superstep is defined to be T = max(w, g • h, L). <ref type="foot" target="#foot_2">3</ref> Although the ≥ max(g lg p, L/g) Yes</p><p>The result for QSM is new. The emulations are randomized and the bounds are obtained with high probability in p.</p><p>BSP is a message-passing model, it can also be viewed as a distributed-memory model where each memory component serves as a memory bank.</p><p>To compare the cost metrics of the BSP and the QSM, we consider the distributedmemory view of the BSP and a superstep comprised of local work, read requests, and write requests. We can equate the two g parameters, and w i with c i (and hence w with m op ). Let h s = max p i=1 s i , the maximum number of read/write requests by any one processor, and let h r = max p i=1 r i , the maximum number of read/write requests to any one memory bank. The BSP charges the maximum of w, g • h s , g • h r , and L. The QSM, on the other hand, charges the maximum of w, g • h s , and κ, where κ ∈ [1..h r ] is the maximum number of read/write requests to any one memory location and is not multiplied by g.</p><p>One important measure of a bridging model is its ability to be emulated by important lower-level models. Table <ref type="table" target="#tab_1">2</ref> presents some known emulation results of higher-level models on the BSP. The parallel slackness in an emulation is the number of processors in the higher-level model per processor in the BSP model. An emulation is work-preserving if both models perform the same amount of work, to within constant factors. The first three rows show emulation results on the BSP of the EREW PRAM <ref type="bibr" target="#b68">[69]</ref>, the QRQW PRAM <ref type="bibr" target="#b35">[36]</ref> and the CRCW PRAM <ref type="bibr" target="#b68">[69]</ref>; note that none of these three models have a work-preserving emulation on the BSP if g is not a constant. In the case of the CRCW PRAM, even for a BSP with gap parameter that is a constant, a work-preserving emulation on the BSP is known only with a parallel slackness that is very large, i.e., polynomial in p. In contrast, the QSM does have a work-preserving emulation on a BSP with the same gap parameter, for any g, using only modest slackness and small constants. This result will be shown in the next section.</p><p>The emulation result implies that any algorithm designed on the QSM can be mapped onto the BSP in a work-preserving manner with only a modest slowdown. Since the QSM has fewer parameters than the BSP, and does not deal with memory partitioning details, for most problems it should be easier to design algorithms on the QSM than on the BSP. Moreover, the emulation result implies that any machine that can realize the BSP model can also realize the QSM model, given the additional system software needed for the (simple) emulation algorithm.</p><p>Many algorithms designed for the BSP have as their goal to minimize the number of supersteps (e.g., <ref type="bibr" target="#b36">[37]</ref>). In contrast, the QSM does not account for the number of supersteps (e.g., there is no L parameter in the QSM model). Ignoring the number of supersteps simplifies the model, and it can be somewhat formally justified by the emulation result, which shows that any two QSM algorithms with the same QSM time bound will have the same BSP time bound when emulated on the BSP, regardless of the number of supersteps in the respective algorithms.</p><p>One can also consider the mapping of BSP algorithms onto the QSM. Many of the BSP algorithms reported in the literature have a simple version on the QSM corresponding to the case when the latency L = 1. As shown in Section 6 it is possible, in principle, to have BSP algorithms that do not map back to the QSM in a work-and time-preserving manner. Such algorithms would exploit the fact that a BSP processor (i) could receive a piece of information that it did not specifically request, or (ii) could access, as a unit-time local computation, a value (not requested by it) that was written into its local memory bank by another processor in an earlier step.</p><p>These features are appropriate in contexts where a processor can send a message directly to a processor at any time, or can write remotely into a processor's local portion of the shared memory. On the QSM a processor would need to initiate a read for any piece of information that it receives; further, that access will be charged a cost of g at the time the processor reads it in addition to a cost of g being applied at the time the value was written into the shared-memory location.</p><p>While the features listed above could indicate that the BSP is in some ways more powerful than the QSM, it may not be desirable for a general-purpose bridging model to incorporate these features. In general, there will be features such as these arising due to contrasts between message passing and shared memory, between coherent and noncoherent caches, between update and invalidation-based coherence protocols, etc. Any choice of these features may not be representative of a wide range of parallel machines. Moreover, as discussed in Section 2, current designers of parallel processors often hide the memory partitioning information from the processors since this can be changed dynamically at runtime. As a result an algorithm that is designed, say, using this additional power of the BSP over the QSM may not be that widely applicable.</p><p>In Section 6 we show that a BSP that does not exploit features (i) and (ii) can be emulated on a QSM using a simple, deterministic, time-and work-preserving algorithm. We also show that any n-component BSP, even one that exploits these features, has a work-preserving emulation on a QSM with the same gap parameter, with a modest slowdown of O(lg n/(1 + L/g)), with high probability in n; this emulation uses a fairly involved algorithm.</p><p>Thus, overall, a case can be made that the QSM is effective in modeling the essential features of the BSP while remaining at a higher level of abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Emulations of QSM on BSP Models</head><p>The (d, x)-BSP <ref type="bibr" target="#b15">[16]</ref> is a model similar to the (distributed-memory view of the) BSP, but it provides a more detailed modeling of memory bank contention and delay. In <ref type="bibr" target="#b15">[16]</ref> it is argued that, for shared-memory machines with a high-bandwidth communication network and more memory banks than processors, the (d, x)-BSP is a more accurate model than the BSP. Such machines include Cray C90, Cray J90, and Tera MTA (experimental validation of this accuracy claim is provided for Cray C90 and Cray J90). The (d, x)-BSP is parametrized by five parameters, p, g, L , d and x, where p, g, and L are as in the original BSP model, the delay d is the "gap" parameter at the memory banks, and the expansion x is the ratio of memory banks to processors (i.e., there are x• p memory banks). Consider a superstep where w is the maximum local work performed by a processor, h s is the maximum number of read/write requests by a processor, and h r is the maximum number of read/write requests to a memory bank. Then the time, T , charged by the (d, x)-BSP for this superstep is T = max(w, g • h s , d • h r , L). The original BSP can be viewed as a (d, x)-BSP with d = g and x = 1.</p><p>In this section we present two emulations of the QSM on the (d, x)-BSP. The first emulation is for a so-called balanced (d, x)-BSP, in which x ≥ d/g, and is work optimal. Since the BSP is a balanced (d, x)-BSP, this optimal emulation applies also for the BSP. The second emulation is for an unbalanced (d, x)-BSP, in which x &lt; d/g. This emulation suffers from work inefficiency which is proportional to the "imbalance-factor," d/(gx). We show by a lower bound argument that this overhead is unavoidable.</p><p>The two emulations are in fact identical, and differ only in the slackness parameter. We first present the algorithm, followed by the different analysis for the two cases mentioned above, and concluding with the lower bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Emulation Algorithm</head><p>A work-preserving emulation of a model A on a model B provides a formal proof that model A can be realized on model B with only a constant factor overhead in work. If model B is considered to be reflective of an interesting class of parallel machines, then such an emulation supports the use of A as a bridging model, as long as the emulation can be considered "practical." For the QSM on the (d, x)-BSP (and hence on the BSP), we present a very simple emulation algorithm and then discuss its practicality in some detail.</p><p>The emulation algorithm of a v-processor QSM on a p-processor (d, x)-BSP, v ≥ p, is quite simple, and it is similar to emulations that were previously proposed for the PRAM. Unlike previous emulations, our analysis needs to handle the gap parameter in the emulated machine.</p><p>• The shared address space of the QSM is randomly hashed into the x p memory banks of the (d, x)-BSP (or to the p memory modules of the BSP). • In each phase, each processor of the (d, x)-BSP emulates v/ p processors of the QSM.</p><p>In the work-preserving emulation, each phase i of time t i on the QSM is emulated on the (d, x)-BSP (or simply the BSP) in time O((v/ p) • t i ), regardless of the distribution of shared memory reads and writes. The needed parallel slackness, v/ p, is modest, and does not depend on the maximum contention in a phase (which may be much larger than v/ p).</p><p>The mapping of the QSM shared memory among the machine's memory banks assumes the machine supports a single address space. Many recent machines (e.g., Cray T3E) provide hardware support for a single address space; for other machines (e.g., IBM SP-2), it can be emulated in software with some overhead.</p><p>Note that if a computer system already hashes the data using a pseudorandom hash function, then the emulation is nothing but the straightforward implementation of an algorithm whose parallelism is larger than the number of processors. Several parallel database systems already hash their data using pseudorandom hash functions. The Tera MTA provides hardware support for hash functions to be used for pseudorandom mapping of memory locations to memory banks; the Fujitsu µ-VP on the Meiko node already has optional hardware hashing. For other machines, computing a pseudorandom hash in software is feasible. For example, it is shown in <ref type="bibr" target="#b15">[16]</ref> that the overhead to compute a certain provably good (i.e., 2-universal) pseudorandom hash function on the Cray C90 averages 1.8 clock cycles. Also as noted in <ref type="bibr" target="#b15">[16]</ref>, for some algorithms it is possible to get the same effect without memory hashing, by randomly permuting the input and some of the intermediate results. In others, the nature of the algorithm results in random mapping without any additional steps.</p><p>It is well known that hashing destroys spatial locality, but not temporal locality. Spatial locality enables long messages to be sent between components, thereby minimizing overheads on many machines. Some models, such as BDM <ref type="bibr" target="#b43">[44]</ref>, LogGP <ref type="bibr" target="#b4">[5]</ref>, and BSP * <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b10">[11]</ref>, account for advantages in long messages; most others, e.g., QSM, BSP, (d, x)-BSP, and LogP, do not. Thus the QSM shares with the BSP, (d, x)-BSP, and LogP models a disregard for spatial locality. Spatial locality can also arise in initial data placement.</p><p>Here the input can be assumed to be distributed among the private memories of the QSM processors as among the local memories of the BSP, (d, x)-BSP, or LogP processors.</p><p>The emulation of v/ p virtual processors by each physical processor can be done by a variety of techniques. The primary technique is multithreading, in which each virtual processor is its own process, and the physical processor context switches between these processes. The Tera MTA provides hardware support for this multithreading, minimizing the context switching costs. Alternatively, such multithreading can be performed in software. Note that in the QSM, as in other bulk-synchronous models, each virtual processor issues a series of memory requests in a phase. Instead of context switching at each memory request, the multithreading can be performed by executing all the code for the first virtual processor in this phase, then switching to the second virtual processor, and so forth, so that only v/ p context switches are needed for the entire phase (this description assumes that storing values returning in response to shared-memory read requests does not require a context switch).</p><p>In order to minimize the overheads, it is very important to minimize the amount of parallel slackness required. In the worst case, multithreading v/ p processes per machine processor results in v/ p times the storage demand at each level of the processor's memory hierarchy, possibly resulting in various thrashing effects. The emulation of the QSM on the BSP requires only max(g lg p, L/g) slackness; on the (d, x)-BSP, as little as max(d, L/g) slackness may be required. Note that the L/g term matches the limit on multithreading imposed by the LogP model <ref type="bibr" target="#b21">[22]</ref>.</p><p>Thus, overall, the constants hidden by the big-O notation in the emulation result are small, and hence the emulation can arguably be considered practical. (In fact, this emulation is a fundamental component in the design of the Tera MTA.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Work-Preserving QSM Emulation on (d, x)-BSP</head><p>The following theorem presents an emulation of the QSM on a (d, x)-BSP for the case when x ≥ d/g, where g is the gap parameter for both the QSM and the (d, x)-BSP. The emulation is work-preserving for any g (i.e., the work performed on the (d, x)-BSP is within constant factors of the work performed on the QSM). Theorem 4.1 (Work-Preserving QSM Emulation). Consider a p-processor (d, x)-BSP with gap parameter g and periodicity factor L, such that d g ≤ x ≤ p c, for some constant c &gt; 0, where</p><formula xml:id="formula_0">d g = d/g ≥ 1. Let δ =    d lg p i f d g ≤ x ≤ 2d g , d lg p/lg(x/d g ) if 2d g ≤ x ≤ pd g , d i f x ≥ pd g .</formula><p>Then, for all p ≥ max(δ, L/g) • p, each step of an algorithm for the p -processor QSM with gap parameter g with time cost t can be emulated on the p-processor</p><formula xml:id="formula_1">(d, x)-BSP in O(( p / p) • t) time w.h.p.</formula><p>This result is not implied by previous simulation results for the QRQW PRAM <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b15">[16]</ref>, since these previous results considered standard PRAM models with no gap parameter and BSP or (d, x)-BSP models with a small constant gap parameter (that was hence ignored as part of the big-O notation). The question of how the work-efficiency and/or slowdown of the emulation depended upon the gap parameters was not studied. Since we are considering the same gap parameter, g, for the QSM as for the BSP, one might conjecture that considering the gap parameter does not substantially alter the bounds of the simulations without the gap parameter. However, note that the QSM model charges κ for contention κ, regardless of the gap or delay parameters, and indeed a QSM step with time t can have t/g memory requests per processor and maximum contention t. In contrast, in such cases the BSP charges at least g • t and the (d, x)-BSP charges at least d • t. Viewing the mapping of memory locations to memory banks as tossing weighted balls into bins (where the weight of a ball corresponds to the contention of the location), this implies a different mix of balls than considered in previous emulations.</p><p>Before we present the proof of this theorem, we note that in the original BSP, d g = x = 1, so from the above theorem we obtain the following corollary:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 4.2 (Work-Preserving QSM Emulation). A p -processor QSM with gap parameter g can be emulated on a p-processor BSP with gap parameter g and periodicity parameter L in a work-preserving manner w.h.p. provided p ≥ max(g lg p, L/g) • p.</head><p>Proof of Theorem 4.1. We now prove the theorem. The proof is similar to that in <ref type="bibr" target="#b15">[16]</ref>, extended and adjusted to account properly for the gap parameter in the QSM and to improve upon the results for large values of x, even for the previously studied case of g = 1.</p><p>The shared memory of the QSM is randomly hashed onto the B = x • p memory banks of the (d, x)-BSP. In the emulation algorithm, each (d, x)-BSP processor executes the operations of p / p QSM processors.</p><p>We first assume that x ≥ 2d g . Thus,</p><formula xml:id="formula_2">δ ≥ d lg p lg(x/d g ) . (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>Consider the ith step of the QSM algorithm, with time cost t i . Let c &gt; 0 be some arbitrary constant, and let α = max {c + c + 1, e}. We will show that this step can be emulated on the (d, x)-BSP in time at most α( p / p)t i with probability at least 1p -c . Note that by the QSM cost metric, t i ≥ g, and the maximum number of local operations at a processor in this step is t i . The local computation of the QSM processors can be performed on the (d, x)-BSP in time ( p / p)t i , since each (d, x)-BSP processor emulates p / p QSM processors.</p><p>By the definition of the QSM cost metric, we have that κ, the maximum number of requests to the same location, is at most t i , and h s , the maximum number of requests by any one processor, is at most t i /g. For the sake of simplicity in the analysis, we add dummy memory requests to each processor as needed so that it sends exactly t i /g memory requests this step. The dummy requests for a processor are to dummy memory locations, with processor sending all its dummy requests to dummy location . In this way, the maximum number of requests to the same location, κ, remains at most t i , and the total number of requests is Z = p t i /g.</p><p>Let i 1 , i 2 , . . . , i m be the different memory locations accessed in this step (including dummy locations), and let κ j be the number of accesses to location i j , 1 ≤ j ≤ m. Note that m j=1 κ j = Z . Consider a memory bank β. For j = 1, . . . , m, let x j be an indicator binary random variable which is 1 if memory location i j is mapped onto the memory bank β, and is 0 otherwise. Thus, Prob x j = 1 = 1/B. Let a j = κ j /t i ; a j is the normalized contention to location j. Since κ ≤ t i , we have that a j ∈ (0, 1]. Let β = m j=1 a j x j ; β , the normalized request load to bank β, is the weighted sum of Bernoulli trials. The expected value of β is</p><formula xml:id="formula_4">E β = m j=1 a j B = 1 x p m j=1 κ j t i = 1 x p • Z t i = p t i x p t i g = p x pg .</formula><p>Let h β r be the total number of requests to locations mapped to bank β. To show that it is highly unlikely that h β r greatly exceeds this expected value, we use the following theorem by Raghavan and Spencer, which provides a tail inequality for the weighted sum of Bernoulli trials: Theorem 4.3 <ref type="bibr" target="#b62">[63]</ref>. Let a 1 , . . . , a m be reals in (0, 1]. Let x 1 , . . . , x m be independent Bernoulli trials with E x j = ρ j . Let β = m j=1 a j x j . If E β &gt; 0, then, for any ν &gt; 0,</p><formula xml:id="formula_5">Prob β &gt; (1 + ν)E β &lt; e ν (1 + ν) (1+ν) E( β ) . (<label>2</label></formula><formula xml:id="formula_6">)</formula><p>We apply Theorem 4.3 with ρ j = 1/B, and set</p><formula xml:id="formula_7">ν = α x d g -1,</formula><p>implying</p><formula xml:id="formula_8">(1 + ν)E β = α x d g • p x pg = αp dp .<label>(3)</label></formula><p>Therefore,</p><formula xml:id="formula_9">Prob β &gt; αp dp [(2),(3)] &lt; e (1 + ν) (1+ν)E( β ) [(3)] = αx ed g -αp /dp [α ≥ e] ≤ x d g -αp /dp [x &gt; d g ] ≤ x d g (-α/d) max(δ,L/g) [x &gt; d g ] ≤ x d g (-α/d)δ [(1)] ≤ x d g -α(lg p/lg(x/d g )) = p -α ≤ p -(c+c+1) = p -(c+1) p c [x ≤ p c ] ≤ p -(c+1)</formula><p>x .</p><p>Note that</p><formula xml:id="formula_10">h β r = m j=1 x j k j = β • t i .</formula><p>Therefore,</p><formula xml:id="formula_11">Prob h β r &gt; α p t i d p &lt; p -(c+1) x . Let h r = max β h β r . Then Prob h r &gt; α p t i d p ≤ B • Prob h β r &gt; α p t i d p &lt; B • p -(c+1) x = p -c .</formula><p>The time of the (d, x)-BSP step to emulate QSM step i is T i = max(( p / p)t i , g( p / p)(t i /g), d • h r , L). Since t i ≥ g, we have that ( p / p)t i ≥ ( p / p)g ≥ L and hence it follows from the above that</p><formula xml:id="formula_12">Prob T i ≤ α p p t i ≥ 1 -p -c .</formula><p>We next consider the case where d g ≤ x ≤ 2d g , and therefore δ = d lg p. In this case we take α = max{c + c+ 1, 2e}, and the proof proceeds as above except that we make use of the fact that</p><formula xml:id="formula_13">αx ed g -αp /dp ≤ 2 -αp /dp ≤ 2 -(α/d) max(d lg p,L/g) ≤ 2 -α lg p = p -α .</formula><p>This completes the proof of Theorem 4.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Emulating QSM on Unbalanced (d, x)-BSP</head><p>We next consider the case where the bandwidth at the memory banks is less than the bandwidth at the processors and network, i.e., x &lt; d g . We present an emulation whose work bound is within a constant factor of the best possible. Consider the ith step of the QSM algorithm, with time cost t i . Let c &gt; 0 be some arbitrary constant, and let α = max {c + c + 1, 2e}. We will show that this step can be emulated on the (d, x)-BSP in time at most max{( p / p)t i , α(d g /x)( p / p)t i } with probability at least 1p -c .</p><p>The proof proceeds exactly as in the proof of Theorem 4.1: we add dummy requests as needed, define indicator binary random variables x j for each memory bank j, define β , and show that E β = p /(x pg). We apply the Raghavan and Spencer theorem (Theorem 4.3), but with ν = α -1. This yields</p><formula xml:id="formula_14">Prob β &gt; αp x p &lt; α e -αp /x pg [α ≥ 2e] ≤ 2 -(α/xg) max(xg lg p,d,L/g) ≤ p -α ≤ p -(c+c+1) [x &lt; p c ] &lt; p -(c+1)</formula><p>x . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It follows as in the previous proof that</head><formula xml:id="formula_15">Prob h r &gt; α p t i x pg &lt; p -c ,</formula><formula xml:id="formula_16">Prob T i ≤ max p p • t i , α • d x p pg • t i ≥ 1 -p -c .</formula><p>The theorem follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">A Lower Bound</head><p>The following lower bound shows that the work bound in Theorem 4.4 is tight, as well as showing the importance of having a gap parameter on the QSM. In particular, it implies that a PRAM has an inherent inefficiency overhead of g, when emulated on a BSP or (d, x)-BSP with a gap parameter g. Likewise, it implies that g is the minimum gap parameter that should be assigned to the QSM  Proof. Consider a step in which each of the p QSM processors perform t/g memory requests, such that all p t/g requests are to distinct locations in the shared memory. Since there are m = p t/g locations distributed among x p memory banks, then regardless of the mapping of locations to banks, there exists at least one bank j which is mapped to by at least m/x p locations. Also, each (d, x)-BSP processor sends p / p • (t/g ) shared-memory requests. Therefore, the time on the (d, x)-BSP is at least T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Improved Accuracy Through the QSM Abstraction</head><p>The shared-memory abstraction of the QSM hides the details of the partitioning of memory into memory modules/components on existing machines. This partitioning is explicit in message-passing or distributed-memory models such as the BSP or LogP. Thus the QSM provides a higher-level of abstraction, while the BSP and LogP seemingly provide more accurate modeling of memory module contention.</p><p>In this section we draw attention to machines for which the BSP and LogP models fail to model memory module contention accurately, whereas the QSM can lead to a more accurate accounting. For the former, we refer to results in Blelloch et al. <ref type="bibr" target="#b15">[16]</ref>, whereas for the latter we leverage Theorem 4.1 and experimental results in <ref type="bibr" target="#b15">[16]</ref>. We also present a simple illustrative example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">The Problem of Memory Layout Mismatch</head><p>Standard message-passing or distributed-memory models such as the BSP and LogP have the property that the number of memory components is equal to the number of processors. On the other hand, several computer manufacturers, motivated by the increasing divergence between processor speeds and memory speeds, have designed parallel machines with many more memory banks than processors. For example, the 16-processor Cray C90 has 1024 memory banks, the 16-processor Cray J90 has 512 memory banks, the 18-processor SGI Power Challenge has 64 memory banks, and the 256-processor Tera MTA will have 32K memory banks. For these machines, the (d, x)-BSP <ref type="bibr" target="#b15">[16]</ref> (described in Section 4) is a more accurate model than the BSP or LogP since it explicitly accounts for both (i) the bank delay, d, which is the bandwidth gap parameter at a memory bank, and (ii) the bank expansion, x, which is the ratio of memory banks to processors.</p><p>Blelloch et al. showed experimentally that the (d, x)-BSP models the Cray C90 and Cray J90 quite accurately, even though the model ignores many details about these machines. They also showed that accounting for the memory-bank delay is critical in predicting running times of algorithms with high memory contention. Therefore, in some situations the BSP and the LogP provide a poor prediction of an algorithm's performance, while the (d, x)-BSP provides a good one. An example is shown in Figure <ref type="figure" target="#fig_1">1</ref> for the Cray J90. In this figure, predicted and measured performance are shown on a set of memory access patterns extracted from a trace of Greiner's algorithm for finding the connected components of a graph <ref type="bibr" target="#b37">[38]</ref>. Measured times on an eight-processor Cray J90 for several patterns are shown with squares. Predicted times are given for the (d, x)-BSP, BSP, and LogP. The contention is given on a logarithmic scale indicating the ratio between the maximum contention, k, and the total number of requests, p • S ( p is the number of processors and S is the number of requests sent by each processor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Suitability of QSM to Cray-Like Machines</head><p>The QSM is a more high-level model than the BSP or LogP, which in turn are more high-level models than the (d, x)-BSP. Nevertheless, we argue that the QSM is a better model for machines such as the Cray C90 and Cray J90 than the BSP or the LogP, since its shared-memory abstraction does not assume a particular memory layout. In particular, Theorem 4.1 shows that any algorithm designed for the QSM will map in a work-preserving manner onto the (d, x)-BSP given a reasonable amount of parallel slackness, and thus onto these machines. This is because the QSM cost metric accounts for contention to locations, and hence can be translated (via hashing) to a memory layout of any granularity. Thus the abstraction of memory components to shared memory, as assumed in the QSM, makes it more robust to changes in the number of memory components.</p><p>In contrast, message-passing or distributed-memory models such as the BSP and LogP account only for the aggregated contention per processor, and hence reveal insufficient information to enable a work-preserving emulation unless the slackness is ≥ x ≥ d/g. (When the slackness is ≥ x ≥ d/g, then the p-processor distributed-memory model is emulated on a (d, x)-BSP with at most p memory banks.)</p><p>As a simple example illustrating the above discussion, consider the following two memory access patterns, A and B, occurring in an algorithm designed for the BSP.  Suppose k processors send one message each to a BSP component C, for some arbitrary k. In access pattern A, all requests are directed to the same memory location. In access pattern B, each request is directed to a different memory location within C. The cost on the BSP of each access pattern is the same, namely, g • k, as in each case the requests are aggregated. Now suppose that the algorithm is run on a machine well modeled by the (d, x)-BSP, with x ≥ k. On the (d, x)-BSP, requests in A are always mapped to the same memory bank, but the requests in B could be mapped to different banks, depending on the mapping of (d, x)-BSP banks to BSP components. This results in a cost on the (d, x)-BSP of max(g, d • k) for A but a cost of anywhere from max(g, d • k) to max(g, d) for B, a potentially large distinction.</p><p>An algorithm designed for the QSM would distinguish between k requests to the same location versus k requests to different locations, charging max(g, k) for A and g for B. Moreover, Theorem 4.1 implies that using a random mapping of QSM memory locations to the (d, x)-BSP memory banks guarantees that, with high probability, there are no surprises in terms of memory-bank contention when the algorithm is run on a machine well modeled by the (d, x)-BSP. In any such mapping, the requests in A will be mapped to the same (d, x)-BSP memory bank, and hence are rightfully aggregated, whereas the requests in B will likely be mapped to different memory banks, and hence are rightfully not aggregated. Thus while the metric of the BSP may not be consistent with that of the (d, x)-BSP, the QSM maintains close consistency with the (d, x)-BSP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Algorithmic Issues</head><p>As a shared-memory model, the QSM offers a simple high-level medium for the design of parallel algorithms that can take into consideration effective use of limited bandwidth. In this section we present some algorithmic results and techniques for the QSM as well as general strategies to map algorithms developed on some other models onto the QSM.</p><p>In general the QSM is to be used for direct algorithm design that makes effective use of limited bandwidth. However, since we would like to leverage on the extensive literature on PRAM algorithms, in Section 6.1 we discuss the mapping of QRQW PRAM and EREW PRAM algorithms onto the QSM. In Section 6.2 we present some lower bounds, and in Section 6.3 we present some direct QSM algorithms that are faster than the ones obtained by the generic PRAM mapping.</p><p>It is also important to consider the mapping of BSP algorithms onto the QSM, for two reasons: First, a good mapping result of this type will allow us to leverage on the results and techniques that were developed for the BSP model. Second, it will demonstrate that the expressive power of QSM is no less than that of the BSP. We study this issue in Sections 6.4 and 6.5. In view of a simple lower bound of (n • g) that we prove in Section 6.2 on the time needed to read n items from global memory into the QSM processors, for these algorithms we assume that the input is distributed among the local memories of the processors in a suitable way. In Section 6.4 we show that any BSP algorithm that is "well behaved" (as defined in that section) can be adapted in a simple way to the QSM with no loss in performance. In that section we also argue that BSP algorithms that are not "well behaved" use certain features of the BSP that are not quite representative of a large class of parallel machines. For completeness on the issue of expressive power, in Section 6.5 we show a general randomized work-preserving emulation of BSP on QSM. Unlike the simple adaptation for "well-behaved" algorithms, this emulation consists of a fairly involved algorithm and results in logarithmic slowdown. Overall these results demonstrate any algorithm designed for BSP could also be designed on the QSM, without substantial loss of efficiency.</p><p>Finally, in Section 6.6 we discuss the importance of the queuing metric for memory accesses in the QSM model, and note that it is central to its effectiveness as a sharedmemory bridging model.</p><p>First, we consider the property of self-simulation for the QSM, i.e., the problem of simulating a p-processor QSM on a p -processor QSM, where p &lt; p. The availability of an efficient self-simulation is an important feature for parallel models of computation, since it implies that an algorithm written for a large number of processors is readily portable into a smaller number of processors, without loss of efficiency. Observation 6.1. Given a QSM algorithm that runs in time t using p processors, the same algorithm can be made to run on a p -processor QSM, where p &lt; p, in time O(t • p/ p ), i.e., while performing the same amount of work.</p><p>The efficient self-simulation is achieved by the standard strategy of mapping the p processors in the original algorithm uniformly among the p available processors. In the following we state the performance of a QSM algorithm in terms of the fastest time t (n) achievable within a given work bound w(n). When we make such a statement we imply, due to Observation 6.1, that for any p we have an explicit QSM algorithm that runs in O(t (n) + w(n)/ p) time using p processors.</p><p>In the following we assume that the value of the gap parameter g is less than n, the size of the input; in practice we expect g to be much smaller than n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Mapping PRAM Algorithms onto the QSM</head><p>A naive emulation of a QRQW PRAM algorithm (or an EREW PRAM algorithm, which is a special case) on a QSM with the same number of processors results in an algorithm that is slower by a factor of g. This is stated in the following observation. Observation 6.2. Consider a QSM with gap parameter g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>A QRQW PRAM algorithm that runs in time t with p processors is a QSM algorithm that runs in time at most t • g with p processors. 2. A QRQW PRAM algorithm in the work-time framework that runs in time t while performing work w immediately implies a QSM algorithm that runs in time at most t • g with w/t processors.</p><p>Thus the linear-work QRQW PRAM algorithms given in <ref type="bibr" target="#b35">[36]</ref> and <ref type="bibr" target="#b33">[34]</ref> for leader election, linear compaction, multiple compaction, load balancing, and hashing, as well as the extensive collection of linear-work logarithmic-time EREW PRAM algorithms reported in the literature, all translate into QSM algorithms with work O(n • g) on inputs of length n with a slowdown by a factor of at most g. We show in Section 6.2 that this increase in work by a factor of g on the QSM may be unavoidable if the input items are not a priori distributed across the QSM processors.</p><p>There are two other avenues through which we hope to obtain useful results for the QSM over those obtained through the mapping of QRQW PRAM algorithms. First, we can consider tailoring QSM algorithms to its cost metric for the gap parameter, thereby obtaining an improved running time for the algorithm. Second, we can relax the requirement that the input be placed in global memory, and allow the input to be distributed across the local memories of the processors in a suitable way. This would conform to the initial state for BSP algorithms, and in fact most BSP algorithms map back to the QSM in a natural way in this case.</p><p>We address each of these in turn in Sections 6.3 and 6.4, respectively. However, first, in the next section, we mention some lower bounds for the QSM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Lower Bounds</head><p>If n distinct items need to be read from or written into shared memory on a p-processor QSM, then the work performed by the QSM is (n • g) regardless of the number of processors used. To see this we note that the result is immediate if p ≥ n since the QSM has to execute at least one step. If p &lt; n, then some processor needs to read or write n/ p distinct items, and hence that processor spends time ((n/ p) • g). Since p processors are used, the work, which is defined as the processor-time product, is (ng). A similar observation holds for the case when n distinct memory locations are accessed. We state this in the following. Observation 6.3. Consider a QSM with gap parameter g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Any algorithm in which n distinct items need to be read from or written into</head><p>global memory must perform work (n • g).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Any algorithm that needs to perform a read or write on n distinct global memory locations must perform work (n • g).</head><p>By Observations 6.2 and 6.3, the linear-work QRQW PRAM algorithms for problems in which the input of length n resides in global memory translate into algorithms with asymptotically optimal work on the QSM that run with a slowdown of g with respect to the corresponding QRQW PRAM algorithm.</p><p>The following lower bounds for the QSM are given in <ref type="bibr" target="#b0">[1]</ref>. The CRCW PRAM lower bound result of Beame and Håstad <ref type="bibr" target="#b12">[13]</ref> gives a lower bound for the n-element parity, summation, list ranking, and sorting problems of (g • lg n/lg lg n) time on the QSM for either deterministic or randomized algorithms when the number of processors is polynomial in n, the size of the input. Also given in that paper is a simple lower bound with a matching upper bound of (ng) for the one-to-all problem in which one processor has n distinct values in its local memory of which the ith value needs to be read by processor i,</p><formula xml:id="formula_17">1 ≤ i ≤ n.</formula><p>A lower bound of (g lg n/lg g) for broadcasting to n processors is given in <ref type="bibr" target="#b0">[1]</ref>; in contrast to an earlier lower bound for this problem on the BSP given in <ref type="bibr" target="#b44">[45]</ref> this lower bound holds even if processors can acquire knowledge through nonreceipt of messages (i.e., by reading memory locations that were not updated by a recent write operation). We note that the same lower bound on time holds for the problem of broadcasting to n memory locations since any algorithm that broadcasts to n memory locations can broadcast to n processors in additional g units of time. Further, by Observation 6.3 (ng) work necessary since writes to n distinct global memory locations are required. 6.3. Some Faster Algorithms for the QSM By pipelining reads and writes to memory from different processors to amortize against the delay due to the gap parameter g at processors, it is possible to obtain an algorithm for the QSM that runs faster than g times the running time for the fastest QRQW PRAM algorithm. As an example of an algorithm that is optimized for the QSM, consider the leader election problem in which the input is a Boolean n-array, and the output is the first location in the array with value 1, if such a location exists, and is 0 otherwise. The fastest QRQW PRAM algorithm for this problem is just the "binary tree" EREW PRAM method that halves the number of candidates in each of lg n rounds with O(n) work (there is a faster algorithm on the CRQW PRAM, but that algorithm is not known to map onto the QSM with a slowdown of only g). This QRQW PRAM algorithm will map on to the QSM as a O(g lg n) time algorithm with O(gn) work. However, we can optimize further for the QSM by replacing the normal "binary tree" method by a "g-ary tree." This takes advantage of the fact that requests at the memory are processed every time step, while at the processors a request can be sent only every g steps. The time taken by this algorithm to solve the leader election problem on the QSM is O(g lg n/lg g) while still performing O(gn) work. If the input is distributed evenly among n/(g lg n/lg g) processors, then the time is O(g lg n/lg g) and the work is O(n).</p><p>A similar strategy applies to the broadcasting problem in which the value at one location in memory needs to be transmitted to n processors. Again, the QRQW PRAM algorithm of choice for this problem is a "binary tree" broadcasting method that takes O(lg n) time with O(n lg n) work. This algorithm will map onto the QSM as a O(g lg n) time algorithm with O(gn lg n) work. By optimizing along the lines of the algorithm for leader election, we can derive an algorithm to broadcast to n processors on the QSM that runs in O(g lg n/lg g) while performing O((gn lg n)/lg g) work. By the lower bound cited in Section 6.2, this result is optimal.</p><p>We can solve the related problem of broadcasting to n memory locations in the above time bound of O(g lg n/lg g) but with O(ng) work. For this, we use p = n lg g/lg n processors and broadcast to the p processors in time O(g lg n/lg g). We then spend an additional O(g lg n/lg g) time to have each processor write into lg n/lg g locations. As noted in Section 6.2 we have a matching lower bound on both the running time and the work.</p><p>We now consider the problem of sorting on the QSM. The problem of designing highly parallel algorithms for sorting n keys from a totally ordered set is a well-studied one. On the EREW PRAM, there are two known O(lg n) time, O(n lg n) work algorithms for general sorting <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19]</ref>; these deterministic algorithms match the asymptotic lower bounds for general sorting on the EREW and CREW PRAM models. Both of these algorithms map onto the QSM to run in O(g lg n) time and O(gn lg n) work using Observation 6.2. Unfortunately, these two algorithms are not as simple and practical as one would like.</p><p>Goodrich <ref type="bibr" target="#b36">[37]</ref> gives an algorithm for the BSP based on <ref type="bibr" target="#b18">[19]</ref> that performs work O((L + gn) lg n/lg(n/ p)+n lg n) with p processors. Since this algorithm is an adaptation of <ref type="bibr" target="#b18">[19]</ref> it is again a fairly complicated algorithm.</p><p>Among sorting algorithms that are fairly simple, the fastest O(n lg n) work rithm on the EREW PRAM is an O(lg 2 n) time randomized quicksort algorithm (see, e.g., <ref type="bibr" target="#b42">[43]</ref>), and on the QRQW PRAM, a randomized √ n-sample sort algorithm that runs in O(lg 2 n/lg lg n) time, O(n lg n) work, and O(n) space <ref type="bibr" target="#b33">[34]</ref>.</p><p>On the QSM, the randomized sample sort algorithm can be mapped onto the QSM to perform O(n lg n) work provided the computation is very coarse-grained, i.e., the number of processors p is polynomially small in n and g = o(lg n); this QSM algorithm is essentially the same as the BSP algorithm based on sample sort <ref type="bibr" target="#b29">[30]</ref>. If we look for a highly parallel sorting algorithm that is fairly simple, an adaptation of the QRQW PRAM sample sort algorithm appears to be the fastest. A straightforward analysis of this algorithm on the QSM using Observation 6.2 results in an algorithm that runs in O(g • lg 2 n/lg lg n) time while performing O(g • n lg n) work. However, an analysis of the algorithm directly for the QSM shows that it runs in O(lg 2 n/lg lg n+g lg n) time while performing O(gn lg n) work. Thus, if g is moderately large, specifically, (lg n/lg lg n), the sample sort algorithm will run within the same time and work bounds (randomized) as the more involved algorithms obtained by mapping the asymptotically optimal EREW PRAM algorithms onto the QSM. The improvement in running time for the QSM sample sort algorithm in comparison with the QRQW PRAM sample sort comes from the fact that the (lg 2 n/lg lg n) term in the time bound is only due to the bound on the contention at memory locations in a dart-throwing step. Since the QSM model charges only κ time for contention κ, this term is not multiplied by g in the time bound. 6.4. Mapping BSP Algorithms onto the QSM We now turn to the issue of mapping BSP algorithms onto the QSM. For this we assume that the input is distributed across the QSM processors to conform to the input distribution for the BSP algorithm; alternatively one can add the term ng/ p to the time bound for the QSM algorithm to take into account the time needed to distribute the input located in global memory across the private memories of the QSM processors.</p><p>Many of the BSP algorithms reported in the literature can be mapped back on the QSM using the version of the algorithm that results when L = 1. For instance, for the n-element summation, parity, and prefix sums problems, the BSP algorithm that takes time (gd + L) lg d n, minimized by choosing d ≥ 2 appropriately (d = L/g if L &gt; g and d = 2 if L ≤ g) maps onto the QSM as a simple O(g lg n) time algorithm that performs O(ng) work. Similarly the BSP sorting algorithm of <ref type="bibr" target="#b29">[30]</ref> and the matrix multiplication algorithms of <ref type="bibr" target="#b68">[69]</ref> and <ref type="bibr" target="#b58">[59]</ref> map onto the QSM step by step with a performance corresponding to the case when L = 1 in the BSP algorithms.</p><p>The QSM algorithms in the above paragraph are obtained by the following simple strategy to map each step of the BSP algorithm onto the QSM to run in the time the step would take on the BSP if L = 1. A message sent by processor i to a memory location m of processor j on the BSP is written into shared-memory location ( j, m) by processor i in the QSM and then read by processor j. We refer to a BSP algorithm as well behaved if it can be mapped onto the QSM in the above manner.</p><p>The mapping onto the QSM needed for a well-behaved BSP algorithm may not be possible if, in the BSP algorithm, a BSP processor (i) could receive a piece of information that it did not specifically request, and its future behavior depends on whether or not it receives this piece of information; or (ii) could access, as a unit-time local a value (not requested by it) that was written into its local memory bank by another processor in an earlier step.</p><p>On the QSM a processor would need to initiate a read for any piece of information that it receives; further, that access will be charged a cost of g at the time the processor reads it in addition to a cost of g being applied at the time the value was written into the shared-memory location. We now give an example of a BSP computation that is not well behaved. The elements of an array A <ref type="bibr">[1.</ref>.n] are distributed uniformly over p BSP processors. Each processor applies a certain function to its local inputs, and thereby generates some pairs (i, v), where v is the new value for A <ref type="bibr">[i]</ref>. The new values generated have the property that each processor generates no more than c such values, and there are no more than c new updates generated for each block of inputs assigned to a processor, where c = o(n/ p); other than these two restrictions, the indices i of the locations in the array A whose values are changed are arbitrary. These new values are updated on the BSP by sending a c-relation in cg time units. Then in additional n/ p time each BSP processor determines the new values of all of its local inputs by reading the corresponding local memory locations. This computation takes time O(cg + n/ p) on the BSP. If we implement this algorithm step by step on a QSM, the updated values will be written into a copy of the array A <ref type="bibr">[1.</ref>.n] in shared memory, and each QSM processor then needs to read these updated values. Since it is not known ahead of time which values were updated, each QSM processor would need to read from global memory, the current value of each of the n/ p elements of A[i] that it has in local memory. This will take (gn/ p) time, which is larger than the running time on the BSP since c = o(n/ p).</p><p>While the above example indicates that the BSP is in some ways more powerful than the QSM, it may not be desirable for a general-purpose bridging model to incorporate these features of the BSP, as argued in Section 3.2.</p><p>Fortunately, many of the BSP algorithms reported in the literature have simple communication patterns that map onto the QSM by the simple strategy described above. Also, as shown in the next subsection, there is a randomized strategy that can map any BSP algorithm onto the QSM in a work-preserving manner, provided a logarithmic slowdown is acceptable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">A Work-Preserving Emulation of BSP on QSM</head><p>In this section we describe a randomized work-preserving emulation of an n-component BSP on a QSM with O(lg n) slowdown that works with high probability in n (i.e., the probability of failure is 1/n δ , for some δ &gt; 0). For this emulation we assume that the input is distributed across the local memories of the QSM processors in the same manner as in the BSP algorithm.</p><p>In the emulation we use the shared memory of the QSM only for the purpose of realizing the h-relation performed by the BSP in each step, and each QSM processor copies into its private memory any message that was sent to the local memory of the corresponding BSP processor in that step. The algorithm is reminiscent of a randomized CRQW PRAM algorithm for integer sorting given in <ref type="bibr" target="#b33">[34]</ref>. It proceeds by using the shared memory to sort the messages being sent in the current step according to their destination. Each processor then reads the messages being sent to it from an appropriate subarray in the shared memory and writes it into the corresponding location in its local memory. The details of the emulation algorithm are given below. The probability that the emulation will fail to perform according to the stated bounds is less than 1/n δ , for some δ &gt; 0, whose value depends on parameters of the algorithm such as the constants in the sizes of arrays used in steps 5 and 7. Thus, if a BSP algorithm takes no more than n ε steps, for any ε, 0 &lt; ε &lt; δ, then the probability that the emulation of any one of its steps on a QSM fails is polynomially small in n. This leads to the following theorem. Theorem 6.5. An algorithm that runs in time t (n) on an n-component BSP with gap parameter g and periodicity factor L, where t (n) ≤ c • n γ , for some constants c, γ &gt; 0, can be emulated with high probability on a QSM with the same gap parameter g to run in time O(t (n) • g lg n/L ) with n/ g lg n/L processors when L ≥ g, and otherwise in time O(t (n) • lg n) with n/lg n processors. 6.6. On the Queuing Memory Contention Rule for the QSM   We note that a work-preserving emulation of a BSP with g = 1 is not known on the EREW PRAM if the slowdown is to be bounded by polylog(n). If such an emulation is discovered, it will give rise to randomized linear work polylog time algorithms on the EREW PRAM for certain problems, such as computing a random permutation, for which such an algorithm is not known currently. Therefore, even though the EREW PRAM is often referred to as a stronger model than the BSP, its expressive power may actually be inferior, in some cases.</p><p>On the other hand, for the more powerful CRCW PRAM there appears to be a mismatch in the reverse direction since no work-preserving emulation of a CRCW PRAM on a BSP with g = 1 is known if the slowdown is to be bounded by polylog(n). Thus, if either the EREW PRAM or the CRCW PRAM is augmented with the gap parameter, the resulting model is not known to have as strong a correspondence to the BSP as we have shown for the QSM. In other words, the queuing memory contention rule for the QSM, in contrast to the exclusive or concurrent rules, is crucial in order for it to serve as a bridging shared-memory model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Gap Parameter at Memory</head><p>The QSM has a gap parameter g at the processors, but no gap parameter at the memoryeach request at memory is serviced in unit time once it reaches the head of its queue. One could argue that another gap parameter d for processing memory accesses would be a desirable feature in a general-purpose model, since many currently available parallel machines have different gap parameters at processors and at memory banks. We refer to this model as QSM(g, d). The following result is shown in <ref type="bibr" target="#b63">[64]</ref>.</p><p>Observation 7.1 <ref type="bibr" target="#b63">[64]</ref>. There is a deterministic work-preserving emulation of QSM(g, d ) on QSM(g, d) with slowdown O( d/d ).</p><p>The above observation shows that very little generality is lost in assuming that the gap parameter at memory is 1 rather than some other value d. The only potential drawback is that an algorithm designed for the QSM(g, 1) (which is the standard QSM model) may not achieve the full level of speed-up attainable on QSM(g, d), due to the slowdown in the emulation mentioned in the observation. The advantage in not having a gap parameter d at memory is that we have a simpler model with fewer parameters. We believe that the simplicity achieved in not having a gap parameter d at memory far outweighs the drawback of not achieving the best possible speed-up for a specific value of d.</p><p>We define the s-QSM (the symmetric QSM) to be the model QSM(g, g). This is the special case of QSM(g, d) with the same gap parameter g at both processors and memory. This model has the same number of parameters as the QSM, and could serve as an alternative to the QSM. The main difference between the two models is the asymmetry in the application of the gap parameter at processor and memory in the case of the QSM versus the symmetry in this application in the s-QSM. As a result, the fastest speed-up achievable for a given problem can be slightly different in the two models, e.g., on the s-QSM broadcasting a bit to n memory locations has the tight time bound of (g lg n) in contrast to the tight bound of (g lg n/lg g) for the QSM. (Several other lower bounds for QSM and s-QSM are given in <ref type="bibr" target="#b53">[54]</ref>.) However, except for this difference, the QSM and the s-QSM are essentially interchangeable models. Specifically, the QSM can emulate the s-QSM with no slowdown and, as follows from Observation 7.1, there is a work-preserving emulation of the QSM on the s-QSM with slowdown O(g).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>Developing effective models for parallel computation, at suitable levels of abstraction, remains a fundamental challenge in parallel processing. The BSP and LogP models have gained considerable popularity as high-level "bridging models" for parallel computation, and indeed they have many attractive features and have proven to be effective in many scenarios. We have described a new model, the Queuing Shared-Memory (QSM) model, which in many cases may be an attractive alternative as a bridging model for parallel computation. In contrast to the BSP and LogP models, the QSM model provides a sharedmemory abstraction. The model has a simple queuing metric for shared-memory access, and only two parameters-p, the number of processors, and g, the bandwidth gapyet it can be efficiently emulated on both the BSP and (d, x)-BSP models, using an arguably practical emulation. Thus the QSM can be effectively realized on machines that can effectively realize the BSP, as well as on machines that are better modeled by the (d, x)-BSP. We have presented evidence that both the queuing metric and the bandwidth parameter are essential to the QSM's effectiveness as a bridging model. In addition, we have described several algorithms for the QSM, as well as general strategies for mapping EREW PRAM, QRQW PRAM, and BSP algorithms onto the QSM.</p><p>We conclude that a model such as the QSM can serve the role of a bridging model for parallel computation while preserving the high-level abstraction of a shared-memory model. On the other hand, as discussed in this paper, there are tradeoffs in any bridging model, and scenarios in which another model (BSP, LogP, etc.) may be preferred. Thus the choice of a best bridging model remains open to debate.</p><p>Future research should consider further algorithmic techniques that may be useful for this model, as well as experimental validation of the model. Such validation may reveal the primary importance of features not present in either the QSM, BSP, or LogP. For example, each of these models defines a single bandwidth parameter that reflects a per-processor bandwidth limitation; other recent work has considered variants of these models with an aggregate bandwidth limitation <ref type="bibr" target="#b0">[1]</ref> or a hierarchical bandwidth limitation that accounts for network proximity <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b72">[73]</ref>. Per-processor bandwidth limitations better model machines in which each processor has access to its "share" of the network bandwidth and no more, as well as machines for which the primary network bottleneck, in the absence of hot-spots, is in the processor-network interface. As a second example, each of these models ignores the memory hierarchy at a processor, assuming a unit-time charge for local operations regardless of the local working set size. A possible feature to consider is to limit the size of the private memories on the QSM, or to have two levels of memory hierarchy on the BSP or LogP. Third, as discussed in Section 4, each of these models disregards spatial locality. Variants of the BSP and LogP that account for spatial locality include <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b45">[46]</ref>, and <ref type="bibr" target="#b10">[11]</ref>. In machines supporting a single address space, the unit of data transfer between components is typically either a cache line or a page, and hence opportunities to exploit spatial locality are restricted to that level of granularity. A possible enhancement for the QSM would be to have the shared memory partitioned into small, fixed-sized blocks of locations that could be accessed efficiently; the realization of such a QSM on a distributed-memory machine would map these blocks pseudorandomly onto the memory banks. Finally, each of these models ignores the effects of the cache coherence protocol used in most sharedmemory multiprocessors to maintain consistency among the various cached copies of shared-memory data. It would be interesting to study a QSM model that incorporates and accounts for a standard invalidation-based cache coherence protocol <ref type="bibr" target="#b39">[40]</ref>. Should it become necessary to include additional features as part of a bridging model, the QSM may be more suited for augmentation than the BSP or LogP, since it is simpler, with fewer parameters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 4 . 4 (</head><label>44</label><figDesc>QSM on Unbalanced (d, x)-BSP). Consider a p-processor (d, x)-BSP with gap parameter g and periodicity factor L, such that 1 ≤ x &lt; min d g , p c , for some constant c &gt; 0, where d g = d/g. Then, for all p ≥ max(xg lg p, d, L/g) • p, each step of an algorithm for the p -processor QSM with parameter g with time cost t can be emulated on the p-processor (d, x)-BSP in O((d g /x) • ( p / p) • t) time w.h.p. Proof. As in the proof of Theorem 4.1, the shared memory of the QSM is randomly hashed onto the B = x • p memory banks of the (d, x)-BSP. In the emulation algorithm, each (d, x)-BSP processor executes the operations of p / p QSM processors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Inaccuracies in the BSP and the LogP predictions, due to assuming the wrong memory layout and underestimating the cost of memory-bank contention. This figure is from [16].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>A comparison of several models of parallel computation.</figDesc><table><row><cell>Model</cell><cell>Synchrony</cell><cell>Communication</cell><cell>Parameters*</cell></row><row><cell>PRAM [29]</cell><cell>Lock-step</cell><cell>Shared memory</cell><cell>p</cell></row><row><cell>Module Parallel Computer (MPC)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Some emulations of higher-level models on the BSP model.</figDesc><table><row><cell>Model emulated</cell><cell>On model</cell><cell>With slackness</cell><cell>Work-preserving?</cell></row><row><cell>EREW PRAM</cell><cell>BSP(g, L)</cell><cell>≥ max(lg p, L/g)</cell><cell>Inefficient by a factor of g</cell></row><row><cell>QRQW PRAM</cell><cell>BSP(g, L)</cell><cell>≥ max(lg p, L/g)</cell><cell>Inefficient by a factor of g</cell></row><row><cell>CRCW PRAM</cell><cell>BSP(g, L)</cell><cell>≥ max( p 1+ε , L/g)</cell><cell>Inefficient by a factor of g</cell></row><row><cell>QSM(g)</cell><cell>BSP(g, L)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>in order to allow for work-efficient emulation on a</figDesc><table /><note><p>BSP and (d, x)-BSP. Observation 4.5. Let p ≥ p. Any emulation of one step of the p -processor QSM with gap parameter g with time cost t on the p-processor (d, x)-BSP with gap parameter g and periodicity factor L requires T = max(t • (g/g ) • p / p , d • t p /(x pg ) ) time in the worst case.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>1. Compute the total number of messages, M, to be sent by all processors as follows:Construct an array A[1..n] in shared memory, with A[i] containing the number of messages being sent by processor i, and compute M as the sum of the elements in this array. This step can be performed deterministically in O(g lg n) time andO(M + g • n) work (note that M ≤ n • h,where h is the maximum number of messages sent or received by any processor in this BSP step). Construct a sample S of the messages to be sent by choosing each message independently with probability 1/lg 3 M. The size of the sample will be O(M/lg 3 M) w.h.p. 3. Sort the sample deterministically according to destination using a standard sorting algorithm, e.g., Cole's merge-sort; this takes O(g lg M) time and O(g• M/lg 2 M) work. 4. Group the destinations into groups of size lg 3 M and determine the number of messages destined for each group. This can be computed by a prefix sums computation that takes O(g lg M) time and O(gM) work. 5. Let k i be the number of elements in the sample destined for the ith group. Obtain a high probability bound on the total number of messages to each group as r . 6. In parallel, for each i, all processors with a message to a destination i read the value of this bound from R[i]; this takes time ≤ gh and O(g • M) work. 7. Use an algorithm for multiple compaction to get the messages in each group into a linear-sized array for that group; this takes O(g lg M) time and O(g • M) work by the adaptation of the randomized QRQW PRAM algorithm for multiple compaction given in [34] to the QSM using Observation 6.2. 8. Perform a stable sort within each group according to the individual destination; this can be performed in O(g lg M) time and O(gM) work deterministically using an EREW PRAM radix-sort algorithm within each group. 9. Move the messages into an output array R of size M sorted according to destination in O(gh) time and O(M) work. Create an array B of size n that contains the number of messages to each destination, and the starting point in the output array for messages to that destination; this can be done by computing prefix sums on an appropriate M-array and takes O(g lg M) time and O(g • M) work. Processor i reads this value from B[i] and then reads the messages destined for it from the output array in time O(gh) and work O(g • M).If M &lt; n/lg n, then we sort the messages deterministically according to their destination; this takes time O(g lg n) and O(gn) work. We then perform step 9 above. Since M ≤ n • h, the above QSM algorithm runs in O(g(h + lg n)) time while performing O(ghn) work. High-probability bounds for the randomized steps in the above algorithm are shown in<ref type="bibr" target="#b33">[34]</ref>. Since a BSP routes an h-relation in O(gh + L) time while performing O(n(gh + L)) work, this is a work-preserving emulation of a BSP h-relation, with a slowdown of O(1 + lg n/(h + L/g)).In summary we have the following result.</figDesc><table><row><cell>If M ≥ n/lg n, then execute steps 2-9 below. involves routing an h-relation. On a QSM with gap parameter g this step can be emulated with high probability in n in a work-preserving manner with a slowdown of O(1 + 2. Lemma 6.4. Consider a step of an n-component BSP with gap g and latency L that lg n/(h + L/g)).</cell></row></table><note><p><p><p>i = O(max(k i , 1) • lg 3 M). Make lg 3 M copies of each r i , and place the duplicate values of the r i in an array R</p>[1.</p>.n] such that R[i] contains the bound for the group that contains destination i, 1 ≤ i ≤ n. This step can be performed in O(g(1 + lg lg M/lg g)) time and O(ng) work using a broadcasting algorithm for each r i</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Alternatively, the time cost could be m op + g • m r w + κ; this affects the bounds by at most a factor of 3, and the results in<ref type="bibr" target="#b15">[16]</ref> show that, at least for certain machines, taking the maximum is more accurate than taking their sum.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>This issue is explored further in Section 7.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Alternatively, the time is w + g • h + L; this affects the bounds by at most a factor of 3, and the results in<ref type="bibr" target="#b15">[16]</ref> show that, at least for certain machines, taking the maximum of the three terms is more accurate than taking their sum.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The third author was supported in part by NSF Grant CCR/GER-90-23059.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling parallel bandwidth: local vs. global restrictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>9th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="94" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On communication latency in PRAM computations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Snir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>1st ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1989-06">June 1989</date>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Communication complexity of PRAMs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Snir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="28" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sorting in c lg n parallel steps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ajtai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Szemeredi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LogGP: incorporating long messages into the LogP model-one step closer towards a realistic model for parallel computation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Schauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sheiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>7th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
			<biblScope unit="page" from="95" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uniform memory hierarchies</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Feig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st IEEE Symp. on Foundations of Computer Science</title>
		<meeting>31st IEEE Symp. on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="1990-10">October 1990</date>
			<biblScope unit="page" from="600" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Optical Communication for Pointer Based Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<idno>CRI 88-14</idno>
		<imprint>
			<date type="published" when="1988">1988</date>
			<pubPlace>Los Angeles, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Southern California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Clock construction in fully asynchronous parallel systems and PRAM simulation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Aumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd IEEE Symp. on Foundations of Computer Science</title>
		<meeting>33rd IEEE Symp. on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="1992-10">October 1992</date>
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computing global combine operations in the multi-port postal model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Noy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kipnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th IEEE Symp. on Parallel and Distributed Processing</title>
		<meeting>5th IEEE Symp. on Parallel and Distributed essing</meeting>
		<imprint>
			<date type="published" when="1993-12">December 1993</date>
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Designing broadcasting algorithms in the postal model for message-passing systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Noy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kipnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>4th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1992-07">June-July 1992</date>
			<biblScope unit="page" from="13" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fully dynamic search trees for an extension of the BSP model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baumker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dittrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>8th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Truly Efficient Parallel Algorithms: 1-Optimal Multisearch for an Extension of the BSP Model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baumker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dittrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heide</forename><surname>Der</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Paderborn</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimal bounds for decision problems on the CRCW PRAM</title>
		<author>
			<persName><forename type="first">P</forename><surname>Beame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Håstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="643" to="670" />
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Vector Models for Data-Parallel Computing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Programming parallel algorithms</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="85" to="97" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accounting for memory bank contention and delay in high-bandwidth multiprocessors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zagha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Preliminary version appears in Proc. 7th ACM Symp. on Parallel Algorithms and Architectures</title>
		<imprint>
			<date type="published" when="1995">1997. July 1995</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="84" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Accounting for memory bank contention and delay in high-bandwidth multiprocessors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zagha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="943" to="958" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A comparison of sorting algorithms for the Connection Machine CM-2</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Maggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Plaxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zagha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>3rd ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1991-07">July 1991</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parallel merge sort</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="770" to="785" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The APRAM: incorporating asynchrony into the PRAM model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zajicek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>1st ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1989-06">June 1989</date>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The expected advantage of asynchrony</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zajicek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>2nd ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1990-07">July 1990</date>
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">LogP: towards a realistic model of parallel computation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sahay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Schauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Von Eicken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming</title>
		<meeting>4th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bounds on the efficiency of message-passing protocols for parallel computers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cypher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Konstantinidou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>5th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1993-07">June-July 1993</date>
			<biblScope unit="page" from="173" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Work-time-optimal parallel algorithms for string problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Czumaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Galil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gasieniec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Plandowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th ACM Symp. on Theory of Computing</title>
		<meeting>27th ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1995-06">May-June 1995</date>
			<biblScope unit="page" from="713" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards a single model of efficient computation in real parallel machines</title>
		<author>
			<persName><forename type="first">P</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="395" to="408" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Submachine locality in the bulk synchronous setting</title>
		<author>
			<persName><forename type="first">P</forename><surname>De La Torre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Euro-Par &apos;96</title>
		<meeting>Euro-Par &apos;96</meeting>
		<imprint>
			<date type="published" when="1996-08">August 1996</date>
			<biblScope unit="page" from="352" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple, efficient shared memory simulations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dietzfelbinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heide</forename><surname>Der</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>5th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1993-07">June-July 1993</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Contention in shared memory algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Waarts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th ACM Symp. on Theory of Computing</title>
		<meeting>25th ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="174" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Parallelism in random access machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fortune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wyllie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th ACM Symp. on Theory of Computing</title>
		<meeting>10th ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1978-05">May 1978</date>
			<biblScope unit="page" from="114" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Direct bulk-synchronous parallel algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Gerbessiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="251" to="267" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Memory consistency and event ordering in scalable shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lenoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laudon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th International Symp. on Computer Architecture</title>
		<meeting>17th International Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1990-05">May 1990</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Full version in The Asynchronous PRAM: a semi-synchronous model for shared memory MIMD machines</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>1st ACM Symp. on Parallel Algorithms and Architectures<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-06">June 1989. 1989</date>
			<biblScope unit="page" from="158" to="168" />
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note>A more practical PRAM model. Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">What good are shared-memory models?</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1996 ICPP Workshop on Challenges for Parallel Processing</title>
		<meeting>1996 ICPP Workshop on Challenges for Parallel essing</meeting>
		<imprint>
			<date type="published" when="1996-08">August 1996</date>
			<biblScope unit="page" from="103" to="114" />
		</imprint>
	</monogr>
	<note>Invited position paper</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Special issue devoted to selected papers from the</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Symp. on Parallel Algorithms and Architectures</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="442" />
			<date type="published" when="1994">1996. 1994</date>
		</imprint>
	</monogr>
	<note>Journal of Computer and System Sciences</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Queue-Read Queue-Write Asynchronous PRAM model</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="page" from="3" to="29" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The Queue-Read Queue-Write PRAM model: accounting for contention in parallel algorithms</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM-SIAM Symp. on Discrete Algorithms</title>
		<meeting>5th ACM-SIAM Symp. on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="1994">1999. January 1994</date>
			<biblScope unit="page" from="638" to="648" />
		</imprint>
	</monogr>
	<note>To appear. Preliminary version appears</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Communication-efficient parallel sorting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goodrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th ACM Symp. on Theory of Computing</title>
		<meeting>28th ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A comparison of data-parallel algorithms for connected components</title>
		<author>
			<persName><forename type="first">J</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>6th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1994-06">June 1994</date>
			<biblScope unit="page" from="16" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">C 3 : an architecture-independent model for coarse-grained parallel machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hambrusch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khokhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th IEEE Symp. on Parallel and Distributed Processing</title>
		<meeting>6th IEEE Symp. on Parallel and Distributed essing</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="544" to="551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Computer Architecture: A Quantitative Approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A practical hierarchical model of parallel computation: I. The model</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heywood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ranka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="212" to="232" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Parallel implementation of algorithms for finding connected components in graphs</title>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AMS/DIMACS Parallel Implementation Challenge Workshop III</title>
		<title level="s">DIMACS Series</title>
		<meeting>AMS/DIMACS Parallel Implementation Challenge Workshop III<address><addrLine>Providence, RI</addrLine></address></meeting>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="395" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">An Introduction to Parallel Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jájá</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The Block Distributed Memory Model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jájá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Ryu</surname></persName>
		</author>
		<idno>UMIACS-TR-94-5</idno>
		<imprint>
			<date type="published" when="1994-01">January 1994</date>
			<pubPlace>College Park, MD</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute for Advanced Computer Studies, University of Maryland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H H</forename><surname>Juurlink</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Leiden University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The E-BSP model: incorporating general locality and unbalanced communication into the BSP Model</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H H</forename><surname>Juurlink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A G</forename><surname>Wijshoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Euro-Par &apos;96</title>
		<meeting>Euro-Par &apos;96</meeting>
		<imprint>
			<date type="published" when="1996-08">August 1996</date>
			<biblScope unit="page" from="339" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Optimal broadcast and summation in the LogP model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sahay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Schauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>5th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1993-07">June-July 1993</date>
			<biblScope unit="page" from="142" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Parallel algorithms for shared-memory machines</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Handbook of Theoretical Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Van Leeuwen</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">A</biblScope>
			<biblScope unit="page" from="869" to="941" />
			<date type="published" when="1990">1990</date>
			<publisher>Elsevier</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Efficient program transformations for resilient parallel computation via randomization</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Palem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Rabin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th ACM Symp. on Theory of Computing</title>
		<meeting>24th ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1992-05">May 1992</date>
			<biblScope unit="page" from="306" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A research agenda for high performance computing software</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Developing a Computer Science Agenda for High-Performance Computing</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="106" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Introduction to Parallel Algorithms and Architectures: Arrays • Trees • Hypercubes</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Leighton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Communication-efficient parallel algorithms for distributed randomaccess machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Maggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="77" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">An atomic model for message-passing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Aiello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>5th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1993-07">June-July 1993</date>
			<biblScope unit="page" from="154" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Computational bounds for fundamental problems on generalpurpose parallel models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>10th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1998-07">June-July 1998</date>
			<biblScope unit="page" from="152" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Models of parallel computation: a survey and synthesis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Maggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Matheson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Hawaii International Conf. on System Sciences</title>
		<meeting>28th Hawaii International Conf. on System Sciences</meeting>
		<imprint>
			<date type="published" when="1995-01">January 1995</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Trade-offs between communication throughput and parallel time</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Vishkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th ACM Symp. on Theory of Computing</title>
		<meeting>26th ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="372" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Work-optimal asynchronous algorithms for shared memory parallel computers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Martel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subramonian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1070" to="1099" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Effects of communication latency, overhead, and bandwidth in a cluster architecture</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Culler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th International Symp. on Computer Architecture</title>
		<meeting>24th International Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="85" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">A BSP Realization of Strassen&apos;s Algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Mccoll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
		<respStmt>
			<orgName>Computing Laboratory, Oxford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Randomized and deterministic simultaitons of PRAMs by parallel machines with restricted granularity of parallel memories</title>
		<author>
			<persName><forename type="first">K</forename><surname>Melhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Vishkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="339" to="374" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Asynchronous shared memory parallel computation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nishimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>2nd ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1990-07">July 1990</date>
			<biblScope unit="page" from="76" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Large-scale sorting in parallel memories</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Nodine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Vitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>3rd ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1991-07">July 1991</date>
			<biblScope unit="page" from="29" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Probabilistic construction of deterministic algorithms: approximating packing integer programs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="130" to="143" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A general purpose shared memory model for parallel computation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IMA Volumes in Mathematics and Its Applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="volume">105</biblScope>
		</imprint>
	</monogr>
	<note>Algorithms for Parallel Processing. in press</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">A Synthesis of Parallel Algorithms</title>
		<editor>J. H. Reif</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Randomized algorithms for binary search and load balancing on fixed connection networks with geometric applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>2nd ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1990-07">July 1990</date>
			<biblScope unit="page" from="327" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Invited lecture</title>
		<author>
			<persName><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th ACM Symp. on Parallel Algorithms and Architectures</title>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Comparative performance evaluation of cache-coherent NUMA and COMA architectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stenström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 19th International Symp. on Computer Architecture</title>
		<meeting>19th International Symp. on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1992-05">May 1992</date>
			<biblScope unit="page" from="80" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A bridging model for parallel computation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="103" to="111" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">General purpose parallel architectures</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Handbook of Theoretical Computer Science</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Van Leeuwen</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">A</biblScope>
			<biblScope unit="page" from="943" to="972" />
			<date type="published" when="1990">1990</date>
			<publisher>Elsevier</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A parallel-design distributed-implementation (PDDI) general purpose computer</title>
		<author>
			<persName><forename type="first">U</forename><surname>Vishkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="157" to="172" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Optimal disk I/O with parallel block transfer</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Vitter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A M</forename><surname>Shriver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd ACM Symp. on Theory of Computing</title>
		<meeting>22nd ACM Symp. on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1990-05">May 1990</date>
			<biblScope unit="page" from="159" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A quantitative comparison of parallel computation models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A G</forename><surname>Wijshoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H H</forename><surname>Juurlink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th ACM Symp. on Parallel Algorithms and Architectures</title>
		<meeting>8th ACM Symp. on Parallel Algorithms and Architectures</meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Received November 11, 1997, and in final form</title>
		<imprint>
			<date type="published" when="1998-09-21">September 21, 1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
