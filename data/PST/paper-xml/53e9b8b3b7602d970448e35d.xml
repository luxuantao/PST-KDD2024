<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotions from text: machine learning for text-based emotion prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Cecilia</forename><forename type="middle">Ovesdotter</forename><surname>Alm</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<email>danr@uiuc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Sproat</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Linguistics</orgName>
								<orgName type="institution">UIUC Illinois</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">UIUC Illinois</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Linguistics Dept. of Electrical Eng. UIUC Illinois</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Emotions from text: machine learning for text-based emotion prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In addition to information, text contains attitudinal, and more specifically, emotional content. This paper explores the text-based emotion prediction problem empirically, using supervised machine learning with the SNoW learning architecture. The goal is to classify the emotional affinity of sentences in the narrative domain of children's fairy tales, for subsequent usage in appropriate expressive rendering of text-to-speech synthesis. Initial experiments on a preliminary data set of 22 fairy tales show encouraging results over a naïve baseline and BOW approach for classification of emotional versus non-emotional contents, with some dependency on parameter tuning. We also discuss results for a tripartite model which covers emotional valence, as well as feature set alternations. In addition, we present plans for a more cognitively sound sequential model, taking into consideration a larger set of basic emotions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text does not only communicate informative contents, but also attitudinal information, including emotional states. The following reports on an empirical study of text-based emotion prediction.</p><p>Section 2 gives a brief overview of the intended application area, whereas section 3 summarizes related work. Next, section 4 explains the empirical study, including the machine learning model, the corpus, the feature set, parameter tuning, etc. Section 5 presents experimental results from two classification tasks and feature set modifications. Section 6 describes the agenda for refining the model, before presenting concluding remarks in 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Application area: Text-to-speech</head><p>Narrative text is often especially prone to having emotional contents. In the literary genre of fairy tales, emotions such as HAPPINESS and ANGER and related cognitive states, e.g. LOVE or HATE, become integral parts of the story plot, and thus are of particular importance. Moreover, the story teller reading the story interprets emotions in order to orally convey the story in a fashion which makes the story come alive and catches the listeners' attention.</p><p>In speech, speakers effectively express emotions by modifying prosody, including pitch, intensity, and durational cues in the speech signal. Thus, in order to make text-to-speech synthesis sound as natural and engaging as possible, it is important to convey the emotional stance in the text. However, this implies first having identified the appropriate emotional meaning of the corresponding text passage.</p><p>Thus, an application for emotional text-to-speech synthesis has to solve two basic problems. First, what emotion or emotions most appropriately describe a certain text passage, and second, given a text passage and a specified emotional mark-up, how to render the prosodic contour in order to convey the emotional content, <ref type="bibr" target="#b4">(Cahn, 1990)</ref>. The text-based emotion prediction task (TEP) addresses the first of these two problems.</p><p>For a complete general overview of the field of affective computing, see <ref type="bibr" target="#b16">(Picard, 1997)</ref>. <ref type="bibr" target="#b13">(Liu, Lieberman and Selker, 2003)</ref> is a rare study in textbased inference of sentence-level emotional affinity. The authors adopt the notion of basic emotions, cf. <ref type="bibr" target="#b7">(Ekman, 1993)</ref>, and use six emotion categories: ANGER, DISGUST, FEAR, HAPPINESS, SADNESS, SURPRISE. They critique statistical NLP for being unsuccessful at the small sentence level, and instead use a database of common-sense knowledge and create affect models which are combined to form a representation of the emotional affinity of a sentence. At its core, the approach remains dependent on an emotion lexicon and hand-crafted rules for conceptual polarity. In order to be effective, emotion recognition must go beyond such resources; the authors note themselves that lexical affinity is fragile. The method was tested on 20 users' preferences for an email-client, based on user-composed text emails describing short but colorful events. While the users preferred the emotional client, this evaluation does not reveal emotion classification accuracy, nor how well the model generalizes on a large data set.</p><p>Whereas work on emotion classification from the point of view of natural speech and humancomputer dialogues is fairly extensive, e.g. <ref type="bibr" target="#b18">(Scherer, 2003)</ref>, <ref type="bibr" target="#b11">(Litman and Forbes-Riley, 2004)</ref>, this appears not to be the case for text-to-speech synthesis (TTS). A short study by <ref type="bibr">(Sugimoto et al., 2004)</ref> addresses sentence-level emotion recognition for Japanese TTS. Their model uses a composition assumption: the emotion of a sentence is a function of the emotional affinity of the words in the sentence. They obtain emotional judgements of 73 adjectives and a set of sentences from 15 human subjects and compute words' emotional strength based on the ratio of times a word or a sentence was judged to fall into a particular emotion bucket, given the number of human subjects. Additionally, they conducted an interactive experiment concerning the acoustic rendering of emotion, using manual tuning of prosodic parameters for Japanese sentences. While the authors actually address the two fundamental problems of emotional TTS, their approach is impractical and most likely cannot scale up for a real corpus. Again, while lexical items with clear emotional meaning, such as happy or sad, matter, emotion classification probably needs to consider additional inference mechanisms. Moreover, a naïve compositional approach to emotion recognition is risky due to simple linguistic facts, such as context-dependent semantics, domination of words with multiple meanings, and emotional negation.</p><p>Many NLP problems address attitudinal meaning distinctions in text, e.g. detecting subjective opinion documents or expressions, e.g. <ref type="bibr" target="#b22">(Wiebe et al, 2004)</ref>, measuring strength of subjective clauses <ref type="bibr" target="#b23">(Wilson, Wiebe and Hwa, 2004)</ref>, determining word polarity <ref type="bibr">(Hatzivassiloglou and McKeown, 1997)</ref> or texts' attitudinal valence, e.g. <ref type="bibr" target="#b20">(Turney, 2002)</ref>, <ref type="bibr" target="#b2">(Bai, Padman and Airoldi, 2004)</ref>, <ref type="bibr">(Beineke, Hastie and Vaithyanathan, 2003)</ref>, <ref type="bibr">(Mullen and Collier, 2003)</ref>, <ref type="bibr">(Pang and Lee, 2003)</ref>. Here, it suffices to say that the targets, the domain, and the intended application differ; our goal is to classify emotional text passages in children's stories, and eventually use this information for rendering expressive child-directed storytelling in a text-to-speech application. This can be useful, e.g. in therapeutic education of children with communication disorders <ref type="bibr" target="#b21">(van Santen et al., 2003)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Empirical study</head><p>This part covers the experimental study with a formal problem definition, computational implementation, data, features, and a note on parameter tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Machine learning model</head><p>Determining emotion of a linguistic unit can be cast as a multi-class classification problem. For the flat case, let T denote the text, and s an embedded linguistic unit, such as a sentence, where s ∈ T . Let k be the number of emotion classes E = {em 1 , em 2 , .., em k }, where em 1 denotes the special case of neutrality, or absence of emotion. The goal is to determine a mapping function f : s → em i , such that we obtain an ordered labeled pair (s, em i ). The mapping is based on F = {f 1 , f 2 , .., f n }, where F contains the features derived from the text.</p><p>Furthermore, if multiple emotion classes can characterize s, then given E' ⊂ E, the target of the mapping function becomes the ordered pair (s, E ). Finally, as further discussed in section 6, the hierarchical case of label assignment requires a sequen-tial model that further defines levels of coarse versus fine-grained classifiers, as done by <ref type="bibr" target="#b12">(Li and Roth, 2002)</ref> for the question classification problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation</head><p>Whereas our goal is to predict finer emotional meaning distinctions according to emotional categories in speech; in this study, we focus on the basic task of recognizing emotional passages and on determining their valence (i.e. positive versus negative) because we currently do not have enough training data to explore finer-grained distinctions. The goal here is to get a good understanding of the nature of the TEP problem and explore features which may be useful.</p><p>We explore two cases of flat classification, using a variation of the Winnow update rule implemented in the SNoW learning architecture <ref type="bibr" target="#b5">(Carlson et al., 1999)</ref>,<ref type="foot" target="#foot_0">1</ref> which learns a linear classifier in feature space, and has been successful in several NLP applications, e.g. semantic role labeling (Koomen, Punyakanok, <ref type="bibr" target="#b10">Roth and Yih, 2005)</ref>. In the first case, the set of emotion classes E consists of EMOTIONAL versus non-emotional or NEUTRAL, i.e. E = {N, E}. In the second case, E has been incremented with emotional distinctions according to the valence, i.e. E = {N, P E, N E}. Experiments used 10-fold cross-validation, with 90% train and 10% test data.<ref type="foot" target="#foot_1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data</head><p>The goal of our current data annotation project is to annotate a corpus of approximately 185 children stories, including Grimms', H.C. Andersen's and B. Potter's stories. So far, the annotation process proceeds as follows: annotators work in pairs on the same stories. They have been trained separately and work independently in order to avoid any annotation bias and get a true understanding of the task difficulty. Each annotator marks the sentence level with one of eight primary emotions, see table 1, reflecting an extended set of basic emotions <ref type="bibr" target="#b7">(Ekman, 1993)</ref>. In order to make the annotation process more focused, emotion is annotated from the point of view of the text, i.e. the feeler in the sentence. While the primary emotions are targets, the sentences are also marked for other affective contents, i.e. background mood, secondary emotions via intensity, feeler, and textual cues. Disagreements in annotations are resolved by a second pass of tie-breaking by the first author, who chooses one of the competing labels. Eventually, the completed annotations will be made available. Emotion annotation is hard; interannotator agreement currently range at κ = .24 − .51, with the ratio of observed annotation overlap ranging between 45-64%, depending on annotator pair and stories assigned. This is expected, given the subjective nature of the annotation task. The lack of a clear definition for emotion vs. non-emotion is acknowledged across the emotion literature, and contributes to dynamic and shifting annotation targets. Indeed, a common source of confusion is NEUTRAL, i.e. deciding whether or not a sentence is emotional or non-emotional. Emotion perception also depends on which character's point-of-view the annotator takes, and on extratextual factors such as annotator's personality or mood. It is possible that by focusing more on the training of annotator pairs, particularly on joint training, agreement might improve. However, that would also result in a bias, which is probably not preferable to actual perception. Moreover, what agreement levels are needed for successful expressive TTS remains an empirical question.</p><p>The current data set consisted of a preliminary annotated and tie-broken data set of 1580 sentence, or 22 Grimms' tales. The label distribution is in table 2. NEUTRAL was most frequent with 59.94%.   Next, for the purpose of this study, all emotional classes, i.e. A, D, F, H, SA, SU+, SU-, were combined into one emotional superclass E for the first experiment, as shown in table 3. For the second experiment, we used two emotional classes, i.e. positive versus negative emotions; P E={H, SU+} and N E={A, D, F, SA, SU-}, as seen in table 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Feature set</head><p>The feature extraction was written in python. SNoW only requires active features as input, which resulted in a typical feature vector size of around 30 features. The features are listed below. They were implemented as boolean values, with continuous values represented by ranges. The ranges generally overlapped, in order to get more generalization coverage. Feature conjunctions covered pairings of counts of positive and negative words with range of story progress or interjections, respectively. Feature groups 1, 3, 5, 6, 7, 8, 9, 10 and 14 are extracted automatically from the sentences in the stories; with the SNoW POS-tagger used for features 9, 10, and 14. Group 10 reflects how many verbs are active in a sentence. Together with the quotation and punctuation, verb domination intends to capture the assumption that emotion is often accompanied by increased action and interaction. Feature group 4 is based on Finish scholar Antti Aarne's classes of folk-tale types according to their informative thematic contents <ref type="bibr" target="#b0">(Aarne, 1964)</ref>. The current tales have 3 top story types (ANIMAL TALES, ORDINARY FOLK-TALES, and JOKES AND ANECDOTES), and 15 subtypes (e.g. supernatural helpers is a subtype of the ORDINARY FOLK-TALE). This feature intends to provide an idea about the story's general affective personality <ref type="bibr" target="#b16">(Picard, 1997)</ref>, whereas the feature reflecting the story progress is hoped to capture that some emotions may be more prevalent in certain sections of the story (e.g. the happy end).</p><p>For semantic tasks, words are obviously important. In addition to considering 'content words', we also explored specific word lists. Group 11 uses 2 lists of 1636 positive and 2008 negative words, obtained from <ref type="bibr">(Di Cicco et al., online)</ref>. Group 12 uses lexical lists extracted from WordNet <ref type="bibr" target="#b8">(Fellbaum, 1998)</ref>, on the basis of the primary emotion words in their adjectival and nominal forms. For the adjectives, Py-WordNet's <ref type="bibr">(Steele et al., 2004</ref>) SIMI-LAR feature was used to retrieve similar items of the primary emotion adjectives, exploring one additional level in the hierarchy (i.e. similar items of all senses of all words in the synset). For the nouns and any identical verbal homonyms, synonyms and hyponyms were extracted manually.<ref type="foot" target="#foot_2">3</ref> Feature group 13 used a short list of 22 interjections collected manually by browsing educational ESL sites, whereas the affective word list of 771 words consisted of a combination of the non-neutral words from (Johnson-Laird and Oatley, 1989) and <ref type="bibr">(Siegle, online)</ref>. Only a subset of these lexical lists actually occurred. <ref type="foot" target="#foot_3">4</ref>The above feature set is henceforth referred to as all features, whereas content BOW is just group 14. The content BOW is a more interesting baseline than the naïve one, P(Neutral), i.e. always assigning the most likely NEUTRAL category. Lastly, emotions blend and transform <ref type="bibr" target="#b13">(Liu, Lieberman and Selker, 2003)</ref>. Thus, emotion and background mood of immediately adjacent sentences, i.e. the sequencing, seems important. At this point, it is not implemented automatically. Instead, it was extracted from the manual emotion and mood annotations. If sequencing seemed important, an automatic method using sequential target activation could be added next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Parameter tuning</head><p>The Winnow parameters that were tuned included promotional α, demotional β, activation threshold θ, initial weights ω, and the regularization parameter, S, which implements a margin between positive and negative examples. Given the currently fairly limited data, results from 2 alternative tuning methods, applied to all features, are reported.</p><p>• For the condition called sep-tune-eval, 50% of the sentences were randomly selected and set aside to be used for the parameter tuning process only. Of this subset, 10% were subsequently randomly chosen as test set with the remaining 90% used for training during the automatic tuning process, which covered 4356 different parameter combinations. Resulting parameters were: α = 1.1, β = 0.5, θ = 5, ω = 1.0, S = 0.5. The remaining half of the data was used for training and testing in the 10-fold cross-validation evaluation. (Also, note the slight change for P(Neutral) in table 5, due to randomly splitting the data.)</p><p>• Given that the data set is currently small, for the condition named same-tune-eval, tuning was performed automatically on all data using a slightly smaller set of combinations, and then manually adjusted against the 10-fold crossvalidation process. Resulting parameters were: α = 1.2, β = 0.9, θ = 4, ω = 1, S = 0.5. All data was used for evaluation.</p><p>Emotion classification was sensitive to the selected tuning data. Generally, a smaller tuning set resulted in pejorative parameter settings. The random selection could make a difference, but was not explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and discussion</head><p>This section first presents the results from experiments with the two different confusion sets described above, as well as feature experimentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Classification results</head><p>Average accuracy from 10-fold cross validation for the first experiment, i.e. classifying sentences as either NEUTRAL or EMOTIONAL, are included in table 5 and figure <ref type="figure" target="#fig_1">1</ref> for the two tuning conditions on the main feature sets and baselines. As expected, degree of success reflects parameter settings, both for content BOW and all features. Nevertheless, under these circumstances, performance above a naïve baseline and a BOW approach is obtained. Moreover, sequencing shows potential for contributing in one case. However, observations also point to three issues: first, the current data set appears to be too small. Second, the data is not easily separable. This comes as no surprise, given the subjective nature of the task, and the rather low interannotator agreement, reported above. Moreover, despite the schematic narrative plots of children's stories, tales still differ in their overall affective orientation, which increases data complexity. Third and finally, the EMOTION class is combined by basic emotion labels, rather than an original annotated label. More detailed averaged results from 10-fold cross-validation are included in table 6 using all features and the separated tuning and evaluation data condition sep-tune-eval. With these parameters, approximately 3% improvement in accuracy over the naïve baseline P(Neutral) was recorded, and 5% over the content BOW, which obviously did poorly with these parameters. Moreover, precision is  In comparison, with the same-tune-eval procedure, the accuracy improved by approximately 9% over P(Neutral) and by 8% over content BOW.</p><p>In the second experiment, the emotion category was split into two classes: emotions with positive versus negative valence. The results in terms of precision, recall, and F-score are included in table 7, using all features and the sep-tune-eval condition. The decrease in performance for the emotion classes mirrors the smaller amounts of data available for each class. As noted in section 4.3, only 9.87% of the sentences were annotated with a positive emotion, and the results for this class are worse. Thus, performance seems likely to improve as more annotated story data becomes available; at this point, we are experimenting with merely around 12% of the total texts targeted by the data annotation project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Feature experiments</head><p>Emotions are poorly understood, and it is especially unclear which features may be important for their recognition from text. Thus, we experimented with different feature configurations. Starting with all features, again using 10-fold cross-validation for the separated tuning-evaluation condition sep-tuneeval, one additional feature group was removed until none remained. The feature groups are listed in table <ref type="table" target="#tab_7">8</ref>. Figure <ref type="figure">2</ref> on the next page shows the accuracy at each step of the cumulative subtraction process. While some feature groups, e.g. syntactic, appeared less important, the removal order mattered; e.g. if syntactic features were removed first, accuracy decreased. This fact also illustrated that features work together; removing any group degraded performance because features interact and there is no true independence. It was observed that features' contributions were sensitive to parameter tuning. Clearly, further work on developing features which fit the TEP problem is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Refining the model</head><p>This was a "first pass" of addressing TEP for TTS. At this point, the annotation project is still on-going, and we only had a fairly small data set to draw on. Nevertheless, results indicate that our learning approach benefits emotion recognition. For example, the following instances, also labeled with the same valence by both annotators, were correctly classified both in the binary (N vs. E) and the tripartite polarity task (N, NE, PE), given the separated tuning and evaluation data condition, and using all features:</p><p>(1a) E/NE: Then he offered the dwarfs money, and prayed and besought them to let him take her away; but they said, "We will not part with her for all the gold in the world." Cases (1a) and (1b) are from the well-known FOLK TALE Snowdrop, also called Snow White. (1a) and (1b) are also correctly classified by the simple content BOW approach, although our approach has higher prediction confidence for E/NE (1a); it also considers, e.g. direct speech, a fairly high verb count, advanced story progress, connotative words and conjunctions thereof with story progress features, all of which the BOW misses. In addition, the simple content BOW approach makes incorrect predictions at both the bipartite and tripartite levels for examples (2a) and (2b) from the JOKES AND ANEC-DOTES stories Clever Hans and The Valiant Little Tailor, while our classifier captures the affective differences by considering, e.g. distinctions in verb count, interjection, POS, sentence length, connotations, story subtype, and conjunctions.</p><p>Next, we intend to use a larger data set to conduct a more complete study to establish mature findings.</p><p>We also plan to explore finer emotional meaning distinctions, by using a hierarchical sequential model which better corresponds to different levels of cognitive difficulty in emotional categorization by humans, and to classify the full set of basic level emotional categories discussed in section 4.3. Sequential modeling of simple classifiers has been successfully employed to question classification, for example by <ref type="bibr" target="#b12">(Li and Roth, 2002)</ref>. In addition, we are working on refining and improving the feature set, and given more data, tuning can be improved on a sufficiently large development set. The three subcorpora in the annotation project can reveal how authorship affects emotion perception and classification.</p><p>Moreover, arousal appears to be an important dimension for emotional prosody <ref type="bibr" target="#b18">(Scherer, 2003)</ref>, especially in storytelling <ref type="bibr" target="#b1">(Alm and Sproat, 2005)</ref>. Thus, we are planning on exploring degrees of emotional intensity in a learning scenario, i.e. a problem similar to measuring strength of opinion clauses <ref type="bibr" target="#b23">(Wilson, Wiebe and Hwa, 2004)</ref>.</p><p>Finally, emotions are not discrete objects; rather they have transitional nature, and blend and overlap along the temporal dimension. For example, <ref type="bibr" target="#b13">(Liu, Lieberman and Selker, 2003)</ref> include parallel estimations of emotional activity, and include smooth-ing techniques such as interpolation and decay to capture sequential and interactive emotional activity. Observations from tales indicate that some emotions are more likely to be prolonged than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper has discussed an empirical study of the text-based emotion prediction problem in the domain of children's fairy tales, with child-directed expressive text-to-speech synthesis as goal. Besides reporting on encouraging results in a first set of computational experiments using supervised machine learning, we have set forth a research agenda for tackling the TEP problem more comprehensively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1.</head><label></label><figDesc>First sentence in story 2. Conjunctions of selected features (see below) 3. Direct speech (i.e. whole quote) in sentence 4. Thematic story type (3 top and 15 sub-types) 5. Special punctuation (! and ?) 6. Complete upper-case word 7. Sentence length in words (0-1, 2-3, 4-8, 9and negative word counts ( ≥ 1, ≥ 2, ≥ 3, ≥ 4, ≥ 5, ≥ 6) 12. WordNet emotion words 13. Interjections and affective words 14. Content BOW: N, V, JJ, RB words by POS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Accuracy under different conditions (in %)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Basic emotions used in annotation</figDesc><table><row><cell cols="2">Abbreviation Emotion class</cell></row><row><cell>A</cell><cell>ANGRY</cell></row><row><cell>D</cell><cell>DISGUSTED</cell></row><row><cell>F</cell><cell>FEARFUL</cell></row><row><cell>H</cell><cell>HAPPY</cell></row><row><cell>Sa</cell><cell>SAD</cell></row><row><cell>Su+</cell><cell>POSITIVELY SURPRISED</cell></row><row><cell>Su-</cell><cell>NEGATIVELY SURPRISED</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Percent of annotated labels</figDesc><table><row><cell>A</cell><cell>D</cell><cell>F</cell><cell>H</cell></row><row><cell cols="4">12.34% 0.89% 7.03% 6.77%</cell></row><row><cell>N</cell><cell>SA</cell><cell>SU+</cell><cell>SU.-</cell></row><row><cell cols="4">59.94% 7.34% 2.59% 3.10%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>% EMOTIONAL vs. NEUTRAL examples</figDesc><table><row><cell>E</cell><cell>N</cell></row><row><cell cols="2">40.06% 59.94%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>% POSITIVE vs. NEGATIVE vs. NEUTRAL</figDesc><table><row><cell>PE</cell><cell>NE</cell><cell>N</cell></row><row><cell cols="3">9.87% 30.19% 59.94%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Mean classification accuracy: N vs. E, 2 conditions</figDesc><table><row><cell>same-tune-eval sep-tune-eval</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Classifying N vs. E (all features, sep-tune-eval)</figDesc><table><row><cell>Measure</cell><cell>N</cell><cell>E</cell></row><row><cell cols="3">Averaged accuracy 0.63 0.63</cell></row><row><cell>Averaged error</cell><cell cols="2">0.37 0.37</cell></row><row><cell cols="3">Averaged precision 0.66 0.56</cell></row><row><cell>Averaged recall</cell><cell cols="2">0.75 0.42</cell></row><row><cell>Averaged F-score</cell><cell cols="2">0.70 0.47</cell></row><row><cell cols="3">higher than recall for the combined EMOTION class.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>N, PE, and NE (all features, sep-tune-eval)   </figDesc><table><row><cell></cell><cell>N</cell><cell>NE PE</cell></row><row><cell cols="3">Averaged precision 0.64 0.45 0.13</cell></row><row><cell>Averaged recall</cell><cell cols="2">0.75 0.27 0.19</cell></row><row><cell>Averaged F-score</cell><cell cols="2">0.69 0.32 0.13</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Feature group members</figDesc><table><row><cell>Word lists</cell><cell>interj., WordNet, affective lists, pos/neg</cell></row><row><cell>Syntactic</cell><cell>length ranges, % POS, V-count ranges</cell></row><row><cell>Story-related</cell><cell>% story-progress, 1st sent., story type</cell></row><row><cell>Orthographic</cell><cell>punctuation, upper-case words, quote</cell></row><row><cell>Conjunctions</cell><cell>Conjunctions with pos/neg</cell></row><row><cell cols="2">Content BOW Words (N,V,Adj, Adv)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Available from http://l2r.cs.uiuc.edu/∼cogcomp/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Experiments were also run for Perceptron, however the results are not included. Overall, Perceptron performed worse.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Multi-words were transformed to hyphenated form.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">At this point, neither stems and bigrams nor a list of onomatopoeic words contribute to accuracy. Intermediate resource processing inserted some feature noise.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>We are grateful to the annotators, in particular A. Rasmussen and S. Siddiqui. We also thank two anonymous reviewers for comments. This work was funded by NSF under award ITR-#0205731, and NS ITR IIS-0428472. The annotation is supported by UIUC's Research Board. The authors take sole responsibility for the work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Antti</forename><surname>Aarne</surname></persName>
		</author>
		<title level="m">The Types of the Folk-Tale: a Classification and Bibliography</title>
				<meeting><address><addrLine>Helsinki</addrLine></address></meeting>
		<imprint>
			<publisher>Suomalainen Tiedeakatemia</publisher>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Perceptions of emotions in expressive storytelling</title>
		<author>
			<persName><forename type="first">Cecilia</forename><forename type="middle">O</forename><surname>Alm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Sproat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<publisher>INTERSPEECH</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Sentiment extraction from unstructured text using tabu searchenhanced Markov blankets</title>
		<author>
			<persName><forename type="first">Xue</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rema</forename><surname>Padman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edoardo</forename><surname>Airoldi</surname></persName>
		</author>
		<idno>MSW2004</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Seattle</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The sentimental factor: improving review classification via human-provided information</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Beineke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The generation of affect in synthesized Speech</title>
		<author>
			<persName><forename type="first">Janet</forename><surname>Cahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Voice I/O Society</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The SNoW Learning Architecture</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chad</forename><surname>Cumby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Rizzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno>UIUCDCS-R-99-2101</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>UIUC Comp. Sci</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Stacey</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cicco</forename></persName>
		</author>
		<ptr target="http://www.webuse.umd.edu:9090/" />
		<title level="m">General Inquirer Pos</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Facial expression and emotion</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="384" to="392" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predicting the semantic orientation of adjectives</title>
		<author>
			<persName><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<editor>
			<persName><forename type="first">Vasileios</forename><surname>Hatzivassiloglou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</editor>
		<meeting>ACL<address><addrLine>Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997">1998. 1997</date>
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
	<note>WordNet: An Electronic Lexical Database</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The language of emotions: an analysis of a semantic field</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Johnson-Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Oatley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="81" to="123" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized inference with multiple semantic role labeling systems</title>
		<author>
			<persName><forename type="first">Vasin</forename><surname>Peter Koomen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on Computational Language Learning (CoNLL)</title>
				<meeting>the Annual Conference on Computational Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting student emotions in computer-human tutoring dialogues</title>
		<author>
			<persName><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Forbes-Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning question classifiers: the role of semantic information</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computational Linguistics (COLING)</title>
				<meeting>International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="556" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A model of textual affect sensing using real-world knowledge</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Selker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Intelligent User Interfaces</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sentiment analysis using support vector machines with diverse information sources</title>
		<author>
			<persName><forename type="first">Tony</forename><surname>Mullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
				<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Affective computing</title>
		<author>
			<persName><forename type="first">Rosalind</forename><surname>Picard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to resolve natural language ambiguities: a unified approach</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="806" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Vocal communication of emotion: a review of research paradigms</title>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commununication</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="227" to="256" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Futoshi Sugimoto et al. 2004. A method to classify emotional expressions of text and synthesize speech</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Siegle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Oliver Steele</surname></persName>
		</author>
		<ptr target="http://osteele.com/projects/pywordnet/" />
	</analytic>
	<monogr>
		<title level="m">The Balanced Affective Word List</title>
				<imprint>
			<biblScope unit="page" from="611" to="614" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Applications of computer generated expressive speech for communication disorders</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Van Santen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUROSPEECH 2003</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1657" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning subjective language</title>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="308" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Just how mad are you? Finding strong and weak opinion clauses</title>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI)</title>
				<meeting>the Nineteenth National Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
