<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Approximate Optimal Control Approach for Robust Stabilization of a Class of Discrete-Time Nonlinear Systems With Uncertainties</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Ding</forename><surname>Wang</surname></persName>
							<email>ding.wang@ia.ac.cn</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Derong</forename><surname>Liu</surname></persName>
							<email>derong@ustb.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Hongliang</forename><surname>Li</surname></persName>
							<email>hongliang.li625@foxmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Biao</forename><surname>Luo</surname></persName>
							<email>biao.luo@ia.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">Hongwen</forename><surname>Ma</surname></persName>
							<email>mahongwen2012@ia.ac.cn</email>
						</author>
						<author>
							<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">B</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">H</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName><surname>Ma</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">are with the State Key Laboratory of Management and Control for Complex Systems</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology Beijing</orgName>
								<address>
									<postCode>100083</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">IBM Research-China</orgName>
								<address>
									<postCode>100193</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Approximate Optimal Control Approach for Robust Stabilization of a Class of Discrete-Time Nonlinear Systems With Uncertainties</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CE2B3DF91290463BC29D9EB889811252</idno>
					<idno type="DOI">10.1109/TSMC.2015.2466191</idno>
					<note type="submission">received July 20, 2014; revised December 15, 2014 and March 31, 2015; accepted May 18, 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adaptive dynamic programming (ADP)</term>
					<term>generalized Hamilton-Jacobi-Bellman (GHJB) equation</term>
					<term>neural networks</term>
					<term>optimal control</term>
					<term>robust control</term>
					<term>successive approximation method</term>
					<term>uncertainties</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this correspondence paper, the robust stabilization of a class of discrete-time nonlinear systems with uncertainties is investigated by using an approximate optimal control approach. The robust control problem is transformed into an optimal control problem under some proper restrictions on the bound of the uncertainties. For the purpose of dealing with the transformed optimal control, the discrete-time generalized Hamilton-Jacobi-Bellman equation is introduced and then solved using the successive approximation method with neural network implementation. In addition, a numerical simulation is included to illustrate the effectiveness of the robust control strategy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>It is known that the model uncertainties must be considered during the controller design process since they may cause deterioration of the control systems. In general, we say a controller is robust if it works even if the actual system deviates from its nominal model based on which the controller is designed. In fact, the robustness of control systems has been attended and studied by control scientists for many years. Robust control has become an important topic of modern control theory <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. Lin et al. <ref type="bibr" target="#b2">[3]</ref> pointed out that under proper restricted conditions, the robust control problem can be converted into an optimal control problem. Though the detailed operation procedure was not given, it provided an alternative method to deal with the robust stabilization problem. Thus, optimal control methods can be employed to design robust controllers. In fact, the research on linear optimal control has matured during the last several decades. However, when studying the nonlinear optimal control problem, we have to solve the Hamilton-Jacobi-Bellman (HJB) equation, which is often a difficult task. Therefore, some indirect methods have been proposed in order to overcome the difficulty in solving the nonlinear HJB equation. In <ref type="bibr" target="#b3">[4]</ref>, a recursive method was employed to deal with the optimal control problem for continuous-time nonlinear systems by successively solving the generalized HJB (GHJB) equation. The GHJB equation, which gives the cost of an arbitrary control law, can be used to improve the performance of this control and to approximate the HJB equation successively as well. In <ref type="bibr" target="#b4">[5]</ref>, adaptive (or approximate) dynamic programming (ADP) was presented to solve the optimal control problem, mainly for discrete-time nonlinear systems, based on function approximation structures such as neural networks. In recent years, the research on optimal control based on GHJB formulation and the ADP approach has acquired much attention from scholars <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Specifically, ADP has become one of the key directions for future research in intelligent control and understanding intelligence.</p><p>Recently, by taking Taylor series expansion of the cost function, Chen and Jagannathan <ref type="bibr" target="#b10">[11]</ref> and Jagannathan <ref type="bibr" target="#b11">[12]</ref> applied the GHJB formulation to study the optimal control of discrete-time affine nonlinear systems, while the system uncertainties were not taken into consideration. Even so, it is meaningful that the discrete-time GHJB equation and the related discrete-time HJB equation are well-defined. Therefore, the application scope of the GHJB-formulation-based method is greatly extended. In addition, it presents another effective way to solve the constrained optimal control problem of discretetime nonlinear systems <ref type="bibr" target="#b12">[13]</ref>. After that, Adhyaru et al. <ref type="bibr" target="#b1">[2]</ref> studied the bounded robust control of continuous-time constrained nonlinear systems with uncertainties by deriving the neural-network-based HJB solution, but the proposed approach was not suitable for discrete-time systems. Therefore, in this correspondence paper, we will investigate the robust stabilization of a class of discrete-time nonlinear systems with uncertainties using the discrete-time GHJBformulation-based optimal control approach. Remarkably, this paper extends <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>, which focuses on the GHJB-based optimal control for discrete-time affine nonlinear system, to robust controller design of uncertain nonlinear system. Additionally, this paper also develops a new robust control method for discrete-time nonlinear systems with uncertainties under the framework of the idea of ADP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROBLEM STATEMENT</head><p>In this paper, we study a class of discrete-time nonlinear systems described by</p><formula xml:id="formula_0">x k+1 = f (x k ) + g(x k )(u(x k ) + d(x k )) (1)</formula><p>where x k ∈ R n is the state vector, u(x k ) ∈ R m is the control vector, and f (•) and g(•) are differentiable in their arguments with f (0) = 0. In (1), the term g(x k )d(x k ) with d(x k ) ∈ R m is the unknown perturbation that represents the matched uncertainty of system dynamics. Note that in this paper, stability is always with respect to x = 0. In addition, it is assumed that d(x k ) is bounded by a known function</p><formula xml:id="formula_1">d M (x k ), that is d(x k ) ≤ d M (x k ), ∀k.<label>(2)</label></formula><p>Moreover, we assume that d(0) = 0, so that x = 0 is an equilibrium of system <ref type="bibr" target="#b0">(1)</ref>. It is also assumed that the bounded function</p><formula xml:id="formula_2">d 2 M (x) is differentiable and d M (0) = 0.</formula><p>Here, we aim at investigating the robust control problem for uncertain nonlinear systems <ref type="bibr" target="#b0">(1)</ref>. In other words, we should develop a 2168-2216 c 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.</p><p>See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>feedback control law u(x), such that the closed-loop system is globally asymptotically stable for all uncertainties d(x k ). In the following, we will display the result that this problem is closely related to the optimal controller design of the corresponding nominal system, with an appropriate choice of the cost function. Consider the nominal system with respect to system (1) given as follows:</p><formula xml:id="formula_3">x k+1 = f (x k ) + g(x k )u(x k ).</formula><p>(3)</p><p>For system (3), we assume that f + gu is Lipschitz continuous on a set in R n containing the origin. In addition, we assume the system is controllable, i.e., there exists a continuous control law on that can stabilize the system asymptotically.</p><p>When dealing with the optimal control of system (3), we desire to find the control law u(x) which minimizes the infinite horizon cost function</p><formula xml:id="formula_4">J(x k , u) = ∞ q=k ρd 2 M (x q ) + U(x q , u(x q )) .<label>(4)</label></formula><p>In ( <ref type="formula" target="#formula_4">4</ref>), ρ is a positive number and U(•, •) is the utility function with U(0, 0) = 0 and U(x q , u(x q )) ≥ 0 for any x q and u(x q ). In this paper, the utility function is chosen as the quadratic form U(x q , u(x q )) = x T q Qx q + u T (x q )Ru(x q ), where Q is a positive definite matrix and R is a symmetric positive definite matrix, all with suitable dimensions. Note that for the optimal control problem, the designed feedback control law must be admissible <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Now, we define the optimal cost function as follows:</p><formula xml:id="formula_5">J * (x k ) = min {u(•)} ∞ q=k ρd 2 M (x q ) + U(x q , u(x q ))<label>(5)</label></formula><p>where {u(•)} denotes the sequence of control input, i.e., u(x k ), u(x k+1 ), . . . . According to Bellman's optimality principle, we can obtain the discrete-time HJB equation</p><formula xml:id="formula_6">J * (x k ) = min u(x k ) ρd 2 M (x k ) + U(x k , u(x k )) + J * (x k+1 ) . (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>The corresponding optimal control u * is</p><formula xml:id="formula_8">u * (x k ) = - 1 2 R -1 g T (x k ) ∂J * (x k+1 ) ∂x k+1 . (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>Then, using the optimal control u * , the discrete-time HJB equation ( <ref type="formula" target="#formula_6">6</ref>) becomes</p><formula xml:id="formula_10">J * (x k ) = ρd 2 M (x k ) + U x k , u * (x k ) + J * f (x k ) + g(x k )u * (x k ) . (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>When studying the linear quadratic regulator problem, the discretetime HJB equation reduces to the Riccati equation that can be solved efficiently. However, for the general nonlinear problem, it is not the case. Furthermore, the optimal control u * (x k ) is related to x k+1 and J * (x k+1 ), which cannot be determined at present time step k. Hence, in the following, we will employ the GHJB formulation to deal with the optimal control design problem. Moreover, the robust controller for system (1) can be established based on the optimal controller.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ROBUST CONTROLLER DESIGN BASED ON OPTIMAL</head><p>CONTROL APPROACH USING DISCRETE-TIME GHJB FORMULATION In this section, the discrete-time GHJB equation considering the modified cost function is defined first. Then, the successive approximation method is developed to solve the discrete-time GHJB equation and a neural network is constructed for facilitating the implementation, which results in an approximate optimal control. At last, the approximate optimal controller of system ( <ref type="formula">3</ref>) is proved to be a robust stabilizer of system (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Discrete-Time GHJB Equation</head><p>In this part, motivated by the results of <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b6">[7]</ref> for continuoustime systems and <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref> for discrete-time systems, the discretetime GHJB equation with the modified cost function is considered.</p><p>Lemma 1: Given an admissible control μ(x) ∈ u ( u is the set of admissible controls) for system (3), there exists a positive definite and continuously differentiable function V(x) satisfying V(x 0 ) = J(x 0 , μ) if the following equation holds:</p><formula xml:id="formula_12">ρd 2 M (x) + U(x, μ(x)) + (∇V(x)) T ( f (x) + g(x)μ(x) -x) + 1 2 ( f (x) + g(x)μ(x) -x) T ∇ 2 V(x) × ( f (x) + g(x)μ(x) -x) = 0, V(0) = 0 ( 9 )</formula><p>where 2 is the Hessian matrix given as</p><formula xml:id="formula_13">∇V(x) = ∂V(x)/∂x and ∇ 2 V(x) = ∂ 2 V(x)/∂x</formula><formula xml:id="formula_14">∇ 2 V(x) = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ ∂ 2 V(x) ∂x 2 1 ∂ 2 V(x) ∂x 1 x 2 • • • ∂ 2 V(x) ∂x 1 x n ∂ 2 V(x) ∂x 2 x 1 ∂ 2 V(x) ∂x 2 2 • • • ∂ 2 V(x) ∂x 2 x n . . . . . . . . . . . . ∂ 2 V(x) ∂x n x 1 ∂ 2 V(x) ∂x n x 2 • • • ∂ 2 V(x) ∂x 2 n ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ . (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>Proof: Assume that a positive definite V(x) exists and is continuously differentiable. Besides, assume that the high-order terms of the Taylor series expansion of V(x) are small and can be neglected. Since μ is admissible,</p><formula xml:id="formula_16">x k = 0 and V(x k ) = 0 when k → ∞. Denoting V(x k ) = V(x k+1 ) -V(x k ) ≈ (∇V(x k )) T ( f (x k ) + g(x k )μ(x k ) -x k ) + 1 2 ( f (x k ) + g(x k )μ(x k ) -x k ) T ∇ 2 V(x k ) × ( f (x k ) + g(x k )μ(x k ) -x k ) (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>where</p><formula xml:id="formula_18">∇V(x k ) = ∇V(x)| x=x k , ∇ 2 V(x k ) = ∇ 2 V(x)| x=x k</formula><p>, and considering ( <ref type="formula" target="#formula_4">4</ref>) and ( <ref type="formula">9</ref>), we can easily find that V(x k ) = J(x k , μ) based on the proof of <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>.</p><p>In view of Lemma 1, the positive definite function V(x) is also the value function of the optimal control problem, with admissible control being introduced. Now, we define the discrete-time GHJB equation for system (3) as follows:</p><formula xml:id="formula_19">GHJB(V(x), μ(x)) ρd 2 M (x) + U(x, μ(x)) + (∇V(x)) T × ( f (x) + g(x)μ(x) -x) + 1 2 ( f (x) + g(x)μ(x) -x) T ∇ 2 V(x) × ( f (x) + g(x)μ(x) -x) = 0 V(0) = 0. (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>The Hamiltonian function for system (3) is</p><formula xml:id="formula_21">H(x, μ(x), V(x)) = ρd 2 M (x) + U(x, μ(x)) + (∇V(x)) T × ( f (x) + g(x)μ(x) -x) + 1 2 ( f (x) + g(x)μ(x) -x) T ∇ 2 V(x) × ( f (x) + g(x)μ(x) -x). (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>The optimal value V * (x) associated with the discrete-time GHJB equation ( <ref type="formula" target="#formula_19">12</ref>) satisfies</p><formula xml:id="formula_23">0 = min μ∈ u H(x, μ(x), V * (x)). (<label>14</label></formula><formula xml:id="formula_24">)</formula><p>Similar as <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>, we observe that g T (x)∇ 2 V * (x)g(x) + 2R is positive definite. In this sense, the optimal control is</p><formula xml:id="formula_25">μ * (x) = arg min μ∈ u H(x, μ(x), V * (x)) = -g T (x)∇ 2 V * (x)g(x) + 2R -1 g T (x) × ∇V * (x) + ∇ 2 V * (x)( f (x) -x) . (<label>15</label></formula><formula xml:id="formula_26">)</formula><p>As a result, by substituting the optimal control (15) into the discretetime GHJB equation ( <ref type="formula" target="#formula_19">12</ref>), we can obtain the approximate version of the discrete-time HJB equation as follows:</p><formula xml:id="formula_27">ρd 2 M (x) + U(x, μ * (x)) + (∇V * (x)) T ( f (x) + g(x)μ * (x) -x) + 1 2 ( f (x) + g(x)μ * (x) -x) T ∇ 2 V * (x) × ( f (x) + g(x)μ * (x) -x) = 0, V * (0) = 0. (<label>16</label></formula><formula xml:id="formula_28">)</formula><p>Remark 1: It is worth emphasizing that the discrete-time HJB equation ( <ref type="formula" target="#formula_27">16</ref>) is attained under the framework of discrete-time GHJB equation. Actually, it can be regarded as an approximate version of the ideal HJB equation ( <ref type="formula" target="#formula_10">8</ref>) by carrying out the Taylor series expansion. In addition, the optimal control (15) is also an approximation of the ideal optimal control (7) to a certain degree. That is to say, V * and μ * are approximate results of J * and u * , respectively. It is in this sense that μ * (x k ) can be expressed in terms of x k , not x k+1 . For this reason, the optimal control is available.</p><p>Remark 2: Incidentally, though errors inevitably exist during the approximation operations, it is applicable when the high-order terms of Taylor series expansion of the cost function are small. Therefore, the next focal point is designing V * and μ * on the basis of discretetime GHJB formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Approximation Method and Neural Network Implementation</head><p>In this part, the successive approximation method based on the discrete-time GHJB equation is introduced. The main idea is to construct two sequences, i.e., {μ (i) } and {V (i) }, where i = 0, 1, 2, . . . , such that μ (i) → μ * and V (i) → V * as i → ∞.</p><p>Generally speaking, if a control function μ (i) (μ (i) ∈ u ) and a cost function V (i) satisfy relationship that GHJB(V (i) , μ (i) ) = 0, an updated control can be derived by differentiating H(x, μ (i+1) (x), V (i) (x)) = 0 with respect to μ (i+1) . Then, we have</p><formula xml:id="formula_29">μ (i+1) (x) = -g T (x)∇ 2 V (i) (x)g(x) + 2R -1 g T (x) × ∇V (i) (x) + ∇ 2 V (i) (x)( f (x) -x) . (17)</formula><p>In the following, two lemmas are given to show that the updated control function μ (i+1) is admissible and the related cost function is reduced under its action.</p><p>Lemma 2: If μ (i) (x) ∈ u , x 0 ∈ , and the positive definite and continuously differentiable cost function V (i) satisfies GHJB(V (i) , μ (i) ) = 0 with V (i) (0) = 0, the updated control obtained by ( <ref type="formula">17</ref>) is an admissible control for system (3) on . In addition, if V (i+1) is the unique positive definite function satisfying the relationship that GHJB(V (i+1) , μ (i+1) ) = 0, then we have</p><formula xml:id="formula_30">V (i+1) (x 0 ) ≤ V (i) (x 0 ).</formula><p>Lemma 3: Given an initial control μ (0) ∈ u , by solving GHJB(V (i) , μ (i) ) = 0 and updating the control via (17) with i = 0, 1, 2, . . . , the sequence</p><formula xml:id="formula_31">{V (i) } is convergent as i → ∞, i.e., V (i) → V * as i → ∞. Furthermore, μ (i) → μ * as i → ∞.</formula><p>Remark 3: In this paper, Lemmas 2 and 3 can be easily obtained according to the convergence proof of <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>. However, it should be noted that the modified utility function</p><formula xml:id="formula_32">ρd 2 M (x k ) + U(x k , μ(x k )) is employed instead of the traditional one U(x k , μ(x k )).</formula><p>This reflects the distinguishing feature of the transformed optimal control problem when dealing with the robust control of uncertain nonlinear system. Note that the discrete-time GHJB equation is easier to deal with than the discrete-time HJB equation in theory, but the closed-form solution still cannot be obtained. Hence, in this part, a neural network is constructed to solve the discrete-time GHJB equation, so that a control function in feedback form can be developed.</p><p>In view of the property that neural networks can be employed to approximate smooth functions on a prescribed compact set, the cost function V(x) can be approximated by a neural network as follows:</p><formula xml:id="formula_33">V(x) = ωT c σ c (x) = l j=1 ωcj σ cj (x) (<label>18</label></formula><formula xml:id="formula_34">)</formula><p>where ωc = [ ωc1 , ωc2 , . . . , ωcl ] T is the weight vector, σ c (x) = [σ c1 (x), σ c2 (x), . . . , σ cl (x)] T is the activation function, which is assumed to be second-order differentiable, and l is the number of neurons in the hidden layer, respectively. Note that for any j = 1, 2, . . . , l, the activation function σ cj (x) is continuous and satisfies σ cj (x) = 0 when x = 0. Moreover, the set {σ cj (x)} with j = 1, 2, . . . , l is linearly independent.</p><p>The weight vector of the neural network will be trained to minimize the residual error in a least squares sense. Substituting (18) into GHJB(V, μ) = 0, we obtain the discrete-time GHJB equation with a residual error as</p><formula xml:id="formula_35">GHJB ⎛ ⎝ V(x) = l j=1 ωcj σ cj (x), μ ⎞ ⎠ e c (x). (<label>19</label></formula><formula xml:id="formula_36">)</formula><p>Here, the method of weighted residuals is adopted in order to derive the least squares solution. For any x ∈ , the weight vector ωc can be acquired by projecting the residual error onto ∂e c (x)/∂ ωc and letting the result be zero, which can be expressed as</p><formula xml:id="formula_37">∂e c (x) ∂ ωc , e c (x) = 0.<label>(20)</label></formula><p>In (20), the inner product a(x), b(x) is defined as the Lebesgue integral, i.e., a(x), b(x) = a(x)b(x)dx. When solving ωc by expanding (20), the integration is computationally difficult to acquire directly. Instead, an approximate result using the definition of Riemann integration is available. To do this, a mesh with p points over the integral region on is introduced and they are x 1 , x 2 , . . . , x p . Here, the size of the mesh is denoted as x, which should be chosen as a tradeoff between accuracy and computational complexity. In addition, the number of points in the mesh should satisfy p &gt; l. Define</p><formula xml:id="formula_38">A = δ T (x) x=x 1 , δ T (x) x=x 2 , . . . , δ T (x) x=x p T B = η(x)| x=x 1 , η(x)| x=x 2 , . . . , η(x)| x=x p T . (<label>21</label></formula><formula xml:id="formula_39">)</formula><formula xml:id="formula_40">In (21), δ(x) = [δ 1 (x), δ 2 (x), . . . , δ l (x)] T</formula><p>, where</p><formula xml:id="formula_41">δ i (x) = ∇σ T ci (x)( f (x) + g(x)μ(x) -x) + 1 2 ( f (x) + g(x)μ(x) -x) T ∇ 2 σ ci (x)( f (x) + g(x)μ(x) -x), i = 1, 2, . . . , l<label>(22)</label></formula><p>and</p><formula xml:id="formula_42">η(x) = d 2 M (x) + U(x, μ(x)). Then, we have ωc = -A T A -1 A T B (<label>23</label></formula><formula xml:id="formula_43">)</formula><p>which implies that the weight vector of the neural network can be obtained effectively. Additionally, by using (18), the control function related to V(x) can also be derived, that is</p><formula xml:id="formula_44">μ(x) = -g T (x)∇ 2 V(x)g(x) + 2R -1 g T (x) × ∇ V(x) + ∇ 2 V(x)( f (x) -x) (<label>24</label></formula><formula xml:id="formula_45">)</formula><p>where V(x) = ωT c σ c (x). This is the approximate control function associated with the immediate weight vector. If we get the convergent weight vector, we can therefore acquire the approximate optimal control of system <ref type="bibr" target="#b2">(3)</ref>. Now, we present in detail the design procedure of nonlinear optimal control scheme based on the discrete-time GHJB formulation and neural network.</p><p>Step 1: Specify a small positive constant ε and a sufficiently large integer i max . Construct a neural network to approximate the cost function as V(x) = ωT c σ c (x). Set i = 0 and select an initial admissible control μ (0) (x).</p><p>Step 2: Apply the least squares method to deal with the equation GHJB( V(0) , μ (0) ) = 0, and obtain the weight vector ω(0) c and the cost function V(0) (x). Then, update the control function by using</p><formula xml:id="formula_46">μ(i+1) (x) = -g T (x)∇ 2 V(i) (x)g(x) + 2R -1 g T (x) × ∇ V(i) (x) + ∇ 2 V(i) (x)( f (x) -x) (25)</formula><p>where</p><formula xml:id="formula_47">V(i) (x) = ω(i)T c σ c (x). Step 3: Set i = i + 1.</formula><p>Step 4: Solve GHJB( V(i) , μ(i) ) = 0, obtain the weight vector ω(i)</p><formula xml:id="formula_48">c</formula><p>and the cost function V(i) (x), and then derive the updated control μ(i+1) (x) based on (25).</p><p>Step 5: If V(i) (x) -V(i-1) (x) ≤ ε, go to step 7; otherwise, go to step 6.</p><p>Step 6: If i &gt; i max , go to step 7; otherwise, go to step 3.</p><p>Step 7: Stop. After the neural network implementation process, the approximate optimal cost function V * and approximate optimal control μ * for the nominal system (3) are obtained. Next, we prove that μ * is a robust feedback control of system <ref type="bibr" target="#b0">(1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Derivation of Robust Controller</head><p>In this section, we show in theory that the approximate optimal controller of system (3) is a robust stabilizer of uncertain system (1). This is the main result of the paper.</p><p>Theorem 1: For the nominal system (3) with the cost function (4), assume the solution of the discrete-time HJB equation exists. Then, the control function μ * ensures closed-loop locally asymptotic stability of uncertain nonlinear system (1) if the condition</p><formula xml:id="formula_49">ρd 2 M (x k ) ≥ d T (x k )Rd(x k ) + 1 2 (g(x k )d(x k )) T ∇ 2 V * (x k )g(x k )d(x k )<label>(26)</label></formula><p>is satisfied.</p><p>Proof: Let V * (x) be the approximate solution of the discrete-time HJB equation and μ * (x) be the approximate optimal control by using the neural-network-based discrete-time GHJB formulation. Now, we prove that μ * (x) is a solution to the robust control problem, i.e., the equilibrium point x k = 0 of system (1) is asymptotically stable for all possible uncertainties d(x k ).</p><p>Since V * (x) and μ * (x) satisfy the discrete-time HJB equation ( <ref type="formula" target="#formula_27">16</ref>), we can regard V * (x) as a positive definite function and we also obtain</p><formula xml:id="formula_50">∇ V * (x k ) T f (x k ) + g(x k ) μ * (x k ) -x k + 1 2 ( f (x k ) + g(x k ) μ * (x k ) -x k ) T ∇ 2 V * (x k ) ×( f (x k ) + g(x k ) μ * (x k ) -x k ) = -ρd 2 M (x k ) -U x k , μ * (x k ) . (<label>27</label></formula><formula xml:id="formula_51">)</formula><p>In addition, when considering V * and μ * , the formula (24) suggests that</p><formula xml:id="formula_52">g T (x k )∇ 2 V * (x k )g(x k ) + 2R μ * (x k ) + g T (x k ) × ∇ V * (x k ) + ∇ 2 V * (x k )( f (x k ) -x k ) = 0. (28)</formula><p>Obviously, (28) implies that</p><formula xml:id="formula_53">f (x k ) + g(x k ) μ * (x k ) -x k T ∇ 2 V * (x k )g(x k ) + ∇ V * (x k ) T g(x k ) + 2 μ * (x k ) T R = 0. (<label>29</label></formula><formula xml:id="formula_54">)</formula><p>Note that the difference of the approximate optimal cost function V * is</p><formula xml:id="formula_55">V * (x k ) = V * (x k+1 ) -V * (x k ) ≈ ∇ V * (x k ) T f (x k ) + g(x k ) μ * (x k ) + g(x k )d(x k ) -x k + 1 2 f (x k ) + g(x k ) μ * (x k ) + g(x k )d(x k ) -x k T × ∇ 2 V * (x k ) f (x k ) + g(x k ) μ * (x k ) + g(x k )d(x k ) -x k . (<label>30</label></formula><formula xml:id="formula_56">)</formula><p>Considering ( <ref type="formula" target="#formula_50">27</ref>) and (29), we can obtain that (30) becomes</p><formula xml:id="formula_57">V * (x k ) = -ρd 2 M (x k ) -U x k , μ * (x k ) + f (x k ) + g(x k ) μ * (x k ) -x k T ∇ 2 V * (x k ) × g(x k )d(x k ) + ∇ V * (x k ) T g(x k )d(x k ) + 1 2 (g(x k )d(x k )) T ∇ 2 V * (x k )g(x k )d(x k ) = -ρd 2 M (x k ) -U x k , μ * (x k ) -2 μ * (x k ) T Rd(x k ) + 1 2 (g(x k )d(x k )) T ∇ 2 V * (x k )g(x k )d(x k ). (<label>31</label></formula><formula xml:id="formula_58">)</formula><p>By adding and subtracting d T (x k )Rd(x k ) to (31), we can further obtain</p><formula xml:id="formula_59">V * (x k ) = -ρd 2 M (x k ) -x T k Qx k + d T (x k )Rd(x k ) + 1 2 (g(x k )d(x k )) T ∇ 2 V * (x k )g(x k )d(x k ) -μ * (x k ) + d(x k ) T R μ * (x k ) + d(x k ) ≤ -ρd 2 M (x k ) -d T (x k )Rd(x k ) - 1 2 (g(x k )d(x k )) T ∇ 2 V * (x k )g(x k )d(x k ) -x T k Qx k . (<label>32</label></formula><formula xml:id="formula_60">)</formula><p>Considering (26), we can conclude that V * (x k ) ≤ -x T k Qx k &lt; 0 for any x k = 0. Therefore, V * is a Lyapunov function and the conditions for Lyapunov local stability theory are satisfied. The proof is completed.</p><p>The developed robust control strategy is feasible because of the powerfulness of the GHJB-formulation-based optimal control approach. In the following, an example will be taken to demonstrate its effectiveness.</p><p>IV. SIMULATION Consider the following discrete-time nonlinear system: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .Fig. 3 .</head><label>123</label><figDesc>Fig. 1. Simulation results. Convergence process of the (a) norm of weight vector and (b) cost function sequence.</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 61034002, Grant 61233001, Grant 61273140, and Grant 61304086, and in part by the Early Career Development Award of the State Key Laboratory of Management and Control for Complex Systems. This paper was recommended by Associate Editor A.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>which represents the unknown perturbation with ϑ ∈ [-0.5, 0.5] for simplicity. We choose d M (x k ) = x k , which clearly satisfies the bounded condition <ref type="bibr" target="#b1">(2)</ref>. According to the aforementioned results, the robust stabilization problem can be transformed into the optimal control problem of the nominal system. By selecting ρ = 1, Q = I 2 , and R = I, where I denotes the identity matrix with a suitable dimension, the cost function is defined as</p><p>In order to apply the discrete-time GHJB formulation to obtain the approximate optimal control, a neural network is constructed as follows:</p><p>V</p><p>During the implementation process, the mesh size is set as x = 0.02. The initial state vector and the initial control are chosen as x 0 = [-0.5, 0.5] T and μ (0) (x) = 0.5x 2 , respectively. After five iterations, the weight vector of the neural network converges to ω * c = [2.5456, 0, 1.6993, -0.9181, 0, -0.5532, 0, -0.7105, 0.1940, 0, 0.1197, 0, 0.1080, 0, 0.1497] T . The convergence process of the norm of weight vector is depicted in Fig. <ref type="figure">1(a)</ref>. Besides, the convergence of the cost function sequence is displayed in Fig. <ref type="figure">1(b)</ref>. Then, the approximate optimal control μ * of the nominal system is derived, which according to Theorem 1, is also the robust control of the uncertain system (33). Now, we apply the robust control μ * to system (33) for ten time steps. Fig. <ref type="figure">2</ref>(a) and (b) exhibits the state trajectory and control trajectory, respectively, when setting ϑ = 0.5. Besides, Fig. <ref type="figure">3</ref>(a) and (b) exhibits the state trajectory and control trajectory, respectively, when setting ϑ = -0.5. The simulation results illustrate that the established approximate optimal control ensures closed-loop asymptotic stability of the controlled plant.</p><p>V. CONCLUSION A robust control strategy of a class of affine discrete-time nonlinear systems with uncertainties is established based on the optimal control approach using discrete-time GHJB formulation. By transforming the robust control problem into the optimal control problem, the discretetime GHJB equation is introduced and solved through the successive approximation method. Additionally, the detailed design procedure via neural network is given, while the numerical simulation is also provided to verify the control performance. In our future work, the robust control of affine discrete-time nonlinear systems under uncertain and unknown environment will be studied by employing the ADP-based optimal control approach. In addition, more comparisons with other traditional robust stabilization methods will be studied in the future.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust nonlinear control of an intrinsically complicant robotic gait training orthosis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Syst</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="655" to="665" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bounded robust control of nonlinear systems using neural network-based HJB solution</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Adhyaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="103" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust control of nonlinear systems: Compensating for uncertainty</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1453" to="1459" />
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Galerkin approximations of the generalized Hamilton-Jacobi-Bellman equation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Beard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Saridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2159" to="2177" />
			<date type="published" when="1996-08">Aug. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Approximate dynamic programming for real-time control and neural modeling</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Intelligent Control: Neural, Fuzzy, and Adaptive Approaches</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>White</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sofge</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Van Nostrand Reinhold</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>ch. 13</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reinforcement learning and feedback control: Using natural decision methods to design optimal adaptive controllers</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vrabie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Control Syst. Mag</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="76" to="105" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nearly optimal state feedback of constrained nonlinear systems using a neural network HJB approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abu-Khalaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Control</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="251" />
			<date type="published" when="2004-01">Jan. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neuro-optimal control for a class of unknown nonlinear dynamic systems using SN-DHP technique</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="218" to="225" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Policy iteration algorithm for online design of robust control for a class of continuous-time nonlinear systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="627" to="632" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural-network-based robust optimal control design for a class of uncertain nonlinear systems via adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">282</biblScope>
			<biblScope unit="page" from="167" to="179" />
			<date type="published" when="2014-10">Oct. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized Hamilton-Jacobi-Bellman formulation-based neural network control of affine nonlinear discretetime systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="106" />
			<date type="published" when="2008-01">Jan. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural network control in discrete-time using Hamilton-Jacobi-Bellman formulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jagannathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Network Control of Nonlinear Discrete-Time Systems, S. Jagannathan</title>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>ch. 9</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Constrained optimal control of affine nonlinear discrete-time systems using GHJB method</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp</title>
		<meeting>IEEE Symp<address><addrLine>Nashville, TN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-03">Mar. 2009</date>
			<biblScope unit="page" from="16" to="21" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
