<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Prediction to Accelerate Coherence Protocols</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shubhendu</forename><forename type="middle">S</forename><surname>Mukherjee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<addrLine>1210 West Dayton Street</addrLine>
									<postCode>53706-1685</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
							<email>markhill@cs.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<addrLine>1210 West Dayton Street</addrLine>
									<postCode>53706-1685</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Prediction to Accelerate Coherence Protocols</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6171913B2CD005F575D7BAA1AAD009BA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most large shared-memory multiprocessors use directory protocols to keep per-processor caches coherent. Some memory references in such systems, however, suffer long latencies for misses to remotelycached blocks. To ameliorate this latency, researchers have augmented standard coherence protocols with optimizations for specific sharing patterns, such as read-modify-write, producer-consumer, and migratory sharing. This paper seeks to replace these directed solutions with general prediction logic that monitors coherence activity and triggers appropriate coherence actions. This paper takes the first step toward using general prediction to accelerate coherence protocols by developing and evaluating the Cosmos coherence message predictor. Cosmos predicts the source and type of the next coherence message for a cache block using logic that is an extension of Yeh and Patt's two-level PAp branch predictor. For five scientific applications running on 16 processors, Cosmos has prediction accuracies of 62% to 93%. Cosmos' high prediction accuracy is a result of predictable coherence message signatures that arise from stable sharing patterns of cache blocks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most shared-memory multiprocessors accelerate memory accesses using per-processor caches. Caches are usually made transparent to software with a cache coherence protocol. Most large shared-memory multiprocessors use directory protocols <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b18">19]</ref>. Directory protocols maintain a directory entry per memory block that records which processor(s) currently cache the block. On a miss, a processor sends a coherence message over an interconnect to a directory, which often forwards message(s) to processor(s) currently caching the block. These processors may forward data or acknowledgments to the requesting processor and/or directory.</p><p>Unfortunately, this cache miss and directory activity can disturb a programmer's performance model of shared memory by making some memory accesses tens to hundreds of times slower than others. This problem has led to many proposals, including weaker memory models <ref type="bibr" target="#b1">[2]</ref>, multithreading <ref type="bibr" target="#b35">[36]</ref>, non-blocking caches <ref type="bibr" target="#b17">[18]</ref>, and applicationspecific coherence protocols <ref type="bibr" target="#b26">[27]</ref>. To date, all proposals possess one or more of the following drawbacks: require a more complex programmer interface or model, retard uniprocessor performance, or require sophisticated compilers.</p><p>Another class of proposals predict future sharing patterns <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref> and take actions to overlap coherence message activity with current work. Predictions can be made by programmers <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b24">25]</ref>, compilers <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b14">15]</ref>, software <ref type="bibr" target="#b3">[4]</ref>, or hardware. Specialized predictors in hardware include read-modify-write operation prediction in the SGI Origin protocol <ref type="bibr" target="#b18">[19]</ref>, pair-wise sharing prediction in SCI <ref type="bibr" target="#b33">[34]</ref>, dynamic self-invalidation <ref type="bibr" target="#b19">[20]</ref>, and migratory protocols <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35]</ref>. Other examples of hardware predictors are described in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28]</ref>. Existing predictors, however, are directed at specific sharing patterns known a priori. Furthermore, a protocol implementation is often made more complex by intertwining predictors with the standard coherence protocol.</p><p>This paper seeks a more general predictor to accelerate coherence protocols. Predictors would sit beside each standard directory and cache module to monitor coherence activity and request appropriate actions. If a directory predictor, for example, anticipates that a processor asking for a block B "shared" will subsequently ask for block B "exclusive," the directory can answer the "shared" request with block B "exclusive."</p><p>The first contribution of this paper is the design of the Cosmos coherence message predictor for accelerating coherence protocols (Section 3). Cosmos' design is inspired by Yeh and Patt's two-level PAp branch predictor <ref type="bibr" target="#b38">[39]</ref>. Cosmos makes a prediction in two steps. First, it uses a cache block address to index into a Message History Table to obtain one or more &lt;processor,message-type&gt; tuples. These &lt;processor,message-type&gt; tuples correspond to sender and message type of the last few coherence messages received for that cache block. Message-type identifies specific coherence actions for a sharing pattern, whereas processor identifies the specific sharers involved in the sharing pattern. Second, Cosmos uses these &lt;processor,message-type&gt; tuples to index a Pattern History Table to obtain a &lt;processor,message-type&gt; prediction. Notably, Cosmos faces a greater challenge than branch predictors because the Cosmos' prediction is a multi-bit &lt;processor,message-type&gt; tuple rather than a single bit branch outcome. This paper concentrates on coherence protocol message prediction in isolation (analogous to studying branch prediction in isolation). We do not integrate the Cosmos predictor into a coherence protocol for two reasons. First, our tools are not ready to handle a full timing simulation of a protocol that can be accelerated using prediction. Second, we do not want initial results in this area obscured by implementation idiosyncrasies. Nevertheless, we expect such integration to be successful because the integration of directed predictions has been successful <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b34">35]</ref>. Section 4 briefly discusses possibilities for such integration.</p><p>The second contribution of this paper is a detailed evaluation of the Cosmos coherence message predictor. Section 5 states methodological assumptions, including the use of five scientific benchmarks on a target shared-memory machine with 16 processors running the Stache directory protocol <ref type="bibr" target="#b29">[30]</ref>. Section 6 gives Cosmos' prediction rates and analyzes application details. Variations of Cosmos predict the source and type of the next coherence message with surprisinglyhigh accuracies of 62-69% (barnes), 84-86% (moldyn), 84-85% (appbt), 74-92% (unstructured), and 84-93% (dsmc). Cosmos' high prediction accuracy results from predictable coherence message pat-terns or signatures associated with specific cache block addresses. Such signatures are generated by sharing patterns <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref> that do not change or change very slowly during the execution of these applications. Cosmos' lower accuracy for barnes occurs because barnes periodically re-builds its principal data structure (an octree), thereby moving logical nodes (with stable sharing patterns) to different memory addresses (obscuring sharing patterns from Cosmos). Section 7 explores the implications of Cosmos. Coherence message prediction works because sharing patterns are often stable. Others have exploited sharing patterns with directed optimizations, such as dynamic self-invalidation and migratory protocols. Using Cosmos could be better (or worse) than directed predictors due to performance and implementation issues. Cosmos can perform better because it can discover and track application-specific patterns not known a priori (e.g., as occurs for unstructured). It can perform worse if it is slower to recognize known patterns. Cosmos' implementation complexity can be less because predictor logic is separated from the standard protocol logic (unlike previous directed predictors that are intertwined with the standard coherence protocol). Cosmos, however, is likely to require more state than directed optimizations. In summary (Section 8), Cosmos' high prediction accuracies justify more investigation into using prediction to accelerate coherence protocols.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>This section describes the structure of a basic directory protocol (Section 2.1) and reviews Yeh and Patt's two-level adaptive branch predictor (Section 2.2). In the next section we discuss how Cosmosa modified version of Yeh and Patt's two-level predictor-can predict a directory protocol's messages with high accuracy. Throughout the rest of the paper we will use the terms "node" and "processor" interchangeably because we consider only single-processor nodes to simplify our discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Structure of a Directory Protocol</head><p>Most large-scale shared-memory multiprocessors use a directory protocol to keep multiple caches coherent. A directory protocol associates state with both caches and memory. This state is typically maintained at a cache block (e.g., 32-128 bytes) granularity. The state associated with each memory block is referred to as a directory entry. The directory entry for each memory block records whether or not a memory block is idle (that is, no cached copies exist), a writable copy of the block exists, or one or more readable copies of the block exist.</p><p>To simplify our discussion we only consider a full-map and writeinvalidate directory protocol, such as the SGI Origin protocol <ref type="bibr" target="#b20">[21]</ref>. A directory entry in such a protocol maintains logical pointers to caches that hold a valid copy of the block and invalidates all outstanding copies of the block when one processor wishes to write to it. Similarly, a block in a cache is usually in one of three quiescent states: invalid, shared, or exclusive. These states define whether a processor's load or store can access the cache block. Processors must invoke coherence actions on loads to invalid blocks and on stores to shared (i.e. readonly) and invalid blocks.</p><p>A cache coherence protocol can, therefore, be viewed simply as a collection of finite-state machines that change state in response to processor accesses and external messages. For caches, state transitions occur in response to processor accesses and messages from the directory (and possibly other caches). A directory entry changes state in response to messages from caches. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of message exchange and state transitions in two caches and a directory.</p><p>Unfortunately, the finite-state machines that implement the coherence logic often incur multiple long-latency operations. These latencies can become severe if coherence actions are implemented in software (e.g., <ref type="bibr" target="#b29">[30]</ref>) or firmware (e.g., <ref type="bibr" target="#b21">[22]</ref>). Additionally, a directory may need to exchange messages with other caches before it can respond to a processor's request for a memory block. Such message exchange can also introduce substantial delay in the critical path of a remote access. For example, Figure <ref type="figure" target="#fig_0">1a</ref> shows that a processor's store to a block that resides in another node's cache may require five coherence protocol actions and four messages. Other protocols differ (e.g., SGI Origin reduce coherence actions to four and messages to three by directly forwarding processor two's response to processor one), but this should have no first-order effect on coherence prediction's usability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Two-Level Adaptive Branch Predictor</head><p>A branch predictor predicts whether the branch will be taken or not taken. Correct prediction of branch directions improves the performance of wide-issue, deeply pipelined microprocessors because it allows them to fetch and execute probable instructions without waiting for the outcome of previous branches. J. Smith <ref type="bibr" target="#b32">[33]</ref> proposed several dynamic branch predictors that use program feedback to increase the accuracy of branch prediction. More recently, Yeh and Patt pro- Table <ref type="table" target="#tab_1">1</ref> explains the coherence message types. I = invalid, E = exclusive, Dir. = Directory, Proc. = Processor. Initially, processor two has an exclusive copy of a cache block. Processor one issues a store to the block <ref type="bibr" target="#b0">(1)</ref>. This invokes processor one's cache coherence protocol, which sends a message to the directory (2). The directory examines its state and sends a message to processor two requesting it to return the block to the directory and invalidate its copy of the block (3). When the directory receives the block from processor two (4), it forwards it to processor one, which marks the cache block as exclusive in processor one <ref type="bibr" target="#b4">(5)</ref>. The states "I to E" and "E to E" represent transition states.</p><p>(</p><p>(2)  </p><formula xml:id="formula_1">I</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Predicting Coherence Protocol Messages</head><p>This section describes the Cosmos coherence message predictor. The next section briefly outlines how Cosmos can accelerate coherence protocols. This section begins with an example of a producer-consumer sharing pattern and its corresponding coherence message signature. The rest of the section uses this example to describe Cosmos in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Producer-Consumer Sharing Pattern's Signature</head><p>Figure <ref type="figure">2</ref> shows an example of a producer-consumer sharing pattern and how it can lead to predictable message patterns or signatures for a particular cache block. For example, assuming no false sharing, the producer executing the code in Figure <ref type="figure">2a</ref> observes the following message sequence for the cache block containing the variable shared_counter:</p><p>send get_rw_request to directory receive get_rw_response from directory receive inval_rw_request from directory send inval_rw_response to directory Figure <ref type="figure">2b</ref> shows the incoming message signature that results from the above message sequence. Note that examining the incoming messages is sufficient to interpret both the sharing pattern (i.e. producer-consumer) and the local processor's actions (i.e., processor store to produced block).</p><p>Consider a slightly more complex example in which we extend the pseudo code in Figure <ref type="figure">2a</ref> to support two consumers instead of one. In this case the producer and the two consumers will still follow the same predictable signatures as shown in Figure <ref type="figure">2b</ref>. However, at the directory the two get_ro_request messages can now arrive in any order from the two consumers. But, the arrival of a get_ro_request from the first consumer suggests strongly the possibility of the arrival of another get_ro_request from the second consumer and vice versa.</p><p>To achieve high accuracy a predictor must adapt to such variations in the incoming message stream. The rest of this section discusses the design of such an adaptive predictor called Cosmos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Basic Structure of Cosmos</head><p>The previous subsection suggests that a coherence message predictor must adapt to an incoming coherence message stream based on two properties:</p><p>• address of cache blocks, because sharing patterns of different cache blocks may differ, and  <ref type="figure">3</ref>. (a) shows the logical structure of the Cosmos coherence message predictor and (b) shows an example of how the message and pattern history tables for a directory may look like for the shared_counter in Figure <ref type="figure">2</ref>. In this example, we assume that the last message received by the directory is a get_ro_request from the consumer (denoted as P2). So, Cosmos will predict the next message to be an inval_rw_response from the producer (denoted as P1).</p><p>incoming coherence messages correspond to fixed sharing patterns for specific cache blocks. 1  Fortunately, a modified version of Yeh and Patt's two-level adaptive branch predictor called PAp <ref type="bibr" target="#b38">[39]</ref> satisfies the above requirements! We call such a coherence message predictor Cosmos. Given the address of a cache block and the history of messages received for that block, Cosmos can predict with high accuracy the sender and type of the next incoming message for the same block. We allocate a Cosmos predictor for every cache or directory in the machine.</p><p>Figure <ref type="figure">3a</ref> shows the logical structure of Cosmos. Cosmos is a twolevel adaptive predictor. The first-level table-called the Message History Table (MHT)-consists of a series of Message History Registers (MHRs). Each MHR corresponds to a different cache block address. An MHR contains a sequence of &lt;sender, type&gt; tuples corresponding to the last few coherence messages that arrived at the node for the specific cache block. We call the number of tuples maintained in each MHR the depth of the MHR.</p><p>The second-level table of Cosmos consists of a sequence of Pattern History Tables (PHT), one for each MHR. Each PHT contains prediction tuples corresponding to possible MHR entries. Each PHT is indexed by the entry in the MHR entry. The next two subsections outline how to obtain predictions from and update entries in Cosmos.</p><p>Figure <ref type="figure">3b</ref> shows the entries in an MHR and its PHT corresponding to the shared_counter variable in Figure <ref type="figure">2</ref>. The MHT in Figure <ref type="figure">3b</ref> has a depth of one, so this MHR entry contains only one &lt;sender, type&gt; tuple. The &lt;P2, get_ro_request&gt; tuple shown in this figure denotes that the last message received for the cache block containing the shared_counter is a get_ro_request message from the processor P2, which is consumer of the shared_counter in this case. The corresponding PHT captures patterns of messages received for shared_counter. For example, earlier Cosmos observed a get_ro_request message from processor P1 followed by an inval_ro_response from processor P2. The first entry of the PHT reflects this relationship. Thus, Cosmos will predict the arrival of an inval_ro_response message from processor P2, next time it sees a message get_ro_request from processor P1. Because the MHR contains the tuple corresponding to the last message received, to obtain a prediction we simply find the correct MHR, and use that entry to index into the PHT, which will give us a prediction if an entry exists for that tuple.</p><p>Cosmos differs from Yeh and Patt's two-level adaptive branch predictor called PAp (see Section 2.2) in three ways. First, the first-level table in Cosmos is indexed by the address of a cache block, whereas PAp is indexed by the program counter of a branch. Second, Cosmos must choose one prediction from several alternatives, whereas PAp usually chooses between two alternatives-branch taken or branch not taken. Third, the state machine in each PHT entry in PAp encodes the history of the last few outcomes of the same branch. Instead, a PHT entry in Cosmos simply consists of a prediction. Additionally, PHT entries in Cosmos can contain state machines (Section 3.6), but these are typically used as filters to remove noise from the incoming message stream.</p><p>Below we outline the exact steps involved in obtaining a prediction from and updating Cosmos. Specific implementations of Cosmos may either separate or combine these two steps.</p><p>1. Cosmos could predict the next coherence protocol state, instead of the next incoming coherence message. We believe these two approaches are equivalent. However, Cosmos predictors for specific protocols may consume less space if Cosmos captures messages, instead of coherence protocol states. For example, at the directory the coherence protocol state of the Wisconsin Stache protocol (Section 5.1) consumes eight bytes, whereas the message information could be captured in two bytes (Table <ref type="table" target="#tab_11">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Obtaining Predictions from Cosmos</head><p>Here are the steps involved to obtain a prediction from Cosmos:</p><p>• index into the MHR table with address of a cache block, • use the entry in MHR to index into the corresponding PHT, and • return the prediction entry (if one exists) in the PHT as the predicted tuple, which contains the predicted sender and type of the next incomng message corresponding to that cache block; otherwise, return no prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Updating Cosmos</head><p>Typically, we expect Cosmos to be updated after every message reception when we know for sure the &lt;sender, type&gt; tuple of a message. Here are the steps involved in updating Cosmos:</p><p>• index into the MHR table with the address of a cache block, • use the entry in MHR to index into the corresponding PHT,</p><p>• write new &lt;sender,type&gt; tuple as new prediction for the index corresponding to the MHR entry, and</p><p>• left shift the &lt;sender,type&gt; tuple into the MHR for the cache block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">How Cosmos Adapts to Complex Signatures?</head><p>Cosmos can adapt to complex message streams, such as the one outlined at the end of Section 3.1. If two get_ro_request messages arrive out of order from two different consumers (P1 and P2), the PHT table will contain the following two entries: Therefore, Cosmos can effectively predict the next incoming coherence message, even though incoming messages may arrive in a different order in different instances. 2   For more complicated sequences of incoming messages, Cosmos may need an MHR with depth greater than one. For example, if three get_ro_request messages come out of order from three consumers (P1, P2, and P3), then the PHT for a Cosmos predictor with MHR of depth = 2 may contain the following three entries:</p><p>Clearly, this allows Cosmos to predict the third incoming coherence message accurately based on the history of previous messages. Fortunately, several studies (e.g., <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b24">25]</ref>) have shown that the average number of sharers of a cache block is usually less than two. Consequently, we do not expect the depth of the MHR to be very high for most applications. Specifically, we found that an MHR of depth three is sufficient in most cases for the five parallel applications we studied in this paper. 3   2. A more aggressive predictor could ignore the senders for the get_ro_request messages. However, this may not be possible if there are intervening messages of other types for the same cache block.</p><p>3. We cannot ignore the processor number of the messages, even though it may appear so in the example. This is because actions taken by the directory (e.g., sending an invalidation message) based on the prediction may require accurate prediction of the processor number. However, it may be possible to group the processor numbers into a set and perform actions on the entire set of processors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Filtering Noise from Coherence Message Stream</head><p>When updating Cosmos we can use filters to reduce noise from the coherence message stream in the same way Yeh and Patt's PAp predictor removes noise from a stream of branches. For example, if 99% of the time, message B follows message A, then on seeing message A, Cosmos will predict the next message to be B. We do not want our prediction to change if these messages arrive rarely in the sequence: A, C, and B, instead of the sequence A, B. Branch predictors have a similar problem when programs exit loops. Frequently, the exit from loops is a taken branch; however, when the loop is executed completely, the exit is a not-taken branch. Branch predictors typically avoid updating their prediction on exiting a loop via a two-bit saturating counter proposed by J. Smith <ref type="bibr" target="#b32">[33]</ref>. One bit of the two-bit counter represents the direction of the branch and other bit represents the counter. Because a message needs more than one bit to represent a &lt;sender, type&gt; tuple, we simplify the counter and use only a single bit. With this single-bit counter, we update the prediction for a cache block to a different message only if we see two consecutive message mis-predictions for the same block.</p><p>Our results (Section 6.2) suggest that filters increase the prediction accuracy for Cosmos predictor with MHR depth of one, but they do not help Cosmos predictors with MHR depth greater than one. This is because both history and filters reduce noise from the message stream. However, history information adapts to the noise, while filters simply remove it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Implementation Issues for Cosmos</head><p>Cosmos is a two-level adaptive predictor with the first level containing message history registers (MHRs) and the second level containing pattern history tables (PHT). It may be possible to merge the first-level table with the cache block state maintained at both directories and caches. However, this may lead to a loss of Cosmos' history information when cache blocks are replaced. This problem may not arise for the directory because directory state is usually persistent during the entire duration of a parallel application.</p><p>The second-level table is more challenging to implement because it may require large amounts of memory to capture pattern histories for each cache block. However, our results (Section 6.2) show that Cosmos' memory overhead for 128 byte cache blocks is less than 14% for an MHR depth of one. This is because the number of pattern histories corresponding to a cache block is low, that is, less than four (on average) for an MHR depth of one for all five applications we studied in this paper. Consequently, we could preallocate four pattern history entries corresponding to each cache block. If a cache block needs more pattern histories, then it can allocate them from a common pool of dynamically allocated memory in the same way LimitLESS <ref type="bibr" target="#b9">[10]</ref> directory entries capture the list of sharers for a particular cache block. Nevertheless, higher prediction accuracies may require greater MHR depths, which may result in larger amounts of memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Using Coherence Protocol Message Predictors</head><p>This section briefly discusses how a coherence protocol message predictor, such as Cosmos, can be integrated with a coherence protocol. Predictors would sit beside each standard directory and cache module and accelerate coherence activity in two steps. First, they would monitor message activity and make a prediction. Second, based on the prediction, they will invoke an action in the standard coherence protocol. Key challenges include mapping predictions to actions, performing actions at the right time (not too early or late), dealing with mis-predictions, and determining how coherence prediction affects runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mapping Predictions to Actions</head><p>Mapping predictions to actions is straightforward in many cases. Table <ref type="table">2</ref> lists several examples of prediction-action pairs. For example, a directory action corresponding to a read-modify-write prediction for a block would be to return the block to the requesting cache in "exclusive" state, instead of the "shared" state. 1 Figure <ref type="figure">4a</ref> shows another example where the predictor in processor two's cache predicts a write miss from another processor. A consequent action-as done by an implementation of Lebeck and Wood's dynamic self-invalidation protocol <ref type="bibr" target="#b19">[20]</ref>-would be to replace the block from processor two's cache to the directory before the directory receives the write miss request from processor one's cache. More generally, each directory and cache can predict incoming coherence messages, execute protocol actions speculatively (which may include sending messages speculatively), and take appropriate actions on mis-predictions (Figure <ref type="figure">4b</ref>). Speculative execution of coherence protocol action may also involve executing a sequence of protocol actions, instead of executing a single action (that is normally done). This allows a directory and a cache to optimize for sharing patterns not known a priori.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Determining When to Perform Actions</head><p>Detecting when to perform actions is simple in some cases, but can be tricky in others. An obvious time to trigger actions would be to do so on certain protocol transitions. For example, the directory can trigger the action corresponding to a read-modify-write prediction when a read miss request arrives for a block. In Figure <ref type="figure">4a</ref>, processor two's cache can trigger the block replacement action when it sees inval_rw_request messages for other spatially contiguous blocks. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Detecting and Handling Mis-predictions</head><p>Directories and caches can detect prediction success or failure by simply verifying whether the next message for a cache block is indeed the predicted message or not. Additionally, if any action sends messages speculatively to other directories or caches, then these directories or caches must be informed of the mis-prediction. This allows a directory or a cache to recover from mis-predictions caused by other directories and caches.</p><p>Mis-predictions can leave the processor state, protocol state, or both in an inconsistent state. Consequently, a protocol must recover from mis-predictions. In general, actions can be classified into three categories. Below we outline possible recovery mechanisms for each action.</p><p>• Actions that move the protocol between two "legal" states require no recovery on mis-prediction. Replacement of a cache block that moves the block from "exclusive" to "invalid" state is an example of such an action (Figure <ref type="figure">4a</ref>). While there is no explicit recovery in this example, a mis-prediction may still hurt performance by resulting in an extra cache miss for the replaced block.</p><p>• Actions that move the protocol state to a future state, but do not expose this state to the processor, can recover from mis-predictions transparently. On detecting a mis-prediction a protocol simply discards the future state. On detecting a prediction success, however, the coherence protocol state must commit the future state and expose it to the processor. Mis-predictions corresponding to actions in Figure <ref type="figure">4b</ref> can use such recovery actions.</p><p>• Actions that allow both the processor and the protocol to move to future states need greater support for recovering from mispredictions. Before speculation begins both the processor and the protocol can checkpoint their states. Then, on detecting a mis-prediction, both the processor and the coherence protocol must roll back to the checkpointed states. On detecting a success, the current protocol and processor states must be commit-1. Note that the activity of a processor can be interpreted from the incoming coherence message, even though a Cosmos predictor sitting next to a processor cache predicts incoming coherence messages (and not local processor activity). For example, a Cosmos prediction of get_ro_response suggests that the local processor will incur a read miss for a cache block. This information can be used to properly "time" an action corresponding to a prediction.</p><p>ted. Such actions can be created by coupling a speculative processor, such as the MIPS R10000, with a coherence protocol accelerated with prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">How Coherence Prediction Affects Performance?</head><p>A final aspect of coherence prediction is determining exactly how it affects application runtime. As stated in the introduction, this paper concentrates primarily on prediction accuracies. Nevertheless, it would be useful to gain a rough understanding of how prediction affects runtime.</p><p>A simplistic execution model is as follows. Let:</p><p>• p be the prediction accuracy for each message, • f be the fraction of delay incurred on messages predicted correctly (e.g., f=0 means that the time of a message predicted correctly is completely overlapped with other delays), and</p><p>• r be the penalty due to a mis-predicted message (e.g., r=0.5 implies a mis-predicted message takes 1.5 times the delay of a message without prediction).</p><p>If performance is completely determined by the number of messages in the critical path of a parallel program, then speedup due to prediction is:</p><p>Figure <ref type="figure" target="#fig_2">5</ref> displays the model's result for a prediction accuracy of 80% (p=0.8) The model shows, for example, that speedup can be as high as 56% with a mis-prediction penalty of 100% (r=1) and a prediction success benefit of 30% (f=0.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methodology</head><p>We evaluate Cosmos' prediction accuracy using traces of coherence messages obtained from the Wisconsin Stache protocol (Section 5.1) running five parallel scientific applications (Section 5.2). Each application has a start-up phase to initiate the computation (e.g., initiate data structures). Our traces do not contain coherence messages generated in this start-up phase. The traces were generated by the Wisconsin Wind Tunnel II simulator <ref type="bibr" target="#b25">[26]</ref> simulating a 16-node parallel machine, with each node having one processor, a coherent memory bus, and an optimized network interface <ref type="bibr" target="#b23">[24]</ref>.</p><p>The simulated parameters are shown in Table <ref type="table">3</ref>. Cosmos' prediction accuracy is largely insensitive to variations in network latency. For example, changing the network latency from 40 nanoseconds (Table <ref type="table">3</ref>) to one microsecond hardly changes Cosmos' prediction rates of the five applications we studied in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Wisconsin Stache Protocol</head><p>We obtained our coherence message traces from the Wisconsin Stache protocol. Stache is a software, full-map, and write-invalidate directory protocol that uses part of local memory as a cache for remote data <ref type="bibr" target="#b29">[30]</ref>. • Unlike the DASH protocol, Stache uses the half-migratory optimization. In this optimization a directory requests a cache to mark an exclusive block invalid, and not shared, when it receives a read or write miss request from another cache. This is beneficial if this same cache block is not immediately read from the former cache.</p><p>• Our Stache implementation allocates pages in round-robin fashion across the 16 nodes. For example, if page X is allocated to node 10, then page X+1 will be allocated to node 11. The owner of each page functions as the directory for that page. The directory pages are optimized to function as cache pages for the local node. Consequently, in most cases Stache does not generate local messages between the cache and directory within a particular node.</p><p>• Cache blocks on a cache page in a local node communicate only with one specific directory page in another node. Consequently, for blocks on a cache page, the sender is always a fixed node containing the directory page. A directory page can, however, receive messages from any node caching the page.</p><p>• Currently, Stache does not replace pages (and, hence, cache blocks) from the portion of local memory it designates as a cache for remote memory. This implies that Cosmos' history information for cache blocks persists over time. Protocols that replace cache blocks may need to preserve the history information even after the block is replaced. Alternatively, such protocols can speculate only at the directory, where Cosmos' history information is persistent during the duration of a parallel application.</p><p>• Barriers are implemented with point-to-point messages. Consequently, our prediction accuracies do not include prediction rates for barrier variables.  <ref type="bibr" target="#b5">[6]</ref> and parallelized at the University of Wisconsin <ref type="bibr" target="#b8">[9]</ref>, barnes is from the Stanford SPLASH-2 suite <ref type="bibr" target="#b36">[37]</ref>, and dsmc, moldyn, and unstructured are from the Universities of Maryland and Wisconsin <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Depth of MHR</head><p>Nevertheless, Cosmos' prediction results with Stache should not be significantly different from what would be obtained with a full-map, write-invalidate directory protocol.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmarks</head><p>Table <ref type="table" target="#tab_7">4</ref> depicts the five benchmarks used in this study. Appbt is a parallel three-dimensional computational fluid dynamics application <ref type="bibr" target="#b8">[9]</ref> from the NAS benchmark suite. The code is spatially parallelized in three dimensions. The main data structures are a number of 3D arrays, each of which is divided up among different processors as 3D subblocks. Each processor is responsible for updating the sub-block it owns. Sharing occurs between neighboring processors in 3D along the boundaries of these sub-blocks.</p><p>Barnes simulates the interaction of a system of bodies in three dimensions using the Barnes-Hut hierarchical N-body method <ref type="bibr" target="#b36">[37]</ref>. The main data structure is an octree. The octree's leaves contain information about each body and internal nodes represent space cells. In each iteration the octree is rebuilt and traversed once per body to compute the forces on individual bodies. The communication pattern induced by such traversals is quite irregular.</p><p>Dsmc studies the properties of a gas by simulating the movement and collision of a large number of particles in a three-dimensional domain with discrete simulation Monte Carlo method <ref type="bibr" target="#b26">[27]</ref>. Dsmc divides domains into cells in a static Cartesian grid. Each cell contains particles, which collide only with other particles in the cell. The cells are spatially divided up among processors. At the end of each iteration, particles move from one cell to another. The primary communication occurs during this movement.</p><p>Moldyn is a molecular dynamics application, whose computational structure resembles the non-bonded force calculation in CHARMM <ref type="bibr" target="#b7">[8]</ref>. Molecules in moldyn are uniformly distributed over a cuboidal region with a Maxwellian distribution of initial velocities. A molecule's velocity and force exerted by other particles determine the molecule's position. Force computation limits interactions to molecules within a cut-off radius. Unstructured is a computational fluid dynamics application that uses an unstructured mesh to model a physical structure, such as an airplane wing or body <ref type="bibr" target="#b26">[27]</ref>. The mesh is represented by nodes, edges that connect two nodes, and faces that connect three or four nodes. The mesh is static, so its connectivity does not change. The mesh is partitioned spatially among different processors using a recursive coordinate bisection partitioner. The computation contains a series of loops that iterate over nodes, edges, and faces. Most communication occurs along the edges and faces of the mesh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>In this section we examine Cosmos' basic prediction accuracy (Section 6.1) and then delve into Cosmos' sensitivity to noise and initialization effects and Cosmos' memory requirements (Section 6.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Basic Prediction Rate</head><p>Table <ref type="table" target="#tab_6">5</ref> shows that Cosmos achieves high prediction accuracy. With an MHR depth of one, Cosmos' overall prediction accuracy ranges between 62-86%. Cosmos achieves such high accuracy because cache blocks in most applications generate predictable coherence message signatures. These signatures are related directly to sharing patterns of an application's data structures. All our applications, except barnes, have fixed signatures (see Figures <ref type="figure">6</ref> and<ref type="figure">7</ref>) throughout the entire execution of the parallel application. Barnes has slightly lower accuracy because shared-memory addresses are reassigned to different objects across iterations. Below we discuss each application's prediction accuracy in detail.  <ref type="figure">6</ref> for an explanation of the figure. We show unstructured's second dominant message signature (at the cache) using bold and dashed lines.</p><p>to a directory. For the Stache protocol, a cache receives messages from a fixed sender-that is, a fixed directory, which limits the number of &lt;sender,message-type&gt; tuples Cosmos must choose its predictions from. In contrast, a directory receives messages from multiple caches (i.e. senders) for the same cache block. Consequently, Cosmos' predictions are more accurate for Stache caches than Stache directories.</p><p>Table <ref type="table" target="#tab_6">5</ref> also shows that Cosmos' prediction accuracy usually increases with the increase in the MHR depth. With MHR depth of two, the accuracy ranges between 69-88%, while a depth of three results in prediction accuracy that ranges between 69-93%. Having history information helps because it allows Cosmos to recognize predictable coherence streams (Section 3.5). However, most of our applications do not benefit beyond an MHR depth of three (Table <ref type="table" target="#tab_6">5</ref>).</p><p>Below we examine why Cosmos achieves high prediction rates for each of the five applications. Surprisingly, variations in simple sharing patterns studied by Bennett, et al. <ref type="bibr" target="#b6">[7]</ref> and Weber and Gupta <ref type="bibr" target="#b12">[13]</ref>, can lead to sequences of coherence actions (and consequent signatures) that are significantly different from those generated by simple sharing patterns (e.g., see unstructured's sequence of messages below). Consequently, predictors based on simple sharing patterns may not be able to correctly speculate the sequence of coherence actions that may be generated. However, Cosmos can capture such variations in sharing patterns because Cosmos adapts to the incoming message stream, which directly determines the sequence of coherence actions to follow.</p><p>Appbt's high prediction accuracy results from its producer-consumer sharing pattern. Appbt is a three-dimensional stencil-style code in which a cube is divided up into subcubes. Each subcube is assigned to one processor. Communication occurs between neighboring processors along boundaries of the subcubes.</p><p>The sharing pattern that results in the sequence of messages shown for appbt in Figure <ref type="figure">6</ref> is: producer reads, producer writes, and consumer reads. This pattern repeats for most cache blocks throughout the entire application. Consequently, Cosmos adapts well to appbt resulting in a prediction accuracy of 85%.</p><p>Note that the half-migratory optimization discussed in Section 5 hurts appbt because the producer first reads a block before writing to it. In the absence of this optimization, the producer pattern would have simply cycled through the two messages: inval_rw_request and upgrade_response. Clearly, a dynamic predictor, such as Cosmos, can be used to either inhibit (e.g., appbt) or trigger (e.g., see discussions on dsmc and moldyn below) the half-migratory optimization.</p><p>Figure <ref type="figure">6</ref> shows that all transitions for appbt have high prediction accuracy except the transition from upgrade_request to inval_ro_response at the directory. The low accuracy on this transition results from false sharing in two data structures. It appears that this false sharing generates multiple signatures that the protocol oscillates between randomly. This confuses the predictor resulting in lower accuracy.</p><p>Barnes's prediction accuracy ranges between 62-69% for different MHR depths. This is slightly lower than that for our other applications. This is because in barnes nodes of the octree can be assigned different shared-memory addresses in different iterations. Unfortunately, Cosmos cannot make accurate predictions for these nodes of the octree. This is because Cosmos' prediction is based on information it collected on past behavior (e.g., previous iterations) of a particular shared-memory address (at a cache block granularity).</p><p>Figure <ref type="figure">6</ref> shows that barnes has a variety of sharing patterns, some of which exhibit dominant signatures throughout the execution of the program. However, the low accuracies on most arcs improve with more history information (i.e. greater MHR depth).</p><p>Dsmc shows the highest accuracy among all our applications. Dsmc's dominant sharing pattern is the classical producer-consumer pattern in which the producer writes and the consumer reads shared cache blocks. This happens because at the end of each iteration dsmc communicates information between two processors via shared buffers. This leads to the message sequence shown in Figure <ref type="figure">6</ref>. Note that the half-migratory optimization helps dsmc because the producer does not read the data before it writes to it. Consequently, invalidating the producer's cache blocks, instead of converting them to read-only, avoids an extra handshake with the directory.</p><p>Figure <ref type="figure">6</ref> shows that the transition from get_ro_request to inval_rw_response has a low prediction accuracy. This low accuracy, however, disappears with increased MHR depth because updates to shared buffers frequently follow deterministic patterns. Nevertheless, in some cases multiple processors compete for exclusive access to a shared buffer. This creates somewhat oscillating patterns that confuse Cosmos. Fortunately, Cosmos learns to isolate these cases using either more history information or via noise filters (see Section 6.2).</p><p>Moldyn's high accuracy results from two dominant sharing patterns: migratory and producer-consumer patterns. The migratory sharing pattern results in the message sequence &lt;get_ro_response, upgrade_response, inval_rw_response&gt; in both processors a block is migrating between. The same pattern is exhibited for the producer in the producer-consumer pattern. However, the consumer for the producer-consumer pattern sees the sequence: &lt;get_ro_response, inval_ro_request&gt;. Hence, the number of references to the pattern &lt;get_ro_response, upgrade_response, inval_rw_response&gt; is greater than the number of references to the pattern &lt;get_ro_response, inval_ro_request&gt; (Figure <ref type="figure">7</ref>). The sequence seen at the directory results primarily from the migratory pattern.</p><p>Moldyn's migratory pattern results from the way it reduces a shared array, which contains force calculations for simulated molecules. In each iteration each processor collects its contribution for different elements of the shared array in a private array. At the end of the iteration each processor adds its contribution from the private array to the shared array. Updates to each element in the shared array happens in a critical section, which results in the migratory pattern. Note that the half-migratory optimization helps moldyn. In the absence of this optimization moldyn would have probably seen the signature: &lt;get_ro_request, inval_rw_response, upgrade_request, inval_ro_response&gt; at the directory. Moldyn's producer-consumer sharing pattern results from updates to a shared array that contains the coordinates of simulated molecules. Moldyn's producer-consumer pattern results in message signatures similar to that of appbt's at both the producer and consumer caches. However, the average number of consumers for moldyn is 4.9, whereas for appbt the number of consumers is one. Consequently, at the directory we see back-to-back get_ro_request messages arriving with high predictability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Depth of MHR</head><p>Unstructured is different from the rest of our applications because it has different dominant signatures for the same data structures in different phases of the application. The same data structures oscillate between migratory and producer-consumer sharing patterns. The migratory sharing pattern is similar to moldyn's and occurs when each processor updates different elements of the shared arrays in critical sections. The migratory pattern is followed by the producer-consumer pattern in which a producer is itself a consumer of the data. The average number of consumers per producer is 2.6. The signature shown in bold and dashed arrows in Figure <ref type="figure">7</ref> represents the transition from migratory to producer-consumer pattern. The directory sees corresponding signatures.</p><p>Figure <ref type="figure">7</ref> shows that unstructured's prediction accuracy for several arcs with MHR depth of one is low. This is because of the change in sharing pattern. Table <ref type="table" target="#tab_6">5</ref> shows, however, that Cosmos' accuracy increases from 74% to 92% as the MHR depth increases from one to four. This increase in prediction accuracy from the increase in MHR depth also results in high prediction accuracies for these arcs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Additional Analysis</head><p>Effect of Filters on Prediction Accuracy. Noise filters can increase the prediction accuracy of Cosmos. We implement Cosmos' noise filter as a saturating counter, which counts upwards from zero and saturates at a maximum count. Table <ref type="table" target="#tab_10">6</ref> shows the prediction accuracy of Cosmos as we vary the maximum count between 0 and 2.</p><p>Filters increase prediction accuracy slightly (up to around 6%) only for Cosmos predictors with MHR depth of one. For MHR depth of two or beyond filters do not help much. This is because both filters and history information remove noise from the message stream. However, history information allows Cosmos to learn from and adapt to the noise. Consequently, if the noise repeats, then Cosmos can achieve higher accuracy. In contrast, filters simply remove noise, but do not let Cosmos adapt to it. Hence, predictors with filters and MHR depth of one achieve lower accuracy than predictors with greater MHR depths. Additionally, filters do not help predictors that have MHR depth greater than one. We found that unstructured and barnes achieve steady-state behavior quickly (in less than 20 iterations). Appbt and moldyn take slightly longer (around 30 iterations). Dsmc, however, takes a large number of iterations (around 300) to achieve steady state prediction rates. This is because specific transitions in dsmc take a large number of iterations to achieve reasonable prediction accuracies (Table <ref type="table" target="#tab_13">8</ref>).</p><p>Memory Requirement of Cosmos Predictors. Table <ref type="table" target="#tab_11">7</ref> shows that dynamic memory overhead incurred by Cosmos predictors is acceptable-that is, less than 22%-for most applications for predictors with MHR depths of three or lower. Additionally, the number of PHT entries per cache block (or MHR entry) is less than three in most cases. The low PHT to MHR ratio suggests that perhaps a scheme that statically allocates three or four PHT entries per cache block and dynamically allocates the rest from a common pool of memory may work.</p><p>Only for barnes the memory overhead is as high as 63% for MHR depth of three because barnes reassigns shared-memory addresses to logically different objects, which confuses Cosmos and leads to greater number of coherence message patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Comparison with Directed Optimizations</head><p>In this section we compare Cosmos with directed optimizations-that is, optimizations introduced in a coherence protocol for specific sharing patterns. Dynamic self-invalidation <ref type="bibr" target="#b19">[20]</ref> and migratory protocols <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35]</ref> are examples of two such protocols. Both can be thought of as implementing predictors directed at specific optimizations. Cosmos could be less cost-effective than predictors for directed optimizations because Cosmos requires more hardware resources to store, access, and update the Message and Pattern History Tables. However, Cosmos' memory requirement can perhaps be reduced by grouping predictions for multiple cache blocks together (similar to Johnson and Hwu's macroblocks <ref type="bibr" target="#b15">[16]</ref>).</p><p>Cosmos could be better than directed optimizations for two reasons. First, including the composition of predictors of several directed optimizations in a single protocol could be more complex than Cosmos. Predictors in existing coherence protocols are usually integrated with the finite-state machine of the protocol. Such integration may work well when one considers these protocols individually. Unfortunately, combining multiple such predictors into a single protocol can lead to an explosive number of interactions and states, which can make the resulting protocol bulky and hard to debug <ref type="bibr" target="#b10">[11]</ref>. More critically, extending a bulky protocol with other kinds of speculation becomes even harder. In contrast, Cosmos captures the predictors for directed optimizations in a single predictor. Figure <ref type="figure">8</ref> shows the coherence message signatures that trigger the dynamic self-invalidation and migratory protocols. Cosmos can capture these signatures easily. Additionally, protocols accelerated with Cosmos are easier to extend because Cosmos separates the predictor from the protocol itself.</p><p>Second, Cosmos can not only identify known sharing patterns, but can also discover application-specific patterns not known a priori. For example, Section 6.1 shows that one of unstructured's signatures is a complex composition of migratory and producer-consumer sharing patterns. Predictors directed only at migratory or producer-consumer pattern will fail to track unstructured's transition between migratory and producer-consumer sharing patterns. As Section 6.1 also shows, Cosmos can easily capture, filter, and adapt to different message signatures generated by variations in simple sharing patterns studied by Bennett, et al. <ref type="bibr" target="#b6">[7]</ref> and Gupta and Weber <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Summary and Conclusions</head><p>This paper explores using prediction to accelerate coherence protocols. A coherence protocol can execute faster if it can predict future coherence protocol actions and execute them speculatively. It shares with branch prediction the need to have a sophisticated predictor. The first contribution of this paper is the design of the Cosmos coherence message predictor. Cosmos predicts the next &lt;processor,message-type&gt; in two steps reminiscent of Yeh and Patt's two-level PAp branch predictor. Cosmos faces a greater challenge than branch predictors because the Cosmos' prediction is a multi-bit &lt;processor,message-type&gt; tuple rather than a single branch outcome bit.</p><p>The second contribution of this paper is a detailed evaluation of the Cosmos coherence message predictor. Using five scientific benchmarks on a target shared-memory machine with 16 processors running the Stache directory protocol, variations of Cosmos predict the source and type of the next coherence message with surprisingly-high accuracies of 62-69% (barnes), 84-86% (moldyn), 84-85% (appbt), 74-92% (unstructured), and 84-93% (dsmc).</p><p>Cosmos' high prediction accuracy results from predictable coherence message patterns or signatures associated with specific cache block addresses. Such signatures are generated by sharing patterns that do not change or change very slowly during the execution of these applications. Cosmos is more general than directed optimizations, such as dynamic self-invalidation and migratory protocols. Cosmos could be less cost-effective than the directed optimizations because it uses more resources (e.g., tables). Cosmos could be better than directed optimizations because (1) including the composition of these optimizations could be more complex than Cosmos and (2) Cosmos can discover and track application-specific patterns not known a priori.</p><p>More work is needed to determine whether the high prediction rates of Cosmos can significantly reduce execution time with a coherence protocol. This is work is analogous to taking a branch predictor with high prediction rates and integrating it into a micro-architecture to see how much it affects the bottom line. We believe that results in this paper on Cosmos' high prediction rates indicate that work on the next step is justified.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 .</head><label>1</label><figDesc>FIGURE 1. (a)  shows message exchange between a directory and two caches and (b) shows the corresponding state transitions. Table1explains the coherence message types. I = invalid, E = exclusive, Dir. = Directory, Proc. = Processor. Initially, processor two has an exclusive copy of a cache block. Processor one issues a store to the block<ref type="bibr" target="#b0">(1)</ref>. This invokes processor one's cache coherence protocol, which sends a message to the directory (2). The directory examines its state and sends a message to processor two requesting it to return the block to the directory and invalidate its copy of the block (3). When the directory receives the block from processor two (4), it forwards it to processor one, which marks the cache block as exclusive in processor one<ref type="bibr" target="#b4">(5)</ref>. The states "I to E" and "E to E" represent transition states.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>g e t_ rw _ re q u e s t g e t_ r w _ r e s p o n s e in v a l_ r w _ r e s p o n s e g e t_ rw _ re q u e s t g e t_ r w _ r e s p o n s e in v a l_ rw _ re q u e st in v a l_ rw _ re s p o n s eCoherence protocol actionSpeculative execution of coherence protocol action FIGURE4. Two examples of using prediction to accelerate coherence protocols. (a) shows a protocol in which protocol actions are accelerated in anticipation of processor one's write miss. (b) shows a protocol that predicts incoming coherence messages, updates protocol state, generates (but does not send) messages speculatively, and commits protocol state and messages only if the predicted message arrives. Dir. = Directory, Proc. = Processor. Section 4 outlines possible triggers for the speculative actions shown in this figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 5 .</head><label>5</label><figDesc>FIGURE 5. This figure displays a crude execution model that translates coherence message prediction rates into a parallel program's speedup. We assume that execution time is determined purely by the delay of messages in the critical path of the program. Results in this figure (based on a prediction rate of 0.8 for all graphs) show that coherence prediction can result in substantial speedups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>A self-invalidation signature (b) A migratory protocol signature FIGURE 8. This figure shows the coherence message signatures that can trigger dynamic self-invalidation (a) and a migratory protocol (b). The downgrade_response, not shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>(4) (a) (b) Messages Received by Directory from Caches Messages Received by a Cache from a Directory</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>E in</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Proc. two</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>E</cell></row><row><cell></cell><cell>to E</cell><cell>E to E</cell><cell>(3)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>I</cell></row><row><cell></cell><cell>E</cell><cell>E in Proc. one</cell><cell></cell></row><row><cell>Message</cell><cell>Description</cell><cell></cell><cell></cell><cell>Message</cell><cell>Description</cell></row><row><cell>get_ro_request</cell><cell cols="2">get block in read-only (shared) state</cell><cell></cell><cell>get_ro_response</cell><cell>response to get_ro_request</cell></row><row><cell>get_rw_request</cell><cell cols="3">get block in read-write (exclusive) state</cell><cell>get_rw_response response to get_rw_request</cell></row><row><cell>upgrade_request</cell><cell cols="4">upgrade block from read-only to read-write upgrade_response response to upgrade_request</cell></row><row><cell cols="3">inval_ro_response response to inval_ro_request</cell><cell></cell><cell>inval_ro_request</cell><cell>invalidate read-only (shared) copy of block</cell></row><row><cell cols="3">inval_rw_response response to inval_rw_request</cell><cell></cell><cell>inval_rw_request invalidate read-write (exclusive) copy and return block</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 .</head><label>1</label><figDesc>A sample of coherence messages usually found in full-map, write-invalidate coherence protocols.</figDesc><table><row><cell>posed a general dynamic branch predictor called PAp [39]. PAp is a</cell></row><row><cell>two-level adaptive predictor that makes a prediction for a branch based</cell></row><row><cell>on the past behavior of the same branch. First, it uses the program</cell></row><row><cell>counter of a branch to index into a Branch History Table to obtain k</cell></row><row><cell>bits, which represent the last k outcomes of the branch at this program</cell></row><row><cell>counter. Second, it uses these k bits to index a Per-Branch Pattern His-</cell></row><row><cell>tory Table to obtain a prediction. Each entry in the Pattern History</cell></row><row><cell>Table is a finite-state machine, which returns predictions based on the</cell></row><row><cell>behavior of a finite number of previous occurrences of this branch (and</cell></row><row><cell>the k bits from the Branch History Table). In the next section we will</cell></row><row><cell>show how PAp can be modified to obtain coherence message predic-</cell></row><row><cell>tions.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc>shows all the types of coherence messages generated by</figDesc><table><row><cell>time (without prediction) time (with prediction)</cell><cell>=</cell><cell>1 p * f + (1 -p) * (1 + r)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>appbt</cell><cell></cell><cell></cell><cell>barnes</cell><cell></cell><cell></cell><cell>dsmc</cell><cell></cell><cell></cell><cell>moldyn</cell><cell></cell><cell cols="3">unstructured</cell></row><row><cell></cell><cell>C</cell><cell>D</cell><cell>O</cell><cell>C</cell><cell>D</cell><cell>O</cell><cell>C</cell><cell>D</cell><cell>O</cell><cell>C</cell><cell>D</cell><cell>O</cell><cell>C</cell><cell>D</cell><cell>O</cell></row><row><cell>1</cell><cell>91</cell><cell>77</cell><cell>84</cell><cell>80</cell><cell>42</cell><cell>62</cell><cell>94</cell><cell>73</cell><cell>84</cell><cell>92</cell><cell>79</cell><cell>86</cell><cell>85</cell><cell>65</cell><cell>74</cell></row><row><cell>2</cell><cell>90</cell><cell>79</cell><cell>85</cell><cell>81</cell><cell>56</cell><cell>69</cell><cell>95</cell><cell>77</cell><cell>86</cell><cell>91</cell><cell>80</cell><cell>86</cell><cell>90</cell><cell>86</cell><cell>88</cell></row><row><cell>3</cell><cell>89</cell><cell>80</cell><cell>85</cell><cell>79</cell><cell>57</cell><cell>69</cell><cell>94</cell><cell>92</cell><cell>93</cell><cell>90</cell><cell>79</cell><cell>85</cell><cell>90</cell><cell>88</cell><cell>89</cell></row><row><cell>4</cell><cell>89</cell><cell>80</cell><cell>85</cell><cell>78</cell><cell>56</cell><cell>68</cell><cell>94</cell><cell>92</cell><cell>93</cell><cell>90</cell><cell>77</cell><cell>84</cell><cell>96</cell><cell>88</cell><cell>92</cell></row></table><note><p>. Prediction rates (expressed in percentage of hits) obtained from Cosmos. Depth of MHR denotes the number of messages used by Cosmos to predict the next incoming coherence message. C = prediction rate at cache, D = prediction rate at directory, and O = overall prediction rate.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 4 .</head><label>4</label><figDesc>Benchmarks. Iter = number of iterations. appbt is from NASA Ames</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>An interaction list-rebuilt every 20 iterations-records pairs of interacting molecules. The arrays that record the force exerted on molecules and molecules' coordinates induce the</figDesc><table><row><cell>Number of parallel machine nodes</cell><cell>16</cell></row><row><cell>Processor speed</cell><cell>1 GHz</cell></row><row><cell>Cache block size</cell><cell>64 bytes</cell></row><row><cell>Cache size</cell><cell>one megabyte</cell></row><row><cell>Cache associativity</cell><cell>direct-mapped</cell></row><row><cell>Main memory access time</cell><cell>120 ns</cell></row><row><cell>Memory bus coherence protocol</cell><cell>MOESI</cell></row><row><cell>Memory bus width</cell><cell>256 bits</cell></row><row><cell>Memory bus clock time</cell><cell>250 MHz</cell></row><row><cell>Network message size</cell><cell>256 bytes</cell></row><row><cell>Network latency</cell><cell>40 ns</cell></row><row><cell>Network Interface access time</cell><cell>60 ns</cell></row><row><cell>TABLE 3. System Parameters</cell><cell></cell></row><row><cell></cell><cell>maximum communication.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc>and dsmc at the cache and directory. Arcs represent the order in which two messages arrived. Each arc is labelled as X/Y, where X = percentage of correct predictions for that particular arc and Y = percentage of references to that arc. For example, an arc labelled 94/9 is predicted correctly 94% of the time and constitutes 9% of the total references to all arcs. All X and Y numbers are measured with a Cosmos predictor with MHR depth of one. All Y for a benchmark do not add upto 100% because we only present the dominant transitions we observe. The dotted lines represent dominant message signatures observed in the message stream.</figDesc><table><row><cell>shows that Cosmos has higher accuracy for a cache compared</cell></row></table><note><p>FIGURE 7. Dominant (incoming) message signatures for moldyn and unstructured. See caption of Figure</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 6 .</head><label>6</label><figDesc>This table shows the prediction accuracy of Cosmos as we vary the maximum count of the saturating counter from 0 to 2. The saturating counter filters noise from the coherence message stream (Section 3.6). The overall prediction rates in Table5correspond to this table's column 0 (i.e. no filter).</figDesc><table><row><cell></cell><cell></cell><cell>appbt</cell><cell></cell><cell></cell><cell>barnes</cell><cell></cell><cell></cell><cell>dsmc</cell><cell></cell><cell></cell><cell>moldyn</cell><cell></cell><cell></cell><cell>unstructured</cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>0</cell><cell>1</cell><cell>2</cell></row><row><cell>1</cell><cell>84</cell><cell>85</cell><cell>85</cell><cell>62</cell><cell>66</cell><cell>66</cell><cell>84</cell><cell>86</cell><cell>86</cell><cell>86</cell><cell>86</cell><cell>86</cell><cell>74</cell><cell>78</cell><cell>78</cell></row><row><cell>2</cell><cell>85</cell><cell>85</cell><cell>86</cell><cell>69</cell><cell>71</cell><cell>71</cell><cell>86</cell><cell>88</cell><cell>88</cell><cell>86</cell><cell>86</cell><cell>86</cell><cell>88</cell><cell>89</cell><cell>89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE 7 .</head><label>7</label><figDesc>Memory overhead of Cosmos predictors (with no filter). Ratio = total number of PHT entries / total number of MHR entries. MHR entries correspond to cache blocks that were referenced at least once in the parallel section of an application. Ovhd expresses the average memory overhead per 128-byte block as a percentage of the block size. More precisely, Ovhd = (tuple size * [MHR depth + Ratio * (MHR depth + 1)] * 100 / 128)%. We assume the tuple size of two bytes (12 bits for processors and 4 bits for coherence message types). Note that some Ratios are less than one. This is because unless the number of protocol references to a cache block is greater than the MHR depth, we do not allocate a PHT for that MHR. This makes all of dsmc's Ratios less than one because some of dsmc's shared-memory data structures are touched rarely. For the same reason, unlike other benchmarks, dsmc's Ratio decreases with increase in MHR depth because the number of such shared-memory blocks that are touched greater number of times than the MHR depth is even fewer. application as an approximation to time. This is because the five parallel applications we examined in this paper iterate over a number of steps or iterations. Cosmos can predict incoming coherence messages for a cache block fairly accurately because sharing pattern of a cache block in one iteration is usually similar to its sharing pattern in the previous iteration.</figDesc><table><row><cell>Depth</cell><cell>appbt</cell><cell></cell><cell cols="2">barnes</cell><cell>dsmc</cell><cell></cell><cell cols="2">moldyn</cell><cell cols="2">unstructured</cell></row><row><cell>of MHR</cell><cell>Ratio</cell><cell>Ovhd</cell><cell>Ratio</cell><cell>Ovhd</cell><cell>Ratio</cell><cell>Ovhd</cell><cell>Ratio</cell><cell>Ovhd</cell><cell>Ratio</cell><cell>Ovhd</cell></row><row><cell>1</cell><cell>1.2</cell><cell>5.4%</cell><cell>3.8</cell><cell>13.5%</cell><cell>0.8</cell><cell>3.9%</cell><cell>0.8</cell><cell>4.0%</cell><cell>1.7</cell><cell>6.8%</cell></row><row><cell>2</cell><cell>1.4</cell><cell>9.6%</cell><cell>6.9</cell><cell>35.4%</cell><cell>0.4</cell><cell>5.1%</cell><cell>1.1</cell><cell>8.3%</cell><cell>2.1</cell><cell>12.8%</cell></row><row><cell>3</cell><cell>1.9</cell><cell>16.4%</cell><cell>9.3</cell><cell>63.0%</cell><cell>0.3</cell><cell>6.7%</cell><cell>1.6</cell><cell>14.9%</cell><cell>2.8</cell><cell>21.9%</cell></row><row><cell>4</cell><cell>2.6</cell><cell>26.5%</cell><cell>10.9</cell><cell>91.8%</cell><cell>0.3</cell><cell>8.9%</cell><cell>2.0</cell><cell>21.6%</cell><cell>3.4</cell><cell>33.0%</cell></row></table><note><p><p>Time to Adapt.</p>A critical question for predictors, such as Cosmos, is how long it takes them to achieve the steady-state prediction rates. Cosmos predictors need time to achieve steady-state behavior because they adapt to the incoming stream. We use number of iterations of each</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 1</head><label>1</label><figDesc>, is a response to a downgrade_request sent by the directory. On receiving a downgrade_request for a block, a cache must change the block from exclusive to shared state.</figDesc><table><row><cell></cell><cell>4</cell><cell>80</cell><cell>320</cell></row><row><cell>Transition</cell><cell>iterations</cell><cell>iterations</cell><cell>iterations</cell></row><row><cell></cell><cell cols="3">hits refs hits refs hits refs</cell></row><row><cell>&lt;get_ro_response,</cell><cell cols="3">2% 20% 34% 4% 62% 2%</cell></row><row><cell>upgrade_response&gt;</cell><cell></cell><cell></cell><cell></cell></row><row><cell>&lt;get_ro_request,</cell><cell cols="3">2% 25% 18% 13% 30% 12%</cell></row><row><cell>inval_rw_response&gt;</cell><cell></cell><cell></cell><cell></cell></row><row><cell>&lt;inval_rw_response,</cell><cell cols="3">1% 19% 18% 4% 35% 1%</cell></row><row><cell>upgrade_request&gt;</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 8 .</head><label>8</label><figDesc>Dsmc's prediction accuracies for specific transitions for different number of iterations. refs is percentage of total references to the transition. hits is the percentage of hits to the transition. These numbers are measured with a filterless Cosmos predictor with MHR depth of one.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank members of the Wisconsin Wind Tunnel group (http://www.cs.wisc.edu/~wwt) for providing an environment conducive to this work and David Wood for providing key feedback on this manuscript. We would also like to thank Rebecca Hoffman, Stefanos Kaxiras, Jim Larus, Avinash Sodani, Dan Sorin, and T. N. Vijaykumar for their helpful comments on earlier drafts of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported in part by Wright Laboratory Avionics Directorate, Air Force Material Command, USAF, under grant #F33615-94-1-1525 and ARPA order no. B550, National Science Foundation with grants MIP-9225097, MIPS-9625558, and CDA-9623632, a Wisconsin Romnes Fellowship, and donations from Sun Microsystems. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Wright Laboratory Avionics Directorate or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An Evaluation of Fine-Grain Producer-Initiated Communication in Cache-Coherent Multiprocessors</title>
		<author>
			<persName><forename type="first">Hazim</forename><surname>Abdel-Shafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarita</forename><forename type="middle">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><forename type="middle">S</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Third IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="204" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Shared Memory Consistency Models: A Tutorial</title>
		<author>
			<persName><forename type="first">Sarita</forename><forename type="middle">V</forename><surname>Adve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="66" to="76" />
			<date type="published" when="1996-12">December 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An Evaluation of Directory Schemes for Cache Coherence</title>
		<author>
			<persName><forename type="first">Anant</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Simoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hennessy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual International Symposium on Computer Architecture</title>
		<meeting>the 15th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="280" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Software DSM Protocols that Adapt between Single Writer and Multiple Writer</title>
		<author>
			<persName><forename type="first">Cristiana</forename><surname>Amza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhya</forename><surname>Dwarkadas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Third IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="261" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An Effective Preloading Scheme to Reduce Data Access Penalty</title>
		<author>
			<persName><forename type="first">Jean-Loup</forename><surname>Baer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien-Fu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing &apos;91</title>
		<meeting>Supercomputing &apos;91</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="176" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The NAS Parallel Benchmarks</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lasinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horst</forename><surname>Simon</surname></persName>
		</author>
		<idno>RNR-91-002 Revision 2</idno>
		<imprint>
			<date type="published" when="1991-08">August 1991</date>
			<publisher>Ames Research Center</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive Software Cache Management for Distributed Shared Memory</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">K</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">B</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International Symposium on Computer Architecture</title>
		<meeting>the 17th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1990-06">June 1990</date>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Charmm: A program for macromolecular energy, minimization, and dynamics calculation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bruccoleri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Olafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>States</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Swamintathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karplus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Chemistry</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">187</biblScope>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Parallelizing Appbt for a Shared-Memory Multiprocessor</title>
		<author>
			<persName><forename type="first">Doug</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Mehta</surname></persName>
		</author>
		<idno>1286</idno>
		<imprint>
			<date type="published" when="1995-09">September 1995</date>
		</imprint>
		<respStmt>
			<orgName>Computer Sciences Department, University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LimitLESS Directories: A Scalable Cache Coherence Scheme</title>
		<author>
			<persName><forename type="first">David</forename><surname>Chaiken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Kubiatowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anant</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV)</title>
		<meeting>the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS IV)</meeting>
		<imprint>
			<date type="published" when="1991-04">April 1991</date>
			<biblScope unit="page" from="224" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Teapot: Language Support for Writing Memory Coherence Protocols</title>
		<author>
			<persName><forename type="first">Satish</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGPLAN &apos;96 Conference on Programming Language Design and Implementation (PLDI)</title>
		<meeting>the SIGPLAN &apos;96 Conference on Programming Language Design and Implementation (PLDI)</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive Cache Coherency for Detecting Migratory Shared Data</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture</title>
		<meeting>the 20th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="98" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cache Invalidation Patterns in Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolf-Dietrich</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="794" to="810" />
			<date type="published" when="1992-07">July 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cooperative Shared Memory: Software and Hardware for Scalable Multiprocessors</title>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Earlier version appeared in it Fifth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS V)</title>
		<imprint>
			<date type="published" when="1993-11">November 1993</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="300" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reducing False Sharing on Shared Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">J</forename><surname>Jeremiassen</surname></persName>
		</author>
		<author>
			<persName><surname>Eggers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth ACM SIGPLAN Symposium on Principles &amp; Practice of Parallel Programming (PPOPP)</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Run-time Adaptive Cache Hierarchy Management via Reference Analysis</title>
		<author>
			<persName><forename type="first">Teresa</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwu</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
		<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="315" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">R</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">D</forename><surname>Sleator</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Competitive Snoopy Caching. Algorithmica</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="79" to="119" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lockup-free instruction fetch/prefetch cache organization</title>
		<author>
			<persName><forename type="first">David</forename><surname>Kroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual International Symposium on Computer Architecture</title>
		<meeting>the 8th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1981-05">May 1981</date>
			<biblScope unit="page" from="81" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The SGI Origin: A ccNUMA Highly Scalable Server</title>
		<author>
			<persName><forename type="first">James</forename><surname>Laudon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lenoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
		<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="241" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamic Self-Invalidation: Reducing Coherence Overhead in Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">Alvin</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International Symposium on Computer Architecture</title>
		<meeting>the 22nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Design of the Stanford DASH Multiprocessor</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lenoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Laudon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><surname>Lam</surname></persName>
		</author>
		<idno>CSL-TR-89- 403</idno>
		<imprint>
			<date type="published" when="1989-12">December 1989</date>
		</imprint>
		<respStmt>
			<orgName>Computer System Laboratory, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">STiNG: A CC-NUMA Computer System for the Commercial Marketplace</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Lovett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rusell</forename><surname>Clap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International Symposium on Computer Architecture</title>
		<meeting>the 23rd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="308" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Tolerating Latency Through Software-Controlled Data Prefetching</title>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-03">March 1994</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Coherent Network Interfaces for Fine-Grain Communication</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shubhendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International Symposium on Computer Architecture</title>
		<meeting>the 23rd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="page" from="247" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An Evaluation of Directory Protocols for Medium-Scale Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shubhendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1994 International Conference on Supercomputing</title>
		<meeting>the 1994 International Conference on Supercomputing<address><addrLine>Manchester, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-07">July 1994</date>
			<biblScope unit="page" from="64" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wisconsin Wind Tunnel II: A Fast and Portable Parallel Architecture Simulator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shubhendu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Litzkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Huss-Lederman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Performance Analysis and Its Impact on Design</title>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient Support for Irregular Applications on Distributed-Memory Machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shubhendu</surname></persName>
		</author>
		<author>
			<persName><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shamik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth ACM SIGPLAN Symposium on Principles &amp; Practice of Parallel Programming (PPOPP)</title>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
			<biblScope unit="page" from="68" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluation of a Competitive-Update Cache Coherence Protocol with Migratory Detection. Hakan Grahn and Per Stenstrom</title>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="180" />
			<date type="published" when="1996-12">December 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distance-Adaptive Update Protocols for Scalable Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">Alain</forename><surname>Raynaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second IEEE Symposium on High-Performance Computer Architecture</title>
		<meeting>the Second IEEE Symposium on High-Performance Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tempest and Typhoon: User-Level Shared Memory</title>
		<author>
			<persName><forename type="first">K</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual International Symposium on Computer Architecture</title>
		<meeting>the 21st Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1994-04">April 1994</date>
			<biblScope unit="page" from="325" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simple Compiler Algorithms to Reduce Ownership Overhead in Cache Coherence Protocols</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Skeppstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per</forename><surname>Stenstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI)</title>
		<meeting>the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="286" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Compiler Algorithm that Reduces Read Latency in Ownership-Based Cache Coherence Protocols</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Skeppstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per</forename><surname>Stenstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Architectures and Compilation Techniques</title>
		<meeting>the International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Study of Branch Prediction Strategies</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual International Symposium on Computer Architecture</title>
		<meeting>the 8th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="135" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m">IEEE Standard for Scalable Coherent Interface (SCI)</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive Cache Coherence Protocol Optimized for Migratory Sharing</title>
		<author>
			<persName><forename type="first">Per</forename><surname>Stenstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mats</forename><surname>Brorsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Sandberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture</title>
		<meeting>the 20th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Exploiting Choice: Instruction Fetch and Issue on an Implementable Simultaneous Multithreading Processor</title>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">J</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><forename type="middle">M</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">L</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">L</forename><surname>Stamm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
		<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Jaswinder Pal Singh, and Anoop Gupta. The SPLASH-2 Programs: Characterization and Methodological Considerations</title>
		<author>
			<persName><forename type="first">Cameron</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moriyoshi</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Ohara</surname></persName>
		</author>
		<author>
			<persName><surname>Torrie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International Symposium on Computer Architecture</title>
		<meeting>the 22nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1995-07">July 1995</date>
			<biblScope unit="page" from="24" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mechanisms for Cooperative Shared Memory</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satish</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvin</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubhendu</forename><forename type="middle">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Symposium on Computer Architecture</title>
		<meeting>the 20th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1993-05">May 1993. Spring 1994</date>
			<biblScope unit="page" from="156" to="168" />
		</imprint>
	</monogr>
	<note>Also appeared in it CMG Transactions</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Alternative Implementations of Two-Level Adaptive Branch Prediction</title>
		<author>
			<persName><forename type="first">T-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual International Symposium on Computer Architecture</title>
		<meeting>the 19th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="124" to="134" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
