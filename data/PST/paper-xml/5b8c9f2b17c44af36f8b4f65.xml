<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A novel application of deep learning for single-lead ECG classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-05-10">May 10, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sherin</forename><forename type="middle">M</forename><surname>Mathews</surname></persName>
							<email>sherin.m.mathews@intel.com</email>
						</author>
						<author>
							<persName><forename type="first">Chandra</forename><surname>Kambhamettu</surname></persName>
							<email>chandrak@udel.edu</email>
						</author>
						<author>
							<persName><forename type="first">Kenneth</forename><forename type="middle">E</forename><surname>Barner</surname></persName>
							<email>barner@udel.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Intel â€ </orgName>
								<orgName type="institution" key="instit2">University of Delaware</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Intel</orgName>
								<address>
									<postCode>2821, 95051</postCode>
									<settlement>Mission College, Santa Clara</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A novel application of deep learning for single-lead ECG classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-05-10">May 10, 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">DF14C47C0C1B5788F353C3390DF4D011</idno>
					<idno type="DOI">10.1016/j.compbiomed.2018.05.013</idno>
					<note type="submission">Received Date: 15 May 2017 Revised Date: 8 May 2018 Accepted Date: 9 May 2018 Preprint submitted to Journal of L A T E X Templates</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computers in Biology and Medicine heartbeat classification</term>
					<term>Restricted Boltzmann Machine</term>
					<term>deep belief networks (DBN)</term>
					<term>deep learning</term>
					<term>MIT-BIH database. single-lead ECG recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detecting and classifying cardiac arrhythmias is critical to the diagnosis of patients with cardiac abnormalities. In this paper, a novel approach based on deep learning methodology is proposed for the classification of single-lead electrocardiogram (ECG) signals. We demonstrate the application of the Restricted Boltzmann Machine (RBM) and deep belief networks (DBN) for ECG classification following detection of ventricular and supraventricular heartbeats using single-lead ECG. The effectiveness of this proposed algorithm is illustrated using real ECG signals from the widely-used MIT-BIH database. Simulation results demonstrate that with a suitable choice of parameters, RBM and DBN can achieve high average recognition accuracies of ventricular ectopic beats (93.63%) and of supraventricular ectopic beats (95.57%) at a low sampling rate of 114 Hz. Experimental results indicate that classifiers built into this deep learning-based framework achieved state-of-the art performance models at lower sampling rates and simple features when compared to traditional methods. Further, employing features extracted at a sampling rate of 114 Hz when combined with deep learning provided enough discriminatory power for the classification task. This performance is comparable to that of traditional methods and uses a much lower sampling rate and simpler features. Thus, our proposed deep neural network algorithm demonstrates that deep learning-based</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Motivation of Deep Learning for ECG Classification</head><p>Cardiac arrhythmias (abnormal heart rhythms) pose a serious threat to patients recovering from acute myocardial infarction <ref type="bibr" target="#b0">[1]</ref>. Some types of arrhythmias are life-threatening, capable of triggering cardiac arrest and sudden death. Therefore, early automatic detection and classification of ECG patterns is critical to diagnosing and treating patients with life-threatening cardiac arrhythmias <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. An inexpensive and noninvasive technique to detect these disorders is by analyzing electrocardiograms (ECGs) that furnish valuable information on the electrophysiology and functional aspects of the cardiovascular system.</p><p>In past decades, computerized recognition of ECGs has become a wellestablished practice, assisting cardiologists in the task of classifying long-term ECG recordings. Feature extraction methods to discriminate heartbeats have included wave shape functions <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, Hermite functions <ref type="bibr" target="#b8">[9]</ref>, waveletbased features <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, frequency-based features <ref type="bibr" target="#b11">[12]</ref>, ECG morphology <ref type="bibr" target="#b12">[13]</ref>,</p><p>hermite polynomials <ref type="bibr" target="#b13">[14]</ref>, higher order cumulant features <ref type="bibr" target="#b14">[15]</ref>, statistical features <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> and Karhunen-Loeve expansion of ECG morphology <ref type="bibr" target="#b4">[5]</ref>. Methodologies to classify these extracted features have included support vector machines <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b15">[16]</ref>, self-organizing maps with learning vector quantization <ref type="bibr" target="#b13">[14]</ref>, k-th nearest-neighbor rules <ref type="bibr" target="#b18">[19]</ref>, decision trees <ref type="bibr" target="#b17">[18]</ref>, artificial neural networks <ref type="bibr" target="#b19">[20]</ref>, linear discriminants <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, active learning framework <ref type="bibr" target="#b20">[21]</ref> and back prop-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>agation neural networks <ref type="bibr" target="#b14">[15]</ref>. However, these state of-the-art automatic ECG recognition systems often rely on a pattern-matching framework that represents an ECG signal as a sequence of stochastic patterns, so they require complex feature extraction process and high sampling rates and thus burdensome computational times to classify arrhythmias. Consequently, to enable implementation in real time and at reasonable cost, these systems must enlarge their classification criteria by using a set of simple features and a lower sampling rate.</p><p>Though several algorithms have focused on automatically classifying heartbeats in ECGs, another drawback is the scalability failure to handle large intraclass variations wherein the robustness of many existing ECG classification techniques remains limited. A major limitation of above approaches is that they are highly dependent on the supervised trained dataset and perform poorly while dealing with large amount of unknown ECG records. Furthermore, extracting complex features in the transform domains when combined with dimensionality reduction algorithms significantly upsurge the computational complexity of the overall process. This limits the usage of such complicated feature-extraction frameworks in low power applications such as wearable health monitoring devices or mobile applications. Moreover, the classifier algorithms have not performed well in practice in case of inter-patient variations of the ECG signals, thereby demonstrating a common shortcoming of having an inconsistent performance while classifying a new patients ECG signal. This makes them unreliable to be widely used clinically or in practice, as they tend to have high variations in their accuracy and efficiency for larger databases.</p><p>Deep learning <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref> (also known as unsupervised feature learning or representation learning) is a new technique that is becoming mainstream in machine learning and pattern recognition. It has been successfully used in object recognition <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, image verification <ref type="bibr" target="#b32">[33]</ref>, classification <ref type="bibr" target="#b33">[34]</ref>, and speech recognition <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. In recent years, deep learning approaches have dramatically improved the accuracy of recogni-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>tion tools, creating a deep, multi-stage architecture for unsupervised learning and recognition systems. Deep learning networks are implemented using stacked autoencoders and can represent a highly expressive abstraction. Such abstractions can compactly represent a much larger set of functions than shallow networks can. Thus, they offer tremendous representational power that can help reveal unknown feature coherences of input signals, an important capability for learning tasks that involve complicated models. Here, we propose a more accurate and robust approach using deep learning for single-lead ECG classification that generated fewer false alarms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Literature Review of existing Deep Learning work for ECG Classification</head><p>The most successful type of deep learning models are restricted Boltzmann machines (RBM) <ref type="bibr" target="#b38">[39]</ref>, stacked autoencoder (SAE) <ref type="bibr" target="#b39">[40]</ref>, Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> and Deep Belief Networks(DBN) <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>.</p><p>CNNs as a framework contain many layers that transform their input with con- In <ref type="bibr" target="#b42">[43]</ref>, a CNN based classification system was developed which automatically learns a suitable feature representation from two lead ECG data, thereby negating the need of hand-crafted features. However this framework did not involve any QRS wave detection resulting in a large network. In another work <ref type="bibr" target="#b41">[42]</ref>, segmented ECGs are processed by an eleven-layer convolutional neural network resulting in maximum accuracy of 93.18 % using short duration ECG data. Kiranyaz et al. <ref type="bibr" target="#b43">[44]</ref> studied the patient-specific ECG monitoring system using three-layer CNN with only R-peak wave. They also attained good accuracy in the detection of supraventricular ectopic beats and ventricular ectopic beats but incorporated only R-peak wave resulting in very high training time.</p><p>The drawback of direct usage of deep learning frameworks is the lack of usage of robust features which not only necessitates lot of training data but also made the physiological interpretation of the resultant network is some- Another paper <ref type="bibr" target="#b43">[44]</ref> on similar ideology employed a 1-D convolutional 7 neural networks (CNNs) that fused the feature extraction and classification for two-lead ECG classification. For each patient, an individual and simple CNN was trained by using relatively small common and patient-specific training data, and such patient-specific feature extraction ability did provide an improvement in the classification performance. This did negate the necessity to extract handcrafted manual features, but since a dedicated CNN is trained for a particular patient, it can solely be used to only classify a specific patients long ECG data stream in an accurate manner making it practically unscalable for large number of users.</p><p>Kutlu <ref type="bibr" target="#b47">[48]</ref> performed a multi-stage classification system for two lead ECG using considerable number of features(106 ECG waveform features) and a Deep Belief Network (DBN) as classifier to overcome the disadvantage of having a cumbersome network with no physiology interpretation. Though use of features does make the physiological interpretation easier incase of false positives, the training time was extremely large due to large number of feature extracted and use of DBN network. This can be overcomed by introduction of few but robust features thereby providing data augmentation as as presented in our developed framework. Thus inspired by recent progress in the area of deep learning <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref>, we developed a deep learning framework that includes restricted Boltz- has not yet been used to perform single lead ECG classification tasks.</p><p>The remainder of this paper is organized as follows. Section 2 covers the proposed methodology. Here we present the data processing chain (which includes preprocessing, segmentation, and feature extraction). Section 3 briefly describes the proposed deep learning framework. Section 4 details the experiments, and provides, evaluates and discusses their results. Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>A pattern recognition system provides a framework that automatically maps an input signal to a class label by analyzing the features extracted from the signal. The two symbolic stages of this recognition system are feature extraction and classification. Before feature extraction, the data is pre-processed (i.e., filtered), detected and segmented. Then, feature extraction uses mathematical techniques on the input signal to build an association with known models and to obtain the best discriminative representation of the data by exploiting the underlying signal characteristics. Each stage is described below [Figure <ref type="figure" target="#fig_4">1</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Preprocesing</head><p>Each ECG signal is first bandpass filtered at 0.11 Hz and sampled at 360 Hz. It is preprocessed to remove artifacts, such as baseline wander, power-line interference, high-frequency noise, and motion artifacts <ref type="bibr" target="#b3">[4]</ref>. Baseline wander is a low frequency artifact that may be caused by chest-lead ECG signals suffering from coughing or breathing with large chest movements, by poor electrode to skin contact, or by limb-lead ECG signals suffering from arm or leg movements <ref type="bibr" target="#b3">[4]</ref>. To remove baseline wander, we pass the signal through median filters with window sizes of 200ms and 600ms, thus removing P-waves, QRS complexes, This strong interference can stem from improper grounding, loose contact of a patient's cable, or disconnected electrodes. Power-line interference and highfrequency noise are removed from a baseline-corrected ECG using a 12-tap lowpass filter, a finite impulse response filter that has 3 dB at 35 Hz and equal ripple in both pass and stop bands <ref type="bibr" target="#b12">[13]</ref>. Motion artifacts represent transient baseline interference that is introduced by electrode skin impedance caused by electrode motion. Because the peak amplitude of a motion artifact is 500 percent of the peak-to-peak ECG amplitude, and its duration is about 100-500 ms, these artifacts can obscure ECG waveforms, making their interpretation quite difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>Motion artifacts are removed using an adaptive filter by utilizing an Recursive Least Square (RLS) algorithm. Spectrograms and convergence plots results in <ref type="bibr" target="#b51">[52]</ref> concluded RLS algorithm to be more efficient in removing motion artifacts from ECG signals when compared to Least Mean Squares (LMS) algo-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>rithm. Hence, we adopted the motion artifacts removal approach in <ref type="bibr" target="#b51">[52]</ref> wherein adaptive filters altered their filter coefficients with the continuous change of signal using adaptive algorithms, providing the optimum noise removal features for non-stationary signals like ECG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Processing: Heart Beat Detection and Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HeartBeat Detection</head><p>The heartbeat detection is accomplished at a lower sampling rate of 114Hz as compared to the input sampling rate of 360Hz. We followed the filterbank based approach enumerated in <ref type="bibr" target="#b52">[53]</ref> for ECG detection algorithm wherein the Filterbanks subbands are downsampled and components of the one-channel detection block like the feature computation, MWI, and peak detector are operated at a lower rate than the input sampling rate of the ECG. The adoption of filter bank enables the analysis of multiple frequency bands very efficiently. This results in competent heartbeat detection at subband rate along with high computational efficiency. For R-peak detection at subband rate, it is crucial to have a deterministic relationship between fiducial points in the input ECG and the subband signal. This requires that each of the analysis and synthesis filters have a linear phase response as the linear phase requirement ensures that all frequencies in the input signal will have the same sample delay through the analysis filters.</p><p>It is then possible to determine the exact location of the R wave in the input ECG signal, and other fiducial points from analysis of the subbands, thereby resulting in accurate R peak detection <ref type="bibr" target="#b52">[53]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation</head><p>The segmentation module follow the ECG-detection module. For segmentation, we utilize the heartbeat segmentation program of Laguna et al., <ref type="bibr" target="#b3">[4]</ref> since the accuracy of this system in determining heartbeat segmentation points has been validated on the MIT-BIH database and has proven to be commensurate with the inter-expert variation. The heartbeat segmentation stage provides QRS </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T-wave offset detection</head><p>T wave is the representation of repolarization of ventricles through which the myocardium is prepared for the next ECG cycle. In the automatic delineation process of the ECG i.e the process of locating the onset and offset of different waveforms, one of the most critical calculations is the detection of T wave ends, particularly T offset. The detection of the T offset is the most challenging among the ECG fiducial points, primarily due to the slow transition of the signal near the end of T wave and due to the presence of oscillatory patterns that vary from one person to another. We use the proposed method in <ref type="bibr" target="#b53">[54]</ref> , which is based on ECG signal filtering, value estimation of different fiducial points and application of backward and forward search windows with adaptive thresholds.</p><p>For an infallible detection of T waveform and its fiducial points (e.g. T onset, T peak, and T offset), the first step is to define the search window in the entitled signal. The boundaries of the T wave search window are set to be adaptive and relative to the position of QRS offset and RR interval wherein the search window encloses the T wave boundaries, extended from the QRS offset to two-third of previous RR interval. A small segment post the QRS offset is excluded from the search window due to the fact that T wave does not exist immediately after QRS offset and occurs only after the ST segment.</p><p>The next stage is the adaptive threshold estimation wherein the position of T peak is registered by finding either the local maximum and the local minimum in the entitled ECG signal within the search window and the threshold is calculated using the previous T and R peak level values. The threshold is used to classify the morphology of the T wave present in each heartbeat. For eg: if the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>maximum point exceeds the threshold and the absolute value of the minimum point does not, then the T wave is identified as a positive monophasic and the maximum point is registered as T peak. For a negative monophasic T wave, the absolute minimum value must meet the defined requirement in <ref type="bibr" target="#b53">[54]</ref>. In case of a biphasic T wave, both the local maximum and the absolute value of the local minimum should be greater than the threshold. For cases when T wave is not detected in the first attempt, the threshold is then decreased by half and the search method is done over again until a T peak is detected. Furthermore, the detection algorithm traces the onset and offset T values by finding the sample corresponding to the zero slope of the entitled ECG signal. The sample point which has a zero slope and former T peak is identified as T onset. Similarly, T offset is determined at a further distance of T peak as described in <ref type="bibr" target="#b53">[54]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature Extraction</head><p>After down-sampling the ECG signal recordings to 114 Hz, we employ two feature extraction methods. Feature Set 1 (FS1) yielded 26 features comprising RR intervals, heart-beat intervals, and segmented morphology. Feature Set 2 (FS2) produced 22 features consisting of RR intervals and fixed interval morphologies <ref type="bibr" target="#b3">[4]</ref>. We settled upon the single-lead feature extraction method as its lower sampling rate and smaller feature vector both translate to lessened power consumption and lower hardware complexity.</p><p>Feature Set 1 FS1 consisted of 26 features comprising of RR intervals, heartbeat intervals, and segmented morphologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RR Intervals Features</head><p>RR intervals also known as Heartbeat fiducial point intervals correspond to the interval between successive heartbeat fiducial points. The following four features were extracted from RR intervals:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>â€¢ Pre-RR interval: the RR interval between a given heartbeat and the preceding heartbeat.</p><p>â€¢ Post-RR interval: the RR interval between a given heartbeat and the following heartbeat.</p><p>â€¢ Average RR interval: the mean of RR intervals for a recording. This value remains the same for all heartbeats in a recording.</p><p>â€¢ Local average RR interval: estimated by averaging ten RR intervals surrounding a heartbeat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heartbeat Interval Features</head><p>Three features were extracted from post-heartbeat interval segmentation.</p><p>â€¢ QRS duration: time interval between QRS onset and offset.</p><p>â€¢ T-wave duration: time interval between QRS offset and T-wave offset.</p><p>â€¢ Boolean variable: a third variable which indicates the presence or absence of a P-wave.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmented Morphology Interval Features</head><p>Segmented morphology encompasses amplitude values of the ECG signal calculated by a sampling window between QRS onset and offset and a sampling window between QRS offset and T-wave offset points. Two sampling windows were used following the determination of the fiducial point (FP), the first of these bounded by the QRS onset and offset and the second bounded by the QRS offset and the T-wave offset. Ten evenly spaced sample features were derived by uniformly sampling the ECG amplitude in the first window (Figure <ref type="figure" target="#fig_8">2a</ref>) and nine more by uniformly sampling the second window, resulting in a total of 19 features.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RR Intervals Features</head><p>RR intervals (also known as Heartbeat fiducial point intervals) correspond to the interval between successive heartbeat fiducial points, and match the same four features extracted in Feature Set 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fixed-interval morphology features</head><p>To determine fixed interval morphologies, sampling windows were first positioned at the heartbeat FP. Two sampling windows were formed based on FP.</p><p>The first window approximately encompassed the QRS-complex and covered the   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Deep Learning Framework</head><p>Deep Learning, inspired by the human brain's deep hierarchical architecture, is a technique focused on learning deep hierarchical models of data <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref>.</p><p>This system learns an empirical set of features at multiple levels of abstraction, thereby allowing it to learn complex functions from input data without using human-engineered features.</p><p>Deep learning networks, implemented using stacked autoencoders, are capable of representing highly expressive abstractions, thereby compactly yielding much larger sets of functions than shallow networks can <ref type="bibr" target="#b56">[57]</ref>. Through the tremendous representational power of hierarchical feature learning, these networks can help discover unknown feature coherences of input signals, a characteristic that is crucial for learning tasks involving complicated models.</p><p>As suggested in <ref type="bibr" target="#b24">[25]</ref>, the main concept of a DBN training algorithm is to first initialize greedily the weights of each layer in an unsupervised manner by treating each pair of layers as a Restricted Boltzmann Machine (RBM), and to later jointly refine these weights to further improve the likelihood. The resulting DBN can be considered a hierarchy of nonlinear feature detectors that can capture complex statistical patterns in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Restricted Boltzmann Machine</head><p>Derived from a Boltzmann Machine, the RBM is a bi-directionally connected network of stochastic processing units that learns significant features of an unknown probability distribution based on samples from that distribution. An RBM can be described as a bipartite graph having a visible layer and a hidden layer (Figure <ref type="figure" target="#fig_11">3</ref> ). Units in the visible layer are typically characterized by Bernoulli or Gaussian distributions and those in the hidden layer are typically characterized by Bernoulli distributions. Stochastic units in the visible layer associate with stochastic units in the hidden layer by means of a weight matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>No connections exist between units in the same layer. In schematic representation, each edge in the bipartite graph is attached to a weight, denoted as a symmetric matrix W , that is associated with the visible layer (v) and the hidden layer (h). </p><formula xml:id="formula_0">E(v, h) = -v T W h -b T v v -b T h h<label>(1)</label></formula><p>Thus, an RBM represents the joint distribution p(v; h) between visible unit v and hidden random unit h. The joint probability is defined as</p><formula xml:id="formula_1">p(v, h) = exp(-E(v, h)) Z ,<label>(2)</label></formula><p>where Z = v h exp(-E(v, h)) is the partition function</p><p>The probability assigned by the network model to a visible unit v is</p><formula xml:id="formula_2">p(v) = 1 Z h exp(-E(v, h)),<label>(3)</label></formula><p>The lack of connections within a given layer of an RBM results in the visible layer variables being conditionally independent, given the hidden layer variables, and vice versa. Thus the conditional probabilities can be rewritten as:</p><formula xml:id="formula_3">p(v j = 1/h) = Ïƒ(a i + h j w i , j) (4) M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT p(h j = 1/v) = Ïƒ(b j + v i w i , j)<label>(5)</label></formula><p>where Ïƒ is the sigmoid fnuction defined by Ïƒ =</p><formula xml:id="formula_4">1 1+exp -x</formula><p>Signal propagation manifests in two ways: recognition, where visible activations propagate to the hidden units; and reconstruction, where hidden activations propagate to the visible units. Both recognition and reconstruction use the same weight matrix (simply transposed). The Contrastive Divergence (CD) algorithm finds the parameters W , a, and b and performs Gibbs sampling. We use CD to minimize the reconstruction error so the weights can be trained to generate input patterns that are presented to the RBM with high probability.</p><p>(A guide to training an RBM is given in <ref type="bibr" target="#b57">[58]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Deep Belief Networks</head><p>DBNs are a type of multi-layer generative neural network that is recognized for its capability to model and visualize high-level learned features <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b54">[55]</ref>. It is composed of stacked, logistic RBMs wherein the lowest-level RBM learns a shallow model of the data and the next-level RBM learns to model first-layer hidden units, thereby representing high-level abstraction through hierarchical architecture (Figure <ref type="figure" target="#fig_12">4</ref>).  <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b59">[60]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation of Proposed Methodology with results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The MIT-BIH Database</head><p>For our evaluation experiments, we used the acclaimed MIT/Beth Israel Hospital (BIH) Arrhythmia Database available at MIT medical data storage Physionet <ref type="bibr" target="#b60">[61]</ref>. Briefly, this database incorporates 48 half-hour ECG recordings, each containing two ECG lead signals digitized at 360 samples per second with 11-bit resolution over a 10 mV range <ref type="bibr" target="#b60">[61]</ref>. Twenty-three of the recordings were randomly selected from a set of 4,000 ambulatory 24-hour ECGs that were collected from a mixed population of inpatients and outpatients at the medical center. The remaining 25 recordings were selected from the same set but included less common but clinically symbolic arrhythmias. All recordings have been annotated by two or more cardiologists and contain modified limb lead II.</p><p>In our experiments, we focused on using lead A only. In 45 recordings, lead A is modified lead II, and in the other three recordings, lead A is lead V5 <ref type="bibr" target="#b5">[6]</ref>.</p><p>According to the Association for the Advancement of Medical Instrumentation (AAMI) recommended practice, the 4 paced beats are excluded from this experimental evaluation process because these beats possess insufficient signal quality for reliable processing <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">AAMI Standard</head><p>The AAMI standard emphasizes the problem of distinguishing ventricular 430 ectopic beats (VEBs) from non-ventricular ectopic beats <ref type="bibr" target="#b3">[4]</ref>, and hence normal and arrhythmic beats are remapped to the five AAMI heartbeat classes <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref> using the mapping in <ref type="bibr" target="#b3">[4]</ref> with each class including heartbeats of one or more types [Table <ref type="table" target="#tab_1">2</ref>].  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remapped</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>In this work, we used AAMI recommended practice to combine the MIT-BIH heartbeat types into the following five heartbeat classes that we used in all subsequent processing:</p><p>1. Class N corresponding to beats originating in the sinus node (normal and bundle branch block beat types)</p><p>2. Class S corresponding to supraventricular ectopic beats (SVEBs)</p><p>3. Class V corresponding to ventricular ectopic beats (VEBs)</p><p>4. Class F corresponding to beats that result from fusing normal and VEBs 5. Class Q corresponding to unknown beats including paced beats</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation Metrics</head><p>The MIT-BIH database contained a series of manually verified QRS detection points that we utilized in this study. The 48 records from MIT/BIH ECG arrhythmia database <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>  To validate the algorithms on the MIT-BIH database, we used the following performance metrics: accuracy (Acc), sensitivity (Se), positive predictive value (PPV), and false positive rate (FPR).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Experimental Results and Discussion</head><p>We performed our classification on the MIT-BIH arrhythmia database <ref type="bibr" target="#b60">[61]</ref> to detect two types of heartbeat arrhythmias: VEBs and SVEBs. In agreement with AAMI recommended practice, four recordings containing paced beats were removed from the 48 recordings. The data from the remaining 44 recordings were divided into two sets: training (DS1) and test (DS2). We trained the classifier using DS1 and assessed classifier performance using test set DS2.</p><p>For the RBM and DBN algorithms, we used the toolbox developed by Drausin Wulsin <ref type="bibr" target="#b63">[64]</ref>. To determine the best configurations and parameters for We have reported our ECG classification results at sampling rates of 360</p><p>Hz and 114 Hz in Table <ref type="table" target="#tab_3">3</ref>    Our classifier also provided high levels of accuracy, 93.63% and 95.87% for SVEB and VEB classes, respectively when compared to LCKVD <ref type="bibr" target="#b64">[65]</ref> , LDA <ref type="bibr" target="#b65">[66]</ref>,</p><p>510 QDA <ref type="bibr" target="#b65">[66]</ref> and ANN <ref type="bibr" target="#b65">[66]</ref> at a lower sampling rate of 114Hz. This provided advantages of not only reduced computation time, reduced CPU Cycles but also a higher accuracy achieved at lower sampling rate of 114Hz. Thus at both sampling rates, our algorithm provides competitive accuracy performance when compared to previously reported results (rows 3-5 in Table <ref type="table" target="#tab_3">3</ref> and rows 3-6 in 515 Table <ref type="table" target="#tab_4">4</ref>) for automated heartbeat classification systems in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b5">[6]</ref>.</p><p>We also evaluated the recognition accuracy for different sample rates from Dictionary learning (LCKSVD) <ref type="bibr" target="#b64">[65]</ref> methods are very similar over all sampling rates starting 114Hz, with other algorithms yielding comparitively lower accuracies at 114Hz. The boosting methods algorithms in Chazel <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref> and LDA, QDA, ANN methods in <ref type="bibr" target="#b65">[66]</ref> uniformly produce inferior average accuracies as the sampling rate is reduced starting from 180Hz(50%) to 72Hz(20%).</p><p>The reduced accuracy of other algorithms at low sampling rates, relative to the deep learning methods, can be attributed to the value of the inherent exploitation of class affinities by the deep learning approaches. Though the boosting algorithms perform inferior at low sampling rates, they seem to benefit from bagging of the training sample occurring at the higher sampling rates.</p><p>Thus, the boosting and other algorithms accuracies increase only after the sampling rate of the training data is increased substantially. Overall, the average Comparing Table <ref type="table" target="#tab_3">3</ref>  In addition to evaluating the performance of VEB and SVEB classification, we also assessed the per-class classification across all five classes at sampling rates of 360 Hz and 114 Hz (Tables <ref type="table" target="#tab_7">5</ref><ref type="table" target="#tab_8">6</ref><ref type="table" target="#tab_9">7</ref><ref type="table" target="#tab_10">8</ref>). Our per-class classification results are competitive when compared to results from methods in <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b39">[40]</ref>.</p><p>Since varying the sampling rate had minimal impact on performance, we conclude that our approach emulates the performance of stateof-the-art models at a lower sampling rate and with a set of simple features.      Moreover, this performance level was comparable to that of state-of-the-art ECG classification algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In summary, we demonstrate that our approach is able to emulate state-ofthe-art classification results while using a significantly lower sampling rate. In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work we considered the application of Restricted Boltzmann Ma- *Experimental results demonstrate that classifiers built into this deep learning-based framework achieve state-ofthe-art recognition accuracies on ventricular ectopic beats and supraventricular ectopic beats using lower sampling rates and simple features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>5</head><label>5</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>volution filters and has been recently employed in the automated classification of ECG signals. RBMs belong to category of Markov Random Field (MRF) which constitutes an visible layer corresponding to the input layer and a hidden layer corresponding to the latent feature representation. The connections between the nodes are bidirectional, so given an input vector one can obtain the latent feature representation and also vice versa. Training of the individual layers is done in an unsupervised manner and final fine-tuning is performed by adding a linear classifier to the top layer of the DBN and performing a supervised optimization. The ECG classification community has taken notice of these pivotal developments and a recent work [39] introduced a restricted Boltzmann machine learning algorithm for two-lead heart beat classification wherein the unsupervised learning algorithm of restricted Boltzmann machine helped in mining the large set of unlabelled ECG wave beats in the heart healthcare monitoring ap-M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT plications. Wang and Shang [45] used DBN to automatically extract features from raw unlabeled physiological two-lead ECG data. For the automatic clas-85 sification ECG signals, one can find the solution proposed in [46] based on the combination DBN and SVM. In particular, DBN was used for feature learning and the obtained features are fed to SVM for training and classification. Rahlal et al. [40] while also performing ECG classification using deep neural network (DNN) didn't use complex features but used stacked denoising autoencoders 90 (SDAEs) for suitable feature representation from the raw two -lead ECG data. Zubair et al. [43] used CNN with 44 recordings of ECG signals obtained from MIT-BIH database. They extracted R-peak ECG beat patterns for the training of the three-layer CNN. They achieved 92.70% accuracy in detecting the ECG beats into their respective classes (normal, fusion beat, supraventricular ectopic 95 beat, unknown beat, and ventricular ectopic beat).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>times cumbersome. Another line of work employing deep learning for ECG classification involved developing patient specific deep architecture models. Authors proposed a patient specific heartbeat classification framework using time M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT frequency representation and a DL architectural model in [47]. Here, Modified Frequency Slice Wavelet Transform (MFSWT) produced the time-frequency image for heartbeat signal and a deep neural network (DNN) classifier was used for classification. Features were automatically abstracted by stacked denoising auto-encoder (SDA) from the transferred timefrequency image and DNN classifier was constructed by an encoder layer of SDA and a softmax layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>mann Machine (RBM) and deep belief networks (DBN) for single lead ECG classification with simpler features and low sampling rate. This framework of simple features and a low sampling rate yielded competitive ECG classifi-M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT cation performance at lower computational cost, making it a highly practical option in a clinical setting. Although deep learning algorithms are statistically motivated approaches, to the best of our knowledge a deep learning framework</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Block diagram of the proposed methodology</figDesc><graphic coords="9,133.77,124.80,412.47,171.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT onset and T-wave offset times; a Boolean value indicates the presence/absence of a P-wave and, if present, gives the P-wave onset and offset time for each heartbeat fiducial point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>2. 3 . 1 .</head><label>31</label><figDesc>Feature Set 2 FS2's 22 features consisted of RR intervals and fixed interval morphologies<ref type="bibr" target="#b3">[4]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Two time-sampling methods for extracting ECG morphology features. (a)Segmented Morphology Intervals Features: Post determination of the fudicial point (FP), the QRS onset and offset and T-wave offset points are found. Ten evenly spaced samples of the ECG between the QRS onset and offset and nine evenly spaced samples of the ECG between the QRS offset and T-wave offset are extracted. (b) Fixed-interval morphology features: Post determination of the FP, nine samples of the ECG between FP-50 ms and FP + 100 ms andnine samples between FP+150 ms and FP+500 ms are extracted<ref type="bibr" target="#b3">[4]</ref> </figDesc><graphic coords="14,133.77,124.80,425.20,108.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>â€¢â€¢</head><label></label><figDesc>portion of the ECG between FP-50 ms and 100 ms. Nine samples of the ECG between FP-50ms and FP+100ms were extracted from this window. The second window approximately covered the T-wave and started at 150 ms and finished at 500 ms. The next nine samples between FP+150ms and FP+500ms were extracted from the second window, for a total of 18 features used in FS2.[Figure2b] So in totality, the feature sets can be defined as the combination of the following: Feature Set1 (FS1)<ref type="bibr" target="#b25">(26)</ref>: RR intervals (4), heartbeat intervals (3), segmented morphology<ref type="bibr" target="#b18">(19)</ref> â€¢ Feature Set1 (FS2)<ref type="bibr" target="#b21">(22)</ref>: RR intervals (4), fixed interval morphology<ref type="bibr" target="#b17">(18)</ref> An extensive statistical Hypothesis testing experimentation was performed to define these feature sets. The Hypothesis testing results indicated that segmented morphology features, heart-beat interval features and RR Interval features change significantly for SVEB arrhythmia case as compared to VEB and non-arrhythmia class. Due to the robustness of these features to distinguish between SVEB and remaining classes, these features constituted our Feature Set 1. The test also revealed that Fixed Interval Morphology and RR Intervals alter significantly for the VEB arrhythmia samples and hence constituted our Feature Set 2. In addition to Hypothesis testing, we also performed the multi-collinearity test which included a pair-wise correlation and found that multi-collinearity was not a problem in case of RBM-DBN model as the paired t test revealed that the predictors are not correlated with other predictors in the model. Thus, the entire feature extraction can be summarized as follows: Pre-RR Interval â€¢ Post-RR Interval RR Intervals â€¢ Average-RR Interval â€¢ Local avg -RR Interval â€¢ QRS Duration (QRS offset-QRS onset) Heartbeat Intervals â€¢ T-wave duration(T-wave offset-QRS offset) â€¢ P wave flag Segmented Morphology Intervals â€¢ ECG morphology (10 samples) between QRS onset and QRS offset of lead A â€¢ ECG morphology (9 samples) between QRS offset and T-wave offset of lead A Fixed Interval Morphology â€¢ ECG morphology (10 samples) between FP-50ms to FP + 100ms of lead A â€¢ ECG morphology (9 samples) between FP + 150ms to FP + 500ms of lead A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Schematic of a restricted Boltzmann machine</figDesc><graphic coords="18,243.81,203.01,120.30,59.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Schematic of a deep belief network of three layers.</figDesc><graphic coords="19,243.81,508.36,120.30,133.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: MIT-BIH database division into training and testing sets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>we performed a large number of experiments where we used varying combinations of batch sizes (i.e., number of training vectors used in each pass of each epoch for the contrastive divergence algorithm), numbers of hidden units, learning rates, and numbers of stacked RBMs. The final classification layer had five output units, one for each class, and the unit with the highest activation level was considered the most probable class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Recognition Accuracy for VEB arrhythmia at different sampling rate</figDesc><graphic coords="26,133.77,124.80,343.71,301.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>-DL and FS2-DL is consistently higher for SVEB arthymia and VEB arrthymia clasification respectively and improves relative to other boosting methods used in Chazel<ref type="bibr" target="#b3">[4]</ref> [6] methods and LDA, QDA, ANN methods in<ref type="bibr" target="#b65">[66]</ref>, as the fraction of training data is reduced. The proposed deep learning framework thus proves to be the most stable method over all training fractions as observed in both the cases, as measured by the deviation of the accuracies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>varying the number of stacked RBMs and found that outputs of three layered trained RBMs achieved the best performance results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>the case of an average sampling rate of 114 samples versus 360, we are actually achieving a gain factor of three. In fact the smaller feature-set representation and the deep learning framework together contain sufficient discriminative information for accurate ECG classification. Thus, with a suitable choice of parameters, the classifiers built using this deep learning framework provide competitive performance. In addition, our proposed framework opens a new window for future research, highlighting the huge potential of deep learning based methods for accurate classification of other physiological signals, such as arterial blood pressure (ABP), electromyograms (EMG), and heart rate variability (HRV).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>chines and deep belief networks to the automatic classification of single-lead ECG signals. Experimental results indicate that our deep learning framework demonstrates a classification accuracy on the MIT-BIH database of 93.78% for SVEB class signals and 96.94% for VEB class signals at a sampling rate of 360 Hz. Thus our framework provides performance competitive with that of stateof-the-art methods. Experimental results also demonstrate that this framework provides similar classification accuracy (93.63% for SVEB and 95.87% for VEB) when sampling at only 114 Hz. Thus a lower sampling rate of 114 Hz is sufficient to provide good discriminatory power for the ECG classification task. In conclusion, our approach emulated the performance of state-of-the-art threatening ventricular arrhythmias using convolutional neural network, Future Generation Computer Systems 79 (2018) 952-959. learning framework involving Restricted Boltzmann Machine (RBM) and deep belief networks (DBN) is proposed for ECG arrhythmia classification. *The proposed methodology performs robust features extraction for ECG signals at a very low sampling rate of 114 Hz.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="27,133.77,124.80,343.71,268.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Description of Features Included in Feature Group Label</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>MIT-BIH arrhythmia database heartbeat mapped to AAMI heartbeat classes</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>and Table 4, respectively. Column 1 indicates the</figDesc><table><row><cell cols="5">ACCEPTED MANUSCRIPT</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rate</cell><cell>CPU</cell><cell>Time</cell><cell></cell><cell cols="2">SVEB</cell><cell></cell><cell></cell><cell>VEB</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(Hz)</cell><cell>Cycles</cell><cell>in Âµ s</cell><cell>Acc</cell><cell>Se</cell><cell>PPV FPR</cell><cell>Acc</cell><cell>Se</cell><cell>PPV FPR</cell></row><row><cell cols="9">methodology and column 2 indicates the sampling rate; column 3-4 represent the CPU Cycles and time consumed; columns 5-12 indicate the gross classifier performance in terms of Acc (Accuracy), Se (Sensitivity), PPV (Positive predic-tive value) and FPR (False positive rate) for the two arrhythmia types. Rows 1 and 2 in both tables report the overall performance of our classification using Feature Set 1 and Deep Learning and using Feature Set 2 and Deep Learn-ing, respectively. The independent performance assessment of the configuration M FS1+DL 360 18917 328.1 93.78 88.39 33.63 6.68 96.63 77.74 69.20 2.17 FS2+DL 360 19563 317.8 93.47 70.99 32.44 5.66 96.94 85.22 56.63 4.11 Chazel et al. [4] 360 57341 964.2 94.6 75.9 38.5 4.7 97.4 77.7 81.9 1.2 Chazel et al. [6] 360 22731 357.4 93.6 61.2 31.2 5.2 95.4 72.4 62.3 3.0 A N U S C R I P T Chazel et al. [6] 360 23545 392.7 94.4 73.5 37.0 4.8 97.8 87.6 80.3 1.5</cell></row><row><cell cols="7">of FS1 and Deep learning (FS1-DL)framework resulted in an accuracy of 93.78%, a sensitivity of 88.39%, a positive predictivity of 33.63%, and an FPR of 6.68% for the SVEB class. For the VEB class, FS2 and Deep learning framework (FS1-DL) performed better with an accuracy of 96.94%, sensitivity of 85.22%, positive predictivity of 56.63%, and False positive ratio of 4.11%. Chazel [4] reported a classification accuracy of 94.6% and 97.4 % for SVEB &amp; VEB Class but consumed higher CPU cyles as they used complex feature extraction calculation at a higher sampling rate (360Hz). A comparable accu-racy of 93.6 % at 360 Hz was obtained using a simpler feature sets in [6] along with reduced CPU cycle and time consumption. Our proposed Deep learning framework at a sampling rate of 360Hz provided a high accuracy of 93.78% for A C C E P T E D</cell><cell></cell><cell></cell></row><row><cell cols="7">the SVEB class using the feature set 1 and of 96.94% for the VEB class using</cell><cell></cell><cell></cell></row><row><cell>feature set 2.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison of classification results on the test dataset at sampling rate of 360 Hz</figDesc><table><row><cell></cell><cell>Rate</cell><cell>CPU</cell><cell>Time</cell><cell></cell><cell cols="2">SVEB</cell><cell></cell><cell></cell><cell cols="2">VEB</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(Hz)</cell><cell>Cycles</cell><cell>in Âµs</cell><cell>Acc</cell><cell>Se</cell><cell cols="2">PPV FPR</cell><cell>Acc</cell><cell>Se</cell><cell cols="2">PPV FPR</cell></row><row><cell>FS1+DL</cell><cell>114</cell><cell cols="10">12884 225.8 93.63 88.62 35.49 6.17 95.57 78.49 59.65 3.34</cell></row><row><cell>FS2+DL</cell><cell>114</cell><cell cols="10">13664 227.4 93.42 59.16 30.10 5.26 95.87 85.54 60.83 3.47</cell></row><row><cell>LCKSVD [65]</cell><cell>114</cell><cell cols="7">14820 252.3 93.4 75.12 32.84 5.89 93.51</cell><cell>76</cell><cell cols="2">49.97 5.27</cell></row><row><cell>LDA Basil [66]</cell><cell>114</cell><cell cols="2">15785 257.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>93.4</cell><cell>75.8</cell><cell>61.9</cell><cell>4.8</cell></row><row><cell cols="2">QDA Basil [66] 114</cell><cell cols="2">15911 258.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>83.1</cell><cell>97</cell><cell>35.2</cell><cell>18.4</cell></row><row><cell cols="2">ANN Basil [66] 114</cell><cell cols="2">16089 294.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>96.9</cell><cell>79.7</cell><cell>74.6</cell><cell>1.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of classification results on the test dataset at sampling rate of 114 Hz</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>against Table 4, our results demonstrate that a deep learning algorithm framework is better suited to detect VEB and SVEB types of arrhythmia at the lower sampling rate of 114 Hz. Since increasing the sampling rate to 360 Hz did not provide any significant gain in performance, it follows that a 114 Hz sampling rate can provide robust discriminatory power for this classification task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Confusion Matrix obtained with test set using FS1 + Deep Learning Framework at</figDesc><table><row><cell>Sampling Rate of 360 Hz</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Confusion Matrix obtained with test set using FS2 + Deep Learning Framework at</figDesc><table><row><cell>Sampling Rate of 360 Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>N</cell><cell>S</cell><cell>V</cell><cell>F</cell><cell>Q</cell></row><row><cell>N</cell><cell cols="5">31238 2565 1366 6451 640</cell></row><row><cell>S</cell><cell>41</cell><cell cols="2">1543 118</cell><cell>39</cell><cell>0</cell></row><row><cell>V</cell><cell>60</cell><cell cols="3">238 2194 303</cell><cell>0</cell></row><row><cell>F</cell><cell>17</cell><cell>1</cell><cell>22</cell><cell>344</cell><cell>0</cell></row><row><cell>Q</cell><cell>1</cell><cell>0</cell><cell>2</cell><cell>0</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Confusion Matrix obtained with test set using FS1 + Deep Learning Framework at</figDesc><table><row><cell>Sampling Rate of 114 Hz</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>N</cell><cell>S</cell><cell>V</cell><cell>F</cell><cell>Q</cell></row><row><cell>N</cell><cell cols="5">36213 2189 1181 2648 29</cell></row><row><cell>S</cell><cell>347</cell><cell cols="2">1030 358</cell><cell>6</cell><cell>0</cell></row><row><cell>V</cell><cell>100</cell><cell cols="3">201 2391 100</cell><cell>3</cell></row><row><cell>F</cell><cell>19</cell><cell>1</cell><cell>113</cell><cell>251</cell><cell>0</cell></row><row><cell>Q</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Confusion Matrix obtained with test set using FS2 + Deep Learning Framework at Sampling Rate of 114 HzNotably, the combination of parameters that yielded the best result was 112 565 hidden units, a batch size of 42, and a learning rate of 0.00001. With this combination, the DBN achieved a very low error rate of 4.7 %. We used this</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M A N U S C R I P T A C C E P T E D ACCEPTED MANUSCRIPT</head><p>models using a lower sampling rate and a set of simple features. As future work, we will investigate other types of embedding that represent ECG recordings as a feature vector and then use hierarchical deep learning algorithms for robust performance. We would also like to integrate Restricted Boltzmann Machines with ensemble based/Bagging approachto construct multiple individual classifiers. Considering the fact that both deep learning and ensemble learning have leverage in constructing complicated nonlinear functions, the combination of the two frameworks can better handle hard artificial intelligence tasks. We will also extend our framework to the classification of sensor-based cognitive assessment data and the recognition of daily life activities, areas important in healthcare for ubiquitous health computing and medical informatics.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">11th textbook of medical physiology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Guyton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<title level="m">Cardiac oscillations and arrhythmia analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="409" to="422" />
		</imprint>
	</monogr>
	<note>Complex Systems Science in Biomedicine</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">AHA clinical competence statement on electrocardiography and ambulatory electrocardiography</title>
		<author>
			<persName><surname>Acc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American College of Cardiology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2091" to="2100" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic classification of heartbeats using ECG morphology and heartbeat interval features</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Chazal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1196" to="1206" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A patient-adapting heartbeat classifier using ECG morphology and heartbeat interval features</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Chazal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2535" to="2543" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detection of supraventricular and ventricular ectopic beats using a single lead ECG</title>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Annual International Conference of IEEE Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="45" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heartbeat classification using feature selection driven by database generalization criteria</title>
		<author>
			<persName><forename type="first">M</forename><surname>Llamedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>MartÃ­nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="616" to="625" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heartbeat classification using morphological and dynamic features of ECG signals</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Coimbra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2930" to="2941" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clustering ECG complexes using hermite functions and self-organizing maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lagerholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Braccini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Edenbrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sornmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="838" to="848" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A generic and robust system for automated patient-specific classification of ECG signals</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1415" to="1426" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ECG arrhythmias recognition system based on independent component analysis feature extraction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Albayrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE TENCON Region Conference</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing wavelet transforms for recognizing cardiac patterns</title>
		<author>
			<persName><forename type="first">L</forename><surname>Senhadji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bellanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Passariello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Engineering in Medicine and Biology Magazine</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="173" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A patient-adaptable ECG beat classifier using a mixture of experts approach</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Palreddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Tompkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="891" to="900" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Clustering ECG complexes using hermite functions and self-organizing maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lagerholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Braccini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Edenbrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sornmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="838" to="848" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ECG beat recognition using fuzzy hybrid neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Linh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1265" to="1271" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Support vector machine-based expert system for reliable heartbeat recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Hoai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Markiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="582" to="589" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Weighted conditional random fields for supervised interpatient heartbeat classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>De Lannoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>FranÃ§ois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Delbeke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="241" to="247" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time classification of ECGs on a PDA</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Illarramendi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="34" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Premature ventricular contraction classification by the kth nearest-neighbours rule</title>
		<author>
			<persName><forename type="first">I</forename><surname>Christov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jekova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bortolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological measurement</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Block-based neural networks for personalized ECG signal classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1750" to="1761" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Active learning applied to patient-adaptive heartbeat classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wiens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Guttag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2442" to="2450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CNN features offthe-shelf: an astounding baseline for recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="512" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Abdel-Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6669" to="6673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pedestrian detection with unsupervised multi-stage feature learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3626" to="3633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Large displacement optical flow with deep matching</title>
		<author>
			<persName><forename type="first">P</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepflow</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1385" to="1392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Human pose estimation via deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deeppose</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1653" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.7302</idno>
		<title level="m">Learning human pose estimation features with convolutional networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Real-time continuous pose recovery of human hands using convolutional networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Perlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">169</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">3D object recognition with deep belief nets</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1339" to="1347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep learning face representation by joint identification-verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1988" to="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Imagenet classification with deep convolutional neural networks, in: Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups, Signal Processing Magazine</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>-R. Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Conversational speech transcription using contextdependent deep neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Interspeech</publisher>
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">New types of deep neural network learning for speech recognition and related applications: An overview</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8599" to="8603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A restricted boltzmann machine based two-lead electrocardiography classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wearable and Implantable Body Sensor Networks (BSN), 2015 IEEE 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep learning approach for active classification of electrocardiogram signals</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Al Rahhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alhichri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alajlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Yager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">345</biblScope>
			<biblScope unit="page" from="340" to="354" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Raghavendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gertych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hagiwara</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An automated ecg beat classification system using convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zubair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IT Convergence and Security (ICITCS), 2016 6th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time patient-specific ecg classification by 1-d convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="664" to="675" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Modeling physiological data with deep belief networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of information and education technology (IJIET)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">505</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Classification of electrocardiogram signals with deep belief networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Huanhuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Science and Engineering (CSE)</title>
		<imprint>
			<biblScope unit="page" from="7" to="12" />
			<date type="published" when="2014">2014. 2014</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Patient-specific deep architectural model for ecg classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cuschieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of healthcare engineering</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Arrhythmia classification using waveform ecg signals</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Altan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Allahverdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on advanced technology &amp; sciences Google Scholar</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Discriminative deep metric learning for face verification in the wild</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1875" to="1882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hybrid deep learning for face verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1489" to="1496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A study of recursive least squares (rls) adaptive filter algorithm in noise removal from ecg signals</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Mugdha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Rawnaque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Informatics, Electronics &amp; Vision (ICIEV), 2015 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ecg beat detection using filter banks</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">X</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Tompkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="192" to="202" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adaptive technique for p and t wave delineation in electrocardiogram signals</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bayasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tekeste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khandoker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Annual International Conference of the IEEE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="90" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Building high-level features using large scale unsupervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8595" to="8598" />
		</imprint>
	</monogr>
	<note>2013 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning deep architectures for ai</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">A practical guide to training Restricted Boltzmann Machines</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="599" to="619" />
		</imprint>
	</monogr>
	<note>Neural Networks: Tricks of the Trade</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng ; M A N U S C R I P T A C C E P T E D Accepted</surname></persName>
		</author>
		<author>
			<persName><surname>Manuscript</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">MIT-BIH arrhythmia database</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Moody</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3rd Edition</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Testing and Reporting Performance Results of Cardiac Rhythm and STsegment Measurement Algorithms</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Recommended practice for testing and reporting performance results of ventricular arrhythmia detection algorithms</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Wulsin</surname></persName>
		</author>
		<author>
			<persName><surname>Toolbox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Department of Bioengineering, University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Leveraging a discriminative dictionary learning algorithm for single-lead ecg classification</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mathews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Polania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Barner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">st Annual Northeast Biomedical Engineering Conference (NEBEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A comparison of statistical machine learning methods in heartbeat detection and classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Basil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lakshminarayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data Analytics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="16" to="25" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
