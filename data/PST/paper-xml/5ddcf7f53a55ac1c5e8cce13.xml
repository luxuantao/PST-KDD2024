<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Meta-Learning of Neural Architectures for Few-Shot Learning</title>
				<funder>
					<orgName type="full">BMBF</orgName>
				</funder>
				<funder ref="#_7SD6J6J">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
							<email>elsken@cs.uni-freiburg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Freiburg</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benedikt</forename><surname>Staffler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Metzen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Bosch Center for Artificial Intelligence</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Freiburg</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Meta-Learning of Neural Architectures for Few-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent progress in neural architecture search (NAS) has allowed scaling the automated design of neural architectures to real-world domains, such as object detection and semantic segmentation. However, one prerequisite for the application of NAS are large amounts of labeled data and compute resources. This renders its application challenging in few-shot learning scenarios, where many related tasks need to be learned, each with limited amounts of data and compute time. Thus, few-shot learning is typically done with a fixed neural architecture. To improve upon this, we propose METANAS, the first method which fully integrates NAS with gradient-based meta-learning. METANAS optimizes a meta-architecture along with the meta-weights during meta-training. During meta-testing, architectures can be adapted to a novel task with a few steps of the task optimizer, that is: task adaptation becomes computationally cheap and requires only little data per task. Moreover, METANAS is agnostic in that it can be used with arbitrary model-agnostic meta-learning algorithms and arbitrary gradient-based NAS methods. Empirical results on standard few-shot classification benchmarks show that METANAS with a combination of DARTS and REPTILE yields state-of-the-art results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Neural architecture search (NAS) <ref type="bibr" target="#b13">[14]</ref> has seen remarkable progress on various computer vision tasks, such as image classification <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b6">7]</ref>, object detection <ref type="bibr" target="#b19">[20]</ref>, semantic segmentation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36]</ref>, and disparity estimation <ref type="bibr" target="#b43">[44]</ref>. One key prerequisite for this success is the availability of large and diverse (labeled) data sets for the respective task. Furthermore, NAS requires considerable compute resources for optimizing the neural architecture for the target task. This makes it difficult to apply NAS in use-cases where one does not focus on a single task but is interested in a large set (distribution) of tasks. To be effective in this setting, learning must not require large amounts of data and  : Illustration of our proposed method METANAS and related work. Gray highlights task learning, blue metalearning, and orange NAS components. Top: gradientbased meta-learning with fixed architecture such as MAML <ref type="bibr" target="#b15">[16]</ref> or REPTILE <ref type="bibr" target="#b36">[37]</ref>. Middle: applying NAS to metalearning such as AutoMeta <ref type="bibr" target="#b24">[25]</ref>. Bottom: Proposed joint meta-learning of architecture and weights with METANAS. Since architectures are adapted during task learning, the proposed method can learn task-specific architectures. compute for every task but should, like humans, be able to rapidly adapt to novel tasks by building upon experience from related tasks <ref type="bibr" target="#b26">[27]</ref>. This concept of learning from experience and related tasks is known as meta-learning or learning to learn <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b20">21]</ref>. Here, we consider the problem of few-shot learning, i.e., learning new tasks from just a few examples. Prior work has proposed meta-learning methods for this problem that are model-agnostic <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37]</ref> and allow meta-learning weights of fixed neural architectures (see <ref type="bibr">Figure 1,</ref><ref type="bibr">top)</ref>.</p><p>In this work, we fully integrate meta-learning with NAS, by proposing METANAS. METANAS allows adapting architectures to novel tasks based on few datapoints with just a few steps of a gradient-based task optimizer. This allows METANAS to generate task-specific architectures that are adapted to every task separately (but from a joint metalearned meta-architecture). This is in contrast to prior work that applied NAS to multi-task or few-shot learning, where a single neural architecture is optimized to work well on average across all tasks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b38">39]</ref> (see Figure <ref type="figure" target="#fig_0">1</ref>, middle). Moreover, our method directly provides trained weights for these task-specific architectures, without requiring meta retraining them as in concurrent work <ref type="bibr" target="#b29">[30]</ref>. Conceptual illustrations of our method are shown in Figure <ref type="figure" target="#fig_0">1</ref>, bottom, and in Figure <ref type="figure">3</ref>. The key contributions of this work are as follows:</p><p>1. We show that model-agnostic, gradient-based metalearning methods (such as <ref type="bibr" target="#b15">[16]</ref>) can very naturally be combined with recently proposed gradient-based NAS methods, such as DARTS <ref type="bibr" target="#b32">[33]</ref>. This allows for joint meta-learning of not only the weights (for a given, fixed architecture) but also meta-learning the architecture itself (Section 3, see Figure <ref type="figure" target="#fig_0">1</ref> for an illustration).</p><p>2. We propose METANAS, a meta-learning algorithm that can quickly adapt the meta-architecture to a taskdependent architecture. This optimization of the architecture for the task can be conducted with few labeled datapoints and only a few steps of the task optimizer (see Figure <ref type="figure">3</ref> for an illustration).</p><p>3. We extend DARTS such that task-dependent architectures need not be (meta) re-trained, which would be infeasible in the few-shot learning setting with taskdependent architectures for hundreds of tasks (requiring hundreds re-trainings). We achieve this by introducing a novel soft-pruning mechanism based on a temperature annealing into DARTS (see Figure <ref type="figure" target="#fig_2">2</ref>). This mechanism lets architecture parameters converge to the architectures obtained by the hard-pruning at the end of DARTS, while giving the weights time to adapt to this pruning. Because of this, pruning no longer results in significant drops in accuracy, which might also be of interest for the standard single-task setting. We give more details in Section 4.</p><p>METANAS is agnostic in the sense that it is compat-ible with arbitrary gradient-based model-agnostic metalearning algorithms and arbitrary gradient-based NAS methods employing a continuous relaxation of the architecture search space. Already in combination with the simple meta-learning algorithm REPTILE <ref type="bibr" target="#b36">[37]</ref> and NAS algorithm DARTS <ref type="bibr" target="#b32">[33]</ref>, METANAS yields state-of-the-art results on the standard few-shot classification benchmarks Omniglot and MiniImagenet. This paper is structured as follows: in Section 2, we review related work on few-shot learning and neural architecture search. In Section 3, we show that model agnostic, gradient-based meta-learning can naturally be combined with gradient-based NAS. The soft-pruning strategy to obtain task-dependent architectures without the need for retraining is introduced in Section 4. We conduct experiments on standard few-shot learning data sets in Section 5 and conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Few-Shot Learning via Meta-Learning Few-Shot Learning refers to the problem of learning to solve a task (e.g., a classification problem) from just a few training examples. This problem is challenging in combination with deep learning as neural networks tend to be highly over-parameterized and therefore prone to overfitting when only very little data is available. Prior work <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref> often approaches few-shot learning via meta-learning or learning to learn <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, where one aims at learning from a variety of learning tasks in order to learn new tasks much faster than otherwise possible <ref type="bibr" target="#b50">[51]</ref>. There are various approaches to few-shot learning, e.g., learning to compare new samples to previously seen ones <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b51">52]</ref> or meta-learning a subset of weights that is shared across tasks but fixed during task learning <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>In this work, we focus on a particular class of approaches denoted as model-agnostic meta-learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b17">18]</ref>. These methods meta-learn an initial set of weights for neural networks that can be quickly adapted to a new task with just a few steps of gradient descent. For this, the meta-learning objective is designed to explicitly reward quick adaptability by incorporating the task training process into the meta-objective. This meta-objective is then usually optimized via gradient-based methods. Our method extends these approaches to not only meta-learn an initial set of weights for a given, fixed architecture but to also meta-learn the architecture itself. As our method can be combined with any model-agnostic meta-learning method, future improvements in these methods can be directly utilized in our framework.</p><p>Neural Architecture Search Neural Architecture Search (NAS), the process of automatically designing neural network architectures <ref type="bibr" target="#b13">[14]</ref>, has recently become a popular approach in deep learning as it can replace the cumbersome manual design of architectures while at the same time achieving state-of-the-art performance on a variety of tasks <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b43">44]</ref>. We briefly review the main approaches and refer to the recent survey by Elsken et al. <ref type="bibr" target="#b13">[14]</ref> for a more thorough literature overview. Researchers often frame NAS as a reinforcement learning problem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b59">60]</ref> or employ evolutionary algorithms <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b40">41]</ref>. Unfortunately, most of these methods are very expensive, as they require training hundreds or even thousands of architectures from scratch. Therefore, most recent work focuses on developing more efficient methods, e.g., via network morphisms <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b46">47]</ref>, weight sharing <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b3">4]</ref>, or multifidelity optimization <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b55">56]</ref>; however, they are often still restricted to relatively small problems.</p><p>To overcome this problem, Liu et al. <ref type="bibr" target="#b32">[33]</ref> proposed a continuous relaxation of the architecture search space that allows optimizing the architecture via gradient-based methods. This is achieved by using a weighted sum of possible candidate operations for each layer, where the real-valued weights then effectively parametrize the network's architecture as follows:</p><formula xml:id="formula_0">x (j) = i&lt;j o?O ?i,j o o x (i) , w i,j o =: i&lt;j M ixedOp x (i) , w i,j ,<label>(1)</label></formula><p>where ?i,j o = exp(? i,j o ) o ?O exp(? i,j o ) are normalized mixture weights that sum to 1, x (j) and x (i) represent feature maps in the network, O denotes a set of candidate operations (e.g., 3 ? 3 convolution, 5 ? 5 convolution, 3 ? 3 average pooling, ...) for transforming previous feature maps to new ones, w = (w i,j o ) i,j,o denotes the regular weights of the operations, and ? = (? i,j o ) i,j,o serves as a real valued, unconstrained parameterization of the architecture. The mixture of candidate operations is denoted as mixed operation and the model containing all the mixed operations is often referred to as the one-shot model.</p><p>DARTS then optimizes both the weights of the one-shot model w and architectural parameters ? by alternating gradient descent on the training and validation loss, respectively. After the search phase, a discrete architecture is obtained by choosing a predefined number (usually two) of most important incoming operations (those with the highest operation weighting factor ?i,j o ) for each intermediate node j while all others are pruned. This hard-pruning deteriorates performance <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>: e.g., Xie et al. <ref type="bibr" target="#b53">[54]</ref> report a performance drop from 88% (one-shot model's accuracy) to 56% (pruned model's accuracy). Thus, the pruned model requires retraining w. We address this shortcoming in Section 4.</p><p>In our work, we choose DARTS for neural architecture search because of conceptual similarities to gradient-based meta-learning, such as MAML <ref type="bibr" target="#b15">[16]</ref>, which will allow us to combine the two kinds of methods.</p><p>Neural Architecture Search for Meta-Learning There has been some recent work on combining NAS and metalearning. Wong et al. <ref type="bibr" target="#b52">[53]</ref> train an automated machine learning (AutoML <ref type="bibr" target="#b22">[23]</ref>) system via reinforcement learning on multiple tasks and then use transfer learning to speed up the search for hyperparameters and architecture via the learned system on new tasks. Their work is more focused on hyperparameters rather than the architecture; the considered architecture search space is limited to choosing one of few pretrained architectures. Closest to our work are <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b29">30]</ref>. Kim et al. <ref type="bibr" target="#b24">[25]</ref> wrap neural architecture search around meta-learning as illustrated in Figure <ref type="figure" target="#fig_0">1</ref> (middle). They apply progressive neural architecture search <ref type="bibr" target="#b31">[32]</ref> to few shot learning, but this requires running the entire meta-training from scratch in every iteration of the NAS algorithm; therefore, their approach requires large computational costs of more than a hundred GPU days. The approach is also limited to searching for a single architecture suitable for few-shot learning rather than learning task-dependent architectures, which our methods supports. In a concurrent work <ref type="bibr" target="#b29">[30]</ref>, the authors proposed to combine gradient-based NAS and meta-learning for finding task-dependent architectures, similar to our work. However, as they employ the hard-pruning strategy from DARTS with significant drops in performance, they require re-running meta-training for every task-dependent architecture (potentially hundreds), rendering the evaluation of novel tasks expensive. In contrast, our method does not require re-training task-dependent architectures and thus a single run of metatraining suffices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Marrying Gradient-based Meta-Learning and Gradient-based NAS</head><p>Our goal is to build a meta-learning algorithm that yields a meta-learned architecture ? meta with corresponding meta-learned weights w meta . Then, given a new task T i , both ? meta and w meta shall quickly adapt to T i based on few labeled samples. To solve this problem, we now derive METANAS, a method that naturally combines gradientbased meta-learning methods with gradient-based NAS and allows meta-learning ? meta along with w meta . In Section 4, we will then describe how the meta-architectures encoded by ? meta can be quickly specialized to a new task without requiring re-training of w meta .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Setup for Few-Shot Classification</head><p>In the classic supervised deep learning setting, the goal is to find optimal weights of a neural network by minimiz-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Gradient-based Meta-Learning of Neural Architectures</head><p>Similar to MAML's meta-learning strategy in the weight space <ref type="bibr" target="#b15">[16]</ref>, our goal is to meta-learn an architecture with corresponding weights which is able to quickly adapt to new tasks. In accordance with MAML we do so by minimizing a meta-objective</p><formula xml:id="formula_1">L meta (w, ?, p train , ? k ) = Ti?p train L Ti ? k (w, ?, D Ti train ), D Ti test = Ti?p train L Ti (w * Ti , ? * Ti ), D Ti test</formula><p>(2) with respect to a real-valued parametrization ? of the neural network architecture and corresponding weights w. T i = (D Ti train , D Ti test ) denotes a training task sampled from the training task distribution p train (T ), L Ti the corresponding task loss, and ? k (w, ?, D Ti train ) the task learning algorithm or simply task-learner, where k refers to k iterations of learning/ weight updates (e.g., by SGD). Prior work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b24">25]</ref> considered a fixed, predefined architecture ? fixed and chose ? k to be an optimizer like SGD for the weights:</p><formula xml:id="formula_2">w * = w k = ? k (w, ? fixed , D Ti</formula><p>train ) with the one-step updates w j+1 = ?(w j , D Ti train ) := w j -? task ? w L T (w j , D Ti train ) and w 0 = w. In contrast, we choose ? k to be k steps of gradient-based neural architecture search inspired by DARTS <ref type="bibr" target="#b32">[33]</ref> with weight learning rate ? task and architecture learning rate ? task :</p><formula xml:id="formula_3">w j+1 ? j+1 = ?(w j , ? j , D Ti train ) = w j -? task ? w L T (w j , ? j , D Ti train ) ? j -? task ? ? L T (w j , ? j , D Ti train ) .<label>(3)</label></formula><p>Therefore, ? k does not only optimize task weights w * Ti but also optimizes task architecture ? * Ti . Note that we use the same data set to update w j and ? j (Equation <ref type="formula" target="#formula_3">3</ref>) in contrast to Liu et al. <ref type="bibr" target="#b32">[33]</ref> due to the limited amount of data in the few-shot setting not allowing to split into training and validation per task. Moreover, using the same data set also allows updating both sets of parameters with a single forward and backward pass, see Lian et al. <ref type="bibr" target="#b29">[30]</ref>. As we use a real-valued parametrization of ? and a gradient-based task optimizer, the meta-objective L meta (Equation <ref type="formula">2</ref>) is differentiable with respect to w and ?. This means we can use any gradient-based meta-learning algorithm ? not only for w but also for the architecture ?. As an example, one could use MAML <ref type="bibr" target="#b15">[16]</ref> as a meta-learning algorithm, which runs SGD on the meta-objective, yielding meta-updates</p><formula xml:id="formula_4">w i+1 meta ? i+1 meta = ? M AM L (? i meta , w i meta , p train , ? k ) = w i meta -? meta ? w L meta (w i meta , ? i meta , p train , ? k ) ? i meta -? meta ? ? L meta (w i meta , ? i meta , p train , ? k )</formula><p>Algorithm 1 METANAS: Meta-Learning of Neural Architectures 1: Input: distribution over tasks p(T ), task-learner ? k (w, a, D Ti train ) # e.g. DARTS <ref type="bibr" target="#b32">[33]</ref> meta-learner ? w , ? ? # e.g. REPTILE <ref type="bibr" target="#b36">[37]</ref> 2: Initialize w meta , ? meta 3: while not converged do for all T i do 6:</p><formula xml:id="formula_5">w * Ti , ? * Ti ? ? k (w meta , ? meta , D Ti train ) 7:</formula><p>end for 8:</p><formula xml:id="formula_6">w meta ? ? w w meta , {w * Ti , ? * Ti , T i } n i=1 9: ? meta ? ? ? ? meta , {w * Ti , ? * Ti , T i } n i=1</formula><p>10: end while 11: return w meta , ? meta or, as an alternative, one could use REPTILE <ref type="bibr" target="#b36">[37]</ref>, which simply computes the updates as</p><formula xml:id="formula_7">w i+1 meta ? i+1 meta = ? REP T ILE (? i meta , w i meta , p train , ? k ) = w i meta + ? meta Ti (w * Ti -w i meta ) ? i meta + ? meta Ti (a * Ti -? i meta ) .<label>(4)</label></formula><p>We chose REPTILE for all our experiments due to its conceptual simplicity and computational efficiency compared to MAML. Note that one could also use different meta-learning algorithms for w meta and ? meta . However, we restrict ourselves to the same meta-learning algorithm for both for simplicity. We refer to Algorithm 1 for a generic template of our proposed framework for meta-learning neural architectures and to Algorithm 2 for a concrete implementation using DARTS as task learning and REPTILE as a meta-learning algorithm.</p><p>By incorporating a NAS algorithm directly into the metalearning algorithm, we can search for architectures with a single run of the meta-learning algorithm, while prior work <ref type="bibr" target="#b24">[25]</ref> required full meta-learning of hundreds of proposed architectures during the architecture search process. We highlight that Algorithm 1 is agnostic in that it can be combined with any gradient-based NAS method and any gradient-based meta-learning method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Task-dependent Architecture Adaptation</head><p>Using a NAS algorithm as a task optimizer does not only allow directly incorporating architecture search into the meta-training loop, but it also allows an adaptation of the found meta-architecture after meta-learning to new tasks (i.,e., during meta-testing). That is, it allows in principle finding a task-dependent architecture, compare Algorithm w Ti ? w Ti -? task ? w L T (w Ti , ? Ti , D Ti train )</p><p>10:</p><formula xml:id="formula_8">? Ti ? ? Ti -? task ? ? L T (w Ti , ? Ti , D Ti train ) 11:</formula><p>end for 12:</p><p>end for 13:</p><p>w meta ? w meta + ? meta Ti (w * Ti -w i meta )</p><p>14:</p><p>? meta ? ? meta + ? meta Ti (a * Ti -? i meta ) 15: end while 16: return w meta , ? meta 3. This is in contrast to prior work where the architecture is always fixed during meta-testing <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37]</ref>. Also prior work using NAS for meta-learning <ref type="bibr" target="#b24">[25]</ref> searches for a single architecture that is then shared across all tasks.</p><p>Unfortunately, the task-dependent architecture obtained by the DARTS task optimizer is non-sparse, that is, the ? Ti do not lead to mixture weights being strictly 0 or 1, compare Figure <ref type="figure" target="#fig_2">2</ref> (left) for an illustration. As discussed in Section 2, DARTS addresses this issue with a hard-pruning strategy at the end of the architecture search to obtain the final architecture from the one-shot model (line 8 in Algorithm 3). Since this hard-pruning deteriorates performance heavily (see Appendix A.1), the pruned architectures require retraining. This is particularly problematic in a few-shot learning setting as it requires meta re-training all the task-dependent architectures. This is the approach followed by <ref type="bibr" target="#b29">[30]</ref>, but it unfortunately increases the cost of a single task training during meta-testing from a few steps of the task optimizer to essentially a full meta-training run of MAML/REPTILE with a fixed architecture.</p><p>We now propose a method to remove the need for retraining by proposing two modification to DARTS that essentially re-parameterize the search space and substantially alleviate the drop in performance resulting from hardpruning. This is achieved by enforcing the mixture weights ? of the mixed operations to slowly converge to 0 or 1 during task training while giving the operation weights time to adapt to this soft pruning. meta-learned architecture and weights ? meta , w meta 2: w T ? w meta 3: ? T ? ? meta 4: for j ? 1, . . . , k do 5:</p><formula xml:id="formula_9">w T ? w T -? task ? w L T (w T , ? T , D train ) 6:</formula><p>? T ? ? T -? task ? ? L T (w T , ? T , D train ) 7: end for 8: ?T ? PRUNE(? T ) 9: Evaluate D test with ?T , w T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Soft-Pruning of Mixture over Operations</head><p>The first modification sparsifies the mixture weights of the operations forming a mixed operation that transforms node i to node j. We achieve this by changing the normalization of the mixture weights ?i,j o from Equation 1 to become increasingly sparse, that is: more similar to a onehot encoding for every i, j. To achieve this, we add a temperature ? ? that is annealed to 0 over the course of a task training:</p><formula xml:id="formula_10">?i,j ?? (o) = exp(? i,j o /? ? ) o ?O exp(? i,j o /? ? ) .<label>(5)</label></formula><p>A similar approach was proposed by <ref type="bibr" target="#b53">[54]</ref> and <ref type="bibr" target="#b10">[11]</ref> in the context of relaxing discrete distributions via the Gumbel distribution <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b33">34]</ref>. Note that this results in (approximate) one-hot mixture weights in a single mixed operation (compare Figure <ref type="figure" target="#fig_2">2</ref> (middle) for an illustration); however, the sum over all j -1 possible input nodes 0, . . . , j -1 in Equation <ref type="formula" target="#formula_0">1</ref>is still non-sparse, meaning node j is still connected to all prior nodes. As DARTS selects only the top k (k = 2 in the default) input nodes, we need additionally also to spar-sify across the possible input nodes (that is a soft-pruning of them) rather than just summing them up (as done in Equation 1), see Figure <ref type="figure" target="#fig_2">2</ref> (right) for an illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Soft-Pruning of Mixture over Input Nodes</head><p>A natural choice to also sparsify the inputs would be to also introduce weights ? i,j of the inputs and sparsify them the same way as the operations' weights by annealing a temperature ? ? to 0 over the course of a task training:</p><formula xml:id="formula_11">x (j) = i&lt;j exp(? i,j /? ? ) k&lt;j exp(? k,j /? ? ) M ixedOp x (i) . (6)</formula><p>Unfortunately, this would results in selecting exactly one input rather than a predefined number of inputs (e.g., the literature default 2 <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b32">33]</ref>). Instead, we weight every combination of k inputs to allow an arbitrary number of inputs k:</p><p>x</p><formula xml:id="formula_12">(j) = i={i1,...,i k }?I exp(? i,j /? ? ) k?I exp(? k,j /? ? ) ? M ixedOp x (i1) + ? ? ? + M ixedOp x (i k ) ,<label>(7)</label></formula><p>where I = {{i 1 , . . . , i k }|{i 1 , . . . , i k } ? {0, . . . , j -1}} denotes the set of all combinations of inputs of size k. This introduces j k additional parameters per node, which is negligible for practical settings with j ? 5. The input weights ? k,j are optimized along with the operation's weights ?. Note that we simply subsume ? and ? into ? in Algorithm 3.</p><p>With these two modifications, we can now not only find task-dependent optimal weights (given meta-weights) but also find task-dependent architectures (given a metaarchitecture) that can be hard pruned without notable drop in performance, and thus without retraining. We refer to Appendix A. For all architecture, REPTILE was used as a meta-learning algorithm and all results were obtained using the same training pipeline to ensure a fair comparison. Accuracy in %.</p><p>pruning strategies discussed on a standard NAS setting on CIFAR-10 (single task). While in theory we can now enforce a one-hot encoding of the mixture operation as well as over the input nodes, we empirically found that it is sometimes helpful to not choose the minimal temperature too small but rather allow a few (usually not more than two) weights larger than 0 instead of hard forcing an one-hot encoding. At the end of each task learning, we then simply keep all operations and input nodes with corresponding weight ? larger than some threshold (e.g., ? ? 0.01), while all others are pruned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We evaluate our proposed method on the standard fewshot image recognition benchmarks Omniglot <ref type="bibr" target="#b25">[26]</ref> and MiniImagenet (as proposed by <ref type="bibr" target="#b39">[40]</ref>) in the n-way, k-shot setting (as proposed by <ref type="bibr" target="#b51">[52]</ref>), meaning that a few-shot learning task is generated by random sampling n classes from either Omniglot or MiniImagenet and k examples for each of the n classes. We refer to <ref type="bibr" target="#b51">[52]</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Comparison under the same meta-learning algorithm.</head><p>We first compare against the architectures from the original REPTILE <ref type="bibr" target="#b36">[37]</ref> paper and from AutoMeta <ref type="bibr" target="#b24">[25]</ref> when training all models with the same meta-learning algorithm, namely REPTILE. This ensures a fair comparison and differences in performance can be clearly attributed to differences in the architecture. We re-train the architectures from REPTILE and AutoMeta with our own training pipeline for 30, 000 meta epochs (which we found to be sufficient to approximately reproduce results from the REPTILE paper) to further ensure that all architectures are trained under identical conditions. A detailed description of the experimental setup including all hyperparameters can be found in Appendix A.2 in the supplementary material.</p><p>For our method, we consider the following search space based on DARTS and AutoMeta: we search for a normal and reduction cell (which is common practice in the NAS literature <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b54">55]</ref>). Both cells are com-posed of three intermediate nodes (i.e., hidden states). The set of candidate operations is MaxPool3x3, AvgPool3x3, SkipConnect, Conv1x5-5x1, Conv3x3, SepConv3x3, Dilat-edConv3x3. Our models are composed of 4 cells, with the first and third cells being normal cells and the second and forth cell being reduction cells. The number of filters is constant throughout the whole network (rather than doubling the filters whenever the spatial resolution decreases); it is set so that the pruned models match the size (in terms of number of parameters) of the REPTILE and AutoMeta models to ensure a fair comparison. We consider models in the regime of 30, 000 parameters as well as 100, 000 parameters. Note that, in contrast to DARTS, we optimize the architectural parameters also on training data (rather than validation data) due to very limited amount of data in the few-shot setting not allowing a validation split per task.</p><p>The results are summarized in Table <ref type="table" target="#tab_1">1</ref>. In the 1-shot, 20-way Omniglot experiment, METANAS achieves superior performance in the case of small models, while in the case of large models METANAS is on-par with Au-toMeta while both outperform REPTILE. On Omniglot 5-shot, 20-way, all methods perform similarly well with METANAS and AutoMeta having slight advantages over REPTILE. On MiniImagenet 1-shot, 5way, both AutoMeta and METANAS outperform REPTILE. In the 5-shot, 5way setting, METANAS does also outperform AutoMeta in the case of larger models while being slightly worse for small models. In summary, METANAS nearly always outperforms the original REPTILE model while it is on-par or does slightly outperform AutoMeta in almost all cases. We highlight that METANAS achieves this while being 10x more efficient than AutoMeta; the AutoMeta authors report computational costs in the order of 100 GPU days while METANAS was run for approximately one week on a single GPU. Moreover, METANAS finds task-specific architectures; see Figure <ref type="figure" target="#fig_3">4</ref> for the most common cells and Appendix 5 for two other commonly used (reduction) cells, with considerable differences in the operations and connectivity.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Scaling up architectures and comparison to</head><p>other meta-learning algorithms.</p><p>We now compare to other meta-learning algorithms in the fixed architecture setting; that is: we use METANAS not with task-dependent architectures but with a single fixed architecture extracted after running METANAS. For this, we extract the most common used task-dependent architecture (see Figure <ref type="figure" target="#fig_3">4</ref>) and scale it up by using more channels and cells. We retrain the resulting architecture, which has approximately 1 million parameters, for more meta-epochs with stronger regularization (weight decay and DropPath <ref type="bibr" target="#b59">[60]</ref>), which is common practice in the NAS literature <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b6">7]</ref>. Please refer to Appendix A.2 for details. Note that naively enlarging models for fewshot learning without regularization does not improve performance due to overfitting as reported by <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Results are presented in Table <ref type="table" target="#tab_2">2</ref>. Again, METANAS improves over the standard REPTILE architecture and Au-toMeta. Compared to other methods that meta-learn an initial set of parameters (first block), METANAS significantly outperforms all other methods on MiniImagenet and achieves new state-of-the-art performance. On Omniglot, METANAS is on-par with MAML++. As MAML++ outperforms REPTILE as a meta-learning algorithm, it is likely that using MAML++ in combination with METANAS would further improve our results. Also compared to other meta-learning approaches (second block), METANAS is on par or outperforms them while employing a significantly smaller architecture (1 million parameters for METANAS compared to more than 10 million for TADAM <ref type="bibr" target="#b37">[38]</ref>, LEO <ref type="bibr" target="#b42">[43]</ref> and MetaOptNet <ref type="bibr" target="#b27">[28]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have proposed METANAS, the first method which fully integrates gradient-based meta-learning with neural architecture search. METANAS allows meta-learning a neural architecture along with the weights and adapting it to task-dependent architectures based on few labeled datapoints and with only a few steps of gradient descent. We have also proposed an extension of DARTS <ref type="bibr" target="#b32">[33]</ref> that reduces the performance drop incurred during hard-pruning, 1 We report results without label smoothing and without training on the validation set, as this is also not used in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MiniImagenet</head><p>Omniglot Method # params 1-shot, 5-way 5-shot, 5-way 1-shot, 20 way MAML <ref type="bibr" target="#b15">[16]</ref> 30k 48. which might be of independent interest. Empirical results on standard few-shot learning benchmarks show the superiority with respect to simple CNNs mostly used in few-shot learning so far. METANAS is on-par or better than other methods applying NAS to few-shot learning while being significantly more efficient. After scaling the found architectures up, METANAS significantly improves the state-ofthe-art on MiniImagenet, achieving 61.7% accuracy in the 1-shot, 5-way setting and 78.8% in the 5-shot, 5 way setting.</p><p>As our framework is agnostic with respect to the metalearning algorithm as well as to the differentiable architecture search method, our empirical results can likely be improved by using more sophisticated meta-learning methods such as MAML++ <ref type="bibr" target="#b0">[1]</ref> and more sophisticated differentiable architecture search methods such as ProxylessNAS <ref type="bibr" target="#b6">[7]</ref>. In the future, we plan to extend our framework beyond few shot classification to other multi-task problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Comparison of different sparsification strategies and impact on pruning</head><p>We recap the three different sparsification strategies discussed in Section 4 and Figure <ref type="figure" target="#fig_2">2:</ref> 1. vanilla DARTS <ref type="bibr" target="#b32">[33]</ref>, i.e., no sparsification (neither operations nor inputs)</p><p>2. sparsifying the operations only (e.g., as in SNAS <ref type="bibr" target="#b53">[54]</ref>)</p><p>3. sparsifying both operations and inputs (as proposed in our work).</p><p>Prior to the meta-learning setting, we evaluated these three strategies on the default single-task classification setting on CIFAR-10. We ran the search phase of DARTS with default hyperparameters (i.e., hyperparameters identical to Liu et al. <ref type="bibr" target="#b32">[33]</ref>) on CIFAR-10 and evaluated the drop in accuracy after the search phase when going from the one-shot model to the pruned model. The one-shot model is pruned as proposed by Liu et al. <ref type="bibr" target="#b32">[33]</ref>. The results can be found in Table <ref type="table" target="#tab_4">3</ref>. In the vanilla setting without any sparsification, the accuracy drops significantly, almost to chance level. When sparsifying the operations only, accuracy is much better but still clearly below the original performance. In contrast, with our proposed strategy, there is no significant drop in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sparsification strategy</head><p>No sparsification (Fig.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Detailed experimental setup and hyperparameters</head><p>Our implementation is based on the REPTILE [37]<ref type="foot" target="#foot_0">2</ref> and DARTS <ref type="bibr" target="#b32">[33]</ref> <ref type="foot" target="#foot_1">3</ref> code. The data loaders and data splits are adopted from Torchmeta <ref type="bibr" target="#b9">[10]</ref> <ref type="foot" target="#foot_2">4</ref> . The overall evaluation setup is the same as in REPTILE.</p><p>Hyperparameters are listed in Table <ref type="table" target="#tab_6">4</ref>. The hyperparameters were determined by random search centered around default values from REPTILE on a validation split of the training data.</p><p>For the experiments in Section 5.1, all models were trained for 30,000 meta epochs. For METANAS, we did not adapt the architectural parameters for the first 15,000 meta epochs to warm-up the model. Such a warm-up phase is commonly employed as it helps avoiding unstable behaviour in gradient-based NAS <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b43">44]</ref>  For the experiment in Section 5.2, we make the following changes in contrast to Section 5.1: we meta-train for 100,000 meta epochs instead of 30,000 and increase the weight decay on the weights from 0.0 to 10 -4 and use Drop-Path <ref type="bibr" target="#b58">[59]</ref> with probability 0.2. We increase the number of channels per layer to 96 from 14 (30k parameter models) / 28 (100k parameter models) and use 5 cells instead of 4, whereas again the second and forth cell are reduction cells while all others are normal cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Motivation of meta-learning algorithm ?</head><p>In Section 3.2, we proposed the two meta-learning updates w i+1 meta ? i+1 meta = ? M AM L (? i meta , w i meta , p train , ? k ) = w i meta -? meta ? w L meta (w i meta , ? i meta , p train , ? k ) ? i meta -? meta ? ? L meta (w i meta , ? i meta , p train , ? k ) (8) and w i+1 meta ? i+1 meta = ? REP T ILE (? i meta , w i meta , p train , ? k ) = w i meta + ? meta Ti (w * Ti -w i meta ) ? i meta + ? meta Ti (a * Ti -? i meta )</p><p>.</p><p>Equation ( <ref type="formula">8</ref>) extends the MAML update w i+1 meta = w i meta -? meta ? w L meta (w i meta , p train , ? k ), which is simply one step of SGD on the meta-objective (Equation <ref type="formula">2</ref>), while Equation ( <ref type="formula" target="#formula_13">9</ref>) extends the REPTILE update w i+1 meta = w i meta + ? meta Ti (w * Ti -w i meta ), which was shown to maximize the inner product between gradients of different batches for the same task, resulting in improved generalization <ref type="bibr" target="#b36">[37]</ref>. Equations ( <ref type="formula">8</ref>) and ( <ref type="formula" target="#formula_13">9</ref>) constitute a simple heuristic that perform the same updates also on the architectural parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Additional plots</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure1: Illustration of our proposed method METANAS and related work. Gray highlights task learning, blue metalearning, and orange NAS components. Top: gradientbased meta-learning with fixed architecture such as MAML<ref type="bibr" target="#b15">[16]</ref> or REPTILE<ref type="bibr" target="#b36">[37]</ref>. Middle: applying NAS to metalearning such as AutoMeta<ref type="bibr" target="#b24">[25]</ref>. Bottom: Proposed joint meta-learning of architecture and weights with METANAS. Since architectures are adapted during task learning, the proposed method can learn task-specific architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of sparsity of the one-shot model after search. Left: vanilla DARTS (no sparsity enforced at all). Middle: enforcing sparsity over mixture of operations. Right: additionally enforcing sparsity over input nodes (here only a single input per node). ing a loss function L Ttrain (w) given a single, large task T = (D train , D test ) with corresponding training and test data. In contrast, in few-shot learning, we are given a distribution over comparably small training tasks T train ? p train (T ) and test tasks T test ? p test (T ). We usually consider n-way, k-shot tasks, meaning each task is a classification problem with n classes (typically n ? {5, 20}) and k (typically k ? {1, 5}) training examples per class. In combination with meta-learning, the training tasks are used to meta-learn how to improve learning of new tasks from the test task distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>4 :</head><label>4</label><figDesc>Sample tasks T 1 , . . . , T n from p(T ) 5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 2 4 :?? ? meta 8 :</head><label>248</label><figDesc>Meta-Learning of Neural Architectures with DARTS and REPTILE 1: Input: distribution over tasks p(T ), task loss function L T 2: Initialize w meta , ? meta 3: while not converged do Sample tasks T 1 , . . . , T n from p(T ) Ti for j ? 1, . . . , k do 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :Algorithm 3</head><label>33</label><figDesc>Figure 3: Conceptual illustration of the architectures at different stages of METANAS. Left: after initializing the one-shot model. Middle: meta-learned architecture. Right: architecture adapted to respective tasks based on meta-architecture. Colours of the edges (red, blue, green) denote different operations (Conv3x3, Conv5x5 and MaxPooling, respectively. Linewidth of edges visualizes size of architectural weights ? (i.e., large line-width correspond to large ? values).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) Normal cell. (b) Reduction cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The most common normal and reduction cell found by METANAS that are used for the evaluation in Section 5.2.</figDesc><graphic url="image-2.png" coords="8,315.69,72.00,213.83,59.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Two other commonly used reduction cells.</figDesc><graphic url="image-4.png" coords="13,61.19,635.36,211.59,51.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>1 for a comparison of the three different Results (mean ? standard deviation for 3 independent runs) on different data sets and different few-shot tasks.</figDesc><table><row><cell></cell><cell></cell><cell>Omniglot</cell><cell></cell><cell>MiniImagenet</cell><cell></cell></row><row><cell cols="4">Parameters Architecture 1-shot, 20-way 5-shot, 20-way</cell><cell cols="2">1-shot, 5-way 5-shot, 5-way</cell></row><row><cell></cell><cell>REPTILE</cell><cell>86.7 ? 0.38</cell><cell>97.4 ? 0.04</cell><cell>46.5 ? 0.33</cell><cell>63.3 ? 0.3</cell></row><row><cell>?30k</cell><cell>AutoMeta METANAS</cell><cell>89.0 ? 0.52 92.2 ? 0.04</cell><cell>96.7 ? 0.13 98.8 ? 0.05</cell><cell>49.8 ? 0.55 49.7 ? 0.4</cell><cell>64.5 ? 1.36 62.1 ? 0.9</cell></row><row><cell></cell><cell>REPTILE</cell><cell>90.0 ? 0.14</cell><cell>98.0 ? 0.06</cell><cell>48.0 ? 0.44</cell><cell>65.4 ? 0.31</cell></row><row><cell>?100k</cell><cell>AutoMeta METANAS</cell><cell>96.2 ? 0.22 96.2 ? 0.16</cell><cell>99.2 ? 0.08 99.2 ? 0.07</cell><cell>50.1 ? 0.16 53.2 ? 0.4</cell><cell>66.3 ? 0.4 67.8 ? 0.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison to other meta-learning algorithm. The first block contains methods that, similar to ours, learn an initial set of parameters that is quickly adapted to new tasks. The second block contains other meta-learning methods.Here we list the numbers stated in other papers. METANAS</figDesc><table><row><cell></cell><cell></cell><cell>7 ? 1.8</cell><cell>63.1 ? 0.9</cell><cell>95.8 ? 0.03</cell></row><row><cell>MAML++[1]</cell><cell>-</cell><cell>52.2 ? 0.3</cell><cell cols="2">68.3 ? 0.4 97.65 ? 0.05</cell></row><row><cell>T-NAS++[30]</cell><cell>27k</cell><cell>54.1 ? 1.4</cell><cell>69.6 ? 0.9</cell><cell>-</cell></row><row><cell>REPTILE[37]</cell><cell>30k</cell><cell>50.00 ? 0.3</cell><cell>66.0 ? 0.6</cell><cell>89.43 ? 0.14</cell></row><row><cell>AutoMeta[25]</cell><cell>100k</cell><cell>57.6 ? 0.2</cell><cell>74.7 ? 0.2</cell><cell>-</cell></row><row><cell>METANAS  *</cell><cell>1M</cell><cell>61.7 ? 0.3</cell><cell cols="2">78.8 ? 0.2 97.74 ? 0.08</cell></row><row><cell>TADAM [38]</cell><cell>12M</cell><cell>58.5 ? 0.3</cell><cell>76.7 ? 0.3</cell><cell>-</cell></row><row><cell>MetaOptNet [28] 1</cell><cell>12M</cell><cell>61.1 ? 0.6</cell><cell>77.4 ? 0.5</cell><cell>-</cell></row><row><cell>LEO [43]</cell><cell>36.5M</cell><cell>61.8 ? 0.1</cell><cell>77.6 ? 0.1</cell><cell>-</cell></row></table><note><p>* denotes the results of our proposed method after increasing model size, regularization and a longer meta-training period. Accuracy in %.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Comparing the different annealing strategies dis-</cell></row><row><cell>cussed in Section 4 and Figure 2: 1) vanilla DARTS (no an-</cell></row><row><cell>nealing) 2) annealing the operations only, 3) annealing both</cell></row><row><cell>operations and inputs (as proposed in our work). Mean ?</cell></row><row><cell>SEM, on single-task NAS setting (CIFAR-10, DARTS' de-</cell></row><row><cell>fault hyperparameters).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>.</figDesc><table><row><cell>Hyperparameter</cell><cell>Value</cell></row><row><cell>batch size</cell><cell>20</cell></row><row><cell>meta batch size</cell><cell>10</cell></row><row><cell>shots during meta training</cell><cell>15 / 10</cell></row><row><cell>task training steps (during meta training)</cell><cell>5</cell></row><row><cell>task training steps (during meta testing)</cell><cell>50+50 5</cell></row><row><cell>task learning rate (weights)</cell><cell>10 -3</cell></row><row><cell>task learning rate (architecture)</cell><cell>10 -3 / 5 ? 10 -4</cell></row><row><cell>task optimizer (weights)</cell><cell>Adam</cell></row><row><cell>task optimizer (architecture)</cell><cell>Adam</cell></row><row><cell>meta learning rate (weights)</cell><cell>1.0</cell></row><row><cell>meta learning rate (architecture)</cell><cell>0.6</cell></row><row><cell>meta optimizer (weights)</cell><cell>SGD</cell></row><row><cell>meta optimizer (architecture)</cell><cell>SGD</cell></row><row><cell>weight decay ( weights)</cell><cell>0.0</cell></row><row><cell>weight decay (architecture)</cell><cell>10 -3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Listing of hyperparameters for METANAS for the experiments of Section 5.1. Hyperparameters are the same across n-shot, k-way setting. Hyperparameters are the same for MiniImagenet and Omniglot except for rows with two values separated by a slash. In this case, the first value denotes the value for MiniImagenet while the latter one denotes the value for Omniglot.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://github.com/openai/supervised-reptile</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://github.com/khanrc/pt.darts</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/tristandeleu/pytorch-meta</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>By 50+50 we mean that for the first 50 steps, both the weights and architecture are adapted while for the later 50 steps only weights are adapted.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors acknowledge support by the <rs type="funder">European Research Council (ERC)</rs> under the European Union's <rs type="programName">Horizon 2020 research and innovation programme</rs> through grant no. <rs type="grantNumber">716721</rs>, and by <rs type="funder">BMBF</rs> grant DeToL.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7SD6J6J">
					<idno type="grant-number">716721</idno>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How to train your MAML</title>
		<author>
			<persName><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Accelerating Neural Architecture Search using Performance Prediction</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Meta-Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SMASH: One-shot model architecture search through hypernetworks</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theo</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient architecture search by network transformation</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Searching for efficient multi-scale architectures for dense image prediction</title>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="8713" to="8724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName><forename type="first">Liu</forename><surname>Chenxi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liang Chieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Schroff</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Hartwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuille</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Torchmeta: A Meta-Learning library for PyTorch</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>W?rfl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandana</forename><surname>Samiei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Paul Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://github.com/tristandeleu/pytorch-meta" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Simple And Efficient Architecture Search for Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hendrik Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Meta-Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient multi-objective neural architecture search via lamarckian evolution</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hendrik Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hendrik Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">55</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BOHB: Robust and efficient hyperparameter optimization at scale</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Jennifer</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07">Jul 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>International Convention Centre</publisher>
			<date type="published" when="2017-08">Aug 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="9516" to="9527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transferring knowledge across learning processes</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Flennerhag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><forename type="middle">Garcia</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Damianou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Metalearning with warped gradient descent</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Flennerhag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hujun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning scalable feature pyramid architecture for object detection</title>
		<author>
			<persName><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Nas-Fpn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Steven</forename><surname>Sepp Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">R</forename><surname>Younger</surname></persName>
		</author>
		<author>
			<persName><surname>Conwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks -ICANN 2001</title>
		<editor>
			<persName><forename type="first">Georg</forename><surname>Dorffner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Meta-learning in neural networks: A survey</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Kotthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joaquin</forename><surname>Vanschoren</surname></persName>
		</author>
		<ptr target="http://automl.org/book" />
		<title level="m">Machine Learning: Methods, Systems, Challenges</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In press, available at</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Auto-meta: Automated gradient based meta learner search</title>
		<author>
			<persName><forename type="first">Jaehong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngduck</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moonsu</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Kwon Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangyeul</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongseok</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">253</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hyperband: Bandit-based configuration evaluation for hyperparameter optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Desalvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR&apos;17)</title>
		<meeting>the International Conference on Learning Representations (ICLR&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Published online: iclr.cc</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards fast adaptation of neural architectures with meta learning</title>
		<author>
			<persName><forename type="first">Dongze</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yintao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanxiong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Progressive Neural Architecture Search</title>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Hormoz Shahrzad, Arshak Navruzyan, Nigel Duffy, and Babak Hodjat. Evolving Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Risto Miikkulainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliot</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Rawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bala</forename><surname>Francon</surname></persName>
		</author>
		<author>
			<persName><surname>Raju</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00548</idno>
		<imprint>
			<date type="published" when="2017-03">Mar. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast neural architecture search of compact semantic segmentation models via auxiliary cells</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Nekrasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">On firstorder meta-learning algorithms</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName><forename type="first">Boris</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pau</forename><surname>Rodr?guez L?pez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Continual and multi-task architecture search</title>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno>CoRR, abs/1906.05226</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Aging Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Leon Suematsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>International Convention Centre</publisher>
			<date type="published" when="2017-08">Aug 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding optimization</title>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dushyant</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Sygnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Autodispnet: Improving disparity estimation with automl</title>
		<author>
			<persName><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yassine</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019-10">October 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Convolutional neural fabrics</title>
		<author>
			<persName><forename type="first">Shreyas</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="4053" to="4061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Evolutionary principles in selfreferential learning. on learning how to learn: The metameta-meta...-hook. Master&apos;s thesis</title>
		<author>
			<persName><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Technische Universitat Munchen</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Automated design of error-resilient and hardware-efficient deep neural networks</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Schorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Runge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Guntoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerd</forename><surname>Ascheid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Evolving neural networks through augmenting topologies</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Risto</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to learn</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Science+Business Media</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Joaquin</forename><surname>Vanschoren</surname></persName>
		</author>
		<author>
			<persName><surname>Meta-Learning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="35" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Transfer learning with neural automl</title>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="8356" to="8365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yassine</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Towards automated deep learning: Efficient joint neural architecture and hyperparameter search</title>
		<author>
			<persName><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2018 Workshop on AutoML</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Practical block-wise neural network architecture generation</title>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2423" to="2432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Fast context adaptation via meta-learning</title>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Zintgraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyriacos</forename><surname>Shiarli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katja</forename><surname>Vitaly Kurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimon</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><surname>Whiteson</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="7693" to="7702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR) 2017 Conference Track</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
