<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating 3D Molecules for Target Protein Binding</title>
				<funder ref="#_B8yAZjj #_gDUMANM">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Youzhi</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kanji</forename><surname>Uchino</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Koji</forename><surname>Maruhashi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
						</author>
						<title level="a" type="main">Generating 3D Molecules for Target Protein Binding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Preprint. Under review</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A fundamental problem in drug discovery is to design molecules that bind to specific proteins. To tackle this problem using machine learning methods, here we propose a novel and effective framework, known as GraphBP, to generate 3D molecules that bind to given proteins by placing atoms of specific types and locations to the given binding site one by one. In particular, at each step, we first employ a 3D graph neural network to obtain geometry-aware and chemically informative representations from the intermediate contextual information. Such context includes the given binding site and atoms placed in the previous steps. Second, to preserve the desirable equivariance property, we select a local reference atom according to the designed auxiliary classifiers and then construct a local spherical coordinate system. Finally, to place a new atom, we generate its atom type and relative location w.r.t. the constructed local coordinate system via a flow model. We also consider generating the variables of interest sequentially to capture the underlying dependencies among them. Experiments demonstrate that our GraphBP is effective to generate 3D molecules with binding ability to target protein binding sites. Our implementation is available at https://github.com/divelab/GraphBP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Designing molecules that can bind to a specific target protein (a.k.a. structure-based drug design) is a fundamental and challenging problem in drug discovery <ref type="bibr" target="#b0">(Anderson, 2003)</ref>. It is highly promising to develop machine learning methods for this problem since there are recently available large-scale datasets of protein-ligand complex structures, such as PDBbind <ref type="bibr" target="#b24">(Liu et al., 2017)</ref> and CrossDocked2020 <ref type="bibr" target="#b4">(Francoeur et al., 2020)</ref>. In addition, machine learning approaches have been shown to be effective for learning from richly structured data in biochemistry. The most representative example is AlphaFold <ref type="bibr" target="#b14">(Jumper et al., 2021)</ref>, which achieves remarkable accuracy on the problem of 3D protein structure prediction from amino acid sequence, a long-standing challenge for decades. However, machine learning approaches have rarely been explored to generate molecules that bind to specific protein binding sites. We summarize the main challenges or considerations in three folds. (i) Complicated conditional information. When generating molecules that are capable of binding to a specific target protein, both the 3D geometric structure and the chemical features of the binding site are important considerations. It is crucial to consider how to capture such informative context effectively. (ii) Enormous chemical space and continuous 3D space. The chemical space of all possible molecules is enormous (estimated to be larger than 10 60 ), while the number of molecules that have binding ability to a specific target is extremely small. In addition, the 3D space around the binding site is continuous by nature. In other words, it is desirable that our generative model is capable of generating molecules in any continuous positions without discretizing the space. (iii) Equivariance property. Intuitively, if we rotate or translate the binding site, the generated molecules are expected to be rotated or translated the same way. That is, molecules generated by our machine learning approach should be equivariant to any rigid transformation of the binding site.</p><p>In this work, we present GraphBP, a novel and effective generative framework for structure-based drug design, that takes the described challenges into consideration. Particularly, we generate 3D molecules by placing atoms to the specific 3D binding site one by one. At each step, a 3D graph neural network is firstly employed to extract the intermediate contextual information by considering both 3D geometric structures and chemical interactions. Afterwards, we construct a local coordinate system based on a local reference atom selected by the designed auxiliary classifiers. Generating a new atom in this local coordinate system can ensure the equivariance property. Finally, to place a new atom, we generate its atom type and relative continuous position w.r.t. the constructed local coordinate system with a flow model. Moreover, the variables of interest are generated sequentially, aiming to capture the underlying dependencies.</p><p>To our knowledge, in structure-based drug design, our GraphBP is the first machine learning method that satisfies all of the following three characteristics; that is, it can perceive 3D geometric structures and chemical interactions of protein-ligand complexes, place atoms in any continuous positions, and preserve the desirable equivariance property. More discussions with prior works <ref type="bibr" target="#b36">(Ragoza et al., 2021;</ref><ref type="bibr">Luo et al., 2021a)</ref> are included in Section 2. Experiments show that our approach outperforms baselines significantly in generating 3D molecules that have binding affinity to target 3D protein binding sites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries and Related Work</head><p>1D/2D molecule generation. Molecules can be represented as 1D SMILES strings <ref type="bibr" target="#b48">(Weininger, 1988)</ref> or 2D molecular graphs. Several works propose to generate SMILES strings <ref type="bibr" target="#b8">(G?mez-Bombarelli et al., 2018;</ref><ref type="bibr" target="#b19">Kusner et al., 2017;</ref><ref type="bibr" target="#b1">Dai et al., 2018)</ref> with sequence methods. Alternatively, many works generate 2D graphs by leveraging advanced deep generative models. They either generate the node type matrix and adjacency matrix directly <ref type="bibr" target="#b46">(Simonovsky &amp; Komodakis, 2018;</ref><ref type="bibr" target="#b2">De Cao &amp; Kipf, 2018;</ref><ref type="bibr" target="#b52">Zang &amp; Wang, 2020;</ref><ref type="bibr" target="#b22">Liu et al., 2021)</ref>, or generate nodes, edges, or motifs by adding them one by one <ref type="bibr" target="#b21">(Li et al., 2018;</ref><ref type="bibr" target="#b51">You et al., 2018;</ref><ref type="bibr" target="#b13">Jin et al., 2018;</ref><ref type="bibr" target="#b42">Shi et al., 2019;</ref><ref type="bibr">Luo et al., 2021c)</ref>. These methods generate 1D or 2D molecules without perceiving 3D spatial information. Thus, they cannot be directly applied to generate 3D molecules for target protein binding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D molecule generation.</head><p>Recently, many works propose to generate 3D molecular geometries from given 2D graphs <ref type="bibr" target="#b30">(Mansimov et al., 2019;</ref><ref type="bibr" target="#b44">Simm &amp; Hernandez-Lobato, 2020;</ref><ref type="bibr" target="#b7">Gogineni et al., 2020;</ref><ref type="bibr" target="#b50">Xu et al., 2021;</ref><ref type="bibr" target="#b43">Shi et al., 2021;</ref><ref type="bibr" target="#b5">Ganea et al., 2021;</ref><ref type="bibr">Luo et al., 2021b)</ref>, from a given bag of atoms <ref type="bibr">(Simm et al., 2020)</ref>, or from scratch <ref type="bibr" target="#b6">(Gebauer et al., 2019;</ref><ref type="bibr" target="#b11">Hoffmann &amp; No?, 2019;</ref><ref type="bibr" target="#b32">Nesterov et al., 2020;</ref><ref type="bibr" target="#b40">Satorras et al., 2021;</ref><ref type="bibr" target="#b27">Luo &amp; Ji, 2022)</ref>. In structure-based drug design, however, the prior knowledge of 2D graphs or the bag of atoms are unknown. In addition, these methods usually consider small organic molecules <ref type="bibr">(Luo et al., 2021a)</ref>, thus remaining to be insufficient to generate 3D drug-like molecules interacting with given binding sites.</p><p>Structure-based drug design. Generating 3D molecules that bind to specific binding sites with machine learning approaches is a challenging and under-explored problem. LiGAN <ref type="bibr" target="#b36">(Ragoza et al., 2021)</ref> converts protein-ligand complexes to 3D atomic density grids, i.e., 3D images. Then it treats structure-based drug design as a 3D image generation task, thus enabling the usage of GANs <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref> and VAEs <ref type="bibr" target="#b16">(Kingma &amp; Welling, 2013)</ref>. After generating density grids, it performs an atom fitting algorithm to obtain 3D molecular geometries. As a preliminary work, it fails to preserve the desirable equivariance property since performing 3D CNNs <ref type="bibr" target="#b12">(Ji et al., 2012)</ref> on an atomic density grid is not equivariant. Also, it has to discretize the continuous 3D space to construct grids. Another recent work <ref type="bibr">(Luo et al., 2021a)</ref> tackles this problem by modeling the distribution of atom occurrence in the 3D space around the binding site, and then employing a sampling algorithm to place atoms according to the learned distribution. During sampling, it also discretizes the 3D space onto meshgrids and evaluates the probability densities of atom's occurrences on the grids. In contrast, our method can place the atoms in any continuous positions, thereby enabling more flexible atom placement.</p><p>Autoregressive flow models. A flow model <ref type="bibr" target="#b3">(Dinh et al., 2014;</ref><ref type="bibr" target="#b39">Rezende &amp; Mohamed, 2015;</ref><ref type="bibr" target="#b49">Weng, 2018)</ref> defines a parameterized invertible transformation function f ? : z ? R D ? x ? R D from latent variable z ? p Z to data variable x, where p Z is a known prior distribution. The log-likelihood of a data point x can be computed by</p><formula xml:id="formula_0">log p X (x) = log p Z f -1 ? (x) + log det ?f -1 ? (x) ?x .<label>(1)</label></formula><p>Thus, f ? is required to be invertible and its Jacobian determinant should be computed easily. An autoregressive flow model <ref type="bibr" target="#b34">(Papamakarios et al., 2017)</ref> is a specific flow method where the transformation function is formulated as an autoregressive model; that is, each dimension of x is conditioned on the previous dimensions. Formally, it is usually defined as an affine transformation as</p><formula xml:id="formula_1">x i = ? i (x 1:i-1 ) z i + ? i (x 1:i-1 ), i = 1, ? ? ? , D,<label>(2)</label></formula><p>where the scale factor ? i (?) ? R and the translation factor ? i (?) ? R are functions of x 1:i-1 . denotes the element-wise multiplication. This transformation function is easy to inverse as z i = xi-?i ?i . In addition, the determinant of the Jacobian matrix can be computed linearly since it is a triangular matrix. To be specific, det</p><formula xml:id="formula_2">?f -1 ? (x) ?x = D i=1 1 ?i .</formula><p>Figure <ref type="figure">1</ref>. An illustration of one generation step of GraphBP. Details are described in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Notations and problem. We represent the 3D geometry of a molecule (i.e., a ligand) as M = {(a i , r i )} n i=1 and the corresponding binding site of a protein (i.e., a receptor) as P = {(b j , s j )} m j=1 . n and m denote the numbers of atoms in the molecule and in the binding site, respectively. a i ? {0, 1} p is the one-hot vector indicating the atom type of the i-th atom in the molecule, and r i ? R 3 is its 3D Cartesian coordinate. Similarly, the atom type and the coordinate of the j-th atom in the binding site are denoted as one-hot vector b j ? {0, 1} q and s j ? R 3 . p and q represent the total numbers of atom types in molecules and in binding sites, respectively, and they can be obtained from the statistics of the training set. We consider the problem of generating 3D molecules in the given binding site. Thus, our goal is to learn a generative model to capture the conditional distribution p(M|P) of observed protein-ligand pairs in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Generation</head><p>Overview. In GraphBP, we formulate the generation of 3D molecules in the given binding site as a sequential generation process; that is, we place atoms to the given 3D binding site one by one. At the t-th step, we generate the t-th atom, including its atom type a t and coordinate r t , based on the intermediate contextual information C (t-1) . Note that the context C (t-1) contains not only the binding site but also the atoms placed in the previous t -1 steps, i.e., C (t-1) = P ? {(a i , r i )} t-1 i=1 when t ? 2. At the first step (t = 1), the context is the binding site itself, i.e., C (0) = P.</p><p>Within each step, we firstly generate the atom type based on the context. Afterwards, its coordinate is generated by considering both the context and the generated atom type information. Therefore, each step t (t = 1, 2, ? ? ? , n) of our generation process can be formulated as</p><formula xml:id="formula_3">a t = g a C (t-1) ; z a t , r t = g r C (t-1) , a t ; z r t , C (t) ? C (t-1) ? {(a t , r t )} .<label>(3)</label></formula><p>Generators g a (?) and g r (?) are autoregressive functions. z a t and z r t denote the latent variables used in the flow model at step t, which will be introduced in detail later.</p><p>In the following, we describe the details of one generation step, i.e., how the autoregressive functions g a (?) and g r (?) are parameterized. In addition, we also explain how the key challenges summarized in Section 1 are considered in GraphBP. Particularly, there are mainly three parts in one generation step, namely encoding the context, selecting a local reference atom, and placing a new atom, as illustrated in Figure <ref type="figure">1</ref>. The details are elucidated as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">ENCODING THE CONTEXT</head><p>As introduced in Section 1, both geometric shape and chemical interactions are vital to protein-ligand binding affinity. Hence, it is important to capture such information by the context encoder. We firstly construct a graph for the context C (t-1) by connecting atoms with considering certain cutoff distance. Let G (t-1) denote the obtained context graph. Afterwards, we employ a 3D graph neural network (3D GNN) to encode G (t-1) . Formally,</p><formula xml:id="formula_4">{h (t) 1 , ? ? ? , h (t) m+t-1 } = 3DGNN G (t-1) ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_5">h (t)</formula><p>k represents the encoded representation of atom k in the context C (t-1) . Note that there are totally m + t -1 atoms in the context, including m atoms from the binding site and t -1 atoms placed in the previous t -1 steps.</p><p>The first layer of our 3DGNN is an embedding layer for encoding atom types. Note that we use different learnable embeddings for atoms in the binding site and atoms in the ligand, thereby differentiating ligand atoms from protein atoms. For example, a carbon atom in the ligand and a carbon atom in the protein have different initial representations. Let {h</p><formula xml:id="formula_6">(t,0) 1 , ? ? ? , h (t,0)</formula><p>m+t-1 } be the resulting initial representations. Then, we have L feature aggregation layers in our 3DGNN. The aggregation for each atom k at the -th layer (1 ? ? L) can be formulated as</p><formula xml:id="formula_7">h (t, ) k = h (t, -1) k + u?N (k) h (t, -1) u MLP (e RBF (d uk )) ,<label>(5)</label></formula><p>where N (k) denotes neighbors of atom k in G (t-1) , MLP (?) is a multi-layer perceptron, and represents the element-wise multiplication. e RBF (d uk ) is the high-dimensional embedding of the distance d uk using radial basis functions (RBF), such as Gaussian functions <ref type="bibr" target="#b41">(Schlichtkrull et al., 2018)</ref> and spherical Bessel functions <ref type="bibr" target="#b17">(Klicpera et al., 2019)</ref>. Note that the representations {h</p><formula xml:id="formula_8">(t) 1 , ? ? ? , h<label>(t)</label></formula><p>m+t-1 } obtained by these L feature aggregation layers are invariant to the rotation and translation of the context C (t-1) , since the distance d uk used in Eq. ( <ref type="formula" target="#formula_7">5</ref>) is rotationally and translationally invariant. Our aggregation layer shown in Eq. ( <ref type="formula" target="#formula_7">5</ref>) is a variant of SchNet <ref type="bibr" target="#b41">(Schlichtkrull et al., 2018)</ref>. We can further employ more advanced but more memory-consuming 3D GNNs, such as DimeNet <ref type="bibr" target="#b17">(Klicpera et al., 2019)</ref> and SphereNet <ref type="bibr" target="#b23">(Liu et al., 2022)</ref>, to encode the context information. In this work, we do not use them as our encoder because of insufficient memory budget, given that the context graph could have hundreds of atoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">SELECTING A LOCAL REFERENCE ATOM</head><p>As described in Section 1, the location of a generated molecule should be equivariant to any rigid transformation of the binding site. In other words, if we rotate or translate the binding site, the generated molecule should be rotated or translated correspondingly. In our sequential generation case, as formulated in Eq. (3), it is desired that the generated coordinate of the t-th atom is equivariant to any rigid transformation of the context C (t-1) , while the generated atom type keeps invariant. Formally,</p><formula xml:id="formula_9">g a C (t-1) ; z a t = g a RT C (t-1) ; z a t , RT g r C (t-1) , a t ; z r t = g r RT C (t-1) , a t ; z r t ,<label>(6)</label></formula><p>where RT(?) represents any rigid transformation, including rotation, translation, and any composition of them.</p><p>As described in Section 3.1.1, our atom representations obtained from context encoding are invariant to any rigid transformation of the context. Thus, it is straightforward to generate invariant atom type by using these representations. Nevertheless, it is non-trivial to generate coordinate that are equivariant to any rigid transformation of the context. To achieve this desirable equivariance, inspired by G-SchNet <ref type="bibr" target="#b6">(Gebauer et al., 2019)</ref>, MolGym <ref type="bibr">(Simm et al., 2020)</ref>, and G-SphereNet <ref type="bibr" target="#b27">(Luo &amp; Ji, 2022)</ref>, we choose to construct a local spherical coordinate system (SCS) and generate the invariant 3-tuple (d t , ? t , ? t ) w.r.t. the constructed local SCS.</p><p>To construct such local SCS, we consider selecting a local reference atom from the context by using two auxiliary atom-wise classifiers; they are contact atom classifier (for t = 1) and focal atom classifier (for t ? 2). (i) At the first step (t = 1), the known context information is the binding site. The contact atom classifier takes the context-encoded representation of each atom in the binding site as input, and determines if the corresponding atom can serve as a local reference atom (i.e., yes or no). The atom selected based on the contact atom classifier will be used as the local reference atom for generating the first atom in the ligand. This selected atom is termed as contact atom because it acts like a "bridge" in contact with the ligand.</p><p>(ii) For t ? 2, we select a local reference atom from the ligand atoms generated in the previous t -1 steps, considering that the new atom is expected to be placed in the local region of the selected reference atom. To be specific, we apply focal atom classifier to the context-encoded representations of all existing atoms in the ligand, which are generated in the previous t -1 steps, and classify them into two categories: focal atom and non-focal atom. Then, the selected focal atom will be used as the local reference atom to generate the new atom. Overall, for t = 1, a local reference atom is selected from the binding site using the contact atom classifier. For t ? 2, a local reference atom is selected from the existing ligand atoms according to the focal atom classifier. We describe how to train these two auxiliary classifiers in Section 3.2.</p><p>In general, we need three points in the 3D space to define an SCS. Assuming that the selected local reference atom is the f -th atom in the context C (t-1) , we can further find two atoms in the context that are closest and second closest to f . These two atoms are denoted as the c-th and the e-th atom in the context C (t-1) , and they could be in the ligand or in the binding site. With these three atoms (f, c, e), we can construct a local SCS. Further, we can generate the invariant (d t , ? t , ? t ) w.r.t. this local SCS. Specifically, d t is distance between the new atom and atom f , i.e., d t = ||r t -r f || 2 , ? t ? [0, ?] is the angle between line (r f , r t ) and line (r f , r c ), and ? t ? [-?, ?] is the torsion angle formed by plane (r f , r c , r t ) and plane (r f , r c , r e ). Afterwards, we can compute r t based on the generated (d t , ? t , ? t ) and the known (r f , r c , r e ). Note that the constructed local SCS is associated with the context, thus being equivariant to any rigid transformation of the context. In other words, (r f , r c , r e ) is equivariant to any rigid transformation of the context. Therefore, the computed r t also keeps equivariant as long as the generated (d t , ? t , ? t ) is invariant to any rigid transformation of the context C (t-1) . In addition, we can achieve flexible atom placement since the generated (d t , ? t , ? t ) are continuous values, while previous works <ref type="bibr" target="#b36">(Ragoza et al., 2021;</ref><ref type="bibr">Luo et al., 2021a)</ref> have to discretize the continuous space during atom placement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">PLACING A NEW ATOM</head><p>The remaining part in generation is to place a new atom by generating (d t , ? t , ? t ) as well as a t . As analyzed above, a t , d t , ? t , and ? t should be invariant to any rigid transformation of the context C (t-1) . Hence, it is natural to generate them with context-encoded representations of atoms (f, c, e), i.e., (h</p><formula xml:id="formula_10">(t) f , h (t) c , h (t)</formula><p>e ), which are invariant to the rotation and translation of the context C (t-1) . In addition, intuitively, a t , d t , ? t , and ? t are not independent to each other. For example, a carbon atom and an oxygen atom have different distributions over the distance to their local reference atoms. Further, atoms with the same atom type but different distances w.r.t. their local reference atoms could have different distributions over angles. Thus, we propose to generate a t , d t , ? t , and ? t sequentially in each generation step to capture their underlying dependencies. To be specific, we generate these variables using the order a t ? d t ? ? t ? ? t , and the generation of each variable is dependent on the previous variables. For instance, to generate ? t , in addition to C (t-1) , we incorporate the information of a t , d t , and ? t . Mathematically, p a t , d t , ? t , ? t |C (t-1) = p a t |C (t-1) p d t |C (t-1) p ? t |C (t-1) p ? t |C (t-1) does not hold if a t , d t , ? t , and ? t are not independent. In contrast, the following equation always holds according to the multiplication rule of probability, no matter if the variables are independent or not. p a t , d t , ? t , ? t |C (t-1) = p a t |C (t-1) p d t |C (t-1) , a t p ? t |C (t-1) , a t , d t p ? t |C (t-1) , a t , d t , ? t .</p><p>(7)</p><p>This demonstrates that our generation strategy is also technically sound. We conduct ablation study in Section 4 to demonstrate the effectiveness of this sequential generation strategy. Therefore, our one-step generation, as shown in Eq. ( <ref type="formula" target="#formula_3">3</ref>), can be reformulated as</p><formula xml:id="formula_11">a t = g a C (t-1) ; z a t , d t = g d C (t-1) , a t ; z d t , ? t = g ? C (t-1) , a t , d t ; z ? t , ? t = g ? C (t-1) , a t , d t , ? t ; z ? t ,<label>(8)</label></formula><p>where z a t ? R p , z d t ? R, z ? t ? R, and z ? t ? R are all latent variables used in the flow model. During generation, we sample latent variables from known prior Gaussian distributions, and then map them to variables of interest (i.e., a t , d t , ? t , ? t ).</p><p>For training, we map observed variables to latent variables, and maximize their likelihood. Since the atom type vector is discrete, which cannot fit into a flow model, we convert it to a continuous variable during training using dequantization techniques <ref type="bibr" target="#b15">(Kingma &amp; Dhariwal, 2018)</ref>. This is widely used by existing molecule generation methods <ref type="bibr" target="#b29">(Madhawa et al., 2019;</ref><ref type="bibr" target="#b42">Shi et al., 2019;</ref><ref type="bibr" target="#b22">Liu et al., 2021)</ref>. Specifically, we add uniform noise as ?t = a t + u, u ? U(0, 1) p . In the following, we elaborate how to employ flow model to construct invertible mappings z a t ? ?t , z d t ? d t , z ? t ? ? t , and z ? t ? ? t , respectively. The training scheme is elucidated in Section 3.2.</p><p>To generate a t , we first apply affine transformation to map the latent variable z a t to ?t . Formally,</p><formula xml:id="formula_12">?t = ? a t C (t-1) z a t + ? a t C (t-1) ,<label>(9)</label></formula><p>where the scale factor ? a t (?) ? R p and the translation factor ? a t (?) ? R p are both dependent on the context C (t-1) . To be specific, they are computed by applying MLPs to the context-encoded representation of the selected local reference atom f . Formally,</p><formula xml:id="formula_13">? ? ? ? a t C (t-1) = MLP a ? h (t) f , ? a t C (t-1) = MLP a ? h (t) f . (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>After obtaining ?t , we can derive the one-hot a t by performing the argmax operation to ?t .</p><p>Similar to the generation of atom type, we can produce d t , ? t , and ? t as</p><formula xml:id="formula_15">d t = ? d t C (t-1) , a t z d t + ? d t C (t-1) , a t , ? t = ? ? t C (t-1) , a t , d t z ? t + ? ? t C (t-1) , a t , d t , ? t = ? ? t C (t-1) , a t , d t , ? t z ? t + ? ? t C (t-1) , a t , d t , ? t .<label>(11)</label></formula><p>The scale factors</p><formula xml:id="formula_16">? d t (?), ? ? t (?), ? ? t (?) ? R and the translation factors ? d t (?), ? ? t (?), ? ? t (?)</formula><p>? R are dependent on their corresponding conditional information that are defined and justified in our generation strategy, as formulated in Eq. ( <ref type="formula" target="#formula_11">8</ref>). These factors are also naturally parameterized by MLPs with considering their respective conditional information. To be specific,</p><formula xml:id="formula_17">h (t) f /c/e = h (t) f /c/e Embedding (a t ) ,<label>(12)</label></formula><formula xml:id="formula_18">? ? ? ? d t C (t-1) , a t = MLP d ? h (t) f , ? d t C (t-1) , a t = MLP d ? h (t) f ,<label>(13)</label></formula><formula xml:id="formula_19">h (t) f /c/e = h (t) f /c/e LB RBF (e RBF (d t )) , (<label>14</label></formula><formula xml:id="formula_20">) ? ? ? ? ? t C (t-1) , a t , d t = MLP ? ? h (t) f , h (t) c , ? ? t C (t-1) , a t , d t = MLP ? ? h (t) f , h (t) c ,<label>(15)</label></formula><formula xml:id="formula_21">h (t) f /c/e = h (t) f /c/e LB CBF (e CBF (d t , ? t )) , (<label>16</label></formula><formula xml:id="formula_22">) ? ? ? ? ? t C (t-1) , a t , d t , ? t = MLP ? ? h (t) f , h (t) c , h (t) e , ? ? t C (t-1) , a t , d t , ? t = MLP ? ? h (t) f , h (t) c , h (t) e . (<label>17</label></formula><formula xml:id="formula_23">)</formula><p>Embedding (?) is the same embedding layer that is used to encode ligand atom types during context encoding. Multiplying the embedding of a t in Eq. ( <ref type="formula" target="#formula_17">12</ref>) helps to incorporate the generated atom type information in the subsequent generation for d t , ? t , and ? t . As the distance embedding in Eq. ( <ref type="formula" target="#formula_7">5</ref>), e RBF (d t ) is the RBF embedding of the distance d t . Further, e CBF (d t , ? t ) denotes the high-dimensional embedding of (d t , ? t ) with circular basis functions (CBF). We use the same circular basis functions as previous works that consider geometric information <ref type="bibr" target="#b17">(Klicpera et al., 2019;</ref><ref type="bibr" target="#b23">Liu et al., 2022;</ref><ref type="bibr">Klicpera et al., 2021)</ref>. LB RBF/CBF (?) represents a linear layer and [?] denotes the concatenation operation. Intuitively, incorporating the distance embedding in Eq. ( <ref type="formula" target="#formula_19">14</ref>) and distance-angle embedding in Eq. ( <ref type="formula" target="#formula_21">16</ref>) can guide the subsequent generation for ? t and ? t , respectively. This aims to capture the underlying dependencies of variables a t , d t , ? t , and ? t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4.">OVERALL GENERATION PROCESS</head><p>So far, we have described the key components of our generative framework. To generate a 3D molecular geometry for a given binding site, we autoregressively place one atom at each step. At each step t, we firstly encode the current known context information, then select a local reference atom with our auxiliary classifiers, and finally place a new atom by producing a t , d t , ? t , and ? t sequentially. We illustrate one generation step of our GraphBP in Figure <ref type="figure">1</ref>. The autoregressive generation will be terminated if either no atom in the ligand can serve as a local reference atom according to the focal atom classifier or a predefined maximum number of atoms has been achieved. Afterwards, following previous works <ref type="bibr" target="#b36">(Ragoza et al., 2021;</ref><ref type="bibr">Luo et al., 2021a)</ref>, we apply OpenBabel <ref type="bibr" target="#b33">(O'Boyle et al., 2011)</ref> to construct bonds based on our generated 3D molecular geometries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training</head><p>To train our autoregressive generative model, we need to decompose a 3D molecule in a ligand-protein pair to a trajectory of atom placement steps. Inspired by G-SphereNet <ref type="bibr" target="#b27">(Luo &amp; Ji, 2022)</ref>, we expect that the new atom should be placed in the local region of the reference atom during generation. Thus, we select the atom in the binding site that is closest to the ligand as the first local reference atom, i.e., contact atom, and the atom in the ligand that is closest to the binding site as the first atom to be generated. Then, starting from this selected atom in the ligand, we apply Prim's algorithm on the 3D molecular geometry to obtain the placement order of atoms in the ligand, as well as their corresponding local reference atoms. This strategy can guarantee that the new atom for each step is always in the local region of the corresponding reference atom. With such obtained trajectory, GraphBP is trained by stochastic gradient descent using the following three loss functions.</p><p>Atom placement loss L ap . As described in Eq. ( <ref type="formula" target="#formula_0">1</ref>), with flow model, we can compute the log-likelihood of training data and maximize it. Hence, the training loss function for atom placement is defined as the negative of the computed log-likelihood of the training trajectory. Formally, for a 3D molecular geometry with n atoms, we have</p><formula xml:id="formula_24">L ap = - n t=1 log (PD (p Za (z a t ))) + log PD 1 ? a t + log p Z d z d t + log 1 ? d t + log p Z ? z ? t + log 1 ? ? t + log p Z? (z ? t ) + log 1 ? ? t .<label>(18)</label></formula><p>PD(?) is used to represent the product of elements across dimensions of a vector, since z a t and ? a t are both p-dimensional vectors. Latent variables z a t , z d t , z ? t and z ? t can be computed by the inverted mappings of Eq. ( <ref type="formula" target="#formula_12">9</ref>) and Eq. ( <ref type="formula" target="#formula_15">11</ref>), such as  Dataset. We use the CrossDocked2020 dataset <ref type="bibr" target="#b4">(Francoeur et al., 2020)</ref>, which contains over 22 million docked proteinligand crystal structures, to evaluate GraphBP for structure-based drug design. Following LiGAN <ref type="bibr" target="#b36">(Ragoza et al., 2021)</ref>, we ignore any poses that have root-mean-squared deviations (RMSD) greater than 2 ?, thus obtaining a dataset with around 500k protein-ligand complexes. We use the same training set and test set, as used in LiGAN, for fair comparison. Total number of atom types in ligands and in binding sites are 27 and 19, respectively. The atom types are summarized in Appendix B.</p><formula xml:id="formula_25">z d t = dt-? d t ? d t . p Za , p Z d , p Z ? ,</formula><p>Setup. We use the same 10 target proteins as LiGAN for test evaluation. Each of them could have multiple associated ligands, leading to 90 protein-ligand pairs in the test set as reference. Following LiGAN, we generate 100 molecules with GraphBP for each reference binding site in the test set. This evaluation setting is challenging because the test targets are diversely selected from different pocket clusters and the reference ligand usually bind strongly to the target binding site <ref type="bibr" target="#b36">(Ragoza et al., 2021)</ref>. We quantitatively measure the generation performance by two metrics: (i) Validity is the percentage of chemically valid molecules among all generated molecules. A molecule is valid if it can be sanitized by RDkit <ref type="bibr" target="#b20">(Landrum et al., 2006)</ref>. (ii) ?Binding measures the percentage of generated molecules that have higher predicted binding affinity than their corresponding reference molecules. Note that we are unable to perform wet-lab experiment assays to evaluate the binding affinity of generated molecules. Also, there does not exist a computational metric that can serve as a golden standard for assessing binding affinity. Hence, following LiGAN, the binding affinity is predicted by an ensemble of CNN scoring functions <ref type="bibr" target="#b35">(Ragoza et al., 2017)</ref> that were trained on the CrossDocked2020 data set. Such CNN predicted affinity has been shown to be more accurate than using the Autodock Vina empirical scoring function <ref type="bibr" target="#b47">(Trott &amp; Olson, 2010)</ref>. Therefore, it can be used as a reasonable and convincing metric for evaluating the binding affinity of generated molecules. Following LiGAN, we firstly refine the generated 3D molecules by Universal Force Field minimization <ref type="bibr" target="#b38">(Rapp? et al., 1992)</ref>. Afterwards, Vina minimization and CNN scoring are applied to both generated and reference molecules by using gnina, a molecular docking program <ref type="bibr" target="#b31">(McNutt et al., 2021)</ref>.</p><p>Baselines. We consider two variants from the recent LiGAN <ref type="bibr" target="#b36">(Ragoza et al., 2021)</ref> method as baselines. LiGAN-prior generates molecules conditional on the given binding sites, which has the identical conditional information as our GraphBP.</p><p>LiGAN-posterior encodes the whole reference protein-ligand complex as conditional information, thus generating molecules biased towards the reference molecule. Note that LiGAN-posterior incorporates more conditional information than GraphBP and LiGAN-prior.</p><p>Results. We present the quantitative results in Table <ref type="table" target="#tab_0">1</ref>. Our GraphBP can generate more valid molecules than baselines, including LiGAN-posterior which even includes a valid reference ligand as conditional information. More importantly, 27.0% of molecules generated by GraphBP have higher predicted binding affinity than reference molecules. This outperforms LiGAN by an absolute margin of 11.1%. These significant improvements over baselines demonstrate that GraphBP, which incorporates graph representations and a more flexible atom placement strategy, can capture the underlying distribution of 3D molecular geometries conditional on binding sites more effectively.</p><p>We further provide the detailed distributions of ?Binding affinity in Figure <ref type="figure" target="#fig_1">2</ref>. Note that LiGAN-posterior achieves higher average ?Binding affinity but lower variance than LiGAN-prior and GraphBP. This indicates that LiGAN-posterior, with encoding the reference molecules as conditions, might perform slight modifications on reference molecules. Even though, compared with LiGAN-posterior, our GraphBP still generates more molecules that are predicted to bind more strongly than reference molecules (27.0% vs. 15.4%), demonstrating that GraphBP can generate more diverse molecules to bind with target proteins by effectively capturing the underlying conditional distribution.</p><p>In Figure <ref type="figure" target="#fig_2">3</ref>, we provide several examples of generated 3D molecules that are predicted to bind more strongly to the target proteins than their corresponding reference molecules. It can be observed that our generated molecules with higher predicted binding affinity are largely different from reference molecules, further indicating that our model is capable of generating diverse and novel molecules to bind target proteins, instead of simply memorizing or modifying known molecules.</p><p>Ablation studies. In Section 3.1.3, we propose to generate the variables of interest sequentially to capture their underlying  dependencies. Specifically, given context C (t-1) , we produce a t , d t , ? t , and ? t one by one as</p><formula xml:id="formula_26">C (t-1) ? a t ? d t ? ? t ? ? t .</formula><p>To verify the effectiveness of this strategy, we employ the following two variants. (i) No dependencies. The variables a t , d t , ? t , and ? t are generated independently from the context, as C (t-1) ? a t , C (t-1) ? d t , C (t-1) ? ? t , and C (t-1) ? ? t . Thus, we omit the incorporating of atom type embedding (Eq. ( <ref type="formula" target="#formula_17">12</ref>)), distance embedding (Eq. ( <ref type="formula" target="#formula_19">14</ref>)), and distance-angle embedding (Eq. ( <ref type="formula" target="#formula_21">16</ref>)). (ii) Partial dependencies. We consider the generated atom type information when generating d t , ? t , and ? t . However, d t , ? t , and ? t are treated independently. It can be denoted as C (t-1) ? a t , (C (t-1) , a t ) ? d t , (C (t-1) , a t ) ? ? t , and (C (t-1) , a t ) ? ? t , leading to a similar model as G-SphereNet <ref type="bibr" target="#b27">(Luo &amp; Ji, 2022)</ref>. For efficiency, we choose to conduct experiments on random molecular geometry generation, avoiding encoding large binding sites. Following G-SphereNet, we train models on 3D molecules from QM9 <ref type="bibr" target="#b37">(Ramakrishnan et al., 2014)</ref>  The comparison is summarized in Table <ref type="table">2</ref>. It shows that adding dependencies improves the generation performance consistently. Our sequential generation method performs best, demonstrating that it can model the distribution of molecular geometries more effectively by capturing the underlying dependencies among the variables. Since the loss for atom placement (Eq. ( <ref type="formula" target="#formula_24">18</ref>)) can be divided into losses w.r.t. atom type, distance, angle, and torsion, respectively, we can further analyze the modeling ability for these variables by observing their corresponding training losses. We illustrate the comparison of training losses in Figure <ref type="figure" target="#fig_5">4</ref>. By observing the loss for each variable, we can conclude that adding dependencies can help to fit the training data better.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this work, we propose GraphBP, a machine learning approach to generate 3D molecules for target protein binding.</p><p>GraphBP is capable of capturing 3D geometric structures and chemical interactions of protein-ligand complexes, placing atoms without discretizing the 3D space, and preserving the equivariance property during generation. GraphBP is shown to be effective and outperforms recent baselines significantly in generating 3D molecules that bind strongly to target proteins. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Detailed Derivation of L ap</head><p>The detailed derivation of L ap , as introduced in Eq. ( <ref type="formula" target="#formula_24">18</ref>), is as follows.</p><p>L </p><p>PD(?) is used to represent the product of elements across dimensions of a vector, since z a t and ? a t are both p-dimensional vectors. Eq. ( <ref type="formula" target="#formula_27">24</ref>) is obtained from Eq. ( <ref type="formula">23</ref>) by the property of autoregressive flow models, as described in Eq. (1). Latent variables z a t , z d t , z ? t and z ? t can be computed by the inverted mappings of Eq. ( <ref type="formula" target="#formula_12">9</ref>) and Eq. ( <ref type="formula" target="#formula_15">11</ref> Since we apply dequantization technique to obtain ?t from a t during training, the first term in Eq. ( <ref type="formula">23</ref>) maximizes the log-likelihood of p ?t |C (t-1) instead of p a t |C (t-1) . We have to use this dequantization technique since flow model used in our framework does not apply to discrete data directly. Note that we can simply perform argmax operation to convert ?t back to a t . Hence, such dequantization can be viewed as an operation similar to data augmentation during training. Such dequantization technique is widely used and shown to be effective by existing molecule generation methods <ref type="bibr">(Madhawa</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and p Z? are prior Gaussian distributions. The detailed derivation of L ap is included in Appendix A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Visualization of ?Binding affinity distributions for LiGAN and GraphBP. The values denote the relative improvements of generated molecules over their corresponding reference molecules.</figDesc><graphic url="image-2.png" coords="9,224.29,67.06,145.81,90.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Several examples of generated 3D molecules that have higher predicted binding affinity than reference molecules. The PDB IDs and the ligand IDs of proteins and reference molecules are labeled on the top. Two rows are shown from different perspectives for better visualization, but they correspond to the same protein.</figDesc><graphic url="image-3.png" coords="9,102.79,228.55,388.81,153.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and evaluate the generated molecular geometries. The evaluation metrics are validity of generated molecules and the Maximum Mean Discrepancy (MMD) (Gretton et al., 2012) distances of bond length distributions between generated 3D molecules and training 3D molecules. The bond length distributions of molecules generated by different models and training molecules are illustrated in Figure 5, Appendix C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2.</head><label></label><figDesc>Comparison on random molecular geometry generation task between our method and ablation models. ? (?) represents that higher (lower) value indicates better performance. The top two results in terms of each metric are highlighted as 1st and 2nd. dep. 76.72% 0.343 0.384 0.257 0.227 0.373 0.828 0.402 Ours 81.98% 0.232 0.160 0.475 0.058 0.318 0.202 0.241</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Comparison of training losses between our method and ablation models.</figDesc><graphic url="image-4.png" coords="10,151.39,185.67,291.61,192.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Visualization of bond length distributions of generated molecules and training molecules.</figDesc><graphic url="image-5.png" coords="14,55.44,67.06,486.00,187.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="3,55.44,67.06,485.98,122.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Generation performance on structure-based drug design. ? represents that higher value indicates better performance.</figDesc><table><row><cell>Method</cell><cell cols="2">Validity ? ?Binding ?</cell></row><row><cell>LiGAN-prior</cell><cell>90.9%</cell><cell>15.9%</cell></row><row><cell>LiGAN-posterior</cell><cell>98.5%</cell><cell>15.4%</cell></row><row><cell>GraphBP (ours)</cell><cell>99.7%</cell><cell>27.0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>|C (t-1) p d t |C (t-1) , a t p ? t |C (t-1) , a t , d t p ? t |C (t-1) , a t , d t , ? t |C (t-1) + log p d t |C (t-1) , a t + log p ? t |C (t-1) , a t , d t + log p ? t |C (t-1) , a t , d t , ? t ?t |C (t-1) + log p d t |C (t-1) , a t + log p ? t |C (t-1) , a t , d t + log p ? t |C (t-1) , a t , d t , ? t</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(21)</cell></row><row><cell></cell><cell></cell><cell>n</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">= -</cell><cell>t=1</cell><cell cols="5">log p a t (22)</cell></row><row><cell></cell><cell></cell><cell>n</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">-</cell><cell>t=1</cell><cell cols="5">log p (23)</cell></row><row><cell>= -</cell><cell cols="2">n t=1</cell><cell cols="2">log (PD (p Za (z a t ))) + log PD</cell><cell>1 ? a t</cell><cell>+ log p Z d z d t</cell><cell>+ log</cell><cell>1 ? d t</cell></row><row><cell></cell><cell></cell><cell></cell><cell>+ log p Z ? z ? t</cell><cell>+ log</cell><cell>1 ? ? t</cell><cell cols="2">+ log p Z? (z ? t ) + log</cell><cell>1 t ? ?</cell><cell>.</cell></row></table><note><p><p>ap = -log n t=1 p a t , d t , ? t , ? t |C (t-1) (19) = -n t=1 log p a t , d t , ? t , ? t |C (t-1) (20) = -n t=1</p>log p a t</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Za , p Z d , p Z ? , and p Z? are prior Gaussian distributions.</figDesc><table><row><cell>), such as z d t =</cell><cell>dt-? d t t ? d</cell><cell>. p</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Department of Computer Science &amp; Engineering, Texas A&amp;M University, TX, USA</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Fujitsu Research of America, INC., CA, USA</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Fujitsu Laboratories Ltd., Kanagawa, Japan. Correspondence to: Meng Liu &lt;mengliu@tamu.edu&gt;, Shuiwang Ji &lt;sji@tamu.edu&gt;.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">David Koes</rs> and <rs type="person">Matthew Ragoza</rs> for answering our questions about using gnina and sharing their experimental results. This work was supported in part by <rs type="funder">National Science Foundation</rs> grants <rs type="grantNumber">IIS-2006861</rs> and <rs type="grantNumber">IIS-1908220</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_B8yAZjj">
					<idno type="grant-number">IIS-2006861</idno>
				</org>
				<org type="funding" xml:id="_gDUMANM">
					<idno type="grant-number">IIS-1908220</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Contact atom classifier loss L cc . The contact atom classifier is used to select the first local reference atom from the binding site. We train it with the standard binary cross entropy loss. In particular, we use the contact atom, which is the atom in the binding site that is closest to the ligand, as the positive sample, and the atom in the binding site that is furthest to the ligand, as the negative sample.</p><p>Focal atom classifier loss L f c . The focal atom classifier is also trained with the standard binary cross entropy loss and used for selecting a local reference atom from the existing ligand atoms. The ground truth for an atom is negative if all of its bonded atoms have been generated, otherwise positive.</p><p>In summary, the overall loss function for training GraphBP is L = L ap + L cc + L f c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We firstly evaluate the ability of our GraphBP to generate 3D molecules that are capable of binding to given protein targets. The experiment demonstrates that GraphBP outperforms baselines by significant margins. Afterwards, we perform ablation studies to verify the effectiveness of the sequential generation proposed in Section 3. <ref type="bibr">1.3. et al., 2019;</ref><ref type="bibr" target="#b42">Shi et al., 2019;</ref><ref type="bibr">Liu et al.,</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dataset Details</head><p>There are totally 27 atom types for ligands; they are B, C, N, O, F, Mg, Al, Si, P, S, Cl, Sc, V, Fe, Cu, Zn, As, Se, Br, Y, Mo, Ru, Rh, Sb, I, W, and Au. For binding sites, there are 19 possible atom types, including C, N, O, Na, Mg, P, S, Cl, K, Ca, Mn, Co, Cu, Zn, Se, Cd, I, Cs, and Hg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. More Experimental Results</head><p>The bond length distributions of molecules generated by different models and training molecules are compared in Figure <ref type="figure">5</ref>. We can observe that adding dependencies among variables helps to improve the modeling ability. Our sequential generation strategy outperforms ablation variants consistently.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The process of structure-based drug design</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemistry &amp; biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="787" to="797" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Syntax-directed variational autoencoder for structured data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Molgan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11973</idno>
		<title level="m">An implicit generative model for small molecular graphs</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Nice</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<title level="m">Non-linear independent components estimation</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Francoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sunseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Iovanisci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4200" to="4215" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Torsional geometric generation of molecular 3d conformer ensembles</title>
		<author>
			<persName><forename type="first">O.-E</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pattanaik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><surname>Geomol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Gebauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Sch?tt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
		<meeting>the 33rd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7566" to="7578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TorsionNet: A reinforcement learning approach to sequential conformer search</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gogineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Punzalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kammeraad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zimmerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">20142-20153, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic chemical design using a data-driven continuous representation of molecules</title>
		<author>
			<persName><forename type="first">R</forename><surname>G?mez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>S?nchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sheberla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A kernel two-sample test</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="723" to="773" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>No?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03131</idno>
		<title level="m">Generating valid euclidean distance matrices</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3d convolutional neural networks for human action recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="221" to="231" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Junction tree variational autoencoder for molecular graph generation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2323" to="2332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Highly accurate protein structure prediction with alphafold</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jumper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figurnov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tunyasuvunakool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>??dek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Potapenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">596</biblScope>
			<biblScope unit="issue">7873</biblScope>
			<biblScope unit="page" from="583" to="589" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="10215" to="10224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Directional message passing for molecular graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gro?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>G?nnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Universal directional graph neural networks for molecules</title>
		<author>
			<persName><forename type="first">J</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>G?nnemann</surname></persName>
		</author>
		<author>
			<persName><surname>Gemnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Grammar variational autoencoder</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
		<idno>PMLR 70</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34 th International Conference on Machine Learning</title>
		<meeting>the 34 th International Conference on Machine Learning<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">RDKit: Open-source cheminformatics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Landrum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning deep generative models of graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Molecular graph generation with energy-based models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Oztekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Graphebm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.00546</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spherical message passing for 3d molecular graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Oztekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Forging the basis for developing protein-ligand interaction scoring functions</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Accounts of chemical research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="302" to="309" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A 3d generative model for drug design</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Predicting molecular conformation via dynamic graph score matching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An autoregressive flow model for 3d molecular geometry generation from scratch</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A discrete flow model for molecular graph generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Graphdf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7192" to="7203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Madhawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ishiguro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName><surname>Graphnvp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11600</idno>
		<title level="m">An invertible flow model for generating molecular graphs</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Molecular geometry prediction using a deep generative graph neural network</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gnina 1.0: molecular docking with deep learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Mcnutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Francoeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Meli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sunseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">DMolNet: a generative network for molecular structures</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nesterov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Roth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06477</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Open babel: An open chemical toolbox</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>O'boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Banck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vandermeersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hutchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Protein-ligand scoring with convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hochuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Idrobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sunseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="942" to="957" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Generating 3d molecules conditional on receptor binding sites with deep generative models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Masuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Koes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.15200</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Von</forename><surname>Lilienfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">UFF, a full periodic table force field for molecular mechanics and molecular dynamics simulations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Rapp?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Casewit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Goddard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Skiff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American chemical society</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="10024" to="10035" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.09016</idno>
		<title level="m">E(n) equivariant normalizing flows for molecule generation in 3d</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">GraphAF: a flow-based autoregressive model for molecular graph generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning gradient fields for molecular conformation generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A generative model for molecular distance geometry</title>
		<author>
			<persName><forename type="first">G</forename><surname>Simm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernandez-Lobato</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8949" to="8958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Reinforcement learning molecular design guided by quantum mechanics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Simm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pinsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hern?ndez-Lobato</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8959" to="8969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">GraphVAE: Towards generation of small graphs using variational autoencoders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="412" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">AutoDock Vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading</title>
		<author>
			<persName><forename type="first">O</forename><surname>Trott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational chemistry</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="455" to="461" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules</title>
		<author>
			<persName><forename type="first">D</forename><surname>Weininger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and computer sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="36" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Flow-based deep generative models. lilianweng. github. io/lil-log</title>
		<author>
			<persName><forename type="first">L</forename><surname>Weng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An end-to-end framework for molecular conformation generation via bilevel programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gomez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generating realistic graphs with deep auto-regressive models</title>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><surname>Graphrnn</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5708" to="5717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">MoFlow: an invertible flow model for generating molecular graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="617" to="626" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
