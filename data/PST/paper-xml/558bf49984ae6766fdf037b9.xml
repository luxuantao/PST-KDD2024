<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Purdue University</orgName>
								<address>
									<postCode>47907</postCode>
									<settlement>West Lafayette</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">373C737018D5439CC6D3BAA70DAF9416</idno>
					<idno type="DOI">10.1109/TNET.2011.2111382</idno>
					<note type="submission">received December 17, 2009; revised October 14, 2010; accepted January 16, 2011; approved by IEEE/ACM TRANSACTIONS ON NETWORKING Editor S. Diggavi. Date of publication February 24, 2011; date of current version October 14, 2011.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Coded feedback</term>
					<term>network coding</term>
					<term>opportunistic routing</term>
					<term>wireless mesh networks (WMNs)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The use of random linear network coding (NC) has significantly simplified the design of opportunistic routing (OR) protocols by removing the need of coordination among forwarding nodes for avoiding duplicate transmissions. However, NC-based OR protocols face a new challenge: How many coded packets should each forwarder transmit? To avoid the overhead of feedback exchange, most practical existing NC-based OR protocols compute offline the expected number of transmissions for each forwarder using heuristics based on periodic measurements of the average link loss rates and the ETX metric. Although attractive due to their minimal coordination overhead, these approaches may suffer significant performance degradation in dynamic wireless environments with continuously changing levels of channel gains, interference, and background traffic. In this paper, we propose CCACK, a new efficient NC-based OR protocol. CCACK exploits a novel Cumulative Coded ACKnowledgment scheme that allows nodes to acknowledge network-coded traffic to their upstream nodes in a simple way, oblivious to loss rates, and with negligible overhead. Through extensive simulations and testbed experiments, we show that CCACK greatly improves both throughput and fairness compared to MORE, a state-of-the-art NC-based OR protocol.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Efficient Network-Coding-Based Opportunistic</head><p>Routing Through Cumulative Coded</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>W IRELESS mesh networks (WMNs) are increasingly being deployed for providing cheap, low-maintenance Internet access (e.g., <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>). A main challenge in WMNs is to deal with the poor link quality due to urban structures and interference, both internal (among flows in the WMN) and external (from other 802.11 networks). For example, 50% of the operational links in Roofnet <ref type="bibr" target="#b0">[1]</ref> have loss rates higher than 30% <ref type="bibr" target="#b3">[4]</ref>. Hence, routing protocol design is critical to the performance and reliability of WMNs.</p><p>Traditional routing protocols (e.g., <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b6">[7]</ref>) for multihop wireless networks treat the wireless links as point-to-point links. First, a fixed path is selected from the source to the destination. Then, each hop along the chosen path simply sends data packets to the next hop via 802.11 unicast. Opportunistic routing (OR), as first demonstrated in the ExOR protocol <ref type="bibr" target="#b7">[8]</ref>, has recently emerged as a mechanism for improving unicast throughput in WMNs with lossy links. Instead of first determining the next hop and then sending the packet to it, a node with OR broadcasts the packet so that all neighbor nodes have the chance to hear it and assist in forwarding.</p><p>In practice, it is not beneficial if all nodes in the network participate in forwarding traffic for a single flow. Hence, existing OR protocols typically construct a belt of forwarding nodes (FNs) for each flow, and only members of the belt are allowed to forward packets.</p><p>OR provides significant throughput gains compared to traditional routing. However, it introduces a difficult challenge. Without any coordination, all members of the FN belt that hear a packet will attempt to forward it, creating spurious retransmissions, which waste bandwidth. To address this challenge, a coordination protocol needs to run among the nodes so that they can determine which one should forward each packet.</p><p>Recently, <ref type="bibr" target="#b8">[9]</ref> showed that the use of random intraflow network coding (NC) can address this challenge in a very simple and efficient manner, with minimal coordination. With NC, the source sends random linear combinations of packets, and each router also randomly mixes packets it already has received before forwarding them. Random mixing at each router ensures that, with high probability, different nodes that may have heard the same packet can still transmit linearly independent coded packets.</p><p>NC has significantly simplified the design of OR protocols and led to substantial throughput gains <ref type="bibr" target="#b8">[9]</ref> compared to noncoding-based protocols. However, the use of NC introduces a new challenge: How many coded packets should each forwarder transmit? This challenge, if not efficiently addressed, may prevent NC-based OR protocols from realizing the maximum possible gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Challenge in NC-Based OR Protocols</head><p>We illustrate the main challenge in NC-based OR protocols with the example shown in Fig. <ref type="figure" target="#fig_0">1</ref>. This figure shows a typical scenario of an NC-based OR protocol. The source has three downstream FNs , and . Assume for simplicity that has three innovative packets , and to send. Instead of transmitting the native packets, transmits three coded packets , and in sequence, which are denoted by the corresponding coding vectors (1, 1, 1), (3, 1, 2), and (1, 2, 3). Assume that the (1, 1, 1) coded packet is received by , and the (3, 1, 2) and (1, 2, 3) packets are received by and by , respectively. The downstream FNs , and have received a sufficient amount of innovative packets. Collectively, the three FNs can now act as the new source, and the original source should stop transmission. However, it is a nontrivial task for to know whether its downstream FNs have accumulated a sufficient amount of innovative packets.</p><p>The same challenge exists for the intermediate FN . After transmitting a useful coded packet <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5)</ref>, which is received by <ref type="bibr">FN</ref> has to decide whether it should continue or stop sending coded packets. Furthermore, has limited knowledge about the reception status of the three packets transmitted by [e.g., may not know that has received (1, 1, 1) from ], which makes the decision of whether to stop transmission even harder for than for the source .</p><p>Note that overhearing, a commonly used way of acknowledging noncoded wireless traffic due to its zero overhead, does not suit network-coded traffic. For the same example in Fig. <ref type="figure" target="#fig_0">1</ref>, when has the opportunity to transmit, a network-coded packet <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6</ref>) may be generated from the two innovative packets received by . Even if overhears this new <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6)</ref> packet, still does not know whether received the (4, 3, 5) packet transmitted by since it is not aware of the reception of the (1, 1, 1) packet by .</p><p>One way to address the challenge is to combine individual packet overhearing, as in non-coding-based protocols, with a credit system, based on coded transmissions, and have the FNs perform detailed bookkeeping to guarantee credit conservation in the system. This approach is taken in MC <ref type="bibr" target="#b9">[10]</ref>. Although theoretically optimal <ref type="bibr" target="#b10">[11]</ref>, this approach is quite complex in practice. In addition, like every approach that relies on individual packet overhearing, it requires a reliable control plane. In typical WMN environments with high packet loss rates or contention <ref type="bibr" target="#b3">[4]</ref>, this approach can cause excessive signaling overhead and retransmissions, which can significantly limit the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Loss-Rate-Based Approaches</head><p>Since theoretically optimal solutions are hard to implement in practice, existing NC-based OR protocols use heuristics based on link loss rates to address the challenge in a simple manner and to minimize the control overhead.</p><p>MORE <ref type="bibr" target="#b8">[9]</ref>, the first NC-based OR protocol, employs an offline approach that requires no coordination among FNs. In MORE, the source calculates and assigns a transmission credit to each FN using the ETX metric <ref type="bibr" target="#b11">[12]</ref> computed from loss rate measurements. Receptions from upstream nodes are then used to trigger new transmissions at the FNs, with precomputed relative frequencies using the transmission credits. Since the ETX metric expresses the expected behavior, the approach used in MORE cannot guarantee that the destination will always receive enough packets due to the randomness of the wireless channel. Hence, the source in MORE keeps transmitting packets from the same batch until it receives an ACK from the destination, unnecessarily increasing interference.</p><p>Many other works that improve MORE also use offline measured loss rates as a basic component in their proposed solutions (e.g., <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b14">[15]</ref>).</p><p>The drawback of all these approaches is that performance heavily depends on the accuracy and freshness of the loss-rate measurements. Loss-rate estimates are obtained through periodic probing and are propagated from all nodes to the source. Apparently, the higher the probing frequency, the higher the accuracy, but also the higher the overhead. As a recent study <ref type="bibr" target="#b15">[16]</ref> showed, even low-rate control overhead in nonforwarding links can have a multiplicative throughput degradation on data-carrying links.</p><p>To reduce this overhead, the authors of MORE collect the loss rates and calculate the credits only in the beginning of each experiment. In practice, this suggests that loss-rate measurements should be performed rather infrequently. Unfortunately, recent WMN studies <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> have shown that although link metrics remain relatively stable for long intervals in a quiet network, they are very sensitive to background traffic. For example, in <ref type="bibr" target="#b16">[17]</ref>, the authors observe that 100 ping packets (one per second) between two nodes in a 14-node testbed caused an increase of 200% or more to the ETT <ref type="bibr" target="#b18">[19]</ref> metric of around 10% of the links. <ref type="foot" target="#foot_0">1</ref> Even worse, a 1-min TCP transfer between two nodes in the same network caused an increase of more than 300% to the ETT metric of 55% of the links.</p><p>In summary, these approaches suffer from difficulties in accurately estimating loss rates. Overestimated loss rates cause redundant transmissions, which waste wireless bandwidth. On the other hand, underestimated loss rates may have an even worse impact since nodes may not transmit enough packets to allow the destination to decode a batch. This motivates the need for a new approach oblivious to loss rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Our Approach-Cumulative Coded Acknowledgments</head><p>In this paper, we present a novel approach to NC-based OR and propose CCACK, a new efficient NC-based OR protocol. Unlike existing protocols, FNs in CCACK decide how many packets to transmit in an online fashion, and this decision is completely oblivious to link loss rates. <ref type="foot" target="#foot_1">2</ref> This is achieved through a novel Cumulative Coded ACKnowledgment scheme that allows nodes to acknowledge network-coded traffic to their upstream nodes in a simple and efficient way with negligible overhead. Feedback in CCACK is not required strictly on a per-packet basis; this makes the protocol resilient to individual packet loss and significantly reduces its complexity. Take the scenario in Fig. <ref type="figure" target="#fig_0">1</ref> as a continuing example. One naive approach to ensure that (resp. ) knows when to stop transmission is through the use of reception reports, for which each node broadcasts all the basis vectors of the received linear space to its upstream nodes, as illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>(a). <ref type="foot" target="#foot_2">3</ref>An obvious drawback of this approach is the size of the feedback messages. For practical network coding with symbol size and batch size 32, each coding vector contains 32 B. To convey a space of dimension thus requires 32-B vectors, which is too large to piggyback to normal forward traffic. The unreliability of the wireless channel further exacerbates the problem as the 32-B feedback messages need to be retransmitted several times until they are overheard by all the upstream nodes.</p><p>In contrast, in CCACK each node uses a single coded feedback vector to represent the entire space, which may consist of 1 basis vectors. In the broadest sense, the three coded acknowledgment vectors to in Fig. <ref type="figure" target="#fig_1">2</ref>(b) serve as a hash for their corresponding spaces. As will be explained in Section III, we have devised a simple mechanism that successfully compresses (most of) the space information into a single vector, say for node , while allowing upstream nodes to extract the original space from without exchanging any additional control information. Each single vector can be easily piggybacked to the forward data traffic. This compressed/coded acknowledgment is critical to the efficiency since, in CCACK, overhearing any of the data packets of with piggybacked coded ACK will convey to the upstream nodes the entire space (or most of the space) of .</p><p>In addition to efficiently solving the challenge of how many packets each FN should transmit, the cumulative coded acknowledgment scheme in CCACK enables us to develop an efficient rate control algorithm. In contrast, MORE has no explicit rate control mechanism, and its performance degrades as the number of flows in the network increases <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Contributions</head><p>This paper makes the following contributions.</p><p>• We identify a main challenge in the newly emerged class of NC-based OR protocols: How many coded packets should each forwarder transmit? We discuss the inefficiencies of existing loss-based approaches in addressing this challenge and show, through our simulation and testbed evaluations, the severe impact such approaches can have on the performance of NC-based OR protocols.</p><p>• We propose CCACK, a new efficient NC-based OR protocol. Unlike existing protocols, FNs in CCACK decide how many packets to transmit in an online fashion, and this decision is completely oblivious to link loss rates. Central to the design of CCACK is a novel Cumulative Coded ACKnowledgment scheme that allows nodes to acknowledge network-coded traffic to their upstream nodes in a simple and efficient way, with negligible overhead. In addition to efficiently solving the challenge of how many packets each FN should transmit, the cumulative coded acknowledgment scheme in CCACK enables us to develop an efficient rate control algorithm. • CCACK brings a shift to the design paradigm of NC-based OR protocols. Existing NC-based OR protocols have identified feedback overhead as a main cause for performance degradation in practical wireless routing protocols and used NC to eliminate the need for feedback exchange, resorting to offline loss-based heuristics. On the contrary, CCACK encodes feedback to exploit its benefits and avoid the drawbacks of offline heuristics and, at the same time, to hide its overhead. • We present extensive simulations with a realistic physical model showing that CCACK offers significant throughput and fairness improvements over the state-of-the-art MORE by 27%-45% and 5.8%-8.8%, respectively, on average, with a varying number of flows. For some challenged flows that completely starve under MORE, CCACK increases throughput by up to 21 and fairness by up to 124%. We further quantify the header, memory, and coding overheads of CCACK and show that they are comparable to those of MORE, making CCACK easily deployable on commodity hardware. • We present an application-layer implementation of CCACK and MORE and their evaluation on a 22-node 802.11 WMN testbed deployed in two academic buildings at Purdue University, West Lafayette, IN. Despite the small size of our testbed along with the limitations of our implementation that limit the potential gains, our testbed results show that CCACK improves both throughput and fairness over MORE by up to 3.2 and 83%, respectively, with average improvements of 11%-36% and 5.7%-8.3%, respectively, validating the benefits of our approach. The remainder of this paper is organized as follows. In Section II, we introduce the basic principles of coded feedback through a simple existing coded feedback scheme. We identify two problems with this scheme that motivate the design of CCACK, presented in Section III. Section IV evaluates the performance of CCACK and MORE through extensive simulations, and Section V describes the implementation and evaluation of CCACK and MORE on a wireless testbed. Finally, Section VI concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. EXISTING CODED FEEDBACK SCHEME</head><p>One candidate solution (which has been used in the past in a different context <ref type="bibr" target="#b19">[20]</ref>), attractive due to its simplicity, is nullspace-based (NSB) coded feedback, i.e., each node sends to each upstream node one vector randomly chosen among all vectors in the null space of the innovative vectors the node has received in the past. Take for example Fig. <ref type="figure" target="#fig_2">3(a)</ref>, which shows FNs and from Fig. <ref type="figure" target="#fig_0">1</ref>. Let denote the buffer containing the innovative coding vectors received by an FN [ contains two vectors (1, 2, 3) and (3, 1, 2) at node and one vector (1, 2, 3) at node in Fig. <ref type="figure" target="#fig_2">3(a)</ref>]. Every time broadcasts a coded data packet to its own downstream nodes, it also appends to the packet header an ACK vector satisfying</p><formula xml:id="formula_0">(1)</formula><p>Namely, the inner product between and is zero. There may be multiple choices of that satisfy this condition [e.g., in Fig. <ref type="figure" target="#fig_2">3(a)</ref>, can be any vector of the form ]. is then chosen uniformly randomly among all valid vectors satisfying (1). Let denote the linear space spanned by vectors in . One can easily show the following. Lemma 1: With the above random construction of , any vector must satisfy . Moreover, for any vector , we have assuming the finite field is used. The intuition behind Lemma 1 can be explained as follows. Suppose the rank of space in Lemma 1 satisfies . Moreover, we further restrict ourselves to choose a vector that is strictly nonzero. Once such a is chosen, there are totally 256 different vectors that satisfy . Among them, of them are in and of them are not in . Note that, out of the entire space (totally 256 different vectors), there are vectors that are not in . Therefore, the probability that a randomly chosen satisfies is From the above lemma, when the upstream node overhears a packet from , it simply needs to compute the inner product of each of its own innovative vectors with . Suppose that is chosen as . Since concludes that has received packet . On the other hand, since concludes that packet is an innovative packet for , and hence it should send more coded packets to .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problems of the NSB Coded Feedback for Unicast OR</head><p>Although attractive due to its simplicity, the NSB feedback scheme suffers from two significant limitations when used in NC-based OR.</p><p>Problem 1: Collective Space Problem: Take Fig. <ref type="figure" target="#fig_2">3(b</ref>) for example. Based on the NSB concept, and send and , respectively, which are orthogonal to their local innovative vectors. When checks the inner product of the coded feedback and its own innovative packets, we have Therefore thinks that the coding vector (3, 1, 2) is innovative to both its downstream nodes and thus continues transmission even when collectively and have had enough information already. It will not stop transmission until one of its downstream nodes has a local knowledge space that covers the local knowledge space of . This defeats the purpose of OR. This misjudgment is caused by the fact that the NSB coded feedback does not convey the collective space of all downstream nodes, but only the space relationship between the individual pairs (i.e., versus and versus ).</p><p>Problem 2: Nonnegligible False-Positive Probability: Take Fig. <ref type="figure" target="#fig_2">3(c</ref>) for example. Node would like to send two packets to node , and a coded packet has been received by already. sends an orthogonal vector satisfying (1), which is randomly chosen to be any vector of the form . Suppose that happens to choose . Since is orthogonal to all the innovative vectors of will wrongfully infer that the knowledge space of covers the local knowledge space of . thus attempts no further transmission. Although the probability of such a false-positive event is small, its impact to the system performance is significant. Any single hop that experiences this false-positive event will cause an upstream node to stop transmission prematurely. The communication chain is thus broken, and the destination may not be able to receive enough innovative packets to decode the current batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CCACK DESIGN</head><p>In this section, we present the design of CCACK. We first describe how CCACK addresses the collective space problem. We then describe a novel cumulative coded feedback scheme, which reduces the false-positive probability to practically zero. Finally, we present a simple rate control algorithm, built upon this coded feedback scheme.</p><p>The source and the intermediate FNs in CCACK use intraflow random linear NC. We selected a batch size of packets, and the random coefficients for each linear combination are selected from a Galois Field (GF) of size 2 , the same as in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, and <ref type="bibr" target="#b14">[15]</ref>. Similar to <ref type="bibr" target="#b19">[20]</ref>, nodes in CCACK embed an additional ACK vector in the header of each coded data packet of the forward traffic to acknowledge a subset of the packets (or coding vectors) they have received (heard) in the past from their upstream nodes. For the following, we use the terms forward coding vectors and ACK coding vectors to denote the coding coefficients used to encode the payload of the packets and the feedback vectors used to acknowledge the space, respectively. Basically, the forward coding vector and the payload is used by any downstream node that receives this packet. The ACK coding vector is used by any upstream node that receives this packet. For simplicity, assume for now that the ACK coding vector is constructed following the NSB principle, i.e., it is simply a vector in the null space of the innovative vectors owned by the node. In Section III-B, we will describe a new construction of the ACK coding vector that solves the false-positive problem of the NSB feedback.</p><p>All packets in CCACK are broadcast so that they can be heard by all neighbor nodes. Each node maintains a buffer of entries where it stores all the innovative packets of the current batch. If a node receives a packet from an upstream node, it checks whether the packet is innovative by comparing the coding vector to those of the existing packets in . If innovative, the newly received packet is stored in , similarly to MORE and other existing NC-based OR protocols. <ref type="foot" target="#foot_3">4</ref>Unlike the intermediate nodes, which piggyback the ACK vectors to data packets, the destination periodically broadcasts coded feedback to its upstream nodes in the form of ACK vectors (without any payload). This is necessary since the destination sends no data packets. Once it receives innovative packets for a batch, it decodes the batch to obtain the original packets. It then sends an end-to-end ACK back to the source along the shortest ETX path in a reliable manner. <ref type="foot" target="#foot_4">5</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Solving the Collective Space Problem</head><p>As we saw in Section II-A, the collective space problem is due to the fact that each NSB coded acknowledgment can only covey the space information/relationship between one pair of nodes (from the downstream node back to the upstream node). Hence, the first step toward addressing the collective space problem is to collectively consider the NSB acknowledgments from all the downstream nodes.</p><p>However, this is generally not enough. In Fig. <ref type="figure" target="#fig_2">3</ref>(b), we see that the vector (4, 3, 5) owned by is a linear combination of the two vectors owned by . When receives from , it computes and decides that its vector (3, 1, 2) has not been heard by any downstream node. Thus, it continues transmitting packets. Note that the same problem would arise if (4, 3, 5) had been sent by an upstream node of and had been received by both and . In that case, would have dropped it since it is linearly dependent to its own two vectors (1, 2, 3) and (3, 1, 2), and the picture would be the exactly the same as in Fig. <ref type="figure" target="#fig_2">3(b</ref>). Hence, to address the collective space problem, nodes need to remember all the packets that have been in the air, not only the innovative ones.</p><p>To achieve this, nodes in CCACK maintain two additional vector buffers per flow: and . The size and can be larger than since these buffers only store 32-B coding vectors and not whole packets. In our implementation, we used a size equal to . The forward coding vectors in and together constitute all the vectors that have recently been in the air and have been heard by the node of interest. More specifically, nodes store the coding vectors of all packets they receive from upstream nodes in and the coding vectors of the packets they broadcast in . Each such vector can be marked as (heard by a downstream node) or (not heard). A vector is marked as when it initially is inserted in either of the two immediately after it stops transmitting packets for batch i. In the future, we plan to incorporate this feature in CCACK. buffers since the node has no information at that time whether any downstream node has heard the packet or not. Nodes gradually mark the coding vectors in and as as they receive more ACK coding vectors from downstream nodes.</p><p>In contrast to the NSB coded feedback scheme in <ref type="bibr" target="#b19">[20]</ref>, nodes in CCACK construct the ACK coding vectors using all the received forward coding vectors stored in and not only the innovative vectors stored in . Also, when a node overhears a packet from a downstream node, it uses the ACK coding vector of that packet to decide whether any of the coding vectors in , instead of , have been heard by the downstream node.</p><p>We first explain the benefits of using separate buffers and in terms of solving the collective space problem through our running example from Fig. <ref type="figure" target="#fig_2">3</ref>(b) in Fig. <ref type="figure" target="#fig_3">4</ref>. For node contains the received coding vectors (1, 2, 3) and (3, 1, 2), while contains the transmitted vector <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5)</ref>. By checking inner products with and knows that the and have been heard by downstream nodes and accordingly marks them as . Since the rank of the vectors in is the same as the rank of the innovative vectors in stops transmission. To analyze more rigorously how the usage of two separate buffers and can greatly alleviate the collective space problem, we consider the simplified representative scenario in Fig. <ref type="figure" target="#fig_0">1</ref>. is the closest neighbor of and can help relay packets to its downstream nodes and . To focus on the collective space problem faced by , we assume only and have transmitted packets thus far. The downstream nodes and only listen to the transmissions of and , and then compute ACK packets accordingly via the NSB feedback. We further assume that the coding finite field is sufficiently large so that the false-positive probability of the NSB feedback is zero and we can isolate the collective space problem.</p><p>Since source has all the packets, its knowledge space is simply the entire vector space of the current batch of packets. We then divide the transmitted packets into four groups: Group 1: those packets transmitted by and heard by , but not by any of and ; Group 2: those packets transmitted by and heard by one of , but not by ; Group 3: those packets transmitted by and heard by and by one of ; Group 4: those packets transmitted by and heard by one of .</p><p>We first observe that by using two separate buffers and can use the collective NSB feedback from the downstream nodes and to decide whether the packets in its or buffer belong to Group 3 or 4. As a result, a collective space problem happens when and only when the linear span of Group-2, Group-3, and Group-4 packets (i.e., packets heard by ), denoted by , covers the linear span of Group-1 and Group-3 packets (packets heard by , while (i.e., those packets heard by and which is aware of through NSB feedback) does not cover</p><p>. Therefore, with the help of two separate buffers, the collective space problem is completely solved when all packets heard by or are also heard by (i.e., when Group 2 is empty). In practice, we often encounter the case when we do have some Group-2 packets. We show the following. 1) In addition to the above case (in which Group 2 is empty), there are many other cases when the collective space problem is indeed solved by using separate buffers. 2) Even for the cases when the collective space is not completely solved by separate buffers, the penalty we pay is generally very small.</p><p>Consider the moment when is satisfied for the first time, i.e., when should stop transmission since the collective space of and covers . We consider the following two scenarios.</p><p>Scenario 1: . Due to the use of random linear network coding (RLNC) at source , Group-2 packets are as linearly independent as possible from Group-1 and Group-3 packets. We can thus prove that among Groups 2-4, only Group-3 and Group-4 packets can serve the roles of covering Group-1 and Group-3 packets. Therefore, implies . thus knows that it should stop transmission. The collective space problem is completely solved.</p><p>Scenario 2: for some . Following a similar RLNC-based argument as used in Scenario 1, one can show that the overlap between and is at most of rank . As a result, Group-2 packets can help cover for at most rank . Therefore</p><p>This means that even though "feels that" the collective space of and does not cover itself (while it actually does) in the present moment, after another successful transmission from to will be sure that the collective space of and covers itself. The penalty of the collective space problem is thus only additional transmissions. Note that since we use CCACK to stop the transmission of as well, it is likely that the stops transmission the very first moment that the collective space of , and covers that of . Since RLNC is used, it means that stops transmission whenever (recalling that Group-2 packets are independent from Groups 1 and 3). Therefore, we mostly encounter Scenario 1 (when ). In some rare cases when CCACK is not able to stop the transmission of right away, we will see . However, in general, the corresponding is expected to be very small, and hence the penalty we pay in Scenario 2 is very small. The simulation results in Section IV-B confirm our intuition that Scenario 2 happens rarely (or happens, but with a small ) by comparing the performance of CCACK to a perfect ACK scheme that is free of any collective-space problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Solving the False-Positive Problem</head><p>We now describe our new ACK design that drastically reduces the false-positive probability from to for any integer . From Lemma 1, when a node sends one vector in the null space of its innovative vectors, the false-positive probability at an upstream node is . Obviously, if node sends vectors in the null space of its innovative vectors, all in the same packet, then the overall false-positive event happens when all orthogonality tests return false positive, and the overall false-positive probability is . Hence, the main idea in CCACK is to append only one ACK vector to each data packet, similar to NSB, but to construct it in such a way that it is almost equivalent to appending vectors independently distributed over the null space. We achieve this effect by using hash matrices to . Since the vector/matrix operations are heavily used in our description, we further assume that all vectors are row vectors, and we use the transpose to represent a column vector (constructed from the row vector ).</p><p>More explicitly, assume that a node wants to acknowledge vectors, , from its to its upstream node , and let denote the linear space spanned by the vectors. With NSB, would send a vector satisfying . With the hash matrices to , we can rotate the chosen vector times by multiplying it with each of the hash matrices, respectively. We require that the vectors created from the rotations, remain orthogonal to , i.e., we have linear equations , and we choose a single vector that satisfies these equations. Such now represents vectors , and all of them are orthogonal to</p><p>. Sending one such is thus as if we have used the NSB feedback scheme for times. To make the above intuition rigorous, we compute globally different hash matrices to , where is the batch size. Each matrix is a diagonal matrix with the diagonal elements denoted by to . We require that the choice of the set of hash matrices satisfies that: 1) for all and ; and 2) for any distinct indices in , the following square matrix has full rank: . . . . . . . . .</p><p>The intuition behind is that like any other hash-based mechanisms, we would like the hash matrices to be as random as possible. <ref type="foot" target="#foot_5">6</ref> Equation ( <ref type="formula" target="#formula_1">2</ref>) explicitly quantifies the "desired level of randomness" in terms of the corresponding linear independence between the column vectors . Such a quantitative level of randomness is critical for our theoretic exploration.</p><p>Since the hash matrices are designed globally and can be reused for all batches, we only need to compute them once, and they can be reused by any CCACK protocols. In our CCACK protocol design, we start from randomly chosen hash matrices to and repeatedly perturb the hash matrices until they satisfy <ref type="bibr" target="#b1">(2)</ref>. Using the precomputed hash matrices, the detailed algorithm for constructing of an ACK vector is as follows: § CONSTRUCT THE ACK VECTOR 1: Start from a matrix . 2: repeat 3:</p><p>Choose the with the smallest from . If more than one such exist, choose one randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>if is linearly independent to the row space of then 5:</p><p>Add <ref type="foot" target="#foot_6">7</ref> to . 6:</p><formula xml:id="formula_2">end if 7:</formula><p>Increment the of by 1. 8: until the number of rows of equals or until all in have been selected. Remark 1: These vectors in are the vectors being acknowledged. 9: For each , the matrix product is a matrix. Construct a matrix by vertically concatenating all matrices for . 10: Choose randomly the coding coefficients to such that the following matrix equation is satisfied:</p><p>(3) Remark 2: By Lines 8 and 9, (3) contains linear equations and variables. We thus have at least degrees of freedom when solving the above equations. Therefore, we can convert to its equivalent row-echelon form, which makes it easy to choose randomly the desired to . Remark 3: When randomly assigning the values of to , we further require that out of the coefficients to , at least of them are nonzero. This can always be achieved easily by choosing the free variables in the row-echelon form to be nonzero. 11: Use the as the ACK vector.</p><p>To improve the efficiency of our feedback mechanism, we associate a with every vector in (Line 3 of the algorithm). When a vector is first placed in , its is set to 0. Every time this vector is selected in the feedback construction algorithm, its is incremented by 1. The ACK vector is always constructed using those vectors in with the lowest counts. This will reduce the probability that the same vectors are repeatedly acknowledged many times.</p><p>We then observe that we can only acknowledge vectors in (Line 9). The reason is that if we acknowledge coding vectors in , then the resulting matrix has rows and the corresponding matrix has rows. As a result, the number of equations in (3) is larger than the number of variables in (3). Generally, it is thus impossible to find a nonzero vector satisfying (3). Note that the global parameter thus represents a tradeoff between the number of vectors one can acknowledge and the false-positive probability . Since any false-alarm event for any packet over any link will trigger the landsliding cost of breaking the communication chain, we observe in our experiments that any will severely jeopardize the reliability of the CCACK. In our implementation we thus choose , which gives a false-positive probability of that is necessary for the effectiveness of CCACK.</p><p>When a node overhears a packet with an ACK vector from a downstream node, it examines the coding vectors in its by checking the orthogonality to the rotated versions of . More explicitly, a vector (or ) is marked whenever passes all the following different " " (one for each ):</p><p>(4)</p><p>Hence, although the downstream node sent only one ACK vector , the effect is the same as if it sent orthogonal vectors to . We now formally quantify the falsepositive probability (passing all tests simultaneously) with this new coded feedback scheme.</p><p>Proposition 1: Suppose a node would like to acknowledge independent vectors to by constructing an ACK vector according to the proposed feedback construction algorithm. Let denote the linear subspace spanned by to . If we choose a vector uniformly randomly from and apply the orthogonality tests in (4), we then have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>passes all tests passes all tests</head><p>Proof: If is in , then is the linear combination of the selected vectors. Since by construction for all selected , we have . Such will pass all tests.</p><p>To quantify the false-positive probability, we notice that for any chosen vector, a vector can pass all tests if and only if is orthogonal to all column vectors to . If we horizontally concatenate the column vectors to , we can form an matrix. If this matrix is of full column rank , then there are exactly such vectors that can be in the null space of . As a result, the false-positive probability becomes passes all tests, but is not in For the following, we thus only need to show that the matrix is of full column rank . By our construction, has at least nonzero coordinates. Denote the indices of the nonzero coordinates by -, and the corresponding coordinates of by -. Now, we focus on the -rows of the matrix, which is . . . . . . . . .</p><p>The matrix is the product of the diagonal matrix consisting of -and the hash matrix in <ref type="bibr" target="#b1">(2)</ref>. Since all -are nonzero, and by our construction of hash matrices in (2), both matrices are of full rank, hence the above submatrix must be of full rank. Therefore, the matrix is of full column rank. The proof is complete.</p><p>It is worth noting that a naive way of avoiding false-positive events is to increase the underlying finite field size , which is not viable for WMNs. One reason is that to achieve the level of false-positive probability needed in our CCACK scheme , we need , which uses 4 B to represent a single coding symbol. The size of each forward coding vector and each coded feedback vector thus grows from to B, which substantially increases the overhead. An even greater challenge is that each addition and multiplication coding operation now operates on . A table lookup method has to have 4-B entries, which takes prohibitively 64 million TB to store. Even if we use log-exp lookup tables that only require space, the total space is still prohibitively large for (16 GB). Since table lookup is impossible, one thus has to use online polynomial-based computation each time a coding operation needs to be performed, which is beyond today's microprocessor capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Rate Control</head><p>The cumulative coded feedback scheme in CCACK helps nodes to determine when they should stop transmitting packets for a given batch, but it does not tell anything about how fast nodes should transmit before they stop. Unlike in MORE, in CCACK we cannot use receptions from upstream to trigger new transmissions since the goal is exactly to stop the upstream nodes, when the downstream nodes have sufficiently enough packets. In addition, we want to apply rate control to the source as well and not only to the FNs.</p><p>The rate control algorithm in CCACK uses a simple credit scheme, which is oblivious to loss rates, but aware of the existence of other flows in the neighborhood, and leverages CCACK's cumulative coded acknowledgments.</p><p>For each flow at a node, we define the "differential backlog" 8 as (5) 8 Our solution is inspired by the theoretical backpressure based rate control algorithms <ref type="bibr" target="#b20">[21]</ref>. The difference is that, instead of queue lengths, we use innovative coded packets to define a cumulative differential backlog for flow f at every node with respect to all its downstream nodes for that flow.</p><p>where is the set of vectors in marked as , and dim denotes the number of linearly independent packets in the set . Note that . is the difference between the number of innovative packets at a given node and the cumulative number of innovative packets at its downstream FNs for flow . As we saw in Section III-A, when , i.e., , the node stops transmitting packets for flow . Note that for the destination of flow . We also define the relative differential backlog for each flow as <ref type="bibr" target="#b5">(6)</ref> where is the total differential backlog of all the neighbor nodes for all flows, calculated as follows. Every time a node broadcasts a coded data packet, it includes in the packet header its current total differential backlog of all flows crossing that node. All nodes that hear this packet update their as follows: <ref type="bibr" target="#b6">(7)</ref> where is the last advertised by node . A node removes the contribution of its neighbor node to the total by updating if it does not hear a new packet from before a timeout. Every node in CCACK (including the source and the destination) maintains a credit counter for each flow. Every time there is a transmission opportunity for a node A, one flow is selected in a round-robin fashion, among those flows with , and the credit counter of that flow is incremented by . If the counter is positive, the node transmits one coded packet for flow and decrements the counter by one, otherwise it selects the next flow. The credit increment is larger for flows with large "backpressure," thus packets of such flows will be transmitted more frequently. For our implementation, we selected and . If , then and the credit counter will always remain equal to 1, effectively allowing the node to always transmit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Methodology</head><p>We evaluated the performance of CCACK and compared it against MORE using extensive simulations. We used the Glomosim simulator <ref type="bibr" target="#b21">[22]</ref>, a widely used wireless network simulator with a detailed and accurate physical signal propagation model. Glomosim simulations take into account the packet header overhead introduced by each layer of the networking stack and also the additional overhead introduced by MORE or CCACK. For the implementation of MORE, we followed the details in <ref type="bibr" target="#b8">[9]</ref>.</p><p>We simulated a network of 50 static nodes placed randomly in a 1000 1000 m area. The average radio propagation range was 250 m, the average sensing range was 460 m, and the channel capacity was 2 Mb/s. The TwoRay propagation model was used and combined with the Rayleigh fading model to make the simulations realistic. Because of fading, transmission We simulated each protocol in nine different randomly generated topologies, i.e., placement of the 50 nodes. We varied the number of concurrent flows from 1 up to 4. For a given number of flows, we repeated the simulation 10 times for each topology, each time randomly selecting a different set of source-destination pairs, i.e., we had a total of 90 different scenarios for a given number of flows. In each scenario, every source sent a 12-MB file consisting of 1500-B packets.</p><p>Following the methodology in <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b8">[9]</ref>, we implemented an ETX measurement module in Glomosim that was run for 10 min prior to the file transfer for each scenario to compute pairwise delivery probabilities. There was no overhead due to loss rate measurements during the file transfer.</p><p>It is generally known that the full benefit of OR over traditional routing is exposed when the destination is several hops away from the source <ref type="bibr" target="#b8">[9]</ref>. In those cases, OR reduces the overhead of retransmissions incurred by high loss rates and increased self-interference. Hence, for the single-flow experiment, among the 90 flows we simulated, we show the results of the 65 flows for which the destination was not within the transmission range of the source (with ETX shortest paths of 3-9 hops). For the evaluation with multiple flows, we kept scenarios with flows of shorter paths when those flows interfered with other flows. On the other hand, we do not show the results for scenarios where the multiple flows were out of interference range of each other since those scenarios are equivalent to the single-flow case. We were left with 68 scenarios with two flows and 69 scenarios with three and four flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Single Flow</head><p>We begin our evaluation with a single flow. Fig. <ref type="figure" target="#fig_4">5</ref>(a) plots the cumulative distribution function (cdf) of the throughputs of the 65 flows with MORE and CCACK. We observe that CCACK outperforms MORE: The median throughput with CCACK and MORE is 276 and 205 kb/s, respectively.</p><p>To evaluate the performance loss in CCACK due to the facts that in some (rare) occasions CCACK may not solve the collective space problem and that the false-positive probability of CCACK is small but not zero, we implemented a third scheme called OPTACK. OPTACK uses the optimal ACK scheme: When a node hears a packet from a downstream node , we allow node A to directly read from node 's buffer all the basis vectors has received so far. Hence, nodes in OPTACK maintain the exact collective space of the downstream nodes and can compare it to their own space and make the right decision whether to stop or not, without any false negatives or false positives. For a fair comparison to CCACK, we wanted to keep the overhead due to ACK the same for both protocols. Hence, nodes in OPTACK still embed only one 32-B ACK vector in each data packet, which is ignored by the upstream nodes. <ref type="foot" target="#foot_8">9</ref> In OPTACK, nodes update their knowledge of the collective space of their downstream nodes only when they overhear data transmissions. Therefore, the operation of OPTACK is similar to that of CCACK, but is completely free from any collective space problem and any false-positive/negative problem. Fig. <ref type="figure" target="#fig_4">5</ref>(a) shows that OPTACK only slightly outperforms CCACK. The median throughput OPTACK is 292 kb/s, only 6% higher than with CCACK. This result shows that CCACK effectively solves (most of) the collective space and the false-positive problems with low complexity and very little performance loss.</p><p>Fig. <ref type="figure" target="#fig_4">5</ref>(b) plots the cdf of the relative throughput improvement of CCACK over MORE for all 65 flows, defined as %, where and are the throughput of flow with CCACK and MORE, respectively. We observe that CCACK achieves a higher throughput than MORE for 95% of the flows. The median gain of CCACK over MORE is 34%. However, for some challenged flows with the destination several hops away from the source, the throughput with CCACK is much higher than with MORE; the 90th percentile of the gain is 71%.</p><p>Where Does the Gain for CCACK Come From?: Fig. <ref type="figure" target="#fig_5">6</ref>(a) plots the total number of data transmissions with CCACK and MORE in each of the 65 scenarios, as well as the predicted number of transmissions in each scenario using MORE's offline ETX-based credit calculation algorithm. The 65 scenarios are sorted with respect to the predicted number of transmissions.</p><p>We observe that nodes with MORE perform a higher number of transmissions than the predicted number in all 65 scenarios. The actual number is often more than twice the predicted number, and in some scenarios up to 6-7 the predicted number. This shows that the credit calculation algorithm based on offline ETX measurements mispredicts the required number of transmissions even in the absence of background traffic. The cause is self-interference that changes the loss rates, which in most cases become higher than in a quiet network, where only probing traffic exists <ref type="bibr" target="#b17">[18]</ref>. Moreover, the source in MORE keeps transmitting packets until it receives an ACK from the destination. With long paths, this may result in a large number of unnecessary transmissions as the ACK travels toward the source.</p><p>In contrast, the number of data transmissions with CCACK is much lower than with MORE in all but two scenarios. In most scenarios it is close to the predicted number, and in some cases it is even lower. This shows the effectiveness of the coded feedback mechanism in CCACK, combined with the online rate control mechanism of Section III-C. Fig. <ref type="figure" target="#fig_5">6</ref>(b) shows an example (one scenario) of how data transmissions are distributed over the FNs. Nodes are sorted with respect to their ETX distance to the destination, i.e., node 1 is the source and node 10 is the FN closest to the destination. With MORE, the source and the FN closest to the source perform many more transmissions than the remaining FNs, (2.5-7.6 and 1.4-4.6 , respectively). In contrast, CCACK ensures that these nodes stop transmitting when the remaining downstream FNs have received enough innovative packets. Overall, with CCACK, all 10 nodes perform fewer transmissions than with MORE. The savings range from 17% (for node 9) up to 74% (for the source).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multiple Flows</head><p>We now evaluate CCACK and MORE with multiple concurrent flows. Here, in addition to throughput, we compare the two protocols in terms of fairness, using Jain's fairness index (FI) <ref type="bibr" target="#b22">[23]</ref>. Jain's FI is defined as , where is the throughput of flow and is the total number of flows. The value of Jain's FI is between 0 and 1, with values closer to 1 indicating better fairness.</p><p>Throughput Comparison: Fig. <ref type="figure" target="#fig_6">7</ref>(a) and (b) compares throughput with CCACK and MORE with two, three, and four flows. Fig. <ref type="figure" target="#fig_6">7</ref>(a) plots the average per-flow throughput with the two protocols as a function of the number of flows. We observe that CCACK outperforms MORE by 27% on average in the two-flow case, and by 45% on average in the three-flow and four-flow cases. Note that the gain of CCACK is higher with a larger number of flows, when the congestion level becomes higher, causing substantial changes to the link loss rates. By quickly and accurately stopping transmissions for a given flow at nodes whose downstream nodes have collectively received a sufficient number of packets, a large amount of bandwidth is saved, which can be used by the nodes or their neighbors for transmitting packets for other flows. In contrast, the gain of MORE over traditional routing in <ref type="bibr" target="#b8">[9]</ref> drops as the number of concurrent flows increases. Fig. <ref type="figure" target="#fig_6">7</ref>(b) plots the cdf of per-flow relative throughput improvement with CCACK over MORE, as defined in Section IV-B, with two, three, and four flows. CCACK improves per-flow throughputs for more than 85% of the flows in all three cases (with two, three, and four flows). The median improvement is 33%, 55%, and 62%, respectively, with two, three, and four concurrent flows. Similar to the single-flow experiments, some starving flows with MORE show a several-fold improvement with CCACK: The 90th percentiles are 98%, 242%, and 364% in the two-, three-, and four-flow cases, respectively. <ref type="foot" target="#foot_9">10</ref>Fairness Comparison: Fig. <ref type="figure" target="#fig_7">8</ref>(a) and (b) compares fairness with CCACK and MORE in the cases of two, three, and four concurrent flows. Fig. <ref type="figure" target="#fig_7">8</ref>(a) plots the average FI with the two protocols. We observe that the average FI is the same with the two protocols in the two-flow case, but is higher with CCACK in the three-flow and four-flow cases by 5.8% and 8.8%, respectively. Fig. <ref type="figure" target="#fig_7">8</ref>(b) plots the cdf of per-scenario relative FI improvement with CCACK over MORE, defined similarly to the relative throughput improvement in Section IV-B, with two, three, and four flows. We observe that CCACK improves fairness in more scenarios as the number of flows in the network increases-in 40% of the two-flow scenarios, 65% of the three-flow scenarios, and 72% of the four-flow scenarios. Similar to the throughput results, the improvement is very large for some scenarios: up to 74% with three flows, and up to 124% with four flows. This shows again that CCACK improves throughput for some challenged flows, which completely starve with MORE.</p><p>Throughput versus Fairness: We now investigate more closely the relationship between throughput and fairness. Fig. <ref type="figure" target="#fig_8">9</ref>(a) shows the scatterplots of the relative total throughput improvement per scenario versus the relative FI improvement per scenario in the two-, three-, and four-flow experiments.</p><p>We observe that CCACK improves at least one of the two metrics in all but two scenarios [two points in the third quadrant of Fig. <ref type="figure" target="#fig_8">9(a)</ref>]. There are a few points in the second quadrant for all three cases; these are scenarios, where CCACK improves fairness, at the cost of a small total throughput decrease. The majority of the points for the two-flow case are gathered in the first and fourth quadrants, i.e., CCACK either improves throughput at the cost of a (typically) small decrease in fairness, or it improves both metrics. The majority of the points are gathered in the first quadrant for the three-flow and four-flow cases. This shows that as the number of flows increases, CCACK improves both throughput and fairness in most scenarios.</p><p>We now take focus on a few points in the fourth quadrant in Fig. <ref type="figure" target="#fig_8">9</ref>(a), corresponding to scenarios where FI is reduced by more than 20% with CCACK. There are two two-flow, one three-flow, and three four-flow scenarios (points). Note that all six of these points correspond to large throughput improvements, from 72% up to 499%. One may wonder if these improvements are achieved at the cost of compromising the fairness, i.e., throughput of only one flow increases significantly, causing starvation to the remaining flows.</p><p>Fig. <ref type="figure" target="#fig_8">9</ref>(b) shows that this is not the case. This figure plots the individual per-flow throughputs with MORE and CCACK for these six scenarios. We observe that in all but two cases, CCACK improves throughput of all flows involved. The reduction in the FI actually comes from the fact that throughput improvement is much higher for some flows than for some others, and not as a result of starvation of some flows. Take the last scenario [4 flows <ref type="bibr" target="#b2">(3)</ref>] as an example. CCACK improves throughput of the first flow by 11 (from 85 to 978 kb/s), but also improves throughputs of the other three flows by 183%, 108%, and 113%.</p><p>A closer look at the topology of that scenario revealed an interesting situation. We found that the first flow was a 1-hop flow, whose FN belt overlapped with the FN belt of the fourth 9-hop flow, near the source of the fourth flow. With MORE, it took a long time for the destination of the fourth flow to decode each batch. During that time, the source as well as every other FN kept transmitting packets for that batch. Since routers in MORE serve flows in a round-robin fashion, they kept switching between the first and the fourth flow. In other words, a short flow was starved because of a long flow, achieving a throughput of only 85 kb/s, although there was no need for the routers to forward packets of the long flow. In contrast, with CCACK, the coded acknowledgment scheme quickly caused the source of the fourth flow to stop transmitting packets once the remaining FNs had enough packets. Hence, the FNs near the source were able to forward packets only for the 1-hop flow, increasing its throughput to 978 kb/s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. CCACK's Overhead</head><p>Finally, we estimate CCACK's overhead compared to MORE. Similar to <ref type="bibr" target="#b8">[9]</ref>, we discuss three types of overhead: coding, memory, and packet header overhead.</p><p>Coding Overhead: Unavoidably, CCACK's coding overhead is higher than MORE's since routers have to perform additional operations both when transmitting and when receiving a packet. However, all the additional CCACK operations are performed on -byte vectors instead of the whole -byte payload. Therefore, in practical settings (e.g., with and ), the coding overhead of CCACK is expected to be comparable to that of MORE.</p><p>To verify this, we measured the per-packet cost of the various operations performed upon a packet transmission/reception averaged over all packets transmitted/received at all nodes in the 90 simulation scenarios of Section IV-B. Table <ref type="table" target="#tab_0">I</ref> provides the average values and the standard deviations. The costs are given in terms of multiplications, which are the most expensive operations involved in coding/decoding <ref type="bibr" target="#b8">[9]</ref>.</p><p>Construction of an ACK vector in CCACK requires on average 11 584 multiplications. The total coding cost in transmitting a packet (i.e., constructing a coded packet and an ACK vector) in CCACK is only 24% higher than MORE's, assuming the worst-case cost for packet encoding (48 000 multiplications). If we use instead the average packet encoding cost at FNs (27 240 multiplications), the total cost of transmitting a packet in CCACK is only 38 824 multiplications, i.e., lower than MORE's encoding cost at the source. <ref type="foot" target="#foot_10">11</ref>When receiving a packet, the cost of checking for independence (also in MORE) requires on average only 326 multiplications. The additional operations of performing the (if the received packet comes from downstream) and maintaining the rank of the packets in (if a received packet from downstream passes all ) require on average only 428 and 292 multiplications, respectively, i.e., their costs are comparable to the independence check cost. The total cost of packet reception operations in CCACK is only 1.7% of the total packet transmission cost. Hence, the bottleneck operation in CCACK is preparing a packet for transmission at an FN with 32 innovative packets in . In <ref type="bibr" target="#b8">[9]</ref>, the authors found that the bottleneck operation in MORE (packet encoding at the source) takes on average 270 s on a low-end Celeron 800 MHz, limiting the maximum achievable throughput with MORE to 44 Mb/s with a 1500-B packet. In CCACK, the cost of the bottleneck operation is 24% higher, so we can expect a maximum achievable throughput of 35 Mb/s. Note that this value is still higher than the effective bit rate of current 802.11a/g WMNs <ref type="bibr" target="#b23">[24]</ref>.</p><p>Memory Overhead: Same as in MORE, routers in CCACK maintain an innovative packet buffer for each flow, and also to three packets in order to minimize the time from the moment a packet is created at the application layer till the moment the packet is actually transmitted.</p><p>3) Dealing With End-to-End ACKs: In both protocols, a destination sends an end-to-end ACK back to the source every time it decodes a batch. It is critical for the performance of the protocols that these ACKs are propagated to the source in a fast and reliable way since, otherwise, the source cannot move to the next batch. To provide reliability, we unicast the ACKs at the MAC layer, and we implemented an additional ACK-retransmission scheme at the application layer for both protocols. For fast ACK propagation, we prioritize ACKs over data transmissions by leveraging the TOS bits ("TOS field") of the IP header and the priority features in Linux routing <ref type="bibr" target="#b28">[29]</ref>.</p><p>In addition to the two protocols, we also implemented an ETX measurement module, the same as the one we used in our simulations. The source code for the two protocols and the ETX module together is over 7800 lines of C code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental Setup</head><p>In the implementation of the two protocols, we used the same parameters as in our simulation study in Section IV. In all the experiments, the bit rate of the wireless cards was set to 2 Mb/s and the transmission power to 16 dBm. We disabled RTS/CTS for unicast frames as most operational networks do. With these settings, the length of the shortest ETX paths between different nodes is 1-5 hops in length, and the loss rates of the links vary from 0% to 91%, with an average value of 36%.</p><p>We experimented with 20 single-flow scenarios (i.e., randomly selected source-destination pairs), 10 two-flow scenarios, and six three-flow scenarios. For each scenario, we first ran the ETX module to collect the pairwise loss rates and ETX metric for each link of our testbed, and then we ran the two protocols, MORE and CCACK, in sequence. With both protocols, the source sent a 2.3-MB file consisting of 1460-B packets.</p><p>As we have explained in Section IV-A, the gain of CCACK over MORE is more pronounced with flows over long paths, where the destination is several hops away from the source. Unfortunately, the size of our testbed limited our choices in flow selection. Hence, in the single-flow experiments, we also included flows where the destination was 2 hops away from the source. Similarly, the small size of the testbed resulted in a large fraction of the nodes being within sensing range of each other. This prevented us from increasing the total number of flows beyond three since the medium became congested, resulting in very poor performance for both protocols. <ref type="foot" target="#foot_11">12</ref> These two limitations, along with the implementation limitations we discussed in Section V-B1, limited the gains of CCACK over MORE compared to the simulations results in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Results</head><p>Fig. <ref type="figure" target="#fig_10">10</ref>  cdf of per-flow relative throughput improvement with CCACK over MORE, as defined in Section IV-B, with one, two, and three flows. CCACK improves per-flow throughputs for 72% of the flows in the one-flow scenarios, 55% of the flows in the two-flow scenarios, and 75% of the flows in the three-flow scenarios. The median improvement is 18%, 3%, and 28%, respectively, in the one-, two-, and three-flow scenarios. These gains are lower than the ones observed in the simulation results in Section IV due to the limitations we discussed in Section V-C. In spite of these limitations though, our results still demonstrate the benefit of CCACK over MORE in the case of challenged flows. We observe that about 20% of the flows in one-flow and two-flow scenarios, and 17% of the flows in the three-flow scenarios show a several-fold throughput improvement with CCACK, up to 3 , 2.4 , and 3.2 , respectively. Fig. <ref type="figure" target="#fig_10">10(c</ref>) and (d) compares fairness with CCACK and MORE in the cases of two and three concurrent flows. Fig. <ref type="figure" target="#fig_10">10(c</ref>) plots the average FI with the two protocols. We observe that the average FI is higher with CCACK in both the two-flow and three-flow case by 5.7% and 18.9%, respectively. These values are actually higher than the simulation results. Due to the small size of the testbed, the network gets more easily congested, even with two flows, and CCACK's backpressure-inspired credit mechanism is very effective in allocating the medium's bandwidth fairly among contending flows. Fig. <ref type="figure" target="#fig_10">10(d</ref>) plots the cdf of per-scenario relative FI improvement with CCACK over MORE. CCACK improves fairness in 60% of the two-flow scenarios and 65% of the three-flow scenarios, and the gains can be as high as 83% in some challenged scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>The use of random linear NC has significantly simplified the design of opportunistic routing (OR) protocols by removing the need of coordination among forwarding nodes for avoiding duplicate transmissions. However, NC-based OR protocols face a new challenge: How many coded packets should each forwarder transmit?</p><p>In this paper, we presented a novel approach to overcoming this challenge through the design of CCACK, a new efficient NC-based OR protocol. Instead of avoiding feedback exchange, CCACK encodes feedback messages in addition to encoding data packets. A novel Cumulative Coded ACKnowledgment scheme allows nodes in CCACK to acknowledge network coded traffic to their upstream nodes in a simple and efficient way, oblivious to loss rates and with negligible overhead. The cumulative coded acknowledgment scheme in CCACK also enables an efficient credit-based, rate control algorithm. Our experiments on a 22-node 802.11 WMN testbed show that compared to MORE, a state-of-the-art NC-based OR protocol, CCACK improves both throughput and fairness, by up to 3.2 and 83%, respectively, with average improvements of 11%-36% and 5.7%-8.3%, respectively, for a varying number of concurrent flows. Our extensive simulations show that the gains are actually much higher in large networks, with longer routing paths between sources and destinations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Importance of knowing how many coded packets to transmit.</figDesc><graphic coords="2,51.30,67.10,224.00,73.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Different types of feedback for network-coded traffic. (a) Uncoded feedback. (b) Coded feedback.</figDesc><graphic coords="3,42.12,66.18,246.00,81.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Null-space-based (NSB) coded feedback. (a) Basic operation. (b) Collective space problem. (c) False-positive error.</figDesc><graphic coords="4,40.62,66.66,246.00,81.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Solving the collective space problem in CCACK.</figDesc><graphic coords="5,320.82,67.06,214.00,128.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Throughput comparison between CCACK and MORE: single flow. (a) CDF of throughputs achieved with MORE and CCACK. (b) CDF of relative throughput improvement of CCACK over MORE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Total number of data transmissions with MORE and CCACK and predicted number of transmissions based on MORE's credit calculation algorithm, with a single flow. (a) Total number of data transmissions per scenario. (b) Total number of data transmissions per node for one scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Throughput comparison between CCACK and MORE: multiple flows. (a) Average per-flow throughputs (bars) and standard deviations (lines). (b) CDF of relative throughput improvement of CCACK over MORE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Fairness comparison between CCACK and MORE: multiple flows. (a) Average per-scenario FIs (bars) and standard deviations (lines). (b) CDF of relative FI improvement of CCACK over MORE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Investigating the relationship between throughput and fairness. (a) Scatterplot of relative throughput improvement versus relative FI improvement with two, three, and four flows. (b) Per-flow throughputs with MORE and CCACK for the six scenarios with the largest FI decrease under CCACK.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig. 10(a) and (b) compare throughput with CCACK and MORE with one, two, and threeflows. In Fig. 10(a), we observe that CCACK outperforms MORE by 36% on average in the one-flow scenarios, by 11% in the two-flow scenarios, and by 15% on average in the three-flow scenarios. Fig. 6(b) plots the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Testbed evaluation. (a) Average per-flow throughputs (bars) and standard deviations (lines). (b) CDF of relative throughput improvement of CCACK over MORE. (c) Average per-scenario FIs (bars) and standard deviations (lines). (d) CDF of relative FI improvement of CCACK over MORE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I CODING</head><label>I</label><figDesc>OVERHEAD IN CCACK IN TERMS OF GF(2 ) MULTIPLICATIONS. OPERATIONS MARKED WITH (*) ARE COMMON IN MORE AND CCACK</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The ETT metric estimates the quality of a link taking into account both the loss rate (through the ETX metric) and the link bandwidth.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>By "oblivious to link loss rates," we mean here that loss rates are not taken into account in determining how many packets each FN should transmit. We still use MORE's loss-rate-based offline algorithm in CCACK to build the FN belt for a fair comparison between the two protocols. We note though that the coded feedback mechanism in CCACK is orthogonal to the belt construction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>We sometimes refer to the linear space spanned by the received vectors as the knowledge space.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Note that with minor modifications, the performance of the protocol could be slightly improved if nodes also store any innovative packet they potentially receive from downstream nodes. We have incorporated this feature in our implementation, but omit it here to simplify the discussion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p><ref type="bibr" target="#b4">5</ref> In our current implementation, similar to MORE, the source moves to batch i + 1 only when it receives the end-to-end ACK from the destination for batch i. As<ref type="bibr" target="#b14">[15]</ref> showed, a better approach is for the source to move to batch i + 1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>One obvious construction method is to choose all M hash matrices randomly, which turns out to work quite well in our simulation and testbed implementation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>We can convert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>to its row-echelon form in order to speed up the computation when adding a new vector u.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>Apparently, a scheme like OPTACK cannot be implemented in practice; it is feasible only in a simulator.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>Note that the heavy tails of the three-flow and four-flow curves are not shown in Fig. 7(b) for better clarity.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10"><p>Note that the source in CCACK does not have to construct an ACK vector, and hence the cost at the source is the same as in MORE.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11"><p>As explained in<ref type="bibr" target="#b8">[9]</ref>, intraflow NC-based protocols cannot increase the capacity of the network, and they can only improve throughput as long as the total load remains below the network capacity.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments Dimitrios Koutsonikolas, Member, IEEE, ACM, Chih-Chun Wang, Member, IEEE, and Y. Charlie Hu, Senior Member, IEEE, ACM</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science Foundation (NSF) under Grants CCF-0845968 and CNS 0905331.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>a 64-kB lookup table for reducing the cost of the multiplications <ref type="bibr" target="#b8">[9]</ref>. With a packet size of 1500 B, the size of is 48 kB. The extra overhead in CCACK comes from the two additional buffers and , which store, however, only 32-B vectors and not whole packets. In our implementation, the total size of and is kB, which is relatively small compared to the size of MORE's structures.</p><p>Header Overhead: The N-byte ACK vector and the total differential backlog are the two fields we add to the MORE header. The differential backlog per flow is bounded by the batch size . With , 2 B are enough to support up to 2048 flows, and the total size of the two fields is equal to 34 B. However, in CCACK, we do not include in the packet header the transmission credits for the FNs, which are required in MORE. This can potentially make CCACK's header smaller than MORE's depending on the number of FNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. IMPLEMENTATION AND TESTBED EVALUATION</head><p>In this section, we describe an implementation of CCACK on a WMN testbed and present experimental results comparing CCACK and MORE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Testbed Description</head><p>Our testbed, Mesh@Purdue (MAP) <ref type="bibr" target="#b24">[25]</ref>, currently consists of 22 mesh routers (small form factor desktops) deployed on two floors of two academic buildings at Purdue University. Each router has an Atheros 5212-based 802.11a/b/g wireless radio operating in 802.11b ad hoc mode and attached to a 2-dBi rubber duck omnidirectional antenna. The mesh routers run Mandrake Linux 10.1 (kernel 2.6. <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>, and the open-source madwifi driver <ref type="bibr" target="#b25">[26]</ref> is used to enable the wireless cards. IP addresses are statically assigned. The testbed deployment environment is not wireless-friendly, having floor-to-ceiling office walls, as well as laboratories with structures that limit the propagation of wireless signals and create multipath fading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>NC-based wireless protocols (e.g., <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b26">[27]</ref>) are typically implemented as a shim between the IP and the MAC layer, i.e., at layer 2.5. Here, for ease of debugging, deployment, and evaluation, we implemented CCACK at the application layer, using broadcast sockets. For a fair comparison, we also implemented MORE at the application layer, following all the details in <ref type="bibr" target="#b8">[9]</ref>. We note that such an implementation unavoidably results in some performance degradation for both protocols, compared to an implementation closer to the MAC layer, from crossing the kernel-user boundary. Actually, the degradation is larger for CCACK, as we explain later in this section.</p><p>Our implementation handles only synthetic traffic, i.e., data packets are generated within the MORE or CCACK application, similarly to the implementation in <ref type="bibr" target="#b27">[28]</ref>, in which packets are generated within Click. The layer-2.5 header of MORE or CCACK is part of the application-layer packet payload. The source initially generates random payloads for the current batch and mixes them every time it wants to transmit a packet. It then appends the MORE or CCACK header and delivers the resulting packet to the IP layer, which in turn delivers the packet to the MAC for transmission. Packets are broadcast at the MAC layer, and every neighbor node can hear them. When a node receives a packet, it extracts and processes the protocol-specific header from the payload. If the node is an FN (i.e., it finds its ID in the FN list in the header), it also uses the coding vector (also included in the header) to check for linear independence. If the received packet is innovative, the rest of the payload is stored for future mixing (if the node is an FN) or for decoding (if the node is a receiver).</p><p>1) Removing the Dependence on the MAC Layer: In an ideal implementation at layer 2.5, a node running either MORE or CCACK transmits a packet when: 1) the 802.11 MAC allows and 2) the credit counter is positive. In our application-layer implementation, we cannot get any feedback from the MAC, and hence, we had to modify the transmission policy for the two protocols.</p><p>In our implementation of MORE, the application instead delivers packets to the IP when only the second condition holds and there is enough space in the socket buffer. From the IP layer, the packets are delivered to the wireless driver stored at the card's queue for transmission at a later time. Similar to a layer-2.5 implementation, the credit counter is incremented every time a packet is received from an upstream node, and decremented after every transmission.</p><p>Unlike in MORE, the credit counter in CCACK is incremented every time the MAC layer signals a transmission opportunity. Since the application cannot know when there is a transmission opportunity without access to the MAC layer, we approximate the number of transmission opportunities via the following heuristic. A node increments its credit counter every time it hears a data packet transmission from another node by a fraction of of the actual increment determined by the rate control algorithm, where is the number of nodes in the node's neighborhood. The intuition behind this is that with a fair MAC layer, every node in a neighborhood would roughly get an equal number of transmission opportunities. To avoid possible deadlock situations, where every node in a neighborhood is waiting for another node to transmit, we also use a timeout equal to one data packet transmission time, after which a node always increments its credit counter.</p><p>2) Dealing With Queue Sizes: With a layer-2.5 implementation <ref type="bibr" target="#b8">[9]</ref> of an NC-based protocol, a precoded packet is always available awaiting for transmission. If another innovative packet is received before the precoded packet is transmitted, the precoded packet is updated by multiplying the newly received packet with a random number and adding it to the precoded packet. This approach ensures that every transmitted packet includes information from all the received innovative packets, including the most recent ones.</p><p>In contrast, in our implementation, we have no control over a packet once it leaves the application layer, and we cannot update the coded packets buffered at the socket buffer or awaiting for transmission at the card's queue if a new innovative packet is received. This inefficiency can have a significant impact on the performance of the two protocols. If a packet is queued either at the IP or at the MAC layer for a long time, it may not contain information from all the received packets so far. Even worse, the downstream nodes may have already received enough packets from the current batch, in which case the enqueued packets should not be transmitted at all. To avoid this problem, we limit the socket buffer size to one packet and the card's queue length </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">MIT roofnet</title>
		<ptr target="http://www.pdos.lcs.mit.edu/roofnet" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Bay area wireless users group</title>
		<ptr target="http://www.bawug.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Seattle wireless</title>
		<ptr target="http://www.seattlewireless.net" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Link-level measurements from an 802.11b mesh network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Aguayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bicket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Judd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIG-COMM</title>
		<meeting>ACM SIG-COMM</meeting>
		<imprint>
			<date type="published" when="2004-08">Aug. 2004</date>
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Dynamic Source Routing in Ad Hoc Wireless Networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Maltz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ad hoc on-demand distance vector routing</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Perkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Royer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE WMCSA</title>
		<meeting>IEEE WMCSA</meeting>
		<imprint>
			<date type="published" when="1999-02">Feb. 1999</date>
			<biblScope unit="page" from="90" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Architecture and evaluation of an unplanned 802.11b mesh network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bicket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aguayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Mo-biCom</title>
		<meeting>ACM Mo-biCom</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="31" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ExOR: Opportunistic multi-hop routing for wireless networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="133" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Trading structure for randomness in wireless opportunistic routing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chachulski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIG-COMM</title>
		<meeting>ACM SIG-COMM</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="169" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multipath code casting for wireless mesh networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gkantsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Key</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Radunovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gheorghiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CoNEXT</title>
		<meeting>ACM CoNEXT</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An optimization framework for opportunistic multipath routing in wireless mesh networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Radunovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gkantsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Key</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="2252" to="2260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A highthroughput path metric for multi-hop wireless routing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S J D</forename><surname>Couto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aguayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bicket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM MobiCom</title>
		<meeting>ACM MobiCom</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="134" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimized multipath network coding in lossy wireless networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICDCS</title>
		<meeting>IEEE ICDCS</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dice: A game theoretic framework for wireless multipath network coding</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM MobiHoc</title>
		<meeting>ACM MobiHoc</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="293" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CodeOR: Opportunistic routing in wireless mesh networks with segmented network coding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICNP</title>
		<meeting>IEEE ICNP</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="13" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A measurement study of multiplicative overhead effects in wireless networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Camp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mancuso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gurewitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Knightly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM</title>
		<meeting>IEEE INFOCOM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="76" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Studying wireless routing link dynamics</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pucha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Papagiannaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM/USENIX IMC</title>
		<meeting>ACM SIGCOMM/USENIX IMC</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="327" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Effects of interference on throughput of wireless mesh networks: Pathologies and a preliminary solution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rozner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>presented at the Hot-Nets-VI</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Routing in multi-radio, multi-hop wireless mesh networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Draves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM MobiCom</title>
		<meeting>ACM MobiCom</meeting>
		<imprint>
			<date type="published" when="2004-09">Sep. 2004</date>
			<biblScope unit="page" from="114" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Codecast: A network-coding-based ad hoc multicast protocol</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gerla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Medard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wireless Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="76" to="81" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stability properties of constrained queueing systems and scheduling for maximum throughput in multihop radio networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tassioulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ephremides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1936" to="1948" />
			<date type="published" when="1992-12">Dec. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glomosim: A library for parallel simulation of large-scale wireless networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bagrodia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gerla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PADS Workshop</title>
		<meeting>PADS Workshop</meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A quantitative measure of fairness and discrimination for resource allocation in shared computer systems Digital Equipment Corporation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-M</forename><forename type="middle">W</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Hawe</surname></persName>
		</author>
		<idno>DEC-TR-301</idno>
		<imprint>
			<date type="published" when="1984-09">Sep. 1984</date>
			<pubPlace>Hudson, MA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Net throughput with IEEE 802.11 wireless LANs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kamerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE WCNC</title>
		<meeting>IEEE WCNC</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="747" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Purdue Univ</title>
		<author>
			<persName><forename type="first">@</forename><surname>Mesh</surname></persName>
		</author>
		<author>
			<persName><surname>Purdue</surname></persName>
		</author>
		<ptr target="http://www.engineering.purdue.edu/mesh" />
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>West Lafayette, IN</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">MadWifi.net</title>
		<ptr target="http://madwifi.org" />
	</analytic>
	<monogr>
		<title level="m">Linux-Consulting</title>
		<meeting><address><addrLine>Reno, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">XORs in the air: Practical wireless network coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Katti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Medard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crowcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2006-08">Aug. 2006</date>
			<biblScope unit="page" from="243" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">MORE source code</title>
		<ptr target="http://people.csail.mit.edu/szym/more" />
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Linux advanced routing and traffic control</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Mook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Oosterhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Spaans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Larroy</surname></persName>
		</author>
		<ptr target="http://lartc.org//lartc.html/" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
