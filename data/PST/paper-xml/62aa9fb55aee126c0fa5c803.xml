<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking</title>
				<funder>
					<orgName type="full">Funai Overseas Scholarship</orgName>
				</funder>
				<funder ref="#_uHhRZF6 #_X3N3Zpg">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-06-15">15 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuta</forename><surname>Saito</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-15">15 Jun 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539353</idno>
					<idno type="arXiv">arXiv:2206.07247v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS</term>
					<term>Information systems ? Probabilistic retrieval models</term>
					<term>Social recommendation</term>
					<term>? Computing methodologies ? Ranking Fairness in Ranking, Fair Division, Nash Social Welfare</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rankings have become the primary interface in two-sided online markets. Many have noted that the rankings not only affect the satisfaction of the users (e.g., customers, listeners, employers, travelers), but that the position in the ranking allocates exposure -and thus economic opportunity -to the ranked items (e.g., articles, products, songs, job seekers, restaurants, hotels). This has raised questions of fairness to the items, and most existing works have addressed fairness by explicitly linking item exposure to item relevance. However, we argue that any particular choice of such a link function may be difficult to defend, and we show that the resulting rankings can still be unfair. To avoid these shortcomings, we develop a new axiomatic approach that is rooted in principles of fair division. This not only avoids the need to choose a link function, but also more meaningfully quantifies the impact on the items beyond exposure. Our axioms of envy-freeness and dominance over uniform ranking postulate that for a fair ranking policy every item should prefer their own rank allocation over that of any other item, and that no item should be actively disadvantaged by the rankings. To compute ranking policies that are fair according to these axioms, we propose a new ranking objective related to the Nash Social Welfare. We show that the solution has guarantees regarding its envy-freeness, its dominance over uniform rankings for every item, and its Pareto optimality. In contrast, we show that conventional exposure-based fairness can produce large amounts of envy and have a highly disparate impact on the items. Beyond these theoretical results, we illustrate empirically how our framework controls the trade-off between impact-based individual item fairness and user utility.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Ranking interfaces are widely used to mediate online market platforms, ranging from booking a hotel to finding qualified employees. In these two-sided markets, not only the users (e.g., travelers and employers) obtain utility from the rankings, but the ranking policy also has a crucial impact on the items being ranked (e.g., hotels and job seekers). Many have noted that conventional ranking approaches <ref type="bibr" target="#b25">[26]</ref>, which exclusively optimize the utility to the users, may be unfair to the items. In particular, conventional rankings can give items with similar merit (i.e., relevance) very dissimilar exposure and thus economic opportunity <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>To address this disparity of treatment, existing works on fairnessin-ranking explore how to explicitly link merit to the exposure that is allocated to individual items or groups of items <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>. Concrete definitions of exposure-based fairness were introduced in the seminal works by Singh and Joachims <ref type="bibr" target="#b26">[27]</ref> and Biega et al. <ref type="bibr" target="#b2">[3]</ref>, enforcing constraints to allocate exposure proportional to relevance in expectation over groups or amortized over a sequence of rankings. This fairness-of-exposure approach has since been extended to end-to-end policy learning <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>, dynamic ranking <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b34">35]</ref>, evaluation metrics <ref type="bibr" target="#b13">[14]</ref>, and contextual bandits <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b31">32]</ref>. However, a key criticism of exposure-based fairness is the necessity to select a function that links merit and exposure, and there is typically no justification that this relationship should be linear -nor would any other choice be more defendable. Furthermore, we show that the fairness-of-exposure approach can still lead to rankings that violate basic fairness principles.</p><p>To overcome these shortcomings, we develop an axiomatic approach to fairness in ranking that is rooted in principles of fair division. In particular, we provide a novel formulation of fairness in ranking as a resource allocation problem, where the resources are the positions in a ranking that need to be fairly divided among the items. To concisely define fairness, we propose envy-freeness and dominance over uniform ranking as two fairness axioms that parallel widely accepted concepts from the fair-division literature <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31]</ref>. Envy-freeness requires that no item can gain better impact by exchanging its position allocation with another item in a market. Dominance over uniform ranking requires that every item should gain better impact than under the uniform random ranking policy, ensuring that all items draw some benefit from participating in the platform. This axiomatization not only avoids the need for an arbitrary link function between relevance and exposure, it also directly captures the impact (e.g. clicks, conversions, revenue, streams) of the ranking on the items, not just their visibility as in the exposurebased framework. Prior attempts to extend fairness-of-exposure to individual fairness of impact have already been shown to lead to degenerate ranking policies <ref type="bibr" target="#b26">[27]</ref>, making ours the first viable formulation of impact-based individual item fairness.</p><p>The key remaining problem is to find an algorithm for computing rankings that are guaranteed to fulfill the fairness axioms, and that also guarantee a notion of optimality. To this effect, we introduce a new objective for optimizing rankings that is related to the Nash Social Welfare (NSW). Under our formulation, maximizing the NSW is a convex program that is efficiently solvable. We prove that the ranking policy that maximizes the NSW-objective has guarantees regarding the envy-freeness of the position allocations and its dominance over the uniform ranking policy for each item. Furthermore, the rankings are Pareto optimal. We also develop an extension of the NSW called the ?-NSW, which enables a steerable trade-off between user utility and item fairness through a single hyper-parameter. Beyond these conceptual and methodological contributions, we conduct extensive experiments on synthetic and real-world data. We find that conventional exposure-based fairness can produce large amounts of envy and disparate impact on the items. In contrast, the proposed NSW-maximizing policy achieves an almost envy-free impact distribution even with noisy relevance predictions, and provides more equitable benefit to all items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Fair Ranking in Two-Sided Markets. There exist several notions of fairness in ranking, ranging from the ones based on the composition of a prefix of the ranking <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b33">34]</ref> to the exposure-based item fairness. The latter argues that fairness in ranking corresponds to how ranking policies allocate exposure to individual items or groups of items based on their merit <ref type="bibr">[23, 27-29, 33, 35, 36]</ref>. Within the exposure-based framework, Singh and Joachims <ref type="bibr" target="#b26">[27]</ref> introduce a post-processing algorithm to allocate exposure for protected item groups proportional to their merit. Following Singh and Joachims <ref type="bibr" target="#b26">[27]</ref>, other fairness-of-exposure methods have been proposed such as end-to-end policy learning <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b32">33]</ref> and dynamic ranking algorithms <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b34">35]</ref>. Instead of guaranteeing group fairness, there is also a line of work aiming at achieving a fair allocation of exposure among individual items <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7]</ref>. Biega et al. <ref type="bibr" target="#b2">[3]</ref> solve an integer program and optimize amortized share of exposure over time among each item. Bower et al. <ref type="bibr" target="#b6">[7]</ref> propose an optimal-transport-based regularizer to enforce individual item fairness.</p><p>Although the exposure-based formulation is widely accepted for both group and individual item fairness, there is no obvious choice for how exposure should be linked to merit. Most studies require exposure to be proportional to merit -but why not proportional to merit squared or some other function? Indeed, no principled justification has been given for any choice of the link function. Our axiomatic approach overcomes this shortcoming, since it does not rely on an arbitrary link function between exposure and merit, but is solely based on the impact of the ranking on the items. Moreover, we show that the existing exposure-based framework can create a substantially disparate impact among individual items. While a disparate impact constraint has been proposed to ensure group item fairness <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27]</ref>, imposing such constraints per item for individual fairness leads to the uniform random ranking policy <ref type="bibr" target="#b26">[27]</ref>. We are the first to formulate and enforce impact-based individual item fairness in a meaningful way.</p><p>Fair Division. Fair division has been studied extensively in algorithmic game theory <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31]</ref>. The goal of this line of work is to allocate a set of valuable -but limited -resources or goods to the agents in a fair manner. The classical fairness desiderata considered in this field are envy-freeness (EF) and proportional fair share (PFS) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref>. EF requires that no agents prefer another agent's allocation of goods to their own. PFS means that every agent receives 1/? of their utility over the entire set of goods, where ? is the number of agents. When the goods are divisible, maximizing the Nash Social Welfare, the product of agent utilities, has been considered compelling, because its solution ensures EF and PFS as well as being Pareto optimal. In contrast, recent studies focus on a more challenging problem of fairly allocating indivisible goods (e.g., course seats in universities <ref type="bibr" target="#b8">[9]</ref> or computational resources in a cloud computing environment <ref type="bibr" target="#b5">[6]</ref>). When the goods are indivisible, no feasible allocation may satisfy EF or PFS <ref type="bibr" target="#b9">[10]</ref>. Therefore, relaxed versions of these axioms have been considered such as envy-freeness up to one good (EF1) and maximin share guarantee (MMS) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b24">25]</ref>. For example, EF1 requires that any pairwise envy can be eliminated by removing a single good from the envied agent's allocation. An allocation satisfying EF1 always exists for a broad class of utility functions even in the case of indivisible goods <ref type="bibr" target="#b9">[10]</ref>.</p><p>The notion of EF has been adopted to fair machine learning in binary classification <ref type="bibr" target="#b1">[2]</ref>. This is because EF is intuitive and requires no information beyond individuals' utility functions, which contrasts with other notions of fairness such as metric-based individual fairness <ref type="bibr" target="#b15">[16]</ref>. Beyond binary classification, a few works have applied the axioms in fair division to recommender system applications. Patro et al. <ref type="bibr" target="#b24">[25]</ref> map the fair recommendation problem in two-sided markets to the problem of fairly allocating indivisible goods, where the goods are the set of products. The goal of Patro et al. <ref type="bibr" target="#b24">[25]</ref> is then to ensure EF1 among users in terms of their utility and MMS (a relaxed version of PFS) among items in terms of their exposure allocation. Do et al. <ref type="bibr" target="#b14">[15]</ref> consider the problem of auditing the unfair behavior of recommender systems with respect to EF among users. Although these studies formulating versions of EF in the context of recommender systems are related, our contributions are unique in several ways. First, we focus on achieving fairness of impact among individual items. In contrast, Patro et al. <ref type="bibr" target="#b24">[25]</ref> consider the item fairness in terms of exposure and Do et al. <ref type="bibr" target="#b14">[15]</ref> consider only the user-side fairness. In the following sections, we argue that the exposure-based fairness can produce a substantial amount of envy and a highly disparate impact. We are the first to formulate and achieve impact-based fairness rather than fairness-of-exposure in the context of individual fairness in ranking. Second, we build on the exact notions of EF and PFS, while Patro et al. <ref type="bibr" target="#b24">[25]</ref> relax these fairness criteria and rely on EF1 and MMS. We can formulate fairness in rankings as the problem of fairly allocating divisible goods by considering a class of stochastic ranking policies. Stochastic ranking policies have been adapted in the fair ranking literature <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>, and we rely on this stochastic formulation aiming for more desirable fairness criteria than those of previous studies. Finally, our formulation is aware of the position bias in a ranking. Related studies <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b24">25]</ref> do not take into account position bias, which is an inevitable factor in dealing with real-world ranking interfaces <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b29">30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">AN AXIOMATIC APPROACH TO INDIVIDUAL FAIRNESS IN RANKING</head><p>We consider the following class of ranking problems, where a twosided market platform has responsibilities to both users and items.</p><p>? On a news platform, each reader (user) receives a ranking of news stories (items) as a digest of the previous day. ? On a hiring platform, each employer (user) receives a weekly ranking of the most relevant job candidates (items) that were added to the database. ? For a scientific conference, each reviewer (user) receives a ranking of the most relevant submissions (items) during the bidding process.</p><p>All problems have in common that the platform not only aims to maximize the utility of the rankings to the users, but that it also needs to be fair to the items. Specifically, the news providers would like a fair share of the traffic for their items, the job candidates deserve to get an adequate number of connections to relevant employers, and every paper should be given an appropriate chance of finding knowledgeable reviewers. All these problems are instances of batch-ranking problems, where U = [?] is a set of users, and a ranking policy ? aims to optimally order a set of items I = [?] for each user ? ? U. We assume the full-information setting, where we have access to the true relevance labels (or their predictions) ? (?, ?) ? R + for all user-item pairs. A ranking ? is a permutation of the set of items sampled from a ranking policy ? (?|?), which is a distribution over all possible rankings of the items. We consider the general case of stochastic ranking policies, which includes deterministic ranking policies as a special case. Stochastic ranking policies have been utilized in fair ranking research to have fine-grained control over the expected exposure allocation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Utility to Users</head><p>Like in conventional ranking frameworks, we measure the utility that a policy ? provides to the users through a utility function of the following form.</p><formula xml:id="formula_0">? (?) := ?? ? ?U E ??? ( ? |?) ?? ? ?I ? (? (?)) ? ? (?, ?)<label>(1)</label></formula><p>? (?) is the rank of item ? in ranking ?, and ? (?) casts the rank to the exposure probability according to the position-based model (PBM) <ref type="bibr" target="#b12">[13]</ref>. This definition of utility captures widely-used additive ranking metrics through the choice of ? (?). For example, when we define ? (?) := I{? ?? } log 2 (?+1) , the utility becomes DCG@K <ref type="bibr" target="#b18">[19]</ref>. It is also possible to learn an application-specific ? (?) from the data <ref type="bibr" target="#b20">[21]</ref>. We refer to a ranking policy that maximizes the utility to the users as a utility-maximizing policy, which is defined as ? max := arg max ? ?? ? (?).</p><p>To avoid optimizing over the exponentially large space of rankings, we utilize the fact that only the exposure probability ? (?) depends on the rank. This allows us to more concisely express the user utility as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? (?)</head><formula xml:id="formula_1">:= ?? ? ?U ?? ? ?I ? ?? ?=1 ? (?)? (?, ?)? ? ?,?,?<label>(2)</label></formula><p>where ? ? is the tensor whose (?, ?, ?) element ? ? ?,?,? := P(? (?) = ? |?, ?) denotes the marginal probability of item ? being ranked at the ?-th position for user ? under policy ?,<ref type="foot" target="#foot_0">1</ref> and ? ? ?, * , * should be the doubly stochastic matrix<ref type="foot" target="#foot_1">2</ref> . The benefit of using this representation is to reduce the number of parameters needed to specify the effect of policy ?. Specifically, for user ?, we use only |I| 2 parameters rather than the exponential number of possible rankings, as all stochastic ranking policies with the same matrix have the same user utility. This will allow us to optimize in the space of doubly stochastic matrices. Given a doubly stochastic matrix, the Birkhoffvon Neumann (BvN) decomposition can be used to efficiently find a stochastic ranking policy that corresponds to the matrix <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Impact on Items</head><p>While sorting the items by their probability of relevance maximizes the utility to the users <ref type="bibr" target="#b25">[26]</ref>, many existing works have noted that this naive treatment can lead to rankings that are unfair to the items <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>. In particular, Biega et al. <ref type="bibr" target="#b2">[3]</ref> measure similarity between individual items by their amortized merit, and propose a notion of fairness requiring that amortized exposure should be distributed proportional to their amortized merit. This definition of fairness aims at allocating exposure similarly between items with similar merit. However, as we have already argued, this formulation lacks a clear justification for why exposure should be linked proportional to relevance -or linked via any other specific function. Furthermore, the items only indirectly care about exposure, and they more directly care about the impact the ranking has on them. For example, a ranking policy that predominantly shows men for high-paying jobs and shows women for low-paying jobs can perfectly obey fairness of exposure, but it clearly violates fairness of impact.</p><p>We therefore focus on fairness of impact in this work, where impact quantifies the effect that a ranking policy has on a specific item ?. To define impact, we build on an item-centric version of the matrix ? ? * ,?, * whose (?, ?) element is: ? ? ?,?,? = P(? (?) = ? |?, ?). This matrix characterizes the allocation of positions, i.e., how big a fraction of the ?-th position in a ranking for user ? goes to item ?. With this notation, we define the impact on each item as</p><formula xml:id="formula_2">Imp ? (? ? * ,?, * ) := ?? ? ?U ? ?? ?=1 ? ? (?, ?)? ? ?,?,?</formula><p>? ? (?, ?) is an application-dependent impact function, which defines how much impact (e.g., expected clicks, bookings, revenue) item ? receives when it is ranked at the ?-th position for user ?. For ease of exposition, we will use the number of relevant users who see each item under the PBM as the impact function, i.e., ? ? (?, ?) := ? (?)? (?, ?).</p><p>Note that even with this specialization, impact remains more meaningful than fairness of exposure, which does not differentiate between exposure to relevant and non-relevant users. Note that the </p><formula xml:id="formula_3">Merit ? 1.3 0.7 (b) Max: ? (? max ) = 1.30 ? 1 ? 2 Exp ? (? ? max |? 1 ) 1.0 0.0 Exp ? (? ? max |? 2 ) 1.0 0.0 Exp ? (? ? max ) 2.0 0.0 Imp ? (? ? max * ,?, * ) 1.3 0.0 (c) Fair: ? (? expo-fair ) = 1.23 ? 1 ? 2 Exp ? (? ? expo-fair |? 1 ) 1.0 0.0 Exp ? (? ? expo-fair |? 2 ) 0.3 0.7 Exp ? (? ? expo-fair ) 1.3 0.7</formula><p>Imp ? (? ? expo-fair * ,?, * ) 0.95 0.28</p><formula xml:id="formula_4">(d) Uniform: ? (? unif ) = 1.00 ? 1 ? 2 Exp ? (? ? unif |? 1 ) 0.5 0.5 Exp ? (? ? unif |? 2 ) 0.5 0.5 Exp ? (? ? unif ) 1.0 1.0 Imp ? (? ? unif * ,?, * ) 0.65 0.35</formula><p>user utility is equal to the sum of impacts under the specialization</p><formula xml:id="formula_5">? (?) = ?? ? ?I Imp ? (? ? * ,?, * ),</formula><p>making both equally measurable and comparable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fairness Axioms</head><p>We are now in a position to state axioms that ensure individual fairness with respect to the impact on each item as quantified by Imp ? (? ? * ,?, * ). Making connections to well-established principles of fair division <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b30">31]</ref>, we treat the rank positions as the limited resource to allocate, and impact Imp ? (? ? * ,?, * ) as the natural valuation of the items for each resource allocation. We start with the axiom of envy-freeness. Definition 3.1. (Envy-Freeness) A ranking policy ? is said to be envy-free if no item prefers another item's position allocation of ?, i.e., Imp ? (? ? * ,?, * ) ? Imp ? (? ? * ,?, * ), ??, ? ? I.</p><p>An envy-free ranking policy ensures that no item would prefer the positions allocated to another item over their own allocation. If an allocation is envy-free, no item will want to switch allocations with another item.</p><p>The second axiom is dominance over uniform ranking, which requires that a fair ranking policy does not provide worse impact Imp ? (? ? * ,?, * ) to any item than ? unif , which samples every possible permutation uniformly at random (uniform ranking policy). Definition 3.2. (Dominance over Uniform Ranking) A ranking policy ? is said to dominate the uniform random policy ? unif if ? provides better or equal impact on every item compared to ? unif , i.e, Imp ? (? ? * ,?, * ) ? Imp ? (? ? unif * ,?, * ), ?? ? I. Moreover, at least one item should gain impact strictly better than that under ? unif .</p><p>We regard ? unif as a baseline policy, because it provides an impact distribution that one can achieve without implementing any optimization or policy learning procedure. If a policy makes some items worse off than under ? unif , it inflicts active harm on those items and they are likely to abandon the platform.</p><p>In addition to the aforementioned fairness desiderata, we also want the ranking policy to be optimal in the following sense. Definition 3.3. (Pareto Optimality) A ranking policy ? is said to be Pareto optimal if no alternative policy can make some items strictly better off without making any others strictly worse off.</p><p>Pareto optimality ensures that the user utility, and equivalently the sum of item impacts, cannot easily be improved. This codifies that the policy should not needlessly sacrifice utility to the users or aggregate impact to the items, and that there is no obviously avoidable harm to any of the items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fairness of Exposure Violates Axioms</head><p>To motivate the need for new algorithms to achieve fairness of impact, we now show in detail that the conventional fairness-ofexposure framework can cause envy among the items and create an unfair impact distribution in light of our axioms. Exposurebased fairness imposes a constraint to allocate exposure proportional to the amortized merit <ref type="bibr" target="#b2">[3]</ref>. Here, we describe a more general constraint <ref type="bibr" target="#b31">[32]</ref>, where merit is quantified through an applicationdependent link function ? (?) &gt; 0,</p><formula xml:id="formula_6">Exp ? (? ? ) ? (Merit ? ) = Exp ? (? ? ) ? (Merit ? ) , ??, ? ? I,<label>(3)</label></formula><p>where Merit ? := ? ?U ? (?, ?) is the amortized merit, i.e., the relevance of item ? amortized over all users. In contrast, Exp ? (? ? ) := ? Exp ? (? ? |?) = ? ? ? (?)? ? ?,?,? is the total amount of exposure allocated to item ? under policy ?, i.e., the amortized exposure. The link function ? (?) maps the amortized merit to a positive merit value. A typical choice is ? (?) = ?, which leads to a linear program to optimize the rankings <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>Algorithms for computing exposure-based fair rankings find a doubly stochastic matrix that maximizes the utility to the users (or equivalently the sum of impacts), subject to Eq. (3) as follows.</p><formula xml:id="formula_7">? expo-fair = arg max {? ? * ,?, * } ??I ?? ? ?U ?? ? ?I ? ?? ?=1 ? (?)? (?, ?)? ? ?,?,? = ?? ? ?I Imp ? (? ? * ,?, * ) , s.t. Exp ? (? ? ) ? (Merit ? ) = Exp ? (? ? ) ? (Merit ? ) , ??, ? ? I, ? ?? ?=1 ? ? ?,?,? = 1, ?(?, ?) ?? ? ?I ? ? ?,?,? = 1, ?(?, ?) 0 ? ? ? ?,?,? ? 1, ?(?, ?, ?)</formula><p>We use ? expo-fair to denote a policy that solves the above optimization and call it the exposure-based fair ranking policy.</p><p>While widely used as the desideratum for fair ranking <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, the following provides a counterexample which illustrates that a fair allocation of exposure cannot avoid a disparate impact among individual items. Our counterexample consists of two users (U = {? 1 , ? 2 }) and two items (I = {? 1 , ? 2 }).</p><p>We know the true relevance labels of every user-item pair, which is given in Table <ref type="table" target="#tab_0">1a</ref>. For simplicity, we also assume that only the top-ranked item is exposed to the users (? (1) = 1, ? (2) = 0). We consider three ranking policies, (i) the utility-maximizing policy ? max , (ii) the exposure-based fair ranking policy ? expo-fair , and, (iii) the uniform random policy ? unif .</p><p>Tables 1b to 1d provide the exposure allocation of the three policies and how much impact each item receives. ? max allocates all exposure on the item having highest relevance (? 1 ). As a result, it achieves the highest user utility (? (? max ) = 1.3) while leading to the unfair situation where ? 2 obtains no exposure despite its substantial relevance.</p><p>? expo-fair deals with this unfair allocation by imposing the exposure constraint. Specifically, it allocates some amount of exposure to the less relevant item (? 2 ) and ensures that the exposure is allocated proportional to merit as shown in Table <ref type="table" target="#tab_0">1c</ref>. However, our example indicates that ? expo-fair violates impact-based fairness. First, ? expo-fair is not envy-free. Indeed, ? 2 envies the allocation of ? 1 , because impact on ? 2 can be improved by swapping its allocation with that of ? 1 . 3 Second, ? expo-fair does not dominate ? unif for all items. It is easy to see that impact on ? 2 under ? expo-fair (0.28) is smaller than under ? unif (0.35). This implies that ? expo-fair improves impact on ? 1 at the cost of impact on ? 2 , creating a substantial disparity.</p><p>Our counterexample indicates that exposure-based fairness allows a policy to produce envy and an unfair distribution of impact. The following theorem more formally illustrates the possible disparate impact of the existing exposure-based framework. for any ? (?) such that the exposure-fair constraint in Eq. (3) is feasible.</p><p>Theorem 3.4 indicates that exposure-based fair rankings can produce large amounts of envy for some items. It can also actively harm some items beyond a reasonable baseline. Singh and Joachims <ref type="bibr" target="#b26">[27]</ref> describe the disparate impact constraint aiming at allocating impact proportional to merit in the context of group fairness. However, this constraint merely leads to the uniform ranking in the case of individual fairness <ref type="bibr" target="#b26">[27]</ref>. The disparate impact caused by the exposure-based framework and the inapplicability of the disparate impact constraint validate that our framework of impactbased individual fairness is fundamentally new and different from conventional exposure-based fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">COMPUTING RANKINGS WITH FAIRNESS OF IMPACT GUARANTEES</head><p>While the previous section introduced the axiomatization of fairnessof-impact for ranking and showed that the conventional fairness-ofexposure approach does not satisfy these axioms, it is not yet clear 3 We know that Imp ? 2 (? The objective maximizes the product of impacts on the items, and the constraints express that each item needs to have probability 1 to be placed in some position, and each position needs to have probability 1 of receiving an item. This constraint structure makes this optimization problem different from the standard NSW in fair division <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22]</ref>. However, we retain that the optimization problem is convex and thus efficiently solvable, which is easy to see by equivalently replacing the product of impacts in objective with the sum of their logarithms, ? ?I log Imp ? (? ? * ,?, * ). <ref type="foot" target="#foot_2">4</ref> We call the policy that solves the optimization problem the NSW policy, which we denote by ? NSW .</p><p>A useful intuition is that the NSW does not allow any item to have zero impact, thus achieving a more equitable impact distribution. In particular, the NSW becomes zero if there is even a single item with zero impact. This contrasts with the conventional objective of maximizing user utility (which equals the sum of impacts), which may be maximized even if there are some items receiving no impact.</p><p>The following shows more formally that this intuition is correct, and that ? NSW guarantees (approximate) dominance over ? unif . Furthermore, the following shows that ? NSW is (approximately) envy-free and Pareto optimal. Theorem 4.1. If ? = 1 and only the top-ranked item contributes to the utility and impact (e.g., DCG@1), ? NSW is exactly Pareto optimal, is envy-free, and dominates ? unif . For the more general case with ? &gt; 1, ? NSW is still Pareto optimal. Moreover, let us call a pair of items ? and ? "?-twins" if max ? |? (?, ?) -? (?, ?)| ? ?. Then, if every item has at least ? + 1 ?-twins and ?/? = O (1), we have In the case of ? = 1, the solution of our problem coincides with the allocation computed via the competitive equilibrium from equal incomes (CEEI), a classic model of market equilibrium <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31]</ref>, which is known to be Pareto optimal, to be envy-free, and to dominate a uniform random allocation. When ? &gt; 1, the classical result from CEEI does not necessarily hold due to the additional constraints in our problem <ref type="bibr" target="#b21">[22]</ref>. However, Theorem 4.1 characterizes that, even for the general case, ? NSW can approximately satisfy our fairness axioms if there are items that are similar to each other, which is reasonable for large markets. <ref type="foot" target="#foot_3">5</ref> Note that Theorem 4.1 assumes the availability of the true relevance labels, but in Section 5, we empirically show that ? NSW robustly produces fair distributions of impact even with predicted relevance values. Table <ref type="table" target="#tab_2">2</ref> illustrates these guarantees of ? NSW on the same example used earlier. First, we can see that ? NSW produces an envy-free allocation of positions, i.e., neither item prefers the other item's allocation. In addition, ? NSW dominates ? unif , since every item gains higher impact than under ? unif .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Controlling the Fairness/Utility Trade-Off</head><p>In some situations, we may want to exert explicit control over how much user utility to sacrifice for stronger fairness guarantees to the items. For example, in Tables <ref type="table" target="#tab_2">2</ref> and<ref type="table" target="#tab_0">1</ref>, the user utility of ? NSW <ref type="bibr">(1.20)</ref> is lower than that of ? max (1.30) and ? expo-fair (1.23), and we may want to put more emphasis on user utility. To enable explicit control, we extend the NSW to what we call the ?-NSW as follows.</p><formula xml:id="formula_8">? ?-NSW = arg max {? ? * ,?, * } ??I ? ?I Imp ? (? ? * ,?, * ) Merit ? ? , s.t. ? ?? ?=1 ? ? ?,?,? = 1, ?(?, ?) ?? ? ?I ? ? ?,?,? = 1, ?(?, ?)</formula><p>0 ? ? ? ?,?,? ? 1, ?(?, ?, ?) ? ? 0 is a hyper-parameter that controls the balance between maximizing user utility (large ?) and guaranteeing impact-based fairness (small ?). When ? = 0, the ?-NSW objective is reduced to the standard NSW. Note that we can again take the logarithm to rewrite the objective to ? ?I Merit ? ? log Imp ? (? ? * ,?, * ) and solve the program efficiently. The ?-NSW policy ensures only a weaker version of envy-freeness and dominance over ? unif as detailed in the appendix, which means it can achieve higher user utility compared to the standard NSW.</p><p>Table <ref type="table" target="#tab_3">3</ref> illustrates the allocations of the ?-NSW policy ? ?-NSW for ? = 1 and ? = 2 on the example problem. We see that a larger value of ? leads to a better user utility, i.e., ? (? NSW ) &lt; ? (? 1-NSW ) &lt; ? (? expo-fair ) &lt; ? (? 2-NSW ), while a smaller value leads to a more balanced impact distribution. What is particularly notable here is that ? 1-NSW still dominates ? unif and remains envy-free, while achieving a better utility compared to ? NSW . This suggests that an appropriate choice of ? may allow us to improve user utility over ? NSW without sacrificing envy-freeness and dominance over ? unif on particular problem instances, even if we no longer have a-priori guarantees that hold over all problem instances. In the next section, we empirically explore how ? controls this trade-off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We first present experiments on synthetic data where we can control the popularity pattern in the market and the accuracy of the relevance prediction. In addition, we use real-world extreme classification datasets to evaluate how our method works with realistic relevance predictions. Our experiment implementation is available at https://github.com/usaito/kdd2022-fair-ranking-nsw.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Synthetic Data</head><p>To generate synthetic data, we first define the ground-truth relevance between user ? and item ? as</p><formula xml:id="formula_9">? true (?, ?) = (1 -?) ? ? unif (?, ?) + ? ? ? pop (?, ?),<label>(4)</label></formula><p>where ? unif (?, ?) is an independent and uniform draw within range ? ? [0, 1] controls the popularity pattern, where a larger value of ? leads to more severe popularity bias. We also simulate that we typically only have access to (inaccurately) predicted relevances, which we model as</p><formula xml:id="formula_10">? pred (?, ?) := clip ? true (?, ?) + ?, 0, 1 , ? ? Unif (-?, ?),</formula><p>where ? is independent and uniform noise, and ? ? 0 controls the accuracy of the predicted relevance values. We use the predicted relevance ? pred (?, ?) to optimize the rankings, and evaluate the item fairness and user utility of the policies using the groundtruth relevance ? true (?, ?). We use the inverse examination function ? (?) := I{? ? ? }/? in the definition of utility and impact, but we also present experiments with a different function in the appendix. We evaluate the degree of individual item fairness of a ranking policy ? using the following measures:</p><p>(1) Mean Max Envy (smaller is better):    The following evaluates ? NSW in comparison to ? max , ? expo-fair , and ? unif . We also evaluate how the hyper-parameter ? of ? ?-NSW controls the trade-off of item fairness and user utility. Note that we use |U| = 100, |I| = 50, ? = 0.05, ? = 0.5, ? = 5 as defaults, and vary each experiment configuration to see how each affects the behavior of the ranking policies. <ref type="foot" target="#foot_4">6</ref> Results are averaged over 10 simulation runs performed with different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">How do the ranking policies perform with different popularity patterns?</head><p>Here, we test how the fairness measures and user utility of the ranking policies change with different popularity patterns. For this purpose, we vary the experiment parameter ? in Eq. ( <ref type="formula" target="#formula_9">4</ref>) in the range of {0.0, 0.2, . . . , 1.0}. First, Figure <ref type="figure" target="#fig_2">1</ref> (a) shows the amount of envy produced under different levels of popularity bias. The figure suggests that ? NSW is always almost envy-free, while ? max and ? expo-fair produce larger amounts of envy for markets with greater popularity bias. Next, Figure <ref type="figure" target="#fig_2">1</ref> (b) shows how many items gain substantially better impact compared to ? unif under different levels of popularity bias. We observe that ? NSW substantially improves impact on almost all items in all cases, while ? max and ? expo-fair fail to achieve this desideratum. In addition, Figure <ref type="figure" target="#fig_8">1 (c)</ref> indicates that ? max and ? expo-fair decrease impacts on some items over 10% from those under ? unif . In particular, when ? = 1.0, 80% and 40% of the items experience substantial loss of impact under ? max and ? expo-fair , respectively. Instead, ? NSW does not substantially decrease any item's impact below ? unif , even if there exists severe popularity bias. These results demonstrate that ? NSW avoids producing envy and provides fair improvements in impact for almost all items. On the other hand, both ? max and ? expo-fair can lead to an unfair impact distribution and produce substantial amounts of envy, especially in the presence of severe popularity bias.</p><p>Although ? NSW is the most desirable in terms of item fairness, Figure <ref type="figure" target="#fig_2">1</ref> (d) suggests the expected trade-off between maximizing the user utility and satisfying our impact-based axioms. Figure <ref type="figure" target="#fig_2">1</ref> (d) shows how much user utility each policy gains under different popularity patterns. We observe that ? max achieves the largest user utility followed by ? expo-fair and ? NSW . This trend does not change across different levels of popularity bias, however, the gap in user utility among those policies varies. When ? = 0 and there is no popularity bias in the market, all policies except for ? unif achieve almost the same user utility. However, for larger values of ?, the gap in user utility between ? max , ? expo-fair , and ? NSW becomes greater. In particular, ? max and ? expo-fair improve user utility, while that of ? NSW decreases. An explanation is that an increase in popularity bias makes it easier to maximize the user utility by allocating large  amounts of exposure to popular items. Conversely, ? NSW shows the opposite trend since it needs to ever more strongly counteract the popularity bias to maintain impact fairness.</p><p>5.1.2 How does the hyper-parameter of ? ?-NSW balance item fairness and user utility? This experiment investigates how effectively one can control the balance between item fairness and user utility through the hyper-parameter ? of ? ?-NSW . To this end, we evaluate ? ?-NSW with ? ? {0.0, 0.5, 1.0, 2.0} (when ? = 0, ? ?-NSW is identical to ? NSW ) in comparison to ? expo-fair . Figure <ref type="figure" target="#fig_4">2</ref> reports the fairness measures and user utility of ? ?-NSW relative to those of ? expo-fair . Overall, the result demonstrates that ? ?-NSW is able to choose a range of trade-offs through the hyper-parameter. The most interesting trade-off is achieved with ? = 1.0. Figure <ref type="figure" target="#fig_4">2 (a)</ref> indicates that ? 1-NSW reduces the amount of envy over 40% compared to ? expo-fair in all cases. Moreover, Figure <ref type="figure" target="#fig_4">2 (b)</ref> and<ref type="figure">(c</ref>) demonstrate that ? 1-NSW provides a far more equitable distribution of impact compared to ? expo-fair . Finally, Figure <ref type="figure" target="#fig_4">2</ref> (d) shows that ? 1-NSW achieves almost the same user utility as ? expo-fair (about 4% drop even when ? = 1.0). This result suggests that ? ?-NSW has the potential to achieve a substantially fairer impact distribution than ? expo-fair while achieving a comparable level of user utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">How do the ranking policies perform under different relevanceprediction accuracies?</head><p>We also empirically investigate how robust the ranking policies are to inaccurate relevance labels, given that one would typically use predicted relevances in real-world applications. Figure <ref type="figure" target="#fig_5">3</ref> illustrates fairness and user utility for varying values of the accuracy parameter ?. The plots show that user utility slightly decreases as the relevance labels become more inaccurate, while fairness remain almost constant for all policies. Notably, ? NSW is almost envy-free and achieves a fairer impact distribution compared to the other policies in all situations, indicating that the NSW approach is robust to inaccurate relevance predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Real-World Data</head><p>To further evaluate how our method performs with predicted relevances on real-world data, we adapt two multilabel extreme classification datasets, namely Delicious and Wiki10-31K from the Extreme Classification Repository. <ref type="foot" target="#foot_5">7</ref> We regard each data as a user and each label as an item. If a data belongs to a label, then they are considered relevant. As preprocessing, we randomly sample 100 labels, <ref type="foot" target="#foot_6">8</ref> and then split the data into 90% training and 10% test sets. We train a Logistic Regression model on the training set, and predict the probabilities of each data belonging to the labels, which correspond to the relevance predictions. Based on the predictions, the ranking policies optimize the ordering of the labels for each data. We finally evaluate item fairness and user utility of the ranking policies on the test set using the true class labels as the ground-truth relevance. The fairness measures are the same as in the previous section. We use the inverse examination function and vary ? ? {1, 3, 5, 10, 20}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A CONNECTING EXPOSURE-BASED AND IMPACT-BASED NOTIONS OF FAIRNESS</head><p>The existing exposure-based fairness and our impact-based axioms have an interesting connection. Here, we show that the equality of attention of Biega et al. <ref type="bibr" target="#b2">[3]</ref> is a special case of our notion of envy-freeness.</p><p>Theorem A.1. If the impact function is defined as ? ? (?, ?) := ? (?), then envy-freeness coincides with the equality of attention.</p><p>Proof. Consider a pair of items ?, ? ? I (? ? ?). Given that ? ? (?, ?) := ? (?), envy-freeness mandates that Imp ? (? </p><p>Thus, from Eqs ( <ref type="formula">5</ref>) and ( <ref type="formula" target="#formula_11">6</ref>), envy-freeness coincides with the equality of attention, which requires that the amortized exposure should be equal for all items, i.e., Exp ? (? ? ) = Exp ? (? ? ), ??, ? ? I. ?</p><p>Note that ? ?-NSW satisfies the following relaxed version of envyfreeness and dominance over ? unif in the case of ? = 1. for all ? ? I. Here, we can follow a similar step as in Theorem A.1 and show that weighted envy-freeness coincides with the equity (not equality) of attention <ref type="bibr" target="#b2">[3]</ref> when ? = 1 and ? ? (?, ?) := ? (?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weighted</head><p>Theorem A.2. If the impact function is defined as ? ? (?, ?) := ? (?), then weighted envy-freeness with ? = 1 coincides with the equity of attention.</p><p>Proof. Consider a pair of items ?, ? ? I (? ? ?). Given that ? = 1 and ? ? (?, ?) := ? (?), weighted envy-freeness mandates that Imp ? (? ? * ,?, * )</p><formula xml:id="formula_12">Merit ? ? Imp ? (? ? * ,?, * ) Merit ? =? Exp ? (? ? ) Merit ? ? Exp ? (? ? ) Merit ? .<label>(7)</label></formula><p>Analogously, for the opposite direction, we should have that</p><formula xml:id="formula_13">Imp ? (? ? * ,?, * ) Merit ? ? Imp ? (? ? * ,?, * ) Merit ? =? Exp ? (? ? ) Merit ? ? Exp ? (? ? ) Merit ? ,<label>(8)</label></formula><p>Thus, from Eqs ( <ref type="formula" target="#formula_12">7</ref>) and ( <ref type="formula" target="#formula_13">8</ref>), weighted envy-freeness coincides with the equity of attention, which requires that the amortized exposure should be allocated proportional to merit for all items (Eq. ( <ref type="formula" target="#formula_6">3</ref>) in the main text with ? (?) = ?), i.e.,</p><p>Exp ? (? ? )</p><formula xml:id="formula_14">Merit ? = Exp ? (? ? )</formula><p>Merit ? , ??, ? ? I. ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PROOFS</head><p>Proof of Theorem 3.4. Given ? (?, ?) = (? -? + 1)(? -? + 1)/? 2 , amortized merit of ? is Merit ? = ? ? (?, ?) = (? + 1)(? -? + 1)/2?. To satisfy the exposure fairness constraint in Eq. (3), exposure-fair ranking policy ? expo-fair needs to allocate the following amount of exposure to item ?</p><formula xml:id="formula_15">Exp ? (? ? expo-fair ) = Merit ? ? Merit ? ?TE = 2(? -? + 1) ? + 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TE</head><p>where TE := ? ? (?) is the total amount of exposure available for each user and we use ? Merit ? = (? + 1) 2 /4. Then, we have</p><formula xml:id="formula_16">Exp ? (? ? expo-fair ) = 2TE ? + 1 Imp ? (? ? expo-fair * ,?, * ) ? ? (1, ?)Exp ? (? ? expo-fair ) = 2TE ?(? + 1)<label>(9)</label></formula><p>Note that Eq. ( <ref type="formula" target="#formula_16">9</ref>) holds for any policy (including ? expo-fair ) that satisfies the exposure-fair constraint in Eq. ( <ref type="formula" target="#formula_6">3</ref>).</p><p>In contrast, the uniform ranking policy ? unif provides the following impact on the ?-th item:</p><formula xml:id="formula_17">Imp ? (? ? unif * ,?, * ) = ?? ? ? -? + 1 ? 2 TE ? = ? + 1 2? 2 TE</formula><p>Therefore,</p><formula xml:id="formula_18">Imp ? (? ? expo-fair * ,?, * ) Imp ? (? ? unif * ,?, * ) ? 4? (? + 1) 2 = O (? -1 ).</formula><p>In addition, ? ??? := max ? ? (?) needs to be larger than Exp 1 (? ? expo-fair )/? so that the exposure-fair constraint is feasible. Given that ? expo-fair maximizes the utility to the users under the exposure-fair constraint and allocates exposure of the most relevant users preferentially to the 1st item, we have</p><formula xml:id="formula_19">Imp ? (? ? expo-fair * ,1, * ) ? ?? ? ? -? + 1 ? 2 Exp 1 (? ? expo-fair ) ? = TE ?<label>(10)</label></formula><p>Eq. ( <ref type="formula" target="#formula_19">10</ref>) provides the lowest possible utility of the ?-th item under ? Reduction used in Theorem 4.1. If ? = 1, our problem is reduced to the classical fair division of divisible goods with additive utility. Thus, the NSW-maximizing solution is known to satisfy Pareto optimality, envy-freeness, and dominance over ? unif (which corresponds to PFS) <ref type="bibr" target="#b30">[31]</ref>. For a general case with ? &gt; 1, our problem is reduced to fair division with constrained groups described in Appendix A of Kroer and Peysakhovich <ref type="bibr" target="#b21">[22]</ref>. Thus, our result follows from a version of their Theorem 1.</p><p>In more detail, fair division with constrained groups is an instance of fair division with linear utility function where we have a set P of constraint groups, which is a partitioning of resources. Each ? ? P is a subset of the original resources that should be allocated to the agents. It is assumed that each agent can be assigned 1 unit of resources among those in each group ?. This problem of fair division with constrained groups is reduced to our problem of fair ranking when we regard agents as items, resources as positions in a ranking, and a constraint group as a set of positions in a ranking that is shown to each user ?. In the ranking problem, a set of positions (? ? ? P) that is associated with a single user ? can be allocated to each item in total quantity of 1 (i.e., a constraint described as ? ?=1 ? ? ?,?,? = 1, ?(?, ?)) as in fair division with constraint group. Under this reduction and the assumption that there exists at least ? + 1 ?-twins for each item, Theorem 1 in Appendix A.2 of Kroer and Peysakhovich <ref type="bibr" target="#b21">[22]</ref> suggests that envy and the proportional share gap (which is Imp ? (? ? unif * ,?, * ) -Imp ? (? ? NSW * ,?, * ) in our problem) is upper bounded by ? (? 1 + ?/(?? 2 )) for some positive constants ? 1 , ? 2 &gt; 0 where the notations in the original paper, ? ? ? (sum of agent budgets) and |K | (number of constraint groups) can be regarded as ? (number of items) and ? (number of users) in our setup, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C EXPERIMENT DETAILS AND RESULTS C.1 Synthetic Data</head><p>In this section, we employ the same default setting as in Section 5.1 and vary some additional configurations.</p><p>C.1.1 How do the ranking policies perform with different lengths of ranking? Here, we validate how the policies perform as the length of ranking (?) varies. Figure <ref type="figure" target="#fig_9">5</ref> reports the results with ? ? {1, 3, 5, 10, 20}. First, we can see that all policies improve user utility with increasing ? in Figure <ref type="figure" target="#fig_9">5</ref> (d), as more items contribute to the user utility. As for the fairness measures, ? NSW remains envyfree and improves impact on all items over 10% from ? unif , while ? expo-fair produces a larger amount of envy and a less equitable impact distribution with increasing ?. C.1.2 How do the ranking policies perform with different market sizes? Next, we vary the size of the market. Figure <ref type="figure" target="#fig_10">6</ref> shows how the fairness measures and user utility of the ranking policies change with varying numbers of items and a fixed number of users. We observe that ? max produces a larger amount of envy and a less equitable impact distribution with the growing market size. In contrast, ? expo-fair slightly improves both the fairness measures and user utility, but ? NSW is much fairer for all cases, always being almost envy-free and dominating ? unif in terms of impact distribution. ? expo-fair does not achieve these desiderata for all market sizes. C.1.3 How does the examination function influence the relative performance? Finally, we evaluate whether a different examination function results in a different conclusion. We use the inverse function ? (?) := I{? ? ? }/? in the main text, but there are some other types of examination functions we can consider <ref type="bibr" target="#b29">[30]</ref>. Here we use the exponential examination function defined as ? (?) := I{? ? ? }/exp(? -1), which has a steeper drop off in probability than the inverse function, and as a result, assumes that users are likely to only see the top few items. Figure <ref type="figure" target="#fig_11">7</ref> shows the item fairness measures and user utility with varying popularity patterns (? ? {0.0, 0.2, . . . , 1.0}) and with the exponential examination function. In general, we observe trends similar to Figure <ref type="figure" target="#fig_2">1</ref> (which is obtained with the inverse examination function) for all metrics. Because we use a steeper examination function, the user utility decreases for all policies compared to Figure <ref type="figure" target="#fig_2">1</ref>, but the relative fairness and utility remain similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Real-World Data</head><p>Table <ref type="table" target="#tab_7">4</ref> summarizes some statistics of the datasets after applying the preprocessing described in the main text. Figure <ref type="figure" target="#fig_12">8</ref> shows the fairness measures and user utility of ? max , ? NSW , ? 1-NSW , ? expo-fair , and ? unif with varying ? on Wiki10-31K. We observe that ? NSW is almost envy-free and achieves an equitable impact distribution for all values of ?. In addition, ? 1-NSW achieves similar levels of user utility as ? expo-fair , while leading to a fairer impact distribution.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 3 . 4 .</head><label>34</label><figDesc>There exist two-sided markets with |U| = |I| = ? such that, even under the exposure-based fair ranking policy ? expo-fair with ? (?) = ?, there exists item ? whose maximum envy grows while impact compared to ? unif diminishes with the market size ?, i.e., max ? ?I Imp ? (? ? expo-fair * ,?, * ) Imp ? (? ? expo-fair * ,?, * ) = ?(?), Imp ? (? ? expo-fair * ,?, * ) Imp ? (? ? unif * ,?, * )= O (? -1 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>max ? ?I Imp ? (? ? NSW * ,?, * ) -Imp ? (? ? NSW * ,?, * ) = O (?), Imp ? (? ? unif * ,?, * ) -Imp ? (? ? NSW * ,?, * ) = O (?), for all item ? ? I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>[0, 1 ]</head><label>1</label><figDesc>. The second term infuses popularity bias, which we define as ? pop (?, ?) :=</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Fairness and user utility of the NSW policy compared to baseline policies on synthetic data for varying levels of popularity bias.</figDesc><graphic url="image-1.png" coords="7,63.93,86.14,481.86,127.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Fairness and user utility relative to the exposure-based fair policy ? expo-fair for various ?-NSW policies. Note that we omit ? = 0.0 from (a) and ? = 0.0, 0.2, 0.4 from (c), because the measures of ? expo-fair are (almost) zero for these cases.</figDesc><graphic url="image-2.png" coords="7,63.93,253.44,481.86,127.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>( 3 )</head><label>3</label><figDesc>Proportion (%) of items for which ? decreases impact by over 10% compared to ? unif (smaller is better): 100 |I| ?? ? ?I I Imp ? (? ? * ,?, * )/Imp ? (? ? unif * ,?, * ) ? 0.9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Fairness and user utility of the NSW policy compared to baseline policies on synthetic data for varying levels of relevance-prediction accuracy.</figDesc><graphic url="image-3.png" coords="8,63.93,86.13,481.86,127.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Fairness and user utility on the Delicious dataset for varying lengths of the ranking.</figDesc><graphic url="image-4.png" coords="8,63.93,253.58,481.89,127.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>? 1 .</head><label>1</label><figDesc>expo-fair * ,1, * when ? ??? is the lowest possible with ? ??? = Exp 1 (? ? expo-fair ) Using Eqs (9) and (10), we have max ? ?I Imp ? (? ? expo-fair * ,?, * ) Imp ? (? ? expo-fair * ,?, * )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Fairness and user utility on synthetic data with varying lengths of ranking.</figDesc><graphic url="image-6.png" coords="12,72.14,240.31,467.69,123.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Fairness and user utility on synthetic data with varying numbers of items.</figDesc><graphic url="image-7.png" coords="12,72.14,394.75,467.69,123.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Fairness and user utility with different popularity patterns and with exponential examination function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Fairness and user utility on the Wiki10-31K dataset with varying lengths of ranking.</figDesc><graphic url="image-8.png" coords="12,72.14,549.04,467.70,123.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A Illustrative Ranking Problem showing the Exposure Allocations and Impact Fairness of Different Ranking Policies</figDesc><table><row><cell cols="2">(a) True Relevance Table</cell></row><row><cell>? 1</cell><cell>? 2</cell></row><row><cell cols="2">? (? 1 , ?) 0.8 0.3</cell></row><row><cell cols="2">? (? 2 , ?) 0.5 0.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>an efficient algorithm exists to compute fair rankingsand whether fair rankings even exist. To approach this algorithmic question, we formulate the following optimization problem which extends the concept of Nash Social Welfare (NSW) to fair rankings.</figDesc><table><row><cell>? NSW = arg max {? ?  * ,?, *  } ??I</cell><cell>? ?I</cell><cell>Imp ? (? ?  * ,?, *  ),</cell></row><row><cell></cell><cell>?</cell><cell></cell></row><row><cell>s.t.</cell><cell>??</cell><cell>? ? ?,?,? = 1, ?(?, ?)</cell></row><row><cell></cell><cell>?=1</cell><cell></cell></row><row><cell></cell><cell>??</cell><cell>? ? ?,?,? = 1, ?(?, ?)</cell></row><row><cell></cell><cell>? ?I</cell><cell></cell></row><row><cell></cell><cell cols="2">0 ? ? ? ?,?,? ? 1, ?(?, ?, ?)</cell></row></table><note><p>? expo-fair * ,? 2 , * ) = 0.28 from Table 1c. If we replaced ? ? expo-fair * ,? 2 , * with ? ? expo-fair * ,? 1 , * , impact on ? 2 would increase, i.e., Imp ? 2 (? ? expo-fair * ,? 1 , * ) = 0.42. whether</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Allocation of the NSW Policy: ? (? NSW ) = 1.20 Exp ? (? ? NSW |? 1 ) 1.0 0.0 Exp ? (? ? NSW |? 2 ) 0.0 1.0</figDesc><table><row><cell></cell><cell>? 1</cell><cell>? 2</cell></row><row><cell>Exp ? (? ? NSW )</cell><cell cols="2">1.0 1.0</cell></row><row><cell>Imp ? (? ? NSW  * ,?, *  )</cell><cell cols="2">0.8 0.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Exposure Allocations and Impact Fairness of the ?-NSW Policies with Different Hyper-parameter Values</figDesc><table><row><cell cols="3">(a) 1-NSW: ? (? 1-NSW ) = 1.21</cell><cell cols="3">(b) 2-NSW: ? (? 2-NSW ) = 1.24</cell></row><row><cell></cell><cell>? 1</cell><cell>? 2</cell><cell></cell><cell>? 1</cell><cell>? 2</cell></row><row><cell cols="2">Exp ? (? ? 1-NSW |? 1 ) 1.0</cell><cell>0.0</cell><cell cols="2">Exp ? (? ? 2-NSW |? 1 ) 1.0</cell><cell>0.0</cell></row><row><cell cols="2">Exp ? (? ? 1-NSW |? 2 ) 0.1</cell><cell>0.9</cell><cell cols="2">Exp ? (? ? 2-NSW |? 2 ) 0.4</cell><cell>0.6</cell></row><row><cell>Exp ? (? ? 1-NSW )</cell><cell>1.1</cell><cell>0.9</cell><cell>Exp ? (? ? 2-NSW )</cell><cell>1.4</cell><cell>0.6</cell></row><row><cell>Imp ? (? ? 1-NSW  * ,?, *  )</cell><cell cols="2">0.85 0.36</cell><cell>Imp ? (? ? 2-NSW  * ,?, *  )</cell><cell cols="2">1.00 0.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>? * ,?, * ) ? Imp ? (? ? * ,?, * ) =? Exp ? (? ? ) ? Exp ? (? ? ). (5) Analogously, for the opposite direction, we should have that Imp ? (? ? * ,?, * ) ? Imp ? (? ? * ,?, * ) =? Exp ? (? ? ) ? Exp ? (? ? ),</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Statistics of the real-world datasets after preprocessing and the relevance prediction accuracy on the test set</figDesc><table><row><cell></cell><cell cols="2">Delicious Wiki10-31k</cell></row><row><cell>Training Data Size</cell><cell>9,123</cell><cell>7,639</cell></row><row><cell>Test Data Size (|U|)</cell><cell>1,014</cell><cell>849</cell></row><row><cell>Number of Labels (|I|)</cell><cell>100</cell><cell>100</cell></row><row><cell>AUC (on test set)</cell><cell>0.81</cell><cell>0.87</cell></row><row><cell>LogLoss (on test set)</cell><cell>0.31</cell><cell>0.18</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>P(? (?) = ? |?, ?) = E ??? (?|?) [I{? (?) = ? }]where I{?} is the indicator function.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The sum of each row and column is 1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>This type of program is know as the Eisenberg-Gale (EG) program<ref type="bibr" target="#b16">[17]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Note that it may be reasonable to assume that ? decreases with the size of the market, since it should be easier to find a sufficient number of ?-twins in a larger market. This means we could expect ? NSW to more accurately satisfy our axioms with an increasing number of items.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>The results with varying number of items (?) and lengths of ranking (? ) are reported in Appendix C</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>http://manikvarma.org/downloads/XC/XMLRepository.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>We sample label ? with probability ? ? I{? is one of top 100 frequent labels} + (1 -?) ? (100/|I |) (where we set ? = 0.5) to introduce some popularity bias in the data.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by <rs type="funder">NSF</rs> Awards <rs type="grantNumber">IIS-1901168</rs> and <rs type="grantNumber">IIS-2008139</rs>. <rs type="person">Yuta Saito</rs> was supported by the <rs type="funder">Funai Overseas Scholarship</rs>. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uHhRZF6">
					<idno type="grant-number">IIS-1901168</idno>
				</org>
				<org type="funding" xml:id="_X3N3Zpg">
					<idno type="grant-number">IIS-2008139</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We iterate the simulation 10 times with different seeds and report the aggregated results.</p><p>Figure <ref type="figure">4</ref> compares fairness and user utility of ? max , ? NSW , ? 1-NSW , ? expo-fair and ? unif on the Delicious dataset. First, ? NSW achieves almost envy-free and fair impact distribution with increasing ?, suggesting that our desiderata can be achieved even with realistically inaccurate relevance predictions. In addition, ? 1-NSW succeeds in finding a utility-fairness trade-off that is more desirable than that of ? expo-fair . Specifically, ? 1-NSW obtains user utility slightly better than ? expo-fair while leading to a fairer impact distribution. Figure <ref type="figure">4</ref> (a) suggests that ? 1-NSW produces a larger amount of envy compared to ? expo-fair , but the amount is controllable by tuning ?. Appendix C reports qualitatively similar results on Wiki10-31K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We provide a new conceptualization of fairness in ranking as a resource allocation problem and propose impact-based axioms for individual item fairness. This allows us to build upon well-established principles of fairness from economics, removing the need to choose a difficult-to-justify link function as required for exposure-based fairness. We also contribute an efficient algorithm for computing impact-fair rankings, adapting the Nash Social Welfare to ranking problems. Furthermore, we develop a practical extension of the NSW, which enables us to control the trade-off between user utility and item fairness. This work opens a wide range of new research directions, ranging from the development of end-to-end policy learning methods for impact-fair ranking, to the use of partialinformation data and extensions to sequential ranking problems.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Designing Fair Ranking Schemes</title>
		<author>
			<persName><forename type="first">Abolfazl</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautam</forename><surname>Stoyanovich</surname></persName>
		</author>
		<author>
			<persName><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data</title>
		<meeting>the 2019 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1259" to="1276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Envy-Free Classification</title>
		<author>
			<persName><forename type="first">Maria-Florina F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Travis</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Noothigattu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><forename type="middle">D</forename><surname>Procaccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1240" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Equity of Attention: Amortizing Individual Fairness in Rankings</title>
		<author>
			<persName><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="405" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Birkhoff</surname></persName>
		</author>
		<title level="m">Lattice Theory</title>
		<imprint>
			<publisher>American Mathematical Soc</publisher>
			<date type="published" when="1940">1940</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distributed Algorithms via Gradient Descent for Fisher Markets</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Nikhil R Devanur</surname></persName>
		</author>
		<author>
			<persName><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM conference on Electronic commerce</title>
		<meeting>the 12th ACM conference on Electronic commerce</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fair Division under Cardinality Constraints</title>
		<author>
			<persName><forename type="first">Arpita</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Barman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="91" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Individually Fair Rankings</title>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Bower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Eftekhari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Yurochkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuekai</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Handbook of Computational Social Choice</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Conitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulle</forename><surname>Endriss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J?r?me</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><forename type="middle">D</forename><surname>Procaccia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Combinatorial Assignment Problem: Approximate Competitive Equilibrium from Equal Incomes</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Budish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Political Economy</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1061" to="1103" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Unreasonable Fairness of Maximum Nash Welfare</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Caragiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kurokawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herv?</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><forename type="middle">D</forename><surname>Procaccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisarg</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junxing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Economics and Computation (TEAC)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Interventions for Ranking in The Presence of Implicit Bias</title>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Celis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anay</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisheeth</forename><forename type="middle">K</forename><surname>Vishnoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2020 Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="369" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Celis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damian</forename><surname>Straszak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisheeth</forename><forename type="middle">K</forename><surname>Vishnoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06840</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Ranking with Fairness Constraints. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Experimental Comparison of Click Position-bias Models</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onno</forename><surname>Zoeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Ramsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 International Conference on Web Search and Data Mining</title>
		<meeting>the 2008 International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluating Stochastic Rankings with Expected Exposure</title>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asia</forename><forename type="middle">J</forename><surname>Michael D Ekstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Online Certification of Preference-based Fairness for Personalized Recommender Systems</title>
		<author>
			<persName><forename type="first">Virginie</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Corbett-Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamal</forename><surname>Atif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14527</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fairness through Awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Innovations in Theoretical Computer Science Conference</title>
		<meeting>the 3rd Innovations in Theoretical Computer Science Conference</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Consensus of Subjective Probabilities: The Aari-Mutuel Method</title>
		<author>
			<persName><forename type="first">Edmund</forename><surname>Eisenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="165" to="168" />
			<date type="published" when="1959">1959. 1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Resource Allocation and the Public Sector</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><surname>Foley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cumulated Gain-based Evaluation of IR techniques</title>
		<author>
			<persName><forename type="first">Kalervo</forename><surname>J?rvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaana</forename><surname>Kek?l?inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Top-k Contextual Bandits with Equity of Exposure</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Jeunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Goethals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="310" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unbiased Learning-to-Rank with Biased Feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Scalable Fair Division for</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Kroer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Peysakhovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.10925</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">At Most One&apos;Preferences. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Controlling Fairness and Bias in Dynamic Learning-to-Rank</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Morik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="429" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness</title>
		<author>
			<persName><forename type="first">Harrie</forename><surname>Oosterhuis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fairrec: Two-sided Fairness for Personalized Recommendations in Two-Sided Platforms</title>
		<author>
			<persName><forename type="first">Arpita</forename><surname>Gourab K Patro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niloy</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhijnan</forename><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1194" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Probability Ranking Principle in IR</title>
		<author>
			<persName><surname>Stephen E Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of documentation</title>
		<imprint>
			<date type="published" when="1977">1977. 1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fairness of Exposure in Rankings</title>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2219" to="2228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Policy Learning for Fairness in Ranking</title>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fairness in Ranking Under Uncertainty</title>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimizing Rankings for Recommendation in Matching Markets</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magd</forename><surname>Bayoumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="328" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Equity, Envy, and Efficiency</title>
		<author>
			<persName><surname>Hal R Varian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Theory</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="63" to="91" />
			<date type="published" when="1974">1974. 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fairness of Exposure in Stochastic Bandits</title>
		<author>
			<persName><forename type="first">Lequn</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="10686" to="10696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Policy-Gradient Training of Fair and Unbiased Ranking Functions</title>
		<author>
			<persName><forename type="first">Himank</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1044" to="1053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Measuring Fairness in Ranked Outputs</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Stoyanovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Scientific and Statistical Database Management</title>
		<meeting>the 29th International Conference on Scientific and Statistical Database Management</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Maximizing Marginal Fairness for Dynamic Learning to Rank</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2021</title>
		<meeting>the ACM Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="137" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reducing Disparate Exposure in Ranking: A Learning to Rank Approach</title>
		<author>
			<persName><forename type="first">Meike</forename><surname>Zehlike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="2849" to="2855" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
