<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parsing Biomedical Literature</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Matthew</forename><surname>Lease</surname></persName>
							<email>mlease@cs.brown.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Brown Laboratory for Linguistic Information Processing (BLLIP) Brown University Providence</orgName>
								<address>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Brown Laboratory for Linguistic Information Processing (BLLIP) Brown University Providence</orgName>
								<address>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parsing Biomedical Literature</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9535C5C041CFE6A9BCE8410E6DE2661A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a preliminary study of several parser adaptation techniques evaluated on the GENIA corpus of MEDLINE abstracts <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. We begin by observing that the Penn Treebank (PTB) is lexically impoverished when measured on various genres of scientific and technical writing, and that this significantly impacts parse accuracy. To resolve this without requiring in-domain treebank data, we show how existing domain-specific lexical resources may be leveraged to augment PTB-training: part-of-speech tags, dictionary collocations, and namedentities. Using a state-of-the-art statistical parser [3] as our baseline, our lexically-adapted parser achieves a 14.2% reduction in error. With oracleknowledge of named-entities, this error reduction improves to 21.2%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since the advent of the Penn Treebank (PTB) <ref type="bibr" target="#b3">[4]</ref>, statistical approaches to natural language parsing have quickly matured <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. By providing a very large corpus of manually labeled parsing examples, PTB has played an invaluable role in enabling the broad analysis, automatic training, and quantitative evaluation of parsing techniques. However, while PTB's Wall Street Journal (WSJ) corpus has historically served as the canonical benchmark for evaluating statistical parsing, the need for broader evaluation has been increasingly recognized in recent years. Furthermore, since it is impractical to create a large treebank like PTB for every genre of interest, significant attention has been directed towards maximally reusing existing training data in order to mitigate the need for domain-specific training examples. These issues have been most notably explored in parser adaptation studies conducted between PTB's WSJ and Brown corpora <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>.</p><p>As part of our own exploration of these issues, we have been investigating statistical parser adaptation to a novel domain: biomedical literature. This literature presents a stark contrast to WSJ and Brown: it is suffused with domainspecific vocabulary, has markedly different stylistic constraints, and is often written by non-native speakers. Moreover, broader consideration of technical literature shows this challenge and opportunity is not confined to biomedical literature alone, but is also demonstrated by patent literature, engineering manuals, and field-specific scientific discourse. Through our work with biomedical literature, we hope to gain insights into effective techniques for adapting statistical parsing to technical literature in general.</p><p>Our interest in biomedical literature is also motivated by a real need to improve information extraction in this domain. With over 15 million citations in PubMed today, biomedical literature is the largest and fastest growing knowledge domain of any science. As such, simply managing the sheer volume of its accumulated information has become a significant problem. In response to this, a large research community has formed around the challenge of enabling automated mining of the literature <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. While the potential value of parsing has often been discussed by this community, attempts to employ it thus far appear to have been limited by the parsing technologies employed. Reported difficulties include poor coverage, inability to resolve syntactic ambiguity, unacceptable memory and speed, and difficulty in hand-crafting rules of grammar <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. Perhaps the most telling indicator of community perspective came in a recent survey's bleak observation that efficient and accurate parsing of unrestricted text appears to be out of reach of current techniques <ref type="bibr" target="#b13">[14]</ref>.</p><p>In this paper, we show that broad, accurate parsing of biomedical literature is indeed possible. Using an off-the-shelf WSJ-trained statistical parser <ref type="bibr" target="#b2">[3]</ref> as our baseline, we provide the first full-coverage parse accuracy results for biomedical literature, as measured on the GENIA corpus of MEDLINE abstracts <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Furthermore, after showing that PTB is lexically impoverished when measured on various genres of scientific and technical writing, we describe three methods for improving parse accuracy by leveraging lexical resources from the domain: part-of-speech (POS) tags, dictionary collocations, and named-entities. Our general hope is that lexically-based techniques such as these can provide alternative and complementary value to treebank-based adaptation methods such as cotraining <ref type="bibr" target="#b8">[9]</ref> and sample selection <ref type="bibr" target="#b14">[15]</ref>. Our lexically-adapted parser achieves a 14.2% reduction in error over the baseline, and in the case of oracle-knowledge of named-entities, this reduction improves to 21.2%.</p><p>Section 2 describes the GENIA corpus in detail. In Section 3, we present unknown word rate experiments which measure the coverage of PTB's grammar on various genres of scientific and technical writing. Section 4 describes our methods for lexical adaptation and their corresponding effects on parse accuracy. Section 5 concludes with a discussion challenges and opportunities for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The GENIA corpus</head><p>The GENIA corpus <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> consists of MEDLINE abstracts related to transcription factors in human blood cells. Version 3.02p of the corpus includes 1999 1 abstracts (18,545 sentences, 436,947 words) annotated with part-of-speech (POS) tags and named-entities. Named-entities were labelled according to a corpusdefined ontology, and the POS-tagging scheme employed is very similar to that used in PTB (see <ref type="bibr">Section 4.1)</ref>.</p><p>Using these POS annotations and PTB guidelines <ref type="bibr" target="#b15">[16]</ref>, we hand-parsed 21 of these abstracts (215 sentences) to create a pilot treebank for measuring parse accuracy. We performed the treebanking using the GRAPH<ref type="foot" target="#foot_0">2</ref> tool developed for the Prague Dependency Treebank. Initial bracketing was performed without any form of automation. Following this, our baseline parser <ref type="bibr" target="#b2">[3]</ref> was used to propose alternative parses. In cases where hand-generated parses conflicted with those proposed by the parser, hand-parses were manually corrected, or not corrected, according to PTB bracketing guidelines. Our pilot treebank is publicly available <ref type="foot" target="#foot_1">3</ref> .</p><p>Subsequent to this, the Tsujii lab released its own beta version treebank, which includes 200 abstracts (1761 sentences) from the original corpus. This treebanking was performed largely in accordance with PTB guidelines (perhaps the most significant difference being constituent labels NAC and NX were excluded in favor of NP). Because there is no redundancy in the coverage of the Tsuijii lab's treebank and our own pilot treebank (and by chance, NAC and NX do not occur in our pilot treebank either), we have combined the two treebanks to maximize our evaluation treebank (see Table <ref type="table" target="#tab_2">3</ref>).</p><p>An additional note is required regarding our use of named-entities (Section 4.3). Entity annotations (not available in the treebank) were obtained from the earlier 3.02p version of the corpus. Any sentences that did not match between the two versions of the corpus (due to differences in tokenization or other variations) were discarded. The practical impact of this was negligible, as only 25 sentences had to be discarded<ref type="foot" target="#foot_2">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Unknown Words</head><p>Casual reading of technical literature quickly reveals a rich, field-specific vocabulary. For example, consider the following sentence taken from GENIA:</p><p>The study of NF-kappaB showed that oxLDLs led to a decrease of activation-induced p65/p50 NF-kappaB heterodimer binding to DNA, whereas the presence of the constitutive nuclear form of p50 dimer was unchanged.</p><p>To quantitatively measure the size and field-specificity of domain vocabulary, we extracted the lexicon contained in WSJ sections 2-21 and evaluated the unknown word rate (by token) for various genres of technical literature. Results are given in Table <ref type="table" target="#tab_0">1</ref>. Brown-DEV corresponds to a balanced sampling of the Brown corpus (see Table <ref type="table" target="#tab_3">4</ref>). Section J of Brown contains "Learned" writing samples and demonstrated the highest rate of any single Brown section. CRAN contains 1400 abstracts in the field of aerodynamics, and CACM includes 3200 abstracts from Communications of the ACM <ref type="bibr" target="#b16">[17]</ref>. DOE contains abstracts from the Department of Energy, released as part of PTB. GENIA here refers to 333 abstracts (IDs 97449161-99101008) not overlapping our treebank. As this table shows, unknown word rate clearly increases as we move to increasingly technical domains. Annecdotal evaluation on patent literature suggests its unknown rate lies somewhere between that of DOE and GENIA.</p><p>While these results appear to indicate WSJ is lexically impoverished with respect to increasingly technical domains, it was also necessary to consider the possibility that the results were simply symptomatic of technical domains having very large lexicons. If such were the case, we would expect to see these domains demonstrate high unknown word rates even in the presence of a domain-specific lexicon. To test this hypothesis, we contrasted unknown word rates on GENIA using lexicons extracted from WSJ sections 2-21, Brown (training section from Table <ref type="table" target="#tab_3">4</ref>), and from GENIA itself (1,333 abstracts: IDs 90110496-97445684) <ref type="foot" target="#foot_3">5</ref> . Results are presented in Table <ref type="table" target="#tab_1">2</ref> Although the unknown word rate in the presence of in-domain training for GENIA (5.3%, Table <ref type="table" target="#tab_1">2</ref>) is nearly twice that of out-of-domain training (2.7%, Table <ref type="table" target="#tab_0">1</ref>), suggesting a larger lexicon does indeed exist, it is also strikingly clear that WSJ and Brown provide almost no lexical value to the domain: expanding GENIAs lexicon by 45,000 new terms found in WSJ and Brown produced only a meager 0.7% reduction in unknown word rate. Contrast this with the enormous reduction achieved through using GENIA's lexicon instead of the WSJ or Brown lexicons (Table <ref type="table" target="#tab_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parser Adaptation</head><p>In this section, we present three methods for parser adaptation motivated by the results of our unknown word rate experiments (Section 3). The goal of these adaptations is to help an off-the-shelf PTB-trained parser compensate for the large amount of domain-specific vocabulary found in technical literature, specifically biomedical text. To accomplish this without depending on in-domain treebank data, we consider three alternative (and less expensive) domain-specific knowledge sources: part-of-speech tags, dictionary collocations, and named-entities. We report on the results of each technique both in isolation and in combination.</p><p>We adopt as our baseline for these experiments the publicly available Charniak parser <ref type="bibr" target="#b2">[3]</ref> trained on WSJ sections 2-21 of the Penn Treebank. Our division of the GENIA corpus into development and test sets is shown in Table <ref type="table" target="#tab_2">3</ref>. Analysis was carried out on the development section, and the test section was reserved for final evaluation. Parse accuracy was measured using the standard PARSEVAL metric of bracket-bracket scoring, assuming the usual conventions regarding punctuation <ref type="bibr" target="#b17">[18]</ref>. Statistical significance for each experiment was assessed using a two-tailed paired t-test on sentence-averaged f-measure scores. Since our evaluation treebank excludes NX and NAC constituent labels in favor of NP (Section 2), for all experiments (including baseline) we post-processed parser output to collapse these label distinctions <ref type="foot" target="#foot_4">6</ref> . Results from our various experiments are summarized in Table <ref type="table" target="#tab_4">5</ref>.</p><p>Final results of our adapted parser are given in Table <ref type="table" target="#tab_5">6</ref>. For comparison with standard benchmarks, parser performance was also evaluated on WSJ section 23 and on Brown. Table <ref type="table" target="#tab_3">4</ref> shows our division of the Brown corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Using POS Tags</head><p>Part-of-speech tags provide an important data feature to statistical parsers <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. Since technical and scientific texts introduce a significant amount of domainspecific vocabulary (Section 3), a POS-tagger trained only on everyday English is immediately at a disadvantage for tagging such text. Indeed, our off-the-shelf PTB-trained parser achieves only 84.6% tagging accuracy on GENIA. Consequently, our simple first adaptation step was to retrain the parser's POS-tagger on the 1,778 GENIA abstracts not present in the combined treebank (in addition to WSJ sections 2-21). This simple fix raised tagging accuracy to 95.9%. Correspondingly, parsing accuracy improved from 78.3% to 80.8% (Table <ref type="table" target="#tab_4">5</ref>). While such POS-retraining is a direct remedy to learning appropriate tags for new vocabulary, it is only a partial fix to a larger problem. In particular, the trees found in PTB codify a relationship between PTB POS tags and constituent structure, and any mismatch between the tagging schemata used in PTB and that used by our new corpus could result in misapplication or underutilization of the bracketing rules acquired by the parser during training. To overcome this, it is necessary to introduce an additional mapping step which converts between the two POS tagging schemata. For closely related schemata, this mapping may be trivial, but this cannot be assumed without a carefully analysis of tag distribution and usage across the two corpora.</p><p>In the case of GENIA, the tagging guidelines used were based on PTB and only subsequently revised (to improve inter-annotator agreement), so while differences do exist, the problem is much less significant than the general case of arbitrarily different schemata. Reported differences include treatment of hyphenated, partial, and foreign terms, and most notably, the distinction between proper (NNP) and common (NN) nouns <ref type="bibr" target="#b1">[2]</ref>. In order to quantitatively assess the degree to which these and other revisions were made to the tagging scheme, we extracted the POS distribution for 333 GENIA abstracts (as used in our unknown word rate experiments from Section 3). From this distribution, we learned that NNP almost never occurs in GENIA. This meant that our PTBtrained parser would be unable to leverage PTB's constituent structure examples examples that involved proper nouns.</p><p>As a preliminary remedy, we simply relabeled all proper nouns as common in PTB and re-trained the parser. This improved tagging accuracy to 96.4% and parsing accuracy to 81.5% (Table <ref type="table" target="#tab_4">5</ref>). We should note, however, that this solution is not ideal. While it does allow use of PTB's NNP-examples, it does so at the cost of confusing legitimate differences in the syntactic distribution of common and proper nouns in English (as reflected by a 0.7% loss in accuracy on WSJ evaluation when using this NN-NNP conflated training data). Clearly it would be better if GENIA's nouns could be re-tagged to preserve this distinction while preserving inter-annotator agreement. A first step in this direction would be to perform this re-tagging automatically based on determiner usage and GENIA's entity annotations, with success measured by the corresponding impact on parse accuracy. This, along with a more careful analysis of tagging differences, remains for future work.</p><p>We have also evaluated parser performance under the oracle condition of perfect tags. This was implemented as a soft constraint so that the parser's joint probability model could overrule the oracle tag for cases in which no parse could be found using it (cases of annotator error or data sparsity). Using the oracle tag 99.8% of the time (in addition to other POS adaptations) had almost no impact on parse accuracy, suggesting that further POS-related improvements in parse accuracy will only come from the sort of careful analysis of the tagging schemata discussed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Using a Domain-specific Lexicon</head><p>Another strategy we employed for lexical adaptation was the use of a domainspecific dictionary. For biomedicine, such a dictionary is available from the National Library of Medicine: the Unified Medical Language System (UMLS) SPE-CIALIST lexicon <ref type="bibr" target="#b18">[19]</ref>. Covering both general English as well as biomedical vocabulary, the SPECIALIST lexicon contains over 415,000 entries (including orthographic and morphological variants). Entries are also assigned one of eleven POS categories specified as part of the lexicon.</p><p>Given our finding from Section 4.1 that even oracle POS tags would do little to improve upon our re-trained POS tagger, we did not make use of lexicon POS tags. Instead, we restricted our use of the lexicon to extracting collocations. We then added a hard-constraint to the parser that these collocations could not be cross-bracketed and that each collocation must represent a flat phrase with no internal sub-constituents. This approach was motivated by a couple of observations. On one hand, we observed cases where the parser would be confused by long compound nouns; in desperation to find the start of a verb phrase, it would sometimes use part of the compound to head a new verb phrase. Unfortunately, WSJ sections 2-21 contain approximately 500 verb phrases headed by presentparticiple verbs mistagged as nouns, thus making this bizarre bracketing rule statistically viable. A second observation was the frequency with which we saw the terms "in vivo" and "in vitro" (treebanked as foreign adjverbial or adjectival collocations) mis-analyzed. Even in biomedical texts, "in" appears far more often as a preposition than as part of such collocations, and as such, is almost always mis-parsed in these collocational contexts to head a prepositional phrase. Our hope was that by preventing such collocations from being cross-bracketted, we could prevent this class of parsing mistakes.</p><p>We found use of lexical collocations did yield a small (0.3%) but statistically significant improvement in performance over the unmodified parser (Table <ref type="table" target="#tab_4">5</ref>). However, when combined with either POS or entity adaptations, the lexicon's impact on parsing accuracy was statistically insignificant. Our interpretation of this latter result is that the primary limitation of the lexicon is coverage, despite its size. That is, when either of the other adaptations were used, the lexicon did not offer much beyond them. It is not surprising that oracle-knowledge of entities (Section 4.3) provided greater coverage than the generic dictionary, and the improvement in tagging from POS adaptation (sharper tag probabilities) helped somewhat in preventing the verb-ification of some of the long compound nouns. While the lexicon was the only adaptation to correctly fix "in vivo" type mistakes, these phrases alone were not sufficiently frequent to provide a statistically significant improvement in parse accuracy on top of other adaptations. As such, the primary value of this method would be in cases where such a lexicon is available but POS tags and labelled entities are not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Using Named-Entities</head><p>The primary focus of the GENIA corpus is to support training and evaluation of automatic named-entity recognition. As such, a variety of biologically meaningful terms have been annotated in the corpus according to a corpus-defined ontology. Given the availability of these annotations, we were interested in considering the extent to which they could be used as a source of lexical information for parser adaptation.</p><p>Given the problems described earlier with regard to lexical collocations being cross-bracketted by our off-the-shelf PTB-trained parser (Section 4.2), our hope was that named-entities could be used similarly to lexical collocations in helping to prevent this class of mistakes. To put it another way, we hoped to exploit the correlation between named-entities and noun phrase (NP) boundaries. A common preprocessing step in detecting named-entities is to use a chunker to find NPs. Our approach was to do the reverse: to use named-entities as a feature for finding NP boundaries.</p><p>Our initial plan was to use the same strategy we had used with dictionary collocations: to add a hard-constraint to the parser that a named-entity could not be cross-bracketed and had to represent a flat phrase with no internal subconstituents. However, we found upon closer inspection that the entities often did contain substructure (primarily parenthetical acronyms), and so we relaxed the flat-constituent constraint and enforced only the cross-bracketing constraint.</p><p>As a preliminary step, we evaluated the utility of this method using oracleknowledge of named-entities. By itself, this method was roughly equivalent to POS re-training in improving parsing accuracy from 78.3% to 80.9% (Table <ref type="table" target="#tab_4">5</ref>). But when combined with POS adaptations, use of named-entities provided another significant improvement in performance, from 81.5% to 82.9%. Clearly this is a promising avenue for further work, and it will be interesting to see how much of this benefit from the oracle case can be realized when using automatically detected entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>We have found only limited use of parsing reported to date for biomedical literature, thus it is difficult to compare our parsing results against previous work in parsing this domain. To the best of our knowledge, only one other wide-coverage parser has been applied to biomedical literature: Grover et al. report 99% coverage using a hand-written grammar with a statistical ranking component <ref type="bibr" target="#b19">[20]</ref>. We do not know of any quantitative accuracy figures reported for this domain other than those described here.</p><p>For those interested in mining the biomedical literature, the next important step will be assessing the utility of PTB-style parsing compared to other parsing models that have been employed for information extraction. There has been promising work in using PTB-style parses for information extraction by inducing predicate-argument structures from the output parses <ref type="bibr" target="#b20">[21]</ref>. It will be interesting to see for the biomedical domain how these predicate-argument structures compare to those induced by other grammar formalisms currently in use, such as HPSG <ref type="bibr" target="#b21">[22]</ref>.</p><p>The next immediate extension of our work is to evaluate use of detected named-entities in place of the oracle case described in Section 4.3, replacing the current hard-constraint with a soft-constraint confidence term to be incorporated into the parser's generative model. Performance of named-entity recognition on GENIA was recently studied as part of a shared task at BioNLP/NLPBA 2004. The best system achieved 72.6% f-measure <ref type="bibr" target="#b22">[23]</ref>, though note that this task required both detection and classification of named-entities. As our usage of entities does not require classification, this number should be considered a lowerbound in the context of our usage model. We expect this level of accuracy should be sufficient to improve parse scores, though how much of the oracle benefit we can realize remains to be seen.</p><p>There are also interesting POS issues meriting further investigation. As discussed in Section 4.1, we would like to find a better solution to the lack of proper noun annotations in GENIA, perhaps by detecting proper nouns using determiners and labelled entities. More careful analysis of the differences between the PTB and GENIA tagging schemata is also needed. Additionally, there are interesting issues regarding how POS tags are used by the parsing model. Whereas the Collins' model <ref type="bibr" target="#b4">[5]</ref> treats POS tagging as an external preprocessing step (a single best tag is input to the parsing model), the Charniak model <ref type="bibr" target="#b2">[3]</ref> generates tag hypotheses as part of its combined generative model, and thus considers multiple hypotheses in searching for the best parse. The significance of this is that other components of the generative model can influence tag selection, and Charniak has reported adding this feature to his simulated version of the Collins model improved its accuracy by 0.6% <ref type="bibr" target="#b23">[24]</ref>. However, this result was for in-domain evaluation; the picture becomes more complicated when we begin parsing out-of-domain. If we have an in-domain trained POS-tagger, we might not want a combined model trained on out-of-domain data overruling our tagger's predictions. One option may be introducing a weighting factor into the generative model to indicate the degree of confidence assigned to our tagger relative to the other components of the combined model.</p><p>Another issue for further work is the parsing of paper titles. In the GENIA development section, only 28% of the titles are sentences whereas 71% are noun phrases. This distribution is radically different than the rest of the corpus, which is heavily dominated by sentence-type utterances. As headlines are even more rare in our WSJ training data than titles are in GENIA (since WSJ contains full article text), our parser performs miserably at utterance-type detection (i.e. correctly labelling the top-most node in the parse tree): 58.6%. Correspondingly, parse accuracy on titles is only 69.1%, which represents a statistically significant decrease in accuracy in comparison to the entire development section (p = 0.038). In investigating this, we noticed an oddity in GENIA in that most titles were encoded in the corpus with an ending period that did not exist in the original papers the corpus was derived from. By removing these periods, we improved utterance-type detection to 77.9%. While parse accuracy rose to 72.0%, this was statistically insignificant (p = 0.082). The solution we would like to move towards is to respect the legitimate distributional differences between title and non-title utterances and parameterize the parser differently for the two cases. Generally speaking, such "contextual parsing" might allow us to improve parsing accuracy more widely by parameterizing our parser differently based on where the current utterance fits in the larger discourse. This example of period usage in titles also highlights a broader issue that seemingly innocuous issues in corpus preparation can have significant impact when parsing. As a further example of this, the choice to (at times) separately tokenize term-embedded parentheses in GENIA creates unnecessary attachment ambiguity in the resulting parenthetical phrases. For example, in the phrase "C3a and C3a(desArg)", "C3a(desArg)" is tokenized as "C3a ( desArg )", which produces ambiguity as to whether the parenthetical should attach low (to the latter "C3a") or high (to the compound "C3a and C3a"). Issues such as these remind us to be mindful of the relationship between corpus preparation and parsing, as well as downstream processing, and that some issues which appear difficult to resolve while parsing might be handled more easily at another stage in the processing pipeline.</p><p>We view biomedical and other technical texts as providing an interesting set of challenges and questions for future parsing research. An interesting introduction to some of these challenges, supported by examples drawn from the domain, can be found in <ref type="bibr" target="#b24">[25]</ref>. A significant question for consideration is the degree to which these challenges are related to domain knowledge vs. stylistic norms of the genre. For example, <ref type="bibr" target="#b1">[2]</ref> reports that whereas POS determination required domain expertise, prepositional phrase (PP)-attachment could be largely determined even by non-biologists. Our own treebanking experience left us with the opposite impression. For example, in the phrase "gene expression and protein secretion of IL-6", should the PP attach high (IL-6 gene expression and protein secretion) or low (gene expression and IL-6 protein secretion)? Domain knowledge appears to be necessary here for correct resolution. In contrast to this, POS tags appear to be a distributional rather than a semantic concern. Issues like this highlight how little we really understand currently about the parameters of corpus variation. How do the frequencies of different syntactic constructions vary by genre, and are there key structural variations at work? How do we effectively adapt parsers in response? These issues remain important topics for future investigation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Unknown word rate on various technical corpora given WSJ 2-21 lexion.</figDesc><table><row><cell>Corpus</cell><cell>Unknown Word Rate</cell></row><row><cell>WSJ sect. 24</cell><cell>2.7</cell></row><row><cell>Brown-DEV</cell><cell>5.8</cell></row><row><cell>Brown sect. J</cell><cell>7.3</cell></row><row><cell>CRAN</cell><cell>10.0</cell></row><row><cell>CACM</cell><cell>10.7</cell></row><row><cell>DOE</cell><cell>16.7</cell></row><row><cell>GENIA</cell><cell>25.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>. Unknown word rate on GENIA using lexicons extracted from WSJ, Brown, and GENIA.</figDesc><table><row><cell>Lexicon</cell><cell>Size</cell><cell>Unknown Word Rate</cell></row><row><cell>Brown</cell><cell>25K</cell><cell>28.2</cell></row><row><cell>WSJ</cell><cell>40K</cell><cell>25.5</cell></row><row><cell>Brown+WSJ</cell><cell>50K</cell><cell>22.4</cell></row><row><cell>GENIA</cell><cell>15K</cell><cell>5.3</cell></row><row><cell>Brown+WSJ+GENIA</cell><cell>60K</cell><cell>4.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Division of the GENIA combined treebank into development and test sections.</figDesc><table><row><cell>Source</cell><cell cols="2">Section</cell><cell cols="2">Abstract IDs</cell><cell>Sentences</cell></row><row><cell>Pilot</cell><cell cols="2">Development</cell><cell cols="2">99101510-99120900</cell><cell>215</cell></row><row><cell>Tsujii</cell><cell cols="2">Development</cell><cell cols="2">91079577-92060325</cell><cell>732</cell></row><row><cell>Tsujii</cell><cell>Test</cell><cell></cell><cell cols="2">92062170-94051535</cell><cell>1004</cell></row><row><cell></cell><cell cols="3">POS-Train</cell><cell>Development</cell><cell>Test</cell></row><row><cell cols="2">Sentences</cell><cell>19637</cell><cell></cell><cell>2181</cell><cell>2425</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Brown corpus division. Training and evaluation sections were obtained from Gildea<ref type="bibr" target="#b6">[7]</ref>. The development (and final training) section was created by extracting every tenth sentence from Gildea's training corpus.</figDesc><table><row><cell>Adaptation</cell><cell>F-measure</cell><cell>Error reduction</cell><cell>Significance</cell></row><row><cell>none</cell><cell>78.3</cell><cell>-</cell><cell>-</cell></row><row><cell>lexicon</cell><cell>78.6</cell><cell>1.4</cell><cell>p = 0.002</cell></row><row><cell>no NNP</cell><cell>79.1</cell><cell>3.7</cell><cell>p = 0.002</cell></row><row><cell>train POS</cell><cell>80.8</cell><cell>11.5</cell><cell>p &lt; 0.001</cell></row><row><cell>entities</cell><cell>80.9</cell><cell>12.0</cell><cell>p &lt; 0.001</cell></row><row><cell>no NNP, train POS</cell><cell>81.5</cell><cell>14.7</cell><cell>p = 0.043</cell></row><row><cell>no NNP, train POS, entities</cell><cell>82.9</cell><cell>21.2</cell><cell>p &lt; 0.001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>PARSEVAL f-measure scores on the GENIA development section using the adaptation methods described in Section 4. Statistical significance of individual adaptations are compared against no adaptation, and combined adaptations are compared against the best prior adaptation. As the p values indicate, all of the adaptions listed here produced a significant improvement in parse accuracy.</figDesc><table><row><cell>Corpus</cell><cell>F-measure</cell><cell>Error reduction</cell><cell>Significance</cell></row><row><cell>GENIA-unadapted</cell><cell>76.3</cell><cell>-</cell><cell>-</cell></row><row><cell>GENIA-adapted</cell><cell>79.6</cell><cell>14.2</cell><cell>p &lt; 0.001</cell></row><row><cell>Brown-unadapted</cell><cell>83.4</cell><cell>-</cell><cell>-</cell></row><row><cell>Brown-adapted</cell><cell>84.1</cell><cell>4.1</cell><cell>p = 0.002</cell></row><row><cell>WSJ</cell><cell>89.5</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Final PARSEVAL f-measure results on GENIA compared with scores on Brown and WSJ sect.<ref type="bibr" target="#b22">23</ref>. In all cases, the parser was trained on WSJ sect. 2-21 with the over-parsing parameter set to 21x over-parsing. Adapted GENIA results includes POS adaptations only (oracle-type entity adaptation was not used). Adapted Brown results use POS re-training on Brown train section.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>http://quest.ms.mff.cuni.cz/pdt/Tools/Tree Editors/Graph</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>http://www.cog.brown.edu/Research/nlp</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>Because our preliminary use of named-entities assumes oracle-knowledge, this experiment was carried out on the development section only, thus only the development section was reduced in this way.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>While this set of abstracts does overlap the Tsujii treebank, this experiment was run prior to the treebank's release.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>While PTB examples could be similarly pre-processed prior to training, thereby reducing the search space while parsing, the reduction would be minor and would mean giving up a potentially useful distinction in syntactic contexts.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We would like to thank the National Science Foundation for their support of this work (IIS-0112432, LIS-9721276, and DMS-0074276), as well as thank Sharon Goldwater and our anonymous reviewers for their valuable feeback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Genia corpus -a semantically annotated corpus for bio-textmining</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh International Conference on Intelligent Systems for Molecular Biology</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="180" to="182" />
		</imprint>
	</monogr>
	<note>Supplement</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The genia corpus: Medline abstracts annotated with linguistic information</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third meeting of SIG on Text Mining, Intelligent Systems for Molecular Biology (ISMB)</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A maximum-entropy-inspired parser</title>
		<author>
			<persName><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative reranking for natural language parsing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to parse natural language with maximum entropy models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Corpus variation and parser performance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2001 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="167" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised and unsupervised pcfg adaptation to novel domains</title>
		<author>
			<persName><forename type="first">B</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bacchiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="205" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Example selection for bootstrapping statistical parsers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ruhlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Crim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="331" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Literature mining in molecular biology</title>
		<author>
			<persName><forename type="first">B</forename><surname>De Bruijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Federation for Medical Informatics (EFMI) Workshop on Natural Language Processing in Biomedical Applications</title>
		<meeting>the European Federation for Medical Informatics (EFMI) Workshop on Natural Language Processing in Biomedical Applications</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Accomplishments and challenges in literature data mining for biology</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1553" to="1561" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Event extraction from biomedical papers using a full parser</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yakushiji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="408" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Extracting human protein interactions from medline using a full-sentence parser</title>
		<author>
			<persName><forename type="first">N</forename><surname>Daraselia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuryev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Egorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Novichkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nikitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="604" to="611" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mining the biomedical literature in the genomic era: An overview</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shatkay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="821" to="855" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning Probabilistic Lexicalized Grammars for Natural Language Processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hwa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bracketting Guideliness for Treebank II style Penn Treebank Project</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Macintyre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Implementation of the smart information retrieval system</title>
		<author>
			<persName><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<idno>85-686</idno>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Parsing inside-out</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lexical methods for managing variation in biomedical terminologies</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual Symposium on Computer Applications in Medical Care (SCAMC)</title>
		<meeting>the 18th Annual Symposium on Computer Applications in Medical Care (SCAMC)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="235" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparison of parsing technologies for the biomedical domain</title>
		<author>
			<persName><forename type="first">C</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lascarides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural Language Engineering</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using predicate-argument structures for information extraction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Aarseth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-03)</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics (ACL-03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Corpus-oriented grammar development for acquiring a head-driven phrase structure grammar from the penn treebank</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ninomiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCNLP-04</title>
		<meeting>of IJCNLP-04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="684" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploring deep knowledge resources in biomedical name recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Natural Language Processing in Biomedicine and its Applications (JNLPBA-04)</title>
		<meeting>the Joint Workshop on Natural Language Processing in Biomedicine and its Applications (JNLPBA-04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Statistical parsing with a context-free grammar and word statistics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth National Conference on Artificial Intelligence</title>
		<meeting>the Fourteenth National Conference on Artificial Intelligence<address><addrLine>Menlo Park</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press/MIT Press</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using combinatory categorical grammar to extract biomedical information</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="62" to="67" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
