<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning in Visual Computing and Signal Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-02-19">19 February 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Danfeng</forename><surname>Xie</surname></persName>
							<email>danfeng.xie@temple.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Temple University</orgName>
								<address>
									<postCode>19121</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Temple University</orgName>
								<address>
									<postCode>19121</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Temple University</orgName>
								<address>
									<postCode>19121</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning in Visual Computing and Signal Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-02-19">19 February 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">2D2AD3C59E9315ACDC1A3B4B6E0D6E63</idno>
					<idno type="DOI">10.1155/2017/1320780</idno>
					<note type="submission">Received 21 October 2016; Revised 15 December 2016; Accepted 15 January 2017;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning is a subfield of machine learning, which aims to learn a hierarchy of features from input data. Nowadays, researchers have intensively investigated deep learning algorithms for solving challenging problems in many areas such as image classification, speech recognition, signal processing, and natural language processing. In this study, we not only review typical deep learning algorithms in computer vision and signal processing but also provide detailed information on how to apply deep learning to specific areas such as road crack detection, fault diagnosis, and human activity detection. Besides, this study also discusses the challenges of designing and training deep neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning methods are a group of machine learning methods that can learn features hierarchically from lower level to higher level by building a deep architecture. The deep learning methods have the ability to automatically learn features at multiple levels, which makes the system be able to learn complex mapping function ùëì : ùëã ‚Üí ùëå directly from data, without help of the human-crafted features. This ability is crucial for high-level feature abstraction since highlevel features are difficult to be described directly from raw training data. Moreover, with the sharp growth of data, the ability to learn high-level features automatically will be even more important.</p><p>The most characterizing feature of deep learning methods is that their models all have deep architectures. A deep architecture means it has multiple hidden layers in the network. In contrast, a shallow architecture has only few hidden layers (1 to 2 layers). Deep architectures are loosely inspired by mammal brain. When given an input percept, mammal brain processes it using different area of cortex which abstracts different levels of features. Researchers usually describe such concepts in hierarchical ways, with many levels of abstraction. Furthermore, mammal brains also seem to process information through many stages of transformation and representation. A very clear example is that the information in the primate visual system is processed in a sequence of stages: edge detection, primitive shapes, and more complex visual shapes.</p><p>Inspired by the deep architecture of mammal brain, researchers investigated deep neural networks for two decades but did not find effective training methods before 2006: researchers only obtained good experimental results of neural network with one or two hidden layers but could not get good results of neural network with more hidden layers. In 2006, Hinton et al. proposed deep belief networks (DBNs) <ref type="bibr" target="#b0">[1]</ref>, with a learning algorithm that uses unsupervised learning algorithm to greedily train deep neural network layer by layer. This training method, which is called deep learning, turns out to be very effective and efficient in training deep neural networks.</p><p>Many other deep architectures, that is, autoencoder, deep convolutional neural networks, and recurrent neural networks, are successfully applied in various areas. Regression <ref type="bibr" target="#b1">[2]</ref>, classification <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>, dimensionality reduction <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, modeling motion <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, modeling textures <ref type="bibr" target="#b13">[14]</ref>, information retrieval <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>, natural language processing <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>, robotics <ref type="bibr" target="#b20">[21]</ref>, fault diagnosis <ref type="bibr" target="#b21">[22]</ref>, and road crack detection <ref type="bibr" target="#b22">[23]</ref> have seen increasing deep learning-related research studies. There are mainly three crucial reasons for the rapid development of deep learning applications nowadays: the big leap of deep learning algorithms, the significantly increased computational abilities, and the sharp drop of price in hardware.</p><p>This survey provides an overview of several deep learning algorithms and their emerging applications in several specific areas, featuring face recognition, road crack detection, fault diagnosis, and falls detection. As complementarity to existing review papers <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, we not only review the state-of-the-art deep learning methods but also provide detailed information on how to apply deep learning to specific problems. The reminder of this paper is organized as follows. In Section 2, the two categories of deep learning algorithms are introduced: restricted Boltzmann machines (RBMs) and convolutional neural networks (CNNs). The training strategies are discussed in Section 3. In Section 4, we describe several specific deep learning applications, that is, face recognition, road crack detection, fault diagnosis, and human activity detection. In Section 5, we discuss several challenges of training and using the deep neural networks. In Section 6, we conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Deep Learning Algorithms</head><p>Deep learning algorithms have been extensively studied in recent years. As a consequence, there are a large number of related approaches. Generally speaking, these algorithms can be grouped into two categories based on their architectures: restricted Boltzmann machines (RBMs) and convolutional neural networks (CNNs). In the following sections, we will briefly review these deep learning methods and their developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Deep Neural Network. This section introduces how to build and train RBM-based deep neural networks (DNNs).</head><p>The building and training procedures of a DNN contain two steps. First, build a deep belief network (DBN) by stacking restricted Boltzmann machines (RBMs) and feed unlabeled data to pretrain the DBN. The pretrained DBN provides initial parameters for the deep neural network. In the second step, labeled data is fed to train the DNN using backpropagation. After two steps of training, a trained DNN is obtained. This section is organized as follows. Section 2.1.1 introduces RBM, which is the basic component of DBN. In Section 2.1.2, RBM-based DNN is introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Restricted Boltzmann Machines.</head><p>RBM is an energybased probabilistic generative model <ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref>. It is composed of one layer of visible units and one layer of hidden units. The visible units represent the input vector of a data sample and the hidden units represent features that are abstracted from the visible units. Every visible unit is connected to every hidden unit, whereas no connection exists within the visible layer or hidden layer. Figure <ref type="figure">1</ref> illustrates the graphical model of restricted Boltzmann machine.</p><p>As a result of the lack of hidden-hidden and input-input interactions, the energy function of a RBM is</p><formula xml:id="formula_0">Energy (k, h; ùúÉ) = -b ùëá k -c ùëá h -h ùëá Wk,<label>(1)</label></formula><p>where ùúÉ = {W, b, c} are the parameters of RBM and they need to be learned during the training procedure; W denotes the weights between the visible layer and hidden layer; b and c</p><formula xml:id="formula_1">‚Ñé 0 ‚Ñé 1 ‚Ñé 2 ‚Ñé i 0 1 i ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ Figure 1: Restricted Boltzmann machine.</formula><p>are the bias of the visible layer and hidden layer, respectively; this model is called binary RBM because the vectors v and h only contain binary values (0 or 1).</p><p>We can obtain a tractable expression for the conditional probability ùëÉ(‚Ñé | V) <ref type="bibr" target="#b29">[30]</ref>:</p><formula xml:id="formula_2">ùëÉ (‚Ñé | V) = exp (b ùëá k + c ùëá h + h ùëá Wk) ‚àë h exp (b ùëá k + c ùëá h + hùëá Wk) = ‚àè ùëñ exp (c ùëñ h ùëñ + h ùëñ W ùëñ k) ‚àè ùëñ ‚àë hùëñ exp (c ùëñ hùëñ + hùëñ W ùëñ k) = ‚àè ùëñ exp (h ùëñ (c ùëñ + W ùëñ k)) ‚àë hùëñ exp ( hùëñ (c ùëñ + W ùëñ k)) = ‚àè ùëñ ùëÉ (h ùëñ | V) .<label>(2)</label></formula><p>For binary RBM, where ‚Ñé ùëñ ‚àà {0, 1}, the equation for a hidden unit's output given its input is</p><formula xml:id="formula_3">ùëÉ (‚Ñé ùëñ = 1 | V) = ùëí ùëê ùëñ +ùëä ùëñ V 1 + ùëí ùëê ùëñ +ùëä ùëñ V = sigm (ùëê ùëñ + ùëä ùëñ V) .<label>(3)</label></formula><p>Because V and ‚Ñé play a symmetric role in the energy function, the following equation can be derived:</p><formula xml:id="formula_4">ùëÉ (V | ‚Ñé) = ‚àè ùëñ ùëÉ (V ùëñ | ‚Ñé) ,<label>(4)</label></formula><p>and for the visible unit V ùëó ‚àà {0, 1}, we have</p><formula xml:id="formula_5">ùëÉ (V ùëó = 1 | ‚Ñé) = sigm (ùëè ùëó + ùëä ùëá ‚ãÖùëó ‚Ñé) ,<label>(5)</label></formula><p>where ùëä ‚ãÖùëó is the ùëóth column of ùëä.</p><p>Although binary RBMs can achieve good performance when dealing with discrete inputs, they have limitations to handle continuous-valued inputs due to their structure. Thus, in order to achieve better performance on continuous-valued inputs, Gaussian RBMs are utilized for the visible layer <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31]</ref>. The energy function of a Gaussian RBM is</p><formula xml:id="formula_6">Energy (k, h) = ‚àë ùëñ (V ùëñ -ùëé ùëñ ) 2 2ùúé 2 ùëñ -‚àë ùëñùëó ùë§ ùëñùëó ‚Ñé ùëó V ùëñ ùúé ùëñ -‚àë ùëó ùëê ùëó ‚Ñé ùëó ,<label>(6)</label></formula><p>where ùëé ùëñ and ùúé ùëñ are the mean and the standard deviation of visible unit ùëñ. Note here that only the visible layer V is continuous-valued and hidden layer ‚Ñé is still binary. In practical situation, the input data is normalized, which makes ùëé ùëñ = 0 and ùúé ùëñ = 1. Therefore, <ref type="bibr" target="#b5">(6)</ref> becomes  2.1.2. Deep Neural Network. Hinton et al. <ref type="bibr" target="#b0">[1]</ref> showed that RBMs can be stacked and trained in a greedy manner to form so-called deep belief networks (DBNs) <ref type="bibr" target="#b31">[32]</ref>. DBNs are graphical models which learn to extract deep hierarchical representation of the training data. A DBN model with ùëô layers models the joint distribution between observed vector V and ‚Ñì hidden layers ‚Ñé ùëò as follows <ref type="bibr" target="#b29">[30]</ref>: <ref type="bibr" target="#b7">(8)</ref> where V = ‚Ñé 0 , ùëÉ(‚Ñé ùëò-1 | ‚Ñé ùëò ) is a conditional distribution for the visible units conditioned on the hidden units of the RBM at level ùëò and ùëÉ(‚Ñé ‚Ñì-1 , ‚Ñé ‚Ñì ) is the visible-hidden joint distribution in the top-level RBM. This is illustrated in Figure <ref type="figure">2</ref>.</p><formula xml:id="formula_7">Energy (k, h) = 1 2 k ùëá k -c ùëá h -h ùëá Wk.<label>(7)</label></formula><formula xml:id="formula_8">‚Ñé 1 ‚Ñé 1 ‚Ñé 1 ‚Ñé 2 ‚Ñé 2 ‚Ñé 2 ‚Ñé 3 ‚Ñé 3 v ‚Ñé 1 ‚Ñé 2 ‚Ñé 3 {W 3 , b 3 , c 3 } {W 3 , b 3 , c 3 } {W 3 , b 3 , c 3 } {W 1 , b 1 , c 1 } {W 1 , b 1 , c 1 } {W 1 , b 1 , c 1 } {W 2 , b 2 , c 2 } {W 2 , b 2 , c 2 } {W 2 , b 2 , c 2 }</formula><formula xml:id="formula_9">ùëÉ (V, ‚Ñé 1 , . . . , ‚Ñé ‚Ñì ) = ( ‚Ñì-2 ‚àè ùëò=0 ùëÉ (‚Ñé ùëò | ‚Ñé ùëò+1 )) ùëÉ (‚Ñé ‚Ñì-1 , ‚Ñé ‚Ñì ) ,</formula><p>As Figure <ref type="figure">2</ref> shows, the hidden layer of low-level RBM is the visible layer of high-level RBM, which means that the output of low-level RBM is the input of high-level RBM. By using this structure, the high-level RBM is able to learn high-level features from low-level features generated from the low-level RBM. Thus, DBN allows latent variable space in its hidden layers. In order to train a DBN effectively, we need to train its RBM from low level to high level successively.</p><p>After the unsupervised pretraining step for DBN, the next step is to use parameters from DBN to initialize the DNN and do supervised training for DNN using back-propagation. The parameters of the ùëÅ-layer DNN are initialized as follows: parameters {ùëä ùëõ , ùëê ùëõ } (ùëô = 1,...,ùëÅ) except the top layer parameters are set the same as the DBN, and the top layer weights {ùëä ùëÅ , ùëê ùëÅ } are initialized stochastically. After that, the whole network can be fine-tuned by back-propagation in a supervised way using labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Convolutional Neural Network.</head><p>Convolutional neural network is one of the most powerful classes of deep neural networks in image processing tasks. It is highly effective and commonly used in computer vision applications <ref type="bibr" target="#b32">[33]</ref>. The convolution neural network contains three types of layers: convolution layers, subsampling layers, and full connection layers. The whole architecture of convolutional neural network is shown in Figure <ref type="figure">3</ref>. A brief introduction to each type of layer is provided in the following paragraphs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Convolution Layer.</head><p>As Figure <ref type="figure" target="#fig_2">4</ref> shows, in convolution layer, the left matrix is the input, which is a digital image, and the right matrix is a convolution matrix. The convolution layer takes the convolution of the input image with the convolution matrix and generates the output image. Usually the convolution matrix is called filter and the output image is called filter response or filter map. An example of convolution calculation is demonstrated in Figure <ref type="figure">5</ref>. Each time, a block of pixels is convoluted with a filter and generates a pixel in a new image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Subsampling Layer.</head><p>The subsampling layer is an important layer to convolutional neural network. This layer is mainly to reduce the input image size in order to give the neural network more invariance and robustness. The most used method for subsampling layer in image processing tasks is max pooling. So the subsampling layer is frequently called max pooling layer. The max pooling method is shown in Figure <ref type="figure">6</ref>. The image is divided into blocks and the maximum value of each block is the corresponding pixel value of the output image. The reason to use subsampling layer is as follows. First, the subsampling layer has fewer parameters and it is faster to train. Second, a subsampling layer makes convolution layer tolerate translation and rotation among the input pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Full Connection Layer.</head><p>Full connection layers are similar to the traditional feed-forward neural layer. They make the neural network fed forward into vectors with a predefined length. We could fit the vector into certain categories or take it as a representation vector for further processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Training Strategy</head><p>Compared to conventional machine learning methods, the advantage of the deep learning is that it can build deep architectures to learn more multiscale abstract features. Unfortunately, the large amount of parameters of the deep architectures may lead to overfitting problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Augmentation.</head><p>The key idea of data augmentation is to generate additional data without introducing extra labeling costs. In general, the data augmentation is achieved by deforming the existing ones. Mirroring, scaling, and rotation are the most common methods for data augmentation <ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref>. Wu et al. extended the deforming idea to color space, the provided color casting, vignetting, and lens distortion For visual tasks, when it is hard to get sufficient data, a recommendable way is to fine-tune the pretrained CNN by natural images (e.g., ImageNet) and then use specific data set to fine-tune the CNN <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>. Tajbakhsh et al. showed that, for medical applications, the use of a pretrained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch <ref type="bibr" target="#b37">[38]</ref>.</p><p>On the other hand, the deep learning architecture contains hundreds of thousands of parameters to be initialized even with sufficient data. Erhan et al. provided the evidence to explain that the pretraining step helps train deep architectures such as deep belief networks and stacked autoencoders <ref type="bibr" target="#b39">[40]</ref>. Their experiments supported a regularization explanation for the effect of pretraining, which helps the deeplearned model obtain better generalization from the training data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Applications</head><p>Deep learning has been widely applied in various fields, such as computer vision <ref type="bibr" target="#b24">[25]</ref>, signal processing <ref type="bibr" target="#b23">[24]</ref>, and speech recognition <ref type="bibr" target="#b40">[41]</ref>. In this section, we will briefly review several recently developed applications of deep learning (all the results are referred from the original papers).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">CNN-Based Applications in Visual</head><p>Computing. As we know, convolutional neural networks are very powerful tools for image recognition and classification. These different types of CNNs are often tested on well-known ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) data set and achieved state-of-the-art performance in recent years <ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref>. After winning the ImageNet competition in 2012 <ref type="bibr" target="#b41">[42]</ref>, the CNN-based methods have brought about a revolution in computer vision. CNNs have been applied with great success to the object detection <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46]</ref>, object segmentation <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>, and recognition of objects and regions in images <ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref>. Compared with hand-crafted features, for example, Local Binary Patterns (LBP) <ref type="bibr" target="#b54">[55]</ref> and Scale Invariant Feature Transform (SIFT) <ref type="bibr" target="#b55">[56]</ref>, which need additional classifiers to solve vision problems <ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref>, the CNNs can learn the features and the classifiers jointly and provide superior performance. In next subsection, we review how the deep-learned CNN is applied to recent face recognition and road crack detection problem in order to provide an overview for applying the CNN to specific problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">CNN for Face Recognition.</head><p>Face recognition has been one of the most important computer vision tasks since the 1970s <ref type="bibr" target="#b59">[60]</ref>. Face recognition systems typically consist of four steps. First, given an input image with one or more faces, a face detector locates and isolates faces. Then, each face is preprocessed and aligned using either 2D or 3D modeling methods. Next, a feature extractor extracts features from an aligned face to obtain a low-dimensional representation (or embedding). Finally, a classifier makes predictions based on the low-dimensional representation. The key to get good performances for face recognition systems is obtaining an effective low-dimensional representation. Face recognition systems using hand-crafted features include <ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref>. Lawrence et al. <ref type="bibr" target="#b64">[65]</ref> first proposed using CNNs for face recognition. Currently, the state-of-the-art performance of face recognition systems, that is, Facebook's DeepFace <ref type="bibr" target="#b65">[66]</ref> and Google's FaceNet <ref type="bibr" target="#b66">[67]</ref>, are based on CNNs. Other notable CNN-based face recognition systems are lightened convolutional neural networks <ref type="bibr" target="#b67">[68]</ref> and Visual Geometry Group (VGG) Face Descriptor <ref type="bibr" target="#b68">[69]</ref>.</p><p>Figure <ref type="figure" target="#fig_3">7</ref> shows the logic flow of CNN-based face recognition systems. Instead of using hand-crafted features, CNNs are directly applied to RGB pixel values and used as a feature extractor to provide a low-dimensional representation characterizing a person's face. In order to normalize the input image to make the face robust to different view angles, DeepFace <ref type="bibr" target="#b65">[66]</ref> models a face in 3D and aligns it to appear as a frontal face. Then, the normalized input is fed to a single convolution-pooling-convolution filter. Next, 3 locally connected layers and 2 fully connected layers are used to make Table <ref type="table">1</ref>: Experiment results on LFW benchmark <ref type="bibr" target="#b69">[70]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Technique</head><p>Accuracy Human-level (cropped) <ref type="bibr" target="#b73">[74]</ref> 0.9753 FaceNet <ref type="bibr" target="#b66">[67]</ref> 0.9964 ¬± 0.009 DeepFace-ensemble <ref type="bibr" target="#b65">[66]</ref> 0.9735 ¬± 0.0025 OpenFace <ref type="bibr" target="#b69">[70]</ref> 0.9292 ¬± 0.0134 final predictions. The architecture of DeepFace is shown in Figure <ref type="figure" target="#fig_4">8</ref>. Though DeepFace achieves the best performance on face recognition up to date, its representation is difficult to interpret and use because the faces of the same person are not clustered necessarily during the training process. In contrast, FaceNet defines a triplet loss function directly on the representation, which makes the training procedure learn to cluster face representation of the same person <ref type="bibr" target="#b69">[70]</ref>. It should also be noted that OpenFace uses a simple 2D affine transformation to align face input. Nowadays, face recognition in mobile computing is a very attractive topic <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b71">72]</ref>. While DeepFace and FaceNet remain private and are of large size, OpenFace <ref type="bibr" target="#b69">[70]</ref> offers a lightweighted, real-time, and open-source face recognition system with competitive accuracy, which is suitable for mobile computing. OpenFace implements FaceNet's architecture but it is one order of magnitude smaller than DeepFace and two orders of magnitude smaller than FaceNet. Their performances are compared on Labeled Faces in the Wild data set (LFW) <ref type="bibr" target="#b72">[73]</ref>, which is a standard benchmark in face recognition. The experiment results are demonstrated in Table <ref type="table">1</ref>. Though the accuracy of OpenFace is slightly lower than the state of the art, its smaller size and fast execution time show great potential in mobile face recognition scenarios.   medical problems, a deep learning based method for crack detection is proposed <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">CNN for</head><p>Data Preparation. A data set with more than 500 pavement pictures of size 3264 √ó 2448 is collected at the Temple University campus by using a smartphone as the data sensor. Each image is annotated by multiple annotators. Patches of size 99 √ó 99 are used for training and testing the proposed method. 640,000 patches, 160,000 patches, and 200,000 patches are selected as training set, validation set, and testing set, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design and Train the CNN.</head><p>A deep learning architecture is designed, which is illustrated in Figure <ref type="figure" target="#fig_5">9</ref> and conv, mp, and fc represent convolutional, max pooling, and fully connected layers, respectively. The CNNs are trained using the stochastic gradient descent (SGD) method on GPU with a batch size of 48 examples, momentum of 0.9, and weight decay of 0.0005. Less than 20 epochs are needed to reach a minimum on the validation set. The dropout method is used between two fully connected layers with a probability of 0.5 and the rectified linear units (ReLU) as the activation function.</p><p>Evaluate the Performance of the CNN. The proposed method is compared against the support vector machine (SVM) and the Boosting methods. The features for training the SVM and the Boosting method are based on color and texture of each patch which are associated with a binary label indicating the presence or absence of cracked pavement. The feature vector is 93-dimensional and is composed of color elements, histograms of textons, and LBP descriptor within the patch.</p><p>The Receiver Operating Characteristic (ROC) curves of the proposed method, the SVM, and the Boosting method are shown in Figure <ref type="figure" target="#fig_6">10</ref>. Both the ROC curve and Area under the Curve (AUC) of the proposed method indicate that the proposed deep learning based method can outperform the shallow structure learned from hand-crafted features. In addition, more comprehensive experiments are conducted on 300 √ó 300 scenes as shown in Figure <ref type="figure" target="#fig_7">11</ref>.</p><p>For each scene, each row shows the original image with crack, ground truth, and probability maps generated by the SVM and the Boosting methods and that by the ConvNet. The pixels in green and in blue denote the crack and the noncrack, respectively, and higher brightness means higher confidence. The SVM cannot distinguish the crack from the background, and some of the cracks have been misclassified. Compared to the SVM, the Boosting method can detect the cracks with a higher accuracy. However, some of the background patches are classified as cracks, resulting in isolated green parts in Figure <ref type="figure" target="#fig_7">11</ref>. In contrast to these two methods, the proposed method provides superior performance in correctly classifying crack patches from background ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">DBN-Based Applications in Signal Processing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">DNN for Fault Diagnosis.</head><p>Plant faults may cause abnormal operations, emergency shutdowns, equipment damage, or even casualties. With the increasing complexity of modern plants, it is difficult even for experienced operators to diagnose faults fast and accurately. Thus, designing an intelligent fault detection and diagnose system to aid human operators is a critical task in process engineering. Data-driven methods for fault diagnosis are becoming very popular in recent years, since they utilize powerful machine learning algorithms. Conventional supervised learning algorithms used for fault diagnosis are Artificial Neural Networks <ref type="bibr" target="#b75">[76]</ref><ref type="bibr" target="#b76">[77]</ref><ref type="bibr" target="#b77">[78]</ref><ref type="bibr" target="#b78">[79]</ref><ref type="bibr" target="#b79">[80]</ref><ref type="bibr" target="#b80">[81]</ref> and support vector machines <ref type="bibr" target="#b81">[82]</ref><ref type="bibr" target="#b82">[83]</ref><ref type="bibr" target="#b83">[84]</ref>. As one of emerging machine learning techniques, deep learning techniques are investigated for fault diagnosis in a few current studies <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b84">[85]</ref><ref type="bibr" target="#b85">[86]</ref><ref type="bibr" target="#b86">[87]</ref><ref type="bibr" target="#b87">[88]</ref>. This subsection reviews a study which uses Hierarchical Deep Neural Network (HDNN) <ref type="bibr" target="#b21">[22]</ref> to diagnose faults in a well-known data set called Tennessee Eastman Process (TEP).</p><p>TEP is a simulation model that simulates a real industry process. The model was first created by Eastman Chemical Company <ref type="bibr" target="#b74">[75]</ref>. It consists of five units: a condenser, a compressor, a reactor, a separator, and a stripper. Two liquid products G and H are produced from the process with the gaseous inputs A, C, D, and E and the inert component B. The flowsheet of TEP is shown in Figure <ref type="figure" target="#fig_8">12</ref>.</p><p>Data Preparation. The TEP is monitored by a network of sensors that collect measurement at the same sampling time. At the ùëñth sample, the state of ùëöth sensor is represented by a scalar ùë• ùëö ùëñ . By combining all ùëÄ sensors, the state of the whole process in ùëñth sampling interval is represented as a row vector</p><formula xml:id="formula_10">ùë• ùëñ = [ùë• 1 ùëñ , ùë• 2 ùëñ , . . . , ùë• ùëÄ ùëñ ].</formula><p>The fault occurring at the ùëñth sampling interval is indicated with class label ùë¶ ùëñ ‚àà {1, 2, . . . , ùê∂}, where value 1 to ùê∂ represents one of ùê∂ fault types. There are total ùëÅ historical observations collected from all ùëÄ sensors to form a data set ùê∑ = {(ùë• ùëñ , ùë¶ ùëñ ), ùëñ = 1, 2, . . . , ùëÅ, ùë¶ ùëñ ‚àà {1, 2, . . . , ùê∂}}. The objective of fault diagnosis is to train a classification ‚Ñé : ùë• ùëñ ‚Üí ùë¶ ùëñ given data set ùê∑ = {(ùë• ùëñ , ùë¶ ùëñ ), ùëñ = 1, 2, . . . , ùëÅ}.</p><p>For each simulation run, the simulation starts without faults and the faults are introduced at sample 1. Each run collects a total of 1000 pieces of sample data. Each single fault type has 5 independent simulation runs. The Tennessee Eastman Process has 20 different predefined faults but faults Design and Train the HDNN. The general diagnosis scheme of HDNN <ref type="bibr" target="#b21">[22]</ref> is as follows. The symptom data generated by simulation is transmitted to a supervisory DNN. The supervisory DNN then classifies symptom data into different groups and triggers the DNN which is specially trained for that group to do further fault diagnosis. Figure <ref type="figure" target="#fig_9">13</ref> illustrates the fault diagnosis scheme of the HDNN, where each agent represents a DNN.</p><p>Evaluate the Performance of the DNN. The experiment result of the HDNN is compared to single neural network and Duty-Oriented Hierarchical Artificial Neural Network (DOHANN) <ref type="bibr" target="#b75">[76]</ref> and is shown in Figure <ref type="figure" target="#fig_10">14</ref>. 7 out of 17 faults have been diagnosed with 90% accuracy. The highest Correct Classification Rate (CCR) is 99.6% from fault 4, while the lowest CCR is 50.4% from fault 13. The average CCR of our method is 80.5%, while the average of CCRs of SNN and DOHANN is 49.7% and 70.7%, respectively. It demonstrates that the DNN-based algorithm outperforms other conventional NN-based algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">DNN for Human Activity Detection.</head><p>Human activity detection has drawn much attention from researchers due to high demands for security, law enforcement, and health care <ref type="bibr" target="#b89">[90]</ref><ref type="bibr" target="#b90">[91]</ref><ref type="bibr" target="#b91">[92]</ref><ref type="bibr" target="#b92">[93]</ref>. In contrast to using cameras to detect human activity, sensors such as worn accelerometers or in-home radar which use signals to detect human activities are robust to environmental conditions such as weather conditions and light variations <ref type="bibr" target="#b93">[94]</ref><ref type="bibr" target="#b94">[95]</ref><ref type="bibr" target="#b95">[96]</ref><ref type="bibr" target="#b96">[97]</ref><ref type="bibr" target="#b97">[98]</ref><ref type="bibr" target="#b98">[99]</ref>. Nowadays, there are a few emerging research works that focus on using deep learning technologies to detect human activities based on signals <ref type="bibr" target="#b88">[89,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b99">100]</ref>.</p><p>Fall detection is one of the very important human activity detection scenarios for researchers, since falls are a main cause of both fatal and nonfatal injuries for the elderly. Khan and Taati <ref type="bibr" target="#b99">[100]</ref> proposed a deep learning method for falls detection based on signals collected from wearable devices. They propose an ensemble of autoencoders to extract features from each channel of sensing data. Unlike wearable devices which are intrusive and easily broken and must be carried, in-home radars which are safe, nonintrusive, and robust to lighting conditions show their advantages for fall detection. Jokanovic et al. <ref type="bibr" target="#b88">[89]</ref> proposed a method that uses deep learning to detect fall motion through in-home radar. The procedure is demonstrated in Figure <ref type="figure">15</ref>. They first denoise and normalize the spectrogram as input. Then, stacked autoencoders are performed as a feature extractor. On top of the stacked autoencoders, a softmax regression classifier is used to make predictions. The whole model is compared with a SVM model. Experiment results show that the overall correct classification rate for deep learning approach is 87%, whereas the overall correct classification rate for SVM is 78%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Challenges</head><p>Though deep learning techniques achieve promising performance on multiple fields, there are still several big challenges as research articles indicate. These challenges are described as follows. Recently, two possible solutions draw attention from researchers. One of the solutions is to generalize new training data from original training data using multiple data augmentation methods. Traditional ones include rotation, scaling, and cropping. In addition to these, Wu et al. <ref type="bibr" target="#b36">[37]</ref> adopted vignetting, color casting, and lens distortion techniques. These techniques can further produce more different training examples. Another solution is to obtain more training data using weak learning algorithms. Song et al. <ref type="bibr" target="#b100">[101]</ref> proposed a weakly supervised method that can label image-level objectpresence. This method helps to reduce laborious bounding box annotation costs while generating training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training with</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Time Complexity.</head><p>Training deep neural network is very time-consuming in early years. It needs a large amount of computational resources and is not suitable for realtime applications. By default, GPUs are used to accelerate training of large DNNs with the help of parallel computing technique. Thus, it is important to make the most of GPU computing ability when training DNNs. He and Sun <ref type="bibr" target="#b101">[102]</ref> investigated training CNN under time cost constrains and proposed fast training methods for real-world applications while having similar performance as existing CNN models. Li et al. <ref type="bibr" target="#b102">[103]</ref> remove all the redundant computations during training CNNs for pixel wise classification, which leads to a speedup of 1500 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Theoretical Understanding.</head><p>Though deep learning algorithms achieve promising results on many tasks, the underlying theory is still not very clear. There are many questions that need to be answered. For instance, which architecture is better than other architectures in certain task? How many layers and how many nodes in each layer should be chosen in a DNN? Besides, there are a few hyperparameters such as learning rate, dropout rate, and the strength of regularizer which need to be tuned with specific knowledge.</p><p>Several approaches are developed to help researchers to get better understanding in DNN. Zeiler and Fergus <ref type="bibr" target="#b42">[43]</ref> proposed a visualization method that illustrates features in intermediate layers. It displays intermediate features in interpretable patterns, which may help design better architectures for future DNNs. In addition to visualizing features, Girshick et al. <ref type="bibr" target="#b48">[49]</ref> tried to discover the learning pattern of CNN by testing the performance layer by layer during the training process. It demonstrates that convolutional layers can learn more generalized features.</p><p>Although there is progress in understanding the theory of deep learning, there is still large room to improve in deep learning theory aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper gives an overview of deep learning algorithms and their applications. Several classic deep learning algorithms such as restricted Boltzmann machines, deep belief networks, and convolutional neural networks are introduced. In addition to deep learning algorithms, their applications are</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Deep belief network structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Digital image representation and convolution matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Logic flow of CNN-based face recognition [70].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Outline of DeepFace architecture [66].</figDesc><graphic coords="6,86.34,73.88,425.80,93.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Illustration of the architecture of the proposed ConvNet [23].</figDesc><graphic coords="6,128.88,199.88,102.52,96.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: ROC curves [23].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Probability maps.</figDesc><graphic coords="7,72.63,308.06,453.58,86.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Tennessee Eastman Process [75].</figDesc><graphic coords="8,86.64,74.24,425.23,284.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Schematic diagram of HDNN [22].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 14 :</head><label>14</label><figDesc>Figure14: Correct classification rate of SNN, DOHANN<ref type="bibr" target="#b75">[76]</ref>, and HDNN<ref type="bibr" target="#b21">[22]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Road Crack Detection. Automatic detection of pavement cracks is an important task in transportation maintenance for driving safety assurance. Inspired by recent success in applying deep learning to computer vision and</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Representation Representation</cell><cell>SFC labels SFC labels</cell></row><row><cell></cell><cell></cell><cell>C1: C C1:</cell><cell>M2: M2:</cell><cell>C3: C3:</cell><cell>L4: L4:</cell><cell>L5: L5:</cell><cell>L6: L6:</cell><cell>F7: F7:</cell><cell>F8: F8:</cell></row><row><cell>Detection &amp; localization Detection &amp; localization</cell><cell>152 √ó 152 √ó 3 Frontalization: @ 152 √ó 152 √ó 3 @ Frontalization:</cell><cell>32 √ó 11 √ó 11 √ó 3 142 √ó 142 @ 32 √ó 11 √ó 11 √ó 3 142 √ó 142 @</cell><cell>32 √ó 3 √ó 3 √ó 32 71 √ó 71 @ 32 √ó 3 √ó 3 √ó 32 71 √ó 71 @</cell><cell>16 √ó 9 √ó 9 √ó 32 63 √ó 63 @ 16 √ó 9 √ó 9 √ó 32 63 √ó 63 @</cell><cell>16 √ó 9 √ó 9 √ó 16 55 √ó 55 @ 16 √ó 9 √ó 9 √ó 16 55 √ó 55 @</cell><cell>16 √ó 7 √ó 7 √ó 16 25 √ó 25 @ 16 √ó 7 √ó 7 √ó 16 25 √ó 25 @</cell><cell cols="2">16 √ó 5 √ó 5 √ó 16 4096d 21 √ó 21 @ 16 √ó 5 √ó 5 √ó 16 4096d 21 √ó 21 @</cell><cell>4030d 4030d</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Limited Data. Training deep neural network usually needs large amounts of data as larger training data set can prevent deep learning model from overfitting.Limited training data may severely affect the learning ability of a deep neural network. Unfortunately, there are many applications that lack sufficient labeled data to train a DNN. Thus, how to train DNN with limited data effectively and efficiently becomes a hot topic.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>reviewed and compared with other machine learning methods. Though deep neural networks achieve good performance on many tasks, they still have many properties that need to be investigated and justified. We discussed these challenges and pointed out several new trends in understanding and developing deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing Interests</head><p>The authors declare that there is no conflict of interests regarding the publication of this paper.</p><p>Submit your manuscripts at https://www.hindawi.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computer Games Technology</head><p>International Journal of </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using deep belief nets to learn covariance kernels for Gaussian processes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual Conference on Neural Information Processing Systems (NIPS &apos;07)</title>
		<meeting>the 21st Annual Conference on Neural Information Processing Systems (NIPS &apos;07)<address><addrLine>Vcancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-12">December 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Training hierarchical feed-forward visual recognition models using transfer learning from pseudo-tasks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the in European Conference on Computer Vision</title>
		<meeting>the in European Conference on Computer Vision<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008-10">October 2008</date>
			<biblScope unit="page" from="69" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 19 (NIPS &apos;06)</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An empirical evaluation of deep architectures on problems with many factors of variation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning (ICML &apos;07)</title>
		<meeting>the 24th International Conference on Machine Learning (ICML &apos;07)<address><addrLine>Corvalis, Ore, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007-06">June 2007</date>
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning (ICML &apos;09)</title>
		<meeting>the 26th Annual International Conference on Machine Learning (ICML &apos;09)<address><addrLine>Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-06">June 2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sparse feature learning for deep belief networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1185" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poultney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual Conference on Neural Information Processing Systems (NIPS &apos;06)</title>
		<meeting>the 20th Annual Conference on Neural Information Processing Systems (NIPS &apos;06)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-12">December 2006</date>
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning a nonlinear embedding by preserving class neighbourhood structure</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Artificial Intelligence and Statistics (AISTATS &apos;07)</title>
		<meeting>the 8th International Conference on Artificial Intelligence and Statistics (AISTATS &apos;07)<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-03">March 2007</date>
			<biblScope unit="page" from="412" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Factored conditional restricted Boltzmann machines for modeling motion style</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning(ICML &apos;09)</title>
		<meeting>the 26th Annual International Conference on Machine Learning(ICML &apos;09)<address><addrLine>Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-06">June 2009</date>
			<biblScope unit="page" from="1025" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling human motion using binary latent variables</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1345" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling image patches with a directed hierarchy of Markov random fields</title>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1121" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of compact document representations with deep networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="792" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic hashing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="969" to="978" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Many-layered learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Utgoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Stracuzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2497" to="2529" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: deep neural networks with multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A scalable hierarchical distributed language model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual Conference on Neural Information Processing Systems (NIPS &apos;08)</title>
		<meeting>the 22nd Annual Conference on Neural Information Processing Systems (NIPS &apos;08)<address><addrLine>British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-12">December 2008</date>
			<biblScope unit="page" from="1081" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="639" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep belief net learning in a long-range vision system for autonomous off-road driving</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scoffier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS &apos;08)</title>
		<meeting>the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS &apos;08)<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09">September 2008</date>
			<biblScope unit="page" from="628" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical deep neural network for fault diagnosis on Tennessee-Eastman process</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 14th International Conference on Machine Learning and Applications (ICMLA &apos;15)</title>
		<meeting>the IEEE 14th International Conference on Machine Learning and Applications (ICMLA &apos;15)<address><addrLine>Miami, Fla, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-12">December 2015</date>
			<biblScope unit="page" from="745" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Road crack detection using deep convolutional neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Daniel</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing</title>
		<meeting>the IEEE International Conference on Image Processing<address><addrLine>Phoenix, Ariz, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">September 2016</date>
			<biblScope unit="page" from="3708" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep learning and its applications to signal and information processing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="154" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep learning for visual understanding: a review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oerlemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="27" to="48" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Information processing in dynamical systems: foundations of harmony theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. DTIC Document</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A learning algorithm for boltzmann machines</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ackley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="169" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A tutorial on energy-based learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Predicting Structured Data</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Loss functions for discriminative training of energy-based models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Artificial Intelligence and Statistics (AISTATS &apos;05)</title>
		<meeting>the 10th International Workshop on Artificial Intelligence and Statistics (AISTATS &apos;05)</meeting>
		<imprint>
			<date type="published" when="2005-01">January 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning deep architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations and Trends in Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exponential family harmoniums with an application to information retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1481" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep belief networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Scholarpedia</publisher>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Convolutional networks for images, speech, and time series</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Handbook of Brain Theory and Neural Networks</title>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
			<biblScope unit="volume">3361</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep neural networks segment neuronal membranes in electron microscopy images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Cires ¬∏an</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Conference on Neural Information Processing Systems (NIPS &apos;12)</title>
		<meeting>the 26th Annual Conference on Neural Information Processing Systems (NIPS &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012-12">December 2012</date>
			<biblScope unit="page" from="2843" to="2851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving computer-aided detection using convolutional neural networks and random view aggregation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1170" to="1181" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Holistically-nested edge detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th IEEE International Conference on Computer Vision (ICCV &apos;15)</title>
		<meeting>the 15th IEEE International Conference on Computer Vision (ICCV &apos;15)<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-12">December 2015</date>
			<biblScope unit="page" from="1395" to="1403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deep image: scaling up image recognition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1501.02876" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for medical image analysis: full training or fine tuning?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Gurudu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1312" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1285" to="1298" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition</title>
		<author>
			<persName><forename type="first">O</forename><surname>Abdel-Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-R</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP &apos;12)</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP &apos;12)<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012-03">March 2012</date>
			<biblScope unit="page" from="4277" to="4280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Conference on Neural Information Processing Systems (NIPS &apos;12)</title>
		<meeting>the 26th Annual Conference on Neural Information Processing Systems (NIPS &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012-12">December 2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014: 13th European Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">September 6-12, 2014. 2014</date>
			<biblScope unit="volume">8689</biblScope>
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Overfeat: integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1312.6229" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep joint task learning for generic object extraction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems (NIPS &apos;14)</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems (NIPS &apos;14)<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014-12">December 2014</date>
			<biblScope unit="page" from="523" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Colitis detection on abdominal CT scans by rich feature hierarchies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">of Proceedings of SPIE</title>
		<meeting><address><addrLine>San Diego, Calif, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02">2016. February 2016</date>
			<biblScope unit="volume">9785</biblScope>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A deep learning network for right ventricle segmentation in short-axis mri</title>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Computing in Cardiology Conference (CinC &apos;16)</title>
		<meeting>the Computing in Cardiology Conference (CinC &apos;16)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-09">September 2016</date>
			<biblScope unit="page" from="224" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Spatial aggregation of holistically-nested networks for automated pancreas segmentation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1606.07830" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;14)</title>
		<meeting>the 27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;14)<address><addrLine>Columbus, Ohio, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014-06">June 2014</date>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th IEEE International Conference on Computer Vision (ICCV &apos;15)</title>
		<meeting>the 15th IEEE International Conference on Computer Vision (ICCV &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015-12">December 2015</date>
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Two-stream contextualized CNN for fine-grained image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Ariz, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02">February 2016</date>
			<biblScope unit="page" from="4232" to="4233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Dictionary pair classifier driven convolutional neural networks for object detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;16)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;16)<address><addrLine>Las Vegas, Nev, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="2138" to="2146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A deep structured model with radius-margin bound for 3D human activity recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="256" to="273" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: surpassing human-level performance on imagenet classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th IEEE International Conference on Computer Vision (ICCV &apos;15)</title>
		<meeting>the 15th IEEE International Conference on Computer Vision (ICCV &apos;15)<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-12">December 2015</date>
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietik√§inen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>M√§enp√§√§</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Palm vein recognition using directional features derived from local binary patterns</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Signal Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="87" to="98" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Image Processing and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Moving objects segmentation from compressed surveillance video based on motion estimation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Pattern Recognition (ICPR &apos;12)</title>
		<meeting>the 21st International Conference on Pattern Recognition (ICPR &apos;12)<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012-11">November 2012</date>
			<biblScope unit="page" from="3132" to="3135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A novel scheme to code object flags for video synopsis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visual Communications and Image Processing</title>
		<meeting>the IEEE Visual Communications and Image Processing</meeting>
		<imprint>
			<date type="published" when="2012-11">November 2012</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Picture processing system by computer complex and recognition of human faces</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page">3952</biblScope>
		</imprint>
		<respStmt>
			<orgName>Kyoto University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Blessing of dimensionality: high-dimensional feature and its efficient compression for face verification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;13)</title>
		<meeting>the 26th IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
			<biblScope unit="page" from="3025" to="3032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A practical transfer learning algorithm for face verification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th IEEE International Conference on Computer Vision (ICCV &apos;13)</title>
		<meeting>the 14th IEEE International Conference on Computer Vision (ICCV &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013-12">December 2013</date>
			<biblScope unit="page" from="3208" to="3215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Tom-vs-Pete classifiers and identity-preserving alignment for face verification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd British Machine Vision Conference (BMVC &apos;12)</title>
		<meeting>the 23rd British Machine Vision Conference (BMVC &apos;12)</meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2012-09">September 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Bayesian face revisited: a joint formulation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012: 12th European Conference on Computer Vision</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Florence, Italy; Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">October 7-13, 2012. 2012</date>
			<biblScope unit="volume">7574</biblScope>
			<biblScope unit="page" from="566" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Face recognition: a convolutional neural-network approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Back</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="113" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">DeepFace: closing the gap to human-level performance in face verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;14)</title>
		<meeting>the 27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014-06">June 2014</date>
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">FaceNet: a unified embedding for face recognition and clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;15)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;15)<address><addrLine>Boston, Mass, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">A light CNN for deep face representation with noisy labels</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1511.02683" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Deep face recognition</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Openface: a general-purpose face recognition library with mobile applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ludwiczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
		<idno>CMU-CS-16-118</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>CMU School of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Cloud-vision: real-time face recognition using a mobile-cloudlet-cloud acceleration architecture</title>
		<author>
			<persName><forename type="first">T</forename><surname>Soyata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muraleedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Funai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heinzelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE Symposium on Computers and Communication (ISCC &apos;12)</title>
		<meeting>the 17th IEEE Symposium on Computers and Communication (ISCC &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012-07">July 2012</date>
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Face recognition on drones: issues and limitations</title>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Micro Aerial Vehicle Networks, Systems, and Applications for Civilian Use (DroNet &apos;15)</title>
		<meeting>the 1st Workshop on Micro Aerial Vehicle Networks, Systems, and Applications for Civilian Use (DroNet &apos;15)<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="39" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Labeled faces in the wild: a database for studying face recognition in unconstrained environments</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Amherst, Mass, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 07-49</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Attribute and simile classifiers for face verification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Computer Vision (ICCV &apos;09)</title>
		<meeting>the 12th International Conference on Computer Vision (ICCV &apos;09)<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009-10">October 2009</date>
			<biblScope unit="page" from="365" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A plant-wide industrial process control problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Downs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="255" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Designing a hierarchical neural network based on fuzzy clustering for fault diagnosis of the Tennessee-Eastman process</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eslamloueyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1407" to="1415" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A neural network methodology for process fault diagnosis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE Journal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1993" to="2002" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Incipient fault diagnosis of chemical processes via artificial neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kubota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Himmelblau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE Journal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1803" to="1812" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">An approach to fault diagnosis of chemical processes via neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nikolaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE Journal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Diagnosis of multiple simultaneous fault via hierarchical artificial neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hirota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Himmelblau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE Journal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="839" to="848" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multiple simultaneous fault diagnosis via hierarchical and single artificial neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eslamloueyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahrokhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bozorgmehri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientia Iranica</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="300" to="310" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Fault diagnosis based on Fisher discriminant analysis and support vector machines</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Kotanchek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Kordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1389" to="1401" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Fault diagnosis using support vector machine with an application in sheet metal stamping operations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="159" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Decentralized fault detection and diagnosis via sparse PCA based decomposition and maximum entropy decision fusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grbovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Usadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vucetic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Process Control</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="738" to="750" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A sparse auto-encoder-based deep neural network approach for induction motor faults classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="171" to="178" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Construction of hierarchical diagnosis network based on deep learning and its application in the fault pattern recognition of rolling element bearings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">73</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Fault diagnosis based on chemical sensor data with an active deep neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1695</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Root-cause localization using restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Steinhauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mathiason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Helldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Information Fusion (FUSION &apos;16)</title>
		<meeting>the 19th International Conference on Information Fusion (FUSION &apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
		<respStmt>
			<orgName>ISIF</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Radar fall motion detection using deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jokanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Radar Conference (RadarConf &apos;16)</title>
		<meeting>the IEEE Radar Conference (RadarConf &apos;16)<address><addrLine>Philadelphia, Pa, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">MDR for law enforcement</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Frazier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Potentials</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="23" to="26" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Radar flashlight for through the wall detection of humans</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Greneker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Proceedings of the Targets and Backgrounds: Characterization and Representation IV</title>
		<meeting><address><addrLine>SPIE, Orlando, Fla, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-04">April 1998</date>
			<biblScope unit="page" from="280" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Micro-doppler based classification of human aquatic activities via transfer learning of convolutional neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Javier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1990">1990. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Unstructured human activity detection from RGBD images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Robotics and Automation (ICRA &apos;12)</title>
		<meeting>the IEEE International Conference on Robotics and Automation (ICRA &apos;12)<address><addrLine>St Paul, Minn, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05">May 2012</date>
			<biblScope unit="page" from="842" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">RFID-based techniques for human-activity detection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Fishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="39" to="44" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Human walking estimation with radar</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Dorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C A</forename><surname>Groen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proceedings: Radar, Sonar and Navigation</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="356" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Application of linear predictive coding for human activity classification based on micro-doppler signatures</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Javier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1831" to="1834" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Human activity classification based on micro-doppler signatures using a support vector machine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1328" to="1337" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Challenges, issues and trends in fall detection systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Igual</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Medrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMedical Engineering Online</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A survey on ambient-assisted living tools for older adults</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rashidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mihailidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="579" to="590" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Detecting unseen falls from wearable devices using channel-wise ensemble of autoencoders</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taati</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1610.03761" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Weaklysupervised discovery of visual pattern configurations</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual Conference on Neural Information Processing Systems (NIPS &apos;14)</title>
		<meeting>the 28th Annual Conference on Neural Information Processing Systems (NIPS &apos;14)<address><addrLine>Qu√©bec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12">December 2014</date>
			<biblScope unit="page" from="1637" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Convolutional neural networks at constrained time cost</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;15)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR &apos;15)<address><addrLine>Boston, Mass, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="page" from="5353" to="5360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Highly efficient forward and backward propagation of convolutional neural networks for pixelwise classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.4526" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
