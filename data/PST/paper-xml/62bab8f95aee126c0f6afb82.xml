<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Representation Alignment and Uniformity in Collaborative Filtering</title>
				<funder ref="#_AbkeA5A #_6XedymP">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Tsinghua University Guoqiang Research Institute</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-06-26">26 Jun 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuanqing</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chong</forename><surname>Chen</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
							<email>yiqunliu@tsinghua.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">DCST, BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">DCST, BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">AIR</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">DCST, BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">DCST, BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">DCST, BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">DCST, BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Representation Alignment and Uniformity in Collaborative Filtering</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-06-26">26 Jun 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539253</idno>
					<idno type="arXiv">arXiv:2206.12811v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender Systems</term>
					<term>Collaborative Filtering</term>
					<term>Representation Learning</term>
					<term>Alignment and Uniformity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Collaborative filtering (CF) plays a critical role in the development of recommender systems. Most CF methods utilize an encoder to embed users and items into the same representation space, and the Bayesian personalized ranking (BPR) loss is usually adopted as the objective function to learn informative encoders. Existing studies mainly focus on designing more powerful encoders (e.g., graph neural network) to learn better representations. However, few efforts have been devoted to investigating the desired properties of representations in CF, which is important to understand the rationale of existing CF methods and design new learning objectives. In this paper, we measure the representation quality in CF from the perspective of alignment and uniformity on the hypersphere. We first theoretically reveal the connection between the BPR loss and these two properties. Then, we empirically analyze the learning dynamics of typical CF methods in terms of quantified alignment and uniformity, which shows that better alignment or uniformity both contribute to higher recommendation performance. Based on the analyses results, a learning objective that directly optimizes these two properties is proposed, named DirectAU. We conduct extensive experiments on three public datasets, and the proposed learning framework with a simple matrix factorization model leads to significant performance improvements compared to state-of-theart CF methods. Our implementations are publicly available 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommender system has become an essential part of users' engagements with web services, such as product recommendation <ref type="bibr" target="#b16">[17]</ref>, video recommendation <ref type="bibr" target="#b3">[4]</ref>, and so on. To help users discover potential items of interests, collaborative filtering (CF) is widely adopted in personalized recommendation <ref type="bibr" target="#b19">[20]</ref>. The core idea of CF is that similar users tend to have similar preferences. Compared to contentbased recommendation methods, CF only relies on past user behaviors to predict users' preferences on candidate items. The simplicity and effectiveness of CF make it a canonical technique in recommender systems <ref type="bibr" target="#b21">[22]</ref>.</p><p>Most CF methods utilize an encoder to embed users and items to a shared space and then optimize an objective function to learn informative user and item representations <ref type="bibr" target="#b15">[16]</ref>. The simplest encoder can be an embedding table that directly maps user and item IDs to embeddings <ref type="bibr" target="#b9">[10]</ref>, and Bayesian personalized ranking (BPR) <ref type="bibr" target="#b18">[19]</ref> is usually adopted as the objective function to discriminate between positive interactions and unobserved ones. Existing studies about CF mainly focus on designing more powerful encoders to model complex collaborative signals between users and items. Specifically, neural-based interaction encoders emerge in recent years, such as multi-layer perceptron (MLP) <ref type="bibr" target="#b7">[8]</ref>, attention mechanism <ref type="bibr" target="#b2">[3]</ref>, graph neural network (GNN) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>, and so on. Meanwhile, some recent works point out that the nowadays complex encoders in CF actually lead to marginal performance improvements <ref type="bibr" target="#b15">[16]</ref>. As a result, researchers also begin to investigate other objective functions beyond the common pairwise BPR loss (e.g., InfoNCE loss <ref type="bibr" target="#b33">[34]</ref>, cosine contrastive loss <ref type="bibr" target="#b15">[16]</ref>), which have been shown to bring more robust improvements than complex encoders.</p><p>However, few research efforts have been devoted to investigating the desired properties of user and item representations derived by the encoder. This is important to justify the rationale behind existing CF methods and design new learning objectives that favor these properties. Intuitively, representations of positive-related user-item pairs should be close to each other, and each representation should preserve as much information about the user/item itself as possible. Assuming all the representations are ? 2 normalized, these two properties can be referred to as 1) alignment and 2) uniformity on the unit hypersphere <ref type="bibr" target="#b26">[27]</ref>. To learn informative user and item representations, both alignment and uniformity are of great importance. If only alignment is considered, perfectly aligned encoders are easy to be achieved by mapping all the users and items to the same embedding. The goal of existing loss functions in CF can be seen to avoid such trivial constants (i.e., preserving uniformity) while optimizing for better alignment. In practice, negative samples are usually utilized to achieve this goal. For example, the BPR loss <ref type="bibr" target="#b18">[19]</ref> pairs each positive interaction with a randomly sampled negative item, and the predicted score of the interacted item is encouraged to be higher than the negative one.</p><p>In this work, we analyze the alignment and uniformity properties in CF inspired by recent progress in contrastive representation learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref>. We first theoretically show that the BPR loss actually favors these two properties, and perfectly aligned and uniform encoders form the exact minimizers of the BPR loss. Then, we empirically analyze the learning dynamics of typical CF methods in terms of alignment and uniformity via corresponding quantifying metrics proposed in <ref type="bibr" target="#b26">[27]</ref>. We find different CF methods demonstrate distinct learning trajectories, and either better alignment or better uniformity benefits the representation quality. For instance, the simplest BPR quickly converges to promising alignment and mainly improves uniformity afterwards. Other advanced methods achieve better alignment or uniformity via various techniques, such as hard negative samples and graph-based encoders, which lead to better performance accordingly. Based on the analyses results, we propose a learning objective that directly optimizes these two properties, named DirectAU. Extensive experiments are conducted on three public real-world datasets. Experimental results show that a simple matrix factorization based encoder (i.e., embedding table) that optimizes the proposed DirectAU loss yields remarkable improvements (up to 14%) compared to state-of-the-art CF methods.</p><p>The main contributions of this work can be summarized as follows:</p><p>? We theoretically show that perfectly aligned and uniform encoders form the exact minimizers of the BPR loss. We also empirically analyze the learning dynamics of typical CF methods in terms of quantified alignment and uniformity. ? Based on the analyses results, a simple but effective learning objective that directly optimizes these two properties is proposed, named DirectAU.</p><p>? Extensive experiments on three public datasets show that the proposed DirectAU well balances between alignment and uniformity. When optimizing the DirectAU objective, even the simplest matrix factorization based encoder leads to significant performance improvements compared to stateof-the-art CF methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>In this section, we first formulate the collaborative filtering problem.</p><p>Then we introduce how to measure alignment and uniformity based on recent progress in self-supervised learning <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collaborative Filtering</head><p>Let U and I denote the user and item set, respectively. Given a set of observed user-item interactions R = {(?, ?) | ? interacted with ?}, CF methods aim to infer the score ? (?, ?) ? R for each unobserved user-item pair indicating how likely the user ? tends to interact with the item ?. Then, items with the highest scores for each user will be recommended based on the predictions. In general, most CF methods use an encoder network ? (?) that maps each user and item into a low-dimensional representation ? (?), ? (?) ? R ? (? is the dimension of the latent space). For example, the encoder in matrix factorization models is usually an embedding table, which directly maps each user and item to a latent vector based on their IDs. The encoder in graph-based models further utilizes the neighborhood information. Then, the predicted score is defined as the similarity between the user and item representation (e.g., dot product, ? (?, ?) = ? (?) ? ? (?)). As for the learning objective, most studies adopt the pairwise BPR <ref type="bibr" target="#b18">[19]</ref> loss to train the model:</p><formula xml:id="formula_0">L ??? = 1 |R| ?? (?,?) ?R -log [sigmoid (? (?, ?) -? (?, ? -))] ,<label>(1)</label></formula><p>where ? -is a randomly sampled negative item that the user has not interacted with. This loss function aims to optimize the probability that the target item gets a higher score than random negative items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Alignment and Uniformity</head><p>Recent studies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref> in unsupervised contrastive representation learning identify that the quality of representations is highly related to two key properties, i.e., alignment and uniformity. Given the distribution of data ? data (?) and the distribution of positive pairs ? pos (?, ?), alignment is straightforwardly defined as the expected distance between normalized embeddings of positive pairs:</p><formula xml:id="formula_1">? align ? E (?,? + )?? pos || f (?) -f (? + )|| 2 ,<label>(2)</label></formula><p>where f (?) indicates ? 2 normalized representations. On the other hand, the uniformity loss is defined as the logarithm of the average pairwise Gaussian potential:</p><formula xml:id="formula_2">? uniform ? log E ?,??? data ? -2| | f (?)-f (?) | | 2 . (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>These two metrics are well aligned with the objective of representation learning: positive instances should be close to each other while random instances should scatter on the hypersphere. In this work, we will connect the BPR loss with these two metrics and use them to analyze the learning dynamics of typical CF methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALIGNMENT AND UNIFORMITY IN COLLABORATIVE FILTERING</head><p>In this section, we first theoretically show that the BPR loss favors representation alignment and uniformity on the hypersphere. Then, we empirically observe how these two properties evolve during training for different CF methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Theoretical Analyses</head><p>Assuming the distribution of positive user-item pairs is ? pos , and the distribution of users and items is denoted as ? user and ? item respectively, we first define the notion of optimality for alignment and uniformity in CF as follows:</p><p>Definition 1 (Perfect Alignment). An encoder ? is perfectly aligned if f (?) = f (?) a.s. over (?, ?) ? ? pos .</p><p>Definition 2 (Perfect Uniformity). An encoder ? is perfectly uniform if the distribution of f (?) for ? ? ? user and the distribution of f (?) for ? ? ? item are the uniform distribution ? ?-1 on S ?-1 .</p><p>Here S ?-1 = {? ? R ? : ||? || = 1} is the surface of the ?dimensional unit ball. Note that perfectly aligned encoders can be easily achieved by mapping all the inputs to the same representation, at the cost of the worst uniformity. Perfectly uniform encoders can also be achieved considering the number of users/items is usually large and ? is small in real-world applications. The following theorem shows that the BPR loss favors these two properties if perfect alignment and uniformity are realizable. Theorem 1. If perfectly aligned and uniform encoders exist, they form the exact minimizers of the BPR loss L ??? .</p><p>Proof. Assuming the similarity function ? (?, ?) is cosine similarity (user/item representations are normalized), we have</p><formula xml:id="formula_4">L ??? = E (?,?)?? pos -log sigmoid (? (?, ?) -? (?, ? -)) = E (?,?)?? pos -log ? f (?) ? f (?) ? f (?) ? f (?) + ? f (?) ? f (? -) = E (?,?)?? pos -f (?) ? f (?) + log ? f (?) ? f (?) + ? f (?) ? f (? -) ? E (?,?)?? pos -1 + log ? 1 + ? f (?) ? f (? -) (4) ? -1 + ? S ?-1 ? S ?-1 log ? + ? ? ? ? d? ?-1 (?)d? ?-1 (?). (5)</formula><p>According to the definition of perfect alignment, the equality in Equation ( <ref type="formula">4</ref>) is satisfied if and only if ? is perfectly aligned. According to Lemma 2 in <ref type="bibr" target="#b26">[27]</ref>, Equation ( <ref type="formula">5</ref>) is satisfied if and only if the feature distribution induced by ? is ? ?-1 (? is perfectly uniform). Therefore, L ??? ? a constant independent of ? , where equality is satisfied if and only if ? is perfectly aligned and uniform. ?</p><p>Considering the quantified metrics in Section 2.2 have been shown to be well aligned with perfect alignment and uniformity <ref type="bibr" target="#b26">[27]</ref>, this theorem shows that the BPR loss indeed favors lower ? align and ? uniform . Next, we will empirically show the learning dynamics of different CF methods in terms of alignment and uniformity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Empirical Observations</head><p>We use the BPR loss to train a matrix factorization (MF) model on the Beauty dataset<ref type="foot" target="#foot_0">2</ref> . The encoder here is a simple embedding table that maps IDs to embeddings. Figure <ref type="figure" target="#fig_0">1</ref> shows how these two properties <ref type="foot" target="#foot_1">3</ref> , the BPR loss, and the recommendation performance (NDCG@20), change during training. First, we find the randomly initialized encoder is poorly aligned but well uniform (the initial uniformity loss is low). With the optimization of the BPR loss, the alignment loss decreases quickly and results in the increase of the uniformity loss. As the alignment loss becomes stable, the uniformity loss begins to decrease. Overall, the recommendation performance improves as better alignment and uniformity are achieved. This empirically validates the analyses in Section 3.1 that the BPR loss indeed optimizes for lower ? align and ? uniform .</p><p>Besides the simplest MF encoder with the BPR loss (BPRMF), different CF methods may have distinct learning trajectories. We further visualize the alignment and uniformity metrics every epoch <ref type="foot" target="#foot_2">4</ref>for 4 typical CF methods on Beauty, as shown in Figure <ref type="figure" target="#fig_1">2</ref>. BPRMF denotes the simplest MF encoder with the BPR loss as mentioned above. BPR-DS <ref type="bibr" target="#b17">[18]</ref> enhances BPRMF by adopting a dynamic negative sampling strategy that makes the sampling probability proportional to the predicted score. LGCN <ref type="bibr" target="#b6">[7]</ref> utilizes graph neural network (GNN) as the encoder and uses the standard BPR training strategy. ENMF <ref type="bibr" target="#b1">[2]</ref> leverages all the negative interactions and devises an efficient approach to optimize the mean squared error (MSE) loss. The stars in Figure <ref type="figure" target="#fig_1">2</ref> indicate the converged points of different models, and we annotate NDCG@20 in parentheses. We mainly have the following observations:</p><p>? The optimization of BPR focuses more on uniformity (discriminating between positive and negative interactions) but does not continuously pushes positive user-item pairs closer. ? BPR-DS samples more difficult negative items, and hence leads to lower uniformity loss and better performance. But hard negatives also make it difficult to align positive useritem pairs (higher alignment loss).</p><p>? LGCN aggregates the neighborhood information and hence achieves superior alignment even in the beginning. This explains why LGCN generally performs well with the BPR loss. The GNN encoder structure is good at alignment, while We also annotate NDCG@20 for each model in parentheses (higher numbers are better). For ? align and ? uniform , lower numbers are better.</p><p>the BPR loss does well on uniformity. Although the training procedure hurts alignment and the final uniformity is worse than BPRMF, the ending alignment is still remarkable, which leads to better performance accordingly. ? Different from the above pairwise methods, ENMF directly optimizes MSE and leverages all the negative interactions, which pushes the scores of positive user-item pairs to 1 but not just greater than negative pairs like BPR. This wholedata based training benefits the optimization of alignment to a large extent while maintaining promising uniformity, and hence yields superior performance. But such pointwise optimization also hurts uniformity at the later training stage. According to the above observations, we find different CF methods have distinct learning dynamics in terms of alignment and uniformity. Compared to the standard BPRMF, BPR-DS is better at uniformity but leads to worse alignment; LGCN is better at alignment but yields worse uniformity, while both BPR-DS and LGCN achieve higher recommendation performance than BPRMF. ENMF further gets the best performance with both promising alignment and uniformity. This shows that user and item representations in CF indeed favor these two properties. Achieving better alignment or uniformity both contribute to higher recommendation performance, and it can be beneficial to optimize them simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DIRECTLY OPTIMIZING ALIGNMENT AND UNIFORMITY (DIRECTAU)</head><p>The above analyses demonstrate that both alignment and uniformity are essential to learn informative user and item representations. This motivates us to design a new learning objective that directly optimizes these two properties to achieve better recommendation performance, named DirectAU. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the overall structure of the proposed framework. The input positive user-item pairs are first encoded to embeddings and l2-normalized to the hypersphere. We use a simple embedding table (mapping user/item IDs to embeddings) as the default encoder <ref type="foot" target="#foot_4">5</ref> . Then, we quantify alignment and uniformity in CF as follows:</p><formula xml:id="formula_5">? align = E (?,?)?? pos || f (?) -f (?)|| 2 ? uniform = log E ?,? ? ?? user ? -2| | f (?)-f (? ? ) | | 2 / 2 + log E ?,? ? ?? item ? -2| | f (?)-f (? ? ) | | 2 / 2. (<label>6</label></formula><formula xml:id="formula_6">)</formula><p>The alignment loss pushes up the similarity between representations of positive-related user-item pairs, while the uniformity loss measures how well the representations scatter on the hypersphere. We separately calculate the uniformity within user representations and item representations because the data distribution of user and item might be diverse, which is more suitable to be measured respectively. Finally, we jointly optimize these two objectives with a trade-off hyperparameter ?:</p><formula xml:id="formula_7">L DirectAU = ? align + ?? uniform .<label>(7)</label></formula><p>The weight ? controls the desired degree of uniformity, which is dependent on the characteristic of each dataset. The learning algorithm of DirectAU can be found in Appendix. Note that previous CF methods usually rely on negative sampling to discriminate between positive and negative interactions, while DirectAU does not need additional negative samples and only uses the input batch of positive user-item pairs. The uniformity loss is calculated based on the in-batch pairwise distances between representations. Using in-batch instances makes it more consistent with the actual data distribution of users and items (i.e., ? user , ? item ), which has been shown to help reduce exposure bias in recommender systems <ref type="bibr" target="#b33">[34]</ref>. Compared to existing CF methods, DirectAU is easy to implement in the absence of negative samples, and there is only one hyper-parameter to tune (no need to consider the number of negative samples the sampling strategy). This makes DirectAU easy to work with various application scenarios. As for the score function, we use the dot product between user and item representations to calculate ranking scores and make recommendations, which is common in the literature <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we conduct extensive experiments on three public datasets to validate the effectiveness of DirectAU. We first describe the experimental settings (Section 5.1) and compare the overall top-K recommendation performance of DirectAU with other stateof-the-art CF methods (Section 5.2). Then, we show the learning curves when only optimizing alignment or uniformity to verify the importance of both properties (Section 5.3). We also investigate the performance of DirectAU when integrated with other CF encoders (Section 5.4). Finally, we provide the efficiency analyses (Section 5.5) and parameter sensitivity of DirectAU (Section 5.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>5.1.1 Datasets. We use three public datasets in real-world scenarios. All the datasets are publicly available and widely adopted in previous studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>? Beauty 6 : This is one of the series of product review datasets crawled from Amazon. The data is split into separate datasets by the top-level product category. ? Gowalla 7 : This is a check-in dataset <ref type="bibr" target="#b12">[13]</ref> obtained from Gowalla, where users share their locations by checking-in. ? Yelp2018 8 : This is a business recommendation dataset, including restaurants, bars and so on. We use the transaction records after Jan. 1st, 2018 following previous work <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>For preprocessing the datasets, we remove repeated interactions and ensure each user and item to have at least 5 associated interactions. This strategy is also widely adopted in previous work <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>. The statistics of datasets after preprocessing are summarized in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.1.2</head><p>Baselines. We compare the performance of DirectAU with various state-of-the-art CF methods:</p><p>? BPRMF <ref type="bibr" target="#b18">[19]</ref>: This is a typical negative-sampling method that optimizes MF with a pairwise ranking loss, where the negative item is randomly sampled from the item set. ? BPR-DS <ref type="bibr" target="#b17">[18]</ref>: This method enhances BPRMF by adopting the dynamic sampling strategy, where negative items with higher prediction scores are more likely to be sampled. ? ENMF <ref type="bibr" target="#b1">[2]</ref>: This is a MF-based model that uses all the unobserved interactions as negative samples without negative sampling. An efficient learning algorithm that minimizes the MSE loss is introduced to learn from the whole data. Recall@K measures how many target items are retrieved in the recommendation result, while NDCG@K further concerns about their positions in the ranking list. Note that we consider the ranking list of all items (except for the training items in the user history) instead of ranking a smaller set of random items together with the target items, as suggested by recent work <ref type="bibr" target="#b10">[11]</ref>. We repeat each experiment 5 times with different random seeds and report the average score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Implementation Details.</head><p>We use the RecBole <ref type="bibr" target="#b32">[33]</ref> framework to implement all the methods for fair comparisons. Adam is used as the default optimizer and the maximum number of epochs is set to 300. Early stop is adopted if NDCG@20 on the validation dataset continues to drop for 10 epochs. We set the embedding size to 64 and the learning rate to 1e </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall Performance</head><p>Table <ref type="table" target="#tab_2">2</ref> shows the performance of different baseline CF methods and our DirectAU. From the experimental results, we mainly have the following observations. Firstly, it is surprising that directly optimizing alignment and uniformity yields such impressive performance improvements, given that most baselines come from studies in recent two years. This demonstrates that these two properties strongly agree with the Secondly, we find the best baseline varies in different datasets. The contrastive learning based CLRec is effective on Beauty; while the GNN-based DGCF takes advantage on Gowalla; and ENMF achieves remarkable performance on the largest dataset Yelp2018. This shows that the characteristics of different CF models may suit different application scenarios. On the contrary, DirectAU is capable of directly adjusting the balance between alignment and uniformity, leading to consistently the best performance on all three datasets.</p><p>Thirdly, comparing different kinds of baselines, methods with more complex encoders do not always benefit the performance. The most complex model DGCF is only the most effective on Gowalla but generally costs much more time for training. Differently, methods focusing on the learning objective (e.g., ENMF, CLRec) are more robust and usually yields promising results. This shows the importance of designing suitable loss functions rather than sophisticated encoders. The effectiveness of DirectAU also suggests that it is useful to understand the desired properties of representations in CF, which benefit the design of more powerful loss functions.</p><p>Furthermore, in Figure <ref type="figure">4</ref>, we show the alignment and uniformity of different CF methods 10 along with their recommendation performance on Beauty. Overall, we can see methods with both better alignment and uniformity achieve better performance. ENMF and 10 RecVAE is not included because it is a generative method without item embeddings. The alignment and uniformity metrics are invalid under our definition.  and yields the best performance. This verifies the causal effect of alignment and uniformity on the representation quality in CF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) ??CF??????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Importance of Both Alignment and Uniformity Losses</head><p>To show that both properties are important to learn informative encoders, Figure <ref type="figure">5</ref> gives the learning curves when 1) only optimizing the alignment loss, 2) only optimizing the uniformity loss, and 3) optimizing both of the losses on Yelp2018. If only alignment is considered (left), the encoder achieves perfect alignment (? align approaches 0) but suffers a degeneration in uniformity. As a result, the recommendation performance only improves a little at the beginning and then converges to poor results. If only uniformity is considered (middle), the encoder maintains uniformity (randomly initialized embeddings are well uniform) but does not improve alignment. Hence, the performance is even worse than only optimizing ? align . Differently, when optimizing both alignment and uniformity (right), the encoder keeps promising uniformity and continuously improves alignment at the same time. As a result, the representation quality steadily increases and boosts the recommendation performance. These trends demonstrate the importance of addressing both alignment and uniformity in CF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Integration with Other CF Encoders</head><p>In the main experiments (Table <ref type="table" target="#tab_2">2</ref>), we optimize the DirectAU loss with a simple MF encoder (i.e., embedding table ). This raises the question that whether it is also beneficial to directly optimize alignment and uniformity for other CF encoders. Here we take MF and</p><p>LGCN with different numbers of layers as the interaction encoder, respectively. Table <ref type="table" target="#tab_3">3</ref> shows the performance of these methods with their original losses and corresponding variants with the DirectAU loss.</p><p>LGCN-X means the LGCN encoder with X GNN layers. We can see DirectAU consistently brings remarkable improvements to each encoder. Besides, when integrated with more powerful encoders like LGCN-2, DirectAU achieves higher performance than the default MF encoder. This shows the generalization ability of the proposed learning framework. Meanwhile, we find the relative improvements are the most significant for the simplest MF encoder.</p><p>In the Gowalla dataset, it is impressive that MF+DirectAU leads to 59.2% improvements than the original MF on average; while LGCN-2+DirectAU only brings around 8.9% improvements. This verifies the importance of choosing proper learning objectives in CF.</p><p>With the help of the DirectAU loss, a simple MF encoder can also learn high-quality representations, and hence achieves comparable results with the complex LGCN-2 encoder. Considering the balance of effectiveness and efficiency, we still choose MF as the default encoder in the following analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Efficiency Analyses</head><p>Here we compare the training efficiency of DirectAU with BPRMF and other two state-of-the-art CF models, i.e., ENMF and LGCN, which are both relatively efficient in their respective categories.</p><p>In Table <ref type="table" target="#tab_4">4</ref> LGCN. Thus, DirectAU is relatively efficient for its simplicity, and we believe the performance gains justify the runtime costs in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Parameter Sensitivity</head><p>DirectAU introduces a hyper-parameter ? that controls the weight of the uniformity loss. It is worth noting that this is the only hyperparameter to tune for DirectAU, which does not rely on negative sampling like previous CF methods. Therefore, there is no need to consider the number of negative samples and the sampling strategy. This makes DirectAU easy to use in real-world applications. Figure <ref type="figure" target="#fig_5">6</ref> shows how the performance changes when varying this hyperparameter on the three datasets. We can observe a similar trend that the performance increases first and then decreases. Different datasets suit different degrees of uniformity, which depend on the characteristics of datasets. We find higher uniformity weights might be preferable for datasets with more average interactions per user (i.e., Gowalla, Yelp2018), in which case representations might be more likely to be pushed closer due to the alignment loss. Note that the range of ? is not restricted from 0.2 to 10, which may need wider ranges and fine-grained steps in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK 6.1 Collaborative Filtering</head><p>Collaborative filtering (CF) plays an essential role in recommender systems <ref type="bibr" target="#b19">[20]</ref>. The core idea of CF is that similar users tend to have similar preferences. Different from content-based filtering methods, CF does not rely on user and item profiles to make recommendations, and hence is flexible to work in various domains. One of the primary methods for CF is the latent factor model, which learns latent user and item representations from observed interactions. The predicted score of an unobserved user-item pair is derived by the similarity (e.g., dot product) between the user and item representation. Traditional methods are mainly based on matrix factorization (MF) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. With the development of neural networks, neural CF  models begin to emerge to learn more powerful user/item representations <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b31">32]</ref>. Besides, graph neural networks attract increasing attention recently, and a number of graph-based CF models have been proposed <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>. The observed user-item interactions are taken as a bipartite graph, and graph neural networks help to capture high-order connection information.</p><p>Existing studies in CF mainly focus on the model structure of the encoder but pay less attention to other components like the learning objective and the negative sampling strategy, which also contribute to the final performance. Some recent works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> begin to investigate alternative learning paradigms. For example, ENMF <ref type="bibr" target="#b1">[2]</ref> devises an efficient approach to optimize the MSE loss based on the whole data. BUIR <ref type="bibr" target="#b11">[12]</ref> presents a novel asymmetric structure to learn from positive-only data. CLRec <ref type="bibr" target="#b14">[15]</ref> adopts the InfoNCE loss in contrastive learning to address the exposure bias in recommender systems. In this paper, we also focus on the learning objective in CF. Differently, we are the first to investigate the desired properties of representations in CF from the perspective of alignment and uniformity. And a new loss function that directly optimizes these two properties is proposed based on the analyses results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Alignment and Uniformity in Contrastive Representation Learning</head><p>Unsupervised contrastive representation learning has witnessed great success in recent years <ref type="bibr" target="#b5">[6]</ref>. Studies in this literature usually aim to learn informative representations on the unit hypersphere based on self-supervised tasks. Recent work <ref type="bibr" target="#b26">[27]</ref> identifies two key properties related to the quality of representations, namely alignment and uniformity. Similar instances are expected to have similar representations (alignment), and the distribution of representations is preferred to preserve as much information as possible (uniformity). Alignment is usually easy to be achieved (e.g., mapping all the inputs to the same representations), but it is hard to maintain uniformity at the same time. Previous representation learning strategies can be seen to preserve uniformity in different ways, such as discriminating from negative samples <ref type="bibr" target="#b4">[5]</ref> and feature decorrelation <ref type="bibr" target="#b30">[31]</ref>. Directly matching uniformly sampled points on the unit hypersphere is also shown to provide good representations <ref type="bibr" target="#b0">[1]</ref>. However, to the best of our knowledge, there still lacks thorough investigations towards alignment and uniformity in CF. This work theoretically shows the connection between the typical BPR loss and these two properties. Besides, our analyses towards learning dynamics of different CF methods help understand the rationales of existing CF methods and design new learning objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we investigate the desired properties of representations in collaborative filtering (CF). Specifically, we propose to measure the representation quality in CF from the perspective of alignment and uniformity, inspired by recent progress in contrastive representation learning. We first theoretically reveal the connection between the commonly adopted BPR loss and these two properties. Then, we empirically analyze the learning dynamics of typical CF methods in terms of alignment and uniformity. We find different methods may be good at different aspects, while either better alignment or better uniformity leads to higher recommendation performance. Based on the analyses results, a loss function that directly optimizes these two properties is proposed and experimented to be effective. A simple matrix factorization model with the proposed loss function achieves superior performance compared to state-of-the-art CF methods. We hope this work could inspire the CF community to pay more attention to the learning paradigm via in-depth analyses towards the representation quality.</p><p>In the future, we will investigate other learning objectives that also favor alignment and uniformity to further improve effectiveness and efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>In the appendix, we first show the learning algorithm of the proposed DirectAU. Then, we detail the calculation of the alignment and uniformity losses when measuring the entire learned embeddings in CF. Update the encoder ? by gradient descent 7: end for return dist.mul(-2).exp().mean().log() 15: end function</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Learning Algorithm of DirectAU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Alignment and Uniformity Calculation</head><p>According to our definitions for alignment and uniformity in CF, i.e., Eq.( <ref type="formula" target="#formula_5">6</ref>), user-item pairs to calculate the alignment loss should sample from the distribution of positive interactions ? pos , and user-user (item-item) pairs to calculate the uniformity loss should sample from the corresponding user/item distribution ? user /? item . Given the learned embeddings of all the users and items, the alignment loss can be directly calculated as follows:</p><formula xml:id="formula_8">? align = 1 |R| ?? (?,?) ?R || f (?) -f (?)|| 2 , (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>where R is the set of observed user-item interactions as mentioned in Section 2.1. We only need to traverse all the (?, ?) pairs in R, and the time complexity is ? (|R|).</p><p>As for the calculation of uniformity, a naive and intuitive method is to sample ?, ? ? ? U and ?, ? ? ? I. However, this is not consistent with the definition that ?, ? ? ? ? user and ?, ? ? ? ? item . Notice that the calculation of the uniformity loss during training follows the actual ? user and ? item because the training batch is constructed based on positive interactions. When measure the overall uniformity of the learned embeddings, we should also sample two interactions from R and retain the user/item side as the input pair, which ensures that ?, ? ? and ?, ? ? are sampled from corresponding distribution: </p><formula xml:id="formula_10">? uniform = log</formula><p>Meanwhile, this calculation method is time-consuming and contains many redundant computations. We need to traverse the entire interaction set R twice and the time complexity is ? (|R| 2 ), which is usually intractable in practice. To solve this problem, we devise a method to calculate the uniformity loss by directly sampling from the user/item set together with a popularity-weighting strategy: </p><formula xml:id="formula_12">? uniform =</formula><formula xml:id="formula_13">)<label>10</label></formula><p>where ? (?) returns the number of related interactions in R (i.e., popularity). ? ? = ? ?U ? (?) and ? ? = ? ?I ? (?) is the normalization factor, respectively. It is easy to show that Eq.( <ref type="formula" target="#formula_11">9</ref>) and Eq.( <ref type="formula" target="#formula_13">10</ref>) are exactly equivalent, while the latter reduces the computational cost to a large extent because the scale of U/I is usually much smaller than R. In this way, we can measure both alignment and uniformity of the learned embeddings efficiently. This popularity-weighting strategy also explicitly suggests that the uniformity loss focuses more on the distances between popular users/items as expected. Those popular users and items are more likely to be aligned very close, and it is reasonable to encourage them to scatter on the hypersphere.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The trends of ? align and ? uniform during training (left) and the learning curve (right) when optimizing the BPR loss on the Beauty dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: ? align -? uniform plot for different CF methods during training.We visualize these two metrics every epoch, and the stars indicate the converged points. We also annotate NDCG@20 for each model in parentheses (higher numbers are better). For ? align and ? uniform , lower numbers are better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of the proposed DirectAU. We directly optimize 1) representation alignment for positive user-item pairs and 2) in-batch uniformity for users/items.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: ? align -? uniform plot of different CF models on Beauty. For both ? align and ? uniform , lower numbers are better. Colors and numbers in parentheses indicate NDCG@20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Parameter sensitivity with regard to the weight of ? uniform in DirectAU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 1 Algorithm 1</head><label>11</label><figDesc>shows the learning algorithm of DirectAU. PyTorchstyle pseudocodes to calculate alignment and uniformity losses during training are also given to facilitate reproducibility. Learning algorithm of DirectAU (PyTorch style) Input: user-item interactions data R; structure of encoder network ? ; weight of the uniformity loss ?; embedding dimension ?. Output: encoder parameters ? 1: Randomly initialize all parameters. 2: for each mini-batch with ? user-item pairs (?, ?) ? R do 3: Get user and item embeddings ? (?), ? (?) 4: x = ? (?) / ||? (?)||, y = ? (?) / ||? (?)|| 5: L DirectAU = Align(x, y) + ? ? (Uni(x) + Uni(y)) / 2 6:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>8 : 9 :</head><label>89</label><figDesc>function align(x, y) # alignment loss 10: return (x -y).norm(dim=1).pow(2).mean() 11: end function 12: function uni(x) # uniformity loss 13: dist = torch.pdist(x, p=2).pow(2) 14:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1 2 / 2 + log 1</head><label>221</label><figDesc>|R| (|R| -1) ?? (?,?),(? ? ,? ? ) ?R ? -2| | f (?)-f (? ? ) | | |R| (|R| -1) ?? (?,?),(? ? ,? ? ) ?R ? -2| | f (?)-f (? ? ) | | 2 / 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>? RecVAE<ref type="bibr" target="#b20">[21]</ref>: This method is based on the variational autoencoder that reconstructs partially-observed user vectors, which introduces several techniques to improve M-VAE<ref type="bibr" target="#b13">[14]</ref>.? LGCN<ref type="bibr" target="#b6">[7]</ref>: This is a simplified graph convolution network for CF that performs linear propagation between neighbors on the user-item bipartite graph. ? DGCF [29]: This is a state-of-the-art GNN-based method that introduces disentanglement on top of LGCN, which Statistics of datasets. BUIR [12]: This is a state-of-the-art negative-sample-free CF method that learns user and item embeddings with only positive interactions. ? CLRec [34]: This is a recently proposed method based on contrastive learning, which adopts the InfoNCE loss to address the exposure bias in recommender systems. 5.1.3 Evaluation Protocols. Following the common practice [7, 8, 28], for each dataset, we randomly split each user's interactions into training/validation/test sets with the ratio of 80%/10%/10%. To evaluate the performance of top-K recommendation, we employ Recall and Normalized Discounted Cumulative Gain (NDCG) as evaluation metrics.</figDesc><table><row><cell></cell><cell>#user</cell><cell>#item</cell><cell>#inter.</cell><cell>avg. inter.</cell></row><row><cell>Dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>density</cell></row><row><cell></cell><cell>(|U|)</cell><cell>(|I|)</cell><cell>(|R|)</cell><cell>per user</cell></row><row><cell>Beauty</cell><cell cols="2">22.4k 12.1k</cell><cell>198.5k</cell><cell>8.9</cell><cell>0.07%</cell></row><row><cell cols="4">Gowalla 29.9k 41.0k 1027.4k</cell><cell>34.4</cell><cell>0.08%</cell></row><row><cell cols="4">Yelp2018 31.7k 38.0k 1561.4k</cell><cell>49.3</cell><cell>0.13%</cell></row><row><cell cols="6">models the intent-aware interaction graphs and encourages</cell></row><row><cell cols="4">independence of different intents.</cell><cell></cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>6 </p>https://jmcauley.ucsd.edu/data/amazon/links.html 7 http://snap.stanford.edu/data/loc-gowalla.html 8 https://www.yelp.com/dataset</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>-3 for all the methods. The training batch size is set to 256 on Beauty and 1024 on the other two datasets. The weight decay is tuned among [0, 1e -8 , 1e -6 , 1e-4 ]. The default encoder ? in DirectAU is a simple embedding table that maps user/item IDs to embeddings. The weight ? of ? uniform in DirectAU is tuned within [0.2, 0.5, 1, 2, 5, 10]. As for baselinespecific hyper-parameters, we tune them in the ranges suggested by the original paper. All the parameters are initialized by xavier initialization. Codes are publicly available9 .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Top-K recommendation performance on three datasets. The best results are in bold face, and the best baselines are underlined. The superscripts * * indicate ? ? 0.01 for the paired t-test of DirectAU vs. the best baseline (the relative improvements are denoted as Improv.).</figDesc><table><row><cell></cell><cell>Setting</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Baseline Methods</cell><cell></cell><cell>Ours</cell></row><row><cell>Dataset</cell><cell>Metric</cell><cell cols="5">BPRMF BPR-DS ENMF RecVAE LGCN DGCF</cell><cell>BUIR</cell><cell>CLRec DirectAU Improv.</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0806</cell><cell>0.0816</cell><cell>0.0915</cell><cell>0.0824</cell><cell cols="3">0.0863 0.0897 0.0816 0.0937 0.1002  *  *</cell><cell>6.94%</cell></row><row><cell>Beauty</cell><cell>Recall@20 Recall@50 NDCG@10</cell><cell>0.1153 0.1763 0.0444</cell><cell>0.1181 0.1745 0.0459</cell><cell>0.1282 0.1914 0.0511</cell><cell>0.1145 0.1712 0.0486</cell><cell cols="3">0.1201 0.1283 0.1204 0.1337 0.1400  *  *  0.1819 0.1958 0.1866 0.1996 0.2062  *  *  0.0484 0.0501 0.0457 0.0547 0.0582  *  *</cell><cell>4.74% 3.33% 6.44%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0534</cell><cell>0.0554</cell><cell>0.0606</cell><cell>0.0570</cell><cell cols="3">0.0581 0.0600 0.0556 0.0651 0.0686  *  *</cell><cell>5.38%</cell></row><row><cell></cell><cell>NDCG@50</cell><cell>0.0658</cell><cell>0.0670</cell><cell>0.0736</cell><cell>0.0686</cell><cell cols="3">0.0699 0.0738 0.0692 0.0786 0.0820  *  *</cell><cell>4.33%</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0866</cell><cell>0.1132</cell><cell>0.1149</cell><cell>0.1211</cell><cell cols="3">0.1289 0.1301 0.0798 0.1215 0.1394  *  *</cell><cell>7.15%</cell></row><row><cell>Gowalla</cell><cell>Recall@20 Recall@50 NDCG@10</cell><cell>0.1263 0.2040 0.0622</cell><cell>0.1637 0.2593 0.0814</cell><cell>0.1671 0.2675 0.0797</cell><cell>0.1771 0.2768 0.0845</cell><cell cols="3">0.1871 0.1889 0.1164 0.1755 0.2014  *  *  0.2934 0.2919 0.1917 0.2813 0.3127  *  *  0.0930 0.0939 0.0570 0.0868 0.0991  *  *</cell><cell>6.63% 6.56% 5.56%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0736</cell><cell>0.0961</cell><cell>0.0953</cell><cell>0.1007</cell><cell cols="3">0.1097 0.1099 0.0676 0.1022 0.1170  *  *</cell><cell>6.44%</cell></row><row><cell></cell><cell>NDCG@50</cell><cell>0.0926</cell><cell>0.1196</cell><cell>0.1200</cell><cell>0.1251</cell><cell cols="3">0.1356 0.1358 0.0858 0.1281 0.1442  *  *</cell><cell>6.20%</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0416</cell><cell>0.0533</cell><cell>0.0596</cell><cell>0.0495</cell><cell cols="3">0.0508 0.0519 0.0444 0.0547 0.0684  *  *</cell><cell>14.83%</cell></row><row><cell>Yelp2018</cell><cell>Recall@20 Recall@50 NDCG@10</cell><cell>0.0693 0.1293 0.0335</cell><cell>0.0864 0.1572 0.0423</cell><cell>0.0957 0.1710 0.0482</cell><cell>0.0820 0.1494 0.0395</cell><cell cols="3">0.0833 0.0849 0.0737 0.0890 0.1096  *  *  0.1534 0.1575 0.1386 0.1606 0.1935  *  *  0.0406 0.0409 0.0349 0.0436 0.0553  *  *</cell><cell>14.55% 13.16% 14.77%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0428</cell><cell>0.0534</cell><cell>0.0603</cell><cell>0.0504</cell><cell cols="3">0.0514 0.0521 0.0448 0.0551 0.0691  *  *</cell><cell>14.53%</cell></row><row><cell></cell><cell>NDCG@50</cell><cell>0.0602</cell><cell>0.0740</cell><cell>0.0821</cell><cell>0.0698</cell><cell cols="3">0.0717 0.0732 0.0636 0.0758 0.0933  *  *</cell><cell>13.67%</cell></row><row><cell cols="6">representation quality in CF, and current models might not address</cell><cell></cell><cell></cell></row><row><cell cols="6">both alignment and uniformity well, which leads to inferior results.</cell><cell></cell><cell></cell></row><row><cell cols="6">Compared to state-of-the-art CF methods, DirectAU is not only</cell><cell></cell><cell></cell></row><row><cell cols="4">conceptually simple but also empirically effective.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance comparison of different encoders when integrated with the proposed DirectAU loss.</figDesc><table><row><cell></cell><cell cols="2">Beauty</cell><cell cols="2">Gowalla</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Recall@20 NDCG@20 Recall@20 NDCG@20</cell></row><row><cell>BPRMF</cell><cell>0.1153</cell><cell>0.0534</cell><cell>0.1263</cell><cell>0.0736</cell></row><row><cell cols="2">+DirectAU 0.1400  *  *</cell><cell>0.0686  *  *</cell><cell>0.2014  *  *</cell><cell>0.1170  *  *</cell></row><row><cell>LGCN-1</cell><cell>0.1211</cell><cell>0.0560</cell><cell>0.1769</cell><cell>0.1033</cell></row><row><cell cols="2">+DirectAU 0.1444  *  *</cell><cell>0.0700  *  *</cell><cell>0.2036  *  *</cell><cell>0.1184  *  *</cell></row><row><cell>LGCN-2</cell><cell>0.1201</cell><cell>0.0581</cell><cell>0.1871</cell><cell>0.1097</cell></row><row><cell cols="2">+DirectAU 0.1455  *  *</cell><cell>0.0707  *  *</cell><cell>0.2043  *  *</cell><cell>0.1191  *  *</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Efficiency comparison on Yelp2018, including the average training time per epoch, the number of epochs to converge, and the total training time (s: second, m: minute, h: hour).</figDesc><table><row><cell>Method</cell><cell>time/epoch</cell><cell>#epoch</cell><cell>total time</cell></row><row><cell>BPRMF</cell><cell>29.8s</cell><cell>59</cell><cell>29m</cell></row><row><cell>ENMF</cell><cell>24.8s</cell><cell>89</cell><cell>36m</cell></row><row><cell>LGCN</cell><cell>228.6s</cell><cell>107</cell><cell>6h48m</cell></row><row><cell>DirectAU</cell><cell>37.3s</cell><cell>50</cell><cell>31m</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>, we present the average training time per epoch, the number of epochs to converge, and the total training time on the largest dataset Yelp2018. The efficiency experiments are conducted on the same machine (Intel Core 12-core CPU of 3.5GHz and single NVIDIA GeForce GTX 1080 Ti GPU). We compare different methods under the same implementation framework and the setting of batch size is fixed to 256 to ensure fairness. The results show that ENMF is the most efficient in terms of the training time per epoch, which results from the specifically designed learning algorithm. The graph-based LGCN is much slower because of the neighborhood aggregation in each iteration, even if LGCN performs linear propagation for simplicity. Our DirectAU needs a little more training time per epoch than BPRMF and ENMF mainly due to the calculation of the uniformity loss. However, DirectAU generally converges fast and the total time is similar with BPRMF and ENMF, which is much faster than</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>More information about the dataset and metrics will be detailed in Section 5.1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Calculations of alignment and uniformity losses in CF will be detailed in Appendix.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The start point of each method is the status after</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>epochs of training. We do not draw the first few points because they are far away from the main area.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Combinations with other encoders like graph neural networks will be tested in Section 5.4, and we find a simple embedding table yields remarkable performance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p>https://github.com/THUwangcy/DirectAU</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work is supported by the <rs type="funder">Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">U21B2026</rs>, <rs type="grantNumber">62002191</rs>) and <rs type="funder">Tsinghua University Guoqiang Research Institute</rs>. We would like to thank the VMWare gift funding's partly support to the authors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AbkeA5A">
					<idno type="grant-number">U21B2026</idno>
				</org>
				<org type="funding" xml:id="_6XedymP">
					<idno type="grant-number">62002191</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient Neural Matrix Factorization without Sampling for Recommendation</title>
		<author>
			<persName><forename type="first">Chong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention</title>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM conference on recommender systems</title>
		<meeting>the 10th ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08821</idno>
		<title level="m">SimCSE: Simple Contrastive Learning of Sentence Embeddings</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Pierre H Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohan</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Daniel Guo</surname></persName>
		</author>
		<author>
			<persName><surname>Gheshlaghi Azar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07733</idno>
		<title level="m">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lightgcn: Simplifying and powering graph convolution network for recommendation</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On sampled metrics for item recommendation</title>
		<author>
			<persName><forename type="first">Walid</forename><surname>Krichene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1748" to="1757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongku</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjun</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanyoung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.06323</idno>
		<title level="m">Bootstrapping User and Item Representations for One-Class Collaborative Filtering</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling user exposure in recommendation</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on World Wide Web</title>
		<meeting>the 25th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="951" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Variational autoencoders for collaborative filtering</title>
		<author>
			<persName><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 world wide web conference</title>
		<meeting>the 2018 world wide web conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunpu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanxin</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.01317</idno>
		<title level="m">Contrastive Learning for Recommender System</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SimpleX: A Simple and Strong Baseline for Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Kelong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinpeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuqiang</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinfeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving pairwise learning for item recommendation from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM international conference on Web search and data mining</title>
		<meeting>the 7th ACM international conference on Web search and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="273" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th conference on uncertainty in artificial intelligence</title>
		<meeting>the 25th conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Frankowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shilad</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The adaptive web</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="291" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recvae: A new variational autoencoder for top-n recommendations with implicit feedback</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Shenbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Alekseev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Tutubalina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><forename type="middle">I</forename><surname>Nikolenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="528" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey of collaborative filtering techniques</title>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in artificial intelligence</title>
		<imprint>
			<date type="published" when="2009">2009. 2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequential Recommendation with Multiple Contrast Signals</title>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Toward Dynamic User Intention: Temporal Evolutionary Effects of Item Relations in Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Make It a Chrous: Knowledge-and Time-aware Item Modeling for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43th International ACM SIGIR conference</title>
		<meeting>the 43th International ACM SIGIR conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling Item-Specific Temporal Dynamics of Repeat Consumption for Recommender Systems</title>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1977" to="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural graph collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval</title>
		<meeting>the 42nd international ACM SIGIR conference on Research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Disentangled graph collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongye</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1001" to="1010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Session-based recommendation with graph neural networks</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Barlow twins: Self-supervised learning via redundancy reduction</title>
		<author>
			<persName><forename type="first">Jure</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">St?phane</forename><surname>Deny</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03230</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep learning based recommender system: A survey and new perspectives</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Shanlei</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiyuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changxin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingqian</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaliang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.01731</idno>
		<title level="m">RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Contrastive learning for debiased candidate generation in large-scale recommender systems</title>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3985" to="3995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
