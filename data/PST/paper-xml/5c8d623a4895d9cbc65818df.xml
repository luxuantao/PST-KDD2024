<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A FILTER-TRUST-REGION METHOD FOR UNCONSTRAINED OPTIMIZATION *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-10-07">October 7, 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nick</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
							<email>gould@rl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Computational Science and Engineering Department</orgName>
								<orgName type="institution">Rutherford Appleton Laboratory</orgName>
								<address>
									<settlement>Chilton</settlement>
									<region>Oxfordshire</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Caroline</forename><surname>Sainvitu</surname></persName>
							<email>caroline.sainvitu@fundp.ac.be</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Namur</orgName>
								<address>
									<addrLine>61, rue de Bruxelles</addrLine>
									<postCode>B-5000</postCode>
									<settlement>Namur</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>AND</roleName><forename type="first">Philippe</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
							<email>philippe.toint@fundp.ac.be</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">University of Namur</orgName>
								<address>
									<addrLine>61, rue de Bruxelles</addrLine>
									<postCode>B-5000</postCode>
									<settlement>Namur</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A FILTER-TRUST-REGION METHOD FOR UNCONSTRAINED OPTIMIZATION *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-10-07">October 7, 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">F204E4F2F8DB0D4CC6AABADA6EFB967D</idno>
					<idno type="DOI">10.1137/040603851</idno>
					<note type="submission">Received by the editors November 18, 2004; accepted for publication (in revised form) February 9, 2005;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>unconstrained optimization</term>
					<term>filter methods</term>
					<term>trust-region algorithms</term>
					<term>convergence theory</term>
					<term>numerical experiments AMS subject classifications. 90C30</term>
					<term>65K05</term>
					<term>90C26</term>
					<term>90C06</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A new filter-trust-region algorithm for solving unconstrained nonlinear optimization problems is introduced. Based on the filter technique introduced by Fletcher and Leyffer, it extends an existing technique of Gould, Leyffer, and Toint [SIAM J. Optim., 15 (2004), pp. 17-38]   for nonlinear equations and nonlinear least-squares to the fully general unconstrained optimization problem. The new algorithm is shown to be globally convergent to at least one second-order critical point, and numerical experiments indicate that it is very competitive with more classical trust-region algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction.</head><p>Since filter methods were first introduced for constrained nonlinear optimization by Fletcher and Leyffer <ref type="bibr" target="#b5">[5]</ref>, they have enjoyed considerable interest in their original domain of application <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b17">17]</ref>. More recently, they have been extended by Gould, Leyffer, and Toint <ref type="bibr" target="#b8">[8]</ref> and Gould and Toint <ref type="bibr" target="#b12">[12]</ref> to the nonlinear feasibility problem (including nonlinear equations and nonlinear least-squares), which is to minimize the norm of the violations of a set of (possibly nonlinear and/or nonconvex) constraints. It is the purpose of the present paper to consider the further extension of the filter techniques to general unconstrained optimization problems.</p><p>The presentation is organized as follows. Section 2 introduces the problem and the new algorithm, whose global convergence to points satisfying second-order optimality conditions is shown in section 3.1. The results of numerical experience with the new method are discussed in section 4, and some conclusions and perspectives are finally presented in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The problem and the new algorithm.</head><p>We consider the unconstrained minimization problem min x∈R n f (x), <ref type="bibr">(2.1)</ref> where f is a twice continuously differentiable function of the variables x ∈ R n . An efficient technique for solving this problem is to use Newton's method, which, from a current iterate x k , computes a trial step s k by minimizing a model of the objective function consisting of the first three terms of its Taylor's expansion around x k , yielding a trial point</p><formula xml:id="formula_0">x + k = x k + s k .</formula><p>Unfortunately, it is well known that such an algorithm may not always be well defined (when the Taylor's model is nonconvex), or convergent from any initial point x 0 . These difficulties can be circumvented by restricting the model minimization to a trust region containing x k , in a manner that is now well established (see Conn, Gould, and Toint <ref type="bibr" target="#b1">[2]</ref> for an extensive description of trust-region methods and their properties). We propose to further extend such methods by introducing a multidimensional filter technique, whose aim is to encourage convergence to first-order critical points by driving every component of the objective's gradient</p><formula xml:id="formula_1">∇ x f (x) def = g(x) = (g 1 (x), . . . , g n (x))</formula><p>T to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Computing a trial point.</head><p>Before indicating how to apply our filter technique, we start by describing how to compute the trial point x + k = x k + s k from a current iterate x k . At each iteration, we define the model of the objective function to be</p><formula xml:id="formula_2">m k (x k + s) = f (x k ) + g T k s + 1 2 s T H k s,</formula><p>where g k = ∇ x f (x k ) and H k is a symmetric approximation to ∇ xx f (x k ), and consider a trust region centered at x k :</p><formula xml:id="formula_3">B k = {x k + s | s ≤ Δ k },</formula><p>where we believe this model to be adequate. (In this definition and below, • stands for the Euclidean 2 norm). A trial step s k is then computed by minimizing the model (possibly only approximately). At variance with classical trust-region methods, we do not require here that</p><formula xml:id="formula_4">s k ≤ Δ k (2.2)</formula><p>at every iteration of our algorithm. The convergence analysis that follows requires, as is common in trust-region methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">Chapter 6]</ref>, that this step provides, at iteration k, a sufficient decrease on the model, which is to say that</p><formula xml:id="formula_5">m k (x k ) -m k (x k + s k ) ≥ κ mdc max g k min g k β k , Δ k , |τ k | min[τ 2 k , Δ 2 k ] , (2.3)</formula><p>where κ mdc is a constant in (0, 1), β k is a positive upper bound on the norm of the Hessian of the model m k , i.e.,</p><formula xml:id="formula_6">β k def = 1 + H k , and τ k = min [0, λ min [H k ]].</formula><p>Although this condition seems technical, there are efficient numerical methods to compute s k that guarantee that it holds (see <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b13">13]</ref>, or, more generally, <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">Chapter 7]</ref>). Typical trust-region algorithms then evaluate the objective function at the trial point and accept x + k as the new iterate if the reduction achieved in the objective function is at least a fraction of that predicted by the model. The trust-region radius Δ k is also possibly enlarged if this is the case, or it is reduced if the achieved reduction is too small. Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php 2.2. The multidimensional filter. We now consider using a filter mechanism to potentially accept x + k as the new iterate more often. The notion of filter is based on that of dominance: for our problem, we say that a point x 1 dominates a point x 2 whenever</p><formula xml:id="formula_7">|g i (x 1 )| ≤ |g i (x 2 )| for all i = 1, . . . , n.</formula><p>Thus, if iterate x 1 dominates iterate x 2 and if we focus our attention on convergence to first-order critical points only, the latter is of no real interest to us since x 1 is at least as good as x 2 for each of the components of the gradient. All we need to do is remember iterates that are not dominated by other iterates by using a structure called a filter. We define a multidimensional filter F as a list of n-tuples of the form </p><formula xml:id="formula_8">(g k,1 , . . . , g k,n ), where g k,i def = g i (x k ),</formula><formula xml:id="formula_9">(x + k )| ≤ |g ,j | -γ g g , (2.5)</formula><p>where γ g ∈ (0, 1/ √ n) is a small positive constant. If an iterate x k is acceptable in the sense of (2.5), we may wish to add it to the filter and remove from it every g ∈ F such that |g ,j | &gt; |g k,j | for all j ∈ {1, . . . , n}.</p><p>While the mechanism described so far is adequate for convex problems (where a zero gradient is both necessary and sufficient for second-order criticality), it may be unsuitable for nonconvex ones. Indeed it might prevent progress away from a saddle point, in which case an increase in the gradient components is acceptable. We therefore modify the filter mechanism to ensure that the filter is reset to the empty set after each iteration, giving sufficient descent on the objective function at which the model m k was detected to be nonconvex, and set an upper bound on the acceptable objective function values to ensure that the obtained decrease is permanent.</p><p>We are now able to combine these ideas into an algorithm, whose main objective is to let the filter play the major role in ensuring global convergence within "convex basins," falling back on the usual trust-region method only if things do not go well or if negative curvature is encountered.</p><p>Algorithm 2.1. Filter-Trust-Region Algorithm.</p><p>Step 0 : Initialization. An initial point x 0 and an initial trust-region radius Δ 0 &gt; 0 are given. The constants γ g ∈ (0, 1/ √ n), η 1 , η 2 , γ 1 , γ 2 , and γ 3 are also given and satisfy</p><formula xml:id="formula_10">0 &lt; η 1 ≤ η 2 &lt; 1 and 0 &lt; γ 1 ≤ γ 2 &lt; 1 ≤ γ 3 . (2.6)</formula><p>Compute f (x 0 ) and g(x 0 ), set k = 0. Initialize the filter F to the empty set and choose f sup ≥ f (x 0 ). Define two flags RESTRICT and NONCONVEX, the former to be unset.  </p><formula xml:id="formula_11">ρ k = f (x k ) -f (x + k ) m k (x k ) -m k (x + k ) . If f (x + k ) &gt; f sup , set x k+1 = x k ,</formula><formula xml:id="formula_12">ρ k &lt; η 1 or s k &gt; Δ k . • If x + k is not acceptable for the filter F or NONCONVEX is set: If ρ k ≥ η 1 and s k ≤ Δ k , then set x k+1 = x + k , unset RESTRICT and if NONCONVEX is set, set f sup = f (x k+1</formula><p>) and reinitialize the filter F to the empty set; else set x k+1 = x k and set RESTRICT.</p><p>Step 4: Update the trust-region radius.</p><p>If s k ≤ Δ k , update the trust-region radius by choosing</p><formula xml:id="formula_13">Δ k+1 ∈ ⎧ ⎨ ⎩ [γ 1 Δ k , γ 2 Δ k ] if ρ k &lt; η 1 , [γ 2 Δ k , Δ k ] if ρ k ∈ [η 1 , η 2 ), [Δ k , γ 3 Δ k ] if ρ k ≥ η 2 ;</formula><p>(2.7) otherwise, set Δ k+1 = Δ k . Increment k by one and go to Step 1.</p><p>Note that, as stated, our algorithm lacks a formal stopping criterion. In practice, one would obviously stop the calculation if g k falls below some user-defined tolerance and NONCONVEX is unset, or if some fixed maximum number of iterations is exceeded. Also note that our conditions on the step might require us to recompute s k within the trust region if negative curvature were discovered for the model only after computing a step beyond the trust-region boundary. Fortunately, this is typically a very cheap calculation and can be achieved by backtracking <ref type="bibr" target="#b14">[14]</ref> or by other suitable restriction techniques <ref type="bibr" target="#b9">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Global convergence.</head><p>Global convergence properties of Algorithm 2.1 will be proved under the following assumptions. A1 f is twice continuously differentiable on R n . A2 The iterates x k remain in a closed, bounded domain of R n . A3 For all k, the model m k is twice differentiable on R n and has a uniformly bounded Hessian. Note that A1, A2, and A3 together imply that there exist constants κ l , κ u ≥ κ l , κ ufh ≥ 1, and</p><formula xml:id="formula_14">κ umh ≥ 1 such that f (x k ) ∈ [κ l , κ u ], ∇ xx f (x k ) ≤ κ ufh , and H k ≤ κ umh -1 (3.1)</formula><p>for all k. Combining this with the definition of β k , we have that</p><formula xml:id="formula_15">β k ≤ κ umh (3.2)</formula><p>Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php for all k and all x in the convex hull of {x k }. For the purpose of our analysis, we shall consider</p><formula xml:id="formula_16">S = {k | x k+1 = x k + s k },</formula><p>the set of successful iterations;</p><formula xml:id="formula_17">A = {k | g +</formula><p>k is added to the filter}, the set of filter iterations;</p><formula xml:id="formula_18">D = {k | ρ k ≥ η 1 },</formula><p>the set of sufficient descent iterations; and</p><formula xml:id="formula_19">N = {k | NONCONVEX is set},</formula><p>the set of nonconvex iterations. Observe that A ⊆ S and</p><formula xml:id="formula_20">S ∩ N = D ∩ N . (3.3)</formula><p>We conclude this section by stating a crucial property of the algorithm.</p><p>Lemma 3.1. We have that, for all k ≥ 0,</p><formula xml:id="formula_21">f (x 0 ) -f (x k+1 ) ≥ k j=0 j∈S∩N [f (x j ) -f (x j+1 )]. (3.4)</formula><p>Proof. Denoting S ∩ N = {k i }, we observe that the definition of f sup in the algorithm ensures that</p><formula xml:id="formula_22">f (x ki+1 ) ≤ f (x ) &lt; f(x ki )</formula><p>for all i and all k i + 1 ≤ ≤ k i+1 . This directly implies the desired inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Convergence to critical points.</head><p>We first prove the convergence of our algorithm to first-order critical points.</p><p>Our first step is to prove that, as long as a first-order critical point is not approached, we do not have infinitely many successful nonconvex iterations in the course of the algorithm. We start by recalling two results from <ref type="bibr" target="#b1">[2]</ref> in order to show that the trust-region radius is bounded away from zero in this case.</p><p>Lemma 3.2. Suppose that A1-A3 hold and that s k ≤ Δ k . Then we have that</p><formula xml:id="formula_23">|f (x k + s k ) -m k (x k + s k )| ≤ κ ubh Δ 2 k , (3.5) where x k + s k ∈ B k and κ ubh def = max[κ ufh , κ umh ]. (3.6)</formula><p>The proof is identical to that of Theorem 6.4.1 in <ref type="bibr" target="#b1">[2]</ref>, but we now need to make the additional assumption that s k ≤ Δ k explicit (instead of being implicit, in this reference, in the definition of a trust-region step).</p><p>We now show that the trust-region radius must increase if the current iterate is not first-order critical and the trust-region radius is small enough. Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php Lemma 3.3. Suppose that A1-A3 hold and that s k ≤ Δ k . Suppose furthermore that g k = 0 and that</p><formula xml:id="formula_24">Δ k ≤ κ mdc g k (1 -η 2 ) κ ubh . (3.7) Then iteration ρ k ≥ η 2 and Δ k+1 ≥ Δ k . (3.8)</formula><p>The proof is the same as Theorem 6.4.2 in <ref type="bibr" target="#b1">[2]</ref> when s k ≤ Δ k . As a consequence, we obtain that the radius cannot become too small as long as a first-order critical point is not approached.</p><p>Lemma 3.4. Suppose that A1-A3 hold and that there exists a constant κ lbg &gt; 0 such that g k ≥ κ lbg for all k. Then there is a constant κ lbd &gt; 0 such that</p><formula xml:id="formula_25">Δ k ≥ κ lbd (3.9) for all k.</formula><p>Proof. Assume that iteration k is the first such that</p><formula xml:id="formula_26">Δ k+1 ≤ γ 1 min Δ 0 , κ mdc κ lbg (1 -η 2 ) κ ubh def = γ 1 δ 0 . (3.10)</formula><p>This means that the trust-region radius has been decreased at iteration k, which in turn implies, from the condition in Step 4 of the algorithm, that s k ≤ Δ k . We also have that γ 1 Δ k ≤ Δ k+1 and hence that</p><formula xml:id="formula_27">Δ k ≤ δ 0 ≤ κ mdc κ lbg (1 -η 2 ) κ ubh .</formula><p>Our assumption on the norm of the gradient then implies that (3.7) holds. This and the fact that s k ≤ Δ k thus give that (3.8) is satisfied. But this contradicts the fact that iteration k is the first such that (3.10) holds, and our initial assumption is therefore impossible. This yields the desired conclusion with κ lbd = γ 1 δ 0 . We now prove the crucial result that the number of successful nonconvex iterations must be finite unless a first-order critical point is approached.</p><p>Theorem 3.5. Suppose that A1-A3 hold and that there exists a constant κ lbg &gt; 0 such that g k ≥ κ lbg for all k. Then there can be only finitely many successful nonconvex iterations in the course of the algorithm, i.e., |S ∩ N | &lt; +∞.</p><p>Proof. Suppose, for the purpose of obtaining a contradiction, that there are infinitely many successful nonconvex iterations, which we index by S ∩ N = {k i }. It follows from (3.3) that the algorithm also guarantees that ρ k ≥ η 1 for all iterations in S ∩ N , which in turn implies, with (2.3), that for k ∈ S ∩ N , </p><formula xml:id="formula_28">f (x k ) -f (x k+1 ) ≥ η 1 [m k (x k ) -m k (x k + s k )] ≥ η 1 κ mdc g k min g k β k , Δ k ≥ η 1 κ mdc κ</formula><formula xml:id="formula_29">f (x 0 ) -f (x k+1 ) ≥ k j=0 j∈S∩N [f (x j ) -f (x j+1 )] ≥ ς k η 1 κ mdc κ lbg min κ lbg κ umh , κ lbd ,</formula><p>where ς k = |{1, . . . , k} ∩ S ∩ N |. As we have supposed that there are infinitely many successful nonconvex iterations, we have that</p><formula xml:id="formula_30">lim k→∞ ς k = +∞,</formula><p>and [f (x 0 )f (x k+1 )] is unbounded above, which contradicts the fact that the objective function is bounded below, as stated in (3.1). Our initial assumption must then be false, and the set S ∩ N of successful nonconvex iterations must be finite. We now establish the criticality of the limit point of the sequence of iterates when there are only finitely many successful iterations.</p><p>Theorem 3.6. Suppose that A1-A3 and (2.3) hold and that there are only finitely many successful iterations, i.e., |S| &lt; +∞. Then x k = x * for all sufficiently large k, and x * is first-order critical.</p><p>Proof. Let k 0 be the index of the last successful iterate. Then x * = x k0+1 = x k0+j and ρ k0+j &lt; η 1 for all j &gt; 1. <ref type="bibr">(3.11)</ref> Now observe that RESTRICT is set by the algorithm in the course of every unsuccessful iteration. This flag must thus be set at the beginning of every iteration of index k 0 + j + 1 for j &gt; 0. As a consequence, s k0+j+2 ≤ Δ k0+j+2 for all j &gt; 0. This, <ref type="bibr">(3.11)</ref>, and the mechanism of Step 4 of the algorithm then imply that lim k→∞ Δ k = 0. (3.12) Assume now, for the purpose of establishing a contradiction, that g k0+1 ≥ ε for some ε &gt; 0. Then Lemma 3.4 implies that (3.12) is impossible and we deduce that</p><formula xml:id="formula_31">g k0+j = 0 for all j &gt; 0.</formula><p>Having proved the desired convergence property for the case where S is finite, we restrict our attention, for the rest of this section, to the case where there are infinitely many successful iterations, i. for some κ lbg &gt; 0 and define {k i } = A. The bound (3.14) and Theorem 3.5 then imply that |S ∩ N | is finite and therefore that the filter is no longer reset to the empty set for k sufficiently large. Moreover, since our assumptions imply that { g ki+1 } is bounded above and away from zero, there must exist a subsequence {k } ⊆ {k i+1 } such that lim</p><formula xml:id="formula_32">→∞ g k = g ∞ with g ∞ ≥ κ lbg . (3.15)</formula><p>By definition of {k }, x k is acceptable for the filter in each iteration -1. This implies, since the filter is not reset for large enough, that, for each sufficiently large, there exists an index j ∈ {1, . . . , n} such that</p><formula xml:id="formula_33">|g k ,j | -|g k -1 ,j | &lt; -γ g g k -1 . (3.16)</formula><p>But <ref type="bibr">(3.14)</ref> implies that g k -1 ≥ κ lbg for all sufficiently large. Hence we deduce from (3.16) that</p><formula xml:id="formula_34">|g k ,j | -|g k -1 ,j | &lt; -γ g κ lbg</formula><p>for all sufficiently large. But the left-hand side of this inequality tends to zero when tends to infinity because of (3.15), yielding the desired contradiction. Hence (3.13) holds.</p><p>Consider now the case where the number of iterates added to the filter in the course of the algorithm is finite.</p><p>Theorem 3.8. Suppose that A1-A3 hold and that |S| = +∞ but |A| &lt; +∞. Then (3.13) holds.</p><p>Proof. Assume, again for the purpose of obtaining a contradiction, that (3.14) holds for all k large enough and for some κ lbg &gt; 0. The finiteness of |A| then implies that ρ k ≥ η 1 and that s k ≤ Δ k for all k ∈ S sufficiently large. If we define ςp,k = |{p, . . . , k} ∩ S|, we then obtain that</p><formula xml:id="formula_35">f (x p ) -f (x k+1 ) = k j=p j∈S [f (x j ) -f (x j+1 )] ≥ ςp,k η 1 κ mdc κ lbg min κ lbg κ umh , κ lbd ,</formula><p>for p and k sufficiently large, where, as above, we used (2.3), (3.2), (3.9), and (3.14) to derive the inequality. But ςp,k tends to infinity with k for a fixed p sufficiently large since |S| is infinite, and we again derive a contradiction from the fact that f (x k+1 ) then becomes unbounded below. The limit (3.13) then follows.</p><p>By the two last theorems, we have that at least one of the limit points of the sequence of iterates generated by the algorithm satisfies the first-order necessary condition. As the following example shows, this cannot be improved without modifying the algorithm.</p><p>Example 3.1. Consider the objective function</p><formula xml:id="formula_36">f (x) = x 3 (3x -4),</formula><p>which has a (degenerate 1 ) first-order critical point at x = 0, which is not a minimizer, and its global minimizer at x = 1. We will show that it is possible for Algorithm 2.1 to construct iterates for which x 2k = -( <ref type="formula">1</ref>2 ) k and x 2k+1 = 5 4 for k = 0, 1, 2, . . .; clearly there are two limit points, x L * = 0 and x R * = 5 4 , but only the first is critical. Let Δ 0 &gt; 2, and suppose that γ g &lt; 1  2 and that the trust-region updating scheme (2.7) is specifically</p><formula xml:id="formula_37">Δ k+1 = ⎧ ⎨ ⎩ 1 2 Δ k if ρ k &lt; η 1 , Δ k if η 1 ≤ ρ k &lt; η 2 , 2Δ k if η 2 ≤ ρ k .</formula><p>(3.17)</p><p>Now suppose that</p><formula xml:id="formula_38">F = {f (x 2k )} ≡ {-12(1 + ( 1 2 ) k )( 1 2 ) 2k } and Δ 2k &gt; 2. (3.18)</formula><p>We then show that the above iteration is possible for Algorithm 2.1 and that (3.18) will persist.</p><p>Consider first</p><formula xml:id="formula_39">x 2k = -( 1 2</formula><p>) k and the convex model</p><formula xml:id="formula_40">m 2k (x 2k + s) = f (x 2k ) + sf (x 2k ) + 1 2 s 2 h 2k , where h 2k = - f (x 2k ) 5 4 -x 2k &gt; 0.</formula><p>Then the unconstrained global minimizer of m 2k is s 2k = 5 4x 2k , and s 2k will sufficiently reduce the model within the trust region since Δ 2k &gt; 2 &gt; 5  4</p><formula xml:id="formula_41">+ ( 1 2 ) k . Moreover, m 2k (x 2k ) -m 2k (x 2k + s 2k ) = 1 2 (f (x 2k )) 2 h 2k = 1 2 5 4 -x 2k f (x 2k ) → 0 while f (x 2k ) -f (x 2k + s 2k ) = f (x 2k ) -f 5 4 &gt; f(0) -f 5 4 = 125 256 &gt; 0,</formula><p>and thus</p><formula xml:id="formula_42">ρ 2k ≥ η 2 (3.19)</formula><p>for large enough k. The trial point x 2k + s 2k is not acceptable for the filter since its gradient is f ( 5 4 ) = 75 16 f (x 2k ), but it is an acceptable point because the trust-region bound is inactive and because of (3.19). Thus x 2k+1 = x 2k + s 2k = 5 4 , while (3.17 </p><formula xml:id="formula_43">m 2k+1 (x 2k+1 + s) = f (x 2k+1 ) + sf (x 2k+1 ) + 1 2 s 2 h 2k+1 ,</formula><p>where</p><formula xml:id="formula_44">h 2k+1 = f (x 2k+1 ) x 2k+1 + ( 1 2 ) k+1 &gt; 0.</formula><p>As before, the unconstrained global minimizer of m 2k+1 is s 2k+1 = -x 2k+1 -( 1 2 ) k+1 , and s 2k+1 will sufficiently reduce the model within the trust region since Δ 2k+1 &gt; 4 &gt; 5  4 + (  <ref type="formula">1</ref>2 ) k+1 . Moreover, (3.17) and (3.20) imply that f (x 2k+2 ) replaces f (x 2k ) in the filter and that Δ 2k+2 = 1 2 Δ 2k+1 = Δ 2k , and thus that (3.18) persists.</p><formula xml:id="formula_45">)| = |f (-( 1 2 ) k+1 )| &lt; 1 2 |f (x 2k )|. Hence x 2k+2 = x 2k+1 + s 2k+1 = -(</formula><p>It is unclear how to enforce the property that all limit points are first-order critical without adversely affecting the algorithm's numerical behavior. We have considered not allowing filter iterations when the ratio between the current gradient norm and the smallest gradient norm found so far exceeds some prescribed (large) constant. While such a modification does not appear to affect the results of our numerical experiments, to date we have been unable to show that the modification yields the desired conclusion. Since we believe that the likelihood of the algorithm converging to more than a single limit point is very small (as with every trust-region method we are aware of), the issue really is of mostly theoretical interest.</p><p>We thus pursue our analysis by examining convergence to second-order critical points under the assumption that there is only one limit point. As in <ref type="bibr" target="#b1">[2]</ref>, we also assume the following: A4 The matrix H k is arbitrarily close to ∇ xx f (x k ) whenever a first-order critical point is approached; i.e.,</p><formula xml:id="formula_46">lim k→∞ ∇ xx f (x k ) -H k = 0 whenever lim k→∞ g k = 0.</formula><p>(Notice that h 2k → 0 and thus that A4 holds in the above example.)</p><p>We are then able to derive the following theorem. Theorem 3.9. Suppose that A1-A4 hold and that the complete sequence of iterates {x k } converge to the unique limit point x * . Then x * is a second-order critical point.</p><p>Proof. Our proof is strongly inspired by Theorem 6.6.4 of <ref type="bibr" target="#b1">[2]</ref>. Observe that our previous results imply that</p><formula xml:id="formula_47">g(x * ) = 0. (3.21)</formula><p>For the purpose of deriving a contradiction, assume now that</p><formula xml:id="formula_48">τ * def = λ min [∇ xx f (x * )] &lt; 0. (3.22)</formula><p>Then, using A4 and (3.21), we deduce that there exists a k 0 such that for k ≥ k 0 ,</p><formula xml:id="formula_49">λ min [H k ] &lt; 1 2 τ * &lt; 0 and, consequently, that k ∈ N and s k ≤ Δ k (3.23) for k ≥ k 0 . Our sufficient decrease condition (2.3) then ensures that for k ≥ k 0 , m k (x k ) -m k (x k + s k ) ≥ 1 2 κ mdc |τ * | min[ 1 4 τ 2 * , Δ 2 k ]. (3.24)</formula><p>Consider now the ratio of achieved versus predicted reduction ρ k in the case where Δ k ≤ 1  2 |τ * |. Thus, (3.24) and (3.23) imply that</p><formula xml:id="formula_50">m k (x k ) -m k (x k + s k ) ≥ 1 2 κ mdc |τ * |Δ 2 k ≥ 1 2 κ mdc |τ * | s k 2</formula><p>(3.25) Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php for k ≥ k 0 . Using the mean value theorem and the Cauchy-Schwarz inequality successively, we obtain that for some ξ k in the segment [x k , x k + s k ],</p><formula xml:id="formula_51">|ρ k -1| = f (x k + s k ) -m k (x k + s k ) m k (x k ) -m k (x k + s k ) ≤ |s T k ∇ xx f (ξ k )s k -s T k H k s k | κ mdc |τ * | s k 2 (3.26) ≤ 1 κ mdc |τ * | ∇ xx f (ξ k ) -H k for k ≥ k 0 and Δ k ≤ 1 2 |τ * |. Since ξ k -x k ≤ s k ≤ Δ k for k ≥ k 0 , A1, (<label>3</label></formula><p>.21), and A4 imply that the rightmost term of (3.26) must be arbitrarily small for Δ k sufficiently small and k sufficiently large. Thus, there must exist a k 1 ≥ k 0 and a</p><formula xml:id="formula_52">δ 1 ∈ (0, 1 2 |τ * |] such that ρ k ≥ η 2 for all k ≥ k 1 such that Δ k ≤ δ 1 .</formula><p>As a consequence, each iteration where these two conditions hold must be very successful and the algorithm then guarantees that Δ k+1 ≥ Δ k . This and the inequality</p><formula xml:id="formula_53">γ 1 δ 1 &lt; δ 1 ≤ 1 2 |τ * | in turn imply that Δ k ≥ min[γ 1 δ 1 , Δ k0 ] def = δ 2 (3.27)</formula><p>for all k ≥ k 1 . For every successful iteration k ≥ k 1 , we then obtain from (3.24) that</p><formula xml:id="formula_54">f (x k ) -f (x k+1 ) ≥ 1 2 η 1 κ mdc |τ * | min[ 1 4 τ 2 * , δ 2 2 ] &gt; 0.</formula><p>Remembering now that k ∈ N for k ≥ k 1 (and thus that |N | = ∞), we obtain from (3.4) that |S ∩ N |, and hence |S|, must be finite, which in turn implies that the trustregion radius tends to zero. But this contradicts (3.27). Hence our initial assumption (3.22) must be false and the proof is complete. We finally note that, at least in theory, nothing prevents the filter size from growing, possibly to infinity. Practically, a very large number of points might therefore be required, and this could, again in principle, be a serious drawback, especially for large-scale instances where each filter point has itself a large number of components. Fortunately, this problem can be fixed without sacrificing our convergence guarantee. Should the problem arise in that, at some iteration, the total storage for filter points reaches a user-defined upper limit, two different techniques can be used to continue the calculation. The first is simply to revert to a pure trust-region scheme from that iteration on. Admittedly, we would then lose some of the potential benefits of using a filter technique, but convergence is not put at risk. The second strategy is a progressive form of the first. As indicated in <ref type="bibr" target="#b8">[8]</ref>, the components of the gradient can be grouped in progressively larger sets (the filter entries being then defined as the Euclidean norm of the subvector of components belonging to the set). This results in a progressive decrease of the amount of storage required to store the entire filter. In the limit where a single component set is considered and assuming dominated filter points are removed, the filter reduces to a single number (an upper bound on the Euclidean norm of the gradient), thus eliminating all storage problems. Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php 4. Numerical experiments. We now report the results obtained by running our algorithm on the set of 159 unconstrained<ref type="foot" target="#foot_2">2</ref> problems from the CUTEr collection <ref type="bibr" target="#b10">[10]</ref>. The names of the problems with their dimensions<ref type="foot" target="#foot_3">3</ref> are detailed in Table <ref type="table">4</ref>.1.</p><p>In each case, the starting point supplied with the problem was used. All tests were performed in double precision on a Dell Latitude C840 portable computer (1.6 Mhz, 1 Gbyte of RAM) under Red Hat 9.0 Linux and the Lahey Fortran compiler (version L6.10a) with default options. All attempts to solve the test problems were limited to a maximum of 1000 iterations or 1 hour of CPU time. The values γ 1 = 0.0625, γ 2 = 0.25, γ 3 = 2, η 1 = 0.01, η 2 = 0.9, Δ 0 = 1, and</p><formula xml:id="formula_55">γ g = min 0.001, 1 2 √ n</formula><p>were used. Two particular variants were tested. The first (called default) is the algorithm as described above, where exact first and second derivatives are used and where, at each iteration, the trial point is computed by approximately minimizing m k (x k + s) using the generalized Lanczos trust-region algorithm of <ref type="bibr" target="#b9">[9]</ref> (without preconditioning) as implemented in the GALAHAD library <ref type="bibr" target="#b11">[11]</ref>. This procedure is terminated at the first s for which</p><formula xml:id="formula_56">∇m k (x k + s) ≤ min 0.1, max( M , ∇m k (x k ) ) ∇m k (x k ) , (4.1)</formula><p>where M is the machine precision. In addition, we choose</p><formula xml:id="formula_57">f sup = min(10 6 |f (x 0 )|, f(x 0 ) + 1000)</formula><p>at Step 0 of the algorithm. Based on practical experience <ref type="bibr" target="#b12">[12]</ref>, we also impose that s k ≤ 1000Δ k at all iterations following the first one at which a restricted step was taken. The algorithm stops if</p><formula xml:id="formula_58">∇f (x k ) ≤ 10 -6 √ n. (4.2)</formula><p>Finally, dominated filter points are always removed from the filter. The second algorithmic variant is the pure trust-region version, which is the same algorithm with the exception that no trial point is ever accepted for the filter and RESTRICT is always set.</p><p>On the 159 problems, both the default and the pure trust-region versions successfully solve 143. For the problems where both variants succeed, they report the same final objective function value. Failure occurs because the maximal iteration count is reached before convergence is declared, except for problems ARGLINB and ARGLINC that are judged to be too ill-conditioned by the default version, and for problems MEYER3, SCURLY20, and SCURLY30, where the pure trust-region variant stops for the same reason. The filter variant is thus just as reliable <ref type="foot" target="#foot_4">4</ref> as the trust-region version.   the best (see <ref type="bibr" target="#b2">[3]</ref> for a more complete discussion). When comparing CPU times, we must take into account the variability of reported CPU times for identical runs on the same machine. We have chosen to round all reported times to the nearest multiple Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php of 0.1 second. Problems for which all variants required zero seconds (after rounding) are not included in the comparison since the ranking of algorithms with CPU times less than clock accuracy is, in our opinion, of doubtful relevance, both because it is very unreliable and also because its practical impact is negligible (all algorithms are extremely quick in this case). We have also chosen to replace all remaining zero times by the average of the class of times that are rounded to zero (assuming uniform distribution), that is, in our case, by 0.025 (the middle of the interval [0, 0.05]).</p><p>It is not difficult to see in these figures that the filter variant is significantly more efficient than the pure trust-region method in terms of the number of iterations (which is identical to the number of function evaluations minus one). Its advantage is smaller but significant in terms of CPU time and conjugate-gradient iterations. Interestingly, the cost of managing the filter does not appear to dominate the calculation, despite the potentially large number of entries. A closer look at the results shows that the maximum number of filter entries does not exceed 5 for 119 problems, lies between 6 and 10 for 11 problems, lies between 11 and 50 for 11 problems, and exceeds 50 for 4 problems only: EIGENBLS (85 entries), RAYBENDS (340 entries), SCURLY20 (176 entries), and SCURLY30 (233 entries). None of the three last problems could be solved by the pure trust-region method. Moreover, we did not observe any obvious correlation between filter size and number of variables.</p><p>The profiles also include a comparison with LANCELOT-B, one of the GALAHAD codes <ref type="bibr" target="#b11">[11]</ref>. This is a nonmonotone trust-region algorithm (see <ref type="bibr" target="#b15">[15]</ref> or [2, section 10.1]), which we used unpreconditioned with Δ 0 = 1 and with its other settings at their default values. Again this method, which successfully solves 141 out of 159 problems, appears to be consistently inferior to the new filter algorithm. It does not solve RAYBENDS, SCURLY20, or SCURLY30 either. This comparison is interesting in that it suggests not only that the improved performance of the new algorithm might be due Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php   to the nonmonotone nature of the mechanism to accept new iterates, but also that the capability to use steps that extend beyond the trust-region boundaries is also crucial.</p><p>We finally present in Figure <ref type="figure">4</ref>.4 a plot of the evolution of the objective function value for the default and trust-region variants, as well as for LANCELOT B. This plot is typical of the cases where the new algorithm outperforms the others. For this algorithm, we note the large oscillations in objective value prior to convergence. Looking at this figure, it is remarkable that the algorithm is nevertheless provably convergent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion.</head><p>We have presented a filter algorithm for unconstrained optimization and have shown, under standard assumptions, that it produces at least a first-order critical point, irrespective of the chosen starting point. Under mild additional conditions, we also proved that convergence of the complete sequence of iterates can occur only to a second-order critical point. Preliminary numerical experience on the set of unconstrained test problems from the CUTEr collection indicates that significant gains in CPU time and in the number of iterations and function/gradient evaluations can be achieved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>e., |S| = +∞. We first investigate what happens if infinitely many values are added to the filter in the course of the algorithm. Theorem 3.7. Suppose that A1-A3 hold and that |A| = |S| = +∞. Then lim inf k→∞ g k = 0. (3.13) Proof. Assume, for the purpose of obtaining a contradiction, that for all k large enough, g k ≥ κ lbg (3.14) Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>) and(3.19) ensure that Δ 2k+1 = 2Δ 2k . Now consider x 2k+1 = 5 4 and the convex model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figures 4. 1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>, 4 . 2 ,</head><label>42</label><figDesc>and 4.3 give the performance profiles for the two variants for iterations, CPU time, and the total number of conjugate-gradient iterations, respectively. Performance profiles give, for every σ ≥ 1, the proportion p(σ) of test problems on which each considered algorithmic variant has a performance within a factor σ of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 . 1 .</head><label>41</label><figDesc>Fig. 4.1. Iteration performance profiles for the two variants and LANCELOT B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 . 2 .</head><label>42</label><figDesc>Fig. 4.2. CPU performance profiles for the two variants and LANCELOT B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 . 3 .</head><label>43</label><figDesc>Fig. 4.3. CG iteration performance profiles for the two variants and LANCELOT B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>6 Fig. 4 . 4 .</head><label>644</label><figDesc>Fig. 4.4. The objective function value as a function of the iteration progress on the EXTROSNB problem for the two variants and LANCELOT B. The default variant oscillates the most and converges first, followed by the moderately nonmonotone LANCELOT B, itself followed by the monotone pure trust-region variant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>such that if g k and g belong to F, then |g k,j | &lt; |g ,j | for at least one j ∈ {1, . . . , n}. (2.4) Filter methods propose to accept a new trial iterate x + k if it is not dominated by any other iterate in the filter. However, we do not wish to accept a new point x + k if one of the components of g(x + k ) is arbitrarily close to being dominated by another point already in the filter. In order to avoid this situation, we slightly strengthen our acceptability test and say that a new trial point x +</figDesc><table /><note><p>k is acceptable for the filter F if and only if for all g ∈ F ∃ j ∈ {1, . . . , n} : |g j</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>php Step 1: Determine a trial step.</head><label></label><figDesc>Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.Compute a finite step s k that "sufficiently reduces" the model m k , i.e., that satisfies (2.3) and that also satisfies s k ≤ Δ k if RESTRICT is set or if m k is nonconvex. In the latter case, set NONCONVEX; otherwise unset it. Compute the trial point x + k = x k + s k .</figDesc><table><row><cell>Step 2: Compute f (x + k ) and define the following ratio:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Step 3: Test to accept the trial step.</head><label></label><figDesc>set RESTRICT and go to Step 4.</figDesc><table><row><cell>• Compute g + k = g(x + k ). • If x + k is acceptable for the filter F and NONCONVEX is unset: Set x k+1 = x + k , unset RESTRICT and add g + k to the filter F if either</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php where we have used Lemma 3.4, (3.2), and our lower bound on the gradient norm to obtain the last inequality. Combining now this bound with (3.4), we deduce that</figDesc><table /><note><p>lbg min κ lbg κ umh , κ lbd ,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpx 2k+1 + s 2k+1 = -(12 ) k+1 is acceptable for the filter since it is easy to check that |f (x 2k+1 + s 2k+1</figDesc><table><row><cell>(3.20)</cell><cell>ρ 2k+1 &lt; 0,</cell></row></table><note><p><p>1  </p>2 ) k . Although f (x 2k+1 )f (x 2k+1 + s 2k+1 ) &lt; 0 and hence</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 . 1</head><label>41</label><figDesc>The test problems and their dimensions.</figDesc><table><row><cell>Problem</cell><cell cols="2">n Problem</cell><cell cols="2">n Problem</cell><cell>n</cell></row><row><cell>AIRCRFTB</cell><cell>5</cell><cell>DQRTIC</cell><cell>5000</cell><cell>OSBORNEA</cell><cell>5</cell></row><row><cell>ALLINITU</cell><cell cols="2">4 EDENSCH</cell><cell>10000</cell><cell>OSBORNEB</cell><cell>11</cell></row><row><cell>ARGLINA</cell><cell cols="2">200 EG2</cell><cell>1000</cell><cell>PALMER1C</cell><cell>8</cell></row><row><cell>ARGLINB</cell><cell cols="2">200 EIGENALS</cell><cell cols="2">2550 PALMER1D</cell><cell>7</cell></row><row><cell>ARGLINC</cell><cell cols="2">200 EIGENBLS</cell><cell cols="2">2550 PALMER2C</cell><cell>8</cell></row><row><cell>ARWHEAD</cell><cell>5000</cell><cell>EIGENCLS</cell><cell cols="2">2652 PALMER3C</cell><cell>8</cell></row><row><cell>BARD</cell><cell>3</cell><cell>ENGVAL1</cell><cell cols="2">10000 PALMER4C</cell><cell>8</cell></row><row><cell>BDQRTIC</cell><cell>5000</cell><cell>ENGVAL2</cell><cell cols="2">2 PALMER5C</cell><cell>6</cell></row><row><cell>BEALE</cell><cell cols="2">2 ERRINROS</cell><cell cols="2">50 PALMER6C</cell><cell>8</cell></row><row><cell>BIGGS3</cell><cell cols="2">3 EXPFIT</cell><cell cols="2">2 PALMER7C</cell><cell>8</cell></row><row><cell>BIGGS5</cell><cell cols="2">5 EXTROSNB</cell><cell>1000</cell><cell>PALMER8C</cell><cell>8</cell></row><row><cell>BIGGS6</cell><cell cols="2">6 FMINSRF2</cell><cell>5625</cell><cell>PARKCH</cell><cell>15</cell></row><row><cell>BOX2</cell><cell>2</cell><cell>FMINSURF</cell><cell>49</cell><cell>PENALTY1</cell><cell>1000</cell></row><row><cell>BOX3</cell><cell>3</cell><cell>FREUROTH</cell><cell>5000</cell><cell>PENALTY2</cell><cell>200</cell></row><row><cell>BRKMCC</cell><cell>2</cell><cell>GENROSE</cell><cell cols="2">500 PENALTY3</cell><cell>200</cell></row><row><cell>BROWNAL</cell><cell>200</cell><cell>GROWTHLS</cell><cell>3</cell><cell>POWELLSG</cell><cell>5000</cell></row><row><cell>BROWNBS</cell><cell>2</cell><cell>GULF</cell><cell cols="2">3 POWER</cell><cell>100</cell></row><row><cell>BROWNDEN</cell><cell cols="2">4 HAIRY</cell><cell cols="2">2 QUARTC</cell><cell>5000</cell></row><row><cell>BRYBND</cell><cell>5000</cell><cell>HATFLDD</cell><cell>3</cell><cell>RAYBENDL</cell><cell>2046</cell></row><row><cell>CHAINWOO</cell><cell>4000</cell><cell>HATFLDE</cell><cell cols="2">3 RAYBENDS</cell><cell>2046</cell></row><row><cell>CHNROSNB</cell><cell>50</cell><cell>HEART6LS</cell><cell cols="2">6 ROSENBR</cell><cell>2</cell></row><row><cell>CLIFF</cell><cell>2</cell><cell>HEART8LS</cell><cell cols="2">8 S308</cell><cell>2</cell></row><row><cell>CLPLATEA</cell><cell>10100</cell><cell>HELIX</cell><cell cols="2">3 SBRYBND</cell><cell>500</cell></row><row><cell>CLPLATEB</cell><cell>4970</cell><cell>HIELOW</cell><cell cols="2">3 SCHMVETT</cell><cell>5000</cell></row><row><cell>CLPLATEC</cell><cell>4970</cell><cell>HILBERTA</cell><cell cols="2">2 SCOSINE</cell><cell>5000</cell></row><row><cell>COSINE</cell><cell>10000</cell><cell>HILBERTB</cell><cell cols="2">10 SCURLY10</cell><cell>100</cell></row><row><cell>CRAGGLVY</cell><cell cols="2">5000 HIMMELBB</cell><cell cols="2">2 SCURLY20</cell><cell>100</cell></row><row><cell>CUBE</cell><cell>2</cell><cell>HIMMELBF</cell><cell cols="2">4 SCURLY30</cell><cell>100</cell></row><row><cell>CURLY10</cell><cell>10000</cell><cell>HIMMELBG</cell><cell cols="2">2 SENSORS</cell><cell>100</cell></row><row><cell>CURLY20</cell><cell>10000</cell><cell>HIMMELBH</cell><cell cols="2">2 SINEVAL</cell><cell>2</cell></row><row><cell>CURLY30</cell><cell>1000</cell><cell>HYDC20LS</cell><cell>99</cell><cell>SINQUAD</cell><cell>10000</cell></row><row><cell>DECONVU</cell><cell>61</cell><cell>JENSMP</cell><cell>2</cell><cell>SISSER</cell><cell>2</cell></row><row><cell>DENSCHNA</cell><cell>2</cell><cell>KOWOSB</cell><cell>4</cell><cell>SNAIL</cell><cell>2</cell></row><row><cell>DENSCHNB</cell><cell>2</cell><cell>LIARWHD</cell><cell cols="2">5000 SPARSINE</cell><cell>5000</cell></row><row><cell>DENSCHNC</cell><cell>2</cell><cell>LMINSURF</cell><cell>5329</cell><cell>SPARSQUR</cell><cell>10000</cell></row><row><cell>DENSCHND</cell><cell>3</cell><cell>LOGHAIRY</cell><cell cols="2">2 SPMSRTLS</cell><cell>4900</cell></row><row><cell>DENSCHNE</cell><cell>3</cell><cell>MANCINO</cell><cell>100</cell><cell>SROSENBR</cell><cell>5000</cell></row><row><cell>DENSCHNF</cell><cell>2</cell><cell>MARATOSB</cell><cell>2</cell><cell>SSC</cell><cell>4900</cell></row><row><cell>DIXMAANA</cell><cell>9000</cell><cell>MEXHAT</cell><cell cols="2">2 STRATEC</cell><cell>10</cell></row><row><cell>DIXMAANB</cell><cell>9000</cell><cell>MEYER3</cell><cell cols="2">3 TESTQUAD</cell><cell>5000</cell></row><row><cell>DIXMAANC</cell><cell>9000</cell><cell>MINSURF</cell><cell>36</cell><cell>TOINTGOR</cell><cell>50</cell></row><row><cell>DIXMAAND</cell><cell>9000</cell><cell>MOREBV</cell><cell>5000</cell><cell>TOINTGSS</cell><cell>5000</cell></row><row><cell>DIXMAANE</cell><cell cols="2">9000 MSQRTALS</cell><cell>1024</cell><cell>TOINTPSP</cell><cell>50</cell></row><row><cell>DIXMAANF</cell><cell>9000</cell><cell>MSQRTBLS</cell><cell>1024</cell><cell>TOINTQOR</cell><cell>50</cell></row><row><cell>DIXMAANG</cell><cell cols="2">9000 NCB20</cell><cell>5010</cell><cell>TQUARTIC</cell><cell>5000</cell></row><row><cell>DIXMAANH</cell><cell>9000</cell><cell>NCB20B</cell><cell>5000</cell><cell>TRIDIA</cell><cell>5000</cell></row><row><cell>DIXMAANI</cell><cell>9000</cell><cell>NLMSURF</cell><cell>5329</cell><cell>VARDIM</cell><cell>200</cell></row><row><cell>DIXMAANJ</cell><cell>9000</cell><cell>NONCVXU2</cell><cell>5000</cell><cell>VAREIGVL</cell><cell>50</cell></row><row><cell>DIXMAANK</cell><cell>9000</cell><cell>NONCVXUN</cell><cell>5000</cell><cell>VIBRBEAM</cell><cell>8</cell></row><row><cell>DIXMAANL</cell><cell cols="2">9000 NONDIA</cell><cell>5000</cell><cell>WATSON</cell><cell>12</cell></row><row><cell>DIXON3DQ</cell><cell>10000</cell><cell>NONDQUAR</cell><cell>5000</cell><cell>WOODS</cell><cell>10000</cell></row><row><cell>DJTL</cell><cell>2</cell><cell>NONMSQRT</cell><cell>100</cell><cell>YFITU</cell><cell>3</cell></row><row><cell>DQDRTIC</cell><cell>5000</cell><cell>ODC</cell><cell>4900</cell><cell>ZANGWIL2</cell><cell>2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>N. I. M. GOULD, C. SAINVITU, AND PH. L. TOINT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>In other words, both its first and second derivatives vanish. Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>We excluded problem BROYDN7D because of its multiple local minima.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>The number of free variables.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>The two variants consistently fail on CHAINWOO, HYDC20LS, LMINSURF, LOGHAIRY, MEYER3, NLMSURF, NONCVXU2, NONCVXUN, SBRYBND, SCOSINE, and SCURLY10. Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>Downloaded 01/02/13 to 138.26.31.3. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. The authors are indebted to two anonymous referees for their constructive comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The work of this author was supported by EPSRC grant GR/S42170. The work of the third author was conducted in the framework of the Interuniversity Attraction Poles Programme of the Belgian Science Policy Agency.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the global convergence of an SLP-filter algorithm that takes EQP steps</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="161" to="177" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Conn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trust-Region Methods</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2000">2000</date>
			<pubPlace>SIAM, Philadelphia</pubPlace>
		</imprint>
	</monogr>
	<note>MPS-SIAM Ser. Optim.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Benchmarking optimization software with performance profiles</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Moré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="201" to="213" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Redistribution subject to SIAM license or copyright</title>
		<idno>Downloaded 01/02/13 to 138.26.31.3</idno>
		<ptr target="http://www.siam.org/journals/ojsa.php" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Global convergence of a trust-region SQP-filter algorithm for nonlinear programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leyffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">L</forename><surname>Ph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toint</surname></persName>
		</author>
		<author>
			<persName><surname>Wächter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="635" to="659" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonlinear programming without a penalty function</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leyffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="239" to="269" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the global convergence of a filter-SQP algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leyffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="44" to="59" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A globally convergent filter method for nonlinear programming</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Gonzaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Karas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vanti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="646" to="669" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A multidimensional filter algorithm for nonlinear equations and nonlinear least-squares</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leyffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="17" to="38" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Solving the trust-region subproblem using the Lanczos method</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lucidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Roma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Optim</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="504" to="525" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CUTEr, a constrained and unconstrained testing environment, revisited</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Software</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="373" to="394" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GALAHAD-a library of thread-safe Fortran 90 packages for large-scale nonlinear optimization</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Software</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="353" to="372" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">FILTRANE, a Fortran 95 Filter-Trust-Region Package for Solving Systems of Nonlinear Equalities, Nonlinear Inequalities and Nonlinear Least-Squares Problems</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ph</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
		<idno>03/15</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Rutherford Appleton Laboratory, Chilton, Oxfordshire, UK</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computing a trust region step</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Moré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Statist. Comput</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="553" to="572" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Combining trust region and line search techniques</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Nonlinear Programming</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="153" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A non-monotone trust-region algorithm for nonlinear optimization subject to convex constraints</title>
		<author>
			<persName><forename type="middle">L</forename><surname>Ph</surname></persName>
		</author>
		<author>
			<persName><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="69" to="94" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A globally convergent primal-dual interior-point filter method for nonlinear programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ulbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ulbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Vicente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="379" to="410" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Global and Local Convergence of Line Search Filter Methods for Nonlinear Programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wächter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Biegler</surname></persName>
		</author>
		<idno>CAPD B-01-09</idno>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Chemical Engineering, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
