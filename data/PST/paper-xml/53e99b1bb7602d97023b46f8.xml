<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Depth of Field</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Robert</forename><surname>Kosara</surname></persName>
							<email>rkosara@ifs.tuwien.ac.at</email>
						</author>
						<author>
							<persName><forename type="first">Silvia</forename><surname>Miksch</surname></persName>
							<email>silvia@ifs.tuwien.ac.at</email>
						</author>
						<author>
							<persName><forename type="first">Helwig</forename><surname>Hauser</surname></persName>
							<email>hauser@vrvis.at</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">VRVis Research Center</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Depth of Field</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7FFBA0D41A00927BA035ABD197A79068</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.6 [Methodology and Techniques]: Interaction techniques Information Visualization</term>
					<term>Focus and Context</term>
					<term>Non-Realistic Rendering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pointing the user to the parts of a visual display that are currently the most relevant is an important task in information visualization. The same problem exists in photography, where a number of solutions have been known for a long time. One of these methods is depth of field (DOF), which depicts objects in or out of focus depending on their distance from the camera.</p><p>We propose the generalization of this idea to a concept we call semantic depth of field (SDOF), where the sharpness of objects is controlled by their current relevance, rather than their distance. This enables the user to quickly switch between different sets of criteria without having to get used to a different visualization layout or geometric distortion.</p><p>We present several visual metaphors based on SDOF and show examples of their use. Because DOF is widely used in photography and cinematography, SDOF should be easy to understand for most users.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Blur is often regarded as an imperfection of images, and indeed it is -in some respects. But blur can also be an enhancement to an image. One example of this is the depth of field (DOF) effect used in photography <ref type="bibr" target="#b0">[1]</ref> and cinematography <ref type="bibr" target="#b14">[14]</ref>: Scene elements which are out of focus are blurred according to their distance from the plane of focus. As a consequence, the viewers' attention is automatically guided to the most important parts of the image.</p><p>With portraits (Fig. <ref type="figure">1</ref>, left), for example, the person of interest is immediately perceived as the most relevant part of the image. This is because the person is depicted sharply (in focus) whereas all the context (in the background as well as in the foreground) is blurred.</p><p>In this paper, we present a model which we call Semantic Depth of Field (SDOF), for using blur as a focus and context (F+C) technique in computer graphics, especially in visualization. In general, F+C techniques are methods for how to enhance certain scene elements of interest while still using the rest as (non-distracting) context. Many of them are distortion-oriented <ref type="bibr" target="#b19">[19]</ref>, i.e., the parts of interest are enlarged while other parts are scaled down to fit into the remaining image space. Prominent examples are fisheye views <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b26">26]</ref>, hyperbolic trees <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b16">16]</ref>, stretchable rubber sheets <ref type="bibr" target="#b27">[27]</ref>, etc. Other approaches, for instance magic lenses <ref type="bibr" target="#b28">[28]</ref> or toolglasses <ref type="bibr" target="#b2">[3]</ref>, use separate visualization techniques for relevant objects and the context, respectively. Figure <ref type="figure">1</ref>: A portrait as an example for DOF in photography (left)the blurred objects surrounding the face are hardly noticeable. An example for preattentive processing: the object different to all others is immediately perceived (top right); text is another example (bottom right).</p><p>In contrast to existing F+C techniques, the SDOF model uses blur to de-emphasize context objects. Different to DOF in photography, where the blurring of objects solely depends on their spatial depths within the scene, SDOF provides blurring depending on the semantics of the scene.</p><p>From the theory of human perception <ref type="bibr" target="#b7">[8]</ref> we know that human focusing works as follows: First, for the purpose of looking at a particular object of interest, the eye (and usually also the head) is brought into a position and orientation, such that the object of interest gets projected onto the fovea centralis, which is the area of most acute vision. Then, the lens within the eye focuses, such that the image of the object of interest is depicted sharply on the retina of the eye. From photography, we know that this procedure can be reversed: By depicting parts of an image sharply (and the rest of the image blurred), the viewer automatically focuses on that particular part, while ignoring all the rest, at least at first glance (Fig. <ref type="figure">1</ref>, left).</p><p>One important property of this aspect of human vision, i.e., discarding blurred parts from perceived images automatically, is that it takes place in a very short time, usually within ten milliseconds. Processes like these -called preattentive processes <ref type="bibr" target="#b29">[29]</ref> -are performed in a highly parallel way, no serial search is performed. In Fig. <ref type="figure">1</ref> (top right), for example, the viewer immediately perceives the one object which is different from all others, there is no need for examining all objects one after the other.</p><p>A small number of visual features are preattentively processed, for example closure, line orientation, hue, etc. This allows not only for very quick perception, but also for fast estimation of feature quantities as well as for rapid perception of areas where features gather. In this paper, we follow other recent examples <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b30">30]</ref> of exploiting perceptual psychology for computer graphics and visualization, by using preattentive processing as a strong argument in favor of our SDOF approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been surprisingly few attempts to use DOF or blur in visualization at all; the ones relevant to this work are shortly summarized here.</p><p>In a system for the display of time-dependent cardio-vascular data <ref type="bibr" target="#b32">[32]</ref>, a stereoscopic 3D display is included that is controlled by the viewer's eyes. Like a microscope, only one thin slice through the data appears sharp, all others are blurred and therefore almost invisible. Eye tracking equipment determines what the user is looking at, and that point is brought into focus. This makes it possible to concentrate on one detail without the surrounding structures confusing the viewer. Later work <ref type="bibr" target="#b33">[33]</ref> describes "non-linear depth cues", which means displaying structures that currently are of interest (like single organs) in focus, and other objects out of focus, not based on their distance from the camera, but on their importance. This amounts to a semantic use of depth of field.</p><p>The Macroscope <ref type="bibr" target="#b20">[20]</ref> is a system for displaying several zoom levels of information in the same display space. For this purpose, the images on all levels are drawn over each other, with the more detailed ones drawn "in front", i.e., drawn over the less magnified layers. The layers' transparency can be changed so that the background (context) can be more or less visible. In order to make the background less distracting, blur is used for the front-most images that show the coarsest data.</p><p>The most interesting existing approach for this work is a display of geographical information <ref type="bibr" target="#b3">[4]</ref>. In this system, up to 26 layers of information can be displayed at the same time. Each layer has an interest level associated with it that the user can change. The interest level is a combination of blur and transparency, making less interesting layers more blurred and more transparent at the same time. This work does not seem to have been followed up on recently.</p><p>Also interesting in comparison to this work is another existing F+C technique, which is a system for visualizing geographical data <ref type="bibr" target="#b22">[22]</ref> that uses color saturation to show different types of data for the same geographical area. Different cities, hospitals, pharmacies, etc. can be viewed by "lightening them up" with brighter and more saturated colors than other parts of the image. Here also preattentive processing is exploited for the purpose of fast perception.</p><p>All the described approaches only used blur in a very limited way. None of them presented a thorough model or linked their work to perceptual psychology, nor showed the vast field of applicability of SDOF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Depth of Field and Camera Models</head><p>In computer graphics, the pinhole camera is the simplest and therefore most common model in use (Fig. <ref type="figure" target="#fig_0">2</ref>, top left). A pinhole camera consists of a light-tight box that contains a piece of film and has an infinitesimally small hole in the side opposite the film. Through the pinhole, each point on the film is hit by exactly one light ray, and therefore the image is perfectly sharp everywhere.</p><p>In photography (and photo-realistic rendering), cameras usually contain lenses or lens systems. A lens has the advantage of collecting more light than a hole (Fig. <ref type="figure" target="#fig_0">2</ref> length f , and an object is at distance u from the lens, then a sharp image of that object is projected at distance v from the lens (thin lens equation <ref type="bibr" target="#b18">[18]</ref>):</p><formula xml:id="formula_0">1 u + 1 v = 1 f<label>(1)</label></formula><p>While focusing on a scene object at distance zfocus from the image plane, f is fixed, and the lens is moved such that its distance v from the film as well as its distance u = zfocus -v from the object<ref type="foot" target="#foot_1">1</ref> satisfy Eq. 1 (Fig. <ref type="figure" target="#fig_0">2</ref>, top right). Points of (out-of-focus) objects are not depicted as points, but as discs (the so-called circles of confusion, CoC <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">18]</ref>). The size of CoCs depends on the distance of a point from the plane of focus, and from the aperture setting (also called f-stop). The aperture effectively makes the lens diameter D larger or smaller, a larger aperture leads to smaller CoCs (see Eq. 2 and Fig. <ref type="figure" target="#fig_0">2</ref>, bottom). In practice, infinitesimally small points are not needed for a perfectly sharp image. Instead, depending on the magnification of the negative or slide as well as the viewing distance, there is a maximum acceptable CoC diameter that will lead to the image being perceived as sharp. The extent of the space in which the image appears sharp is called depth of field (DOF).</p><p>Assuming camera parameters v and f to be fixed during one shot of an image, we can calculate CoC diameters b for any depicted point, depending on its distance z from the lens as well as from aperture setting a:</p><formula xml:id="formula_1">b = D f (z focus -z) z focus (z -f ) , D = f a , z focus = vf v -f<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SDOF -Semantic Depth of Field</head><p>The basic idea of SDOF can be summarized as follows: Given a certain 2D visualization of some data, for example, a map of a city, and also given a certain user criterion, what part of the visualization is more relevant as compared to others, we may think of extending the given 2D scene into 3D, by assigning z-values to each scene object according to the user criterion. We may also assume that the depth values assigned to scene objects correspond to DOF in such a way that relevant objects lie in the vicinity of the plane of focus, whereas irrelevant objects are either before or behind it. Consequently, rendering of the 3D scene by the use of photo-realistic camera as described before will result in relevant objects as being depicted sharply as well as irrelevant objects as being shown in a blurred style (Fig. <ref type="figure" target="#fig_1">3</ref>). When rendering images with SDOF, we can build upon existing building blocks, like camera models and transformations, as shown in Fig. <ref type="figure" target="#fig_2">4</ref>. One part, which SDOF takes as an input, is the spatial arrangement of scene objects as specified by the applicationnote that this might be trivial in case of inherent spatial locations as usually given in photo-realistic rendering, or a complex task itself as usually given in information visualization. Another important building block of SDOF is the relevance mapping: Scene objects are assigned importance values according to a user criterion. These building blocks are described in more detail in the following sections. A more formal summary of these steps can be found in Tab.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spatial Arrangement</head><p>One input SDOF requires from the application in use is a certain spatial arrangement of data items. Both 2D and 3D arrangements can be combined with SDOF. We call the function that maps data points to locations place, it is responsible for producing a layout for the data that the user will understand. In cases where data items inherently exhibit spatial locations anyhow, this part becomes trivial.</p><p>However, in many cases, especially in information visualization, the data to be depicted does not have any inherent spatial structure and therefore, in principle, there is a significant freedom to place data items in visualization space. In database visualization, for example, usually no inherent spatial sorting of rows and columns is present -how to arrange data items, instead, is an integral part of the visualization procedure. Usually, the spatial arrangement which is chosen by a visualization algorithm tries to reflect the distances between data items with regard to a certain similarity metric. Automatic layout algorithms are used to optimize, for example, the drawing of the nodes of a graph <ref type="bibr" target="#b5">[6]</ref>.</p><p>In cases where data items do not have any inherent spatial structure and, therefore, some synthetic layout has to be chosen for visualization, the user needs to form a so-called mental map of the visualization. The user needs to learn the visualization layout in order to be able to work with it. As a consequence, it is necessary to avoid major changes to the data layout as much as possible. Therefore, in cases, where relevance of data items changes during a visualization session (which is the usual case), other techniques for enhancing objects of interest, like SDOF, are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Relevance and Blurring</head><p>The model so far lacks a way of pointing out relevant objects without changing the layout of the visualization. It is therefore necessary to introduce another mapping we call rel, which assigns relevance values to data items. The result of rel is a value in the range [0, 1], where 1 represents maximal relevance: Examples for relevance functions are selections (objects that fulfill certain criteria are selected, i.e., assigned a relevance value of 1 whereas all the other data items are assigned 0), similarity to a reference object (possibly yielding a continuous measure of relevance), age of a data value, etc. In addition to function rel, another function named blur is needed to translate relevance values into CoC diameters, i.e., positive blur levels. It would be possible, of course, to map data values directly to blur factors. But separating the mapping from data to screen space from visualization parameters gives the user more direct and independent control (see Fig. <ref type="figure" target="#fig_3">5</ref>). For our purposes, blur factors are always measured in pixel units. Therefore, a value of 1 or below denotes a perfectly sharp depiction of an object, any larger value makes the image more and more blurred.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Viewing and Camera Models</head><p>Depending on whether the visualization space is two-or threedimensional, different camera models can be used to finally achieve the SDOF effect. The camera provides two functions: camera projects data values from an intermediate space (where the information was layed out by the place function) to screen space; and dof, which calculates the blur level of each data item depending on its z coordinate and the z focus value the camera is currently focused at.</p><p>In the following, we describe two simple models. We demonstrate that a regular photo-realistic camera can be used in the 2D case. For 3D, we present a so-called adaptive camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">2D SDOF and Photorealistic Camera</head><p>In the 2D case, objects get an additional coordinate in addition to their x and y values: the blur disc diameter b. The objects are subsequently moved in the z direction so as to be properly blurred by the camera. If the camera is focused at z focus , an object with intended blur b has to be moved to a distance of z from the camera:</p><formula xml:id="formula_2">b = dofp(z, z focus ) = D f (z focus -z) z focus (z -f )<label>(3)</label></formula><formula xml:id="formula_3">z = dof -1 p (b, z focus ) = D + b D z focus + b f (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>(D is the effective lens diameter as defined in Sect. 3 and f is the focal length of the lens in use.)</p><p>The above equations apply to camera models such as distribution ray tracing <ref type="bibr" target="#b4">[5]</ref>, linear post-filtering <ref type="bibr" target="#b24">[24]</ref>, light field rendering <ref type="bibr" target="#b10">[11]</ref>, etc. But other cameras can of course be based on different (more mathematically complex) models <ref type="bibr" target="#b18">[18]</ref>, or be entirely different (like extended cameras <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b25">25]</ref>, etc.) .</p><p>If the camera uses perspective projection, objects also have to be scaled to compensate for depth effects that are not desirable in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">3D SDOF and Adaptive Camera</head><p>In the 3D case, of course, it is not possible to directly map blur factors to depth values (and therefore use a constant z focus -value together with the standard camera as described above) -the spatial arrangement of data items already contains a third dimension. However, using a simple extension of the photo-realistic camera, it is possible to also handle the 3D case.</p><p>The adaptive camera is a modification of a photorealistic camera that can change its focus for every object point to be rendered. This is easily done with object-order rendering, but can also be achieved when rendering in image order. In contrast to the photo-realistic camera, the adaptive camera can render SDOF in 2D and 3D scenes. The photorealistic camera is, in fact, a special case of the adaptive camera (which simply stays focused at the same distance for the whole image).</p><p>Function dofa is defined like dofp in Eq. 3. Different to the 2D case, now the inversion of dofa must be resolved for z focus -values:</p><formula xml:id="formula_5">b = dofa(z, z focus ) = dofp(z, z focus )<label>(5)</label></formula><formula xml:id="formula_6">z focus = dof -1 a (b, z) = D D+b z -b f<label>(6)</label></formula><p>A special case of the adaptive camera is splatting <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b31">31]</ref>, which is a volume visualization technique, but is also used in information visualization. By changing the size of the splat kernel depending on the b value of a data point, SDOF can be implemented easily.</p><p>Another special case are pre-blurred billboards <ref type="bibr" target="#b23">[23]</ref>. Objects are rendered into memory, the images are then blurred and put onto polygons into the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Parameterization</head><p>When using SDOF, the user can control two different functions: rel and blur. The former is application-specific and has to be provided by the developers of the visualization.</p><p>For the blur function, there are no restrictions other than that it has to be monotonically decreasing (so a more relevant object is always depicted sharper than or at least as sharply as a less relevant one). But a few typical functions can still be distinguished and shall be briefly discussed here.</p><p>The simplest case is a constant function (Fig. <ref type="figure" target="#fig_5">6a</ref>). If its value is 1, it will lead to a completely sharp image that does not show any SDOF effects. Using a higher value will yield a uniformly blurred image that is generally not very desirable.</p><p>Using a step function (Fig. <ref type="figure" target="#fig_5">6b</ref>) makes it possible to do a binary classification of objects. Moving the r value where the step occurs changes the threshold and thus shows a different set of objects in focus. Changing the height of the step (i.e., the b value for r less then the step value) shows irrelevant objects more or less out of focus. Depending on the application, it can be desirable to still be able to recognize currently irrelevant objects, or to make them almost disappear. This function could be used for a classification where the relevance of objects depends on their age. Changing the threshold r value shows clearly distinguishes between objects younger and older than the age corresponding to the threshold. The chessboard visualization in Fig. <ref type="figure">7</ref> also uses a step function, for exmple. If the function contains several steps (Fig. <ref type="figure" target="#fig_5">6c</ref>), it provides a classification into several groups. If the user is able to change the width and height of each step, very fine-grained control of the resulting image is possible. Using this function for objects whose relevance depends on their age, each step could be a whole day, thus making it possible to see how old objects are, and at the same time being shown more recent objects more clearly.</p><formula xml:id="formula_7">data[i] place 2D -------→ rel --→ r blur --→   x ŷ b = blur(r)   view 2D ----→ dof -1 p --→   x y z = dof -1 p (b)   camerap ----→ x ȳ data[i] place 3D -------→ rel --→ r blur --→    x ŷ ẑ b = blur(r)    view 3D ----→ dof -1 a --→    x y z z focus = dof -1 a (b)    cameraa ----→ x ȳ</formula><p>A continuous linear function (Fig. <ref type="figure" target="#fig_5">6d</ref>) is especially suited for applications where differences of features are of interest. Making the relevance of objects correspond to their distance in one of the the features makes it easy to find similar or different objects. Another application is a layered 2D view, where the user can change the distance between layers, and thus their relevance, which is then directly mirrored in their blur (this is a metaphor that very closely resembles focusing with a camera). The user needs control of the gradient of the function and the r value above which the function is constant. A linear function is used in the map viewer example in Fig. <ref type="figure">8</ref>.</p><p>If it is not only important to see the difference between objects, but also to precisely see which objects are different (even if they are very similar), a step can be included in the otherwise continuous and linear function (Fig. <ref type="figure" target="#fig_5">6e</ref>). This makes it possible to leave the gradient of the function small, but still precisely see which objects are equal (or within a certain range) and which are not.</p><p>A function that is somewhat similar to the continuous linear function, but stresses larger differences more, is the exponential blur (Fig. <ref type="figure" target="#fig_5">6e</ref>). It is most useful where small differences are not very significant, but larger differences are more and more important. This function can of course be combined with a step, linear sections, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Applications</head><p>The following applications are some of the possible uses of the model as described above. We distinguish three different classes purely for the sake of easier implementation. The model contains all three of them, as well as any combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">2D SDOF</head><p>Displaying information in 2D, it is possible to use blur to show a selection or any other distance function. This does not have much in common with DOF as used in photography (which only exists if there is a third dimension), but is useful nonetheless.</p><p>An example for this application would be a window manager that blurs all screen areas that are currently not used. Thus, a window showing the output of a program, or tracking a communication channel could be blurred so that it does not interfere with other work currently done by the user. If new messages arrive, the scrolling would be visible. It would also be possible to bring the window to focus on such a case, and thus directly guide the user's attention to it, without popping up a window or otherwise interfering with the user's current task.</p><p>Another example is a 2D chess board (Fig. <ref type="figure">7</ref>, left column; see also the video on the accompanying CDROM) that shows which pieces threaten a specific piece, or how well a particular square on the board is guarded by other pieces of the same color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Layered 2D SDOF</head><p>When several 2D layers of information are put on top of each other, it is possible to provide the user with an intuitive way of choosing how much and which information to display crisply. Independent Layers. A number of 2D depictions at the same level of detail are put one above the other, like floor plans in architecture drawn on tracing paper. The layers are translucent (the level of translucency can be changed), so that the other layers can be seen through the ones on top. Any subset of these layers can be rendered out of focus, so that the information on the in-focus layers becomes much more dominant. For a user interface that is based on layering inspired by transparent paper <ref type="bibr" target="#b1">[2]</ref>, the idea of wiggling the different layers is presented, so that the different layers can be discriminated. We believe that SDOF can show this effect much more effectively, and also provide many other means of interaction. Stacked Layers. Using the same topology as for independent layers, this mode is closer related to the photographic metaphor. Only a subset of neighboring layers is in focus here, all other layers are blurred according to their distance from the nearest in-focus layer. An example for layered 2D SDOF is a map viewer that allows many layers of geographic information (streets, mountains, rivers, telephone lines, weather data, population data, etc.) to be displayed at the same time (Fig. <ref type="figure">8</ref>). The user can select what information is shown and how sharp, thus focusing on certain information while at the same time getting the context of the depiction. Hierarchical Layers. If data from several levels (semantic or from different magnification levels) is put together into one image, the different levels can be included more easily if there is a smooth focus change between layers with different detail levels while the image is zoomed. It is thus possible to immediately see the correspondences between objects on different layers, without having to switch back and forth between them. Magnification and blur can change simultaneously or independently of each other, depending on the user's needs. Unlike the Macroscope (see Sect. 2), the different magnification levels are not drawn in the same size over each other, but maintain their relative sizes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">3D SDOF</head><p>The above uses of SDOF were only special cases of 3D SDOF. In 3D, it is possible to shift the focus between any objects, similar to the 2D case. Together with other interactions like navigation, pan, zoom, rotation, the user can have the system point to the objects that meet certain criteria, etc. An example of 3D SDOF is a 3D file system viewer that displays files and directories as objects in 3D space, and that allows searches and selections, the results of which are displayed by blurring all objects that do not match the criteria. When looking for objects that have a certain age, it displays the difference from the searched age with continuous blur levels.</p><p>Any hierarchical data could be displayed using nested, translucent boxes; these boxes are blurred when the user focuses on their contents, while the contained objects are blurred (and the boxes drawn crisply) when the higher hierarchy level is of interest. This also solves the problem of how to draw these boxes so that they can be distinguished: because their contents are shown (but not in detail), they are recognizable.</p><p>The chessboard example cited above in 2D can of course also be extended to 3D (Fig. <ref type="figure">7</ref>, right column; see also the video on the accompanying CDROM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Implementation</head><p>We implemented a chess viewer that can display both 2D and 3D chess boards and show any figure and field at any blur radius. We used billboards for both the 2D and 3D displays. The figures were first drawn into a buffer, then copied to main memory, blurred, and then applied as a texture to the billboards. For the 2D case, these textures can be cached and reused (and every piece of each color only has to be blurred once for every blur diameter). This is not true for the 3D case, where the appearance of a piece depends not only on its blur level, but also on the camera position. For the 3D display, the billboards need to be depth-sorted because the edges of the chess pieces become semitransparent when being blurred, and therefore need to be rendered into the frame buffer in the correct order.</p><p>For the map viewer, we used the accumulation buffer <ref type="bibr" target="#b8">[9]</ref> to blur the different map layers, and then composited them using blending directly into the frame buffer.</p><p>Both implementations are rather slow, and are in need of some optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions and Future Work</head><p>We have proposed a new method for providing focus and context in visualizations. It exploits effects well known from photography and cinematography, namely depth of field. Because blur is an intrinsic feature of the human eye, selective blur is a highly effective way of pointing users to pieces of information.</p><p>We believe that SDOF, being a non-distorting focus and context technique, can be incorporated into any existing visualization. It can also be combined with other methods such as color coding to point out different dimensions of information.</p><p>Combining SDOF with distortion-oriented F+C methods is another possibility. SDOF can serve as a "relevance cue", and therefore replace other effects such as fog <ref type="bibr" target="#b15">[15]</ref> in visualization.</p><p>We found out that blurring of text (Fig. <ref type="figure">1</ref>) is quite effective, which is a result we did not anticipate.</p><p>The combination of SDOF with other features like color to provide multivariate data visualization and how well SDOF is suited for this needs further investigation.</p><p>We are also working on methods to render SDOF using low-end 3D graphics hardware, to make it usable on standard PCs. One method we think can be applied is texture mapping, which is particularly fast on most hardware.</p><p>One obvious problem SDOF has is that it is hard to combine with DOF as a depth cue. We therefore also want to investigate the implications of this.</p><p>Finally, measuring blur in pixels has proven to be a bad choice, because it does not work very well with printed images, projections, and high resolution screens. We are therefore working on a measure that will take different target sizes, resolutions and viewing distances into account, so that the impression of blur is always the same.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Camera models. The pinhole camera model (top left) and the thin lens model (top right). The focal length f is the distance from the lens at which light rays parallel to the lens axis are focused (top right). A smaller effective lens diameter D leads to a smaller circles of confusion for out-of-focus points (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The basic idea of SDOF: applying DOF individually to scene objects depending on their semantics.</figDesc><graphic coords="3,227.94,253.90,57.07,57.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>PhotorealisticAdaptive ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Two functions are used to map objects to blur diameters. This makes independent control of semantic and visualization parameters possible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Examples for different blur functions mapping relevance values r to to blur factors b (for discussion, see Sect. 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 ,</head><label>6</label><figDesc>Fig. 6, different types of functions are discussed in Sect. 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>a) The chessboard as it is known b) Which chessmen cover the white knight on e3? c) Which chessmen threaten the white knight on e3?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Using SDOF in chess: a) all pieces have a relevance r = 1; b) the white pieces covering a white knight (and the knight itself) have r = 1, all others r = 0; c) the black chessmen threatening a white knight (and the white knight) have r = 1, all others r = 0 (from Garry Kasparov vs. Deep Blue, "IBM Kasparov vs. Deep Blue: The Rematch", May 3, 1997, after the 23 rd move).</figDesc><graphic coords="6,276.26,485.63,257.00,170.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>All steps necessary for visualizing data values data[i] with 2D (top) and 3D SDOF (bottom).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>TR-VRVis-2001-001</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>In optics, distances are measured from the lens, while in photography and computer graphics they are measured from the film plane. For the sake of simplicity, we will use distances measured from the lens in this paper, and mark distances measured from the image plane with a tilde ˜.Asgaard-TR-2001-1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Asgaard-TR-2001-1</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgments</head><p>We would like to thank Markus Hadwiger, Lukas Mroz and Robert F. Tobler for their critique and suggestions that greatly improved this paper.</p><p>This work is part of the Asgaard Project, which is supported by Fonds zur Förderung der wissenschaftlichen Forschung (Austrian Science Fund), grant P12797-INF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Camera. Little Brown &amp; Company</title>
		<author>
			<persName><forename type="first">A</forename><surname>Adams</surname></persName>
		</author>
		<idno>Asgaard-TR-2001-1 -7 - TR-VRVis-2001-001</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Back to the future: A graphical layering system inspired by transparent paper</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lokuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rivers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERCHI&apos;93 Conference Companion</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="129" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Toolglass and magic lenses: The see-through interface</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Derose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings SIGGRAPH&apos;93)</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
	<note>Annual Conference Series</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transparency and blur as selective cues for complex visual information</title>
		<author>
			<persName><forename type="first">G</forename><surname>Colby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Scholl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">1460</biblScope>
			<biblScope unit="page" from="114" to="125" />
		</imprint>
	</monogr>
	<note>Image Handling and Reproduction Systems Integration</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distributed ray tracing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings SIGGRAPH&apos;84)</title>
		<imprint>
			<date type="published" when="1984-07">July 1984</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="137" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithms for drawing graphs: An annotated bibliography</title>
		<author>
			<persName><forename type="first">G</forename><surname>Di Battista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tollis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Geometry: Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="235" to="282" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generalized fisheye views</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computer Systems, SIGCHI Bulletin</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mantei</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Orbeton</surname></persName>
		</editor>
		<meeting>the ACM Conference on Human Factors in Computer Systems, SIGCHI Bulletin<address><addrLine>New York, U.S.A.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computer Machinery</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Wahrnehmungspsychologie: Eine Einführung</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Spektrum Akademischer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The accumulation buffer: Hardware support for high-quality rendering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Haeberli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings SIGGRAPH&apos;90)</title>
		<imprint>
			<date type="published" when="1990-08">Aug. 1990</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large datasets at a glance: Combining textures and colors in scientific visualization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="167" />
			<date type="published" when="1999-04">Apr. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Slusalek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Seidel</surname></persName>
		</author>
		<title level="m">An image-based model for realistic lens systems in interactive computer graphics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<author>
			<persName><forename type="first">In</forename><forename type="middle">W A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mantei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Klassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics Interface &apos;97</title>
		<imprint>
			<publisher>Canadian Information Processing Society</publisher>
			<date type="published" when="1997-05">May 1997</date>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph visualization and navigation in information visualization: A survey</title>
		<author>
			<persName><forename type="first">I</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Melanc ¸on</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="43" />
			<date type="published" when="2000-03">Jan.-Mar. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fastsplats: Optimized splatting on rectilinear grids</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shareef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Visualization 2000</title>
		<meeting>Visualization 2000<address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000-08-13">Oct. 8-13 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Film directing shot by shot: Visualizing from concept to screen</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Focal Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The generalized detail-in-context problem</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Keahey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Symposium on Information Visualization</title>
		<meeting>IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A scalable framework for information visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kreuseler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Vizualization</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000-08-13">Oct. 8-13 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A focus+context technique based on hyperbolic geometry for visualizing large hierarchies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings CHI&apos;95</title>
		<meeting>CHI&apos;95</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Review of image-blur models in a photographic system using principles of optics</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="405" to="421" />
			<date type="published" when="1990-05">May 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A review and taxonomy of distortion-oriented presentation techniques</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Apperley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="160" />
			<date type="published" when="1994-06">June 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A multi-scale, multi-layer, translucent virtual space</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lieberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Information Visualization</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997-09">Sept. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ray tracing with extended cameras</title>
		<author>
			<persName><forename type="first">H</forename><surname>Löffelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization and Computer Animation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="228" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Geospace: An interactive visualization system for exploring complex information spaces</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lokuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ishizaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI&apos;95 Proceedings</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Advanced graphics programming techniques using OpenGL</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mcreynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH 2000 Course</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A lens and aperture camera model for synthetic image generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Potmesil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chakravarty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings SIGGRAPH&apos;81)</title>
		<imprint>
			<date type="published" when="1981-08">Aug. 1981</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="297" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiple-center-of-projection images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rademacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings SIGGRAPH&apos;98)</title>
		<title level="s">Annual Conference Series</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Brown</surname></persName>
		</author>
		<title level="m">Graphical fisheye views. Communications of the ACM</title>
		<imprint>
			<date type="published" when="1994-12">Dec. 1994</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="73" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stretching the rubber sheet: A metaphor for visualizing large layouts on small screens</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology, Visualizing Information</title>
		<meeting>the ACM Symposium on User Interface Software and Technology, Visualizing Information</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The movable filter as a user interface tool</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM CHI&apos;94 Conference on Human Factors in Computing Systems</title>
		<meeting>ACM CHI&apos;94 Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="306" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Preattentive processing in vision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="156" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for Design</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Footprint evaluation for volume rendering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SIGGRAPH&apos;90)</title>
		<meeting>SIGGRAPH&apos;90)</meeting>
		<imprint>
			<date type="published" when="1990-08">Aug. 1990</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Four-dimensional processing tools for cardiovascular data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Wixson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="53" to="59" />
			<date type="published" when="1983-08">Aug. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The display of 3d MRI data with non-linear focal depth cues</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Wixson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computers in Cardiology</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1990-09">Sept. 1990</date>
			<biblScope unit="page" from="379" to="380" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
