<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Saliency Detection via Sparsity Pursuit</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Junchi</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Mengyuan</forename><surname>Zhu</surname></persName>
							<email>zhumengyuan@126.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huanxi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Yuncai</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Saliency Detection via Sparsity Pursuit</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">36B303859B7192905CF029080F9A8480</idno>
					<idno type="DOI">10.1109/LSP.2010.2053200</idno>
					<note type="submission">received April 17, 2010; revised June 01, 2010; accepted June 06, 2010. Date of publication June 17, 2010; date of current version June 28, 2010.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Matrix decomposition</term>
					<term>object detection</term>
					<term>sparse sensing</term>
					<term>visual saliency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Saliency mechanism has been considered crucial in the human visual system and helpful to object detection and recognition. This paper addresses a novel feature-based model for visual saliency detection. It consists of two steps: first, using the learned overcomplete sparse bases to represent image patches; and then, estimating saliency information via low-rank and sparsity matrix decomposition. We compare our model with the previous methods on natural images. Experimental results on both natural images and psychological patterns show that our model performs competitively for visual saliency detection task, and suggest the potential application of matrix decomposition and convex optimization for image analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>B Y THE guidance of attention, the human visual system is able to locate objects of interest in a complex scene, where attention provides a mechanism to quickly identify subsets within the scene that contain important information. Besides the scientific goal of understanding this human behavior, a computational approach to visual attention also contributes to the image analysis.</p><p>During the past decade, several computational models have been invented to simulate human visual attention. Inspired by the feature-integration theory <ref type="bibr" target="#b0">[1]</ref>, Itti et al. <ref type="bibr" target="#b1">[2]</ref> proposed one of the earliest bottom-up selective attention model by utilizing color, intensity and orientation of images. Bruce et al. <ref type="bibr" target="#b2">[3]</ref> introduced the idea of using Shannon's self-information to measure the perceptual saliency. More recently, Hou et al. <ref type="bibr" target="#b3">[4]</ref> proposed a dynamic visual attention approach to calculate the saliency map based on Incremental Coding Length (ICL).</p><p>In this paper, we propose a novel approach towards visual saliency detection via matrix decomposition. Specifically, by sparse prior, we learn an overcomplete dictionary of image patches. The input image is divided into overlapped patches and the patches are further decomposed over the dictionary. Thus, the image can be represented as the patch-wise decomposition over the dictionary. Such a representation has the natural form of a matrix, with each column representing the response of a patch. The matrix can be considered as the sum of two parts: the regular part by a low-rank matrix and the salient part by a sparse matrix <ref type="bibr" target="#b4">[5]</ref>. We show that it is possible to solve the rank-sparsity decomposition by minimizing a weighted combination of the trace norm and of the norm in the design of a tractable convex optimization procedure <ref type="bibr" target="#b5">[6]</ref>. Finally, the sparsity matrix in feature space, representing the response of image over a dictionary, is transformed to the image to generate the saliency map. Experiments on human eye fixation data indicate that our method can achieve accurate results.</p><p>The proposed model differs significantly from most previous related approaches in two aspects. First, as the proposed model begins with a rational image information representation, it focuses on pursuing saliency components via low-rank-sparsity matrix decomposition. Although this technique is not our original work, to our best knowledge, we firstly apply it to the visual saliency detection task. Second, our model advocates the use of a feature-based model via overcomplete sparse bases, which is more reasonable to represent the image patches as our brain.</p><p>The rest of the paper is organized as follows. In Section II, we introduce the motivation to formulate the visual saliency as a matrix decomposition problem, and then give the concept of sparse feature representation to learn the basis functions. Section III presents how to solve the matrix decomposition problem. Also, we give more details on extracting the saliency map from the decomposed sparse matrix. Section IV shows experimental results of comparison between our model and previous methods, and Section V concludes this paper. Refer to Fig. <ref type="figure" target="#fig_0">1</ref> for an overview of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. THE THEORY</head><p>One basic principle in the visual system is to suppress the response to frequently occurring input patterns, while at the same 1070-9908/$26.00 © 2010 IEEE time keeping sensitive to novel features. Thus, stimuli that correlate to rarely activated features will become salient in our brain, and can be more likely delivered to the next stages of processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Saliency as Sparse Component</head><p>From a view of cognitive science, the image information can be decomposed into two parts where denotes the information with high regularities, and represents the novelty part. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates this concept. In this sense, we can leverage on the fact that such information has low intrinsic dimensionality which alleviates the curse of dimensionality. More precisely, this says that the redundant information should have approximately to be low-rank. Meanwhile, always builds on the property that a preference for a small number of objects. Intuitively, this property suggests the distribution of tend to be sparse. Therefore, we cast the saliency detection as a sparse component recovery problem. In the following sections, we will demonstrate a method to obtain the visual saliency via direct low-rank and sparsity matrix decomposition in the feature-based domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sparse Coding Scheme in Feature Space</head><p>In the previous applications on matrix decomposition, the sparse component is commonly considered as noise <ref type="bibr" target="#b6">[7]</ref>, rather than saliency. In order to avoid image noise in spatial domain, we must seek a more reasonable space to extract the sparse component. Many studies in neuroscience suggest that sparse coding strategy <ref type="bibr" target="#b7">[8]</ref> is an efficient coding way for modeling natural scenes as a sparse representation, successfully simulating the V1 population responses to natural stimuli. Based on this observation, we transform images into feature space as a linear combination of sparse coding basis functions where noise will be suppressed. The basic idea of sparse coding is simple: a vectorized image patch, can be represented in terms of a linear superposition of basis as (</p><formula xml:id="formula_0">)<label>1</label></formula><p>where denotes the basis dictionary with columns as bases, and , is the response on parch . Note that since it is an overcomplete dictionary. Fig. <ref type="figure" target="#fig_2">3</ref> shows a set of trained bases (here is the color image patches). In general, more bases contribute to a better performance. We find that 300 is a good tradeoff between efficacy and efficiency. In our practice for each basis, we set the patch size , with 8 8 as the size and 3 as the dimension of RGB space. To suppress noise in original image space, we advocate the use of response matrix , ( is the number of basis atoms in an overcomplete dictionary, and is the number of patch from an input image) which stacks the response of each input patch on all basis as its column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Dictionary Learning for Sparse Coding</head><p>In order to learn the dictionary, we consider a finite training set of image patches , and optimize the empirical cost function as follows</p><formula xml:id="formula_1">(2) (3)</formula><p>where is a regularization parameter that balances between the distortion (the first term) and sparsity (the second term), is the response vector. And is the dictionary whose column represents the basis vector. Note that (2) is used to prevent from being arbitrarily large. The optimization problem (3) can be efficiently solved by the recently proposed method <ref type="bibr" target="#b8">[9]</ref> which is a fast online algorithm based on stochastic approximations.</p><p>Given the image patch and learned overcomplete dictionary , we want to estimate the coefficients in the feature space. We use Lasso <ref type="bibr" target="#b9">[10]</ref> to efficiently solve the -regularized least squares problem <ref type="bibr" target="#b3">(4)</ref> where indicates the tradeoff between sparsity and distortion. Thus we obtain the response for each patch and batch them into a response matrix as the representation in the feature space for an input image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SALIENCY PURSUIT VIA DECOMPOSITION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Rank-Sparsity Decomposition</head><p>After transforming original image to the feature space via sparse coding, one is supposed to recover the saliency part. The problem formulation suggests a conceptual solution: given the response matrix , where and are the unknown low-rank and sparsity matrix respectively, recover that is sparse:</p><p>. The Lagrangian reformulation of this optimization problem is: <ref type="bibr" target="#b4">(5)</ref> where balances between rank and sparsity. For an appropriate , the solution recovers the pair that generated the data . In general, solving the decomposition problem is NP-hard and no efficient solution is guaranteed. Fortunately, according to the recent work <ref type="bibr" target="#b4">[5]</ref>, the trace and the norm have been shown to be the tight convex approximation for the rank and the norm of matrices, respectively. Let that denotes the trace norm of the matrix , where are the singular values. And let which denotes the norm of the matrix , one can relax by and obtain a tractable optimization problem:</p><formula xml:id="formula_2">(6)</formula><p>Moreover, recent theoretic analysis <ref type="bibr" target="#b6">[7]</ref> indicates that under rather weak assumptions, ( <ref type="formula">6</ref>) is able to exactly recover the lowrank matrix and sparse matrix in high probability. Various algorithms exist <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b6">[7]</ref>. We apply the inexact ALM (IALM) method <ref type="bibr" target="#b5">[6]</ref> to extract the sparsity matrix .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. From Sparse Matrix to Saliency Map</head><p>After the sparsity matrix is obtained, with each column as the response of an input patch. We quantify the response by the norm:</p><p>Since patch overlapping is allowed, the final saliency map is generated by accumulating the saliency patch. Some results are shown in Fig. <ref type="figure" target="#fig_3">4</ref> and Fig. <ref type="figure" target="#fig_4">5</ref>, where the maximum region in map denotes the most salient objects in image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>In our experiments, the overcomplete bases are trained from the natural images database collected by <ref type="bibr" target="#b10">[11]</ref> (refer to Fig. <ref type="figure" target="#fig_2">3</ref> for the visual result). We sequentially sample all over the possible image patches with a 8 8 window. To access the performance, we computed the area under Receiver Operating Characteristic (ROC) curve (refer <ref type="bibr" target="#b11">[12]</ref> for the details of definition) on the fixation data collected by Bruce et al. <ref type="bibr" target="#b2">[3]</ref> as the benchmark. The data set contains a collection of eye movements from  <ref type="bibr" target="#b3">[4]</ref>. (e) Saliency map produced by Bruce's method <ref type="bibr" target="#b2">[3]</ref>. (f) Saliency map generated by Itti's model <ref type="bibr" target="#b1">[2]</ref> using the SaliencyToolBox (STB) <ref type="bibr" target="#b12">[13]</ref>. 20 observers as they viewed 120 images. Specifically, Tatler's version of ROC score <ref type="bibr" target="#b11">[12]</ref> compares the saliency of attended points against a baseline based on the distribution of human saccades rather than the uniform distribution (refer <ref type="bibr" target="#b11">[12]</ref> for the details of the procedure of computing the ROC score). Here we applied this validation technique (following the same procedure as in <ref type="bibr" target="#b15">[16]</ref>) to compensate for the so-called central fixation bias. As pointed out in <ref type="bibr" target="#b15">[16]</ref>, the validation technique used in <ref type="bibr" target="#b11">[12]</ref> is prone to underestimate the performance, while the performance would be overestimated without such a validation. However this measurement does not affect the efficacy for comparing the relative performance of different models. Fig. <ref type="figure" target="#fig_3">4</ref> shows the visual comparison of our method with the previous approaches <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b12">[13]</ref>. The mean and the standard errors are reported in Table <ref type="table" target="#tab_0">I</ref>. <ref type="foot" target="#foot_0">1</ref>We also test our method with psychological patterns. As observed from Fig. <ref type="figure" target="#fig_5">6</ref>, on one hand, the color distinction can be easily detected. On the other side, it fails to find out the unique  circle among "C," which is similar with the result of Hou's approach in <ref type="bibr" target="#b14">[15]</ref>. In our analysis, this is because the bases are trained from natural images where the artifacts in the psychological patterns rarely exist, while the orientation is more pronounced in the psychological patterns. Thus our model may suffer from this limitation. Even so, as shown in Fig. <ref type="figure" target="#fig_2">3</ref>, our bases show better orientation regularity than the ICA bases that are depicted in <ref type="bibr" target="#b3">[4]</ref>, which we believe contributes to the performance of our model on the psychological patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>We presented a novel model to estimate saliency map with the purpose of object detection. The method is mainly based on low-rank and sparsity matrix decomposition algorithm, which focuses on directly extracting information from sparse matrix. Our experimental results suggest the potential power for convex programming as a tool for image analysis. Moreover, although the proposed method emphasizes the sparse component, in some applications, the low-rank part obtained by it truly is the object of interest; see the redundant part in Fig. <ref type="figure" target="#fig_1">2</ref>. We experimentally compare our method with the previous models. And the experimental results show that our approach performs competitively to find the salient objects in natural images and in psychological patterns.</p><p>In future work, we plan to extend the rank-sparsity decomposition from matrix to tensor where the three color channels can be elegantly incorporated. Also, for the spatial consistency of saliency, the idea of block-sparse structure <ref type="bibr" target="#b16">[17]</ref> might be introduced.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed method.</figDesc><graphic coords="1,303.66,133.94,246.00,178.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Image Information can be decomposed into two parts: Redundancy and Saliency.</figDesc><graphic coords="2,57.12,66.54,216.00,189.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Overcomplete bases whose size is 8 2 8 2 3 for each, trained from natural images. Note that the bases show orientation regularity benefiting from sparse coding.</figDesc><graphic coords="2,305.16,66.70,246.00,89.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of our model with previous methods. (a) Original Image. (b) Fixation density map based on human eye tracking data. (c) Saliency map produced by our model. (d) Saliency map by ICL<ref type="bibr" target="#b3">[4]</ref>. (e) Saliency map produced by Bruce's method<ref type="bibr" target="#b2">[3]</ref>. (f) Saliency map generated by Itti's model<ref type="bibr" target="#b1">[2]</ref> using the SaliencyToolBox (STB)<ref type="bibr" target="#b12">[13]</ref>.</figDesc><graphic coords="3,303.66,71.30,246.00,184.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Results produced by our model on Bruce's dataset. Top: original image; middle: ground truth; bottom: our results.</figDesc><graphic coords="3,303.78,344.98,245.00,140.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Responses to psychological patterns of the proposed method. From left to right: curve, closure, density, color. These images available at http://www. csc.ncsu.edu/faculty/healey/PP/index.html.</figDesc><graphic coords="4,42.12,144.50,246.00,124.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I ROC</head><label>I</label><figDesc>(SE) OF DIFFERENT METHODS</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The ROC values for Bruce and Tsotos's method<ref type="bibr" target="#b2">[3]</ref> have been updated in a recent publication<ref type="bibr" target="#b13">[14]</ref> with an improved ROC area score of 0.781.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by China National 973 Program 2006CB303103, China NSFC Key Program 60833009, NSFC Program 60975012, and by National 863 program 2009AA01Z330. The associate editor coordinating the review of this manuscript and approving it for publication was Prof Lisimachos Paul Kondi.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A feature-integration theory of attention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gelade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="136" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Saliency based on information maximization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dynamic visual attention: Searching for coding length increments</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust principal component analysis: Exact recovery of corrupted low-rank matrices by convex optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low Rank Matrices UIUC Tech</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno>Rep. UILU-ENG-09-2215</idno>
		<imprint>
			<date type="published" when="2009-10">Oct. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust principal component analysis?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Candês</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Online learning for matrix factorization and sparse coding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">SLEP: A Sparse Learning Package</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<ptr target="http://www.public.asu.edu/jye02/Software/SLEP2010" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling the shape of the scene: A holistic representation of the spatial envelope</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual correlates of fixation selection: Effects of scale and time</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tatler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baddele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gilchrist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="643" to="659" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling attention to salient proto-objects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1395" to="1407" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Saliency, attention, and visual search: An information theoretic approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Saliency detection: A spectral residual approach</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition</title>
		<meeting>Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SUN: A Bayesian framework for saliency using natural statistics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient recovery of jointly sparse vectors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
