<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Architecture and Performance of Devito, a System for Automated Stencil Computation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Luporini</surname></persName>
							<email>f.luporini12@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Imperial College London MATHIAS LOUBOUTIN</orgName>
								<orgName type="department" key="dep2">Institute of Technology MICHAEL LANGE</orgName>
								<orgName type="department" key="dep3">Imperial College London PHILIPP WITTE</orgName>
								<orgName type="department" key="dep4">Institute of Technology JAN HÜCKELHEIM</orgName>
								<orgName type="laboratory">European Centre for Medium-Range Weather Forecasts NAVJOT KUKREJA</orgName>
								<orgName type="institution">Imperial College London CHARLES YOUNT</orgName>
								<address>
									<country>Georgia, Georgia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">H J</forename><surname>Kelly</surname></persName>
							<email>p.kelly@imperial.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">Intel Corporation</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gerard</forename><forename type="middle">J</forename><surname>Gorman</surname></persName>
							<email>g.gorman@imperial.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">FELIX J. HERRMANN</orgName>
								<orgName type="institution" key="instit1">Imperial College London</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Navjot</forename><surname>Kukreja</surname></persName>
							<email>n.kukreja@imperial.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Hückelheim</surname></persName>
							<email>j.hueckelheim@imperial.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mathias</forename><surname>Louboutin</surname></persName>
							<email>mlouboutin3@gatech.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Imperial College Lon-don</orgName>
								<address>
									<addrLine>South Kensington</addrLine>
									<postCode>SW7 2BU</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philipp</forename><surname>Witte</surname></persName>
							<email>pwitte3@gatech.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Imperial College Lon-don</orgName>
								<address>
									<addrLine>South Kensington</addrLine>
									<postCode>SW7 2BU</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Felix</forename><forename type="middle">J</forename><surname>Herrmann</surname></persName>
							<email>felix.herrmann@gatech.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Imperial College Lon-don</orgName>
								<address>
									<addrLine>South Kensington</addrLine>
									<postCode>SW7 2BU</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Lange</surname></persName>
							<email>michael.lange@ecmwf.int</email>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Architecture and Performance of Devito, a System for Automated Stencil Computation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FA0D091AD88B38F70D71F49FE2E0A85F</idno>
					<idno type="DOI">10.1145/3374916</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts:</term>
					<term>Mathematics of computing → Mathematical software performance</term>
					<term>• Software and its engineering → Compilers</term>
					<term>Domain specific languages</term>
					<term>Finite-difference method, stencil, domain-specific language, symbolic processing, structured grid, compiler, performance optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Stencil computations are a key part of many high-performance computing applications, such as image processing, convolutional neural networks, and finite-difference solvers for partial differential equations. Devito is a framework capable of generating highly optimized code given symbolic equations expressed in Python, specialized in, but not limited to, affine (stencil) codes. The lowering process-from mathematical equations down to C++ code-is performed by the Devito compiler through a series of intermediate representations.</p><p>Several performance optimizations are introduced, including advanced common sub-expressions elimination, tiling, and parallelization. Some of these are obtained through well-established stencil optimizers, integrated in the backend of the Devito compiler. The architecture of the Devito compiler, as well as the performance optimizations that are applied when generating code, are presented. The effectiveness of such performance optimizations is demonstrated using operators drawn from seismic imaging applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Architecture and Performance of Devito, a System for Automated Stencil Computation 6:3 facilitates performance portability across different computer architectures <ref type="bibr" target="#b28">[29]</ref>. This is important, as industrial codes are often used on a variety of platforms, including clusters with multi-core CPUs, GPUs, and many-core chips spread across several compute nodes, as well as various cloud platforms. Devito also performs high-level transformations for floating-point operation (FLOP) reduction based on symbolic manipulation, as well as loop-level optimizations as implemented in Devito's own optimizer, or using a third-party stencil compiler such as YASK <ref type="bibr" target="#b41">[42]</ref>. The Devito compiler is presented in detail in Sections 4, 5, and 6.</p><p>After the presentation of the Devito compiler, we show test cases in Section 7 that are inspired by real-world seismic-imaging problems. The article finishes with directions for future work and conclusions in Sections 8 and 9, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The objective of maximizing productivity and performance through frameworks based upon DSLs has long been pursued. In addition to well-known systems such as Mathematica and Matlab, which span broad mathematical areas, there are several tools specialized in numerical methods for PDEs, some dating back to the 1970s <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">DSL-Based Frameworks for PDEs</head><p>One noteworthy contemporary framework centered on DSLs is FEniCS <ref type="bibr" target="#b22">[23]</ref>, which allows the specification of weak variational forms, via UFL <ref type="bibr" target="#b1">[2]</ref>, and FE methods, through a high-level syntax. Firedrake <ref type="bibr" target="#b30">[31]</ref> implements the same languages as FEniCS, although it differs from it in several features and architectural choices. Devito is heavily influenced by these two successful projects, particularly by their philosophy and design. Since solving a PDE is often a small step of a larger workflow, the choice of Python to implement this software provides access to a wide ecosystem of scientific packages. Firedrake also follows the principle of graceful degradation by providing a very simple lower-level API to escape the abstraction when non-standard calculations (i.e., unrelated to the FE formulation) are required. Likewise, Devito allows injecting arbitrary expressions into the FD specification; this feature has been used in real-life cases, such as for interpolation in seismic imaging operators. However, a major difference is that Devito lacks a formal specification language such us UFL in FEniCS/Firedrake. This is partly because there is no systematic foundation underpinning FD, as opposed to FE which relies upon the theory of Hilbert spaces <ref type="bibr" target="#b4">[5]</ref>. Yet another distinction is that, for performance reasons, Devito takes control of the time-stepping loop. Other examples of embedded DSLs are provided by the OpenFOAM project, with a language for FV <ref type="bibr" target="#b13">[14]</ref>, and by PyFR, which targets flux reconstruction methods <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">High-Level Approaches to FDs</head><p>Due to its simplicity, the FD method has been the subject of multiple research projects, chiefly targeting the design of effective software abstraction and/or the generation of high-performance code <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22]</ref>. Devito distinguishes itself from previous work in several ways, including support for the principle of graceful degradation for when the DSL does not cover a feature required by an application, incorporation of a symbolic mathematics engine, using actual compiler technology rather than template-based code generation, and adoption of a native Python interface that naturally allows composition into complex workflows such as optimization and machine-learning frameworks.</p><p>At a lower level of abstraction there are several tools targeting "stencil" computation (FD codes belong to this class), whose major objective is the generation of efficient code. Some of them provide a DSL <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44]</ref>, whereas others are compilers or user-driven code generation systems, often based upon a polyhedral model (e.g., <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19]</ref>). From the Devito standpoint, the aim is to harness these tools-for example, by integrating them-to maximize performance portability. As a proof of concept, we shall discuss the integration of one such tool, namely YASK <ref type="bibr" target="#b41">[42]</ref>, with Devito.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Devito and Seismic Imaging</head><p>Devito is a general-purpose system, not restricted to specific PDEs, so it can be used for any form of the wave equation. Thus, unlike software specialized in seismic exploration, like IWAVE <ref type="bibr" target="#b32">[33]</ref> and Madagascar <ref type="bibr" target="#b12">[13]</ref>, it suffers neither from the restriction to a small set of wave equations and discretizations, nor from the lack of portability and composability typical of a pure C/Fortran environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Performance Optimizations</head><p>The Devito compiler can introduce three types of performance optimizations: FLOP reduction, data locality, and parallelism. Typical FLOP reduction transformations are common sub-expressions elimination (CSE), factorization, and code motion. A thorough review is provided by Ding and Shen <ref type="bibr" target="#b10">[11]</ref>. Devito applies all of these techniques (see Section 5.1). Particularly relevant for stencil computation is the search for redundancies across consecutive loop iterations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21]</ref>. This is at the core of the strategy described in Section 6, which essentially extends these ideas with optimizations for data locality. Typical loop transformations for parallelism and data locality <ref type="bibr" target="#b17">[18]</ref> are also automatically introduced by the Devito compiler (e.g., loop blocking, vectorization); more details will be provided in Sections 5.2 and 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SPECIFICATION OF AN FD METHOD WITH DEVITO</head><p>The Devito DSL allows concise expression of FD and general stencil operations using a mathematical notation. It uses SymPy <ref type="bibr" target="#b27">[28]</ref> for the specification and manipulation of stencil expressions. In this section, we describe the use of Devito's DSL to build PDE solvers. Although the examples used here are for FD, the DSL can describe a large class of operations, such as convolutions or basic linear algebra operations (e.g., chained tensor multiplications).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Symbolic Types</head><p>The key steps to implement a numerical kernel with Devito are shown in Figure <ref type="figure">1</ref>. We describe this workflow, as well as fundamental features of the Devito API, using the acoustic wave equation, also known as d'Alembertian or Box operator. Its continuous form is given by</p><formula xml:id="formula_0">m(x, y, z) d 2 u (x, y, z, t ) dt 2 -∇ 2 u (x, y, z, t ) = q s , u (x, y, z, 0) = 0, du (x, y, z, t ) dt | t =0 = 0,<label>(1)</label></formula><p>where the variables of this expression are defined as follows:</p><p>• m(x, y, z) = 1 c (x,y,z ) 2 is the parameterization of the sub-surface with c (x, y, z) being the speed of sound as a function of the three space coordinates (x, y, z); • u (x, y, z, t ) is the spatially varying acoustic wavefield, with the additional dimension of time t; and • q s is the source term, which is a point source in this case.</p><p>The first step toward solving this equation is the definition of a discrete computational grid on which the model parameters, wavefields, and source are defined. The computational grid is defined as a Grid(shape) object, where shape is the number of grid points in each spatial dimension. Optional arguments for instantiating a Grid are extent, which defines the extent in physical units, and origin, the origin of the coordinate system, with respect to which all other coordinates are defined.</p><p>The next step is the symbolic definition of the squared slowness, wavefield, and source. For this, we introduce some fundamental types:</p><p>• Function represents a discrete spatially varying function, such as the velocity. A Function is instantiated for a defined name and a given Grid. • TimeFunction represents a discrete function that is both spatially varying and time dependent, such as wavefields. Again, a TimeFunction object is defined on an existing Grid and is identified by its name. • SparseFunction and SparseTimeFunction represent sparse functions-that is, functions that are only defined over a subset of the grid, such as a seismic point source. The corresponding object is defined on a Grid, identified by a name, and also requires the coordinates defining the location of the sparse points.</p><p>Apart from the grid information, these objects carry their respective FD discretization information in space and time. They also have a data field that contains values of the respective function at the defined grid points. By default, data is initialized with zeros and therefore automatically satisfies the initial conditions from Equation <ref type="bibr" target="#b0">(1)</ref>. The initialization of the fields to solve the wave equation over a 1D grid is displayed in Listing 1.</p><p>Listing 1. Setup Functions to express and solve the acoustic wave equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discretization</head><p>With symbolic objects that represent the discrete velocity model, wavefields, and source function, we can now define the full discretized wave equation. As mentioned earlier, one of the main features of Devito is the possibility to formulate stencil computations as concise mathematical expressions. To do so, we provide shortcuts to classic FD stencils, as well as the functions to define arbitrary stencils. The shortcuts are accessed as object properties and are supported by TimeFunction and Function objects. For example, we can take spatial and temporal derivatives of the wavefield u via the shorthand expressions u.dx and u.dt (Listing 2). Furthermore, Devito provides shortcuts for common differential operations such as the Laplacian via u.laplace. The full discrete wave equation can then be implemented in a single line of Python (Listing 3).</p><p>Listing 3. Expressing the wave equation.</p><p>To solve the time-dependent wave equation with an explicit time-stepping scheme, the symbolic expression representing our PDE has to be rearranged such that it yields an update rule for the wavefield u at the next timestep:</p><formula xml:id="formula_1">u (t + dt ) = f (u (t ), u (t -dt ))</formula><p>). Devito allows to rearrange the PDE expression automatically using the solve function, as shown in Listing 4.</p><p>Listing 4. Time-stepping scheme for the acoustic wave equation. region=INTERIOR ensures that the Dirichlet BCs at the edges of the grid are satisfied.</p><p>Note that the stencil expression in <ref type="bibr">Listing 4</ref> does not yet contain the point source q. This could be included as a regular Function that has zeros all over the grid except for a few points, but it would obviously be wasteful. Instead, SparseFunctions allow to perform operations, such as injecting a source or sampling the wavefield, at a subset of points determined by coordinates. In general, receivers (where the solution is to sampled) are not co-located with grid points. Therefore, an interpolation operator is needed (e.g., trilinear interpolation for 3D). To ensure a consistent discrete adjoint, source terms are implemented as the adjoint of the interpolation operator usedthat is, the gather operation for interpolation becomes a scatter operation for source injection. Equation <ref type="bibr" target="#b1">(2)</ref> gives the expressions for linear interpolation in 1D assuming the origin is zero for readability:</p><p>Find the two closest indices:</p><formula xml:id="formula_2">x 1 = q coor ds [i] h x , x 2 = x 1 + 1 Interpolation coefficients: c 1 = 1 - q coor ds [i] -x 1 x 2 -x 1 , c 2 = 1 - x 2 -q coor ds [i] x 2 -x 1 Interpolate: q[i] = c 1 * u[t, x 1 ] + c 2 * u[t, x 2 ] Inject: u[t, x 1 ] = q[i] * c 1 , u[t, x 2 ] = q[i] * c 2 .</formula><p>(2)</p><p>Architecture and Performance of Devito, a System for Automated Stencil Computation 6:7 Listing 5. Expressing the injection of a source into a field.</p><p>To inject a point source defined at the physical location q_coords into the stencil expression, we use the inject function of the SparseTimeFunction object that represents our seismic source (Listing 5). <ref type="foot" target="#foot_1">1</ref>The inject function takes the field being updated as an input argument (in this case u.forward), whereas expr=dt**2 * q / m is the expression being injected. The result of the inject function is a list of symbolic expressions that correspond to the different steps of Equation (2). As we shall see, these expressions are eventually joined together and used to create an Operator object-the solver of our PDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Boundary Conditions</head><p>Simple boundary conditions (BCs), such as Dirichlet BCs, can be imposed on individual equations through special keywords (see <ref type="bibr">Listing 4)</ref>. For more exotic schemes, instead, the BCs need to be explicitly written (e.g., Higdon BCs <ref type="bibr" target="#b15">[16]</ref>), just like any of the symbolic expressions defined in preceding listings. For reasons of space, this aspect is not elaborated further; the interested reader may refer to Louboutin and Luporini <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Control Flow</head><p>By default, the extent of a TimeFunction in the time dimension is limited by its time order. Hence, the shape of u in Listing 1 is (time_order + 1, nx ) = (3, nx ). The iterative method will then access u via modulo iteration (i.e., u[t%3, . . .]). In many scenarios, however, the entire time history, or at least periodic time slices, should be saved (e.g., for inversion algorithms). Listing 6 expands our running example with an equation that saves the content of u every four iterations, up to a maximum of save = 100 time slices. In general, all equations that access Functions (or TimeFunctions) employing one or more ConditionalDimensions will be conditionally executed. The condition may be a number indicating how many iterations should pass between two executions of the same equation, or even an arbitrarily complex expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Domain, Halo, and Padding Regions</head><p>A Function internally distinguishes between three regions of points: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain:</head><p>This represents the computational domain of the Function and is inferred from the input Grid. This includes any elements added to the physical domain purely for computational purposes, such as absorbing boundary layers. Halo: The grid points surrounding the domain region-for instance, "ghost" points that are accessed by the stencil when iterating in proximity of the domain boundary. Padding: The grid points surrounding the halo region, which are allocated for performance optimizations, such as data alignment. Normally this region should be of no interest to a user of Devito, except for precise measurement of memory allocated for each Function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE DEVITO COMPILER</head><p>In Devito, an Operator carries out three fundamental tasks: generation of low-level code, JIT compilation, and execution. The Operator input consists of one or more symbolic equations. In the generated code, these equations are scheduled within loop nests of suitable depth and extent. The Operator also accepts substitution rules (to replace symbols with constant values) and optimization levels for the Devito Symbolic Engine (DSE) and the Devito Loop Engine (DLE). By default, all DSE and DLE optimizations that are known to unconditionally improve performance are automatically applied. The same Operator may be reused with different input data; JIT compilation occurs only once, triggered by the first execution. Overall, this lowering process-from high-level equations to dynamically compiled and executable code-consists of multiple compiler passes, summarized in Figure <ref type="figure" target="#fig_1">2</ref> and discussed in the following sections (a minimal background in data dependence analysis is recommended; the unfamiliar reader may refer to a classic textbook such as that of Aho et al. <ref type="bibr" target="#b0">[1]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Equation Lowering</head><p>In this pass, three main tasks are carried out: indexification, substitution, and domain-alignment:</p><p>• As explained in Section 3, the input equations typically involve one or more indexed Functions. The indexification consists of converting such objects into actual arrays. An array always keeps a reference to its originating Function. For instance, all accesses to u such as u[t, x + 1] and u[t + 1, x -2] would store a pointer to the same, user-defined Function u (t, x ). This metadata is exploited throughout the various compilation passes. • During substitution, the user-provided substitution rules are applied. These may be given for any literal appearing in the input equations, such as the grid spacing symbols. Applying a substitution rule increases the chances of constant folding, but it makes the Operator less generic. The values of symbols for which no substitution rule is available are provided at execution time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Local Analysis</head><p>The lowered equations are analyzed to collect information relevant for the Operator construction and execution. In this pass, an equation is inspected "in isolation," ignoring its relationship with the rest of the input. The following metadata are retrieved and/or computed:</p><p>Architecture and Performance of Devito, a System for Automated Stencil Computation 6:9 • input and output Functions;</p><p>• Dimensions, which are topologically ordered based on how they appear in the various array index functions; and • two notable Spaces: the iteration space, ISpace, and the data space, DSpace.</p><p>A Space is a collection of points given by the product of n compact intervals on Z. </p><formula xml:id="formula_3">[t[0, 0] + , x[0, 0] * ].</formula><p>The first entry t[0, 0] + indicates that, along t, the equation should run between t m + 0 and t M + 0 (extremes included) in the forward direction, as indicated by the symbol +. This is because there is a flow dependency in t, so only a unitary positive stepping increment (i.e., t = t + 1) allows a correct propagation of information across consecutive iterations. The only difference along x is that the iteration direction is now arbitrary, as indicated by * . The DSpace is [t[0, 1], x[0, 0]]; intuitively, the entry t[0, 1] is used right before running an Operator to provide a default value for t M -in particular, t M will be set to the largest possible value that does not cause out-of-domain accesses (i.e., out-of-bounds array accesses). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Clustering</head><p>A Cluster is a sequence of equations having (i) same ISpace, (ii) same control flow (i.e., same ConditionalDimensions), and (iii) no dimension-carried "true" anti-dependencies among them.</p><p>As an example, consider again the setup in Section 3. The equation stencil cannot be "clusterized" with the equations in the injection list, as their ISpaces are different. However, the equations in injection can be grouped together in the same Cluster because (i) they have same ISpace [t[0, 0] * , p q [0, 0] * ], (ii) they have the same control flow, and (iii) there are no true anti-dependencies among them (note that the second equation in injection does write to u[t + 1, . . .], but as explained later this is in fact a reduction, which is a "false" anti-dependency).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Iteration Direction.</head><p>First, each equation is assigned a new ISpace, based upon a global analysis. Any of the iteration directions that had been marked as "arbitrary" ( * ) during local analysis may now be enforced to forward (+) or backward (-). This process exploits data dependence analysis.</p><p>For instance, consider the flow dependency between stencil and the injection equations. If we want u to be up-to-date when evaluating injection, then we eventually need all equations to be scheduled sequentially within the t loop. For this, the ISpaces of the injection equations are specialized by enforcing the direction forward along the Dimension t.</p><formula xml:id="formula_4">The new ISpace is [t[0, 0] + , p q [0, 0] * ].</formula><p>Algorithm 1 illustrates how the enforcement of iteration directions is achieved in general. Whenever a clash is detected (i.e., two equations with ISpace [d[0, 0] + , . . .] and [d[0, 0] -, . . .]), the original direction determined by the local analysis pass is kept (lines 11 and 13), which will eventually lead to generating different loops. 2 Grouping. This step performs the actual clustering, checking ISpaces and antidependencies, as well as handling control flow. The procedure is shown in Algorithm 2; some explanations follow:</p><p>• Robust data-dependence analysis, capable of tracking flow-, anti-, and output-dependencies at the level of array accesses, is necessary. In particular, it must be able to tell whether two generic array accesses induce a dependency or not. The data-dependence analysis performed is conservative-that is, a dependency is always assumed when a test is inconclusive. Dependence testing is based on the standard Lamport test <ref type="bibr" target="#b0">[1]</ref>. In Algorithm 2, data-dependence analysis is carried out by the function get_dependencies. • If an anti-dependency is detected along a Dimension i, then i is marked as atomic-meaning that no further clustering can occur along i. This information is also exploited by later Operator passes (see Section 4.5). • Reductions, and particularly increments, are treated specially. They represent a special form of anti-dependency, as they do not break clustering. get_dependences detects reductions and removes them from the set of anti-dependencies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Symbolic Optimization</head><p>The DSE is a macro-pass reducing the arithmetic strength of Clusters (e.g., their operation count). It consists of a series of passes, ranging from standard CSE to more advanced rewrite procedures, applied individually to each Cluster. The DSE output is a new ordered sequence of Clusters: there may be more or fewer Clusters than in the input, and both the overall number of equations and the sequence of arithmetic operations might differ. The DSE passes are discussed in Section 5.1.</p><p>We remark that the DSE only operates on Clusters (i.e., on collections of equations); there is no concept of "loop" at this stage yet. However, by altering Clusters, the DSE has an indirect impact on the final loop-nest structure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">IET Construction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="18">end for</head><p>Consider again our running acoustic wave equation example. There are three Clusters in total: C 1 for stencil, C 2 for save, and C 3 for the equations in injection. We use Algorithm 3-an excerpt of the actual cluster scheduling algorithm-to explain how this sequence of Clusters is turned into an IET. Initially, the schedule list is empty, so when C 1 is handled, two nested Iterations are created (line 15) for the Dimensions t and x, respectively. Subsequently, C 2 's ISpace and the current schedule are compared (line 5). It turns out that t appears among C 2 's guards, and hence the for loop is exited at line 12 without inspecting the second and last iteration. Thus, index = 1, and the previously built Iteration over t is reused. Finally, when processing C 3 , the for loop is exited at the second iteration due to line 6, since p q x. Again, the t Iteration is reused, whereas a new Iteration is constructed for the Dimension p q . Eventually, the constructed IET is as in Listing 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">IET Analysis</head><p>The newly constructed IET is analyzed to determine Iteration properties such as sequential, parallel, and vectorizable, which are then attached to the relevant nodes in the IET. These properties are used for loop optimization, although only by a later pass (see Section 4.7). To determine whether an Iteration is parallel or sequential, a fundamental result from compiler theory is used-the i-th Iteration in a nest comprising n Iterations is parallel if for all dependencies D, expressed as distance vectors</p><formula xml:id="formula_5">D = (d 0 , . . . ,d n-1 ), either (d 1 , . . . ,d i-1 ) &gt; 0 or (d 1 , . . . ,d i ) = 0 [1].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">IET Optimization</head><p>This macro-pass transforms the IET for performance optimization. Apart from runtime performance, this pass also optimizes for rapid JIT compilation with the underlying C compiler. Several loop optimizations are introduced, including loop blocking, minimization of remainder loops, SIMD vectorization, shared-memory (hierarchical) parallelism via OpenMP, and software prefetching. These will be detailed in Section 5. A backend (see Section 4.9) might provide its own loop optimization engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Synthesis, Dynamic Compilation, and Execution</head><p>Finally, the IET adds variable declarations and header files, as well as instrumentation for performance profiling, in particular, to collect execution times of specific code regions. Declarations are injected into the IET, ensuring they appear as close as possible to the scope in which the relative variables are used while honoring the OpenMP semantics of private and shared variables. To generate C code, a suitable tree visitor inspects the IET and incrementally builds a CGen tree <ref type="bibr" target="#b19">[20]</ref>, which is ultimately translated into a string and written to a file. Such files are stored in a software cache of Devito-generated Operators, JIT-compiled into a shared object, and eventually loaded into the Python environment. The compiled code has a default entry point (a special function), which is called directly from Python at Operator application time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Operator Specialization Through Backends</head><p>In Devito, a backend is a mechanism to specialize data types, as well as Operator passes, while preserving software modularity (inspired by Markall et al. <ref type="bibr" target="#b25">[26]</ref>).</p><p>One of the main objectives of the backend infrastructure is promoting software composability. As explained in Section 2, a significant number of interesting tools exist for stencil optimization, which we may want to integrate with Devito. For example, one of the future goals is to support GPUs, and this might be achieved by writing a new backend implementing the interface between Devito and third-party software specialized for this particular architecture.</p><p>Currently, two backends exist: core the default backend, which relies on the DLE for loop optimization. yask an alternative backend using the YASK stencil compiler to generate optimized C++ code for Intel Xeon and Intel Xeon Phi architectures <ref type="bibr" target="#b41">[42]</ref>. Devito transforms the IET into a format suitable for YASK and uses its API for data management, JIT compilation, and execution. Loop optimization is performed by YASK through the YASK Loop Engine (YLE).</p><p>The core and yask backends share the compilation pipeline in Figure <ref type="figure" target="#fig_1">2</ref> until the loop optimization stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">AUTOMATED PERFORMANCE OPTIMIZATIONS</head><p>As discussed in Section 4, Devito performs symbolic optimizations to reduce the arithmetic strength of the expressions, as well as loop transformations for data locality and parallelism. The former are implemented as a series of compiler passes in the DSE, whereas for the latter there currently are two alternatives, namely the DLE and the YLE (depending on the chosen execution backend). Devito abstracts away the single optimizations passes by providing users with a certain number of optimization levels, called modes, which trigger pre-established sequences of optimizationsanalogous to what general-purpose compilers do with, for example, -O2 and -O3. In Sections 5.1, 5.2, and 5.3, we describe the individual passes provided by the DSE, DLE, and YLE, respectively, whereas in Section 7.1, we explain how these are composed into modes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Devito Symbolic Engine</head><p>The DSE passes attempt to reduce the arithmetic strength of the expressions through FLOPreducing transformations <ref type="bibr" target="#b10">[11]</ref>. They are illustrated in Listings 8 through 11, which derive from the running example used throughout the article. A detailed description follows:</p><p>• Common sub-expressions elimination: Two implementations are available-one based upon SymPy's cse routine and one built on top of more basic SymPy routines, such as xreplace. The former is more powerful, being aware of key arithmetic properties such as associativity; hence, it can discover more redundancies. The latter is simpler but avoids a few critical issues: (i) it has a much quicker turnaround time, (ii) it does not capture integer index expressions (for increased quality of the generated code), and (iii) it tries not to break factorization opportunities. A generalized CSE routine retaining the features and avoiding the drawbacks of both implementations is still under development. By default, the latter implementation is used when the CSE pass is selected. Listing 8. An example of CSE.</p><p>• Factorization: This pass visits each expression tree and tries to factorize FD weights. Factorization is applied without altering the expression structure (e.g., without expanding products) and without performing any heuristic search across groups of expressions. This choice is based on the observation that a more aggressive approach is only rarely helpful (never in the test cases in Section 7), whereas the increase in symbolic processing time could otherwise be significant. The implementation exploits the SymPy collect routine. However, although collect only searches for common factors across the immediate children of a single node, the DSE implementation recursively applies collect to each Add node (i.e., an addition) in the expression tree, until the leaves are reached.</p><p>9. An example of FD weights</p><p>• Extraction: The name stems from the fact that sub-expressions matching a certain condition are pulled out of a larger expression, and their values are stored into suitable scalar or tensor temporaries. For example, a condition could be "extract all time-varying subexpressions whose operation count is larger than a given threshold." A tensor temporary may be preferred over a scalar temporary if the intention is to let the IET construction pass (see Section 4.5) place the pulled sub-expressions within an outer loop nest. Obviously, this comes at the price of additional storage. This peculiar effect-trading operations for memory-will be thoroughly analyzed in Sections 6 and 7. • Detection of shif invariants: In essence, a shift invariant is a sub-expression that is redundantly computed at multiple iteration points. Because of its key role in the shift-invariants elimination (SIE) algorithm, the explanation of how shift invariants are detected is postponed until Section 6.</p><p>11. An example of shift-invariant detection. The shift-invariant 9.0 * temp0 * u[t, x] is assigned to the vector temporary temp[x] so that it can be used in place of the two sub-expressions 9.0 * temp0 * u[t, x + 1] and 9.0 * temp0 * u[t, x + 3].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Devito Loop Engine</head><p>The DLE transforms the IET via classic loop optimizations for parallelism and data locality <ref type="bibr" target="#b17">[18]</ref>. These are summarized as follows:</p><p>• SIMD vectorization: Implemented by enforcing compiler auto-vectorization via special pragmas from the OpenMP 4.0 language. With this approach, the DLE aims to be performance portable across different architectures. However, this strategy causes a significant fraction of vector loads/stores to be unaligned to cache boundaries, due to the stencil offsets. As we shall see, this is a primary cause of performance loss. sequences of loop nests. This is exploited by the SIE algorithm, as shown in Section 6.3. To determine an optimal block shape, an Operator resorts to empirical auto-tuning. • Parallelism: Shared-memory parallelism is introduced by decorating Iterations with suitable OpenMP pragmas. The OpenMP static scheduling is used. Normally, only the outermost fully parallel Iteration is annotated with the parallel pragma. However, heuristically nested fully parallel Iterations are collapsed if the core count is greater than a certain threshold. This pass also ensures that all array temporaries allocated in the scope of the parallel Iteration are declared as private and that storage is allocated where appropriate (stack, heap).</p><p>Summarizing, the DLE applies a sequence of typical stencil optimizations, aiming to reach a minimum level of performance across different architectures. As we shall see, the effectiveness of this approach, based on simple transformations, deteriorates on architectures strongly conceived for hierarchical parallelism. This is one of the main reasons behind the development of the yask backend (see Section 4.9), described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The YASK Loop Engine</head><p>YASK-Yet Another Stencil Kit <ref type="foot" target="#foot_4">2</ref> -is an open source C++ software framework for generating highperformance implementations of stencil codes for Intel Xeon and Intel Xeon Phi processors. Previous publications on YASK have discussed its overall structure <ref type="bibr" target="#b41">[42]</ref> and its application to the Intel Xeon Phi x100 family (code named Knights Corner) <ref type="bibr" target="#b38">[39]</ref> and Intel Xeon Phi x200 family (code named Knights Landing) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40]</ref> many-core CPUs. Unlike Devito, it does not expose a symbolic language to the programmer or create stencils from FD approximations of differential equations. Rather, the programmer provides simple declarative descriptions of the stencil equations using a C++ or Python API. Thus, Devito operates at a level of abstraction higher than that of YASK, whereas YASK provides performance portability across Intel architectures and is more focused on low-level optimizations. Following is a sample of some of the optimizations provided by YASK:</p><p>• Vector folding: In traditional SIMD vectorization, such as that provided by an autovectorizing compiler, the vector elements are arranged sequentially along the unit-stride dimension of the grid, which is also the dimension iterated over in the innermost loop of the stencil kernel. Vector folding is an alternative data-layout method whereby neighboring elements are arranged in small multi-dimensional tiles. Figure <ref type="figure" target="#fig_10">3</ref> illustrates three ways to pack eight double-precision floating-point values into a 512-bit SIMD register. Figure <ref type="figure" target="#fig_10">3</ref>(a) shows a traditional 1D "in-line" layout, and Figure <ref type="figure" target="#fig_10">3</ref>(b) and (c) show alternative 2D and 3D "folded" layouts. Furthermore, these tiles may be ordered in memory in a dimension independent of the dimensions used in vectorization <ref type="bibr" target="#b38">[39]</ref>. The combination of these two techniques can significantly increase overlap and reuse between successive stencil-application iterations, reducing the memory-bandwidth demand. For stencils that are bandwidth bound, this can provide significant performance gains <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b38">39]</ref>. • Software prefetching: Many high-order or staggered-grid stencils require multiple streams of data to be read from memory, which can overwhelm the hardware prefetchers. YASK can automatically generate software-prefetch instructions to improve the cache hit rates, especially on Xeon Phi CPUs.  this technique, sometimes called cache blocking, is typical to assign each thread to one or more small rectilinear subsets of the domain in which to apply the stencil(s). However, if these threads share caches, one thread's data will often evict data needed later by another thread, reducing the effective capacity of the cache. YASK addresses this by employing two levels of OpenMP parallelization: the outer level of parallel loops are applied across the cache blocks, and an inner level is applied across sub-blocks within those tiles. In the case of the Xeon Phi, the eight hyper-threads that share each L2 cache can now cooperate on filling and reusing the data in the cache rather than evicting each other's data.</p><p>YASK also provides other optimizations, such as temporal tiling and MPI support that are not exploited by Devito at the time of writing. The interested reader may refer to Yount and Duran <ref type="bibr" target="#b39">[40]</ref> and Yount et al. <ref type="bibr" target="#b40">[41]</ref>.</p><p>To leverage both the symbolic processing of Devito and the low-level optimizations of YASK, we have integrated the YASK framework into the Devito package. In essence, the Devito yask backend exploits the intermediate representation of an Operator to generate YASK kernels. In Devito v3.1, roughly 70% of the Devito API is supported by the yask backend. <ref type="foot" target="#foot_5">3</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">THE SIE ALGORITHM</head><p>Shift invariants, or "cross-iteration redundancies" (informally introduced in Section 5.1), in FD operators depend on the differential operators used in the PDE(s) and the chosen discretization scheme. From a performance viewpoint, the presence of shift invariants is a non-issue as long as the operator is memory bound, whereas it becomes relevant in kernels with a high arithmetic intensity. In Devito, the SIE algorithm attempts to remove shift invariants with the goal of reducing the operation count. As shown in Section 7, the SIE algorithm has considerable impact in seismic imaging kernels. The algorithm is implemented through the orchestration of multiple DSE and DLE/YLE passes, namely extraction of candidate expressions (DSE), detection of shift invariants (DSE), and loop blocking (DLE/YLE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Extraction of Candidate Expressions</head><p>The criteria for extraction of candidate sub-expressions are as follows:</p><p>• Any maximal time invariant whose operation count is greater thanThr 0 = 10 (floating-point arithmetic only). The term maximal means that the expression is not embedded within a larger time invariant. The default value Thr 0 = 10, determined empirically, provides systematic performance improvements in a series of seismic imaging kernels. Transcendental functions are given a weight in the order of tens of operations, again determined empirically. • Any maximal time varying whose operation count is greater than Thr 1 = 10. Such expressions often lead to shift-invariants, since they typically result from taking spatial and time derivatives on TimeFunctions. In particular, cross derivatives are a major cause of shift invariants.</p><p>This pass leverages the extraction routine described in Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Detection of Shif Invariants</head><p>To define the concept of shift-invariant expressions, we first need to formalize the notion of shifted operands. Here, an operand is regarded as the arithmetic product of a scalar value (or "coefficient") and one or more indexed objects. An indexed object is characterized by a label (i.e., its name), a vector of n dimensions, and a vector of n displacements (one for each dimension). We say that an operand o 1 is shifted with respect to an operand o 0 if o 0 and o 1 have same coefficient, label, and dimensions, and if their displacement vectors are such that one is the translation of the other (in the classic geometric sense). For example, the operand 2 * u[x, y, z] is shifted with respect to the operand 2 * u[x + 1, y + 2, z + 3] since they have same coefficient (2), label (u), and dimensions ([x, y, z]), whereas the displacement vectors [0, 0, 0] and <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> are expressible by means of a translation. Now consider two expressions e 0 and e 1 in fully expanded form (i.e., a non-nested sum of operands). We say that e 0 is shifted with respect to e 1 if the following conditions hold:</p><p>• the operands in e 0 (e 1 ) are shifted with respect to the operands in e 1 (e 0 ); • the same arithmetic operators are applied to the involved operands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For example, consider e = u[x] + v[x], having two operands u[x] and v[x]; then:</head><p>• u[x-1] + v[y-1] is not shifted with respect to e, due to a different dimension vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• u[x] + w[x]</head><p>is not shifted with respect to e, due to a different label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• u[x+2] + v[x]</head><p>is not shifted with respect to e, since it cannot be expressed as a translation of e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• u[x+2] + v[x+2]</head><p>is shifted with respect to e, as it can be expressed through the translation</p><formula xml:id="formula_6">T (x ) = x + 2.</formula><p>The relation "e 0 is shifted with respect to e 1 " is an equivalence relation, as it is at the same time reflexive, symmetric, and transitive. Thanks to these properties, the turnaround times for detecting shift invariants are extremely quick (less than 2 seconds running on an Intel Xeon E5-2620 v4 for the challenging tti test case with so =16, described in Section 7.2), despite the O (n 2 ) computational complexity (with n representing the number of candidate expressions, see Section 6.1).</p><p>Algorithm 4 highlights the fundamental steps of shift invariants detection. In the worst case scenario, all pairs of candidate expressions are compared by applying the shift-invariant definition given previously. Aggressive pruning, however, is applied to minimize the cost of the search. The algorithm uses some auxiliary functions: (i) calculate_displacements returns a mapper associating, to each candidate, its displacement vectors (one for each indexed object); (ii) compare_ops(e 1 , e 2 ) evaluates to true if e 1 and e 2 perform the same operations on the same Architecture and Performance of Devito, a System for Automated Stencil Computation 6:19 operands; and (iii) is_translated(d 1 , d 2 ) evaluates to true if the displacement vectors in d 2 are pairwise shifted with respect to the vectors in d 1 by the same factor. Together, (ii) and (iii) are used to establish whether two expressions are shifted (line 8). From an implementation point of view, these functions exploit key SymPy expression properties (e.g., immutability, deterministic ordering of operands) and operators (e.g., for structural equality testing), so they eventually result rather simply.</p><p>Eventually, m sets of shift invariants are determined. For each of these sets G 0 , . . . ,G m-1 , a pivot-a special shift invariant-is constructed. This is the key for operation count reduction: the pivot p i of G i = {e 0 , . . . , e k-1 } will be used in place of e 0 , . . . , e k-1 (thus obtaining a reduction proportional to k). A simple example is illustrated in Listing 11. • The pivot of G i is constructed, rather than selected out of e 0 , . . . , e k-1 , so that it could coexist with as many other pivots as possible within the same Cluster. For example, consider again Listing 11: there are infinite possible pivots temp[x + s] = 9.0*temp0*u[t, x + s], and the one with s = 0 is chosen. However, this choice is not random. The pivots are chosen based on a global optimization strategy, which takes into account all of the m sets of shift invariants. The objective function consists of choosing s so that multiple pivots will have identical ISpace and thus be scheduled to the same Cluster (and, eventually, to the same loop nest). • Conservatively, the chosen pivots are assigned to array variables. A second optimization pass, called index bumping and array contraction in Devito v3.1, attempts to turn these arrays into scalar variables, thus reducing memory consumption. This pass is based on datadependence analysis, which essentially checks whether a given pivot is required only within its Cluster or by later Clusters as well. In the former case, the optimization is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Loop Blocking for Working-Set Minimization</head><p>In essence, the SIE algorithm trades operation for memory-the (array) temporaries to store the shift invariants. From a runtime performance viewpoint, this is convenient only in arithmetic-intensive kernels. Unsurprisingly, we observed that storing temporary arrays spanning the entire grid rarely provides benefits (e.g., only when the operation count reductions are exceptionally high). We then considered the following options:</p><p>(1) Capturing redundancies arising along the innermost dimension only: Thus, only scalar temporaries would be necessary. This approach presents three main issues, however: (i) only a small percentage of all redundancies are captured; (ii) the implementation is non-trivial, due to the need for circular buffers in the generated code; and (iii) SIMD vectorization is affected, since inner loop iterations are practically serialized. Some previous articles followed this path <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. (2) A generalization of the previous approach: Using both scalar and array temporaries, without searching for redundancies across the outermost loop(s). This mitigates issue (i), although the memory pressure is still severely affected. Issue (iii) is also unsolved. This strategy was discussed in Kronawitter et al. <ref type="bibr" target="#b20">[21]</ref>. (3) Using loop blocking: Redundancies are sought and captured along all available dimensions, although they are now assigned to array temporaries whose size is a function of the block shape. A first loop nest produces the array temporaries, whereas a subsequent loop nest consumes them, to compute the actual output values. The block shape should be chosen so that writes and reads to the temporary arrays do not cause high latency accesses to the DRAM. An illustrative example is shown in Listing 12.</p><p>The SIE algorithm uses the third approach, based on cross-loop-nest blocking. This pass is carried out by the DLE, which can introduce blocking over sequences of loops (see Section 5.2).</p><p>Listing 12. The loop nest produced by the SIE algorithm for the example in Listing 11. Note that the block loop (line 2) wraps both the producer (line 3) and consumer (line 5) loops. For clarity, unnecessary information is omitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">PERFORMANCE EVALUATION</head><p>We outline in Section 7.1 the compiler setup, computer architectures, and measurement procedure that we used for our performance experiments. Following that, we outline the physical model and numerical setup that define the problem being solved in Section 7.2. This leads to performance results, presented in Sections 7.3 and 7.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Compiler and System Setup</head><p>We analyze the performance of generated code using enriched roofline plots. Since the DSE transformations may alter the operation count by allocating extra memory, only by looking at GFlops/s performance and runtime jointly can a quality measure of code syntheses be derived.</p><p>For the roofline plots, Stream TRIAD was used to determine the attainable memory bandwidth of the node. Two peaks for the maximum floating-point performance are shown: the ideal peak, calculated as</p><formula xml:id="formula_7">#[cores] • #[avx units] • #[vector lanes] • #[FMA ports] • [ISA base frequency],</formula><p>and a more realistic one, given by the LINPACK benchmark. The reported runtimes are the minimum of three runs (the variance was negligible). The model used to calculate the operational intensity assumes that the time-invariant Functions are reloaded at each time iteration. This is a more realistic setting than a "compulsory-traffic-only" model (i.e., an infinite cache).</p><p>We had exclusive access to two architectures: an Intel Xeon Platinum 8180 (formerly code named Skylake) and an Intel Xeon Phi 7250 (formerly code named Knights Landing), which will be referred to as skl8180 and knl7250, respectively. Thread pinning was enabled with the program numactl. The Intel compiler icc version 18.0 was used to compile the generated code. The experiments were run with Devito v3.1 <ref type="bibr" target="#b42">[43]</ref>. The experimentation framework with instructions for reproducibility is available from the Devito Team <ref type="bibr" target="#b33">[34]</ref>. All FLOPs are performed in single precision, which is typical for seismic imaging applications.</p><p>Any arbitrary sequence of DSE and DLE/YLE transformations is applicable to an Operator. Devito provides three preset optimization sequences, or "modes," which vary in aggressiveness and affect code generation in three major ways:</p><p>• the time required by the Devito compiler to generate the code,</p><p>• the potential reduction in operation count, and • the potential amount of additional memory that might be allocated to store (scalar, tensor) temporaries.</p><p>A more aggressive mode might obtain a better operation count reduction than a non-aggressive one, although this does not necessarily imply a better time to solution as the memory pressure might also increase. The three optimization modes-basic, advanced, and aggressive-apply the same sequence of DLE/YLE transformations, which includes OpenMP parallelism, SIMD vectorization, and loop blocking. However, they vary in the number, type, and order of DSE transformations.</p><p>In particular, we have the following: Thus, aggressive triggers the full-fledged SIE algorithm, whereas advanced uses only a relaxed version (based on time invariants). All runs used loop tiling with a block shape that was determined individually for each case using auto-tuning. The auto-tuning phase, however, was not included in the measured experiment runtime. Likewise, the code generation phase is not included in the reported runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Test Case Setup</head><p>In the following sections, we benchmark the performance of operators modeling the propagation of acoustic waves in two different models: isotropic and tilted transverse isotropy (TTI <ref type="bibr" target="#b44">[45]</ref>), henceforth isotropic and tti, respectively. These operators were chosen for their relevance in seismic imaging techniques <ref type="bibr" target="#b44">[45]</ref>.</p><p>Acoustic isotropic modeling is the most commonly used technique for seismic inverse problems, due to the simplicity of its implementation, as well as the comparatively low computational cost in terms of FLOPs. The tti wave equation provides a more realistic simulation of wave propagation and accounts for local directional dependency of the wave speed but comes with increased computational cost and mathematical complexity. For our numerical tests, we use the tti wave equation as defined by Zhang et al. <ref type="bibr" target="#b44">[45]</ref>. The full specification of the equation and the FD schemes and its implementation using Devito are provided in Louboutin et al. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. Essentially, the tti wave equation consists of two coupled acoustic wave equations, in which the Laplacians are constructed from spatially rotated first derivative operators. As indicated by Figure <ref type="figure" target="#fig_13">4</ref>, these spatially rotated Laplacians have a significantly larger number of stencil coefficients in comparison to its isotropic equivalent that comes with an increased operational intensity.</p><p>The tti and isotropic equations are discretized with second order in time and varying space orders of 4, 8, 12, and 16. For both test cases, we use zero initial conditions, Dirichlet BCs, and absorbing boundaries with a 10-point mask (Section 3.5). The waves are excited by injecting a time-dependent but spatially localized seismic source wavelet into the sub-surface model, using Devito's sparse point interpolation and injection as described in Section 3.1. We carry out performance measurements for two velocity models of 512 3 and 768 3 grid points with a grid spacing of 20 m. Wave propagation is modeled for 1,000 ms, resulting in 327 timesteps for isotropic and 415 timesteps for tti. The time-stepping interval is chosen according to the Courant-Friedrichs-Lewy (CFL) condition <ref type="bibr" target="#b7">[8]</ref>, which guarantees stability of the explicit time-marching scheme and is determined by the highest velocity of the sub-surface model and the grid spacing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Performance: Acoustic Wave in Isotropic Model</head><p>This section illustrates the performance of isotropic with the core and yask backends. To simplify the exposition, we show results for the DSE in advanced mode only; the aggressive has no impact on isotropic, due to the memory-bound nature of the code <ref type="bibr" target="#b23">[24]</ref>.</p><p>The performance of core on skl8180, illustrated in Figure <ref type="figure" target="#fig_14">5</ref>(a) (yask uses slightly smaller grids than core due to a flaw in the API of Devito v3.1, which will be fixed in Devito v3.2), degrades as the space order (henceforth, so) increases. In particular, it drops from 59% of the attainable machine peak to 36% in the case of so =16. This is the result of multiple issues. As so increases, the number of streams of unaligned virtual addresses also increases, causing more pressure on the memory system. Intel VTune revealed that the lack of split registers to efficiently handle split loads was a major source of performance degradation. Another major issue for isotropic on core concerns the quality of the generated SIMD code. The in-line vectorization performed by the auto-vectorizer produces a large number of pack/unpack instructions to move data between vector registers, which introduces substantial overhead. Intel VTune also confirmed that, unsurprisingly, isotropic is a memory-bound kernel. Indeed, switching off the DSE basically did not impact the runtime, although it did increase the operational intensity of the four test cases.</p><p>The performance of core on knl7250 is not as good as that on skl8180. Figure <ref type="figure" target="#fig_14">5</ref>(b) shows an analogous trend to that on skl8180, with the attainable machine peak systematically dropping as so increases. The issue is that here the distance from the peak is even larger. This simply suggests that core is failing at exploiting the various levels of parallelism available on knl7250.</p><p>The yask backend overcomes all major limitations to which core is subjected. On both skl8180 and knl7250, yask outperforms core, essentially since it does not suffer from the issues presented earlier. Vector folding reduces memory-read streams, software prefetching helps especially for larger values of so, and hierarchical OpenMP parallelism is fundamental to leverage shared caches. The speedup on knl7250 is remarkable, as even in the best scenario for core (so =4), yask is roughly 3× faster, and it is more than 4× faster when so = 12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Performance: Acoustic Wave in the TTI Model</head><p>This sections illustrates the performance of tti with the core backend. tti cannot be run on the yask backend in Devito v3.1 because some fundamental features are still missing; this is part of our future work (more details in Section 8).</p><p>Unlike isotropic, tti significantly benefits from different levels of DSE optimizations, which play a key role in reducing the operation count as well as the register pressure. Figure <ref type="figure" target="#fig_2">6</ref> displays the performance of tti for the usual range of space orders on skl8180 and knl7250 for two different cubic grids.</p><p>Generally, tti does not reach the same level of performance as isotropic. This is not surprising given the complexity of the PDEs (e.g., in terms of differential operators), which translates into code with much higher arithmetic intensity. In tti, the memory system is stressed by a considerably larger number of loads per loop iteration than in isotropic. On skl8180, we ran performanceprofiling analyses using Intel VTune. We determined that the major issues are pressure on both L1 cache (lack of split registers, insufficient "fill buffers" to handle requests to the other levels of the hierarchy) and DRAM (bandwidth and latency). Clearly, this is only a summary from some sample kernels-the actual situation varies depending on the DSE optimizations and the so employed.   It is notable that on both skl8180 and knl7250, and on both grids, the cutoff point beyond which advanced results in worse runtimes than aggressive is so =8. One issue with aggressive is that to avoid redundant computation, not only is additional memory required but also more data communication may occur through caches rather than through registers. As shown later in Figure <ref type="figure" target="#fig_4">12</ref>, for example, we can easily deduce that temp is first stored and then reloaded in the subsequent loop nest. This is an overhead that advanced does not pay, since temporaries are communicated through registers, for as much as possible. Beyond so = 8, however, this overhead is overtaken by the reduction in operation count, which grows almost quadratically with so, as reported in Table <ref type="table" target="#tab_8">1</ref>.</p><p>The performance on knl7250 is overall disappointing. This is unfortunately caused by multiple factors-some of which already were discussed in the previous sections. These results, and more in general, the need for performance portability across future (Intel or non-Intel) architectures, motivated the ongoing yask project. Here, the overarching issue is the inability to exploit the multiple levels of parallelism typical of architectures such as knl7250. Approximately 17% of the attainable peak is obtained when so =4 with advanced (best runtime out of the three DSE modes for the given space order). This occurs when using 512 3 points per grid, which allows the working set to completely fit in MCDRAM (our calculations estimated a size of roughly 7.5 GB). With the larger grid size (Figure <ref type="figure" target="#fig_2">6</ref>(d)), the working set increases up to 25.5 GB, which exceeds the MCDRAM capacity. This partly accounts for the 5× slow down in runtime (from 34 to 173 seconds) despite only a 3× increase in number of grid points computed per time iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Overhead Summary</head><p>To run an Operator, there are four major sources of overhead:</p><p>Code generation: The phase during which the high-level symbolic specification is lowered into C/C++. Compilation into a shared object: The generated C/C++ file is compiled into a shared object by a C/C++ compiler with optimizations enabled. The time spent in this phase highly depends on the quality of the generated code. Calling the shared object: This requires analyzing the user input, provided at Operator application time, and forwarding it to the loaded shared object. Auto-tuning: This step is optional. Its impact varies greatly across different problem sizes and even across backends (core, yask).</p><p>On skl8180, Devito's turnaround times for all of these four phases are extremely quick, even in the most complex problems in which hundreds of lines of code are generated (e.g., high-order tti). The Intel compiler took less than 7 seconds to build tti so =16 at the maximum optimization level, whereas the Operator required around 3 seconds to emit the C code (with DSE aggressive). Calling the loaded shared object from Python takes negligible time, despite the extensive checks to validate the arguments. Auto-tuning took 3 minutes to complete (heuristic-based search); however, from a user perspective, this is hardly relevant because auto-tuning is disabled (by default) until production or benchmark runs. All of these times improve, even significantly, as the arithmetic complexity of a problem decreases (e.g., at lower orders or when considering isotropic).</p><p>On knl7250, due to weaker single-core performance, the overheads are more pronounced. It took slightly more than 1 minute to produce a shared object for tti so =16. Auto-tuning took around 15 minutes. Since it is unlikely that a knl7250 will ever be used as a development platform, these overheads are easily amortized out during production runs.</p><p>With the yask backend, the compilation times tend to increase, although the order of magnitude is still the same as with core. All other phases are substantially unchanged.</p><p>For all experiments, we report the time spent in each of these phases in the logs available from the Devito Team <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">FURTHER WORK</head><p>Although many simulation and inversion problems such as full-waveform inversion only require the solver to run on a single shared-memory node, many other applications require support for distributed memory parallelism (typically via MPI) so that the solver can run across multiple compute nodes. The immediate plan is to leverage yask's MPI support and perhaps to include MPI support into core at a later stage. Another important feature is staggered grids, which are necessary for a wide range of FD discretization methods (e.g., modeling elastic wave propagation). Basic support for staggered grids is already included in Devito v3.1, but currently only through a low-level API-the principle of graceful degradation in action. We plan to make the use of this feature more convenient.</p><p>As discussed in Section 7.4, the yask backend is not feature complete yet; in particular, it cannot run the tti equations in the presence of array temporaries. As tti is among the most advanced models for wave propagation used in industry, extending Devito in this direction has high priority.</p><p>There also is a range of advanced performance optimization techniques that we want to implement, such as "time tiling" (i.e., loop blocking across the time dimension), on-the-fly data compression, and mixed-precision arithmetic exploiting application knowledge. Finally, there is an ongoing effort toward adding an ops <ref type="bibr" target="#b31">[32]</ref> backend, which will enable code generation for GPUs and also supports distributed memory parallelism via MPI.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>5 Fig. 1 .</head><label>51</label><figDesc>Fig. 1. The typical usage of Devito within a larger application.</figDesc><graphic coords="5,86.43,87.70,84.04,68.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Listing 2 .</head><label>2</label><figDesc>Example of spatial and temporal FD stencil creation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Listing 6 .</head><label>6</label><figDesc>Implementation of time sub-sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6 : 8 F</head><label>68</label><figDesc>. Luporini et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Compiler passes to lower symbolic equations into shared objects through an Operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>With the notation d[o m , o M ], we indicate the compact interval [d m + o m , d M + o M ] over the Dimension d, in which d m and d M are parameters (specialized only at runtime), whereas o m and o M are known integers. For instance, [x[0, 0], y[-1, 1]] describes a rectangular 2D space over x and y, whose points are given by the Cartesian product [x m , x M ] × [y m -1, y M + 1]. The ISpace and DSpace are two special types of Space. They usually span different sets of Dimensions. A DSpace may have Dimensions that do not appear in an ISpace, particularly those that are accessed only via integer indices. Likewise, an ISpace may have Dimensions that are not part of the DSpace, such as a reduction axis. Further, an ISpace also carries, for each Dimension, its iteration direction. As an example, consider the equation stencil in Listing 4. Immediately we see that input = [u, m], output = [u], and Dimensions = [t, x]. The compiler constructs the ISpace</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>6 : 10 F</head><label>610</label><figDesc>. Luporini et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>ALGORITHM 1 : 6 else</head><label>16</label><figDesc>Clustering: enforcement of iteration directions (pseudocode). Input: A sequence of equations E. Output: A sequence of equations E with altered ISpace. // Map each dimension to a set of expected iteration directions 1 mapper ← detect_flow_directions(E); 2 for e in E do 3 for dim, directions in mapper do 4 if len(directions) == 1 then // No ambiguity 5 forced[dim] ← directions.pop(); if len(directions) == 2 then // No ambiguity as long as one of the two items is /Any/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>13 Listing 7 .</head><label>137</label><figDesc>Architecture and Performance of Devito, a System for Automated Stencil Computation 6:Graphical representation of the IET produced by the cluster scheduling algorithm for the running example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Listing 10 .</head><label>10</label><figDesc>An example of time-varying sub-expressions extraction. Only sub-expressions performing at least one FLOP are extracted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Various folds of eight elements [39]. The smaller diagram in the upper left of each sub-figure illustrates a single SIMD layout, which is also the configuration of the output elements from a single SIMD computation. The larger diagram shows the SIMD input values needed for a typical 25-point stencil (e.g., from an eighthorder FD approximation of an isotropic acoustic wave). The colored elements highlight the first element in the output layout (purple element) and the corresponding elements in the inputs (red through blue elements, where the different colors indicate the distance from the center). Note that the 1 × 1 × 8 1D fold corresponds to the traditional in-line vectorization.</figDesc><graphic coords="17,73.92,83.38,337.84,91.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>ALGORITHM 4 : 6 G 7 for e in unseen do 8 if 9 G</head><label>46789</label><figDesc>Detection of shift invariants (pseudocode).Input: A sequence of expressions E. Output: A sequence of shift-invariant objects A.1 displacements ← calculate_displacements(E); 2 A ← list(); 3 unseen ← list(E);4 while unseen is not empty do 5 top ← unseen.pop(); = ShiftInvariant(top); compare_ops(top, e) and is_translated(displacements[top], displacements[e]) then Several optimizations for data locality, not shown in Algorithm 4, are also applied. The interested reader may refer to the documentation and the examples of Devito v3.1 for more details; in the following, we only mention the underlying ideas:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>basic enables: CSE. advanced enables: factorization; extraction of time-invariant shift invariants; detection of shift invariants; all basic passes. aggressive enables: extraction of time-varying shift invariants; all advanced passes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Stencils of the acoustic Laplacian for the isotropic (left) and tti (right) wave equations and spaceorder of 16. The anisotropic Laplacian corresponds to a spatially rotated version of the isotropic Laplacian. The color indicates the distance from the central coefficient.</figDesc><graphic coords="22,127.27,83.78,231.00,106.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Performance of isotropic on multiple Devito backends and architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>6 : 24 F</head><label>624</label><figDesc>. Luporini et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Performance of tti on core for different architectures and grids.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>•</head><label></label><figDesc>Given the sequence of equations [E 1 , E 2 , E 3 ], it is possible that E 3 can be grouped with E 1 , but not with its immediate predecessor E</figDesc><table /><note><p><p>2 (e.g., due to a different ISpace). However, this can only happen when there are no flow or anti-dependences between E 2 and E 3 -that is, when the if commands at lines 10 and 13 are not entered, thus allowing the search to proceed with the next equation. This optimization was originally motivated by gradient operators in seismic imaging kernels.</p>• The routine control_flow, omitted for brevity, creates additional Clusters if one or more ConditionalDimensions are encountered. These are tracked in a special Cluster field, guards, as also required by later passes (see Section 4.5). ALGORITHM 2: Clustering: grouping expressions into Clusters (pseudocode). Input: A sequence of equations E. Output: A sequence of clusters C. 1 C ← ClusterGroup();</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>2 for e in E do 3 grouped ← false; 4 for c in reversed</head><label></label><figDesc></figDesc><table /><note><p>(C) do 5 anti, flow ← get_dependencies(c, e); 6 if e.ispace == c.ispace and anti.carried is empty then 7 c.add(e); 8 grouped ←</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>true; 9 break; 10 else if anti.carried is not empty then 11 c</head><label></label><figDesc>.atomics.update(anti.carried.cause);</figDesc><table><row><cell>6:12</cell><cell>F. Luporini et al.</cell></row><row><cell>12</cell><cell>break;</cell></row><row><cell>13</cell><cell>else if flow.cause.intersection(c.atomics) then</cell></row><row><cell></cell><cell>// cannot search across earlier clusters</cell></row><row><cell>14</cell><cell>break;</cell></row><row><cell>15</cell><cell>end for</cell></row><row><cell>16</cell><cell>if not grouped then</cell></row><row><cell>17</cell><cell>C.append(Cluster(e));</cell></row><row><cell>18</cell><cell>end if</cell></row><row><cell cols="2">19 end for</cell></row><row><cell cols="2">20 C ← control_flow(C);</cell></row><row><cell cols="2">21 return C</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>then 7 break; 8 end if</head><label></label><figDesc>In this pass, the intermediate representation is lowered to an Iteration/Expression Tree (IET). An IET is an abstract syntax tree in which Iterations and Expressions-two special node typesare the main actors. Equations are wrapped within Expressions, whereas Iterations represent loops. Loop nests embedding such Expressions are constructed by suitably nesting Iterations.</figDesc><table /><note><p>Each Cluster is eventually placed in its own loop (Iteration) nest, although some (outer) loops may be shared by multiple Clusters. ALGORITHM 3: An excerpt of the cluster scheduling algorithm, turning a list (ofClusters) into a tree (IET). Here, the fact that different Clustersmay eventually share some outer Iterations is highlighted. Input: A sequence of Clusters C. Output: An Iteration/Expression Tree. 1 schedule ← list(); 2 for c in C do 3 root ← None; 4 index ← 0; 5 for i 0 , i 1 in zip(c.ispace, schedule) do 6 if i 0 i 1 or i 0 .dimension in c.atomics 9 root ← schedule[i1]; 10 index ← index + 1; 11 if i 0 .dim in c.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>guards then 12 break; 13 end if 14 end for 15 build</head><label></label><figDesc>as many Iterations as Dimensions in c.ispace[index:] and nest them inside root ;</figDesc><table /><note><p><p>16</p>update schedule ; 17 ...</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>•</head><label></label><figDesc>Loop blocking: Also known as tiling, this technique implemented by replacing Iteration trees in the IET. The current implementation only supports blocking over fully parallel</figDesc><table /><note><p>Iterations. Blocking over dimensions characterized by flow-or anti-dependencies, such as the time dimension in typical explicit FD schemes, is instead work in progress (this would require a preliminary pass known as loop skewing; see Section 8 for more details). However, a feature of the present implementation is the capability of blocking across particular 6:16 F. Luporini et al.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 1 .</head><label>1</label><figDesc>Operation Counts for Different DSE</figDesc><table><row><cell></cell><cell></cell><cell>Modes in tti</cell><cell></cell></row><row><cell cols="4">so basic advanced aggressive</cell></row><row><cell>4</cell><cell>299</cell><cell>260</cell><cell>102</cell></row><row><cell>8</cell><cell>857</cell><cell>707</cell><cell>168</cell></row><row><cell cols="2">12 1,703</cell><cell>1,370</cell><cell>234</cell></row><row><cell cols="2">16 2,837</cell><cell>2,249</cell><cell>300</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactions on Mathematical Software, Vol. 46, No. 1, Article 6. Publication date: April 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>More complicated interpolation schemes can be defined by pre-computing the grid points corresponding to each sparse point and their respective coefficients. The result can then be used to create a PrecomputedSparseFunction, which behaves like a SparseFunction at the symbolic level.ACM Transactions on Mathematical Software, Vol. 46, No. 1, Article 6. Publication date: April</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2020" xml:id="foot_2"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_3"><p>return E ACM Transactions on Mathematical Software, Vol. 46, No. 1, Article 6. Publication date: April 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_4"><p>Formerly, Yet Another Stencil Kernel. ACM Transactions on Mathematical Software, Vol. 46, No. 1, Article 6. Publication date: April 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_5"><p>At the time of writing, reaching feature completeness is one the major ongoing development efforts. ACM Transactions on Mathematical Software, Vol.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>46, No. 1, Article 6. Publication date: April 2020.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>Devito is a system to automate high-performance stencil computations. Although Devito provides a Python -based syntax to easily express FD approximations of PDEs, it is not limited to FDs. A Devito Operator can implement arbitrary loop nests and can evaluate arbitrarily long sequences of heterogeneous expressions such as those arising in FD solvers, linear algebra, or interpolation. The compiler technology builds upon years of experience from other DSL-based systems such as FEniCS and Firedrake, and wherever possible Devito uses existing software components including SymPy and NumPy, as well as YASK. The experiments in this article show that Devito can generate production-level code with compelling performance on state-of-the-art architectures.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the Engineering and Physical Sciences Research Council through grants EP/I00677X/1, EP/L000407/1, and EP/I012036/1, by the Imperial College London Department of Computing, by the Imperial College London Intel Parallel Computing Centre (IPCC), by the Georgia Research Alliance, by the Georgia Institute of Technology, and by the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research, Applied Mathematics and Computer Science programs under contract number DE-AC02-06CH11357. M. Louboutin, P. Witte, and F. J. Herrmann acknowledge the University of British Columbia, where part of this research was carried out.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Alfred</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Sethi</surname></persName>
		</author>
		<ptr target="http://www.loc.gov/catdir/toc/ecip0618/2006024333.html" />
		<title level="m">Compilers: Principles, Techniques, and Tools</title>
		<editor>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Pearson/Addison Wesley</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unified form language: A domain-specific language for weak formulations of partial differential equations</title>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">S</forename><surname>Alnaes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><forename type="middle">B</forename><surname>Ølgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><forename type="middle">E</forename><surname>Rognes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garth</forename><forename type="middle">N</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Arbona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miñano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Palenzuela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Artigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bona-Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Massó</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.04715</idno>
		<title level="m">Simflowny 2: An upgraded platform for scientific modeling and simulation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A practical automatic polyhedral parallelizer and locality optimizer</title>
		<author>
			<persName><forename type="first">Uday</forename><surname>Bondhugula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Hartono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramanujam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sadayappan</surname></persName>
		</author>
		<idno type="DOI">10.1145/1375581.1375595</idno>
		<ptr target="https://doi.org/10.1145/1375581.1375595" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI&apos;08)</title>
		<meeting>the 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI&apos;08)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="101" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Susanne</forename><forename type="middle">C</forename><surname>Brenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Ridgway</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-387-75934-0</idno>
		<ptr target="https://doi.org/10.1007/978-0-387-75934-0" />
		<title level="m">The Mathematical Theory of Finite Element Methods</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">PDEL-A language for partial differential equations</title>
		<author>
			<persName><forename type="first">Alfonso</forename><forename type="middle">F</forename><surname>Cárdenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><forename type="middle">J</forename><surname>Karplus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="184" to="191" />
			<date type="published" when="1970">1970. 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ALPAL: A Tool for the Development of Large-Scale Simulation Codes</title>
		<author>
			<persName><forename type="first">Grant</forename><forename type="middle">O</forename><surname>Cook</surname><genName>Jr</genName></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<pubPlace>Livermore, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Lawrence Livermore National Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the partial difference equations of mathematical physics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Courant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friedrichs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lewy</surname></persName>
		</author>
		<idno type="DOI">10.1147/rd.112.0215</idno>
		<ptr target="https://doi.org/10.1147/rd.112.0215" />
	</analytic>
	<monogr>
		<title level="j">International Business Machines (IBM) Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="234" />
			<date type="published" when="1967-03">1967. March 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Auto-tuning the 27-point stencil for multicore</title>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasily</forename><surname>Volkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Oliker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of iWAPT 2009: The 4th International Workshop on Automatic Performance Tuning</title>
		<meeting>iWAPT 2009: The 4th International Workshop on Automatic Performance Tuning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Eliminating redundancies in sum-of-product array computations</title>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Deitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradford</forename><forename type="middle">L</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Snyder</surname></persName>
		</author>
		<idno type="DOI">10.1145/377792.377807</idno>
		<ptr target="https://doi.org/10.1145/377792.377807" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Supercomputing (ICS&apos;01)</title>
		<meeting>the 15th International Conference on Supercomputing (ICS&apos;01)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="65" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">GLORE: Generalized loop redundancy elimination upon LER-notation</title>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133898</idno>
		<ptr target="https://doi.org/10.1145/3133898" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Programming Languages</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2017-10">2017. Oct. 2017</date>
		</imprint>
	</monogr>
	<note>OOPSLA</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Performance optimization of fully anisotropic elastic wave propagation on 2nd generation Intel Xeon Phi processors</title>
		<author>
			<persName><forename type="first">Albert</forename><surname>Farres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><surname>Hanzich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW&apos;18)</title>
		<meeting>the 2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Madagascar: Open-source software project for multidimensional data analysis and reproducible computational experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fomel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vlad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bashkardin</surname></persName>
		</author>
		<idno type="DOI">10.5334/jors.ag</idno>
		<ptr target="https://doi.org/10.5334/jors.ag" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Research Software</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">OpenFOAM v5 User Guide</title>
		<ptr target="https://cfd.direct/openfoam/user-guide/" />
	</analytic>
	<monogr>
		<title level="s">The OpenFOAM Foundation. n.d</title>
		<imprint>
			<date type="published" when="2020-03-17">March 17. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simulation software generation using a domain-specific language for partial differential field equations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Hawick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Playne</surname></persName>
		</author>
		<idno>SER3829</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Software Engineering Research and Practice (SERP&apos;13)</title>
		<meeting>the 11th International Conference on Software Engineering Research and Practice (SERP&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Numerical absorbing boundary conditions for the wave equation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Higdon</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/2008250" />
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="65" to="90" />
			<date type="published" when="1987">1987. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">OpenSBLI: A framework for the automated derivation and parallel execution of finite difference solvers on a range of computer architectures</title>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">T</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Satya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Jammy</surname></persName>
		</author>
		<author>
			<persName><surname>Sandham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.01277</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">High Performance Parallelism Pearls Volume Two: Multicore and Many-Core Programming Approaches</title>
		<author>
			<persName><forename type="first">Jim</forename><surname>Jeffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Reinders</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Loo.py: Transformation-based code generation for GPUs and CPUs</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Klöckner</surname></persName>
		</author>
		<idno type="DOI">10.1145/2627373.2627387</idno>
		<ptr target="https://doi.org/10.1145/2627373.2627387" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ARRAY&apos;14: ACM SIGPLAN Workshop on Libraries, Languages, and Compilers for Array Programming</title>
		<meeting>ARRAY&apos;14: ACM SIGPLAN Workshop on Libraries, Languages, and Compilers for Array Programming</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">CGen -C/C++ Source Generation from an AST</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Klöckner</surname></persName>
		</author>
		<ptr target="https://github.com/inducer/cgen" />
		<imprint>
			<date type="published" when="2016-03-17">2016. March 17. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Redundancy elimination in the ExaStencils code generator</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Kronawitter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Kuckuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Lengauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Algorithms and Architectures for Parallel Processing</title>
		<meeting>the International Conference on Algorithms and Architectures for Parallel Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>ICA3PP&apos;16</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ExaStencils: Advanced stencil-code engineering</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Lengauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Apel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bolten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Größlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hannig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Köstler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Rüde</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-14313-2_47</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-14313-2_47" />
	</analytic>
	<monogr>
		<title level="m">Euro-Par 2014: Parallel Processing Workshops</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8806</biblScope>
			<biblScope unit="page" from="553" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Automated Solution of Differential Equations by the Finite Element Method</title>
		<idno type="DOI">10.1007/978-3-642-23099-8</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-23099-8" />
		<editor>Anders Logg, Kent-Andre Mardal, and Garth N. Wells</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Performance prediction of finite-difference solvers for different computer architectures</title>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Louboutin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">J</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navjot</forename><surname>Kukreja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>Gorman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cageo.2017.04.014</idno>
		<ptr target="https://doi.org/10.1016/j.cageo.2017.04.014" />
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Geosciences</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="148" to="157" />
			<date type="published" when="2017-08">2017. 08 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Devito (v3.1.0): An embedded domain-specific language for finite differences and geophysical exploration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Louboutin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luporini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kukreja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Velesko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Gorman</surname></persName>
		</author>
		<idno type="DOI">10.5194/gmd-12-1165-2019</idno>
		<ptr target="https://doi.org/10.5194/gmd-12-1165-2019" />
	</analytic>
	<monogr>
		<title level="j">Geoscientific Model Development</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1165" to="1187" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Performance-portable finite element assembly using PyOP2 and FEniCS</title>
		<author>
			<persName><forename type="first">Graham</forename><forename type="middle">R</forename><surname>Markall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Rathgeber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Loriant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Bertolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">H J</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-38750-0_21</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-38750-0_21" />
	</analytic>
	<monogr>
		<title level="m">Supercomputing</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7905</biblScope>
			<biblScope unit="page" from="279" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Boundary conditions in Devito</title>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Louboutin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Luporini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In preparation</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Meurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Paprocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Čertík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sergey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kirpichev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Rocklin</surname></persName>
		</author>
		<author>
			<persName><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj-cs.103</idno>
		<ptr target="https://doi.org/10.7717/peerj-cs.103" />
	</analytic>
	<monogr>
		<title level="m">SymPy: Symbolic computing in Python</title>
		<imprint>
			<date type="published" when="2017-01">2017. Jan. 2017</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">J</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Sewall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07409</idno>
		<title level="m">A metric for performance portability</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Halide: A language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connelly</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédo</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
		<idno type="DOI">10.1145/2491956.2462176</idno>
		<ptr target="https://doi.org/10.1145/2491956.2462176" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI&apos;13)</title>
		<meeting>the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI&apos;13)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="519" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Firedrake: Automating the finite element method by composing abstractions</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Rathgeber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Luporini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gheorghe-Teodor</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><forename type="middle">R</forename><surname>Bercea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">H J</forename><surname>Markall</surname></persName>
		</author>
		<author>
			<persName><surname>Kelly</surname></persName>
		</author>
		<idno type="DOI">10.1145/2998441</idno>
		<ptr target="https://doi.org/10.1145/2998441" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2016-12">2016. Dec. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The OPS domain specific abstraction for multi-block structured grid computations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>István</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gihan</forename><forename type="middle">R</forename><surname>Reguly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">B</forename><surname>Mudalige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><surname>Mcintosh-Smith</surname></persName>
		</author>
		<idno type="DOI">10.1109/WOLFHPC.2014.7</idno>
		<ptr target="https://doi.org/10.1109/WOLFHPC.2014.7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing (WOLFHPC&apos;14</title>
		<meeting>the 4th International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing (WOLFHPC&apos;14<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="58" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">From modelling to inversion: Designing a well-adapted simulator</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Symes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Enriquez</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1365-2478.2011.00977.x</idno>
		<ptr target="https://doi.org/10.1111/j.1365-2478.2011.00977.x" />
	</analytic>
	<monogr>
		<title level="j">Geophysical Prospecting</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="814" to="833" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Devito Experimentation Framework v1.0. Retrieved March 17</title>
		<ptr target="https://github.com/opesci/devito-performance/releases/tag/v1.0" />
		<imprint>
			<date type="published" when="2018">2018. 2020</date>
			<publisher>The Devito Team</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accelerating seismic simulations using the Intel Xeon Phi Knights Landing processor</title>
		<author>
			<persName><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Heinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifeng</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ISC High Performance Conference (ISC&apos;17)</title>
		<meeting>the 2017 ISC High Performance Conference (ISC&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">DEQSOL: A numerical simulation language for vector/parallel processors</title>
		<author>
			<persName><forename type="first">Yukio</forename><surname>Umetani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1985 IFIP TC2/WG22 Conference</title>
		<meeting>the 1985 IFIP TC2/WG22 Conference</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="147" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">CTADEL: A generator of multi-platform high performance codes for PDE-based scientific applications</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Van Engelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lex</forename><surname>Wolters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>Cats</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Supercomputing</title>
		<meeting>the 10th International Conference on Supercomputing<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="86" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PyFR: An open source framework for solving advec-tionâĂŞdiffusion type problems on streaming architectures using the flux reconstruction approach</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Witherden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Farrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cpc.2014.07.011</idno>
		<ptr target="https://doi.org/10.1016/j.cpc.2014.07.011" />
	</analytic>
	<monogr>
		<title level="j">Computer Physics Communications</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="3028" to="3040" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Vector folding: Improving stencil performance via multi-dimensional SIMD-vector representation</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCC-CSS-ICESS.2015.27</idno>
		<ptr target="https://doi.org/10.1109/HPCC-CSS-ICESS.2015.27" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 17th International Conference on High Performance Computing and Communications (HPCC&apos;15)</title>
		<meeting>the IEEE 17th International Conference on High Performance Computing and Communications (HPCC&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="865" to="870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Effective use of large high-bandwidth memory caches in HPC stencil computation via temporal wave-front tiling</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Duran</surname></persName>
		</author>
		<idno>SC&apos;16/PMBS&apos;16</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop in Performance Modeling, Benchmarking, and Simulation of High Performance Computer Systems held as part of ACM/IEEE Supercomputing</title>
		<meeting>the 7th International Workshop in Performance Modeling, Benchmarking, and Simulation of High Performance Computer Systems held as part of ACM/IEEE Supercomputing</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multi-level spatial and temporal tiling for efficient HPC stencil computation on many-core processors with large shared caches</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2017.10.041</idno>
		<ptr target="https://doi.org/10.1016/j.future.2017.10.041" />
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="903" to="919" />
			<date type="published" when="2019-03">2019. March 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">YASK-Yet another stencil kernel: A framework for HPC stencil code-generation and tuning</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Yount</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Duran</surname></persName>
		</author>
		<idno type="DOI">10.1109/WOLFHPC.2016.08</idno>
		<ptr target="https://doi.org/10.1109/WOLFHPC.2016.08" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing held as part of ACM/IEEE Supercomputing 2016 (SC&apos;16/WOLFHPC&apos;16)</title>
		<meeting>the 6th International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing held as part of ACM/IEEE Supercomputing 2016 (SC&apos;16/WOLFHPC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Devito v3.1. Software used in Architecture and performance of Devito, a system for automated stencil computation</title>
		<author>
			<persName><forename type="first">/</forename><surname>Zenodo</surname></persName>
		</author>
		<author>
			<persName><surname>Devito</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.836688</idno>
		<ptr target="https://doi.org/10.5281/zenodo.836688" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Auto-generation and auto-tuning of 3D stencil codes on GPU clusters</title>
		<author>
			<persName><forename type="first">Yongpeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mueller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2259016.2259037</idno>
		<ptr target="https://doi.org/10.1145/2259016.2259037" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Symposium on Code Generation and Optimization (CGO&apos;12)</title>
		<meeting>the 10th International Symposium on Code Generation and Optimization (CGO&apos;12)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houzhu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanquan</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1190/1.3554411</idno>
		<idno>WA3-WA11</idno>
		<ptr target="https://doi.org/10.1190/1.3554411" />
	</analytic>
	<monogr>
		<title level="m">A stable TTI reverse time migration and its implementation</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="volume">76</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
