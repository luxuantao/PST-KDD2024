<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph-based prediction of Protein-protein interactions with attributed signed graph embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fang</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<addrLine>5 South Zhongguancun Street</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Haidian District</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<addrLine>5 South Zhongguancun Street</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Haidian District</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kunjie</forename><surname>Fan</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Ohio, Columbus</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dandan</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<addrLine>5 South Zhongguancun Street</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Haidian District</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<addrLine>5 South Zhongguancun Street</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Haidian District</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huakang</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<addrLine>5 South Zhongguancun Street</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Haidian District</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<addrLine>5 South Zhongguancun Street</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Haidian District</orgName>
								<address>
									<postCode>100081</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph-based prediction of Protein-protein interactions with attributed signed graph embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1186/s12859-020-03646-8</idno>
					<note type="submission">Received: 22 August 2019 Accepted: 8 July 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Protein-protein interaction</term>
					<term>Representation learning</term>
					<term>Network embedding</term>
					<term>Variational graph auto-encoder</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: Protein-protein interactions (PPIs) are central to many biological processes. Considering that the experimental methods for identifying PPIs are time-consuming and expensive, it is important to develop automated computational methods to better predict PPIs. Various machine learning methods have been proposed, including a deep learning technique which is sequence-based that has achieved promising results. However, it only focuses on sequence information while ignoring the structural information of PPI networks. Structural information of PPI networks such as their degree, position, and neighboring nodes in a graph has been proved to be informative in PPI prediction. Results: Facing the challenge of representing graph information, we introduce an improved graph representation learning method. Our model can study PPI prediction based on both sequence information and graph structure. Moreover, our study takes advantage of a representation learning model and employs a graph-based deep learning method for PPI prediction, which shows superiority over existing sequence-based methods. Statistically, Our method achieves state-of-the-art accuracy of 99.15% on Human protein reference database (HPRD) dataset and also obtains best results on Database of Interacting Protein (DIP) Human, Drosophila, Escherichia coli (E. coli), and Caenorhabditis elegans (C. elegan) datasets. Conclusion: Here, we introduce signed variational graph auto-encoder (S-VGAE), an improved graph representation learning method, to automatically learn to encode graph structure into low-dimensional embeddings. Experimental results demonstrate that our method outperforms other existing sequence-based methods on several datasets. We also prove the robustness of our model for very sparse networks and the generalization for a new dataset that consists of four datasets: HPRD, E.coli, C.elegan, and Drosophila.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Proteins are versatile macromolecules and perform a vast array of vital functions within organisms, and over 80% of proteins interact with other proteins while carrying out their functions <ref type="bibr" target="#b2">[1]</ref>. Those interactions, known as protein-protein interactions (PPIs), are physical contacts of high specificity established between two or more protein molecules. PPI is of great importance in many cellular biological processes, including signal transduction, immune response, cell proliferation, DNA transcription, and replication. Analysis and elucidation of the PPIs provide valuable insights into the molecular mechanism and the protein functions <ref type="bibr" target="#b3">[2]</ref>. In recent years, the rapid development of high-throughput technologies are used to detect protein interactions, such as yeast two-hybrid screens (Y2H) <ref type="bibr" target="#b4">[3]</ref>, tandem affinity purification (TAP) <ref type="bibr" target="#b5">[4]</ref> and mass spectrometric protein complex identification (MS-PCI) <ref type="bibr" target="#b6">[5]</ref>, Tandem Affinity Purification and Mass Spectrometry (TAP-MS) <ref type="bibr" target="#b7">[6]</ref>, affinity chromatography and Co-Immunoprecipitation (Co-IP) <ref type="bibr" target="#b8">[7]</ref>. These experimental methods have contributed to exponential growth of the number of PPIs of various species, but the functional annotation of both proteins and their interactions is updated at a slow speed. Meanwhile, these data suffer from problems including high false positives, false negative rate and low coverage <ref type="bibr" target="#b9">[8]</ref>. To be more specific, although many protein-protein interaction links have been experimentally determined, the total number is still relatively few compared to the tremendous amount of links collected by the high-throughput technologies <ref type="bibr" target="#b10">[9]</ref>. And these genome-scale experiments are costly, with inherent bias and limited coverage. The limitations of device resolution and environmental interference during operation will inevitably lead to errors and deviations in experimental techniques <ref type="bibr" target="#b11">[10]</ref>. Therefore, high-throughput computational methods that are useful for the study of protein functions are required for discovering PPI with high quality and accuracy <ref type="bibr" target="#b12">[11]</ref>.</p><p>Recently, many high-throughput computational methods have been proposed. On the whole, they can be divided into two groups: classic machine learning algorithms and deep learning methods. For the first group, different machine learning methods were utilized for predicting PPIs to improve the efficiency and accuracy, such as decision trees <ref type="bibr" target="#b13">[12]</ref>, k-Nearest Neighbor (KNN) <ref type="bibr" target="#b14">[13]</ref>, naive bayes <ref type="bibr" target="#b15">[14]</ref>, random forest <ref type="bibr" target="#b16">[15]</ref> and support vector machine (SVM) <ref type="bibr" target="#b17">[16]</ref><ref type="bibr" target="#b18">[17]</ref><ref type="bibr" target="#b19">[18]</ref>. These features of these methods measure physicochemical properties of the 20 canonical amino acids, and aim at summarizing full sequence information relevant to PPIs. Compared to classic machine learning methods, deep learning methods are advantaged in extracting features directly from data and capture nonlinear dependencies between abstract features. They can also fully exploit the availability of the increasing large-scale and high-dimension raw datasets. Therefore, deep learning methods are unprecedentedly popular in recent years and have been successfully applied in various problems <ref type="bibr" target="#b20">[19]</ref>. For PPI prediction, Sun et al. recently proposed a stacked autoencoder (SAE) to study the sequence-based PPI prediction, which was the first to apply a deep learning algorithm to sequence-based PPI prediction and achieved promising results <ref type="bibr" target="#b21">[20]</ref>. Du et al. proposed a method called Deep neural networks for Protein Protein Interactions prediction (DeepPPI), which employed deep learning to extract high-level discriminative features from common protein descriptors <ref type="bibr" target="#b22">[21]</ref>. Lei et al. put forward a novel computational method based on Multimodal Deep Polynomial Network (MDPN) to encode multiple data from protein properties for PPIs prediction <ref type="bibr" target="#b23">[22]</ref>. Hashemifar et al. presented a convolution-based model where feature extractions are terminated by processing data through an original randomly initialized and untrained matrix they named "random projection module" <ref type="bibr" target="#b24">[23]</ref>. Next, a neural network based approach called Ensemble Deep Neural Networks (EnsDNN) was proposed to predict PPIs based on different representations of amino acid sequences <ref type="bibr" target="#b25">[24]</ref>. Particularly, EnsDNN separately used auto covariance descriptor, local descriptor, and multi-scale continuous and discontinuous local descriptor, to represent and explore the pattern of interactions between sequentially distant and spatially close amino acid residues. Finally, Richoux et al. compared two carefully designed deep learning models and showed pitfalls to avoid while predicting PPIs through deep learning methods <ref type="bibr" target="#b26">[25]</ref>.</p><p>However, the deep learning algorithm presented by Sun et al. <ref type="bibr" target="#b21">[20]</ref> and most of the methods we discussed above only considered sequence data, while the network data, such as their degree, position, and neighboring nodes in the graph, has been proved to be informative in PPI prediction. For example, Licamele and Getoor looked at the shared neighborhood among proteins and calculated the clustering coefficient among the neighborhoods for the first-order and second-order protein relations to predict the interactions in a yeast dataset <ref type="bibr" target="#b27">[26]</ref>. Paradesi et al. identified nine structural features for Saccharomyces cerevisiae PPI networks and used them to learn classifiers for predicting new interactions <ref type="bibr" target="#b28">[27]</ref>. You et al. developed a robust manifold embedding technique for assessing the reliability of interactions and predicting new interactions by utilizing the topological information of PPI networks <ref type="bibr" target="#b29">[28]</ref>.</p><p>The biggest challenge to apply graph-based deep learning methods for PPI prediction is the utilization way of the network information, that is, how to represent the graph structure of PPI network in low-dimensional embeddings, which should be used as feature inputs for downstream machine learning classifier. The good news is that there has been a surge in approaches that automatically learn to encode graph structure recently, using techniques based on deep learning and nonlinear dimensionality reduction. These methods are representation learning on graphs, which can be used to analyze social networks, molecular graph structures and recommender systems. The idea behind the representation learning approach is to learn a mapping that embeds nodes, or entire graphs, as points in a low-dimensional vector space. The purpose is to optimize the mapping so that geometric relationships in the learned space could reflect the structure of the original graph <ref type="bibr" target="#b30">[29]</ref>. Representation learning has been successfully applied to link prediction, such as predicting missing friendship links in social networks <ref type="bibr" target="#b31">[30]</ref> and inferring affinities between users and movies <ref type="bibr" target="#b32">[31]</ref>.</p><p>In this paper, by regarding PPI network as an undirected graph, we propose signed variational graph auto-encoder (S-VGAE), a representation learning model that could effectively take advantage of the graph structure and naturally incorporate protein sequence information as features. Our overall framework is composed of three parts. The first part is designed to code raw protein sequences, and the second part is the essential S-VGAE model used to further extract vector embedding for each protein with both graph structure and sequence information. The final part is a simple three-layer softmax classifier. Our S-VGAE model is designed based on the variational graph auto-encoder (VGAE) model proposed by Kipf and Welling <ref type="bibr" target="#b33">[32]</ref>, which is a framework that makes use of latent variables and is capable of learning interpretable representations for undirected graphs. To apply it to efficiently predict PPI, we primarily made three key improvements on the VGAE and greatly boosted the ultimate performance. Firstly, we modified the cost function to only consider those interactions with high confidence, which allowed us to learn accurate feature representation by focusing on high-confidence interaction information and was more robust to noise. In addition, we gave different signs to different interactions in the adjacency matrix so that the model could consider different impact of each interaction during the training process and strengthen the negative impact of the highly negative interactions. The last improvement was that we further train a neural network as the final classifier instead of using generative model to infer interactions. Since the input embedded representations already contained enough information, using the simple classifier is sufficient according to Occam's Razor Principle <ref type="bibr" target="#b34">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Our work consists of three steps: basic protein sequence coding, graph-based feature extraction model, and the final neural network classifier. Firstly, we transform raw protein sequences into fixed-length coding using the conjoint triad (CT) method. Next, we propose an improved weighted variational graph auto-encoder (S-VGAE) to learn embeddings for each protein based on their sequence features and local graph information. Finally, we use these embeddings as inputs to train a simple feedforward neural network as the final classifier. In this section, we firstly evaluated the performance of the proposed method for predicting five different datasets: Human protein reference database (HPRD) dataset, Database of Interacting Protein (DIP) Human, Drosophila, Escherichia coli (E. coli), and Caenorhabditis elegans (C. elegan) by using different evaluation measures. We then compared the performance of the proposed method with existing methods from previous literature are presented. Finally, we discussed the robustness and the generalization of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation criteria</head><p>In this paper, the performance of the proposed model was evaluated by means of the classification accuracy, specificity, sensitivity and precision, F-score value, as defined respectively by:</p><formula xml:id="formula_0">Accuracy = TP + TN TP + TN + FP + FN (1)</formula><formula xml:id="formula_1">Sensitivity = TP TP + FN (<label>2</label></formula><formula xml:id="formula_2">)</formula><formula xml:id="formula_3">Specificity = TN TN + FP (3) Precision = TP TP + FP (4) F − score = 2 * Precision * Sensitivity Precision + Sensitivity (5)</formula><p>where TP, TN, FP and FN represent true positive, true negative, false positive, and false negative, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with other methods</head><p>In order to demonstrate the performance of our model, we evaluated our model on five datasets as described in the "Datasets" section and compared our model to several popular methods. As indicated in Table <ref type="table" target="#tab_0">1</ref>, our method achieved above 98.5% accuracy on all datasets. For 2007 HPRD, Drosophila and C.elegan datasets, the F-score values of our model are more than 99%. As shown in Figs. <ref type="figure" target="#fig_1">1 and 2</ref>, on the 2007 HPRD dataset, our model achieved state-of-the-art F-score value of 99.15% compared to eight popular existing methods. For example, Sun's <ref type="bibr" target="#b21">[20]</ref> obtained prediction F-score value of 97.16% and prediction accuracy of 97.19%. And Pan's <ref type="bibr" target="#b35">[34]</ref> work obtained prediction accuracy of 97.90% of latent dirichlet allocation-random forest (LDA-ROF) and prediction Fscore value of 90.4% of latent dirichlet allocation-support vector machine (LDA-SVM) respectively. In summary, our model achieved the best prediction capacity.</p><p>The detailed results of our method on the DIP Human, E. coli, Drosophila and C. elegans were listed in Table <ref type="table" target="#tab_1">2</ref>. Our model was compared against multiple baseline approaches, including: SAE <ref type="bibr" target="#b21">[20]</ref>, Lasagna <ref type="bibr" target="#b36">[35]</ref>, DeepPPI <ref type="bibr" target="#b26">[25]</ref>. The results of SAE <ref type="bibr" target="#b21">[20]</ref> were attained from the data provided by Guo et al. <ref type="bibr" target="#b19">[18]</ref>. As the other methods of SVM <ref type="bibr" target="#b19">[18]</ref>, LDA-ROF <ref type="bibr" target="#b35">[34]</ref>, compressive sampling-support vector machine (CS-SVM) <ref type="bibr" target="#b37">[36]</ref>, and extreme learning machine (ELM) <ref type="bibr" target="#b38">[37]</ref> were not conducted on these four datasets. Particularly, Richoux et al. <ref type="bibr" target="#b26">[25]</ref> proposed to compare two different neural network architectures: Deep Fully Connected Network (DFC) and Deep Long Short Memory Network (DLSTM). Our model was compared with these two models respectively. In addition, since the DFC and  DLSTM methods were applicable to large-scale datasets which were designed to solve the problem of information leak and didn't avoid the underfitting in the small datasets, we didn't use their results on E. coli and C. elegans datasets.</p><p>On the DIP Human dataset, our model yielded a F-score value of 98.78% which greatly outperformed the model named Lasagna <ref type="bibr" target="#b36">[35]</ref> being 97.25% and the model named DFC <ref type="bibr" target="#b26">[25]</ref> being 95.14%. For E. coli, our model achieved the F-score value of 98.92%, which was also significantly superior to other methods. For Drosophila, our model obtained the Fscore value of 99.80% while for C.elegans the F-score value was 99.25%. It can be seen that our model has demonstrated promising results on several datasets and has proved its potential in PPI prediction regardless of the dataset's size, coverage, and species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness and generalization</head><p>First, we discuss the robustness of our model for very sparse datasets since the existing PPIs are limited <ref type="bibr" target="#b39">[38]</ref>. We define coverage as the proportion of training samples to the number of total samples. The training set is selected as each protein includes coverage portion of its positive edges and highly negative edges. The less the coverage, the more sparse the training set.</p><p>As we can see from Fig. <ref type="figure" target="#fig_2">3</ref>, the accuracy, sensitivity, specificity, and precision are all rising as the coverage increases. It can be observed from Fig. <ref type="figure" target="#fig_2">3a</ref> that the accuracy is already above 93% even when the coverage is only 0.1, which illustrates that our model is effective  even when the datasets are sparse and can be applied in real prediction of other species. Besides, as indicated in Fig. <ref type="figure" target="#fig_2">3b</ref>, the sensitivity is up to 99% at the coverage of only 0.4. Figure <ref type="figure" target="#fig_2">3c</ref> and d also demonstrate the robustness and validity of our model consistently.</p><p>To test the generalization, we combine HPRD, E.coli, C.elegan and Drosophila datasets into one larger dataset. This new dataset consists of four different species and contains 21881 proteins with 69550 positive samples and 69283 negative samples. We randomly split the dataset into 50% training samples and 50% test samples and this process is repeated five times. The training data was trained for 50 iterations and the average of five results denotes the final score. As we can see in Table <ref type="table" target="#tab_2">3</ref>, the accuracy, sensitivity, specificity and precision, F-score value are all more than 96%. Considering the heterogeneity and sparsity of this dataset, the performance is reasonable and desirable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>With a graph representation learning model, our method is demonstrated effective and robust in PPI prediction. However, the model still has great improvement space as follows. In our model, considering different impacts of different edges, we introduce the mechanism of confidence for each edge in the PPI network which can be reflected in the adjacency matrix A. Currently, we divide all the edges into three groups and assign constant value for each edge in the same group. In the future work, the quality of each interaction should be taken into account and assigned a specific confidence value to make the prediction model more informative.</p><p>For protein sequence coding, we used the pre-defined CT method. Other popular coding methods such as auto covariance (AC) and local descriptor (LD), the manually constructed or selected representation is more or less polluted or biased, which would affect the learning ability of the deep learning method. But the CT method is based on rules and the error will be smaller than these two method. Therefore, developing more precise coding methods is crucial to further improve the model in our future work. As we all known, the sequence of nucleotides that forms a gene is first translated into an amino acid sequence, following the rules encoded in the genetic code. The corresponding linear chain of amino acids becomes functional only when it adopts a three-dimensional shape, the so-called tertiary, or native structure of the protein. These 3D structures of proteins provide the opportunity for in silico prediction methods. The opportunity is that if in silico methods can predict whether two given 3D structures interact, then these methods may be applied to predict interactions among the large amount of proteins with known or inferred 3D structure <ref type="bibr" target="#b40">[39]</ref>. Our future work could integrate the text description information annotated in the database to the codings using natural language processing technique and the 3D structures of proteins to better represent the protein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In this paper, we proposed S-VGAE, an improved graph representation learning method, to incorporate graph information in PPI networks into PPI prediction. Then the abstract features are based on both sequence information and graph structure. Experimental results demonstrated that our method performed significantly well and outperformed other existing sequence-based methods on several datasets. We also proved the robustness of our model for very sparse networks and the generalization for different kinds of datasets. To the best of our knowledge, our method is one of the first models to apply graph-based representation learning technique, thus successfully apply a deep learning algorithm to graph-based PPI prediction. It is also anticipated that our method can be generalized to many other related bioinformatics studies. For example, we can conduct representation learning with graph and simplified molecular input line entry specification (SMILES) string features of drug molecules using S-VGAE to predict drug interactions. We can construct an undirected weighted graph, where each vertex represents one drug and each edge denotes one interaction between two drugs. After obtaining the SMILES strings of drug molecules as the input features of each node, we can apply S-VGAE to obtain the hidden representations of drugs and predict the interactions between them. Particularly, Drug-drug interactions (DDIs) are from DrugComb database <ref type="bibr" target="#b41">[40]</ref> and DDIExtraction 2013 dataset <ref type="bibr" target="#b42">[41]</ref> and molecular structures of drugs can be obtained freely from DrugBank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Our overall framework consists of three steps as shown in Fig. <ref type="figure" target="#fig_3">4</ref>: basic protein sequence coding, graph-based feature extraction model, and the final neural network classifier. The first step is to transform raw protein sequences into fixed-length codings in order for subsequent training. Next, we propose an improved weighted variational graph autoencoder (S-VGAE) to learn embeddings for each protein based on their sequence features and local graph information, which is equivalent to the feature reduction and extraction. Finally, we use these embeddings as inputs to train a simple feedforward neural network as the final classifier. In this section, we also introduce the datasets and model settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark dataset</head><p>We used Pan's <ref type="bibr" target="#b35">[34]</ref> dataset from http://www.csbio.sjtu.edu.cn/bioinf/LR_PPI/Data.htm as the benchmark dataset. The positive samples in the dataset are from the human protein reference database (HPRD, 2007 version), with the elimination of the self-interactions and duplicate interactions. We finally obtained 36591 positive pairs. Based on the common assumption that two proteins in different cellular compartments do not interact, proteins used in constructing negative samples are selected by following the listed criteria: (1) Collecting human proteins annotated with "human" in the ID field only. (2) Excluding sequences annotated with ambiguous or uncertain subcellular localization terms, such as "potential", "probable", "probably", "maybe", or "by similarity". (3) Including those sequences marked with unique locations only. (4) Excluding sequences annotated with "fragments", and eliminating sequences with less than 50 amino acid residues as they may only be fragments. ( <ref type="formula">5</ref>) Proteins with unusual amino acids such as U and X were removed. The collected proteins were randomly paired with other proteins in different subcellular locations to generate negative samples. Finally, the total amount of the remaining negative samples were 36324.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other datasets</head><p>We also used Guo's <ref type="bibr" target="#b19">[18]</ref> dataset to evaluate our model including: (1) Human dataset containing 9435 proteins with 37020 positive samples and 37027 negative samples. (2) E. coli dataset containing 1834 proteins with 6954 positive samples and 6954 negative samples.</p><p>(3) Drosophila dataset containing 7059 proteins with 21975 positive samples and 21975 negative samples. ( <ref type="formula">4</ref>) C. elegan dataset containing 2640 proteins with 4030 positive samples and 4030 negative samples. The negative samples used for training in each dataset were selected according to the same criteria presented in the above Benchmark Dataset part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model settings</head><p>Our model was implemented using Tensorflow in Python and took advantage of the strong computing capacity of GPU. All the simulations were carried out on a computer with 4.00GHz 8-core CPU and 59GB memory. The GPU we used was NVIDIA GeForce GTX 1080 with 7GB memory. Our source code and datasets are available at https:// github.com/fangyangbit/S-VGAE.</p><p>The S-VGAE model has two hidden layers with 96 neurons and 48 neurons of each layer respectively. The final softmax classifier has three hidden layers with 128, 64 and 32 neurons each layer and uses dropout technique during training in order to avoid overfitting. Dropout is a technique that randomly drops units (along with their connections) from the neural network during training <ref type="bibr" target="#b43">[42]</ref>. For both parts, we initialize weights as described in <ref type="bibr" target="#b44">[43]</ref> and train for 50 iterations using Adam algorithm with a learning rate of 0.005. We tuned the hyperparameters of our model to optimize system performance by conducting 5-fold sentence-level cross-validation on the training set. To determine the parameter, four-fifths of the whole dataset are randomly chosen to train the classifiers with different number of hidden nodes, while the rest one-fifths of the dataset are used as the validation set to compute the accuracy. For Adam optimization, we set the learning rate lr = 0.005 as suggested by Kingma et al. <ref type="bibr" target="#b45">[44]</ref>. To alleviate the over-fitting problem, the dropout rate was set to 0.5 in our model, as used by Hinton et al. <ref type="bibr" target="#b46">[45]</ref>.</p><p>In our experiments, each dataset was randomly split into 80% training set and 20% test set. The model was trained and validated using 5-fold cross-validation, and the performance of our model was evaluated by the hold-out test set. In order to test the robustness of our method, this process of random selection was repeated five times. Therefore, five models were generated based on different training sets and the overall performance was the average of results on five different test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Protein sequence coding</head><p>There are several existing methods for protein sequence representation such as auto AC, CT, and LD <ref type="bibr" target="#b47">[46]</ref>. In our model, we choose CT as our coding method. The CT method was first proposed by Shen et al. to code single protein <ref type="bibr" target="#b48">[47]</ref>. The information of protein sequences can be projected into a homogeneous vector space by counting the frequencies of each triad type. The whole process is described as follows. First of all, all amino acids are clustered into seven categories according to their dipole and side chain volumes. The classification of amino acids is shown in Table <ref type="table" target="#tab_3">4</ref> and the classification principle is described in detail in the paper <ref type="bibr" target="#b48">[47]</ref>. Amino acids within the same group likely involve synonymous mutations due to their analogous characteristics. Then, each amino acid can be substituted by its category label and thus each protein is a string of integers. Next, a window of size three is used to slide across the sequence one step at a time and count the number of occurrences of each triad type. Since we regard any three continuous amino acids as a unit and the amino acids have been catalogued into seven classes, there are 7×7×7 different combinations, that is the size of CT vector is 343. The CT representation is defined as:</p><formula xml:id="formula_4">V =[ n 0 , n 1 , . . . , n q ] (<label>6</label></formula><formula xml:id="formula_5">)</formula><p>where n i is the number of occurrences of each triad type and q equals to 343.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our S-VGAE model</head><p>This is the core part of our overall framework. After initial coding of sequences by the CT method, we further conduct representation learning with graph and sequence features using our signed variational graph auto-encoder (S-VGAE) model. We will discuss this model by problem formulation, and then its inference part and generative part. The inference part is an encoder that encodes original proteins into embeddings while the generative part is a decoder that decodes the embeddings back into original proteins. The purpose of this model is to learn interpretable embedding for each protein by training encoder and decoder at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem formulation</head><p>We are given an undirected weighted graph G = (V, E) with N = |V| nodes, thus N is the number of proteins, and each vertex of G represents one protein while each edge is one interaction. The adjacency matrix A of G is provided. In matrix A, A ij denotes whether there exists an interaction between protein i and protein j. We enforce self-loops in the graph by simply adding the identity matrix to A. The input features of each node are included in an N × R matrix X, which are sequence representations by the CT method and R equals to 343 in this case. The desired outputs of this model are latent variables z i , summarized in an N × P matrix Z, which will contain the embeddings of proteins we expect to get where P is the dimension of each embedding. The model is basically an encoder-decoder approach. First the encoder maps each node v i in the graph to a low-dimensional vector embedding, z i , based on the node's position in the graph, its local neighborhood structure, and its attributes. Next, the decoder extracts the classification label A ij associated with v i and v j (i.e., the label of interaction between protein i and j). By jointly optimizing the encoder and decoder, the model learns to compress information about graph structure into the low-dimensional embedding space. The intuition behind this encoder-decoder idea is that if we can learn to decode hig-dimensional graph information from encoded low-dimensional embeddings, then, in principle, these learned low-dimensional vectors should contain all information necessary for downstream machine learning tasks, for example, classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The encoder</head><p>The inference module is a graph convolutional networks (GCNs) encoder <ref type="bibr" target="#b49">[48]</ref>, which is a function with the goal of a mapping from the original features X to embeddings Z with the augmented information of A. In our current implementation, a simple model parameterized by a two-layer GCN is utilized:</p><formula xml:id="formula_6">q(Z|X, A) = N i=1 q(z i |X, A) (7) q(z i |X, A) = N z i |μ i , diag σ 2 i (<label>8</label></formula><formula xml:id="formula_7">)</formula><p>where μ = GCN μ (X, A) is the matrix of mean vectors μ i and log σ = GCN σ (X, A). The GCN model is defined as GCN(X, A) = AReLU(AXW 0 )W 1 , and W i are parameter matrices we need to train. In our model, GCN μ (X, A) and GCN σ (X, A) share W 0 in order to reduce parameters. ReLU(•) = max(0, •) is the activation function and N is the unit gaussian distribution. The intuition of GCN using GCN(X, A) = ReLU(AXW 0 ) is as follows.</p><p>The multiplication with adjacency matrix A means that, for every node, we sum up all the feature vectors of all neighboring nodes and itself. In this way, GCN can effectively learn embeddings through integrating neighboring graph features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The decoder</head><p>The generative module we define here is a simple inner product decoder:</p><formula xml:id="formula_8">p(A|Z) = N i=1 N j=1 p(A ij |z i , z j ) (9) p(A ij = 1|z i , z j ) = σ (z i z j ) (<label>10</label></formula><formula xml:id="formula_9">)</formula><p>where σ (•) is the logistic sigmoid function. We use the inner product of two embeddings z i and z j as the probability of these two proteins existing the interaction. As indicated in Fig. <ref type="figure" target="#fig_3">4</ref>, the output of the decoder Â is the approximation of adjacency matrix A and we optimize the model so as to make them as close as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training method and implementation details</head><p>In this section, we will detailedly discuss two improvements we proposed on VGAE and explain why they work in our application.</p><p>(</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) cost function</head><p>As the whole interaction network is regarded as an undirected graph and each item in the adjacency matrix represents whether there exists an interaction between the two proteins, in our S-VGAE model, we define the cost function as:</p><formula xml:id="formula_10">L = E q(Z|X,A) [ log p(A |Z)] −KL[ q(Z|X, A) p(Z)]<label>(11)</label></formula><p>where KL[ q(•) p(•)] is the Kullback-Leibler divergence between q(•) and p(•). The first term is to minimize the reconstruction error of the adjacency matrix A. It should be noticed that, we only consider those interactions with high confidence, which we specify as A (A ⊂ A) to be reconstructed. The second term is to minimize the difference between q(Z|X, A) and p(Z). The cost function is the tradeoff between how accurate our model can be and how close the distribution of embeddings can match p(Z). In this case, we assume p(Z) as a Gaussian prior and the reparameterization trick is used for training <ref type="bibr" target="#b50">[49]</ref>.</p><p>As mentioned above, we only consider the cost of interactions with high confidence while ignoring those edges of uncertain confidence. In other words, we assume that those edges of uncertain confidence are random noises to our model and even disturb the training process thus affecting the ultimate performance. Therefore, we need to construct high-confidence sets from original datasets. For positive samples, the confidence are always high since they are actually observed. As for other items in the adjacency matrix A, they are divided into two groups: the highly negative group and the uncertain group. The edges in the highly negative group are negative edges with high confidence, which are selected based on the criteria described in the "Datasets" section.</p><p>(2) signed adjacency matrix During the training process, the adjacency matrix A plays an important role since it not only defines the cost function but also serves as a critical parameter in the GCN. The common adjacency matrix consists of only 0 and 1. However, as we discussed in the last section, different edges actually have different confidence and therefore should have different impacts on the learning process.</p><p>In order to embody the differentiated impacts, we assign positive edges positive values (1), the highly negative group negative values (-1) and the uncertain group 0. By setting different signs and even different weights, we expect to reinforce existing observed interactions and in the meanwhile, strengthen the negative impact of the highly negative interactions. Detailed comparison of the model with or without signed adjacency matrix in Table <ref type="table" target="#tab_0">S1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feedforward neural network classifier</head><p>Instead of directly using generative model to infer interactions, we take out embeddings z i contained in the matrix Z and further train a simple neural network as the final classifier. Correspondingly, the inputs to the classifier are concatenations of embeddings of two proteins, while the output label is a binary value representing whether there exist an interaction between the two proteins.</p><p>The performance of the classifier can be remarkably good without complex neural network structures since the embeddings already contain enough information and are highly representative in the learned low-dimensional vector space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 A</head><label>1</label><figDesc>Fig. 1 A detailed comparison of accuracy to several previous methods on the 2007 HPRD dataset</figDesc><graphic url="image-4.png" coords="5,155.53,512.24,283.72,202.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 A</head><label>2</label><figDesc>Fig. 2 A detailed comparison of F1 score to several previous methods on the 2007 HPRD dataset</figDesc><graphic url="image-5.png" coords="6,154.99,94.64,283.69,203.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Relationship between four criteria and coverage. All the simulations were trained on the HPRD dataset for 50 iterations</figDesc><graphic url="image-6.png" coords="7,155.53,94.46,283.72,238.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Our overall model architecture. The first part is CT used for protein coding. The second part is S-VGAE used for feature extraction. The final part is a simple neural network classifier used for prediction</figDesc><graphic url="image-7.png" coords="9,127.03,93.77,340.36,208.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The performance of our model on five datasets</figDesc><table><row><cell>Dataset</cell><cell>Accuracy (%)</cell><cell>Sensitivity (%)</cell><cell>Specificity (%)</cell><cell>Precision (%)</cell><cell>F1(%)</cell></row><row><cell>HPRD</cell><cell>99.15 ±0.11</cell><cell>99.41 ±0.17</cell><cell>98.89 ±0.17</cell><cell>98.90 ±0.16</cell><cell>99.15 ±0.12</cell></row><row><cell>Human</cell><cell>98.79 ±0.07</cell><cell>98.00 ±0.21</cell><cell>99.58 ±0.17</cell><cell>99.57 ±0.17</cell><cell>98.78 ±0.24</cell></row><row><cell>E.coli</cell><cell>98.92 ±0.37</cell><cell>98.42 ±0.34</cell><cell>99.42 ±0.73</cell><cell>99.42 ±0.73</cell><cell>98.92 ±0.54</cell></row><row><cell>Drosophila</cell><cell>99.80 ±0.01</cell><cell>99.61 ±0.17</cell><cell>100 ±0.02</cell><cell>100 ±0.02</cell><cell>99.80 ±0.15</cell></row><row><cell>C.elegan</cell><cell>99.26 ±0.23</cell><cell>99.16 ±0.38</cell><cell>99.35 ±0.28</cell><cell>99.35 ±0.28</cell><cell>99.25 ±0.33</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>The performance comparison of F1 score between our model and four existing sequence-based methods on four PPI datasets</figDesc><table><row><cell>Method</cell><cell>Human</cell><cell>E.coli</cell><cell>C. elegan</cell><cell>Drosophila</cell></row><row><cell>Our model</cell><cell>98.78</cell><cell>98.92</cell><cell>99.25</cell><cell>99.80</cell></row><row><cell>Lasagna [35]</cell><cell>97.25</cell><cell>89.92</cell><cell>98.40</cell><cell>98.89</cell></row><row><cell>DFC [25]</cell><cell>95.14</cell><cell>--</cell><cell>--</cell><cell>96.39</cell></row><row><cell>DLSTM [25]</cell><cell>89.10</cell><cell>--</cell><cell>--</cell><cell>91.05</cell></row><row><cell>SAE [20]</cell><cell>94.53</cell><cell>96.03</cell><cell>97.17</cell><cell>97.16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>The performance of our model on the combined new datasets</figDesc><table><row><cell>Test set</cell><cell>Accuracy (%)</cell><cell>Sensitivity (%)</cell><cell>Specificity (%)</cell><cell>Precision (%)</cell><cell>F1 (%)</cell></row><row><cell>1</cell><cell>97.61</cell><cell>97.91</cell><cell>97.31</cell><cell>97.33</cell><cell>97.62</cell></row><row><cell>2</cell><cell>96.60</cell><cell>97.88</cell><cell>95.31</cell><cell>95.44</cell><cell>96.64</cell></row><row><cell>3</cell><cell>97.07</cell><cell>97.58</cell><cell>96.55</cell><cell>96.60</cell><cell>97.09</cell></row><row><cell>4</cell><cell>96.78</cell><cell>97.17</cell><cell>96.40</cell><cell>96.44</cell><cell>96.80</cell></row><row><cell>5</cell><cell>97.73</cell><cell>97.84</cell><cell>97.61</cell><cell>97.63</cell><cell>97.73</cell></row><row><cell>Average</cell><cell>97.16 ±0.50</cell><cell>97.68 ±0.31</cell><cell>96.64 ±0.90</cell><cell>96.69 ±0.86</cell><cell>97.18 ±0.41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Classification of Amino Acids according to their Dipoles and Volumes of the Side Chains</figDesc><table><row><cell>Class</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Not applicable.</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>The code and datasets during the current study are available in the GitHub repository: https://github.com/fangyangbit/ S-VGAE.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was supported by National Key Research and Development Program of China (Grant No. 2016YFB1000902) and National Natural Science Foundation of China (Grant Nos. 61976021 and U1811262).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary information</head><p>Supplementary information accompanies this paper at https://doi.org/10.1186/s12859-020-03646-8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional file 1:</head><p>Detailed comparison of the model with or without signed adjacency matrix. Table <ref type="table">S1</ref>. Detailed comparison of the model with or without signed adjacency matrix. Authors' contributions FY, KF and DS conceived of the method. FY and KF designed the method. FY, KF and HL implemented the method and wrote the manuscript. All authors read, edited and approved of the final manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abbreviations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics approval and consent to participate</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication</head><p>Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare that they have no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Publisher's Note</head><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">DLSTM: Deep long short memory network; DIP: Database of interacting protein; C.elegans: Caenorhabditis elegans; E.coli: Escherichia coli; AC: Auto covariance; CT: Conjoint triad; LD: Local descriptor; GCN: Graph convolutional network; ReLU: Rectified linear unit; LDA-SVM: Latent dirichlet allocation-support vector machine; VGAE: Variational graph auto-encoder</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Signed variational graph auto-encoder; HPRD: Human protein reference database; SMILES: Simplified molecular input line entry specification; DDIs: Drug-drug interactions</title>
		<author>
			<persName><forename type="first">S-Vgae</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Methods for the detection and analysis of protein-protein interactions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Berggård</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Linse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteomics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2833" to="2842" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis on multi-domain cooperation for predicting protein-protein interactions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">391</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A comprehensive two-hybrid analysis to explore the yeast protein interactome</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ozawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hattori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sakaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4569" to="4574" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Functional organization of the yeast proteome by systematic analysis of protein complexes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gavin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bösche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marzioch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Michon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Cruciat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="issue">6868</biblScope>
			<biblScope unit="page" from="141" to="147" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Systematic identification of protein complexes in saccharomyces cerevisiae by mass spectrometry</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gruhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heilbut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-L</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Millar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Boutilier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="issue">6868</biblScope>
			<biblScope unit="page" from="180" to="183" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Data on the identification of protein interactors with the evening complex and pch1 in arabidopsis using tandem affinity purification and mass spectrometry (tap-ms)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Nusinow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Brief</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="56" to="60" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Studying protein-protein interactions in budding yeast using co-immunoprecipitation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Foltman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanchez</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4939-3145-3_17</idno>
		<ptr target="https://doi.org/10.1007/978-1-4939-3145-3_17" />
	</analytic>
	<monogr>
		<title level="j">Yeast Cytokinesis</title>
		<imprint>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="2016">2016</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A highly efficient approach to protein interactome mapping based on collaborative filtering framework</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7702</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Effect of sampling on topology predictions of protein-protein interaction networks</title>
		<author>
			<persName><forename type="first">Jdj</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dupuy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Cusick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Biotechnol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="839" to="844" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protein-protein interactions: A supra-structural phenomenon demanding trans-disciplinary biophysical approaches</title>
		<author>
			<persName><forename type="first">O</forename><surname>Byron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vestergaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr Opin Struct Biol</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="76" to="86" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prediction of protein function using protein-protein interaction data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="947" to="960" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Prediction of protein-protein interactions using random decision forest framework</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="4394" to="4400" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Supervised statistical and machine learning approaches to inferring pairwise and module-based protein interaction networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Azuaje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE</title>
				<meeting>the 7th IEEE</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="1365" to="1369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Heterogeneous data integration by tree-augmented naïve bayes for protein-protein interactions prediction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteomics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="268" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions from primary protein sequences using a novel multi-scale local feature representation scheme and the random forest</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">125811</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving the performance of an svm-based method for predicting protein-protein interactions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dohkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Takagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Silico Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="515" to="529" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Detecting protein-protein interactions with a novel matrix-based protein sequence representation and support vector machines</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Z</forename></persName>
		</author>
		<idno type="DOI">10.1155/2015/867516</idno>
		<ptr target="https://doi.org/10.1155/2015/867516" />
	</analytic>
	<monogr>
		<title level="j">BioMed Res Int</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pred_ppi: a server for predicting protein-protein interactions based on sequence data with probability assignment</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Res Notes</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning and its applications in biomedicine</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics Proteomics Bioinforma</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="32" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequence-based prediction of protein protein interaction using a deep-learning algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">277</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deepppi: boosting prediction of protein-protein interactions with deep neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Chem Inf Model</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1499" to="1510" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Protein-protein interactions prediction via multimodal deep polynomial network and regularized extreme learning machine</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elazab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lei</surname></persName>
		</author>
		<idno type="DOI">10.1109/jbhi.2018.2845866</idno>
		<ptr target="https://doi.org/10.1109/jbhi.2018.2845866" />
	</analytic>
	<monogr>
		<title level="j">IEEE J Biomed Health Inf</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions through sequence-based deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hashemifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="802" to="810" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Protein-protein interactions prediction based on ensemble deep neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="10" to="19" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Comparing two deep learning sequence-based models for protein-protein interaction prediction</title>
		<author>
			<persName><forename type="first">F</forename><surname>Richoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Servantie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Borès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Téletchéa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.06268</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions using relational features</title>
		<author>
			<persName><forename type="first">L</forename><surname>Licamele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<ptr target="https://drum.lib.umd.edu/handle/1903/7555" />
	</analytic>
	<monogr>
		<title level="j">Proc ICML Workshop Stat Netw Anal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Structural prediction of protein-protein interactions in saccharomyces cerevisiae</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Paradesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<idno type="DOI">10.1109/bibe.2007.4375729</idno>
		<ptr target="https://doi.org/10.1109/bibe.2007.4375729" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE</title>
				<meeting>the 7th IEEE</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="1270" to="1274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Using manifold embedding for assessing and predicting protein interactions from high-throughput experimental data</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="2744" to="2751" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05584</idno>
		<title level="m">Representation learning on graphs: Methods and applications</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<idno type="DOI">10.1145/2736277.2741093</idno>
		<ptr target="https://doi.org/https://doi.org/10.1145/2736277.2741093" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
				<meeting>the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Graph convolutional matrix completion</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V D</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Occam&apos;s razor. Principia Cybernet Web</title>
		<author>
			<persName><forename type="first">F</forename><surname>Heylighen</surname></persName>
		</author>
		<ptr target="http://pespmc1.vub.ac.be/OCCAMRAZ.html" />
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Large-scale prediction of human protein-protein interactions from amino acid sequence based on latent topic features</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Proteome Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4992" to="5001" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multifaceted protein-protein interaction prediction based on siamese residual rcnn</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cjt</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><forename type="middle">W</forename><surname>Lasagna</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz328</idno>
		<ptr target="https://doi.org/10.1093/bioinformatics/btz328" />
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date>2018501791</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adaptive compressive learning for prediction of protein-protein interactions from primary sequence</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Theor Biol</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="52" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Large-scale protein-protein interactions detection by integrating big biosensing data with computational model</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Z</forename></persName>
		</author>
		<idno type="DOI">10.1155/2014/598129</idno>
		<ptr target="https://doi.org/10.1155/2014/598129" />
	</analytic>
	<monogr>
		<title level="j">BioMed Res Int</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Building and analysis of protein-protein interactions related to diabetes mellitus using support vector machine, biomedical text mining and network analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bapat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karthikeyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Chem</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="37" to="44" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Large-scale prediction of protein-protein interactions from structures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riffle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Noble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">144</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Drugcomb: an integrative cancer drug combination data portal</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zagidullin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aldahdooh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malyutina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jafari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pessia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="43" to="51" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Segura-Bedmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herrero-Zazo</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/S13-2056" />
		<title level="m">SemEval-2013 task 9 : Extraction of drug-drug interactions from biomedical texts</title>
				<meeting><address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">DDIExtraction 2013. SemEval 2013. 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
	<note>Proceedings of the Seventh International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
				<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Prediction of protein-protein interactions from amino acid sequences with ensemble extreme learning machines and principal component analysis</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions based only on sequences information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4337" to="4341" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
