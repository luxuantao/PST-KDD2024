<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-14">14 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Weng</forename><surname>Lam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaixuan</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lilong</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xingjian</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiahua</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maodi</forename><surname>Hu</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Dianping Group</orgName>
								<orgName type="institution">Tsinghua University ? Meituan</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Code</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-14">14 Jul 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2207.07087v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prompt tuning attempts to update few taskspecific parameters in pre-trained models. It has achieved comparable performance to finetuning of the full parameter set on both language understanding and generation tasks. In this work, we study the problem of prompt tuning for neural text retrievers. We introduce parameter-efficient prompt tuning for text retrieval across in-domain, cross-domain, and cross-topic settings. Through an extensive analysis, we show that the strategy can mitigate the two issues-parameter-inefficiency and weak generalizability-faced by finetuning based retrieval methods. Notably, it can significantly improve the out-of-domain zero-shot generalization of the retrieval models. By updating only 0.1% of the model parameters, the prompt tuning strategy can help retrieval models achieve better generalization performance than traditional methods in which all parameters are updated. Finally, to facilitate research on retrievers' cross-topic generalizability, we curate and release an academic retrieval dataset with 18K query-results pairs in 87 topics, making it the largest topic-specific one to date. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Seeking for relevant texts has been a fundamental problem for a broad range of natural language processing (NLP) applications such as open-domain question answering <ref type="bibr" target="#b5">(Chen et al., 2017)</ref>, retrievalaugmented language modeling <ref type="bibr" target="#b12">(Guu et al., 2020)</ref>, and fact verification <ref type="bibr" target="#b41">(Thorne et al., 2018)</ref>. Its recent progress has been dominantly favored by the neural approaches <ref type="bibr" target="#b19">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b20">Khattab and Zaharia, 2020)</ref>, especially the large-scale pre-trained language models with ever-growing parameters. For example, a recent study attempts to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter-Efficiency Zero-shot Generalization</head><p>Cross-Domain (BEIR) Cross-Topic (OAG-QA) In-Domain</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0.1% tuned 100% tuned</head><p>Fine-tuning (fully tuned) PE learning (0.1% parameters tuned)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confidence Calibration Query-length Robustness</head><p>Figure <ref type="figure">1</ref>: For DPR <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> trained on OpenQA datasets, PE learning (e.g., P-Tuning v2) offers parameter-efficiency and improved generalization thanks to better calibration and query-length robustness.</p><p>leverage models up to 10 billion parameters <ref type="bibr" target="#b32">(Ni et al., 2021)</ref>, i.e., 100? larger than those used previously <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>.</p><p>Meanwhile, an increasing number of studies have focused on the parameter-efficiency and generalizability challenges of neural methods. In terms of parameter-efficiency, the common practices <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> rely on fine-tuning dual encoders for queries and documents separately and thus cause parameter redundancy <ref type="bibr" target="#b10">(Geigle et al., 2022)</ref>. Furthermore, fine-tuning the full parameters of a pre-trained retriever for multi-lingual <ref type="bibr" target="#b24">(Litschko et al., 2022)</ref> or cross-topic settings can also result in parameter-inefficiency. Moreover, despite neural approaches' in-domain outperformance, it has been found that their cross-domain generalization cannot match the simple BM25 method <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>. Consequently, these issues pose challenges to develop cost-effective neural text retrievers.</p><p>Recently, parameter-efficient (PE) transfer learning, including prompt tuning <ref type="bibr" target="#b23">(Li and Liang, 2021;</ref><ref type="bibr">Liu et al., 2021c;</ref><ref type="bibr" target="#b22">Lester et al., 2021)</ref>, adapters <ref type="bibr" target="#b15">(Houlsby et al., 2019)</ref>, and hybrid methods <ref type="bibr" target="#b16">(Hu et al., 2021;</ref><ref type="bibr" target="#b51">Zaken et al., 2022)</ref>, is proved to achieve comparable performance to fine-tuning on language understanding and generation tasks by employing very few task-specific tuning parame-ters. Inspired by this progress, we propose to study whether and how PE learning can benefit neural text retrieval in terms of both parameter-efficiency and generalizability.</p><p>In this work, we systematically examine a line of mainstream PE methods in in-domain, crossdomain, and cross-topic settings. As expected, most PE approaches perform comparably to finetuning on in-domain retrieval. Excitingly, PE prompt tuning <ref type="bibr" target="#b23">(Li and Liang, 2021;</ref><ref type="bibr" target="#b27">Liu et al., 2022)</ref> can also encourage neural text retrievers to generalize on the cross-domain benchmark BEIR <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref> and OAG-QA-a new multi-discipline academic cross-topic retrieval dataset we constructed. For example, by simply replacing finetuning to the parameter-efficient P-Tuning v2 <ref type="bibr" target="#b27">(Liu et al., 2022)</ref>, we achieve relative gains ranging from 3.5% to 105.0% on out-of-domain BEIR datasets.</p><p>Through empirical analyses, we attempt to provide an understanding of the better generalization brought by PE prompt tuning. First, PE prompt tuning can help empower the neural model with better confidence calibration, which refers to the theoretical principle that a model's predicted probabilities of labels should correspond to the ground-truth correctness likelihood <ref type="bibr" target="#b11">(Guo et al., 2017)</ref>. Second, it encourages better performance on queries with different lengths from in-domain training, demonstrating PE methods' generalization capacity to out-of-domain datasets.</p><p>To summarize, this work aims to advance the neural text retrievers from three aspects:</p><p>? Problem: we propose to leverage PE learning for neural text retrievers with much fewer tuning parameters. We demonstrate that PE prompt tuning can not only perform comparably to fine-tuning in-domain but also enable neural retrievers to achieve significant generalization advantages over fine-tuning on crossdomain and cross-topic benchmarks.</p><p>? Understanding: we provide an understanding of PE learning's outperformance across domains and topics. Our analysis suggests that its generalization advantage largely comes from its confidence-calibrated prediction and query-length robustness.</p><p>? Dataset: we construct OAG-QA, an academic paper retrieval dataset curated from real-world questions and expert answers, to test retrievers' cross-topic generalizability. With 22 dis-ciplines and 87 topics, OAG-QA is the largest fine-grained topic retrieval dataset to date.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Neural Text Retrieval. Text retrievers traditionally rely on sparse lexical-based inverted index to rank candidate documents containing query terms (e.g., TF-IDF and BM25). They benefit from the simplicity but often suffer from the lexical gap <ref type="bibr" target="#b2">(Berger et al., 2000)</ref>. Recently, neural text retrievers, including dense retrievers <ref type="bibr" target="#b19">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b49">Xiong et al., 2021;</ref><ref type="bibr" target="#b14">Hofst?tter et al., 2021)</ref>, late-interaction models <ref type="bibr" target="#b20">(Khattab and Zaharia, 2020;</ref><ref type="bibr" target="#b38">Santhanam et al., 2021)</ref>, and hybrid or re-ranking models <ref type="bibr" target="#b33">(Nogueira et al., 2019;</ref><ref type="bibr">Wang et al., 2020b)</ref>, becomes popular as they can capture the semanticlevel query-document similarity thanks to the advance of pre-trained language models <ref type="bibr" target="#b13">(Han et al., 2021)</ref>.</p><p>Generalization in Text Retrieval. The weaker generalizability of neural retrievers compared to conventional lexical ones has recently arouse concerns in the community <ref type="bibr">(Liu et al., 2021a,b;</ref><ref type="bibr" target="#b6">Chen et al., 2022)</ref>, and it results in BEIR, a heterogeneous cross-domain generalization benchmark <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>. While recent works notice and employ ideas like bigger pre-trained models <ref type="bibr" target="#b32">(Ni et al., 2021)</ref> or unsupervised pre-training on large corpus <ref type="bibr" target="#b17">(Izacard et al., 2021)</ref> to improve scores on BEIR, few of them focus on studying better transferring strategies based on existing architectures and datasets for out-of-domain generalization.</p><p>Parameter-Efficient (PE) Learning. Sizes of pretrained language models are soaring up <ref type="bibr" target="#b4">(Brown et al., 2020)</ref>, causing great challenges to traditional task transfer based on full-parameter finetuning. A recent focus has been on the emerged PE transfer learning, including prompt tuning <ref type="bibr" target="#b23">(Li and Liang, 2021;</ref><ref type="bibr">Liu et al., 2021c;</ref><ref type="bibr" target="#b22">Lester et al., 2021)</ref>, adapters <ref type="bibr" target="#b15">(Houlsby et al., 2019)</ref>, and hybrid methods <ref type="bibr" target="#b16">(Hu et al., 2021;</ref><ref type="bibr" target="#b51">Zaken et al., 2022)</ref>. They employ very few tuning parameters to achieve finetuning comparable transfer performance. Despite abundant research made on problems like language understanding <ref type="bibr" target="#b15">(Houlsby et al., 2019;</ref><ref type="bibr" target="#b27">Liu et al., 2022)</ref> and generation (Li and Liang, 2021), how it will impact retrieval remains under-explored.</p><p>The neural text retriever, which leverages pretrained language models, e.g., BERT <ref type="bibr" target="#b9">(Devlin et al., 2019)</ref> and RoBERTa <ref type="bibr" target="#b29">(Liu et al., 2019)</ref>, as the backbone, has significantly mitigated the lexical gap <ref type="bibr" target="#b2">(Berger et al., 2000)</ref> in text retrieval and become a standard component for many NLP applications <ref type="bibr" target="#b5">(Chen et al., 2017;</ref><ref type="bibr" target="#b12">Guu et al., 2020;</ref><ref type="bibr" target="#b35">Petroni et al., 2021)</ref>. It consists of several different categories and in this work we focus on the following two dominant ones.</p><p>? Dense Retriever <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>: Dense retrieval learns dual encoders to map queries and documents into a dense vector space such that relevant pairs of queries and documents have shorter distances. It usually adopts the inner-dot product for the sake of efficiency as sim(q, p) = E Q (q) T E P (p) where E Q (?) and E P (?) are dense encoders that map queries and documents to dense vectors, respectively. A ruleof-thumb training objective is the Noise Contrastive Error (NCE), which takes the query q i and its relevant (positive) document p + i and n irrelevant (negative) documents p - i,j as:</p><formula xml:id="formula_0">L NCE = -log e sim(q i ,p + i )</formula><p>e sim(q i ,p + i ) + n j=1 e sim(q i ,p - i,j )</p><p>(1) ? Late-Interaction Retriever <ref type="bibr" target="#b20">(Khattab and Zaharia, 2020)</ref>: ColBERT combines the strengths of the bi-encoder and cross-encoder to encode the the query and document at a finer granularity into multi-vector representations. The relevance is estimated by using the rich yet scalable interaction between the query and document representations. Specifically, the model produces an embedding for every token in queries and documents and compute the relevance using the sum of maximum similarities between vectors of query tokens and all document tokens as:</p><formula xml:id="formula_1">sim(q, p) = i?||Eq|| max j?||E d || E T d j E q i (2)</formula><p>where E q and E d are the sequences of embeddings for query q and document d.</p><p>Challenges. Neural retrieval approaches, such as dense retrievers and late-interaction models, have achieved outperformance over lexical ones on typical open-domain question answering datasets, e.g., NaturalQuestions <ref type="bibr" target="#b21">(Kwiatkowski et al., 2019)</ref>. However, recent studies <ref type="bibr" target="#b24">(Litschko et al., 2022;</ref><ref type="bibr" target="#b40">Thakur et al., 2021)</ref> unveil some of their inherent limitations, posing the following challenges:</p><p>? Parameter Inefficiency: Though the fullparameter fine-tuning empowers neural retrievers to achieve good results, it results in substantial parameter redundancy from two aspects. First, training dual-encoders double the size of the parameters to be tuned. The improving strategies, such as parameter sharing <ref type="bibr" target="#b50">(Yan et al., 2021;</ref><ref type="bibr" target="#b10">Geigle et al., 2022)</ref>, have to sacrifice the retrieval performance. Second, the cross-lingual <ref type="bibr" target="#b24">(Litschko et al., 2022)</ref> and crossdomain <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref> transfer may require additional full-parameter tuning on each of the individual tasks and consequently increase the number of parameters by several times. ? Weak Generalizability: Though neural retrievers offers advantages on domain datasets, e.g., OpenQA datasets <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>, some of them-particularly dense retrievers-cannot generalize well to zero-shot cross-domain benchmarks <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>. However, the zeroshot setting is widely adopted in downstream scenarios, as constructing retrieval training datasets with annotations could be outrageously expensive. Such challenge also broadly connects to the generalizability of neural networks.</p><p>In this work, we aim to explore the solutions for addressing the above challenges in neural text retrieval. Specifically, we focus on the parameterefficient transfer learning, which has offered alternative strategies for the downstream usage of pre-trained models in natural language processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parameter-Efficient Transfer Learning</head><p>We introduce the parameter-efficient transfer learning (PE learning) framework and notable techniques. Different from fine-tuning <ref type="bibr" target="#b9">(Devlin et al., 2019)</ref>, which updates the full parameters of pretrained models for each target task, PE learning aims to achieve comparable performance to finetuning by tuning only a small portion of parameters per task <ref type="bibr" target="#b15">(Houlsby et al., 2019;</ref><ref type="bibr" target="#b23">Li and Liang, 2021;</ref><ref type="bibr" target="#b27">Liu et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Transformers</head><p>The success of PE learning largely takes advantages of the Transformer architecture <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref>. Transformers are composed of stacked lay- ers, each containing a multi-head attention module and a feed-forward network (FFN). The attention function can be written as:</p><formula xml:id="formula_2">Attention(x) = softmax( QK T ? d k )V<label>(3)</label></formula><p>where the query Q, key K and value V are:</p><formula xml:id="formula_3">{Q, K, V }(x) = W {q,k,v} x + b {q,k,v}<label>(4)</label></formula><p>The multi-head attention performs N heads in parallel and concatenates their outputs to form the input to FFN where f is an activation function:</p><formula xml:id="formula_4">FFN(x) = f (xW 1 + b 1 )W 2 + b 2<label>(5)</label></formula><p>Different PE learning methods attempt to modify different modules of a Transformer to achieve parameter efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameter-Efficient Learning Methods</head><p>We introduce several emerging PE learning methods. Figure <ref type="figure" target="#fig_0">2</ref> illustrates the technical differences between them.</p><p>Adapters <ref type="bibr" target="#b15">(Houlsby et al., 2019;</ref><ref type="bibr" target="#b36">Pfeiffer et al., 2020)</ref>. The adapter inserts small modules between Transformer layers, which forms as a bottleneck to limit the amount of parameters in the format of:</p><formula xml:id="formula_5">h ? h + f (hW down )W up (<label>6</label></formula><formula xml:id="formula_6">)</formula><p>where h is the input, W down ? R d?r and W up ? R r?d are project matrices, and f (?) is the activation function (Cf.  <ref type="bibr">(Liu et al., 2021c)</ref>. This approach inserts trainable continuous prompts to the input sequences of the Transformer. Given a PLM, e(?) is the input embedding function that maps input tokens to input embeddings. For a template T = {[P 0:i ],</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lester et al. &amp; P-Tuning</head><p>x, [P i+1:m ], y} where x is the context and y is the target, e.g., the [MASK] token, the model's inputs are:</p><formula xml:id="formula_7">{h 0 , h 1 , ...h i , e(x), h i+1 , ..., h m , e(y)} (7)</formula><p>where h i is the trainable prompt (Cf. Figure <ref type="figure" target="#fig_0">2 (b)</ref>).</p><p>Prefix-Tuning (Li and Liang, 2021) &amp; P-Tuning v2 <ref type="bibr" target="#b27">(Liu et al., 2022)</ref>. Prefix-tuning concatenates l trainable key and value embeddings of the attention to the prefix on each layer of the language models. Specifically, given the original key vectors K ? R l?d and value vectors V ? R l?d , the trainable vectors P k , P v are correspondingly concatenated to K and V . The computation of an attention head becomes:</p><formula xml:id="formula_8">headi(x) = Attention(xW (i) , [P (i) k : K (i) ], [P (i) v : V (i) ])<label>(8)</label></formula><p>Here the superscript (i) refers to the part of the vectors that correspond to the i-th head. It has been empirically proved comparable to fine-tuning on a wide range of downstream tasks, including text generation (Li and Liang, 2021), natural language understanding (NLU) and sequence labeling <ref type="bibr" target="#b27">(Liu et al., 2022)</ref>.</p><p>Since the retrieval task is more related to NLU, we employ P-Tuning v2's implementation, which makes several optimizations on top of prefix-tuning (Cf. Figure <ref type="figure" target="#fig_0">2 (c)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">In-Domain Parameter-Efficiency</head><p>In this section, we describe the data and settings we used for the in-domain OpenQA experiments and evaluate the retrieval performance of the parameterefficient methods introduced above.</p><p>Datasets. We follow <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> to use five open-QA datasets and their train/test/valid splits: Natural Questions (NQ) (Kwiatkowski  <ref type="bibr" target="#b18">(Joshi et al., 2017)</ref>, We-bQuestions (WQ) <ref type="bibr" target="#b1">(Berant et al., 2013)</ref>, Curat-edTREC (TREC) <ref type="bibr" target="#b0">(Baudis and Sediv?, 2015)</ref> and SQuAD v1.1 <ref type="bibr" target="#b37">(Rajpurkar et al., 2016)</ref>. We follow <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> to use the split text blocks from the English Wikipedia dump as the retrieval candidate set, which contains 21,015,324 passages.</p><p>Settings. We evaluate the in-domain performance using the Dense Passage Retrieval (DPR) Model proposed by <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> We use top-k retrieval accuracy as our evaluation metric, which measures the percentage of questions that have at least one document containing the answer in the top k retrieved documents.</p><p>In our experiments, we report top-20 and top-100 accuracy following <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>.</p><p>Results. We identify the best-performed hyperparameters for each method and the results are shown in Table <ref type="table" target="#tab_0">1</ref>. P-Tuning v2 and BitFit are comparable to fine-tuned baseline on all datasets as expected. P-Tuning v2 also performs the best on four in-domain datasets among the tested PE approaches. On the other hand, Lester et al. &amp; P-Tuning performs a bit weaker than the fine-tuned baseline. Adapter shows weak performance, but might be attributed to the version of implementation <ref type="bibr" target="#b36">(Pfeiffer et al., 2020)</ref> (i.e., other versions with different implementation or more tunable parame-ters may be better). The results empirically demonstrate that PE methods can significantly cut down necessary tuning parameters to 0.1% and provide competitive performance in in-domain data.</p><p>Interestingly, we also notice that on the out-ofdomain dataset SQuAD, P-Tuning v2, Lester et al. &amp; P-Tuning, and BitFit substantially outperform the fine-tuned counterpart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Cross-Domain and Cross-Topic Generalizability</head><p>In this section, we examine the zero-shot generalizability of fine-tuning and PE learning. We take P-Tuning v2 <ref type="bibr" target="#b27">(Liu et al., 2022)</ref> as an representative for PE methods, which has the highest average indomain accuracy . Particularly, as previous work seldom looks into the cross-topic generalization, we introduce OAG-QA, the largest fine-grained cross-topic retrieval dataset to date. On crossdomain evaluation, we adopt the well-acknowledge BEIR <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref> benchmark.</p><p>6.1 OAG-QA: A Fine-Grained Cross-Topic Scientific Literature Retrieval Dataset OAG-QA is a fine-grained topic-specific passage retrieval dataset constructed by collecting high-quality questions and answers from Online Question-and-Answers (Q&amp;A) forums, such as Quora and Stack Exchange. These forums offer people chances to ask questions and receive answers from other expert users, potentially with reference to academic papers. These references can be consequently aligned to paper entities with rich meta-information (e.g. abstract, fieldof-study (FOS)) in the Open Academic Graph (OAG) <ref type="bibr" target="#b52">(Zhang et al., 2019)</ref>, the largest publicly available academic entity graph to date. We collect questions from two influential web- Q: What is the smallest real q such that there is always a prime between n q and (n + 1) q ? Paper: Explicit Estimate on Primes Between Consecutive Cubes  <ref type="table" target="#tab_3">3</ref>) which consists of 17,948 unique queries from 22 scientific disciplines and 87 fine-grained topics. Given each topic, we sample 10,000 candidate papers including the groundtruth from the same disciplines as OAG annotates, and take their titles and abstracts as the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Zero-Shot Cross-Domain Generalization</head><p>Datasets. We adopt Benchmarking-IR (BEIR) proposed in <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>, a zero-shot generalization benchmark for evaluating retrievers tasks across domains. It consists of zero-shot evaluation datasets, (15 out of 18 are available) from 9 retrieval tasks of heterogeneity. The datasets vary from each other in corpus sizes (3.6k -15M documents), queries and documents' lengths, and domains (news articles vs. scientific papers).</p><p>Settings. Following <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>, we trained the models on one dataset and report the zero-shot performances on the other datasets. We choose DPR <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> from dense retrievers and ColBERT <ref type="bibr" target="#b20">(Khattab and Zaharia, 2020)</ref> from late-interaction models to explore the retrieval effectiveness under PE and full-parameter finetuning settings. Following the settings of BEIR, we use the open-sourced Multi-dataset DPR checkpoint <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> and ColBERT model trained on MS MARCO <ref type="bibr" target="#b31">(Nguyen et al., 2016)</ref>.</p><p>To obtain comparable evaluation across datasets and tasks in BEIR <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>, we use Normalized Cumulative Discount Gain (nDCG@k) to involve both binary and graded relevance measures for ranking quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results. Table 4 reports the results of DPR and</head><p>ColBERT on the 15 datasets of BEIR. For DPR, P-Tuning v2 generalizes much better than the finetuned one on all datasets except for MS MARCO and DBPedia. We observe that the datasets where our method improves by more than 5 points, such as Touche-2020 and SciFact, usually consist of long documents with average lengths over 200. We conjecture that the DPR trained on OpenQA has been biased to the 100-word document length in the oridinary setting. In summary, P-Tuning v2 achieves an absolute 5.2% improvement on the fine-tuned baseline on average. Thus, P-Tuning v2 greatly improves the out-of-domain generalization of dense retrieval models.</p><p>On the other hand, ColBERT trained by P-Tuning v2 also outperforms the fine-tuned Col-BERT on almost all (13/15) datasets. P-Tuning v2 slightly underperforms on NQ and Quora where documents are relatively short. For the out-ofdomain average scores, P-Tuning v2 outperforms the baseline ColBERT by an absolute gain of 2.4%. Compared to DPR, fine-tuned ColBERT generalizes better, probably because it is trained on the larger and more diverse MS MARCO and its architecture can be more scalable. But P-Tuning v2 still gains an advancement on generalization over the fine-tuned one. In conclusion, the results Table <ref type="table">4</ref>: Zero-shot cross-domain generalization evaluated on 14 datasets of BEIR <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>. All scores are nDCG@10, and those of "FT" are taken from BEIR's report. ("*" denotes in-domain datasets; "FT" denotes fine-tuning; "PT2" denotes P-Tuning v2) show that with similar in-domain performance, P-Tuning v2 can improve zero-shot generalization on cross-domain data by a large margin compared to fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Zero-Shot Cross-Topic Generalization</head><p>In addition to cross-domain generalization, crosstopic generalization is a more pragmatic and meaningful challenge for retrieval tasks. For example, in a scientific literature retrieval system, the corpus sizes, abstract lengths, and writing styles would not vary too much. The challenge lies in refining retrievers for more fine-grained fields-of-study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Settings.</head><p>We use the same trained DPR <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> and ColBERT (Khattab and Zaharia, 2020) model introduced in 6.2 and conduct a zero-shot evaluation. We measure top-20 retrieval accuracy on the dataset of each topic and report the average scores over each discipline.</p><p>Results. Table <ref type="table" target="#tab_5">5</ref> compares models trained by P-Tuning v2 and fine-tuning using top-20 retrieval accuracy. P-Tuning v2 outperforms fine-tuning in 20/22 topics in DPR and 18/22 topics in ColBERT respectively. Specifically, P-Tuning v2 performs poorly in Algebra and Linear algebra, two fields which contain a large number of mathematical symbols, in both DPR and ColBERT at the same time. Overall, on average P-Tuning v2 are better than that of baseline, gaining 2.6% and 1.2% absolute improvement over DPR and ColBERT respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">An Understanding of the Generalization</head><p>How does PE learning help neural text retrievers to generalize well? While the merit might be attributed to a larger learning rate or preventing pretrained language models from catastrophic forgetting in fine-tuning, in this section we look into other quantifiable reasons that it can encourage confidence calibration and query-length robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Confidence Calibration</head><p>Despite things like accuracy are usually the most concerned for a machine learning model, there are more metrics to care about, such as calibration. Calibration (or confidence calibration) refers to models' ability to provide class probability that corresponds to its likelihood of being true. A calibrated model provide trustful confidence to its prediction, which is particularly important for algorithms deploying in critical real-world scenarios. Notwithstanding the higher accuracy, modern neural networks are known to be miscalibrated <ref type="bibr" target="#b11">(Guo et al., 2017)</ref>. Recent literature has  <ref type="bibr" target="#b30">(Naeini et al., 2015)</ref> of Fine-tuning (FT) and P-Tuning v2 (PT2) based on DPR <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>; smaller the better. Figure <ref type="figure">4</ref>: NDCG@10 (left axis) and #Query (right axis) of P-Tuning v2 (PT2) and Fine-tuning (FT) by query length (splitted into bins) on ArguAna and Quora based on DPR <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>. also demonstrated that cross-domain calibration is a nice proxy for model's out-of-domain generalizability <ref type="bibr" target="#b46">(Wald et al., 2021)</ref>. To measure a retriever's calibration, we resort to Expected Calibration Error (ECE) proposed in <ref type="bibr" target="#b30">(Naeini et al., 2015)</ref> as:</p><formula xml:id="formula_9">ECE = M m=1 |B m | n 1 B m i?Bm [I(? i = y i ) -pi ]</formula><p>(9) which bins estimates from n samples within [0, 1] into B m , a set of M equal length buckets. Each sample i has its label y i , estimated label ?i , and estimated probability pi .</p><p>Following prior work <ref type="bibr" target="#b34">(Penha and Hauff, 2021)</ref>, we cast the ranking problem as multi-class classification to compute ECE. We take queries with valid top-5 predictions, apply softmax over retrieval scores per query, and turns the ranking into 5-class classification to derive ECE (Cf. Table <ref type="table" target="#tab_6">6</ref>) and calibration diagrams (Cf. Figure <ref type="figure" target="#fig_2">3</ref>).</p><p>Findings. As shown in Table <ref type="table" target="#tab_6">6</ref> and Figure <ref type="figure" target="#fig_2">3</ref>, we find that P-Tuning v2 based DPR are more calibrated than its fine-tuned counterpart, whatever on in-domain or cross-domain datasets. The only exception is the TREC-COVID dataset in BEIR, which only evaluates on 50 queries and may cause a variance. To conclude, even though fine-tuning and P-Tuning v2 share a similar in-domain performance, their levels of calibration still vary largely from each other, which accords with observations in <ref type="bibr" target="#b11">(Guo et al., 2017</ref>) that better accuracy does not mean better calibration property. It is also no surprise now for us to understand P-Tuning v2's generalizability, as pointed out in <ref type="bibr" target="#b46">(Wald et al., 2021)</ref>, as it shows a superior multi-domain calibration effect to fine-tuning that usually leads to better crossdomain generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Query-Length Robustness</head><p>Mismatched query lengths across datasets is another hidden reason that might raises concerns. For example, in four OpenQA datasets we experiment DPR on, most query lengths locate in the interval from 8 to 40; while some other datasets can have very different query lengths. Fine-tuning may change pre-trained models' positional embeddings and consequently bias text retrievers to certain query lengths. On the contrary, none of existing PE methods would tune the positional embeddings.</p><p>Findings. We present a case study on two typical datasets, Quora and ArguAna from BEIR <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref>, to justify the hypothesis. The query lengths are derived from splitting plain query texts by white-spaces. For a clearer visualization, we split the lengths by equal-sized bins. As shown in Figure <ref type="figure">4</ref>, when queries are medium-length (30-100), both P-Tuning v2 and fine-tuning perform comparably. But when queries are either relatively short (in Quora) or long (in ArguAna), P-Tuning v2 generalizes much better than fine-tuning. This indicates that PE learning based (e.g., P-Tuning v2) neural text retrievers have a better robustness against varied query lengths in testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We propose to leverage PE prompt learning for neural text retrieval. We empirically demonstrate that PE learning can achieve comparable performance to full-parameter fine-tuning in in-domain setting while drastically reduce the usage of parameters. Furthermore, PE approaches like P-Tuning v2 significantly improve the cross-domain and cross-topic generalization. Moreover, we show that this generalization advantage comes from the improved confidence calibration and query length robustness of PE learning. Finally, we construct and release the largest fine-grained topic-specific academic retrieval dataset OAG-QA, which contains 87 different domains and 17,948 query-paper pairs, to support future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this section we discuss several potentially unresolved topics related to this work.</p><p>First, despite the superior parameter-efficiency of PE learning, a long-standing challenge is that it converges slower and is relatively more sensitive to hyper-parameters (typically, learning rate) than fine-tuning. We have the same observation in this work and have to bypass the problem by training longer and trying multiple groups of hyperparameters. It is thus important to design more robust and stable training strategies for prompt tuning in the future.</p><p>Second, the OAG-QA dataset requires further exploration. As indicated in Table <ref type="table" target="#tab_7">7</ref>, we purposely leave 20 samples in each fine-grained topic for future investigations on the effectiveness of PE learning in few-shot and meta learning settings. Conventionally, these settings require fine-tuning the whole model in each task separately, causing great redundancy. However, PE learning's extreme parameter efficiency can come to its rescue. We leave this investigation for future work.</p><p>Third, PE learning's calibration and generalization properties should ideally be applicable to other language tasks, such as text understanding and generation. In this work, we focus on neural text retrieval, as it usually faces more distribution-shift scenarios. However, many other practical problems also suffer from the challenges of biased training data and generalization, and the application of PE learning on them remains largely unexplored. A.3 Alignment.</p><p>We align the extracted papers with the OAG paper database <ref type="bibr" target="#b52">(Zhang et al., 2019)</ref> to retrieve more information of papers, especially abstract. The papers which cannot be found in the database or whose corresponding abstract is missing in the database are discarded. Finally we only keep the questionpaper pairs with complete title and abstract text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Statistics</head><p>Our self-construct dataset OAG-QA composes of 17,948 unique questions from 21 scientific discipline and 87 fine-grained topics. We sample 10,000 papers including the groundtruth papers to construct a candidate set for each topic. The queries in each topic is divided as a training set of size 20 and a test set with the remaining data. OAG-QA has a two-level hierarchical structure where each topic is under a specific discipline. Table <ref type="table" target="#tab_7">7</ref> shows the statistics of OAG-QA in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details</head><p>B.1 Implementation of DPR Experiment enviroment We conducted our experiments on the Linux platform, the version of which was 3.10.0-957.el7.x86_64, and the GPU version was NVIDIA Corporation GV100GL [Tesla V100 PCIe 32GB]. After installation of CUDA 11.2, we set basic experiment environment with conda 4.10.1. Our models were implemented using Python 3.8 and PyTorch 1.11.0. We used the transformers library (version 4.12.5) for the pre-trained BERT model. When training DPR with Adapter, the adapter-transformers(version 2.2.0) was used.</p><p>Original DPR <ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref> We used the open-sourced DPR checkpoint trained on multitask data with bert-base-uncased model (sequence length: 256). The results are aligned with DPR authors' reported ones in paper.</p><p>DPR with P-tuning v2 <ref type="bibr" target="#b27">(Liu et al., 2022)</ref>. For Ptuning v2 training, we used a batch size of 128 and a sequence length of 256. We trained the question and passage encoders, which are based on bertbased-uncased model, for up to 40 epochs for large datasets (NQ, TriviaQA, SQuAD and Multi-dataset setting) and 100 epochs for small datasets (TREC, QA) with a learning rate of 0.01 and a prefix length of 100 using Adam, linear scheduling with 5% warm-up and dropout rate 0.1.</p><p>DPR with <ref type="bibr">Lester et al. &amp; P-Tuning (Liu et al., 2021c)</ref>. Like P-tuning v2, we used bert-baseduncased model as basic model, however, we only applied modification to the input and set the parameters of learning rate as 0.01. We tried different prefix length such as 100, 200 to test the performance of the model.</p><p>DPR with <ref type="bibr">BitFit (Zaken et al., 2022)</ref>. In BitFit training, we use the same values of batch size, sequence length, dropout rate and learning rate as in P-tuning v2 as well as the same model, bert-baseduncased model. It took 40 epochs to train the model in the same datasets using Adam Optimizer and linear scheduling with 5% warm-up. We fixed all parameters and trained only bias parameters.</p><p>DPR with Adapter <ref type="bibr" target="#b15">(Houlsby et al., 2019)</ref>. In the procedure of training Adapter, we set the Adapter architectures as PfeifferConfig style, and except learning rate of 3e-5 and epochs of 50, the parameters and datasets were all same as in Bit-Fit as introduced in the above paragraph. We adopt the implementation of adapter in ADAPTER-TRANSFORMER <ref type="bibr" target="#b36">(Pfeiffer et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Implementation of ColBERT</head><p>Original ColBERT <ref type="bibr" target="#b20">(Khattab and Zaharia, 2020)</ref> In full-parameter training, We adopt the parameters offered by <ref type="bibr" target="#b20">(Khattab and Zaharia, 2020)</ref>. We trained ColBERT model with a learning rate of 3 ? 10 -6 with a batch size of 32. We fix the number of embeddings per query at 32 and follows <ref type="bibr" target="#b40">(Thakur et al., 2021)</ref> to set the number of document embeddings as 300. The embedding dimension is set as 128. The model is trained for up to 400k iterations.</p><p>ColBERT with P-Tuning v2 <ref type="bibr" target="#b27">(Liu et al., 2022)</ref>.</p><p>With P-tuning v2, We trained ColBERT from the parameters of bert-based-uncased for up to 400K steps on MS MARCO dataset with a learning rate of 0.01 and a prefix length of 64. We used a batch size of 32 and fixed the number of embeddings per query at 32 and the number of embeddings per document at 300. The embedding dimension is set to be 128.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The illustration of four parameter-efficient methods. The PLM module represents a certain sublayer of a PLM, e.g., the attention or FFN. The components in blue are frozen and the yellow ones are trainable.</figDesc><graphic url="image-1.png" coords="4,70.87,70.87,453.55,96.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2 (a)).BitFit<ref type="bibr" target="#b51">(Zaken et al., 2022)</ref>. Each Transformer layer consists of self-attention, FFN, and Layer-Norm operations, all of which have certain bias terms as shown in Eqs 4 and 5. Bit-fit proposes to only tune the bias terms b(?) of the Transformer (Cf. Figure2 (d)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Calibration diagrams of DPR using P-Tuning v2 and fine-tuning on in-domain OpenQA datasets (e.g., NaturalQuestions and TriviaQA) and cross-domain BEIR datasets (e.g., ArguAna, Quora and SciFact).</figDesc><graphic url="image-2.png" coords="8,428.64,159.15,95.77,95.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>In-domain parameter-efficiency. The retrievers are multi-task fine-tuned or PE trained on 4 OpenQA datasets (except for SQuAD * , which is excluded from Avg.) following the setting in<ref type="bibr" target="#b19">(Karpukhin et al., 2020)</ref>.</figDesc><table><row><cell>Retrievers</cell><cell>#Params</cell><cell>Top-20</cell><cell></cell><cell>Top-100</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">Avg. NQ Trivia WQ TREC SQuAD  *  Avg. NQ Trivia WQ TREC SQuAD  *</cell></row><row><cell>BM25</cell><cell>-</cell><cell>63.0 59.1 66.9 55.0 70.9</cell><cell>68.8</cell><cell>76.4 73.7 76.7 71.1 84.1</cell><cell>80.0</cell></row><row><cell>Fine-tuning</cell><cell>100%</cell><cell>80.6 79.4 78.8 75.0 89.1</cell><cell>51.6</cell><cell>86.9 86.0 84.7 82.9 93.9</cell><cell>67.6</cell></row><row><cell>P-Tuning v2</cell><cell>0.1%</cell><cell>80.6 79.5 78.8 75.2 88.8</cell><cell>54.6</cell><cell>87.5 86.6 85.0 83.3 95.1</cell><cell>69.6</cell></row><row><cell>Adapter 1</cell><cell>0.8%</cell><cell>38.8 37.1 38.8 30.3 49.1</cell><cell>28.3</cell><cell>56.9 53.8 56.4 47.5 70.0</cell><cell>44.1</cell></row><row><cell cols="3">Lester et al. &amp; P-tuning 0.01% 78.0 76.7 75.6 72.3 87.5</cell><cell>56.1</cell><cell>85.8 85.0 82.8 82.1 93.1</cell><cell>70.6</cell></row><row><cell>BitFit</cell><cell cols="2">0.09% 79.9 78.8 77.6 74.8 88.2</cell><cell>56.0</cell><cell>87.2 86.3 84.5 83.3 94.5</cell><cell>71.4</cell></row><row><cell cols="6">1 We adopt (Pfeiffer et al., 2020)'s implementation (Cf. Appendix B.1) and tried several hyper-parameter combinations.</cell></row><row><cell cols="2">et al., 2019), TriviaQA</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Examples of disciplines, topics, and example query-paper pairs (only titles are shown) in OAG-QA. What is the effective potential for photons in X-ray diffraction? Paper: Introduction to the theory of x-ray matter interaction</figDesc><table><row><cell>Disc.</cell><cell cols="2">#Topic Example Topic</cell><cell cols="2">#Query Example query-paper pairs</cell></row><row><cell>Neural Network</cell><cell>2</cell><cell>Artificial Neural Network</cell><cell>488</cell><cell>Q: Can neural networks be used to prove conjectures? Paper: Generating Correctness Proofs with Neural Networks</cell></row><row><cell cols="5">Quantum Mechanics Q: Number 12 Photon 125 Theory 4 Prime Number 225</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>OAG-QA's statistics and examples. Compared to existing scientific retrieval dataset (Sci-Fact<ref type="bibr" target="#b45">(Wadden et al., 2020)</ref>, SCIDOCS<ref type="bibr" target="#b8">(Cohan et al., 2020)</ref>, TREC-COVID<ref type="bibr" target="#b43">(Voorhees et al., 2021)</ref>).</figDesc><table><row><cell>Dataset</cell><cell cols="4">#Query #Corpus #Disc. #Topic Fabrication</cell></row><row><cell>SciFact</cell><cell>1,409</cell><cell>5,183 -</cell><cell cols="2">-Crowd-Source</cell></row><row><cell>SCIDOCS</cell><cell cols="2">22,000 25,657 -</cell><cell>-</cell><cell>User Clicks</cell></row><row><cell cols="3">TREC-COVID 50 171,332 -</cell><cell cols="2">-Crowd-Source</cell></row><row><cell>OAG-QA</cell><cell cols="2">17,948 870,000 22</cell><cell cols="2">87 Online Forum</cell></row></table><note><p><p><p><p>sites: Stack Exchange 2 in English, and Zhihu 3 in Chinese. On top of the collected pairs of questions and paper titles, we align them to OAG</p><ref type="bibr" target="#b52">(Zhang et al., 2019;</ref> Wang et al., 2020a;<ref type="bibr" target="#b39">Tang et al., 2008)</ref> </p>paper ids via public API 4 . In terms of topics, disciplines from Stack Exchange and tags from Zhihu naturally serve as fine-grained topics attached to collected questions after post-processing. For more construction details, please refer to Appendix A.</p>Consequently, we present OAG-QA (Cf. Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Zero-shot cross-topic generalization evaluated on 22 disciplines of OAG-QA. All scores are Top-20.</figDesc><table><row><cell cols="5">("FT" denotes fine-tuning; "PT2" denotes P-Tuning</cell></row><row><cell>v2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model(?)</cell><cell></cell><cell cols="2">Dense</cell><cell>Late-Interaction</cell></row><row><cell>Topic(?)</cell><cell>FT</cell><cell>DPR</cell><cell>PT2</cell><cell>ColBERT FT PT2</cell></row><row><cell>Geometry</cell><cell cols="4">0.154 0.199 0.303 0.323</cell></row><row><cell>Statistics</cell><cell cols="4">0.149 0.184 0.289 0.302</cell></row><row><cell>Algebra</cell><cell cols="4">0.194 0.171 0.271 0.267</cell></row><row><cell>Calculus</cell><cell cols="4">0.145 0.169 0.248 0.259</cell></row><row><cell>Number theory</cell><cell cols="4">0.136 0.161 0.260 0.256</cell></row><row><cell>Linear algebra</cell><cell cols="4">0.227 0.211 0.351 0.345</cell></row><row><cell>Astrophysics</cell><cell cols="4">0.130 0.160 0.213 0.229</cell></row><row><cell>Quantum mechanics</cell><cell cols="4">0.134 0.169 0.240 0.245</cell></row><row><cell>Physics</cell><cell cols="4">0.205 0.245 0.349 0.360</cell></row><row><cell>Chemistry</cell><cell cols="4">0.157 0.159 0.296 0.300</cell></row><row><cell>Biochemistry</cell><cell cols="4">0.301 0.332 0.443 0.463</cell></row><row><cell>Health Care</cell><cell cols="4">0.367 0.388 0.446 0.459</cell></row><row><cell>Natural Science</cell><cell cols="4">0.306 0.364 0.408 0.410</cell></row><row><cell>Psychology</cell><cell cols="4">0.214 0.247 0.332 0.362</cell></row><row><cell>Algorithm</cell><cell cols="4">0.211 0.244 0.365 0.390</cell></row><row><cell>Neural Network</cell><cell cols="4">0.176 0.207 0.214 0.245</cell></row><row><cell>Computer Vision</cell><cell cols="4">0.152 0.197 0.264 0.291</cell></row><row><cell>Data Mining</cell><cell cols="4">0.139 0.161 0.226 0.231</cell></row><row><cell>Deep Learning</cell><cell cols="4">0.143 0.173 0.249 0.271</cell></row><row><cell>Machine Learning</cell><cell cols="4">0.136 0.187 0.258 0.278</cell></row><row><cell>NLP</cell><cell cols="4">0.149 0.160 0.234 0.254</cell></row><row><cell>Economics</cell><cell cols="4">0.339 0.353 0.321 0.298</cell></row><row><cell>Average</cell><cell cols="4">0.194 0.220 0.299 0.311</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Expected Calibration Error (ECE)  </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Statistics of OAG-QA.</figDesc><table><row><cell>Discipline</cell><cell>Topic</cell><cell cols="4">#Query Train Test #Query</cell></row><row><cell></cell><cell>geometry</cell><cell>230</cell><cell>20</cell><cell>210</cell><cell></cell></row><row><cell></cell><cell>algebraic_geometry</cell><cell>188</cell><cell>20</cell><cell>168</cell><cell></cell></row><row><cell></cell><cell>algebraic_topology</cell><cell>131</cell><cell>20</cell><cell>111</cell><cell></cell></row><row><cell>Geometry</cell><cell>differential_geometry</cell><cell>230</cell><cell>20</cell><cell>210</cell><cell>1380</cell></row><row><cell></cell><cell>group_theory</cell><cell>248</cell><cell>20</cell><cell>228</cell><cell></cell></row><row><cell></cell><cell>category</cell><cell>191</cell><cell>20</cell><cell>171</cell><cell></cell></row><row><cell></cell><cell>topology</cell><cell>162</cell><cell>20</cell><cell>142</cell><cell></cell></row><row><cell></cell><cell>mathematical_statistics</cell><cell>144</cell><cell>20</cell><cell>124</cell><cell></cell></row><row><cell>Statistics</cell><cell>bayes_theorem</cell><cell>134</cell><cell>20</cell><cell>114</cell><cell>516</cell></row><row><cell></cell><cell>probability_theory</cell><cell>238</cell><cell>20</cell><cell>218</cell><cell></cell></row><row><cell>Algebra</cell><cell>algebra polynomial</cell><cell>280 107</cell><cell>20 20</cell><cell>260 87</cell><cell>387</cell></row><row><cell></cell><cell>calculus</cell><cell>242</cell><cell>20</cell><cell>222</cell><cell></cell></row><row><cell></cell><cell>partial_differential_equation</cell><cell>200</cell><cell>20</cell><cell>180</cell><cell></cell></row><row><cell>Calculus</cell><cell>functional_analysis</cell><cell>127</cell><cell>20</cell><cell>107</cell><cell>868</cell></row><row><cell></cell><cell>hilbert_space</cell><cell>127</cell><cell>20</cell><cell>107</cell><cell></cell></row><row><cell></cell><cell>real_analysis</cell><cell>172</cell><cell>20</cell><cell>152</cell><cell></cell></row><row><cell></cell><cell>number_theory</cell><cell>274</cell><cell>20</cell><cell>254</cell><cell></cell></row><row><cell>Number theory</cell><cell>combinatorics set_theory</cell><cell>221 179</cell><cell>20 20</cell><cell>201 159</cell><cell>899</cell></row><row><cell></cell><cell>prime_number</cell><cell>225</cell><cell>20</cell><cell>205</cell><cell></cell></row><row><cell>Linear algebra</cell><cell>linear_algebra matrix</cell><cell>220 130</cell><cell>20 20</cell><cell>200 110</cell><cell>350</cell></row><row><cell></cell><cell>astronomy</cell><cell>108</cell><cell>20</cell><cell>88</cell><cell></cell></row><row><cell></cell><cell>astrophysics</cell><cell>101</cell><cell>20</cell><cell>81</cell><cell></cell></row><row><cell></cell><cell>universe</cell><cell>112</cell><cell>20</cell><cell>92</cell><cell></cell></row><row><cell></cell><cell>cosmology</cell><cell>159</cell><cell>20</cell><cell>139</cell><cell></cell></row><row><cell></cell><cell>general_relativity</cell><cell>191</cell><cell>20</cell><cell>171</cell><cell></cell></row><row><cell>Astrophysics</cell><cell>special_relativity</cell><cell>132</cell><cell>20</cell><cell>112</cell><cell>1575</cell></row><row><cell></cell><cell>spacetime</cell><cell>172</cell><cell>20</cell><cell>152</cell><cell></cell></row><row><cell></cell><cell>dark_matter</cell><cell>176</cell><cell>20</cell><cell>156</cell><cell></cell></row><row><cell></cell><cell>black_hole</cell><cell>160</cell><cell>20</cell><cell>140</cell><cell></cell></row><row><cell></cell><cell>entropy</cell><cell>127</cell><cell>20</cell><cell>107</cell><cell></cell></row><row><cell></cell><cell>string_theory</cell><cell>137</cell><cell>20</cell><cell>117</cell><cell></cell></row><row><cell></cell><cell>quantum_mechanics</cell><cell>467</cell><cell>20</cell><cell>447</cell><cell></cell></row><row><cell></cell><cell>quantum_entanglement</cell><cell>101</cell><cell>20</cell><cell>81</cell><cell></cell></row><row><cell></cell><cell>quantum_field_theory</cell><cell>295</cell><cell>20</cell><cell>275</cell><cell></cell></row><row><cell></cell><cell>quantum_gravity</cell><cell>154</cell><cell>20</cell><cell>134</cell><cell></cell></row><row><cell></cell><cell>quantum_information</cell><cell>190</cell><cell>20</cell><cell>170</cell><cell></cell></row><row><cell>Quantum mechanics</cell><cell>particle_physics photon</cell><cell>247 125</cell><cell>20 20</cell><cell>227 105</cell><cell>2385</cell></row><row><cell></cell><cell>supersymmetry</cell><cell>245</cell><cell>20</cell><cell>225</cell><cell></cell></row><row><cell></cell><cell>thermodynamics</cell><cell>213</cell><cell>20</cell><cell>193</cell><cell></cell></row><row><cell></cell><cell>experimental_physics</cell><cell>143</cell><cell>20</cell><cell>123</cell><cell></cell></row><row><cell></cell><cell>conformal_field_theory</cell><cell>101</cell><cell>20</cell><cell>81</cell><cell></cell></row><row><cell></cell><cell>gauge_theory</cell><cell>104</cell><cell>20</cell><cell>84</cell><cell></cell></row><row><cell></cell><cell>classical_mechanics</cell><cell>115</cell><cell>20</cell><cell>95</cell><cell></cell></row><row><cell></cell><cell>condensed_matter_physics</cell><cell>201</cell><cell>20</cell><cell>181</cell><cell></cell></row><row><cell>Physics</cell><cell>optics</cell><cell>151</cell><cell>20</cell><cell>131</cell><cell>862</cell></row><row><cell></cell><cell>electromagnetism</cell><cell>224</cell><cell>20</cell><cell>204</cell><cell></cell></row><row><cell></cell><cell>mathematical_physics</cell><cell>171</cell><cell>20</cell><cell>151</cell><cell></cell></row><row><cell></cell><cell>organic_chemistry</cell><cell>332</cell><cell>20</cell><cell>312</cell><cell></cell></row><row><cell></cell><cell>chemical_synthesis</cell><cell>240</cell><cell>20</cell><cell>220</cell><cell></cell></row><row><cell>Chemistry</cell><cell>inorganic_chemistry</cell><cell>218</cell><cell>20</cell><cell>198</cell><cell>1082</cell></row><row><cell></cell><cell>physical_chemistry</cell><cell>190</cell><cell>20</cell><cell>170</cell><cell></cell></row><row><cell></cell><cell>computational_chemistry</cell><cell>102</cell><cell>20</cell><cell>82</cell><cell></cell></row><row><cell>Biochemistry</cell><cell>biochemistry cell_biology</cell><cell>129 313</cell><cell>20 20</cell><cell>109 293</cell><cell>442</cell></row><row><cell></cell><cell>health_care</cell><cell>288</cell><cell>20</cell><cell>268</cell><cell></cell></row><row><cell>Health Care</cell><cell>endocrinology</cell><cell>111</cell><cell>20</cell><cell>91</cell><cell>623</cell></row><row><cell></cell><cell>physiology</cell><cell>224</cell><cell>20</cell><cell>204</cell><cell></cell></row><row><cell>Natural Science</cell><cell>natural_science evolutionary_biology</cell><cell>193 471</cell><cell>20 20</cell><cell>173 451</cell><cell>664</cell></row><row><cell>Psycology</cell><cell>social_psychology cognitive_neuroscience</cell><cell>223 348</cell><cell>20 20</cell><cell>203 328</cell><cell>571</cell></row><row><cell>Algorithm</cell><cell>algorithm graph_theory</cell><cell>386 189</cell><cell>20 20</cell><cell>366 169</cell><cell>575</cell></row><row><cell>Neural Network</cell><cell>artificial_neural_network cognitive_science</cell><cell>488 102</cell><cell>20 20</cell><cell>468 82</cell><cell>590</cell></row><row><cell></cell><cell>computer_vision</cell><cell>315</cell><cell>20</cell><cell>295</cell><cell></cell></row><row><cell>Computer Vision</cell><cell>computer_graphics_images</cell><cell>68</cell><cell>20</cell><cell>48</cell><cell>661</cell></row><row><cell></cell><cell>convolutional_neural_network</cell><cell>278</cell><cell>20</cell><cell>258</cell><cell></cell></row><row><cell></cell><cell>data_mining</cell><cell>131</cell><cell>20</cell><cell>111</cell><cell></cell></row><row><cell></cell><cell>feature_selection</cell><cell>130</cell><cell>20</cell><cell>110</cell><cell></cell></row><row><cell>Data Mining</cell><cell>cross_validation</cell><cell>117</cell><cell>20</cell><cell>97</cell><cell>694</cell></row><row><cell></cell><cell>time_series</cell><cell>224</cell><cell>20</cell><cell>204</cell><cell></cell></row><row><cell></cell><cell>cluster_analysis</cell><cell>92</cell><cell>20</cell><cell>72</cell><cell></cell></row><row><cell></cell><cell>deep_learning</cell><cell>372</cell><cell>20</cell><cell>352</cell><cell></cell></row><row><cell>Deep Learning</cell><cell>optimization_algorithm</cell><cell>238</cell><cell>20</cell><cell>218</cell><cell>791</cell></row><row><cell></cell><cell>reinforcement_learning</cell><cell>181</cell><cell>20</cell><cell>161</cell><cell></cell></row><row><cell></cell><cell>machine_learning</cell><cell>583</cell><cell>20</cell><cell>563</cell><cell></cell></row><row><cell>Machine Learning</cell><cell>hidden_markov_model classifier</cell><cell>112 269</cell><cell>20 20</cell><cell>92 249</cell><cell>1208</cell></row><row><cell></cell><cell>linear_regression</cell><cell>244</cell><cell>20</cell><cell>224</cell><cell></cell></row><row><cell>NLP</cell><cell>natural_language_processing recurrent_neural_network</cell><cell>305 282</cell><cell>20 20</cell><cell>285 262</cell><cell>587</cell></row><row><cell>Economics</cell><cell>economics</cell><cell>238</cell><cell>20</cell><cell>218</cell><cell>238</cell></row><row><cell>Total</cell><cell>-</cell><cell cols="4">17948 1740 16208 17948</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://stackexchange.com/sites</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://www.zhihu.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://www.aminer.cn/restful_service</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://cloud.tencent.com/document/product/551/32572</p></note>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and data are at https://github.com/THUDM/ P-tuning-v2/tree/main/PT-Retrieval</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Details of OAG-QA</head><p>In this section, we introduced the steps for building our fine-grained cross-topic dataset OAG-QA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Data Collecting</head><p>OAG-QA is collected from two widely used websites: Stack Exchange in English and Zhihu in Chinese. Stack Exchange consists of various forums for specific domain, such as data science, physics and chemistry, where questions are marked by fine-grained tags by users. Zhihu is not divided by domains but questions are also tagged by topics.</p><p>A.2 Data Pre-Processing Paper Extraction and Title Retrieval. We extract the paper from answers by regular expression patterns for paper URLs. So far, we focus on five types of URLs from the answer context: arxiv.org, dl.acm.org, doi.org, researchgate.net, www.nature.com, which can indicate publications cited by users. Then we retrieve the titles from the URLs using the the strategies listed below: ? arxiv.org: We recognize pdf suffix in the URL and extract arxiv id with regular expression, then query in the arxiv API with arxiv id to get the paper title. ? dl.acm.org: We get the HTML with URL, use the text in "title" label, then delete the website name in the suffix, take the result as the paper title. ? doi.org: We extract doi with regular expression, then query the doi api with the doi to get the paper title. ? researchgate.net: We just split the suffix of URL into words with "_" as the paper title. ? www.nature.com: We get the HTML with URL, use the text in "title" label, then delete the website name in the suffix, take the result as the paper title.</p><p>Translation. Because questions from Zhihu are in Chinese, we use Tencent Cloud 5 for the corpus translation.</p><p>Cleaning. Out of consideration for remaining the diversity of questions and difficulty to evaluate the quality of questions in academic fields, we just use simple cleaning strategies. For the questions from Stack Exchange, we deleted the questions shorter than 4 words which usually not able to restrict the topic to an appropriately sized field for paper retrieval. For the questions from Zhihu, we also just removed the questions manually which are obviously not related to academic topics.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling of the question answering task in the yodaqa system</title>
		<author>
			<persName><forename type="first">Petr</forename><surname>Baudis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Sediv?</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24027-5_20</idno>
	</analytic>
	<monogr>
		<title level="m">Experimental IR Meets Multilinguality, Multimodality, and Interaction -6th International Conference of the CLEF Association, CLEF 2015</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-09-08">2015. September 8-11, 2015</date>
			<biblScope unit="volume">9283</biblScope>
			<biblScope unit="page" from="222" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013<address><addrLine>Grand Hyatt Seattle, Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013-10">2013. 18-21 October 2013</date>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Bridging the lexical chasm: statistical approaches to answer-finding</title>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vibhu</forename><forename type="middle">O</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="DOI">10.1145/345508.345576</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">SIGIR 2000: Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">July 24-28, 2000</date>
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mc-Candlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Out-of-domain semantics to the rescue! zero-shot hybrid retrieval models</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="95" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SPECTER: document-level representation learning using citation-informed transformers</title>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.207</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="2270" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Retrieve fast, rerank smart: Cooperative and joint approaches for improved cross-modal retrieval</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Geigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="503" to="521" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Retrieval augmented language model pre-training</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
	<note>Panupong Pasupat, and Mingwei Chang</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pre-trained models: Past, present and future</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="225" to="250" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficiently teaching an effective dense retriever with balanced topic aware sampling</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hofst?tter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for NLP</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislaw</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruna</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML</title>
		<meeting>the 36th International Conference on Machine Learning, ICML<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">2019. 2019, 9-15 June 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lora: Low-rank adaptation of large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shean</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Towards unsupervised dense information retrieval with contrastive learning</title>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno>CoRR, abs/2112.09118</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. 2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Colbert: Efficient and effective passage search via contextualized late interaction over BERT</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401075</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SI-GIR 2020, Virtual Event</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SI-GIR 2020, Virtual Event<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-07-25">2020. July 25-30, 2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3045" to="3059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.353</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4582" to="4597" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Robert</forename><surname>Litschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Glava?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02292</idno>
		<title level="m">Parameter-efficient neural reranking for cross-lingual and multilingual retrieval</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">2021a. Generalizing discriminative retrieval models using generative tasks</title>
		<author>
			<persName><forename type="first">Binsheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J Shane</forename><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<biblScope unit="page" from="3745" to="3756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Challenges in generalization in open domain question answering</title>
		<author>
			<persName><forename type="first">Linqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01156</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaixuan</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicheng</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weng</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10385</idno>
		<imprint/>
	</monogr>
	<note type="report_type">2021c. Gpt understands, too. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Obtaining well calibrated probabilities using bayesian binning</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Mahdi Pakdaman Naeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milos</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><surname>Hauskrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)</title>
		<meeting>the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 colocated with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-09">2016. December 9. 2016</date>
			<biblScope unit="volume">1773</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Large dual encoders are generalizable retrievers</title>
		<author>
			<persName><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Hern?ndez ?brego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">B</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<idno>CoRR, abs/2112.07899</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">From doc2query to doctttttquery</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Epistemic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Online preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the calibration and uncertainty of neural learning to rank models for conversational search</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Penha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Hauff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter</title>
		<meeting>the 16th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Main Volume</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="160" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">KILT: a benchmark for knowledge intensive language tasks</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Majid</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><forename type="middle">De</forename><surname>Yazdani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilis</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName><surname>Riedel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.200</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06-06">2021. June 6-11, 2021</date>
			<biblScope unit="page" from="2523" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adapterhub: A framework for adapting transformers</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifton</forename><surname>Poth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aishwarya</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
	<note>Systems Demonstrations. Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11-01">2016. 2016. November 1-4, 2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Colbertv2: Effective and efficient retrieval via lightweight late interaction</title>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Saad-Falcon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno>CoRR, abs/2112.01488</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models</title>
		<author>
			<persName><forename type="first">Nandan</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021</title>
		<meeting>the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021</meeting>
		<imprint>
			<date type="published" when="2021-12">2021. December 2021</date>
		</imprint>
	</monogr>
	<note>Abhishek Srivastava, and Iryna Gurevych. virtual</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fever: a large-scale dataset for fact extraction and verification</title>
		<author>
			<persName><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arpit</forename><surname>Mittal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tasmeer</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>William R Hersh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Trec-covid: constructing a pandemic information retrieval test collection</title>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR Forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fact or fiction: Verifying scientific claims</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.609</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="7534" to="7550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">On calibration and out-of-domain generalization. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Greenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2215" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Microsoft academic graph: When experts are not enough</title>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chieh-Han</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anshul</forename><surname>Kanakia</surname></persName>
		</author>
		<idno type="DOI">10.1162/qss_a_00021</idno>
	</analytic>
	<monogr>
		<title level="j">Quant. Sci. Stud</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="396" to="413" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers</title>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5776" to="5788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2021-05-03">2021. May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A unified pretraining framework for passage ranking and expansion</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4555" to="4563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models</title>
		<author>
			<persName><forename type="first">Elad</forename><surname>Ben Zaken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shauli</forename><surname>Ravfogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05-22">2022. May 22-27, 2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Short Papers), ACL 2022</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">OAG: toward linking large-scale heterogeneous entity graphs</title>
		<author>
			<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3292500.3330785</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-08-04">2019. 2019. August 4-8, 2019</date>
			<biblScope unit="page" from="2585" to="2595" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
