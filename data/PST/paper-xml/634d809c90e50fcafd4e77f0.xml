<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TaxoPrompt: A Prompt-based Generation Method with Taxonomic Context for Self-Supervised Taxonomy Expansion</title>
				<funder ref="#_MjyKJ68">
					<orgName type="full">Chinese Scientific and Technical Innovation</orgName>
				</funder>
				<funder ref="#_4Vq8VUC">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_pKwQ8WF #_UccRAam">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hongyuan</forename><surname>Xu</surname></persName>
							<email>xuhongyuan@dbis.nankai.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tianjin Media Computing Center</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yunong</forename><surname>Chen</surname></persName>
							<email>chenyunong@dbis.nankai.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tianjin Media Computing Center</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zichen</forename><surname>Liu</surname></persName>
							<email>liuzichen@dbis.nankai.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tianjin Media Computing Center</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanlong</forename><surname>Wen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tianjin Media Computing Center</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaojie</forename><surname>Yuan</surname></persName>
							<email>yuanxj@nankai.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Tianjin Media Computing Center</orgName>
								<orgName type="institution">Nankai University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TaxoPrompt: A Prompt-based Generation Method with Taxonomic Context for Self-Supervised Taxonomy Expansion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Taxonomies are hierarchical classifications widely exploited to facilitate downstream natural language processing tasks. The taxonomy expansion task aims to incorporate emergent concepts into the existing taxonomies. Prior works focus on modeling the local substructure of taxonomies but neglect the global structure. In this paper, we propose TaxoPrompt, a framework that learns the global structure by prompt tuning with taxonomic context. Prompt tuning leverages a template to formulate downstream tasks into masked language model form for better distributed semantic knowledge use. To further infuse global structure knowledge into language models, we enhance the prompt template by exploiting the taxonomic context constructed by a variant of the random walk algorithm. Experiments on seven public benchmarks show that our proposed TaxoPrompt is effective and efficient in automatically expanding taxonomies and achieves state-of-the-art performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Taxonomy, a tree structure of hierarchical classifications for a given set of objects, is widely used in several NLP downstream tasks such as query understanding <ref type="bibr" target="#b14">[Yang et al., 2017]</ref>, information extraction <ref type="bibr" target="#b8">[Karamanolakis et al., 2020]</ref>, and personalized recommendation <ref type="bibr" target="#b5">[Huang et al., 2019]</ref>. However, the low coverage problem remains a bottleneck that restricts the performance of these taxonomy-dependent applications.</p><p>Recent studies <ref type="bibr" target="#b13">[Shen et al., 2018;</ref><ref type="bibr" target="#b14">Wang et al., 2021]</ref> focus on the automatic taxonomy expansion task to cover emergent concepts since manually curating a taxonomy is laborintensive, domain-specific, and time-consuming. The taxonomy expansion task aims to insert new concepts ("query concepts") into an existing taxonomy ("seed taxonomy") by finding their most appropriate hypernyms ("anchor concepts" or "positions") in the seed taxonomy while maintaining the consistency of the expanded taxonomy.</p><p>Early taxonomy expansion methods focus on learning semantic and contextual features of query concepts and an-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What is [parent-of] [data] [migration]?</head><p>It is</p><formula xml:id="formula_0">[MASK].</formula><p>Cloze Task</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It is [data] [mining]. Data Migration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[reduction]</head><p>[mining]</p><p>[migration]</p><p>[?]</p><p>? Pre-trained MLMs The grey box (right) shows the example of attaching the new concept "Data Migration" to the existing "Computer Science" taxonomy.</p><p>chor nodes extracted from corpora <ref type="bibr">[Nickel and Kiela, 2017;</ref><ref type="bibr" target="#b13">Shen et al., 2018]</ref>. However, these methods only model the hypernym-hyponym (is-a) relations but fail to capture the structure information of the existing taxonomy. To better leverage the existing taxonomy, recent works model the designed heuristic local structures of taxonomies which contain richer hierarchical information <ref type="bibr" target="#b13">[Shen et al., 2020;</ref><ref type="bibr" target="#b15">Yu et al., 2020;</ref><ref type="bibr" target="#b14">Wang et al., 2021]</ref>. Nevertheless, they all neglect the global structure information of the existing taxonomy and only consider the relations between query concepts and anchor structures. To overcome the above limitations, we propose Taxo-Prompt, a prompt-based taxonomy expansion framework. Proven to be effective for capturing the global structure information of graphs <ref type="bibr" target="#b1">[Chen et al., 2020]</ref>, the random walk is leveraged for our framework to generate self-supervision signals. Specifically, based on the characteristics of taxonomies, we design a random walk algorithm with different walk types. The walked paths generated from the existing taxonomy construct taxonomic context as our self-supervision signals.</p><p>Inspired by recent successes of prompt-based methods <ref type="bibr">[Liu et al., 2021a]</ref>, we employ the prompt tuning paradigm to fully exploit the semantic knowledge in the language model (LM). Under the prompt paradigm, we formulate the taxonomy expansion problem as a hypernym generation task. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, TaxoPrompt applies the prompt template designed for hypernym generation to enhance the learning of lexical-syntactic features. To make the best use of constructed self-supervision signals, we complement the prompt template by attaching taxonomic context as knowledgeable context during training. In this way, we infuse the global structure knowledge into the language model. TaxoPrompt tends to generate hypernyms with the structure consistency after learning the structure knowledge of the existing taxonomy.</p><p>Our contributions are summarized as follows:</p><p>? We propose a self-supervised framework that expands taxonomy by prompt-based hypernym generation. The framework reduces the time complexity that previously increased with the square of the number of nodes to linear in both training and inferring.</p><p>? We design a random walk algorithm to capture the global structure of the existing taxonomy and infuse structure knowledge into the LM in a contextual way.</p><p>? Extensive experiments on seven benchmark taxonomy datasets demonstrate the efficiency and effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Taxonomy Expansion. The taxonomy expansion methods aim to attach emergent concepts to the most appropriate anchor node in seed taxonomies. Many recent methods achieved considerable success. For example, TaxoExpan <ref type="bibr" target="#b13">[Shen et al., 2020]</ref> proposed position-enhanced egonet for neighborhood information aggregation and HyperExpan <ref type="bibr">[Ma et al., 2021]</ref> further extended such approach to hyperbolic space. STEAM <ref type="bibr" target="#b15">[Yu et al., 2020]</ref> serialized the existing taxonomies into mini-paths and scored the query node with them. TEMP <ref type="bibr">[Liu et al., 2021b]</ref>  Tuning Paradigm. Pre-trained LMs have been widely exploited in taxonomy expansion task <ref type="bibr" target="#b15">[Yu et al., 2020;</ref><ref type="bibr" target="#b14">Takeoka et al., 2021;</ref><ref type="bibr">Liu et al., 2021b;</ref><ref type="bibr" target="#b14">Wang et al., 2021]</ref>. Most existing methods followed a fine-tuning paradigm where LM is adapted to the downstream tasks like binary classification. Such a paradigm is prone to catastrophic forgetting, where the LM may lose its acquired knowledge before finetuning <ref type="bibr">[Liu et al., 2021a]</ref>. In our work, we follow a prompt tuning paradigm and adapt the taxonomy expansion task to LMs for better knowledge utilization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary</head><p>Definition 1 (Taxonomy). We follow <ref type="bibr" target="#b16">[Zhang et al., 2021]</ref> and define a taxonomy T = (N , E) as a directed acyclic graph where each node n ? N represents a concept (i.e., a word or a phrase) and each directed edge ?u, v? ? E implies a general "is a hyponym of" relation or heterogeneous relations such as "is type of" or "is capital of". The taxonomy follows a hierarchical structure where concept u is the most specific concept related to the concept v. Note that a concept node may have multiple parents in a large-scale taxonomy.</p><p>Definition 2 (Taxonomy Expansion). Given (1) an existing taxonomy T 0 = N 0 , E 0 and (2) a set of new concepts C, which can be either manually specified or automatically extracted from corpus D. The main goal of taxonomy expansion task is to complete the existing taxonomy T 0 into a larger taxonomy T = N 0 ? C, E 0 ? R with R being the newly discovered relations for each concept c ? C.</p><p>In this paper, we solve the taxonomy expansion task by generating hypernym for a query concept. More specifically, given (1) a set of terms N 0 and ( <ref type="formula">2</ref>) a new concept c ? C, our goal is to generate a list of tokens L = ? 1 , ? 2 , . . . , ? |L| , where ? i ? V is i-th token and |L| is the total length of the generated list, V denotes the token vocabulary. Then, we convert the token list L to a concept u ? N 0 and add ?u, c? to the existing taxonomy. Mathematically, our final taxonomy expansion goal can be formulated as following |C| independent optimization problems <ref type="bibr" target="#b13">[Shen et al., 2020]</ref>:</p><formula xml:id="formula_1">?i = arg max ui?N 0 log P (c i | u i , ?) , ?i ? {1, 2, . . . , |C|}, (1)</formula><p>where ? is the set of model parameters and u i is the hypernym generated for the query concept c i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modeling Hypernym Generation</head><p>Backbone Generation Model TaxoPrompt follows the prompt tuning paradigm <ref type="bibr">[Liu et al., 2021a]</ref> and exploits LMs in the masked language model task way (shown in Figure .1). Specifically, TaxoPrompt takes BERT base <ref type="bibr" target="#b3">[Devlin et al., 2019]</ref> as its inner LM. The impact of choices for LMs will be discussed in Section 4.4.</p><p>TaxoPrompt first leverages a prompting function <ref type="bibr">[Schick and Sch?tze, 2021]</ref> to modify an input query concept c into a base prompt P (c). As shown in Figure <ref type="figure" target="#fig_1">2</ref>, the function applies a template with two slots: "What is parent-of [X]? It is <ref type="bibr">[MASK]</ref>." and fills slot [X] with the name of input concept c:</p><formula xml:id="formula_2">P (c) = What is parent-of c? It's [MASK].</formula><p>Then, TaxoPrompt feeds the prompt into the LM for word tokenization using algorithm like WordPiece <ref type="bibr">[Schuster and Nakajima, 2012]</ref> and gets a prompt sentence s with n tokens: where t 1:i is the left-to-right context for masked positions and t j:n is the opposite. Finally, the LM is applied for parallel masked positions prediction by calculating the conditional probability distribution <ref type="bibr" target="#b6">[Jiang et al., 2020]</ref>:</p><formula xml:id="formula_3">s = t 1 , t 2 , . . . , t i , ?mask? 1 , . . . , ?mask? |L| , t j , . . . , t n , (2) What is parent-of data migration? It is [MASK]. It is [MASK]. data migration is the process of selecting, preparing, extracting,??? It is [MASK]. data migration parent-of</formula><formula xml:id="formula_4">tk = argmax t ? k ?V P (t ? k | t 1 , . . . , t k-1 , t k+1 , . . . , t n , ?) , (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where t ? k indicates the generated token for k-th position in Eq.( <ref type="formula">2</ref>), and t 1:k-1 , t k+1:n are surrounding tokens which can either be words or mask tokens. P (?, ?) can be measured with logit scores :</p><formula xml:id="formula_6">O = LayerNorm(?(HD T )) L = OM T ,<label>(4)</label></formula><p>where H ? R n?h is the output of last multi-head selfattention layer and h represents the hidden size. D ? R h?h and M ? R |V|?h are learnable projection matrices. ? represents the activation function. L ? R n?|V| equals to the logits scores, and we denote L(k, t) as the logit score of token t at k-th position of the prompt sentence s. Thus, Eq.( <ref type="formula" target="#formula_4">3</ref>) is equivalent to:</p><formula xml:id="formula_7">tk = argmax t ? k ?V L(k, t ? k ),<label>(5)</label></formula><p>after |L| times prediction, the token list L is generated.</p><p>Discussion.</p><p>We believe that our prompt-based hypernym generation method is sufficient to perform lexical-syntactic reasoning for two reasons: (1) Lexical-syntactic features <ref type="bibr" target="#b15">[Yu et al., 2020]</ref> are shown to LMs through tokenization algorithm <ref type="bibr">[Liu et al., 2021b]</ref> ; (2) LMs have acquired semantic meanings and contextual relations of tokens after pre-trained on a large corpus <ref type="bibr" target="#b14">[Takeoka et al., 2021]</ref>. Prompt learning can make better use of existing knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Knowledgeable Context Construction</head><p>We note that no right-to-left context is available for masked positions in Eq.( <ref type="formula">2</ref>), which underutilizes the powerful bidirectional MLM task. Besides, task-specific knowledge like Taxonomic Context structure knowledge is also very important to the expansion task. In this section, we introduce an approach to infuse knowledge into the LM by attaching knowledgeable contexts to the base prompt. Taxonomic Context. Previous approaches focus on modeling the local substructure of taxonomies like ego-nets <ref type="bibr" target="#b13">[Shen et al., 2020]</ref>, mini-paths <ref type="bibr" target="#b15">[Yu et al., 2020]</ref> and ego-trees <ref type="bibr" target="#b14">[Wang et al., 2021]</ref>. In contrast, we model the global structure of taxonomies by the following steps: First, we define a list of relation tokens R, where R = {parent-of, child-of, siblingof, nephew-of, posterity-of}. Then, we design a three-stage random walk algorithm: (1) Selecting a random relation r i from R, where i indicates the i-th walk.</p><formula xml:id="formula_8">??? ??? ??? ??? ???</formula><p>(2) Choosing a concept u i randomly from the set consisting of concepts that hold relation r i with u i-1 , where u i-1 is the last concept in current path. (3) Attaching r i and u i to the tail of current path.</p><p>After ? times random walk, we serialize the taxonomy into a walked path named taxonomic context (shown in Figure <ref type="figure" target="#fig_3">3</ref>):</p><formula xml:id="formula_9">W(c) = c, r 1 , u 1 , r 2 , . . . , u i-1 , r i , u i . . . , u ?-1 , r ? , u ? ,<label>(6)</label></formula><p>where W(c) denotes one taxonomic context for a query concept c ? N 0 and ? is a hyperparameter. Finally, we concatenate ? taxonomic contexts to construct the full taxonomic context W ? (c). Suppose the query concept is "Data Migration", a possible taxonomic context could be "Data Migration parent-of Data Reduction nephew-of Machine Learning" with ? = 2, ? = 1. After seeing all taxonomic contexts, the LM learns the global structure knowledge of taxonomy by capturing hierarchical information and understanding relations between local structures. Descriptive Context. Corpora resources like Wikipedia summary <ref type="bibr">[Liu et al., 2021b]</ref> and WordNet definition <ref type="bibr" target="#b14">[Wang et al., 2021]</ref> have been proved to imply the target is-a relation. We denote the description of a query concept c as D (c). <ref type="bibr" target="#b4">[He et al., 2020]</ref> has demonstrated that the LM can be complemented by D (c) since the LM learns to summarize the main attributes from the description:</p><formula xml:id="formula_10">D (c) LM --? {a 1 , a 2 , . . . , a n }</formula><p>where a i is one summarized attribute of concept c. In this way, the LM builds a deeper understanding of concept semantics. Finally, our prompt function of the query node c</p><p>during training is formulated as:</p><formula xml:id="formula_11">P (c) [SEP ]D (c) , P (c) [SEP ]W ? (c) (7)</formula><p>and the former prompt is applied during inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning and Inference</head><p>Training Data Construction. Given one edge ?u, c? from the existing taxonomy T 0 = N 0 , E 0 , we first construct prompt for query concept c using the prompt function in Eq.( <ref type="formula">7</ref>). Then we generate the prompt sentence s in Eq.( <ref type="formula">2</ref>) by feeding the prompt to the LM tokenizer. Answer token list L gold is constructed by tokenizing the parent node u. Notice that the number of masked tokens in s equals to |L gold |.</p><p>Finally, one training instance X = ?s, L gold ? corresponds to the edge ?u, c? is created. By repeating the above process for each edge in T 0 , we obtain the full training dataset</p><formula xml:id="formula_12">X = {X 1 , X 2 , . . . , X |E 0 | }.</formula><p>Model Training. We adopt cross entropy loss as the main training objective:</p><formula xml:id="formula_13">L(?) = - 1 |X| Xi?X ? ? t * k ?L gold log exp (L (k, t * k )) t?V exp (L (k, t)) ? ? , (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>where t * k represents the ground truth token at the k-th position of s and L is logit scores defined in Eq.( <ref type="formula" target="#formula_6">4</ref>). The above equation is also known as MLM loss.</p><p>Inference. During inference, for each new concept c ? C and an candidate concept u ? N 0 , we construct a prompt sentence s without taxonomic context and calculate their match score by the average logit score:</p><formula xml:id="formula_15">score (u, c) = 1 |L u | ?i?Lu L (k, ? i ) ,<label>(9)</label></formula><p>where L u = tokenize (u) and ? i represents i-th token in L u . k-th position of s is the i-th mask token, where ? i is supposed to be filled in.</p><p>Complexity Analysis. The time complexity of training is</p><formula xml:id="formula_16">O(I ? |E 0 | ? l 2 avg ? d)</formula><p>, where I is the number of iterations, l avg is the average length of input sentence for the LM and d is the dimension of embedding. We infuse global structure knowledge into the LM to distinguish similar positions instead of negative sampling, making it possible to train efficiently. The time complexity of inference is O(|C| ? l 2 avg ? d), where |C| is the total number of new concepts, while the time complexity of the previous transformer-based methods <ref type="bibr">[Liu et al., 2021b;</ref><ref type="bibr" target="#b14">Wang et al., 2021]</ref> </p><formula xml:id="formula_17">is O(|C| 2 ? l 2 avg ? d).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate the performance of our proposed method TaxoPrompt. Our experiments are designed to answer the following research questions (RQs):  <ref type="table" target="#tab_1">1</ref>.</p><p>Low-resource Taxonomies. Following previous work <ref type="bibr" target="#b15">[Yu et al., 2020;</ref><ref type="bibr">Liu et al., 2021b;</ref><ref type="bibr" target="#b14">Wang et al., 2021]</ref>, we evaluate our TaxoPrompt on three benchmark taxonomies from SemEval-2016 Task 13 <ref type="bibr" target="#b0">[Bordea et al., 2016]</ref>. We experiment on three English datasets from different domains: environment, science, and food. We follow <ref type="bibr" target="#b14">[Wang et al., 2021]</ref> and exclude 20% nodes in each dataset, of which ten nodes are separated as the validation set and the rest as the test set.</p><p>Large-scale Taxonomies. Following previous work <ref type="bibr" target="#b13">[Shen et al., 2020;</ref><ref type="bibr" target="#b16">Zhang et al., 2021;</ref><ref type="bibr">Ma et al., 2021]</ref>, we further evaluate our model on four large-scale real-world taxonomies from Microsoft Academic Graph (MAG) <ref type="bibr" target="#b14">[Sinha et al., 2015]</ref> and WordNet <ref type="bibr" target="#b7">[Jurgens and Pilehvar, 2016]</ref>. We randomly sample 1,000 leaf nodes for each dataset as the test set and another 1,000 leaves as the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>TaxoPrompt ranks all candidate hypernyms by calculating the score in Eq.( <ref type="formula" target="#formula_15">9</ref>) during testing. Given n query nodes, we denote their ground truth hypernyms as { ?1 , ?2 , . . . , ?n } and the predicted hypernyms as {u 1 , u 2 , . . . , u n } for lowresource benchmarks. Following prior works <ref type="bibr" target="#b15">[Yu et al., 2020;</ref><ref type="bibr" target="#b13">Shen et al., 2020;</ref><ref type="bibr">Liu et al., 2021b;</ref><ref type="bibr" target="#b14">Wang et al., 2021]</ref>, we adopt the following metrics:</p><p>(1) Accuracy (Acc) measures the times when the predicted hypernym exactly equals to the ground truth: Table <ref type="table">2</ref>: Overall experimental results on low-resource datasets (in %). We report our performance using the average of three runs. Note that we highlight the best results and underline the second best.</p><formula xml:id="formula_18">Acc = 1 n n i=1 (u i = ?i )<label>(</label></formula><p>(3) Wu &amp; Palmer similarity (Wu&amp;P) represents the semantic similarity between the prediction and the ground truth:</p><formula xml:id="formula_19">Wu&amp;P = 1 n n i=1 2 |u ? ?i | |u i | + |? i | ,</formula><p>where | ? | indicates the depth of a concept in the taxonomy and u i ? ?i is the last concept in the intersection of the paths from root to the u i and ?i <ref type="bibr">[Liu et al., 2021b]</ref>.</p><p>For large taxonomies, we adopt the F1 score to evaluate the performance of automatical taxonomies expansion since these taxonomies are DAG-structured rather than treestructured, i.e., a single node may have multiple parents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines Comparison</head><p>We compare TaxoPrompt with the following baseline taxonomy expansion methods:</p><p>? BERT+MLP adopts the pre-trained concept embeddings from BERT and leverages a Multi-Layer Perceptron (MLP) for the is-a relations identification. The experimental results are from <ref type="bibr" target="#b15">[Yu et al., 2020</ref>]. ? TaxoExpan <ref type="bibr" target="#b13">[Shen et al., 2020]</ref> incorporates hierarchical positional information by adopting position-enhanced graph neural networks (GNN). It trains a log-bilinear model to identify a candidate concept. ? STEAM <ref type="bibr" target="#b15">[Yu et al., 2020]</ref> solves the taxonomy expansion by learning to insert query concepts into mini-paths with a multi-view co-training procedure. ? TMN <ref type="bibr" target="#b16">[Zhang et al., 2021]</ref> leverages auxiliary and primal signals based on the neural tensor network and regulates concept embeddings via the channel-wise gating mechanism.</p><p>? TEMP <ref type="bibr">[Liu et al., 2021b]</ref> relies on the pre-trained contextual encoder as its core and preserves taxonomical structure information in taxonomy-paths. ? HEF [Wang et al., 2021] models the taxonomy with the ego-tree structure to exploit the hierarchical information for taxonomies coherence maintenance. ? HyperExpan <ref type="bibr">[Ma et al., 2021]</ref> preserves taxonomical structure information in a hyperbolic space. It leverages a hyperbolic graph neural network (HGNN) for encoding concept embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>We use BERT base (uncased) in experiments. The optimizer is AdamW <ref type="bibr" target="#b11">[Loshchilov and Hutter, 2019]</ref> with a learning rate of 1e-5. For length ? and times ? of random walk, we set them as 6 and 5 for best performance after the extensive search. We set the batch size to 6 and train the model with 15 epochs. For descriptive context construction, we follow previous work to leverage Wikipedia summary <ref type="bibr">[Liu et al., 2021b]</ref> and Word-Net definition <ref type="bibr" target="#b14">[Wang et al., 2021]</ref>. We use Wikipedia summary for Environment, MAG-CS/PSY, and WordNet definition for WordNet-Noun/Verb. For the rest datasets, we combine Wikipedia summary and WordNet definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison (RQ1)</head><p>Table <ref type="table">2</ref> presents overall experimental results on three lowresource taxonomies and Table <ref type="table" target="#tab_3">3</ref> shows the F1 results on four large taxonomies. We have the following observations: First, BERT+MLP performs the worst since pre-trained language models are not designed for word-level representations, and such representations provide little contextual information. TaxoExpan propagates the neighborhood information into embeddings via graph neural networks and consistently outperforms the BERT+MLP.</p><p>Second, STEAM further improves the performance of Tax-oExpan by leveraging mini-paths for hierarchical information capture. TMN formulates the anchor position as a candidate hypernym and hyponym pair, and such a local path structure has been proven effective for leaf expansion.</p><p>Third, transformer-based methods like TEMP and HEF achieve state-of-the-art performance and outperform previous methods with a large margin. Their success can be attributed to the better structural information capture and contextual relation extract in the fine-tuning paradigm.</p><p>TaxoPrompt consistently outperforms all the baselines on three low-resource benchmarks. Specifically, TaxoPrompt improves state-of-the-arts by 3.7%, 1.5%, and 2.8% for Acc, MRR, and Wu&amp;P on average, confirming the effectiveness of the prompt tuning paradigm for the hypernym generation. Improvement on MRR and Wu&amp;P shows that TaxoPrompt tends to rank the ground truth high and predict semantically similar answers for query concepts. Such improvement relies on that TaxoPrompt can better leverage knowledge in LMs and exploit the structure information of taxonomies compared with all baselines. Finally, results from Table <ref type="table" target="#tab_3">3</ref> show that TaxoPrompt automatically expands the four large taxonomies better than the state-of-the-art method HyperExpan. We find TaxoPrompt improves HyperExpan vastly on taxonomies with deeper depth and high-quality descriptive contexts. This observation further demonstrates the ability of TaxoPrompt to better leverage both semantical and structural knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Studies (RQ2)</head><p>We conduct experiments on the science dataset for ablation studies and have the following observations:</p><p>As shown in Table <ref type="table" target="#tab_4">4</ref>, both descriptive context and taxonomic context contribute to TaxoPrompt (lines 1-4). Compared with line 1, we find Acc, MRR, and Wu&amp;P drop 3.9%, 2.6%, and 2.3% respectively in line 4 without the structure knowledge infused by taxonomic context. To further explore the impact of taxonomic context on distinguishing similar concepts, we replace it with negative sampling in line 5 and train the model with margin ranking loss as in <ref type="bibr">[Liu et al., 2021b]</ref>. The results show that our proposed taxonomic context can lead the LM to distinguish negative answers better.</p><p>We further study whether the taxonomic context learns global structure instead of local by restricting random walking areas. In line 6, we forbid nodes from walking to their siblings or uncles, and the constructed taxonomic context is downgraded to separate paths like mini-paths <ref type="bibr" target="#b15">[Yu et al., 2020]</ref> or taxonomy-paths <ref type="bibr">[Liu et al., 2021b]</ref>. The Acc, MRR, and Wu&amp;P results go down to 59.2%, 68.0%, and 83.5% since the model fails to capture relations between these paths for global structure learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Prompt Discussion (RQ3)</head><p>In this section, we discuss the impact of the prompt template and language models on the taxonomy expansion task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Template</head><p>Acc MRR Wu&amp;P  We initialize them using albert-base-v2, roberta-base, electra-smalldiscriminator and distilbert-base-uncased.</p><p>The Effect of Prompt Template. Table <ref type="table" target="#tab_5">5</ref> shows the experimental results on science dataset using different prompt templates. Designing an appropriate template for the taxonomy expansion task is essential as the Acc difference between the worst and the best template comes to 4.4%. An effective template will help LMs better exploit task-specific knowledge. Besides, prompt tuning can consistently benefit Wu&amp;P under different templates.</p><p>The Effect of Language Models. The choice of language models is another key problem for prompt tuning. As shown in Figure <ref type="figure" target="#fig_4">4</ref>, DistillBERT <ref type="bibr" target="#b12">[Sanh et al., 2019]</ref> achieves the similar performance with BERT. We find that the pre-trained knowledge stored in BERT essentially improves the performance of the hypernym generation. Besides, RoBERTa <ref type="bibr" target="#b9">[Liu et al., 2019</ref>] also has remarkable power on the hypernym generation since it exploits dynamic masking for pre-training. We observe that ELECTRA <ref type="bibr" target="#b2">[Clark et al., 2020]</ref> fails to achieve the best performance as it did in the fine-tuning solution <ref type="bibr">[Liu et al., 2021b]</ref>. One possible reason can be that ELECTRA is pre-trained with the discriminative replaced token detection (RTD) task instead of the MLM task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We propose TaxoPrompt to solve taxonomy expansion efficiently by prompt tuning. TaxoPrompt utilizes a random walk algorithm to capture the global structure of taxonomies and infuses structure knowledge into the LM via taxonomic context. Experimental results show that TaxoPrompt outperforms state-of-the-art methods. Further ablation studies demonstrate the effectiveness of our key designs. In future work, we plan to study the relationship between taxonomic context and negative sampling under the prompt tuning paradigm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of the prompt-based hypernym generation. The grey box (right) shows the example of attaching the new concept "Data Migration" to the existing "Computer Science" taxonomy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A pipeline of the hypernym generation. The left box shows the construction process of the prompt sentences (note that LTR is short for Left-To-Right context, and RTL is the opposite.), and the right box illustrates the function of LMs (the dashed arrows indicate the correspondence, [S] represents the possible answer set).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An illustration of the proposed random walk algorithm for one taxonomic context construction. Note that circles represent concept nodes, and squares represent walks of different relations. The dash lines indicate hypernym-hyponym relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Results of different language models over science dataset. We initialize them using albert-base-v2, roberta-base, electra-smalldiscriminator and distilbert-base-uncased.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset Statistics. |N | and |E| are the number of nodes and edges in the existing taxonomy. |D| indicates the taxonomy depth.</figDesc><table><row><cell>Dataset</cell><cell>|N |</cell><cell>|E|</cell><cell>|D|</cell></row><row><cell>Environment</cell><cell>261</cell><cell>261</cell><cell>6</cell></row><row><cell>Science</cell><cell>429</cell><cell>452</cell><cell>8</cell></row><row><cell>Food</cell><cell>1,486</cell><cell>1,576</cell><cell>8</cell></row><row><cell>MAG-CS</cell><cell cols="2">24,754 42,329</cell><cell>6</cell></row><row><cell>MAG-PSY</cell><cell cols="2">23,187 30,041</cell><cell>6</cell></row><row><cell cols="4">WordNet-Verb 13,936 13,408 13</cell></row><row><cell cols="4">WordNet-Noun 83,073 76,812 20</cell></row><row><cell cols="4">? RQ2: How do different components (i.e., base prompt,</cell></row><row><cell cols="4">descriptive context, and taxonomic context) affect Taxo-</cell></row><row><cell>Prompt?</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">? RQ3: What is the impact of different prompt designs</cell></row><row><cell cols="4">(i.e., choice of language models and design of prompt</cell></row><row><cell>template)?</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">4.1 Experimental Setups</cell><cell></cell><cell></cell></row></table><note><p><p><p>? RQ1: How does TaxoPrompt model perform compared with state-of-the-art taxonomy expansion methods?</p>Datasets</p>We evaluate our model on different benchmarks. The statistics of each dataset are shown in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results of the F1 score on four large datasets (in %). Results of baselines come from[Ma et al., 2021].</figDesc><table><row><cell>Methods</cell><cell cols="2">Verb Noun PSY</cell><cell>CS</cell></row><row><cell>TaxoExpan</cell><cell cols="3">12.40 19.90 29.46 19.67</cell></row><row><cell>TMN</cell><cell cols="3">14.00 20.90 29.11 19.81</cell></row><row><cell cols="4">HyperExpan 15.00 24.15 32.47 19.92</cell></row><row><cell cols="4">TaxoPrompt 25.39 41.44 33.12 21.88</cell></row><row><cell># Setting</cell><cell></cell><cell cols="2">Acc MRR Wu&amp;P</cell></row><row><cell>1 TaxoPrompt</cell><cell></cell><cell cols="2">61.4 68.7 85.6</cell></row><row><cell cols="2">2 w/o two contexts</cell><cell cols="2">45.6 54.4 76.2</cell></row><row><cell cols="4">3 w/o descriptive context 50.0 57.0 76.9</cell></row><row><cell cols="4">4 w/o taxonomic context 57.5 66.1 83.3</cell></row><row><cell cols="4">5 #4 + negative sampling 58.7 68.3 84.7</cell></row><row><cell cols="2">6 #1 -sibling -nephew</cell><cell cols="2">59.2 68.0 83.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ablation studies on science dataset (in %). "w/o" means "without".</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>[X], [MASK]. 58.8 68.3 84.9 [X] is a [MASK]. 57.9 67.8 83.2 [MASK], such as [X]. 57.0 66.4 83.0 What's parent-of [X]?It's [MASK]. 61.4 68.7 85.6 Impact of different prompt templates on science dataset (in %).</figDesc><table><row><cell>1.0</cell><cell>ALBERT</cell><cell></cell></row><row><cell></cell><cell>ELECTRA</cell><cell></cell></row><row><cell>0.8</cell><cell>DistilBERT</cell><cell></cell></row><row><cell></cell><cell>RoBERTa</cell><cell></cell></row><row><cell></cell><cell>BERT</cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Acc</cell><cell>MRR</cell><cell>Wu&amp;P</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is supported by <rs type="funder">Chinese Scientific and Technical Innovation</rs> Project <rs type="grantNumber">2030</rs> (No.<rs type="grantNumber">2018AAA0102100</rs>), <rs type="funder">National Natural Science Foundation of China</rs> (No.<rs type="grantNumber">U1936206</rs>, <rs type="grantNumber">62077031</rs>). We thank the reviewers for their constructive comments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MjyKJ68">
					<idno type="grant-number">2030</idno>
				</org>
				<org type="funding" xml:id="_4Vq8VUC">
					<idno type="grant-number">2018AAA0102100</idno>
				</org>
				<org type="funding" xml:id="_pKwQ8WF">
					<idno type="grant-number">U1936206</idno>
				</org>
				<org type="funding" xml:id="_UccRAam">
					<idno type="grant-number">62077031</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 13: Taxonomy extraction evaluation (texeval-2)</title>
		<author>
			<persName><surname>Bordea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Georgeta Bordea, Els Lefever, and Paul Buitelaar</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1081" to="1091" />
		</imprint>
	</monogr>
	<note>SemEval-2016</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Graph representation learning: a survey</title>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AP-SIPA</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ELECTRA: pre-training text encoders as discriminators rather than generators</title>
		<author>
			<persName><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Infusing disease knowledge into BERT for health question answering, medical inference and disease name recognition</title>
		<author>
			<persName><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="4604" to="4614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Taxonomy-aware multi-hop reasoning networks for sequential recommendation</title>
		<author>
			<persName><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="573" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">X-FACTR: multilingual factual knowledge retrieval from pretrained language models</title>
		<author>
			<persName><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="5943" to="5959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 14: Semantic taxonomy enrichment</title>
		<author>
			<persName><forename type="first">Pilehvar</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pilehvar</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval-2016</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1092" to="1102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Txtract: Taxonomy-aware knowledge extraction for thousands of product categories</title>
		<author>
			<persName><surname>Karamanolakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="8489" to="8502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.13586</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2021</date>
			<biblScope unit="page" from="3854" to="3863" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>TEMP: taxonomy expansion with dynamic margin loss through taxonomy-paths</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hyperexpan: Taxonomy expansion with hyperbolic representation learning</title>
		<author>
			<persName><forename type="first">Hutter</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<publisher>Maximilian Nickel and Douwe Kiela</publisher>
			<date type="published" when="2017">2019. 2019. 2021. 2021. 2020. 2017. 2017</date>
			<biblScope unit="page" from="6338" to="6347" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><surname>Sanh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01108</idno>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<meeting><address><addrLine>Nakajima</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2019. 2019. 2021. 2012. 2012</date>
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>EACL</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Taxoexpan: Selfsupervised taxonomy expansion with position-enhanced graph neural network</title>
		<author>
			<persName><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2018">2018. 2018. 2020. 2020</date>
			<biblScope unit="page" from="486" to="497" />
		</imprint>
	</monogr>
	<note>WWW</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enquire one&apos;s parent and child before decision: Fully exploit hierarchical structure for selfsupervised taxonomy expansion</title>
		<author>
			<persName><surname>Sinha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.03682</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015">2015. 2015. 2021. 2021. 2021. 2017. 2017</date>
			<biblScope unit="page" from="3111" to="3118" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Enhancing taxonomy completion with concept generation via fusing relational representations</title>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020">2020. 2020. 2021. 2021</date>
			<biblScope unit="page" from="2104" to="2113" />
		</imprint>
	</monogr>
	<note>KDD</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Taxonomy completion via triplet matching network</title>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="4662" to="4670" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
