<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Experimental study on population-based incremental learning algorithms for dynamic optimization problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-04-22">22 April 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shengxiang</forename><surname>Yang</surname></persName>
							<email>s.yang@mcs.le.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Ae</forename><forename type="middle">Xin</forename><surname>Yao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">X</forename><surname>Yao</surname></persName>
							<email>x.yao@cs.bham.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Leicester</orgName>
								<address>
									<addrLine>University Road</addrLine>
									<postCode>LE1 7RH</postCode>
									<settlement>Leicester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Birmingham Edgbaston</orgName>
								<address>
									<postCode>B15 2TT</postCode>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Experimental study on population-based incremental learning algorithms for dynamic optimization problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-04-22">22 April 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">1BB1D2EBF527243C36B06319C212625A</idno>
					<idno type="DOI">10.1007/s00500-004-0422-3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Evolutionary algorithms have been widely used for stationary optimization problems. However, the environments of real world problems are often dynamic. This seriously challenges traditional evolutionary algorithms. In this paper, the application of populationbased incremental learning (PBIL) algorithms, a class of evolutionary algorithms, for dynamic problems is investigated. Inspired by the complementarity mechanism in nature a Dual PBIL is proposed, which operates on two probability vectors that are dual to each other with respect to the central point in the genotype space. A diversity maintaining technique of combining the central probability vector into PBIL is also proposed to improve PBIL's adaptability in dynamic environments. In this paper, a new dynamic problem generator that can create required dynamics from any binary-encoded stationary problem is also formalized. Using this generator, a series of dynamic problems were systematically constructed from several benchmark stationary problems and an experimental study was carried out to compare the performance of several PBIL algorithms and two variants of standard genetic algorithm. Based on the experimental results, we carried out algorithm performance analysis regarding the weakness and strength of studied PBIL algorithms and identified several potential improvements to PBIL for dynamic optimization problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a class of meta-heuristic algorithms, evolutionary algorithms (EAs) make use of principles of natural selection and population genetics. Due to the robust capability of finding solutions to difficult problems, EAs have become the optimization and search techniques of choice for many applications. Especially, they are widely applied for solving stationary optimization problems where the fitness landscape does not change during the course of computation <ref type="bibr" target="#b12">[13]</ref>. However, the environments of real world optimization problems are often dynamic, where the problem fitness landscape changes over time. For example, in scheduling problems the scheduling demands and available resources may change over time. This forms a serious challenge to traditional EAs since they cannot adapt well to a changed environment once converged.</p><p>In recent years, there is a growing interest in the research of applying EAs for dynamic optimization problems since many of the problems that EAs are being used to solve are known to vary over time <ref type="bibr">[1,</ref><ref type="bibr" target="#b21">22]</ref>. Usually the dynamic environment requires EAs to maintain sufficient diversity for a continuous adaptation to the changing landscape. Researchers have developed many approaches into EAs to address this problem. Branke <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> has grouped them into four categories: (1) increasing diversity after a change, such as the hypermutation scheme <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref>; (2) maintaining diversity throughout the run, such as the random immigrants scheme <ref type="bibr" target="#b14">[15]</ref>; (3) memory-based methods, such as the diploidy and multiploidy approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref>; and (4) multi-population approaches <ref type="bibr" target="#b5">[6]</ref>.</p><p>In this paper, we investigate the application of a class of EAs, population-based incremental learning (PBIL) algorithms, for solving dynamic optimization problems. We study the effect of introducing several approaches into PBIL to address dynamic optimization problems, such as the multi-population and random immigrants methods. Inspired by the complementarity mechanism broadly existing in nature, we propose a Dual PBIL that operates on two probability vectors that are dual to each other with respect to the central point in the search space. To address the convergence problem, we also introduce a diversity maintaining technique, similar to the random immigrants method for GAs, into PBIL to improve its adaptability under dynamic environments.</p><p>In this paper, we also formalize a new dynamic problem generator, first applied in <ref type="bibr" target="#b29">[30]</ref>, which can generate required dynamics from a given stationary problem. Using this generator, we systematically construct a series of dynamic problems from two benchmark and one real-word stationary problems and carry out an experimental study comparing the investigated PBILs and two variants of standard genetic algorithm. Based on the analysis of the experimental results, we identify the weakness and strength of the studied PBILs and discuss some improvements to PBIL for dynamic optimization problems.</p><p>The rest of this paper is organized as follows. The next section briefly reviews some existing dynamic problem generators and presents the new dynamic problem generator. Section 3 details several algorithms investigated in this paper including our proposed Dual PBIL. Section 4 describes the test environment for this study, including the stationary test suite and related dynamic problems. The basic experimental results and relevant analysis are presented in Sect. 5. In Sect. 6, we investigate the introduction of a diversity maintaining probability vector into PBIL for dynamic optimization problems. Finally we conclude this paper in Sect. <ref type="bibr" target="#b6">7</ref> and give out discussions on future work in Sect. 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dynamic problem generators</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Review of existing generators</head><p>Over the past few years, in order to study the performance of EAs for dynamic optimization problems researchers have developed a number of dynamic problem generators to create dynamic test environments. Generally speaking, these generators can be roughly divided into two types. The first type of constructing dynamic environments is quite simple. The environment is just switched between two or more stationary problems (or states of a problem). For example, many researchers have tested their algorithms on a time varying knapsack problem where the total weight capacity of the knapsack changes over time, usually oscillating between two or more fixed values <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26]</ref>. Cobb and Grefenstette <ref type="bibr" target="#b9">[10]</ref> constructed a significantly changing environment that oscillates between two different fitness landscapes. For this type of generators, the dynamics of environmental change is mainly characterized by the speed of change. It can be fast or slow relative to EA time and is usually measured in EA generations.</p><p>The second type of dynamic problem generators starts from a predefined fitness landscape, usually constructed in n-dimensional real space <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28]</ref>. This stationary landscape is composed of a number of component landscapes (e.g., cones), each of which can change independently. Each component has its own morphology with such parameters as peak height, peak slope and peak location. And the center of the peak with the highest height is taken as the optimum solution of the landscape. For example, Morrison and De Jong's generator <ref type="bibr" target="#b22">[23]</ref>, called DF1, defines the basic landscape in n-dimensional real space as follows:</p><formula xml:id="formula_0">f ðxÞ ¼ max i¼1;...;m H i À R i Â ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi X n j¼1 x j À X ij À Á 2 r !<label>ð1Þ</label></formula><p>where x=(x 1 , ..., x n ) is a point in the landscape, m specifies the number of cones in the environment, and each cone i is independently specified by its height H i , its slope R i , and its center X i =(X i1 , ..., X in ). These independently specified cones are blended together by the max function. Based on this stationary landscape, dynamic problems can be created through changing the parameters of each component. With respect to how to change a parameter, there may be a variety of properties. For example, one property of the dynamics of environmental change is related to the magnitude or step size of change for each parameter. It may be large or small. Another dynamics property is related to the speed of change, which can be slow or fast.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A new dynamic problem generator</head><p>In this paper, we formalize a new dynamic problem generator that can generate dynamic test problems from any binary encoded stationary problem. Given a stationary problem f(x) (x2{0, 1} l where l is the chromosome length), we can construct dynamic landscape from it as follows: we first create a binary mask M2{0, 1} l , randomly or in a controlled way, periodically or not.</p><p>When evaluating an individual x in the population, we first perform the operation x ¯M on it, where ''¯'' is the bitwise exclusive-or (XOR) operator (i.e., 1 ¯1=0, 1 ¯0=1, 0 ¯0=0). The resulting individual is then evaluated to obtain a fitness value for the individual x. Suppose that the change happens at generation t, then we have f(x, t+1)= f(x ¯M).</p><p>In this way, we can revolve the fitness landscape but still keep certain properties of the original fitness landscape, e.g., the total number of optima and fitness values of optima though their locations are shifted. For example, if we apply a template M=1111 to Whitley's 4-bit deceptive function (to be described in Sect. 4.1), the original optimal point x * =1111 becomes sub-optimal while the original deceptive solution x=0000 becomes the new optimal point in the changed landscape, but the optimal fitness value (i.e., 30) and the uniqueness of optimum keep invariant.</p><p>With the new dynamic problem generator, the dynamics of environmental change can be characterized by two parameters: the speed of change and the magnitude or degree of change in the sense of Hamming distance. As for other generators, the first parameter can be measured in EA generations. In this paper it will be referred to as the environmental change period, denoted by s, and is defined as the number of EA generations between two changes. With respect to the degree of change, it can be measured by the ratio of ones in the mask M, denoted by q. The more ones in the mask, the severer the change and the bigger the challenge to EAs. When q=0.0, the problem stays stationary. When q=1.0, it brings in the extreme or heaviest fitness landscape change in the sense of Hamming distance, analogous to natural environmental change between sunny daytime and dark night.</p><p>Putting things together, we can generate dynamic problems from a stationary problem as follows. Suppose that the environment is periodically changed every s generations the dynamics can be formulated as follows:</p><formula xml:id="formula_1">f ðx; tÞ ¼ f ðx È MðkÞÞ<label>ð2Þ</label></formula><p>where k=Øt/sø is the period index, t is the generation counter, and M(k) is the XORing mask for period k.</p><p>And given a value for parameter q, M(k) can be incrementally generated as follows:</p><formula xml:id="formula_2">MðkÞ ¼ Mðk À 1Þ È TðkÞ ð<label>3Þ</label></formula><p>where T(k) is an intermediate binary template randomly created for period k containing q• l ones. For the first period k=1, M(1) is initialized to be a zero vector.</p><p>Comparing with other generators, the new dynamic problem generator has the following properties.</p><p>-It is genotype-based. That is, it operates on the problem genotype instead of phenotype. Hence, we can carry out theoretical analysis more thoroughly in the genotype space. -It is easy to realize required dynamics. We can not only test the speed of environmental change by tuning the parameter s, but also test the degree of environmental change by tuning the parameter q easily. -With this generator we can study the performance of algorithms on the dynamic version of many well studied benchmark problems in EA's community. For example, the royal road <ref type="bibr" target="#b20">[21]</ref> and deceptive <ref type="bibr" target="#b28">[29]</ref> functions are selected as test problems in this paper. -It can be easily combined with other dynamic problem generators to generate required dynamic environments.</p><p>3 Description of algorithms investigated</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Population-based incremental learning</head><p>The population-based incremental learning algorithm, first proposed by Baluja <ref type="bibr" target="#b2">[3]</ref>, is a combination of evolu-tionary optimization and competitive learning. PBIL has proved to be very successful on numerous benchmark and real-world problems <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19]</ref>. Theoretical work on PBILs has also been carried out <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>The aim of PBIL is to generate a real valued probability vector which, when sampled, creates high quality solutions with high probability. PBIL starts from an initial probability vector with values of each entry set to 0.5. 1 This means when sampling by this initial probability vector random solutions are created because the probability of generating a 1 or 0 on each locus is equal. However, as the search progresses, the values in the probability vector are gradually learnt towards values representing high evaluation solutions. The evolution process is described as follows.</p><p>At each iteration, a set of samples (solutions) are created according to the current probability vector. <ref type="foot" target="#foot_0">2</ref> The set of samples are evaluated according to the problemspecific fitness function. Then the probability vector is learnt (pushed) towards the solution(s) with the highest fitness. The distance the probability vector is pushed depends on the learning rate parameter. After the probability vector is updated, a new set of solutions is generated by sampling from the new probability vector and this cycle is repeated. As the search progresses, the entries in the probability vector move away from their initial settings of 0.5 towards either 0.0 or 1.0. The search progress stops when some termination condition is satisfied, e.g., the maximum allowable number of iterations t max is reached or the probability vector is converged to either 0.0 or 1.0 for each bit position.</p><p>The pseudocode for the PBIL investigated in this paper is shown in Fig. <ref type="figure">1</ref>. Within this PBIL, at iteration t a set S t of n=120 solutions are sampled from the probability vector P t and only the best solution B t from the set S t is used to learn the probability vector P t . The learning rate a is set to a commonly used value 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parallel PBIL</head><p>Using multi-population instead of one population has proved to be a good approach for improving the performance of EAs for dynamic optimization problems. Similarly, multi-population can be introduced into PBIL by using multiple probability vectors <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref>. Each probability vector is sampled to generate solutions independently, and is learnt according to the best solu-1 For the convenience of description in this paper we will call the probability vector that has 0.5 for all of its entries central probability vector or just central vector because it represents the central point in the genotype space. tion(s) generated by itself. For the sake of simplicity, in this paper we investigate a PBIL with two parallel probability vectors, called Parallel PBIL (PPBIL2). The pseudocode for PPBIL2 is shown in Fig. <ref type="figure">2</ref>.</p><p>Within PPBIL2, one of the two probability vectors P 1 is initialized to the central probability vector (for the sake of performance comparison with the PBIL) and the other P 2 is randomly initialized. P 1 and P 2 are sampled and updated independently. Initially P 1 and P 2 have an equal sample size. However, in order to give the probability vector that performs better more chance to generate samples, the sample sizes of the probability vectors are slightly adapted within the range of [n min , n max ]= [0.2• n, 0.8• n]= <ref type="bibr" target="#b23">[24,</ref><ref type="bibr">96]</ref> according to their relative performance. If one probability vector outperforms the other, its sample size is increased by a constant value D=0.05• n=6 while the other's sample size is decreased by D; otherwise, if the two probability vectors tie, there is no change to the sample sizes. The learning rate for both P 1 and P 2 is the same as that for the PBIL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dual PBIL</head><p>Dualism and complementarity are quite common in nature. For example, in biology the DNA molecule consists of two complementary strands that are twisted together into a duplex chain. Inspired by the complementarity mechanism in nature, a primal-dual genetic algorithm has been proposed and applied for dynamic optimization problems <ref type="bibr" target="#b29">[30]</ref>. In this paper we investigate the application of dualism into PBIL and propose a Dual PBIL, denoted DPBIL2. For the convenience of description, we first introduce the definition of dual probability vector here. Given a probability vector P=(P[1], ..., P[l])2I=[0.0, 1.0] l of fixed length l, its dual probability vector is defined as P¢=dual(P)=(P¢[1], ..., P¢[l])2I where P¢[i]=1.0-P[i](i=1, ..., l). That is, a probability vector's dual probability vector is the one that is symmetric to it with respect to the central probability vector. With this definition, DPBIL2 consists of a pair of probability vectors that are dual to each other. The pseudocode of DPBIL2 is given in Fig. <ref type="figure">3</ref>.</p><p>From Figs. 2 and 3 it can be seen that DPBIL2 differs from PPBIL2 only in the definition of the probability vector P 2 and the learning mechanism. The other aspects of DPBIL2, such as the sampling mechanism, the sample size updating mechanism, and relevant parameters, are the same as those of PPBIL2. Within DPBIL2 P 2 is now defined to be the dual probability vector of P 1 . As the search progresses only P 1 is learnt from the best generated solution since P 2 changes with P 1 automatically. If the best overall solution is sampled by</p><formula xml:id="formula_3">P 1 t (i.e., f(B 1 t ) ‡ f(B 2 t )) then P 1 t is updated towards B 1 t ; otherwise, P 1 t is updated away from B 2</formula><p>t , the best solution created by P 2 t . The reason to P 1 t learning away from B 2 t lies in that it is equivalent to P 2 t learning towards B 2 t . The motivation of introducing a dual probability vector into PBIL lies in two aspects: increasing diversity of generated samples and fighting significant environmental changes. On the first aspect, usually with the progress of parallel PBILs the probability vectors will converge towards each other and the diversity of generated samples is reduced. This situation doesn't occur with dual probability vectors. On the second aspect, when the environment is subject to significant changes the dual probability vector is expected to generate high evaluation solutions and hence improve PBIL's adaptability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Standard genetic algorithm</head><p>Genetic algorithms (GAs) are one kind of well studied evolutionary algorithms. The standard genetic algorithm maintains a population of individuals, usually encoded as fixed length binary strings. The initial population is randomly created. New populations are created through a process of selection, recombination (crossover) and mutation. At each generation, the fitness of each individual in the population is calculated according to the problem-specific evaluation function. Then the individuals are probabilistically selected from the current population based on their fitness to generate a mating pool, which is called selection for reproduction. Afterwards, the recombination and mutation operators are applied to some or all individuals in the mating pool. The recombination operator randomly combines parts of two ''parents'' that are randomly selected from the mating pool to produce two ''offsprings''. And the mutation operator randomly flips each bit of a string with a small probability p m to create a new string. This process continues until some termination condition is satisfied, e.g., the maximum allowable number of generations t max is reached <ref type="bibr" target="#b17">[18]</ref>. Usually with the iteration of the GA, the average fitness of the population will progressively improve due to the selective pressure applied through the process. The best individual in the final population should be a highly evolved solution to the given problem.</p><p>Genetic algorithms are closely related to PBILs. In fact PBIL is an abstraction of the GA that explicitly maintains the statistics contained in GA's population <ref type="bibr" target="#b3">[4]</ref>. In this study, one variant of the standard GA (SGA), as shown in Fig. <ref type="figure">4</ref>, is taken as a peer EA to compare the performance of PBILs for dynamic optimization problems. The peer SGA has the following typical genetic operator and parameter settings: generational, uniform crossover with a crossover probability p c =0.6, traditional bit mutation with a mutation probability p m =0.01, and fitness proportionate selection with the stochastic universal sampling (SUS) <ref type="bibr" target="#b1">[2]</ref> scheme. There is no elitist scheme used in the SGA and the population size n is set to 120.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Algorithm test environments</head><p>In order to compare different PBILs and SGA, a set of well studied stationary problems, including one GA-easy royal road function, one GA-hard deceptive function, and one real world knapsack problem, is selected as the test suite. A series of dynamic optimization problems are constructed from these stationary problems using the dynamic problem generator described in Sect. 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Stationary test problems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Knapsack problem</head><p>The knapsack problem is a well known NP-complete combinatorial optimization problem. The problem is to select from a set of items with varying weights and profits those items that will yield the maximal summed profit to fill in the knapsack without exceeding its limited weight capacity. Given a set of m items and a knapsack, the 0-1 knapsack problem can be described as follows:</p><formula xml:id="formula_4">max pðxÞ ¼ X m i¼1 p i x i<label>ð4Þ</label></formula><p>subject to the weight constraint</p><formula xml:id="formula_5">X m i¼1 w i x i 6C<label>ð5Þ</label></formula><p>where x=(x 1 ... x m ), x i is 0 or 1, w i and p i are the weight and profit of item i respectively, and C is the capacity of the knapsack. If x i =1, the ith item is selected. In this paper, a knapsack problem with 100 items using strongly correlated sets of randomly generated data is constructed as follows:</p><formula xml:id="formula_6">w i ¼ uniformly random integer ½1; 50 ð<label>6Þ</label></formula><formula xml:id="formula_7">p i ¼ w i þ uniformly random integer ½1; 5 ð<label>7Þ</label></formula><formula xml:id="formula_8">C ¼ 0:6 Â X 100 i¼1 w i<label>ð8Þ</label></formula><p>And given a solution x, its fitness f(x) is evaluated as follows. If the sum of the item weights is within the capacity of the knapsack, the sum of the profits of the selected items is used as the fitness. If the solution selects too many items such that the summed weight exceeds the capacity of the knapsack, the solution is judged by how much it exceeds the knapsack capacity (the less, the better) and its fitness is evaluated to be the difference between the total weight of all items and the weight of selected items, multiplied by a small constant 10 À10 to ensure that the solutions that overfill the knapsack are not competitive with those which do not. Together, the fitness of a solution x is evaluated as follows: That is, the royal road function is defined as follows:</p><formula xml:id="formula_9">f</formula><formula xml:id="formula_10">f ðxÞ ¼ X 8 i¼1 c i d i ðxÞ ð<label>10Þ</label></formula><p>where d i (x)={1, if x2s i ; 0, otherwise}. This function has an optimum fitness of 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Deceptive function</head><p>Deceptive functions are devised as difficult test functions for GAs. They are a family of functions where there exist low-order building blocks that do not combine to form higher-order building blocks: instead they form building blocks resulting in a solution, called deceptive attractor <ref type="bibr" target="#b28">[29]</ref>, which is sub-optimal itself or near a sub-optimal solution. It is even claimed that the only challenging problems for GAs are problems that involve some degree of deception. Based on an algorithm of constructing fully deceptive functions, Whitley <ref type="bibr" target="#b28">[29]</ref>  In this study, we construct a deceptive function consisting of 30 copies of Whitley's 4-bit fully deceptive function (order-4 subproblem). This function has an optimum fitness of 900 and a representation of 120 bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constructing dynamic test environments</head><p>In this paper, we construct dynamic test environments from above stationary problems in the following way. The fitness landscape of each stationary problem is periodically changed every s generations during the run of algorithms. Based on our preliminary experiments on the stationary problems (see Sect. 5.2), s is set to 10, 100 and 200 respectively to create three dynamic problems with respect to this parameter only. The environmental change speed parameter s is set to these values because on the stationary problems all algorithms are sort of consistently on different search stages at generations of these values. For example, on the stationary problems almost all algorithms are at quite early searching stage at generation 10, at medium searching stage at generation 100, and at late stage or converged at generation 200. By setting s to these values we can test each algorithm's capability of adapting to dynamic environment under different degree of convergence (or searching stage).</p><p>In order to test the effect of another dynamics parameter, the degree of environmental change, on the performance of algorithms, the value of q is set to 0.05, 0.2, 0.4, 0.6, 0.8, and 0.95 respectively for each run of an algorithm on a problem. These values represent different environmental change levels, from very light shifting (q=0.05) to medium variation (q=0.2, 0.4, 0.6, 0.8) to significant change (q=0.95). In order to study the behavior of algorithms in randomly changing environment we also set q to be a random number uniformly distributed in [0.01, 0.99], i.e., q=rand(0.01, 0.99).</p><p>Totally, we systematically construct a series of 21 dynamic problems, three values of s combined with seven values of q, from each stationary test problem. The environmental dynamics parameter settings are summarized in Table <ref type="table" target="#tab_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental design</head><p>Experiments were carried out to compare the performance of PBILs as well as the SGA on the test environments constructed above. In addition to the above described PBILs, we also test the effect of the re-start scheme on the performance of PBIL in dynamic environments. A complete re-start of EAs after a change in the environment has occurred is the simplest option to maintain diversity in the population and react to changes in the environment. However, it is not always possible to detect a change and do a re-start deliberately. In this study, for the sake of algorithm performance comparison we also investigate the PBIL with an ideal re-start scheme, called PBILr, where whenever the environment changes the PBIL is re-started from scratch. That is, with PBILc all elements in the probability vector is reset to 0.5 whenever the environment changes.</p><p>For each experiment of combining different algorithm and test problem (no matter stationary or dynamic), 50 independent runs were executed with the same set of 50 random seeds. For each run of different algorithm on each problem, the best-of-generation fitness was recorded every generation. And for each run of an algorithm on a dynamic problem, ten periods of environmental changes are allowed. <ref type="foot" target="#foot_1">3</ref>The overall performance of an algorithm on a problem is measured by the mean best-of-generation fitness. It is defined as the best-of-generation fitness averaged across the number of total runs and then averaged over the data gathering period. More formally this is:</p><formula xml:id="formula_11">F BG ¼ 1 G X G i¼1 1 N X N j¼1 F BG ij !<label>ð11Þ</label></formula><p>where F BG is the mean best-of-generation fitness, G is the number of generations which is equivalent to ten periods of environmental changes (i.e., G=10•s), n=50 is the total number of runs, and F BG ij is the best-ofgeneration fitness of generation i of run j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental results on stationary problems</head><p>In order to help analyze the experimental results on dynamic problems later on in this paper, preliminary experiments were carried out on the stationary test problems. For each run of different algorithm on each problem the maximum allowable number of generations was set to 200. The preliminary experimental results are shown in Fig. <ref type="figure" target="#fig_2">5</ref> where the data were averaged over 50 runs. From Fig. <ref type="figure" target="#fig_2">5</ref>, it can be seen that in general all PBILs outperform SGA. This result is consistent with other researchers' study <ref type="bibr" target="#b3">[4]</ref>. On the knapsack and royal road problems PBIL outperforms PPBIL2 and DPBIL2 while PPBIL2 performs as well as DPBIL2. This result shows that on stationary problems introducing extra probability vector may not be beneficial because the existence of an extra probability vector that performs worse may slow down the learning speed of the other probability vector that performs better. However, on the deceptive function the situation seems quite different. PBIL and PPBIL2 performs equally well while both are beaten by DPBIL2 during late searching stage. This happens because the deceptive attractor x=00 ... 0 in this function strongly draws the probability vectors of PBIL and PPBIL2 towards its trap. The existence of the dual probability vector in DPBIL2 slows down the process of trapping, and after about 140 generations when the fitness level 840 of the deceptive attractor is reached, the dual probability vector helps escaping the local optimum and pushes the searching towards the global optimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental results on dynamic problems</head><p>The experimental results on dynamic problems and some key statistical test results are summarized in Table 2 and Table <ref type="table" target="#tab_4">3</ref> respectively. The experimental results are also plotted in Fig. <ref type="figure" target="#fig_3">6</ref>, where the environmental dynamics setting can be indexed according to Table <ref type="table" target="#tab_2">1</ref>.</p><p>From Table <ref type="table" target="#tab_3">2</ref>, Table <ref type="table" target="#tab_4">3</ref> and Fig. <ref type="figure" target="#fig_3">6</ref> several results can be observed.</p><p>First, the performance of PBILr increases with the value of s but doesnot change much with the value of q. This is easy to understand. Given the perfect re-start scheme, each time the environment changes PBILr is in fact starting from the same initial state to search the equivalent problem regardless of the changing degree, i.e., the value of q. And with the increasing of s PBILr has more time to search solutions with higher fitness before the next change.</p><p>PBILr outperforms other algorithms in many dynamic problems, especially when the environment changes slowly (and hence convergence becomes a problem). This is due to the maximum diversity the restart scheme introduces into the population. However, in slightly changing environments (q=0.05) PBILr is beaten by other PBILs in many cases due to the lack of information transfer from the last generation of the last dynamic period. Since it is usually not possible to detect environmental change timely and perform the re-start scheme immediately when the environment changes, we will exclude PBILr in following algorithm performance comparison and analysis.</p><p>Second, from Fig. <ref type="figure" target="#fig_3">6</ref> it is easy to see that for each fixed s DPBIL2 outperforms other algorithms (even including PBILr) on most of the dynamic problems when the environment is subject to significant changes, e.g., when q is set to 0.95. In fact, from Table <ref type="table" target="#tab_4">3</ref> it can be seen that when q=0.95, DPBIL2 statistically significantly outperforms PBIL and PPBIL2 on all dynamic problems and SGA on all dynamic knapsack and deceptive functions. This result confirms our expectation of introducing the dual probability vector into DPBIL2. When the environment suffers significant changes, the dual probability vector takes effect quickly to adapt DPBIL2 to the changed environment. This effect on DPBIL2 also takes place when q is set to 0.6 and 0.8. DPBIL2 still statistically significantly outperforms PBIL and PPBIL2 on most dynamic problems when q equals 0.6 and 0.8 and SGA on most dynamic knapsack problems and deceptive functions when q=0.8.</p><p>Third, PBIL is now beaten by both PPBIL2 and DPBIL2 on most dynamic problems except when the value of q is small. When q is small, the dynamic problems are close to their corresponding stationary problems. For stationary (and nearly stationary) problems introducing an extra probability vector may not be beneficial, which has been verified in our preliminary experiments in Sect. 5.2 (see Fig. <ref type="figure" target="#fig_2">5</ref>). However, when the value of q increases the introduction of an extra probability vector helps improving PBIL's performance. Fourth, as opposed to stationary problems, SGA now outperforms PBILs on many dynamic problems, especially when the value of s is large. This happens because when s is large the algorithms are given more time to search before the next environmental change and hence they are more likely to converge. Convergence   deprives PBILs of the adaptability to changing environments. However, the mutation mechanism embedded in SGA gives it more diversity than PBILs and hence better adaptability to environmental changes. Hence, SGA outperforms PBILs in many dynamic problems. It seems that SGA performs much better on dynamic royal road functions than on dynamic knapsack prob-lems and dynamic deceptive functions when the value of s is large. The reason lies in the intrinsic characteristics of the royal road function where there exists a big gap with respect to the fitness levels of its component building block. Only when all ones appear in a building block it will contribute 8 to the whole fitness, otherwise for all other cases it will contribute 0. This makes the effect of the mutation scheme in SGA more significant on dynamic royal road functions.</p><formula xml:id="formula_12">+ + + + + + À À À À À À À + À À À + + $ DPBIL2 -PBIL À À À + + + + À À À À $ + $ À À À $ + + $ DPBIL2 -PPBIL2 $ À À $ + + + À À $ $ + + $ À À À À + + À PPBIL2 -PBIL À À À $ À $ $ $ $ $ $ À $ $ $ $ $ + + + + PBILr -PBIL À À $ + + + + À À À $ $ À À À À À + $ À À PBILr -PPBIL2 À À + + + + + À À $ $ $ À À À À À $ $ À À PBILr -DPPBIL2 À À + + + À + À À $ + $ À À À À $ + À À À s=100,</formula><p>Fifth, given a value of s when the environment changes randomly with respect to the changing severity, i.e., q=rand(0.01, 0.99), the performance of algorithms is similar to the situation of setting q to medium values, e.g., 0.4 or 0.6. This fits well with the fact that the expected value of rand(0.01, 0.99) is about 0.5. It is also notable that when q=rand(0.01, 0.99), DPBIL2 still significantly outperforms PBIL and PPBIL2 on most dynamic problems and SGA on several cases. This happens because the dual probability vector inside DPBIL2 improves its adaptability if by chance the environment is subject to significant changes, i.e., q is randomly set to a big value.</p><p>Finally, from Fig. <ref type="figure" target="#fig_3">6</ref> an interesting result that can be seen is that for each fixed s with the increasing of the value of q (excluding the random situation) DPBIL2 performs consistently across the three series of dynamic problems (knapsack, royal road and deceptive). When q increases from 0.05 to 0.2, 0.4, 0.6, 0.8 to 0.95 the performance curve of DPBIL2 looks like a big ''U''. PBIL and PPBIL2 have this performance curve on dynamic royal road and deceptive functions, while on the dynamic knapsack problems they have the performance curve of ''falling stone''. SGA has a ''falling stone'' performance curve on almost all dynamic problems. The reason to this observation lies in the intrinsic characteristics of the problems and will be further explained below.</p><p>In order to better understand the experimental results, we need to have a deeper look into the dynamic behavior of different algorithms. The dynamic behavior of different algorithms with respect to best-of-generation fitness against generations on the three series of dynamic problems is shown in Figs. <ref type="figure">7,</ref><ref type="figure" target="#fig_4">8</ref>, and 9 respectively, where the data were averaged over 50 runs. In these figures s is set to 10 (left column) and 200 (right column) respectively, and q is set to 0.05, 0.4, and 0.95 from top row to bottom row respectively. From these figures it can be easily observed that for PBILr on all dynamic problems its dynamic behavior for each dynamic period is almost the same as that for the stationary period.</p><p>For DPBIL2 on all dynamic problems the dynamic performance drops heavier and heavier when the value of q increases from 0.05 to 0.4. However, when q=0.8 (not shown in Fig. <ref type="figure">7</ref>) and 0.95 the situation is different. Now, when s=10 its performance rises instead of drops with the increment of dynamic periods due to less convergence and high adaptability brought in by the dual probability vector, while when s=200 with the increment of dynamic periods DPBIL2's performance maintains almost the same on dynamic knapsack problems or For both values of s whenever the environment changes the dual probability vector adapts DPBIL2 quickly to the new environment. This stops its performance from significant drop for dynamic periods. All in all, this results in DPBIL2's big ''U'' performance curve on all the dynamic problems.</p><p>For PBIL and PPBIL2, generally speaking, when the value of q increases from 0.05 to 0.4 their dynamic performance drops heavier and heavier on all dynamic problems, which is similar to DPBIL2's dynamic per-formance. However, when q=0.95 their dynamic performance is different from DPBIL2's. When q=0.95, the dynamic behavior of PBIL and PPBIL2 is sort of switching between odd and even environmental periods. They start from a harsher state for even environmental periods than for odd environmental periods. The reason to this lies in that after the stationary period for the following odd period the environment is in fact greatly returned or repeated from previous odd period given q=0.95. Hence at the start of odd environmental periods the performance of PBIL and PPBIL2 doesnot drop Fig. <ref type="figure">7</ref> Dynamic behavior of algorithms on dynamic knapsack problems. The environmental dynamics parameter s is set to 10 (Left Column) and 200 (Right Column) respectively and q is set to 0.05, 0.4, and 0.95 from top to bottom row respectively as heavy as it does at the start of even periods. This benefits the whole performance of PBIL and PPBIL2 and also results in the big ''U'' overall performance curve for them on dynamic royal road and deceptive functions. However, the inside mechanism is that PBIL and PPBIL2 are sort of waiting for the return of previously well sought environment, which is totally different from DPBIL2 where the high performance is achieved by rapid adaptation to the newly changed environment. On dynamic knapsack problems, PBIL and PPBIL2 do not have the big ''U'' overall performance curve because their performance drops too much during the start of even environmental periods to be compensated by the benefit gained during odd periods.</p><p>In order to better understand the above discussion, in Fig. <ref type="figure">10</ref> we present extra experimental results with the extreme environmental dynamics of q=1.0 and s=200 on the dynamic problems. From Fig. <ref type="figure">10</ref> it can be clearly seen that when the environment changes DPBIL2 immediately adapts to the new environment while PBIL and PPBIL2 switch between two states: one low fitness state of even environmental periods where PBIL and PPBIL2 are poorly searching or in fact waiting for the return of their previously adapted For SGA the mutation scheme gives it certain learning capacity in dynamic environments. Hence, its average performance for each dynamic period does not drop too heavily with the growing of dynamic periods. However, when the environment undergoes severer and severer changes, i.e., when the value of q changes from 0.05 to 0.95, SGA faces harsher and harsher starting points when the environment changes. Hence, the performance of SGA degrades consistently with the increasing of q and SGA does not have a big ''U'' performance curve on most dynamic optimization problems.</p><p>6 Introducing the central probability vector</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Modified algorithms</head><p>One major problem for EAs to solve dynamic optimization problems is due to the convergence of population or probability vector. Once converged, the EA loses the To address this problem, Grefenstette <ref type="bibr" target="#b14">[15]</ref> introduced the random immigrants approach into GAs where in every generation the population is partly replaced by randomly created individuals (random immigrants). Since the approach only replaces a small ratio, e.g. 10%, of the population, it introduces diversity without disrupting the ongoing search progress greatly.</p><p>In this paper, incorporating a similar technique into PBILs is also investigated. The idea is to introduce the central probability vector into PBIL since from it random solutions can be sampled. We add a central prob-ability vector into PBIL, PPBIL2, and DPBIL2 and call the obtained algorithms PBILc, PPBIL3, and DPBIL3 respectively. The pseudocodes for PBILc, PPBIL3, and DPBIL3 are shown in Fig. <ref type="figure">11</ref>, 12, and 13 respectively.</p><p>Within PBILc, PPBIL3, and DPBIL3, we set the sample size of the central probability vector to a small constant value, 0.1• n, in order to limit its effect on the algorithm as a whole. The sampling mechanism is the same as that in PPBIL2 and DPBIL2. The probability vectors are independently sampled to generate their own set of solutions. However, the central probability vector doesn't change or learn over time. Within PPBIL3 the other two probability vectors learn from the best solution generated by themselves independently. However, if the best solution generated by the central probability vector is better than their best solution, they learn from that solution. Within PBILc and DPBIL3, the learning mechanism is a little different. As in DPBIL2 only the first probability vector P 1 learns. In PBILc, if P 1 's best sample B 1 has higher fitness than P 2 's best sample B 2 , P 1 will learn towards B 1 ; otherwise, P 1 will learn towards B 2 . In DPBIL3 if P 1 's best sample B 1 has the overall highest fitness, P 1 will learn towards B 1 ; if P 3 's best sample B 3 has higher fitness than both P 1 's and P 2 's, P 1 will learn towards B 3 ; otherwise, if f(B 2 ) &gt; f(B 1 ) and f(B 2 ) ‡ f(B 3 ), P 1 will learn away from B 2 .</p><p>As in PPBIL2 and DPBIL2, within PPBIL3 and DPBIL3 the sample size of the two varying probability vectors is initialized to an equal value and is slightly adapted by a constant value D=6 within the range of In order to compare the effect of introducing the central probability vector into PBILs with the random immigrants technique in GAs one variant of SGA, called RIGA, which combines the random immigrants technique within SGA is also studied as a peer algorithm. RIGA differs from SGA only in that when the population has undergone the crossover and mutation operations and just before it is put to evaluation, a subset of randomly selected individuals (10% of the population) is replaced by randomly created individuals. Then the population is evaluated and put to next evolution cycle. The genetic operators and relevant parameter settings for RIGA are all the same as those for SGA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental results</head><p>The experimental settings for RIGA, PBILc, PPBIL3 and DPBIL3 are the same as previous settings. The experimental results are shown in Fig. <ref type="figure" target="#fig_8">14</ref> (where the environmental parameter setting is indexed the same way by Table <ref type="table" target="#tab_2">1</ref>) and Table <ref type="table" target="#tab_6">4</ref>. Some key statistical test results are given in Table <ref type="table" target="#tab_7">5</ref>. From Tables 4, Table <ref type="table" target="#tab_7">5</ref> and Fig. <ref type="figure" target="#fig_8">14</ref> the following results can be observed.</p><p>First, generally speaking PBILc, PPBIL3, and DPBIL3 outperform their peers PBIL, PPBIL2, and DPBIL2 respectively, especially when the environmental dynamics parameter s is large and q is set to medium values of 0.4 and 0.6 or rand(0.01, 0.99). When s=10, the effect of introducing the central probability vector is not significant in many cases or is negative in some cases. This is because convergence is not very serious when the environment changes quickly. When q is set to medium values, PBILc, PPBIL3, and DPBIL3 achieve statistically significantly better performance over their peers respectively, see Table <ref type="table" target="#tab_7">5</ref> for the t-test results with respect to PBILc-PBIL, PPBIL3-PPBIL2, and DPBIL3-DPBIL2. This happens because the central probability vector works well under dynamic environments with medium degree of changes. In the genotype space with q set to a medium value each time when the environment changes an optimal solution is shifted about halfway away from its original point toward its complementary point in terms of Hamming distance, and falls into the very area represented by the central vector.</p><p>Second, both PPBIL3 and DPBIL3 now outperform RIGA on most dynamic knapsack and deceptive problems, see the t-test results with respect to PPBIL3-RIGA and DPBIL3-RIGA in Table <ref type="table" target="#tab_7">5</ref>. This result happens because the advantage of introducing diversity by the mutation mechanism in RIGA is now overrun by the effect of the central probability vector in PPBIL3 and DPBIL3. However, on dynamic royal road functions it seems that the central probability vector in PPBIL3 and DPBIL3 is not strong enough for them to beat RIGA.</p><p>Third, comparing PBILc with PPBIL2 and DPBIL2, from the t-test results in Table <ref type="table" target="#tab_7">5</ref> with respect to PBILc-PPBIL2 and PBILc-DPBIL2 it can be seen that when s is large PBILc significantly outperforms PPBIL2 on almost all dynamic problems and it outperforms DPBIL2 on most dynamic problems except when q is set to 0.95. This means when convergence becomes a problem, the central probability vector is more helpful than just an extra or dual probability vector. However, when the environment suffers significant changes, e.g., q=0.95, introducing the dual probability vector is more helpful than the central probability vector.</p><p>Finally, from Table <ref type="table" target="#tab_7">5</ref> an interesting and sort of confusing observation is that RIGA outperforms SGA on several dynamic royal road functions when q is set to medium values and on dynamic knapsack problems when s=10 and q=0.05 while it is beaten by SGA on most other dynamic problems. The reason lies in the interactive effect between SGA and the problems. According to our extra experimental results (not shown in this paper) decreasing the mutation probability p m in SGA from 0.01 to 0.001 increases SGA's performance on the stationary knapsack problem and deceptive function while decreasing its performance on the stationary royal road function. This means strengthening the mutation and hence the diversity may not be beneficial for the knapsack and deceptive problems. This also sort of explains that the effect of introducing random immigrants into SGA is problem-dependent.</p><p>Similarly, in order to better understand the effect of the central probability vector, we give the dynamic behavior of RIGA, PBILc, PPBIL2, DPBIL2, PPBIL3, and DPBIL3 with respect to best-of-generation fitness against generations on dynamic problems in Figs. <ref type="figure" target="#fig_9">15,</ref><ref type="figure"></ref> 16, and 17 respectively, where the value of s equals 200 and q equals 0.05, 0.4, and 0.95 from top to bottom row respectively. From these figures it can be seen that when q is small or large, the central probability vector does not help much. However, when q is set to medium values (e.g., 0.4), the performance of PBILc, PPBIL3 and DPBIL3 is greatly improved in comparison to their peers (the performance of PBIL is not shown) respec- tively during dynamic periods. The central probability vector stops their performance from significant dropping. From Figs. 15 and 17 it can also be seen that for RIGA due to the random immigrants scheme its performance is degraded heavily during the stationary period and hence the following dynamic periods on  + + + + + À + + + + + + À + À + + + + À + RIGA -SGA À À À À À À À À À $ + + + $ À À À À À À À</p><formula xml:id="formula_13">$ + + + + + $ $ $ $ $ $ $ $ $ $ $ À À $ DPBIL3 -DPBIL2 À À $ $ $ À $ $ $ $ $ $ À À $ À À À $ $ À PPBIL3 -RIGA + + + + + À + À À À À À À À + + $ $ $ + + DPBIL3 -RIGA + + + + + + + À À À À À À À + + À À + + $ PBILc -PBIL À $ $ + + + $ $ $ $ $ $ $ $ À À $ $ À À $ PBILc -PPBIL2 + + + + + + + $ $ $ $ $ $ $ $ À $ À À À À PBILc -DPBIL2 + + + + À À À + $ + + À À $ + + + $ À À À RIGA -SGA À À $ $ + + $ À $ + + + $ + À À À $ $ $ À s=100,</formula><p>The t-test result regarding Alg. 1-Alg. 2 is shown as ''+'', ''À'', or ''$'' when Alg. 1 is significantly better than, significantly worse than, or statistically equivalent to Alg. 2 respectively dynamic knapsack problems and dynamic deceptive functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper we investigate the application of PBIL algorithms for dynamic optimization problems. We study the effect of introducing several approaches, such as the re-start, multi-population, and random immigrants methods, from EA's community into PBIL to improve its performance in dynamic environments. Inspired by the complementarity mechanism broadly existing in nature, we propose a Dual PBIL that operates on a pair of probability vectors that are dual to each other with respect to the central point in the genotype space. In order to counterbalance the problem caused by the convergence of probability vectors, the central probability vector is also introduced into PBILs. This paper also formalizes a new dynamic problem generator that can generate required dynamics from any binary encoded stationary problem. This generator is genotype-based, easy to realize required dynamics, and From the experimental results, the following conclusions can be achieved on the tested dynamic problems.</p><p>First, on the stationary problems introducing extra probability vector into PBIL may not be beneficial.</p><p>Second, if it is feasible to timely detect environmental changes, the re-start scheme is a good choice for PBIL in dynamic environments, especially when the environment changes slowly and hence convergence becomes a problem. However, it is usually not possible to detect environmental changes timely, which greatly degrades the re-start scheme for PBIL in dynamic environments.</p><p>Third, when the environment is subject to significant changes in the sense of genotype space, introducing the dual probability vector into PBIL can achieve very high performance improvement.</p><p>Fourth, introducing the central probability vector can improve PBIL's performance under dynamic environments, especially when the environment is subject to medium degree of changes in the genotype space.</p><p>Finally, the effect of introducing the random immigrants scheme into SGA is problem dependent.</p><p>Generally speaking, the experimental results indicate that PBILs with dual and central probability vectors seem to be a good choice as EAs for dynamic problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Future work</head><p>This paper starts an interesting work on applying PBILs for dynamic optimization problems. Based on this paper there are several works to be carried out in the future.</p><p>First, PBILs investigated in this paper are relatively simple. It is an interesting work to investigate more mechanisms, such as mutation, population interaction schemes <ref type="bibr" target="#b3">[4]</ref>, and the hypermutation technique from EA's community into PBILs and compare their performance for dynamic optimization problems.</p><p>Second, it is also an interesting future work to extend the results in this paper to other estimation of distribution algorithms (EDAs) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b24">25]</ref>, of which PBILs are a sub-class, and compare obtained algorithms with other GAs or EAs for dynamic optimization problems.</p><p>Finally, based on the new dynamic problem generator it is an important work to carry out theoretical analysis of the performance of PBILs and other EAs for dynamic optimization problems, e.g., with respect to the environmental change speed and change severity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 Fig. 2</head><label>12</label><figDesc>Fig. 1 Pseudocode for the PBIL with one probability vector</figDesc><graphic coords="4,50.99,46.57,238.20,253.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 Fig. 3</head><label>43</label><figDesc>Fig. 4 Pseudocode for the standard GA (SGA)</figDesc><graphic coords="5,306.04,484.95,238.32,209.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Experimental results with respect to best-of-generation fitness against generations of algorithms on stationary problems: a Knapsack, b Royal road, and c Deceptive. The data were averaged over 50 runs</figDesc><graphic coords="8,55.45,46.57,229.32,503.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Experimental results of SGA, PBIL, PBILr, PPBIL2, and DPBIL2 with respect to mean best-of-generation fitness against different environmental dynamics parameter settings on dynamic problems: a Knapsack, b Royal road, and c Deceptive</figDesc><graphic coords="10,56.69,46.58,226.80,511.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8</head><label>8</label><figDesc>Fig. 8 Dynamic behavior of algorithms on dynamic royal road functions. The environmental dynamics parameter s is set to 10 (Left Column) and 200 (Right Column) respectively and q is set to 0.05, 0.4, and 0.95 from top to bottom row respectively</figDesc><graphic coords="12,62.36,46.58,473.04,485.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9</head><label>9</label><figDesc>Fig. 9 Dynamic behavior of algorithms on dynamic deceptive functions. The environmental dynamics parameter s is set to 10 (Left Column) and 200 (Right Column) respectively and q is set to 0.05, 0.4, and 0.95 from top to bottom row respectively</figDesc><graphic coords="13,62.36,46.58,472.32,485.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 Fig. 11</head><label>1011</label><figDesc>Fig. 10 Dynamic behavior of algorithms on dynamic problems: (Top) Knapsack, (Middle) royal road, and (Bottom) Deceptive. The environmental dynamics parameter s is set to 200 and q is set to 1.0</figDesc><graphic coords="14,56.69,46.57,226.80,471.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 12 Fig. 13</head><label>1213</label><figDesc>Fig. 12 Pseudocode for PPBIL3</figDesc><graphic coords="15,50.99,46.58,238.20,456.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 14</head><label>14</label><figDesc>Fig. 14 Experimental results of RIGA, PBILc, PPBIL3, and DPBIL3 with respect to mean best-of-generation fitness against different environmental dynamics parameter settings on dynamic problems: a Knapsack, b royal road, and c Deceptive</figDesc><graphic coords="16,56.69,46.58,226.80,512.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 15</head><label>15</label><figDesc>Fig. 15 Dynamic behavior of algorithms on dynamic knapsack problems. The environmental dynamics parameter s is set to 200 and q is set to 0.05, 0.4, and 0.95 from top to bottom respectively Fig. 16 Dynamic behavior of algorithms on dynamic royal road functions. The environmental dynamics parameter s is set to 200 and q is set to 0.05, 0.4, and 0.95 from top to bottom respectively</figDesc><graphic coords="18,56.69,46.58,226.80,478.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="19,56.69,46.58,226.80,478.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>) to the total fitness if all of the 8 bits are set to one. The fitness of a bit string x is computed by summing the coefficients c i corresponding to each of the given building blocks s i of which x is an instance (denoted by x2s i ).</figDesc><table><row><cell>ðxÞ ¼</cell><cell>(</cell><cell>P 100 i¼1 p i x i ; 10 À10 Â P 100 i¼1 w i À</cell><cell>i¼1 w i x i P 100</cell><cell>if ; else P 100 i¼1 w i x i 6C</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>ð9Þ</cell></row><row><cell cols="3">4.1.2 Royal road function</cell><cell></cell><cell></cell></row><row><cell cols="5">This function is the same as Mitchell, Forrest and</cell></row><row><cell cols="5">Holland's royal road function R1 [21]. It is defined on a</cell></row><row><cell cols="5">64 bit string consisting of eight contiguous building</cell></row><row><cell cols="5">blocks of 8 bits, each of which contributes c i =8 (i=1,</cell></row><row><cell>..., 8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>The index table for environmental dynamics parameter setting</figDesc><table><row><cell>s</cell><cell cols="5">Environmental dynamics index</cell><cell></cell><cell></cell></row><row><cell>10</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell></row><row><cell>100</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>14</cell></row><row><cell>200</cell><cell>15</cell><cell>16</cell><cell>17</cell><cell>18</cell><cell>19</cell><cell>20</cell><cell>21</cell></row><row><cell>qÞ</cell><cell>0.05</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>0.95</cell><cell>rand(0.01, 0.99)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Experimental results of SGA, PBIL, PBILr, PPBIL2, and DPBIL2 on dynamic problems with respect to overall mean best-ofgeneration fitness</figDesc><table><row><cell cols="2">Dynam-</cell><cell cols="2">Knapsack problem</cell><cell>Royal road function</cell><cell>Deceptive function</cell></row><row><cell>ics</cell><cell></cell><cell></cell><cell></cell></row><row><cell>s</cell><cell>q</cell><cell>SGA</cell><cell cols="2">PBIL PBILr PPBIL2 DPBIL2 SGA PBIL PBILr PPBIL2 DPBIL2 SGA PBIL PBILr PPBIL2 DPBIL2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Statistical comparison of algorithms on dynamic problems by one-tailed t-test with 98 degrees of freedom at a 0.05 level of significance</figDesc><table><row><cell>t-test result</cell><cell>Knapsack problem</cell><cell>Royal road function</cell><cell>Deceptive function</cell></row><row><cell>s=10, qÞ</cell><cell cols="3">0.05 0.2 0.4 0.6 0.8 0.95 rand 0.05 0.2 0.4 0.6 0.8 0.95 rand 0.05 0.2 0.4 0.6 0.8 0.95 rand</cell></row><row><cell>DPBIL2 -SGA</cell><cell>+</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Experimental results of RIGA, PBILc, PPBIL3, and DPBIL3 on dynamic problems with respect to overall mean best-ofgeneration fitness</figDesc><table><row><cell cols="2">Dynamics</cell><cell cols="2">Knapsack problem</cell><cell></cell><cell></cell><cell cols="3">Royal road function</cell><cell></cell><cell cols="3">Deceptive function</cell></row><row><cell>s</cell><cell>q</cell><cell>RIGA</cell><cell>PBILc</cell><cell cols="9">PPBIL3 DPBIL3 RIGA PBILc PPBIL3 DPBIL3 RIGA PBILc PPBIL3 DPBIL3</cell></row><row><cell>10</cell><cell>0.05</cell><cell cols="3">1,411.1 1,432.0 1,429.2</cell><cell>1,427.2</cell><cell>25.6</cell><cell>17.3</cell><cell>16.6</cell><cell>15.6</cell><cell>592.9</cell><cell>650.1</cell><cell>650.9</cell><cell>636.4</cell></row><row><cell>10</cell><cell>0.2</cell><cell cols="3">1,411.0 1,421.8 1,420.4</cell><cell>1,418.0</cell><cell>17.3</cell><cell>10.2</cell><cell>10.1</cell><cell>9.8</cell><cell>588.6</cell><cell>603.3</cell><cell>603.8</cell><cell>594.7</cell></row><row><cell>10</cell><cell>0.4</cell><cell cols="3">1,410.4 1,415.8 1,414.8</cell><cell>1,413.2</cell><cell>13.3</cell><cell>8.9</cell><cell>8.8</cell><cell>8.6</cell><cell>587.1</cell><cell>588.2</cell><cell>588.3</cell><cell>584.1</cell></row><row><cell>10</cell><cell>0.6</cell><cell cols="3">1,409.7 1,412.2 1,411.9</cell><cell>1,411.1</cell><cell>12.1</cell><cell>8.6</cell><cell>8.5</cell><cell>8.5</cell><cell>585.5</cell><cell>583.7</cell><cell>584.7</cell><cell>582.2</cell></row><row><cell>10</cell><cell>0.8</cell><cell cols="3">1,409.0 1,409.5 1,409.8</cell><cell>1,412.0</cell><cell>12.6</cell><cell>8.6</cell><cell>8.6</cell><cell>8.7</cell><cell>584.6</cell><cell>583.4</cell><cell>584.2</cell><cell>586.5</cell></row><row><cell>10</cell><cell>0.95</cell><cell cols="3">1,409.0 1,408.0 1,408.4</cell><cell>1,417.8</cell><cell>1,5.7</cell><cell>9.8</cell><cell>10.0</cell><cell>10.7</cell><cell>583.3</cell><cell>591.9</cell><cell>598.8</cell><cell>609.2</cell></row><row><cell>10</cell><cell cols="4">rand 1,409.8 1,412.8 1,412.8</cell><cell>1,413.5</cell><cell>13.7</cell><cell>8.9</cell><cell>8.9</cell><cell>8.7</cell><cell>585.7</cell><cell>586.7</cell><cell>589.7</cell><cell>586.9</cell></row><row><cell cols="2">100 0.05</cell><cell cols="3">1,411.1 1,459.3 1,458.1</cell><cell>1,457.3</cell><cell>44.2</cell><cell>26.3</cell><cell>27.4</cell><cell>25.1</cell><cell>595.6</cell><cell>780.2</cell><cell>781.5</cell><cell>771.7</cell></row><row><cell cols="2">100 0.2</cell><cell cols="3">1,411.1 1,442.3 1,442.8</cell><cell>1,439.5</cell><cell>35.4</cell><cell>17.5</cell><cell>20.1</cell><cell>16.5</cell><cell>595.1</cell><cell>697.3</cell><cell>712.9</cell><cell>691.9</cell></row><row><cell cols="2">100 0.4</cell><cell cols="3">1,411.0 1,433.6 1,433.6</cell><cell>1,429.6</cell><cell>28.3</cell><cell>14.8</cell><cell>17.0</cell><cell>13.8</cell><cell>594.6</cell><cell>697.0</cell><cell>702.9</cell><cell>688.1</cell></row><row><cell cols="2">100 0.6</cell><cell cols="3">1,411.1 1,427.1 1,428.2</cell><cell>1,428.0</cell><cell>25.0</cell><cell>13.5</cell><cell>16.1</cell><cell>13.5</cell><cell>593.9</cell><cell>690.3</cell><cell>693.2</cell><cell>688.3</cell></row><row><cell cols="2">100 0.8</cell><cell cols="3">1,411.0 1,421.8 1,423.8</cell><cell>1,439.3</cell><cell>23.8</cell><cell>14.3</cell><cell>16.7</cell><cell>15.8</cell><cell>594.1</cell><cell>703.7</cell><cell>711.5</cell><cell>689.2</cell></row><row><cell cols="2">100 0.95</cell><cell cols="3">1,410.8 1,418.9 1,421.4</cell><cell>1,455.6</cell><cell>23.9</cell><cell>15.9</cell><cell>18.2</cell><cell>23.9</cell><cell>593.7</cell><cell>742.2</cell><cell>752.5</cell><cell>754.4</cell></row><row><cell cols="5">100 rand 1,410.9 1,433.5 1,433.3</cell><cell>1,437.9</cell><cell>27.8</cell><cell>15.5</cell><cell>17.9</cell><cell>17.1</cell><cell>594.6</cell><cell>717.4</cell><cell>723.4</cell><cell>705.6</cell></row><row><cell cols="2">200 0.05</cell><cell cols="3">1,411.1 1,461.2 1,462.0</cell><cell>1,459.8</cell><cell>48.5</cell><cell>25.8</cell><cell>26.8</cell><cell>24.5</cell><cell>595.9</cell><cell>789.6</cell><cell>794.0</cell><cell>793.1</cell></row><row><cell cols="2">200 0.2</cell><cell cols="3">1,411.1 1,448.0 1,450.0</cell><cell>1,445.7</cell><cell>40.9</cell><cell>18.6</cell><cell>21.1</cell><cell>17.7</cell><cell>595.5</cell><cell>713.3</cell><cell>736.3</cell><cell>711.8</cell></row><row><cell cols="2">200 0.4</cell><cell cols="3">1,411.1 1,442.1 1,443.1</cell><cell>1,437.4</cell><cell>34.1</cell><cell>17.0</cell><cell>21.3</cell><cell>16.6</cell><cell>595.2</cell><cell>745.6</cell><cell>756.7</cell><cell>744.4</cell></row><row><cell cols="2">200 0.6</cell><cell cols="3">1,411.1 1,438.6 1,439.5</cell><cell>1,437.1</cell><cell>30.6</cell><cell>16.9</cell><cell>20.1</cell><cell>15.6</cell><cell>595.2</cell><cell>756.3</cell><cell>760.0</cell><cell>741.7</cell></row><row><cell cols="2">200 0.8</cell><cell>1410.9</cell><cell cols="2">1,434.4 1,436.5</cell><cell>1,446.3</cell><cell>29.1</cell><cell>17.0</cell><cell>20.1</cell><cell>17.4</cell><cell>594.8</cell><cell>749.0</cell><cell>764.8</cell><cell>712.0</cell></row><row><cell cols="2">200 0.95</cell><cell cols="3">1,411.1 1,432.0 1,435.2</cell><cell>1,459.8</cell><cell>28.2</cell><cell>17.9</cell><cell>19.9</cell><cell>25.6</cell><cell>594.7</cell><cell>763.9</cell><cell>773.5</cell><cell>782.9</cell></row><row><cell cols="5">200 rand 1,411.1 1,444.0 1,444.6</cell><cell>1,445.4</cell><cell>33.7</cell><cell>18.0</cell><cell>21.1</cell><cell>17.8</cell><cell>595.2</cell><cell>758.9</cell><cell>766.5</cell><cell>741.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Statistical comparison of algorithms on dynamic problems by one-tailed t-test with 98 degrees of freedom at a 0.05 level of significance</figDesc><table><row><cell>t-test Result</cell><cell>Knapsack problem</cell><cell>Royal road function</cell><cell>Deceptive function</cell></row><row><cell>s=10, qÞ</cell><cell cols="3">0.05 0.2 0.4 0.6 0.8 0.95 rand 0.05 0.2 0.4 0.6 0.8 0.95 rand 0.05 0.2 0.4 0.6 0.8 0.95 rand</cell></row><row><cell cols="2">PPBIL3 -PPBIL2 $</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>For each bit position of a solution, assuming binary encoded, if a random created real number in the range of [0.0, 1.0] is less than the probability value of corresponding element in the probability vector, the bit is set to 1 (or 0), otherwise it is set to 0 (or 1 respectively).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>For the convenience of analyzing experimental results on dynamic problems, we herein call the first period stationary since the behavior of an algorithm on a dynamic problem during this period is the same as that on the relevant stationary problem. And the other nine periods are called dynamic.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments The authors would like to thank Dr. Ju¨rgen Branke and the anonymous reviewers for their thoughtful suggestions and helpful comments. Shengxiang Yang was supported by UK EPSRC under Grant GR/S79718/01.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the behavior of evolutionary algorithms in dynamic fitness landscape</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ba¨ck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 IEEE international conference on evolutionary computation</title>
		<meeting>the 1998 IEEE international conference on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="446" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reducing bias and inefficiency in the selection algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on genetic algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstelle</surname></persName>
		</editor>
		<meeting>the 2nd international conference on genetic algorithms</meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="14" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Population-based incremental learning: a method for integrating genetic search based function optimi-Fig. 17 Dynamic behavior of algorithms on dynamic deceptive functions. The environmental dynamics parameter s is set to 200 and q is set to 0.05, 0.4, and 0.95 from top to bottom respectively zation and competitive learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
		<idno>CMU-CS-94- 163</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Removing the genetics from the standard genetic algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international conference on machine learning</title>
		<meeting>the 12th international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="38" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Memory enhanced evolutionary algorithms for changing optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 congress on evolutionary computation</title>
		<meeting>the 1999 congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1875" to="1882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A multipopulation approach to dynamic optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kaußler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schmeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adaptive computing in design and manufacturing</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evolutionary approaches to dynamic optimization problems-updated survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO Workshop on evolutionary algorithms for dynamic optimization problems</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="134" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Evolutionary optimization in dynamic environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Kluwer, Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An Investigation into the use of hypermutation as an adaptive operator in genetic algorithms having continuous, time-dependent nonstationary environments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Cobb</surname></persName>
		</author>
		<idno>AIC-90-001</idno>
		<imprint>
			<date type="published" when="1990">1990</date>
			<pubPlace>Washington</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Naval Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Genetic algorithms for tracking changing environments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Cobb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international conference on genetic algorithms</title>
		<meeting>the 5th international conference on genetic algorithms</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonstationary function optimization using the structured genetic algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on parallel problem solving from nature</title>
		<meeting>the 2nd international conference on parallel problem solving from nature</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="145" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonstationary function optimization using genetic algorithms with dominance and diploidy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on genetic algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstelle</surname></persName>
		</editor>
		<meeting>the 2nd international conference on genetic algorithms</meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization, and machine learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Analyzing the population based incremental learning algorithm by means of discrete dynamical systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gonza´lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Larran˜aga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="465" to="479" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Genetic algorithms for changing environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on parallel problem solving from nature</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Ma¨nner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Manderick</surname></persName>
		</editor>
		<meeting>the 2nd international conference on parallel problem solving from nature</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evolvability in dynamic fitness landscapes: a genetic algorithm approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 congress on evolutionary computation</title>
		<meeting>the 1999 congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2031" to="2038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards a theory of population-based incremental learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ho¨hfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE conference on evolutionary computation</title>
		<meeting>the 4th IEEE conference on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Estimation of distribution algorithms: a new tool for evolutionary computation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Larran˜aga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lozano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparison of dominance mechanisms and simple mutation on non-stationary problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ritchie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th int conf on parallel problem solving from nature</title>
		<meeting>the 5th int conf on parallel problem solving from nature</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="139" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The royal road for genetic algorithms: fitness landscapes and GA performance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st European conference on artificial life</title>
		<meeting>the 1st European conference on artificial life</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptation to changing environments by means of the memory based thermodynamical genetic algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th international conference on genetic algorithms</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Ba¨ck</surname></persName>
		</editor>
		<meeting>the 7th international conference on genetic algorithms</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A test problem generator for non-stationary environments</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 congress on evolutionary computation</title>
		<meeting>the 1999 congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2047" to="2053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Triggered hypermutation revisited</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 congress on evolutionary computation</title>
		<meeting>the 2000 congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1025" to="1032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From recombination of genes to the estimation of distributions I. Binary parameters</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mu¨hlenbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Paab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th international conference on parallel problem solving from nature</title>
		<editor>
			<persName><forename type="first">H-M</forename><surname>Voigt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Ebeling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<meeting>the 4th international conference on parallel problem solving from nature</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="178" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new diploid scheme and dominance change mechanism for non-stationary function optimisation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th international conference on genetic algorithms</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Eshelman</surname></persName>
		</editor>
		<meeting>the 6th international conference on genetic algorithms</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Function optimization using multiple-base population based incremental learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Servais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Jaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Greene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th South African workshop on pattern recognition</title>
		<meeting>the 8th South African workshop on pattern recognition</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evolutionary optimization in non-stationary environments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Trojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comp Sci Technol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="93" to="124" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fundamental principles of deception in genetic search</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Whitley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of genetic algorithms</title>
		<editor>
			<persName><forename type="first">Gje</forename><surname>Rawlins</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="221" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Non-stationary problem optimization using the primal-dual genetic algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 congress on evolutionary computation</title>
		<meeting>the 2003 congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2246" to="2253" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
