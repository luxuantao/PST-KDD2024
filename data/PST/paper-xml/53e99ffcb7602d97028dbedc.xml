<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Developing Niching Algorithms in Particle Swarm Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Xiaodong</forename><surname>Li</surname></persName>
							<email>xiaodong.li@rmit.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Developing Niching Algorithms in Particle Swarm Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F86C99315B9095E69E3D4B7C0887092B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Niching as an important technique for multimodal optimization has been used widely in the Evolutionary Computation research community. This chapter aims to provide a survey of some recent efforts in developing stateof-the-art PSO niching algorithms. The chapter first discusses some common issues and difficulties faced when using niching methods, then describe several existing PSO niching algorithms and how they combat these problems by taking advantages of the unique characteristics of PSO. This chapter will also describe a recently proposed lbest ring topology based niching PSO. Our experimental results suggest that this lbest niching PSO compares favourably against some existing PSO niching algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Stochastic optimization algorithms such as Evolutionary Algorithms (EAs) and more recently Particle Swarm Optimization (PSO) algorithms have shown to be effective and robust optimization methods for solving difficult optimization problems. The original and many existing forms of EAs and PSOs are usually designed for locating a single global solution. These algorithms typically converge to one final solution because of the global selection scheme used. However, many real-world problems are "multimodal" by nature, that is, multiple satisfactory solutions exist. For such an optimization problem, it might be desirable to locate all global optima and/or some local optima that are also considered as being satisfactory. Numerous techniques have been developed in the past for locating multiple optima (global or local). These techniques are commonly referred to as "niching" methods. A niching method can be incorporated into a standard EA to promote and maintain the formation of multiple stable subpopulations within a single population, with an aim to locate multiple optimal or suboptimal solutions. Niching methods are of great value even when the objective is to locate a single global optimum. Since a niching EA searches for multiple optima in parallel, the probability of getting trapped on a local optimum is reduced.</p><p>Niching methods have also been incorporated into PSO algorithms to enhance their ability to handle multimodal optimization problems. This chapter aims to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Niching Methods</head><p>Just like Evolutionary Algorithms themselves, the notion of niching is inspired by nature. In natural ecosystems, individual species must compete to survive by taking on different roles. Different species evolve to fill different niches (or subspaces) in the environment that can support different types of life. Instead of evolving a single population of individuals indifferently, natural ecosystems evolve different species (or subpopulations) to fill different niches. The terms species and niche are sometimes interchangeable. Niching methods were introduced to EAs to allow maintenance of a population of diverse individuals so that multiple optima within a single population can be located <ref type="bibr" target="#b25">[25]</ref>. One of the early niching methods was developed by De Jong in a scheme called crowding. In crowding, an offspring is compared to a small random sample taken from the current population, and the most similar individual in the sample is replaced. A parameter CF (crowding factor ) is commonly used to determine the size of the sample. The most widely used niching method is probably fitness sharing. The sharing concept was originally introduced by Holland <ref type="bibr" target="#b16">[16]</ref>, and then adopted by Goldberg and Richardson <ref type="bibr" target="#b14">[14]</ref> as a mechanism to divide the population into different subpopulations according to the similarity of the individuals in the population. Fitness sharing was inspired by the sharing concept observed in nature, where an individual has only limited resources that must be shared with other individuals occupying the same niche in the environment. A sharing function is often used to degrade an individual's fitness based on the presence of other neighbouring individuals. Although fitness sharing has proven to be a useful niching method, it has been shown that there is no easy task to set a proper value for the sharing radius parameter σ share in the sharing function without prior knowledge of the problems <ref type="bibr" target="#b13">[13]</ref>.</p><p>Apart from the above, many more niching methods have been developed over the years, including derating <ref type="bibr" target="#b0">[1]</ref>, deterministic crowding <ref type="bibr" target="#b24">[24]</ref>, restricted tournament selection <ref type="bibr" target="#b15">[15]</ref>, parallelization <ref type="bibr" target="#b1">[2]</ref>, clustering <ref type="bibr" target="#b37">[37]</ref>, and speciation <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b20">20]</ref>. Niching methods have also been developed for PSO, such as NichePSO <ref type="bibr" target="#b31">[31]</ref>, SPSO <ref type="bibr" target="#b26">[26]</ref>, and VPSO <ref type="bibr" target="#b33">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Difficulties Facing Niching Methods</head><p>Most of these niching methods, however, have difficulties which need to be overcome before they can be applied successfully to real-world multimodal problems. Some identified issues include the following:</p><p>• Reliance on prior knowledge of some niching parameters, which must be set with some optimal values so that the optimization algorithm can perform well. A common use of a niching parameter is to tell how far apart two closest optima are. A classic example is the sharing parameter σ share in fitness sharing <ref type="bibr" target="#b14">[14]</ref>. Other uses of niching parameters include crowding factor in crowding method <ref type="bibr" target="#b12">[12]</ref>, the window size w in restricted tournament selection <ref type="bibr" target="#b15">[15]</ref>, or the number of clusters in k-means clustering methods <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b17">17]</ref>. • Difficulty in maintaining found solutions in a run. Some found solutions might be lost in successive generations. For example, the original De Jong's crowding has been shown unable to maintain all found peaks during a run <ref type="bibr" target="#b24">[24]</ref>. A good niching algorithm should be able to form and maintain stable subpopulations over the run. • In traditional niching EAs, it was observed that crossover between two fit individuals from different niches could produce far less fit offspring than the parents <ref type="bibr" target="#b25">[25]</ref>. How can we minimize such detrimental crossover operations across different niches? • Some existing niching methods are designed only for locating all global optima, while ignoring local optima. Examples include the sequential niche GA (SNGA) <ref type="bibr" target="#b0">[1]</ref>, clearing <ref type="bibr" target="#b30">[30]</ref>, SCGA <ref type="bibr" target="#b20">[20]</ref>, NichePSO <ref type="bibr" target="#b31">[31]</ref>, and SPSO <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b26">26]</ref>. However, it might be desirable to obtain both global and local optima in a single run. • Most niching methods are evaluated on test functions of only 2 or 3 dimensions. How well these niching algorithms perform on high dimensional problems remain unclear. • Higher computational complexity. Most of the niching algorithms use global information calculated from the entire population, therefore require at least O(N 2 ) computational complexity (where N is the population size). Many niching algorithms suffer from this problem. • Most existing niching methods are evaluated using static functions. When functions can vary over time, ie., the multimodal fitness landscape may change over time, most existing niching methods are unable to cope with the dynamically changing environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problems with Niching Parameters</head><p>Most existing niching methods, however, suffer from a serious problem -their performance is subjected heavily to some niching parameters, which are often difficult to set by a user. For example the sharing parameter σ share in fitness sharing <ref type="bibr" target="#b14">[14]</ref>, the species distance σ s in species conserving GA (SCGA) <ref type="bibr" target="#b20">[20]</ref>, the distance measure σ clear in clearing <ref type="bibr" target="#b30">[30]</ref>, and the species radius r s in the X. Li speciation-based PSO (SPSO) <ref type="bibr" target="#b26">[26]</ref>. Sometimes niching parameters can be under different disguises, such as the crowding factor in crowding <ref type="bibr" target="#b12">[12]</ref>, the window size w in restricted tournament selection <ref type="bibr" target="#b15">[15]</ref>, or the number of clusters in kmeans clustering methods <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b17">17]</ref>. The performance of these EAs depend very much on how these parameters are specified. Unfortunately, in many real-world problems such prior knowledge are often unavailable. Some recent works by Bird and Li <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5]</ref> attempted to reduce the sensitivity of the SPSO to the niche radius parameter values. However, either this parameter still remains (though made more robust), or several new parameters are introduced. It would be desirable if a user can be completely freed from specifying any niching parameters.</p><p>Fig. <ref type="figure" target="#fig_4">1</ref> shows an example of a function fitness landscape that has 9 pairs of global optima and numerous local optima. Within each pair, two global optima are very close to each other but optima from different pairs are further away. A niching algorithm relying on a fixed niche radius value to determine a particle's membership in a niche would have a significant difficulty to work properly on such a landscape. To capture all peaks, a niching EA would have to set its niche radius extremely small so that the closest two peaks can be distinguished. However, doing so would form too many small niches, with possibly too few individuals in each niche. As a result, these niches tend to prematurely converge. On the other hand, if the niche radius is set too large, peaks with a distance between them smaller than this value will not be distinguished. In short, it is likely that there is no optimal value for the niche radius parameter. Dependency on a fixed niche radius is a major drawback for niching methods that rely on such a parameter. For example in <ref type="bibr" target="#b20">[20]</ref>, on the inverted Shubert 2D function (as shown in Fig. <ref type="figure" target="#fig_4">1</ref>), SCGA had to be tuned with a radius value of 0.98 and a population size of 1000 in order to locate all 18 global peaks reliably <ref type="bibr" target="#b20">[20]</ref>.</p><p>For Shubert 3D, SCGA used a population size of 4000 in order to locate all 81 global peaks. As dimension increased to 4, SCGA was only able to identify groups of global peaks, but not individual global optima within each group. Another similar niching algorithm SPSO <ref type="bibr" target="#b26">[26]</ref> suffers the same problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Particle Swarm Optimization</head><p>Particle Swarm Optimization (PSO) is a Swarm Intelligence technique originally developed from studies of social behaviours of animals or insects, e.g., bird flocking or fish schooling <ref type="bibr" target="#b18">[18]</ref>. In a canonical PSO, the velocity of each particle is modified iteratively by its personal best position (i.e., the position giving the best fitness value so far), and the position of best particle from the entire swarm. As a result, each particle searches around a region defined by its personal best position and the position of the population best. Let's use v i to denote the velocity of the i-th particle in the swarm, x i its position, p i the best position it has found so far, and p g the best position found from the entire swarm (so called global best). v i and x i of the i-th particle in the swarm are updated according to the following two equations <ref type="bibr" target="#b10">[10]</ref>:</p><formula xml:id="formula_0">v i ← χ(v i + R 1 [0, ϕ 1 ] ⊗ (p i -x i ) + R 2 [0, ϕ 2 ] ⊗ (p g -x i )),<label>(1)</label></formula><formula xml:id="formula_1">x i ← x i + v i ,<label>(2)</label></formula><p>where R 1 [0, ϕ 1 ] and R 2 [0, ϕ 2 ] are two separate functions each returning a vector comprising random values uniformly generated in the range [0, ϕ 1 ] and [0, ϕ 2 ] respectively. ϕ 1 and ϕ 2 are commonly set to ϕ 2 (where ϕ is a positive constant). The symbol ⊗ denotes point-wise vector multiplication. A constriction coefficient χ is used to prevent each particle from exploring too far away in the search space, since χ applies a dampening effect to the oscillation size of a particle over time. This Type 1" constricted PSO suggested by Clerc and Kennedy is often used with χ set to 0.7298, calculated according to χ =</p><formula xml:id="formula_2">2 2-ϕ- √ ϕ 2 -4ϕ</formula><p>, where ϕ = ϕ 1 + ϕ 2 = 4.1 <ref type="bibr" target="#b10">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PSO Niching Methods</head><p>This section describes several representative niching methods that have been developed in conjunction with PSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stretching Method</head><p>In <ref type="bibr" target="#b27">[27]</ref>, Parsopoulos and Vrahitis introduced a method in which a potentially good solution is isolated once it is found, then the fitness landscape is 'stretched' to keep other particles away from this area of the search space <ref type="bibr" target="#b28">[28]</ref>, similar to the derating method used in SNGA <ref type="bibr" target="#b0">[1]</ref>. The isolated particle is checked to see if it is a global optimum, and if it is below the desired accuracy, a small population is generated around this particle to allow a finer search in this area.</p><p>The main swarm continues its search in the rest of the search space for other potential global optima. With this modification, Parsopoulos and Vrahitis' PSO was able to locate all the global optima of some selected test functions successfully. However, the drawback is that this stretching method introduces several new parameters which are difficult to specify in the stretching function, as well as the risk of introducing false optima as a result of stretching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NichePSO</head><p>Brits et al. proposed NichePSO <ref type="bibr" target="#b31">[31]</ref>, which further extended Parsopoulos and Vrahitis's model. In NichePSO, multiple subswarms are produced from a main swarm population to locate multiple optimal solutions in the search space. Subswarms can merge together, or absorb particles from the main swarm. NichePSO monitors the fitness of a particle by tracking its variance over a number of iterations. If there is little change in a particle's fitness over a number of iterations, a subswarm is created with the particles closest neighbor. The issue of specifying several user parameters still remains. The authors also proposed nbest PSO in <ref type="bibr" target="#b9">[9]</ref>, where a particle's neighbourhood best is defined as the average of the positions of all particles in its neghbourhood. By computing the Euclidean distances between particles, the neighbourhood of a particle can be defined by its k closest particles, where k is a user-specified parameter. Obviously the performance of nbest PSO depends on how this parameter is specified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speciation-Based PSO</head><p>The speciation-based PSO (SPSO) model was developed based on the notion of species <ref type="bibr" target="#b21">[21]</ref>. The definition of species depends on a parameter r s , which denotes the radius measured in Euclidean distance from the center of a species to its boundary. The center of a species, the so-called species seed, is always the bestfit individual in the species. All particles that fall within the r s distance from the species seed are classified as the same species.</p><p>The procedure for determining species seeds, introduced by Pétrowski in <ref type="bibr" target="#b30">[30]</ref> and also <ref type="bibr">Li et al. in [20]</ref>, is adopted here. By applying this algorithm at each iteration step, different species seeds can be identified for multiple species and these seeds' p i can be used as the p g (like a neighbourhood best in a lbest PSO) for different species accordingly. Algorithm 1 summarizes the steps for determining species seeds.</p><p>Algorithm 1 is performed at each iteration step. The algorithm takes as an input L sorted , a list containing all particles sorted in decreasing order of their x i fitness. The species seed set S is initially set to ∅. All particles' x i are checked in turn (from best to least-fit) against the species seeds found so far. If a particle does not fall within the radius r s of all the seeds of S, then this particle will become a new seed and be added to S. Fig. <ref type="figure" target="#fig_1">2</ref> provides an example to illustrate the working of this algorithm. In this case, applying the algorithm will identify s 1 , s 2 and s 3 as the species seeds. Note also that if seeds have their radii overlapped (e.g., s 2 and s 3 here), the first identified seed (such as s 2 ) will dominate over those seeds identified later from the list L sorted . For example, s 2 dominates s 3 therefore p should belong to the species led by s 2 . Since a species seed is the best-fit particle's x i within a species, other particles within the same species can be made to follow the species seed's p i as the newly identified neighborhood best. This allows particles within the same species to be attracted to positions that make them even fitter. Because species are formed around different optima in parallel, making species seeds the new neighborhood bests provides the right guidance for particles in different species to locate multiple optima.</p><p>Since species seeds in S are sorted in the order of decreasing fitness, the more highly fit seeds also have a potentially larger influence than the less fit seeds. This also helps the algorithm to locate the global optima before local ones.</p><p>Once the species seeds have been identified from the population, we can then allocate each seed's p i to be the p g to all the particles in the same species at each iteration step. The speciation-based PSO (SPSO) accommodating the algorithm for determining species seeds described above can be summarized in Algorithm 2.</p><p>In SPSO, a niche radius must be specified in order to define the size of a niche (or species). Since this knowledge might not be always available a priori, it might be difficult to apply this algorithm to some real-world problems. To combat this problem, two extensions to SPSO aiming to improve the robustness to such a niching parameter were proposed in <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b5">5]</ref>. In <ref type="bibr" target="#b4">[4]</ref>, population statistics were used to adaptively determine the niching parameters during a run (see also section 3.1), whereas in <ref type="bibr" target="#b5">[5]</ref>, a time-based convergence measure was used to directly enhance SPSO's robustness to the niche radius value. These extensions to SPSO made it more robust. Nevertheless, the need to specify the niche radius still remains. </p><formula xml:id="formula_3">f (xi); if f (xi) &gt; f(pi) then pi ← xi</formula><p>Sort all particles according to their fitness values (from the best-fit to the least-fit); Call the speciation procedure in Algorithm 1 to identify species seeds; Assign each identified species seed's pi as the pg to all individuals identified in the same species; Adjust particle positions using PSO update equations ( <ref type="formula" target="#formula_0">1</ref>) and ( <ref type="formula" target="#formula_1">2</ref>); Check each species to see if the numP articles &gt; pmax; If so, replace the excess particles with random particles into the search space; until the termination condition is met ; Algorithm 2. The species based PSO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive Niching PSO</head><p>Instead of requiring a user to specify the niche radius r, the Adaptive Niching PSO (ANPSO) proposed in <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b3">3]</ref> adaptively determines it from the population statistics at each iteration. More specifically, ANPSO sets r to the average distance between every particle and its closest neighbour (see Fig. <ref type="figure">3</ref>), as follows:</p><formula xml:id="formula_4">r = N i=1 min j =i ||x i -x j || N . (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>Fig. <ref type="figure">3</ref>. Calculating the distance from each particle to the particle closest to it. r is calculated by averaging these distances.</p><p>An undirected graph g is then created containing a node for each particle. If ANPSO finds pairs of particles that are within r of each other for several iterations, a niche is formed. The remaining unconnected particles (ie., unniched) are mapped onto a von Neumann neighbourhood. At each iterations, particles can join or be removed from existing niches. Whereas the standard PSO updates are applied to particles in each niche, the lbest PSO according to the von Neumann neighbourhood topology is used to update particles that are classified as unniched. The unniched particles are useful especially to search more broadly around the problem space. ANPSO removes the need to specify niche radius r in advance, however, at the same time, it introduces two new parameters, the number of steps two particles must be close before forming a niche, and the maximum number of particle in each niche. Nevertheless, at least on some multimodal test functions, ANPSO's performance was shown to be less sensitive to these two parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fitness-Euclidean Distance Ratio Based PSO</head><p>A PSO based on Fitness-Euclidean distance Ratio (FER-PSO) was proposed in <ref type="bibr" target="#b22">[22]</ref>. In FER-PSO, personal bests of the particles are used to form a memoryswarm to provide a stable network retaining the best points found so far by the population, while the current positions of particles act as parts of an explorerswarm to explore broadly around the search space. Instead of using a single global best, each particle is attracted towards a fittest-and-closest neighbourhood point p n which is identified via computing its FER (Fitness and Euclidean-distance Ratio) value:</p><formula xml:id="formula_6">F ER (j,i) = α • f (p j ) -f (p i ) ||p j -p i || , (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where α = ||s|| f (pg )-f (pw) is a scaling factor, to ensure that neither fitness nor Euclidean distance becomes too dominated over one another. ||s|| is the size of the input : A list of all particles in the population output: Neighbourhood best pn based on the i-th particle's FER value return pn Algorithm 3. The pseudocode of calculating pn for the i-th particle under consideration, according to its FER value. To obtain pn for all particles, this algorithm needs to be iterated over the population.</p><formula xml:id="formula_8">F ER ← 0, tmp ← 0, euDist ← 0 ; for j = 1 to</formula><p>search space, which can be estimated by its diagonal distance Dim k=1 (x u kx l k ) 2 (where x u k and x l k are the upper and lower bounds of the k-th dimension of the search space). p w is the worst-fit particle in the current population.</p><p>FER-PSO is able to reliably locate all global optima, given that the population size is sufficiently large. One noticeable advantage is that FER-PSO does not require specification of niching parameters. Nevertheless, it introduces a parameter α which needs to be determined by the upper and lower bounds of the variables. Since the algorithm uses global information, the complexity of the algorithm is O(N 2 ) (where N is the population size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vector-Based PSO</head><p>In <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b33">33]</ref>, a vector-based PSO (VPSO) was developed by treating each particle as a vector and simply carrying out vector operations over them. For each particle, VPSO computes the dot product Δ of two differential vectors, p ix i and p ix i . A niche is defined by a niche radius determined by the distance between p g and the nearest particle with a negative dot product (ie., moving in an opposite direction). Niche identification is done in a sequential manner. Once a niche is determined, it is excluded from the population, and the process is repeated on the remaining population, until the entire population is grouped into various niches. In VPSO it is not required to specify the niche radius parameter. However, the distance calculations can be expensive since every particle has to be compared with all remaining particles in the population.</p><p>In a subsequent work <ref type="bibr" target="#b35">[35]</ref>, PVPSO which is a parallel version of VPSO was proposed. In PVPSO, different niches can be maintained in parallel. A special procedure was also introduced to merge niches if they are too close to each other (below a specified threshold ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering-Based PSO</head><p>The use of clustering techniques for PSO was first proposed by Kennedy in <ref type="bibr" target="#b17">[17]</ref>, where the k-means clustering algorithm was used to identify the centers of different clusters of particles in the population, and then use these cluster centers to substitute the personal bests or neighborhood bests. However, Kennedy's clustering technique was used to help locate a single global optimum, rather than multiple optima, as niching normally does. Inspired by this work, a k-means clustering PSO (kPSO) for niching was proposed in <ref type="bibr" target="#b29">[29]</ref>. In kPSO, k-means is repeatedly applied to the swarm population at a regular interval. Between each interval, PSO is executed in the normal manner. Particles in different clusters at an early stage of a run could end up in the same cluster as they converge towards the same local optimum. The parameter k is estimated by using the Bayesian information criterion (BIC) <ref type="bibr" target="#b36">[36]</ref>. More specifically, k-means is repeatedly applied to the population with different k values (usually from 2 to N /2), and the resulting clustering that has the highest BIC value is chosen. By doing this, there is no need to specify k in kPSO. It was shown that the performance of kPSO was comparable to existing PSO niching algorithms such as SPSO and ANPSO on some multimodal test functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Niching PSOs for Dynamically Changing Multimodal Environments</head><p>Many real-world optimization problems are dynamic and require optimization algorithms capable of adapting to the changing optima over time. An environment that is both multimodal and dynamic presents additional challenges. In fully dynamic multimodal environments, optima may shift spatially, change both height and shape or come into or go out of existence. One useful approach in handling this is to divide the population into several subpopulations, with each subpopulation searches for a promising region of the search space simultaneously. This is the core idea of several recently proposed PSO niching algorithms for handling a dynamical multimodal landscape such as the Dynamic SPSO <ref type="bibr" target="#b26">[26]</ref> and the multi-swarm PSO (MPSO) <ref type="bibr" target="#b8">[8]</ref>, and rSPSO <ref type="bibr" target="#b6">[6]</ref>. Several additional issues must be addressed, including outdated memory, population re-diversification, change detections and response strategies. For further information, readers can refer to <ref type="bibr" target="#b7">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">New Niching Methods Using a lbest PSO</head><p>In <ref type="bibr" target="#b23">[23]</ref>, a novel PSO niching method was developed using a simple ring neighbourhood topology, which belongs to the class so called lbest PSO models. This PSO niching method makes use of the inherent characteristics of PSO and does not require any niching parameters. It can operate as a niching algorithm by using individual particles' local memories to form a stable network retaining the best positions found so far, while these particles explore the search space more broadly. Given a reasonably large population uniformly distributed in the search space, the ring topology based niching PSOs are able to form stable niches across different local neighbourhoods, eventually locating multiple global/local optima. This section describes several such ring topology based niching PSO variants in detail, and how PSO's inherent characteristics such as memory-swarm and explorer-swarm can be utilized to induce stable niching behaviours.</p><p>Generally speaking, two common approaches of choosing p g in equation ( <ref type="formula" target="#formula_0">1</ref>) are known as gbest and lbest methods. In a gbest PSO, the position of each particle in the search space is influenced by the best-fit particle in the entire population, whereas a lbest PSO only allows each particle to be influenced by the best-fit particle chosen from its neighborhood. The lbest PSO with a neighborhood size set to the population size is equivalent to a gbest PSO. Kennedy and Mendes <ref type="bibr" target="#b19">[19]</ref> studied PSOs with various population topologies. One of common population topologies suggested was a ring topology, where each particle on the population array is only allowed to interact with its two immediate neighbours. Among all topologies studied, the ring topology was considered to be "the slowest, most indirect communication pattern", whereas the gbest PSO represents "the most immediate communication possible".</p><p>Clearly the ring topology is desirable for locating multiple optima, because ideally we would like to have individuals to search thoroughly in its local neighbourhood before propagating the information throughout the population. The consequence of any quicker than necessary propagation would result in the population converging onto a single optimum (like gbest PSO).</p><p>As we will demonstrate in the following sections, the ring topology is able to provide the right amount of communication needed for inducing stable niching behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Memory-Swarm vs. Explorer-Swarm</head><p>In PSO, interactions among particles play an important role in particles' behaviour. A distinct feature of PSO (which is different from many EAs) is that each particle carries a memory of its own, i.e., its personal best. We can never underestimate the significance of using local memory. As remarked by Clerc in <ref type="bibr" target="#b11">[11]</ref>, a swarm can be viewed as comprising of two sub-swarms according to their differences in functionality. The first group, explorer-swarm, is composed of particles moving around in large step sizes and more frequently, each strongly influenced by its velocity and its previous position (see equation ( <ref type="formula" target="#formula_0">1</ref>) and ( <ref type="formula" target="#formula_1">2</ref>)). The explorer-swarm is more effective in exploring more broadly the search space. The second group, memory-swarm, consists of personal bests of all particles. This memory-swarm is more stable than the explorer-swarm because personal bests represent positions of only the best positions found so far by individual particles. The memory-swarm is more effective in retaining better positions found so far by the swarm as a whole.</p><p>Fig. <ref type="figure" target="#fig_2">4 a</ref>) shows an example of a conventional EA using a ring topology with a population of 7 individuals. Fig. <ref type="figure" target="#fig_2">4 b</ref>) shows a swarm of 7 particles using a ring topology, as illustrated by using a 'graph of influence' as suggested by Clerc <ref type="bibr" target="#b11">[11]</ref>. The 'graph of influence' can be used to explicitly demonstrate the source and receiver of influence for each particle in a swarm. A particle that informs another particle is called 'informant'. Here the explorer-swarm consists of particles as marked from numbers 1 to 7, and the memory-swarm consists of particles as marked from m1 to m7. Each particle has 3 informants, from two neighbouring particles' memories and its own memory. Each particle's memory also has 3 informants, from two neighbouring particles and the particle itself. In stark contrast, Fig. <ref type="figure" target="#fig_2">4 a</ref>) shows that no local memories are used in a conventional EA using a ring topology.</p><p>The idea of memory-swarm and explorer-swarm inspired us to develop effective PSO niching algorithms. With an aim to locate and maintain multiple optima, the more stable personal best positions retained in the memory-swarm can be used as the 'anchor' points, providing the best positions found so far. Meanwhile, each of these positions can be further improved by the more exploratory particles in the explorer-swarm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">lbest PSO Using a Ring Topology</head><p>As shown in Fig. <ref type="figure" target="#fig_2">4</ref>, in a lbest PSO with a ring topology, each particle interacts only with its immediate neighbours. An implementation of such a lbest PSO  <ref type="formula" target="#formula_0">1</ref>), pg should be replaced by the i-th particle's neighbourhood best pn,i. using a ring topology is provided in Algorithm 4. Note that we can conveniently use population indices to identify the left and right neighbours of each particle. Here we assume a 'wrap-around' ring topology, i.e., the first particle is the neighbour of the last particle and vice versa. The neighbourhoodBest() function returns the best-fit personal best in the i-th neighbourhood, which is recorded as p n,i (denoting the neighbourhood best for the i-th particle). This p n,i is then used as the local leader when updating the i-th particle in Equation ( <ref type="formula" target="#formula_0">1</ref>) and (2). Note that different particles residing on the ring can have different p n 1 , and they do not necessarily converge into a single value over time. As illustrated in Fig. <ref type="figure" target="#fig_3">5</ref>, the ring topology not only provides a mechanism to slow down information propagation in the particle population, but also allows different neighbourhood bests to coexist (rather than becoming homogeneous) over time. This is because a particle's p n can only be updated if there is a better personal best in its neighbourhood, but not by a better p n of its neighbouring particle. Assuming that particles from the initial population are uniformly distributed across the search space, niches can naturally emerge as a result of the coexistence of multiple p n positions being the local attraction points for the particles in the population. With a reasonable population size, such a lbest PSO is able to form stable niches around the identified neighbourhood bests p n .</p><p>Apart from its simplicity, the ring topology lbest PSO does not require any prior knowledge of (neither the need to specify) any niching parameters, e.g., the niche radius or the number of peaks, since niches emerge naturally from the initial population. The complexity of the algorithm is only O(N ) (where N is the population size), as the calculation to obtain a neighbourhood best is only done locally from each particle's local neighbourhood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Numerical Examples</head><p>To evaluate the niching ability of the above lbest PSO with a ring topology, we used 3 multimodal optimization test functions of different characteristics. For n-dimensional Shubert function, there are n • 3 n global optima unevenly distributed. These global optima are divided into 3 n groups, with each group having n global optima being close to each other. For f 3 Shubert 3D, there are 81 global optima in 27 groups; whereas for f 3 Shubert 4D, there are 324 global optima in 81 groups. f 3 will pose a serious challenge to any niching algorithm relying on a fixed niche radius parameter.</p><p>The lbest PSO with a ring topology as described above has overlapping local neighbourhoods. To further restrain the influence from a few dominant p n points, we could reduce the neighbourhood size or even completely remove the overlaps.</p><p>In our experiments, we used the following ring topology based PSO variants:</p><p>• r3pso: a lbest PSO with a ring topology, each member interacts with its immediate member on its left and right (as in Fig. <ref type="figure" target="#fig_3">5</ref>); • r2pso: a lbest PSO with a ring topology, each member interacts with only its immediate member to its right; • r3pso-lhc: the same as r3pso, but with no overlapping neigbourhoods.</p><p>Basically multiple PSOs search in parallel, like local hill climbers. • r2pso-lhc: the same as r3pso-lhr, but with each member interacts with only its next member on the population array. For any particle with its x i exceeding the boundary of the variable range, its position is reset to a value which is twice of the right (or left boundary) subtracting x i .</p><p>The performance of the above PSO variants were compared with SPSO <ref type="bibr" target="#b26">[26]</ref>, which is a typical niching algorithm requiring a user to pre-specify a niche radius parameter.</p><p>To compare the performance of niching algorithms, we first allow a user to specify a level of accuracy (typically 0 &lt; ≤ 1), i.e., how close the computed solutions to the expected optimal solutions are. If the distance from a computed solution to an expected optimum is below the specified , then we can consider the optimum is found. For all comparing niching algorithms in this paper, we used SPSO's procedure for identifying species seeds (as described in the previous section) to check if a niching algorithm has located all expected global optima. Note that this procedure was only used for the purpose of performance measurement, but not for optimization in the proposed PSO niching methods, with the only exception of SPSO itself.</p><p>All PSO niching algorithms' performance were measured in terms of success rate, i.e., the percentage of runs in which all global optima are successfully located, for a given number of evaluations in each run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and Discussion</head><p>For the relatively simple f 1 and f 2 , a population size of 50 was used. The PSO niching variants were run until all the known global optima were found, or a maximum of 100,000 evaluations was reached. For the more challenging f 3 2D and 3D, a population size of 500 was used. For f 3 3D, we allowed a maximum of 200,000 evaluations for each run. For f 3 4D, a population size of 1000 was used, and we allowed a maximum of 400,000 evaluations. All results were averaged over 50 runs. For all PSO niching methods (except SPSO) and r (niche radius) were used purely for the purpose of performance measurement. In order to measure more accurately each niching algorithm's ability in forming niches in the vicinities of all known global optima, for f 1 and f 2 , both and r were set to 0.01. For f 3 2D, was set to 0.1, and for f 3 3D and 4D, was set to 0.2. For all f 3 2D, 3D and 4D, r was set to 0.5.</p><p>Table <ref type="table" target="#tab_3">1</ref> presents the success rates on f 1 , f 2 and f 3 2D. On f 1 nd f 2 , almost all comparing PSOs achieved a 100% success rate. However, for the more challenging f 3 2D, SPSO did not perform very well, whereas the ring topology PSOs achieved success rates greater than 90%. Bear in mind that SPSO was tuned with the Table <ref type="table">2</ref>. Averaged peak ratios on f11 Inverted Shubert 3D and 4d over 50 runs. fnc r r2pso r3pso r2pso-lhc r3pso-lhc SPSO f3 (3D) 0.2 0.5 0.16 0.61 0.27 0.66 0.01 f3 (4D) 0.2 0.5 0.00 0.25 0.00 0.14 0.00 optimal niche radius, whereas the ring topology based PSOs did not depend on any niching parameters, showing greater robustness. Fig. <ref type="figure" target="#fig_5">6 a</ref>) shows an example of running r3pso on f 1 . At iteration 15, all 5 global peaks were located by the p n points identified for individual particles on the population array. Although particles' x i points (i.e., current positions) tended to be more exploratory oscillating around peaks, their p n points converged stably on the tips of the peaks, even if we ran the model for a large number of iterations. Niches formed from neighbouring particles (as shown by their indices on the population array) are clearly visible in Fig. <ref type="figure" target="#fig_5">6 b</ref>). It can be also observed that for each of the 5 peaks, r3pso formed multiple small niches centered around the p n points.</p><p>Fig. <ref type="figure">7</ref> shows that r3pso was able to locate all 18 global peaks on f 3 the inverted Shubert 2D by iteration 75 in a single run. Multiple emerged niches are clearly visible.</p><p>For the more challenging f 3 Inverted Shubert 3D and 4D functions, since no run can find all peaks, hence we used averaged peak ratio (instead of success rate) as the performance measure. Peak ratio measures the percentage of global peaks found in a single run.  Shubert 3D and 4D over 50 runs. As can be seen in Table <ref type="table">2</ref>, r3pso and r3psolhc are the best performers, whereas SPSO is the worst. r2pso and r2pso-lhc were able to find a few global peaks on f 3 3D, but failed to find almost any peaks on f 3 4D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Effect of Varying Population Size</head><p>For the proposed ring topology based PSOs, the only parameter that needs to be specified is population size. Given a reasonably large population size, these PSOs are able to locate all global optima reliably. Fig. <ref type="figure" target="#fig_6">8</ref> shows that on f 3 2D, with a population size of 450 or above, the ring topology based PSOs achieved 90% or above success rates. In contrast, even with a population size of 500, SPSO only managed to achieve 60% success rate. Another similar niching algorithm, SCGA <ref type="bibr" target="#b20">[20]</ref>, which also required a user to specify a niche radius parameter, needed a population size of 1000 or above in order to locate all 18 global optima.</p><p>It is worth noting that the local hill-climber variants r2pso-lhc and r3pso-lhc performed better than r2pso and r3pso on f 3 2D. This indicates that when handling problems with a large number of global optima, it might be more effective to have multiple local hill climbers each optimizing independently than a niching algorithm working with a single large population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Niching methods have been developed mostly in the context of EAs, and have been around for more than two decades. Recent advances in Swarm Intelligence and in particular PSO has made possible to design novel and competent niching methods for multimodal optimization. This chapter has presented a survey of several state-of-the-art PSO niching algorithms, and described how some of the challenging issues faced by classic niching methods can be addressed. Apart from the fact that existing niching methods developed in the early days of EAs can be easily incorporated into a PSO, more importantly, it has been shown here that the inherent characteristics of PSO can be utilized to design highly competitive niching algorithms. In particular, it is shown that in a lbest PSO, local memory and slow communication topology are the two key elements for its success as an effective niching algorithms. In fact it is foreseeable that other population based stochastic optimization methods characterized by these two key elements can be also used to induce stable niching behaviour.</p><p>In future, we will be interested in investigating how to increase the search capability of small niches so that the performance of these niches will scale well with increasing dimensions, since lbest PSO niching algorithms tend to generate multiple small niches. Ideally a function generator suitable for this kind of evaluation will need to offer controllable features such as the number global optima and local optima, which are independent from the number of dimensions. One recently proposed function generator for multimodal function optimization in <ref type="bibr" target="#b32">[32]</ref> seems to be a promising tool for this purpose. We will be also interested in developing techniques to adapt or self-adapt the population size, as this is the only parameter that still needs to be supplied by a user. Anther interesting research topic will be to apply the lbest niching PSO to tracking multiple peaks in a dynamic environment <ref type="bibr" target="#b26">[26]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 Fig. 1 .</head><label>11</label><figDesc>Fig. 1. Inverted Shubert 2D function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. An example of how to determine the species seeds from a population of particles. s1, s2 and s3 are chosen as the species seeds. Note that p follows s2.</figDesc><graphic coords="8,114.02,52.23,201.19,152.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. a)The ring topology used in a conventional EA. Each member interacts only with its immediate left and right neighbours, with no local memory used; b) Graph of influence for a lbest PSO using the same ring topology (see also p.89 in<ref type="bibr" target="#b11">[11]</ref>). Each particle possesses a local memory; c) The same as b) but also showing the overlapping subpopulations, each consisting of a particle and its two immediate neighbours, and their corresponding memories.</figDesc><graphic coords="13,42.74,52.25,343.72,136.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. A ring topology with each member interacting with its 2 immediate neighbours (left and right). Local neighbourhoods are overlapped with each other. The i-th particle's neighbourhood best pn,i is the same as those of its 2 immediate neighbouring particles, but differs from those particles in the neighbourhoods further out.</figDesc><graphic coords="14,88.82,360.82,251.64,116.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 f 1</head><label>1</label><figDesc>Equal Maxima has 5 evenly spaced global maxima, whereas f 2 Uneven Maxima has 5 global maxima unevenly spaced. f 3 Inverted Shubert function is the inverted Shubert function, as shown in Fig. 1, the inverted Shubert 2D function has 9 groups of global optima, with 2 very close global optima in each group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. a) Niches formed when using r3pso variant on the f1 at iteration 15 (a population size of 50 was used); b) Particles' pi and their pn on the population array at iteration 15, corresponding to the run in a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Success rates for varying population sizes on f3 the inverted Shubert 2D function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>L sorted -a list of all particles sorted in their decreasing f (xi) values output: S -a list of all dominating particles identified as species seeds</figDesc><table><row><cell>begin</cell></row><row><cell>S = ∅;</cell></row><row><cell>while not reaching the end of L sorted do</cell></row><row><cell>Get best unprocessed p ∈ L sorted ;</cell></row><row><cell>found ← FALSE;</cell></row><row><cell>for all s ∈ S do</cell></row><row><cell>if d(s, p) ≤ rs then</cell></row><row><cell>found ← TRUE;</cell></row><row><cell>break;</cell></row><row><cell>if not found then</cell></row><row><cell>let S ← S ∪ {p};</cell></row></table><note><p><p>input :</p>end Algorithm 1. The algorithm for determining species seeds according to all f (xi) values.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Population Size doCalculate the Euclidean distance euDist from pi to the j-th particle's</figDesc><table><row><cell>personal best pj;</cell></row><row><cell>if (euDist not equal to 0) then</cell></row><row><cell>Calculate F ER according to equation (4) ;</cell></row><row><cell>if (j equal to 1) then tmp ← F ER;</cell></row><row><cell>if (F ER &gt; tmp) then</cell></row><row><cell>tmp ← F ER ;</cell></row><row><cell>pn ← pj ;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>The pseudocode of a lbest PSO using a ring topology. Note that in equation (</figDesc><table><row><cell>Randomly generate an initial population</cell></row><row><cell>repeat</cell></row><row><cell>for i = 1 to Population Size do</cell></row><row><cell>if fit(xi) &gt; fit(pi) then pi = xi;</cell></row><row><cell>end</cell></row><row><cell>for i = 1 to Population Size do</cell></row><row><cell>pn,i = neighbourhoodBest(pi-1, pi, pi+1);</cell></row><row><cell>end</cell></row><row><cell>for i = 1 to Population Size do</cell></row><row><cell>Equation (1);</cell></row><row><cell>Equation (2);</cell></row><row><cell>end</cell></row><row><cell>until termination criterion is met ;</cell></row><row><cell>Algorithm 4.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Success rates.</figDesc><table><row><cell>fnc</cell><cell cols="3">r2pso r3pso r2pso-lhc r3pso-lhc SPSO</cell></row><row><cell>f1</cell><cell>98% 100% 100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell>f2</cell><cell>100% 100% 100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell cols="2">f3(2D) 94% 100% 100%</cell><cell>98%</cell><cell>60%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table2shows the averaged peak ratios on f 3 Inverted The niching behaviour of the r3pso (with a population size of 500) on f3 the inverted Shubert 2D function at iteration 10 and 75 of a run.</figDesc><table><row><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">from pBest to current</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">from pBest to current</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>current</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>current</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>pBest nBest</cell><cell></cell><cell></cell><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>pBest nBest</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-10</cell><cell>-8</cell><cell>-6</cell><cell>-4</cell><cell>-2</cell><cell>0</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>-10</cell><cell>-8</cell><cell>-6</cell><cell>-4</cell><cell>-2</cell><cell>0</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">(a) iteration 10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) iteration 75</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Fig. 7. 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Success Rate</cell><cell></cell><cell>0.6 0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">r2pso</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">r3pso r2pso-lhc</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">r3pso-lhc</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">SPSO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100</cell><cell cols="2">150</cell><cell cols="3">250 200 250</cell><cell>300</cell><cell>350</cell><cell>400</cell><cell></cell><cell>450</cell><cell>500</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Population Size</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We use pn to denote a non-specific 'neighbourhood best'.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>These</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>functions are also described in<ref type="bibr" target="#b23">[23]</ref>.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A sequential niche technique for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Beasley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Bull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="125" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note>citeseer.ist.psu.edu/beasley93sequential.html X. Li</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Island model cooperating with speciation for multimodal optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bessaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pétrowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Siarry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Merelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPSN 2000</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Schwefel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H.-P</forename><surname>Yao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">1917</biblScope>
			<biblScope unit="page" from="16" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>citeseer.ist.psu.edu/bessaou00island.html</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Adaptive techniques for enhancing the robustness and performance of speciated psos in multimodal environments, phd thesis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Melbourne, Australia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>RMIT University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptively choosing niching parameters in a PSO</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1145/1143997.1143999</idno>
		<ptr target="http://doi.acm.org/10.1145/1143997.1143999" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Genetic and Evolutionary Computation Conference</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Cattolico</surname></persName>
		</editor>
		<meeting>Genetic and Evolutionary Computation Conference<address><addrLine>Seattle, Washington, USA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006-07-08">2006. July 8-12. 2006</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhancing the robustness of a speciation-based PSO</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/servlet/opac?punumber=11108" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 IEEE Congress on Evolutionary Computation</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</editor>
		<meeting>the 2006 IEEE Congress on Evolutionary Computation<address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2006">July 16-21. 2006</date>
			<biblScope unit="page" from="843" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using regression to improve local convergence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE Congress on Evolutionary Computation</title>
		<meeting>the 2007 IEEE Congress on Evolutionary Computation<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1555" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Particle swarms for dynamic optimization problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Swarm Intelligence -Introduction and Applications</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Merkle</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="193" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-swarm optimization in dynamic environments</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Raidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Drechsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marchiori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rothlauf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EvoWorkshops 2004</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Squillero</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3005</biblScope>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Solving systems of unconstrained equations using particle swarm optimizers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Negelbrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Systems, Man, Cybernetics</title>
		<meeting>of the IEEE Conference on Systems, Man, Cybernetics</meeting>
		<imprint>
			<date type="published" when="2002-10">October 2002. 2002</date>
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The particle swarm -explosion, stability, and convergence in a multidimensional complex space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="2002-02">February 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Particle Swarm Optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISTE Ltd</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An analysis of the behavior of a class of genetic adaptive systems</title>
		<author>
			<persName><forename type="first">Jong</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Massive multimodality, deception, and genetic algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<editor>Männer, R., Manderick, B.</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Elsevier Science Publishers</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>B. V., Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>citeseer.ist.psu.edu/goldberg92massive.html</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Genetic algorithms with sharing for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Second International Conference on Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Grefenstette</surname></persName>
		</editor>
		<meeting>of the Second International Conference on Genetic Algorithms</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Finding multimodal solutions using restricted tournament selection</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Harik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Sixth International Conference on Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Eshelman</surname></persName>
		</editor>
		<meeting>of the Sixth International Conference on Genetic Algorithms<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
	<note>citeseer.ist.psu.edu/harik95finding.html</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Stereotyping: Improving particle swarm performance with cluster analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Int. Conf. Evolutionary Computation</title>
		<meeting>of IEEE Int. Conf. Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<title level="m">Swarm Intelligence</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Population structure and particle swarm performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2002 Congress on Evolutionary Computation</title>
		<meeting>of the 2002 Congress on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1671" to="1675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A species conserving genetic algorithm for multimodal function optimization</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Balazs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="234" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptively choosing neighbourhood bests using species in a particle swarm optimizer for multimodal function optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECCO 2004</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3102</biblScope>
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multimodal function optimization based on fitness-euclidean distance ratio</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Genetic and Evolutionary Computation Conference</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</editor>
		<meeting>of Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="78" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Niching without niching parameters: Particle swarm optimization using a ring topology</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="150" to="169" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parallel Problem Solving From Nature 2</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mahfoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amsterdam</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Männer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Manderick</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="27" to="36" />
			<date type="published" when="1992">1992</date>
			<pubPlace>North-Holland</pubPlace>
		</imprint>
	</monogr>
	<note>Crowding and preselection revisited. citeseer.ist.psu.edu/mahfoud92crowding.html</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Niching methods for genetic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mahfoud</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/mahfoud95niching.html" />
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Urbana, IL, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Locating and tracking multiple dynamic optima by a particle swarm model using speciation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Parrott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="440" to="458" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modification of the particle swarm optimizer for locating all the global minima</title>
		<author>
			<persName><forename type="first">K</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Genetic Algorithms</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">N M K V</forename><surname>Kurkova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Steele</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="324" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the computation of all global minimizers through particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evol. Compu</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="224" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Particle swarm optimization for multimodal functions: a clustering approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Passaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Starita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Evol. App</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A clearing procedure as a niching method for genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pétrowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 3rd IEEE International Conference on Evolutionary Computation</title>
		<meeting>of the 3rd IEEE International Conference on Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="798" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A niching particle swarm optimizer</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E R</forename><surname>Brits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 4th Asia-Pacific Conference on Simulated Evolution and Learning</title>
		<meeting>of the 4th Asia-Pacific Conference on Simulated Evolution and Learning</meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002. 2002</date>
			<biblScope unit="page" from="692" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A generator for multimodal test functions with multiple global optima</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rönkkönen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kyrki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kirley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ciesielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Abbass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hendtlass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SEAL 2008</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5361</biblScope>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Niching in particle swarm optimization, phd thesis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Schoeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Pretoria, South Africa</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Pretoria</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Using vector operations to identify niches for particle swarm optimization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Schoeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2004 IEEE Conference on Cybernetics and Intelligent Systems</title>
		<meeting>of the 2004 IEEE Conference on Cybernetics and Intelligent Systems<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="361" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A parallel vector-based particle swarm optimizer</title>
		<author>
			<persName><forename type="first">I</forename><surname>Schoeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 7th International Conference on Artificial Neural Networks and Genetic Algorithms (ICANNGA 2005)</title>
		<meeting>of the 7th International Conference on Artificial Neural Networks and Genetic Algorithms (ICANNGA 2005)<address><addrLine>Coimbra, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A fast genetic algorithm with sharing scheme using cluster analysis methods in multi-modal function optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Germay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Artificial Neural Networks and Genetic Algorithms</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="450" to="457" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
