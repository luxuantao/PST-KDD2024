<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cognitive Modeling Reveals Menu Search is Both Random and Systematic</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1997">MARCH 1997</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anthony</forename><forename type="middle">J</forename><surname>Hornof</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Kieras</surname></persName>
							<email>kieras@eecs.umich.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="laboratory">Artificial Intelligence Laboratory Electrical Engineering</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<addrLine>1101 Beal Avenue</addrLine>
									<postCode>48109-2110 +1 3137636985</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cognitive Modeling Reveals Menu Search is Both Random and Systematic</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1997">MARCH 1997</date>
						</imprint>
					</monogr>
					<idno type="MD5">393BD4FF2804E4B6ACE9BF54E52B3645</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cognitive models</term>
					<term>menu selection</term>
					<term>visual search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To understand how people search for a known target item in an unordered pull-down menu, this research presents cognitive models that vary serial versus parallel processing of menu items, random versus systematic search, and different numbers of menu items fitting into the fovea simultaneously.</p><p>Varying these conditions, models were constructed and run using the EPIC cognitive architecture. The selection times predicted by the models are compared with selection times of human subjects performing the same menu task. Comparing the predicted and observed times, the models reveal that 1) people process more than one menu item at a time, and 2) people search menus using both random and systematic search strategies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION Models of human performance</head><p>permit aspects of user interfaces to be evaluated for usability by making predictions based on task analysis and established principles of human performance <ref type="bibr">[4,</ref><ref type="bibr">5]</ref>. Though much previous research (including <ref type="bibr">[3,</ref><ref type="bibr">9,</ref><ref type="bibr">12,</ref><ref type="bibr">14]</ref>) has investigated menu selection, there are no empirically validated models of the low-level perceptual, cognitive, and motor processing that people use when they select a known target item from an unordered pull-down menu.</p><p>Researchers have proposed theories about the low-level strategies that people use to find a known item in an unordered menu. Norman <ref type="bibr">[12]</ref> and Vandierendonck, <ref type="bibr">Van Hoe,</ref><ref type="bibr">and De Soete [14]</ref> suggested that people process one menu item at a time. But they did not validate this low-Ievel assumption empirically.</p><p>There have also been conflicting theories. <ref type="bibr">Card [3]</ref> proposed that people randomly choose which item to examine next, while Lee and MacGregor <ref type="bibr">[9]</ref> provided evidence that people search systematically from top to bottom. The research presented here examines the plausibility of these theories by providing an empirically validated model of the low-level perceptual, cognitive, and motor processing that people use in a menu selection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE EPIC COGNITIVE ARCHITECTURE</head><p>The EPIC (Executive Process Interactive Control) cognitive architecture <ref type="bibr">[6,</ref><ref type="bibr">7]</ref> provides a general framework for simulating a human interacting with their environment to accomplish a task, and is well-suited to model a menu selection task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EPIC resembles the Model Human Processor</head><p>[4], but differs in that EPIC is a precise computational model, has a programmable production-rule cognitive processor, and incorporates more specific constraints synthesized from human performance literature.</p><p>EPIC consists of a production-rule cognitive processor and perceptual-motor peripherals.</p><p>To model human performance aspects of accomplishing a task, a cognitive strategy and perceptual-motor processing parameters must be speeified. A cognitive strategy is represented as a set of production rules, much the same way that CCT [2], ACT-R <ref type="bibr" target="#b0">[1]</ref>, and SOAR <ref type="bibr">[8]</ref> represent procedural knowledge. The simulation is driven by a description of the task environment that specifies aspects of the environment that would be directly observable to a human, such as what objects appear at what times, and how the environment changes based on EPIC's motor movements. EPIC computational models are generative in that the production rules only represent general procedural knowledge of the task, and when EPIC interacts with the task environment, EPIC generates a speeific sequence of perceptual, cognitive, and motor activities required to perform each specific instance of the task.</p><p>EPIC takes as its input: " The cognitive strategy for accomplishing a task.</p><p>q Availability of object features, to represent human perceptual limitations.</p><p>q Details of the task environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EPIC generates as output: q</head><p>The time required to execute the task. q A trace of the modeled human processing.</p><p>As shown in Figure <ref type="figure" target="#fig_0">1</ref>, information flows from sense organs, through perceptual processors, to a cognitive processor (consisting of a production rule interpreter and a working memory), and finally to motor processors that control effecter organs. All processors run independently and in parallel. A single stimulus in the task environment can produce multiple outputs from a perceptual processor to be deposited in working memory at different times. First the detection of a perceptual event is sent, followed later by features that describe the event. The perceptual processors are "pipelined."</p><p>If an object's features begin moving to working memory, the arrival of those features will not be delayed by any other processing.</p><p>Working memory contains these items deposited by perceptual processors, as well as control information such as the current task goal. At the end of each simulated 50 msec cycle, EPIC f~es all of the production roles whose conditions match the current contents of working memory.</p><p>EPIC allows for parallel execution of production rules in the cognitive processor, and some parallelism in each motor processor.</p><p>In short, EPIC is applied to a task as follows:</p><p>The production-rule strategy directs the eyes to objects in the environment.</p><p>The eyes have a resolving power which determines the processing time required for different object features, such as location and text. When information needed to determine the next motor movement arrives in working memory, the strategy instructs the ocular motor and manual motor processors to move the eyes and hands.</p><p>Information processing and motor movement times are held constant across modeling efforts, and are based on human performance literature.</p><p>Manual movement times, for example, are determined by Fitts' law (see <ref type="bibr">[4]</ref>, Ch. 2). For lack of space, EPIC cannot be described in full detail here.</p><p>A more thorough description is presented in <ref type="bibr">[6,</ref><ref type="bibr">7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THE TASK</head><p>The specific pull-down menu task modeled in this paper is based on a menu selection task used by Nilsen in an experiment with human subjects (Experiment 2 in [1 l]). Nilsen used menus that had three, six, and nine menu items.</p><p>Each menu item was a single numerical digit. Menu items were randomly reordered for each trial. Subjects were experienced mouse (and thus presumably menu) users and were financially motivated to perform each trial as quickly as possible. Nilsen ran eight subjects, each with six trials for every possible combination of menu length and target position.</p><p>The distance between menu items was roughly 0.2 inches. The distance from eye to screen was neither controlled nor measured.</p><p>As shown in Figure <ref type="figure" target="#fig_1">2</ref>, each trial consisted of the following steps: Using the mouse, move the cursor to the GO box which causes the precue of the target item to appear above the GO "box. Commit the precue to memory. Click on the GO box. The GO box and precue disappear, the menu appears, and the clock starts. As quickly as possible, click on the target item in the menu. The clock stops. This task isolates a subset of the processes required in a "real world" menu task. It is thus particularly well-suited for studying the low-level perceptual-motor processes of visual search and response selection.</p><p>The task is not confounded with more complex processes of reading, comprehension, judgment, decision making, and problem solving. Though Nilsen mostly used the data to examine motor control, this modeling effort focuses on visual search. The data is particularly usefhl for modeling visual search of menus because Nilsen varied menu length and reported selection time as a function of the serial position of the target menu item. Few researchers have reported such data. As will be shown, this combination is critical for revealing search strategy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Also: Time required to move the mouse to each target position as predicted by Fitts' law (dashed line).</head><p>There are several key features to note in the observed data . . .</p><p>When the target item is in the same position across menus of different lengths, shorter menus are faster. Selection time increases with a fairly linear slope of about 100 msec per item for each menu length (excluding serial position 1). As can be seen in the graph, the mouse movement time predicted by Fitts' law cannot entirely account for this slope.</p><p>The selection time for serial position 1 is a little higher than the selection time for se~al position 2.</p><p>The EPIC models that follow are all evaluated with respect to how well they match these trends in Nilsen's observed data.</p><p>THE MODELS This section presents six models that result from varying two strategic dimensions: Serial versus parallel processing of menu items, and random versus systematic search. In the parallel processing models, the eye-to-screen distance is varied (8 and 20 inches) to result in one or three items being visible in the fovea simultaneously.</p><p>The fovea is fixed as the circular region within 1°of visual angle from the center of the gaze. It is assumed that recognition of digits is only possible in the fovea.</p><p>The discussion of each model includes a flowchart that summarizes the production rules written in EPIC to represent that model.</p><p>Production roles were written to maximize performance within the constraints imposed by EPIC, and to be as simple as possible.</p><p>EPIC was otherwise used 'as is' for all models. Details and parameters such as the availability of object features were established and validated in other modeling projects in different task domains, and are discussed in <ref type="bibr">[6,</ref><ref type="bibr">7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Serial Processing Models</head><p>The serial processing models represent a belief that people move their gaze to an item, visually process it, decide if it is the target, click on the item if it is, or go on to the next item if it is not. Figure <ref type="figure" target="#fig_3">4</ref> represents a serial processing model proposed by <ref type="bibr">Norman [12]</ref>.</p><p>Since the model proposed in Figure <ref type="figure" target="#fig_3">4</ref> does not specifj the search strategy used to find the next item, two separate sets of production rules were built in EPIC to represent two possible models, one with random search and the other with systematic topto-bottom search. Both serial processing models were only run with an eyeto-screen distance of 8 inches so that only one item would fit into the fovea at a time, insuring the serial encoding process specified by Norman. At greater distances, more than one item would fit into the fovea simultaneously, and parallel encoding would ensue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Serial Processing Random Search Model</head><p>The results from running the Serial Processing Random Search model are shown in Figure <ref type="figure" target="#fig_4">5</ref>. Each predicted selection time is averaged from 300 trials run for that menu length and serial position combination. The results in Figure <ref type="figure" target="#fig_4">5</ref> (on preceding page) suggest that the Serial Processirm Random Search model is wromz. The only feature in the observed data that this model accounts for is that shorter menus are faster than longer menus. Otherwise, the model does not fit the observed data. Selection times are much too high overall. Slopes are very small because every item takes on average the same amount of time to find and select; any slope that appears is due to the mouse movement. A higher selection time for serial position 1 is not predicted. This model does not account for the observed data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Serial Processing Systematic Seatch Model</head><p>The results from running the Serial Processing Systematic Search model are shown in Figure <ref type="figure" target="#fig_5">6</ref>. The results in Figure <ref type="figure" target="#fig_5">6</ref> suggest that this model is also wrong. The only feature in the observed data that this model accounts for is a positive slope greater than that of the predicted Fitts movement time. The model accounts for no other features in the observed data. Shorter menus are not faster. The slope of the predicted data is too steep.</p><p>The selection time for serial position 1 is not higher than for serial position 2. This model does not account for the observed data.</p><p>The prediction has a slope resulting from more than just the mouse movement, but the predicted slope is too steep, about 380 msec per item as opposed to about 100 msec per item in the observed data. The discrepancy between the predicted and observed data results from all of the processing that must take place before moving the gaze to the next menu item. The slope of approximately 380 msec results because this is the time required for EPIC to move the eye, perceptually process a menu item, move the features to working memory, and decide on an item. Serially processing each item cannot produce a slope of 100 msec per item. Only by processing multiple items at once can a model produce such a small slope.</p><p>The results provided by the serial processing models provide strong evidence that, when scanning a menu, people process more than one menu item at a time. The serial processing models asserted by <ref type="bibr">Norman [12]</ref> and Vandierendonck, <ref type="bibr">Van Hoe,</ref><ref type="bibr">and De Soete [14]</ref> are highly implausible.</p><p>Menu selection models should take this human capability into consideration.</p><p>The remaining models presented in this paper utilize parallel processing of menu items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel Processing Models</head><p>The parallel processing models represent a belief that people move their gaze across the menu as quickly as their perceptual-cognitive-motor processes allow, process the features of all objects that appear in the fovea in parallel using a "pipeline" facility to continue recognition even after the gaze has shifted away, and at the same time continually check working memory to see if the target item has yet been seen. As soon as the target item has been located, the person moves their gaze to it and clicks on it. In one of the parallel processing models, people search randomly for the target; in the other, they start at the top and scarI down the menu.</p><p>Both parallel processing models were run with different eyeto-screen distances that resulted in one and three items fitting into the fovea simultaneously.</p><p>When more than one item is visible in the fovea, all of those objects' features are sent to working memory in parallel. To prevent a random eye "movement" to essentially the same location while searching, both models choose the next item to look at from outside the fovea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel Praceasing Random Search Model</head><p>The Parallel Processing Random Search model was inspired by <ref type="bibr">Card [3]</ref>, who proposed that a random search model could account for menu selection times observed in an experimental task.</p><p>Card concluded that people randomly decide which item in the menu to examine next. But note that Card's task was not a search task in which subjects are precued with the target item before timing starts. Rather, in Card's task the target item appeared above the menu at the same time that the menu itself appeared and at the same time that the clock started, perhaps combining a matching task with a search task. In Nilsen's task, modeled here, subjects were precued and could commit the target item to memory before initiating the timed portion of the trial. These are arguably different tasks, with Nilsen's more closely resembling a menu task in which the user knows the target item before opening the menu.</p><p>Figure <ref type="figure">7</ref> shows a flowchart that represents the production rules built in EPIC to investigate the possibility that subjects used a Parallel Processing Random Search strategy.</p><p>To prevent a random eye "movement" to essentially the same location, the model chooses the next item from among all items currently outside the fovea. The predictions tlom the Parallel Processing Random Search model have some features that correspond to the observed data, but also have some problems.</p><p>As can be seen in Figure <ref type="figure" target="#fig_9">8</ref> (top graph), when one item at a time is visible in the fovea, the model accounts for shorter menus being faster, but no other features of the observed data.</p><p>The overall predicted times are, however, significantly lower than in the Serial Processing Random Search model discussed above.</p><p>As can be seen in Figure <ref type="figure" target="#fig_9">8</ref> (bottom graph), when three items are visible in the fovea simultaneously, the model can account for some features of the observed data Shorter menus are faster, and about the right amount faster, as is shown by the distance between the predicted lines approximating the distance between the observed lines. The predicted values fall entirely within the range of the observed values. Most importantly, this model accounts for serial position 1 being higher than serial position 2. However, the overall slope is still too small.</p><p>In Figure <ref type="figure" target="#fig_9">8</ref> (bottom graph), both the first and last serial positions are higher because the model combines random search with three menu items fitting into the fovea. Items at both ends of the menu have a lower probability of being in the fovea after any random fixation. Any of the middle menu items can be foveated by moving the eye to that item, or to either of the two adjacent items. But the first and last items only have one adjacent item. This might explain serial position 1 being higher than serial position 2 in the observed data.</p><p>The predictions from the Parallel Processing Random Search model suggest that the model is partly correct, and partly incorrect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel Processing Systematic Search Model</head><p>Figure <ref type="figure" target="#fig_8">9</ref> is a flowchart that represents the production rules built in EPIC to investigate the possibility that subjects used a Parallel Processing Systematic Search strategy. Though other systematic searches are possible, top-tobottom is the one most commonly proposed.</p><p>In this model, the first eye movement is made to any of the items that are within one foveal radius from the topmost item (to insure the first gaze captures the topmost item). Each subsequent movement is made to an item one foveal diameter below the center of the current fixation. These details represent the belief that, when using a systematic search strategy, people attempt to maximize the foveal coverage with a minimum number of eye movements.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ssrisl Position</head><p>Fi@_e 10. Selection times observed (solid lines) and predicted (dashed lines) by the Parallel Processing Systematic Search model run with one item (top graph) and three iterns (bottom graph) fitting into the fovea. h each graph, the predicted times for the same serial position in dl~erent length menus are the same and are thus supen"mposed.</p><p>The predictions from the Parallel Processing Systematic Search model have some features that correspond to the observed, but also have some problems.</p><p>As can be seen in Figure <ref type="figure" target="#fig_0">10</ref> (top graph), when one itern at a time is visible in the fovea, the model only accounts for a positive slope. The model does not predict that shorter menus will be faster, the slope is too steep, and serial position 1 is not higher.</p><p>As can be seen in Figure <ref type="figure" target="#fig_0">10</ref> (bottom graph), when three items are visible in the fovea simultaneously, the model can account for important features of the data. The slope is correct and the predicted values fall entirely within the range of the observed values. But again, the model does not account for shorter menus being faster, and serial position 1 is not higher.</p><p>These results show that the Parallel Processing Systematic Search model can partially explain how the subjects accomplished the task, but not account for all aspects of the observed data.</p><p>None of the models presented thus far can account for all of the features in the observed data. The serial processing models account for essentially none of the features of the observed data. But all features of the observed data are accounted for bv at least one of the various Darallel processing modefi, as shown in Figure <ref type="figure" target="#fig_0">11</ref>. " -Slope is too small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Strategy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Systematic</head><p>-Slope is too big.</p><p>-Serial position 1 -Serial position 1 is not higher.</p><p>is not higher. -Slope is too small. + Slope is correct.</p><p>+ S&amp;\position 1 is -Serial position 1 is not higher.</p><p>Figure 11. Summary of how the parallel processing models account for (+) and do not account for (-) features in the observed data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hvbrid Models</head><p>Me hybrid models represent a belief that, when Nilsen ran his experiment, 1) subjects used both random and systematic search, and 2) screen-to-eye distance varied acrosi trials. These models were motivated by observing, as shown in Figure <ref type="figure" target="#fig_0">11</ref>, that all of the features in the observed data are accounted for by at least one of the parallel processing models when run one or three items fitting into the fovea. The random search model accounts for faster selection times in shorter menus. When three items tit into the fovea, the random search model also accounts for serial position 1 being higher. The systematic search model accounts for the correct slope when three items fit into the fovea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Strategy Hybrid Model</head><p>The Dual Strategy Hybrid model represents the belief that subjects processed menu items in parallel in all of the observed trials, but that subjects searched randomly in half of the trials and systematically in half of the trials. Such a model could accurately account for the observed data if 1) some subjects searched randomly and others systematically, or 2) subjects varied their search strategy from trial to trial. Since the observed data were averaged across subjects and blocks, either scenario would produce the same results. * 22-27 MARCH 1997</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PAPERS</head><p>Predictions from this hybrid model can be obtained in two ways. The first is to build a set of EPIC production rules that contain the rules from both the Parallel Processing Random Search strategy and the Parallel Processing Systematic Search strategy; the strategy would randomly choose which search strategy to use at the start of each trial.</p><p>The second is to average the predicted values produced by running the two models independently. Since both approaches would produce the same predictions, the second approach was chosen for expedience. Figure <ref type="figure" target="#fig_11">12</ref> shows the results of this model, as determined by taking an unweighed average of the results shown in Figure <ref type="figure" target="#fig_9">8</ref> and Figure <ref type="figure" target="#fig_0">10</ref>. As can be seen in Figure <ref type="figure" target="#fig_11">12</ref> (top graph), when one item fits into the fovea, the model accounts for faster selection times in shorter menus and produces a near-perfect slope. But the model does not account for the higher selection time in serial position 1, and overall the predicted values are higher than the observed values.</p><p>As can be seen in Figure <ref type="figure" target="#fig_11">12</ref> (bottom graph), when three items fit into the fovea, the model accounts for faster selection times in shorter menus, produces a comparable slope, accounts for the higher selection time in serial position 1, and predicts values that are in range of the observed data. The only shortcoming of this model is that the predicted values do not exactly match the observed values.</p><p>The predictions from the Dual Strategy Hybrid model suggest that the model is almost correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Strategy Varying Distance Hybrid Model</head><p>The Dual Strategy Varying Distance Hybrid model represents a belief that subjects performed the menu selection task as asserted by the Dual Strategy Hybrid model and that the screen-to-eye distance varied across trials. Since this distance was not controlled or measured during the experiment, it is very likely that some subjects sat closer to the computer screen than others, and that subjects moved nearer to and further from the screen during the course of the experiment.</p><p>Predictions from this hybrid model can be obtained in two ways. The first is to build a task environment that varies the screen distance from trial to trial, and to run a set of production rules developed for the Dual Strategy Hybrid model using this task environment.</p><p>The second is to average the predicted values produced by running the Dual Strategy Hybrid model in two task environments, each with a fixed screen-to-eye distance. Since both approaches would produce the same predictions, the second approach was chosen for expedience. Figure <ref type="figure" target="#fig_12">13</ref> shows the results of this model, as determined by taking a weighted average of the results shown in the two graphs in Figure <ref type="figure" target="#fig_11">12</ref>, with 15% from the top graph (one item in fovea) and 85% from the bottom graph (three items in fovea). The Dual Strategy Varying Distance Hybrid model accounts for all of the features in the observed data, As can be seen in Figure <ref type="figure" target="#fig_12">13</ref>, the model predicts the observed values very well (rz = 0.99).</p><p>Matching the observed values, the Dual Strategy Varying Distance Hybrid model offers a highly plausible explanation of the task environment and strategies used by subjects in Nilsen's experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>The models presented here provide evidence that 1) people do not stop and decide on menu items individually, but rather process many items in parallel, and 2) people search menus using both systematic top-to-bottom and random visual search strategies. The models presented here provide a plausible explanation of the low-level perceptual, cognitive, and motor processing that people use when they select an item from a menu. Having validated aspects of these models with empirical data, these models provide strong evidence that previously asserted serial processing theories <ref type="bibr">[12,</ref><ref type="bibr">14]</ref> are incorrect, and that there is an element of truth to both previously asserted random search models (such as in <ref type="bibr">[3]</ref>) and previously asserted systematic search models (such as in <ref type="bibr">[9]</ref>). Perhaps unmeasured or unreported factors in the experiments biased subjects in one experiment towards random search and in another experiment towards systematic search, thus giving rise to these conflicting theories, FUTURE WORK Future plans include to attempt to explain Nilsen's observed data for ordered menus with an ordered menu selection model. Also looking to the future, successfidly modeling menu search provides evidence that a general purpose tool for evaluating the efficiency of visual aspects interfaces might be feasible. The tool would take as its input a definition of a screen layout and a task. The tool would provide as output a prediction of the time required for the user to execute the task. Previous researchers have set a precedent that such a tool can be built <ref type="bibr">[10,</ref><ref type="bibr">13]</ref>. Such a tool would analyze screen layouts and predict the cognitive effort required by a user to extract the information needed to accomplish a task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Subset of EPIC architecture, showing flow of information and control. The processors run independently and in paraIlel. Not shown: Auditory and vocal motor processors, task environment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Nilsen's task with six items in the menu.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 Figure 3 .</head><label>33</label><figDesc>Figure 3 shows Nilsen's observed data, averaged across subjects and blocks, as well as the time required to move the mouse to each position as predicted by Fitts' law (Welford's form of Fitts' law, see [4], Ch. 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Norman's [12] information processing model for search of an explicitly known target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Selection times observed (solid lines) and predicted (dashed lines) by the Serial Processing Random Search model run with one item fitting into thefovea.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Selection times observed (solid lines) and predicted (dashed lines) by the Serial Processing Systematic Search model run with one item fitting into the fovea. The predicted times for the same serial position in dl~erent menu lengths are the same and are thus superimposed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Figure 7. Parallel Processing Random Search model. The results from running the Parallel Processing Random Search model are shown in Figure 8. Each predicted selection time is averaged from 300 trials run for that menu length and serial position combination.3000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>t</head><label></label><figDesc>MOvm mouaa ard gaze to item.Cfii mouaa.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Parallel Processing Systematic Search model, The results from running the Parallel Processing Systematic Search model are shown in Figure 10. Each predicted selection time is averaged from one trial run for each possible combination of menu length, serial position, and first eye movement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8</head><label>8</label><figDesc>Figure 8 (top graph)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure</head><label></label><figDesc>Figure 8 (bottom graph) Figure 10 (bottom graph] + :t:rer menus are -Shorter menus are not faster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12</head><label>12</label><figDesc>Figure 12 Selection times observed (solid lines) and predicted (dashed lines) by the Dual Strategy Hybrid model, with one item (top graph) and three items (bottom graph) fitting into the fovea. The predictions horn the Dual Strategy Hybrid model can account for most of the features in the observed data, but do not fit the observed values perfectly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Selection times observed (solid lines) and predicted (dashed lines) with a Dual Strategy Varying Distance Hybrid model, with 15% of the trials at a one-item-in-fovea distance, and 85% of the trials at a three-items-in-fovea dirtance.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Many thanks to Erik Nilsen for providing additional details on his experiment and generously sharing a copy of the menu soflware used in his experiment. This work was supported by the Advanced Research Projects Agency under order number B328, monitored by NCCOSC under contract number N6600 1-94-C-6036 awarded to David Kieras.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Psychology</head><p>of Human-Computer Interaction.</p><p>Hillsdale, NJ: Lawrence Erlbaum Associates.  <ref type="bibr">Kieras, D. E., &amp; Meyer, D, E. (1995)</ref>. An overview of the EPIC architecture for cognition and performance with application to hurrim-computer interaction (EPIC Tech. Rep. No. 5, TR-95/ONR-EPIC-5).</p><p>Ann Arbor, Michigan: Department of Electrical Engineering and Computer Science.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kieras, D. E., &amp; Meyer, D. E. (in press</head><p>). An overview of the EPIC architecture for cognition and performance with application to human-computer interaction.</p><p>Human-Computer Interaction.</p><p>Laird, J., Rosenbloom, P., &amp; Newell, A. <ref type="bibr">(1986)</ref>.</p><p>Universal subgoaling and chunking.  <ref type="bibr">Psychological,</ref><ref type="bibr">69(3),</ref><ref type="bibr">[231]</ref><ref type="bibr">[232]</ref><ref type="bibr">[233]</ref><ref type="bibr">[234]</ref><ref type="bibr">[235]</ref><ref type="bibr">[236]</ref><ref type="bibr">[237]</ref><ref type="bibr">[238]</ref><ref type="bibr">[239]</ref><ref type="bibr">[240]</ref><ref type="bibr">[241]</ref><ref type="bibr">[242]</ref><ref type="bibr">[243]</ref><ref type="bibr">[244]</ref><ref type="bibr">[245]</ref><ref type="bibr">[246]</ref><ref type="bibr">[247]</ref><ref type="bibr">[248]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acts</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Rules of the mind</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Erlbaum</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The acquisition and performance of text editing skill: A cognitive complexity analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bovair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Kieras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Poison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual search of computer command menus</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Attention and Performance X: Control of Lunguage Processes</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Bouma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bouwhuis</surname></persName>
		</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates, Publishers</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="97" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Tke</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
