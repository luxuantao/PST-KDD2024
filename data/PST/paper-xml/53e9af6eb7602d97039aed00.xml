<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ADAM: Run-time Agent-based Distributed Application Mapping for on-chip Communication</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mohammad</forename><forename type="middle">Abdullah</forename><surname>Al Faruque</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rudolf</forename><surname>Krist</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jörg</forename><surname>Henkel</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Karlsruhe</orgName>
								<orgName type="institution" key="instit2">Chair for Embedded Systems</orgName>
								<address>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Anaheim</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ADAM: Run-time Agent-based Distributed Application Mapping for on-chip Communication</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B079E46A2A7286D452FCB61A17EA08F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C.3[Special-purpose and application-based systems]: Real-time and embedded systems Algorithms</term>
					<term>Design Agent-based application mapping</term>
					<term>On-chip communication</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Design-time decisions can often only cover certain scenarios and fail in efficiency when hard-to-predict system scenarios occur. This drives the development of run-time adaptive systems. To the best of our knowledge, we are presenting the first scheme for a runtime application mapping in a distributed manner using agents targeting for adaptive NoC-based heterogeneous multi-processor systems. Our approach reduces the overall traffic produced to collect the current state of the system (monitoring-traffic), needed for runtime mapping, compared to a centralized mapping scheme. In our experiment, we obtain 10.7 times lower monitoring traffic compared to the centralized mapping scheme proposed in [8] for a 64×64 NoC. Our proposed scheme also requires less execution cycles compared to a non-clustered centralized approach. We achieve on an average 7.1 times lower computational effort for the mapping algorithm compared to the simple nearest-neighbor (NN) heuristics proposed in <ref type="bibr" target="#b6">[6]</ref> in a 64 × 32 NoC. We demonstrate the advantage of our scheme by means of a robot application and a set of multimedia applications and compare it to the state-of-the-art run-time mapping schemes proposed in <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b19">19]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION AND RELATED WORK</head><p>Intel projects the availability of 100 billion transistors on a 300mm 2 die by 2015 <ref type="bibr" target="#b4">[4]</ref> which allows to integrate thousands of processors or equivalent logic gates on a single die. Heterogeneous Processing Elements (PEs), i.e. different types of instruction set processors or reconfigurable hardware on such an architecture, are proposed for building an energy-efficient system <ref type="bibr" target="#b19">[19]</ref>. Besides the low power concern regarding computation, communication in such an architecture is another dominant factor since a scalable but light-weight communication infrastructure is needed on-chip <ref type="bibr" target="#b4">[4]</ref>. This motivates toward the development of a tile-based heterogeneous Multiprocessor System on Chip (MPSoC) interconnected by a Network on Chip (NoC) <ref type="bibr" target="#b1">[1,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b13">13]</ref>. In general, all related work proposes to design an application-specific system where the parameters for the fabricated chip are adjusted at design time.</p><p>The more complex a system grows the more it must be able to handle those situations efficiently that are unpredictable at design time. In this case the system needs to adapt itself to the new situation and therefore, the System on Chip (SoC) needs to be designed with the capability of self-adaptiveness in mind. Self-adaptation in SoC design is relatively new. The idea of adaptivity in future SoC design is introduced in <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b14">14]</ref>. Taking the same spirit into NoC-based architecture design, we are the first to propose an adaptive on-chip communication scheme into <ref type="bibr" target="#b11">[11]</ref>. An adaptive system needs to map the tasks of an application to various PEs at run-time without interfering the currently executing applications. To do this in a transparent way is a challenging research topic.</p><p>To solve the problem of mapping tasks to respective processing elements, several design-time (off-line) mapping algorithms have been proposed in related work. In <ref type="bibr" target="#b15">[15]</ref>, Branch and Bound-based, in <ref type="bibr" target="#b16">[16]</ref> Genetic Algorithm-based, and in <ref type="bibr" target="#b12">[12]</ref> heuristic-based mapping algorithms are proposed. But an adaptive system that changes its configuration over time requires a re-mapping/run-time mapping of applications. Possible reasons for the necessity of a run-time mapping are listed in Section 2. In <ref type="bibr" target="#b19">[19]</ref> the authors extend the Min-Weight algorithm proposed in <ref type="bibr" target="#b5">[5]</ref> for solving the problem of runtime task assignment on heterogeneous processors. The task graphs are restricted to a small number of vertices or a large number of vertices with a degree of no more than two. Authors in <ref type="bibr" target="#b6">[6]</ref> investigate the performance of several mapping heuristics promising for runtime use in NoC-based MPSoCs with dynamic workloads, targeting NoC congestion minimization. The work presented in <ref type="bibr" target="#b8">[8]</ref> proposes an efficient technique for run-time application mapping onto a homogeneous NoC platform with multiple voltage levels. Their work is limited to a homogeneous architecture. A separate control network besides the data network is used which represents an extra overhead in terms of area and energy consumption. The state-ofthe-art run-time mapping work <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b19">19]</ref> has used a Centralized Manager (CM) for conducting the job of mapping which is not scalable in the context of hundreds or even thousands of cores that may soon be integrated on a SoC. It suffers from a single point of failure, larger volume of monitoring traffic<ref type="foot" target="#foot_0">1</ref> , central point of communication around the CM (hot-spot), and scalability issues.</p><p>The concept of task migration is an integral part of the run-time application mapping. The study of task migration to move a currently executing task between different processors which are connected by a network has already been a research focus in the distributed and parallel computing domain <ref type="bibr" target="#b20">[20]</ref>. Now it is used to facilitate run-time application mapping in adaptive heterogeneous MPSoCs. Work presented in <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b17">17]</ref> discuss the issues related to the task migration for MPSoC design, i.e. the cost to interrupt a given task, save its context, transmit all data to a new IP, and restart the task in the new IP. In our work we use this approach though the details of task migration are out of the scope of this paper.</p><p>The rest of the paper is organized as follows: In Section 2, we present our motivation and novel contribution. In Section 3, we introduce our ADAM architecture whereas in Section 4, our novel clustering algorithm and agent-based run-time application mapping are explained in detail. Experimental results are discussed in Section 5 with Section 6 concluding the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MOTIVATION AND NOVEL CONTRIBU-TIONS</head><p>Let us motivate the need of an agent-based distributed application mapping for NoCs by means of a simple scenario. We study a 32 × 32 NoC with a mesh topology. Some events that may require a re-mapping at run-time for an adaptive system where design-time mapping algorithms fail are given below:</p><p>• On-line detection of hardware faults. • To minimize run-time system costs (i.e. to save energy because of the low battery status). • When the user requirements change, e.g. the user wants to switch video playback to a higher resolution.</p><p>• When an adaptive system tries to configure the underlying NoC infrastructure (i.e. changing the routing algorithm and the buffer assignment) and if it fails, then the mapping instance of the application needs to be changed <ref type="bibr" target="#b11">[11]</ref>.</p><p>State-of-the-art run-time mapping is handled using a Centralized Manager (CM) which may bear the following problems:</p><p>• Single point of failure.</p><p>• Higher computational cost to calculate mapping inside CM.</p><p>• Large volume of monitoring-traffic.</p><p>• Point of hot-spot as every tile sends the status of the PE to the CM after every instance of mapping. It increases the chance of bottleneck around the CM.</p><p>To solve the problem of a static design-time mapping algorithm which may require a high computational effort, we need a scheme that can perform a low-cost (execution time) mapping scheme inside a virtual cluster (see Def.</p><p>3) constructed at run-time. We solve the problems of a centralized mapping scheme by using a distributed mapping inside each virtual cluster. This distributed mapping is accomplished by software modules that are autonomous, modifiable, and exhibit adaptation capabilities. To the best of our knowledge we are the first to design an agent-based distributed application mapping for a NoC platform. The system is analyzed during run-time and self-adapts in terms of when and how a mapping algorithm should be invoked. Our novel contributions are as follows:</p><p>(1) We provide a run-time agent-based distributed mapping algorithm for next generation self-adaptive heterogeneous MPSoCs. Our mapping algorithm is composed of two main parts: (a) virtual cluster selection and cluster reorganization at run-time, and (b) a mapping algorithm inside a cluster at run-time.</p><p>(2) We propose a run-time cluster negotiation algorithm that generates virtual clusters to solve the problems of the centralized mapping algorithm.</p><p>(3) We present a low cost heuristic-based mapping algorithm in terms of execution cycles on any instruction set processor that minimizes the communication related energy consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">OUR ADAM SCHEME</head><p>In the following we introduce our run-time Agent-based Distributed Application Mapping (ADAM) for a heterogeneous MP-SoC with a NoC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Some Definitions</head><p>Definitions necessary to explain our run-time ADAM concept are described in the following: Definition 1: An application communication task graph (CTG) is a directed graph G k = (T, F ), where T is a set of all tasks of an application and fi,j ∈ F is a set of all flows between connected tasks ti and tj annotated by the inter-task bandwidth requirement. Definition 2: A heterogeneous MPSoC architecture in a NoC platform HMP SoCNoC is a directed graph P = (N, V ), where vertices N is a set of tiles ni and vi,j ∈ V present an edge, the physical channel between two tiles ni and nj. A tile , ni ∈ N is composed of: a heterogeneous PE, a network interface, a router, local memory and a cache. Definition 3: A cluster is a subset Ci ⊆ N , where N is the set of tiles nj that belong to the HMP SoCNoC and a virtual cluster Cvi, is a cluster where there are no fixed boundaries to decide which tiles are included and which tiles are not. It can be created, resized and destroyed at run time. Definition 4: An agent Ag is a computational entity, which acts on behalf of others. The construction of an agent is motivated from <ref type="bibr" target="#b3">[3]</ref> where agents are used for distributed network management. The properties of an agent in our scheme are: an agent (1) is a smaller task closer to the system, (2) it must do resource management, (3) it may need memory to store state information for the resources, (4) it must be executable on any processing element, (5) it must be migratable, <ref type="bibr" target="#b6">(6)</ref> it must be recoverable, and <ref type="bibr">(7)</ref> it may be destroyed if the cluster no longer exists. An agent-based mapping scheme provides a flexible framework for run-time mapping because it has the negotiation capability among the clusters distributed over the whole chip and it is not dependent on the design-time parameters (see above properties).  Definition 5: A cluster agent CA ∈ Ag is an agent that is responsible for mapping operations within the cluster Ci. The cluster agent is located in the processing element p C i j where the index j of pj denotes that the cluster agent can be mapped to any PE of the cluster. The CA stores the information about the cluster that the agent is responsible for (see Table <ref type="table" target="#tab_4">1</ref>, 2). Definition 6: A global agent GA is an agent that stores the information for performing the mapping operations to a selected cluster. It stores information regarding the current usage of communication and computation resources for each cluster and this information is used for selection and re-organization of the clusters (see Table <ref type="table" target="#tab_4">1</ref>). GA is movable and the stored information is light-weight and easily recoverable (there are multiple instances of the global agents). Definition 7: The application mapping function is given by m : T ti → nj ∈ N and the run-time mapping function mrun maps the instance of task graph set Gt at time t to HMP SoCNoC. Definition 8: A binding is a function b : T ti → tpPE ∈ T ps, where T is the set of all tasks of an application and T ps is the set of the PE types that are used on the HMP SoCNoC. The function assigns each task ti of the CTG to a favorable type of PE. After the binding operation is completed, the tasks are allowed to be mapped only to PEs of the type given by the binding function b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The ADAM Flow</head><p>An overview of our ADAM system is presented in Fig. <ref type="figure" target="#fig_0">1</ref>. The run-time mapping in our scheme is achieved by using a negotiation policy among Cluster Agents (CAs) and Global Agents (GAs) of a certain instance of time distributed over the whole chip. In Fig. <ref type="figure" target="#fig_0">1</ref> an application mapping request is sent to the CA of the requesting cluster which receives all mapping requests and negotiates with the GAs. There can be multiple instances of the GAs that are synchronized over time. The GAs have global information about all the clusters of the NoC in order to make decisions onto which cluster the application should be mapped to. Possible replies to this mapping request are:</p><p>1. When a suitable cluster of the application exists then the GAs inform the requesting source CA and the requesting source CA asks the suitable destination CA for the actual mapping of the application. 2. When no suitable clusters are found by the GAs then the GAs report the next most promising cluster where it is possible to map the application to after task migration which is negotiated between the GA and the CA to make this cluster suitable for the mapping. The number of iterations is a configuration parameter.</p><p>3. When neither a suitable cluster nor a candidate cluster for task migration are found, then the re-clustering concept is used. It tries to acquire PEs from the neighboring clusters (see Subsection 4.1). If the requirements are met after reclustering then the application may be mapped to that cluster. This step is iterated for a number of times specified by the configuration. If all the above-mentioned options do not lead to a successful mapping (the application and the system constraints are not met), then the mapping request is refused and reported to the requester. The requester waits until some resources are freed to proceed with the mapping. In the next section the detailed description of the runtime mapping algorithm using our ADAM concept is presented.  </p><formula xml:id="formula_0">Algorithm 1 Suitable cluster negotiation input: CT G, {nhistc[] | c is cluster} (a),(f) output: c, b[] (suitable</formula><formula xml:id="formula_1">[ti] = mintp j {E(tpj, ti) = u(tpj, ti) • (E [100] (tpj) - E [0] (tpj)) + E [0] (tpj)} // initial binding, // min. energy (d) 3: u[b[ti]] = u[b[ti]] + u(b[ti], ti) // columns of res. // req. profile (c) 4: k = u(tpj, ti) • n cl 5: thist[b[ti], k] = thist[b[ti], k] + 1<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ALGORITHM FOR RUN-TIME MAPPING</head><p>In this section we present our detailed algorithm of run-time Agent-based Distributed Application Mapping (ADAM) which has the following two (1) a cluster negotiation algorithm and (2) a mapping algorithm inside a virtual cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Cluster Negotiation Algorithm</head><p>Here we present our run-time suitable cluster negotiation algorithm (see Alg. 1). The algorithms (Alg. 1 and Alg. 2) have the following important input and output data objects:</p><p>• The application CTG, G with required computational resource profiles for each task. G is given by a set of entries for each flow: entry = (idsrc, id dst , bwreq, lat, RRtp). Here, idsrc and id dst are the id of the source and destination task of the flow, respectively bwreq is the required bandwidth of the flow, lat is the communication latency and RRtp is the resource requirement on each PE type that is needed for a task to ensure a successful execution.  ∀i ∈ 1, .., n cl -1 :</p><formula xml:id="formula_2">n cl -1 X j=n cl -i thist[tp, j] ≤ i X j=1 nhistc[tp, j] (1)</formula><p>In Fig. <ref type="figure" target="#fig_1">2</ref> we present an example of the cluster searching procedure. The task graph of an application that is requested to be mapped is shown in Fig. <ref type="figure" target="#fig_1">2(a)</ref>. The energy consumed by various PE types in different resource requirement levels is given in 2(b) and it is used to calculate the actual required energy consumption for every task on different types of PEs (see 2(d)). The resource requirements of the tasks is given in 2(c). Using the tables 2(c) and 2(d) the minimum energy binding for the tasks of the application is derived. Using the task binding, Fig. <ref type="figure" target="#fig_1">2</ref>(e) shows the resource requirement profile to create a histogram corresponding to the data object thist[]. Fig. <ref type="figure" target="#fig_1">2</ref>(f) presents the histogram nhistc[] for a cluster. In this example task 2 needs to be rebound to a new PE type to find a suitable cluster which has better energy consumption during the algorithm execution. Finally, Fig. <ref type="figure" target="#fig_1">2</ref>(g) presents the new binding and the selection of the cluster. The complexity of our cluster negotiation algorithm is O(m + r • log r) where m is the number of tasks and r is the number of virtual clusters. Due to the low complexity, this part of our approach is suitable to be applied at run-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connected tiles Cluster agent</head><p>Source tile Destination tile  In case a suitable cluster cannot be found in Alg. 1, it starts looking for the clusters which support task migration. Task migration 2 as an integral part of our run-time mapping algorithm is demonstrated in Fig. <ref type="figure" target="#fig_3">3</ref>. The parent task sends a migration request to the CA and upon receiving the request it freezes the source tile, tiles connected to the source, and the destination tile for successful and transparent migration. Then, the migration is performed with all local data within the executing task, the state of the task and even the modified binary of the task (the binary of the application may need to be changed to make it executable for different instruction set processors). The feedback is then provided to the CA. Figure <ref type="figure">4</ref>: The re-clustering algorithm flow When the migration of tasks does not deliver a suitable cluster, then the re-clustering operation shown in Fig. <ref type="figure">4</ref> is invoked. First negotiation is done between neighboring clusters to see if there are some unoccupied PEs that can be given away to the requesting cluster. If no unoccupied PEs are available, the neighbors are requested to migrate tasks from some PEs to other PEs of that cluster without losing its performance and run-time constraints. If that is not successful either, then the neighboring cluster is requested for the least utilized PEs that may be shared with the requesting cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Mapping Algorithm</head><p>Our run-time mapping algorithm inside a cluster managed by the CA is motivated by the static mapping algorithm presented in <ref type="bibr" target="#b12">[12]</ref> as it is light-weight in terms of execution cycles and provides a near-optimal mapping solution. The given algorithm is executed once at design time. But for using the algorithm at run-time it needs to be modified to keep the current instance of the mapping. It is then executed in the background reacting to mapping requests 2 Details of task migration are not discussed in the scope of this paper. Our scheme uses the approach presented in <ref type="bibr" target="#b17">[17]</ref>  whenever the current instance of the mapping needs to be modified. The pseudo code of the run-time mapping algorithm inside each cluster is presented in Alg. 2. The input data is the CTG of the application and the model tile LU T,clu of the HMP SoCNoC that stores the current state of the used computation and communication resources of that particular cluster. The CTG contains the required energy consumption for each task to be executed on a particular PE type. The task binding is done in the cluster negotiation step with the GAs before the mapping step inside a virtual cluster. The CTG contains the communication costs for each flow fij between the tasks ti and tj. The tile-LUT tile LU T,clu contains each tile's current computation resource usage, the type of the PE of this tile tpPE, and the current bandwidth usage for each link. The output (mpng) is the mapping of tasks to tiles of the network which is used to allocate the tiles physically on the network and to update the tile LU T,clu by the added application.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5: Run-time application mapping example</head><p>To decide to which tile of a particular PE type a task should be mapped, a heuristics is used, described by the cost function c(t, n), for the selection of a tile nj for a given task ti.</p><formula xml:id="formula_3">c(ti, nj) = α(D(nj)+bwt(nj)+RR(nj))+β X k∈Tcon,m d(k)vol(k) where, D(n) = 1 #tiles clu P l∈N d(n, l): D(n)</formula><p>is the average distance of a tile to all other tiles of the cluster, d(n, l) is the Manhattan distance between tiles n and l, Tcon,m is the set of all connected and mapped tasks ti, d(k) is the Manhattan distance between the mapped tasks, vol(k) is the communication between the connected tasks, RR(nj) is the resource requirement of the PE that will be assigned for the task, and bwt(nj) is the total bandwidth requirement of the tasks on the tile.</p><p>In the following, Alg. 2 is explained using an example (see Fig. <ref type="figure">5</ref>). In Fig. <ref type="figure">5</ref> (a) we present a task graph, whose tasks are grouped by the binding function (shown in different colors) in the earlier negotiation stage. In 5 (b) a part of the tiles of the current cluster is presented, 5 (g) shows the current resources in use of some of these X * Cycles ADAM (Our Scheme) ADAM (Our Scheme) centralized NN (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized NN (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized MAC (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized MAC (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized PL (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized PL (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized NN (app. from <ref type="bibr" target="#b6">[6]</ref>) ADAM (Our Scheme) ADAM (Our Scheme) centralized NN (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized NN (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized MAC (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized PL (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized MAC (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized MAC (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized PL (app. from <ref type="bibr" target="#b6">[6]</ref>) centralized PL (app. from <ref type="bibr" target="#b6">[6]</ref>) Figure <ref type="figure">6</ref>: Computation complexity of mapping compared to <ref type="bibr" target="#b6">[6]</ref> tiles and 5 (f) presents the computational resource requirements for each task of the task graph. In this example the availability of the resources is presented by the ordered column in a table (Fig. <ref type="figure">5 (d)</ref>). In Fig. <ref type="figure">5</ref> (e) we see the first set of flows f tp 2 that connect PEs of PE type 2: {f12, f13, f34}. The flows are sorted in a decreasing order according to their bandwidth requirements. The result of a successful mapping is illustrated in Fig. <ref type="figure">5 (c</ref>). To achieve a mapping instance we iterate the set of flows and select tiles where the previously un-mapped tasks connected by the flows will be mapped. Then the algorithm continues with the next set of flows f tp 1 that are connected to PEs of type 1. The complexity of our mapping algorithm is O(m • log m + m • n) where m is the number of tasks and n is the number of tiles in a particular cluster. The complexity is low compared to the heuristics in <ref type="bibr" target="#b6">[6]</ref> when it is used in a distributed manner. This fact is verified in the result section (see Fig. <ref type="figure">6</ref> We study which data objects are needed by the mapping algorithms and what kind of filtering mechanism may be used to reduce the amount of data stored in the GAs. The state information about the tiles and the links of the HMP SoCNoC have to be stored by agents on different levels (GAs, CAs). CAs will need the fine grained information about the cluster to provide the distributed mapping shown in Table <ref type="table" target="#tab_4">1</ref> and<ref type="table" target="#tab_6">2</ref>. Table <ref type="table" target="#tab_4">1</ref> contains the histogram of computational resource requirements of the PEs. For each cluster there is also an instance of this PE type LUT stored in the GA. The filtering process is as follows: (1) using the "raw" data from the data object described by Table <ref type="table" target="#tab_6">2</ref>, (2) calculating the information stored in data object described by Table <ref type="table" target="#tab_4">1</ref>, and (3) transmitting this data from the CAs to the GAs. Another data object stored within each CA is the variable mpng, a LUT shown in Alg. 2. The structure of each entry within this LUT consists of the id of the source task, destination task, assigned tile, application, resource requirements for execution, communication volume, and the required latency.</p><p>The run-time flexibility of the mapping algorithm compared to a design-time static mapping algorithm comes at some extra penalties: near-optimal mapping solution (Fig. <ref type="figure" target="#fig_7">8</ref>), extra computation at run-time (Fig. <ref type="figure">6(b</ref>)), additional traffic to collect information about the current state of the chip (Fig. <ref type="figure">7</ref>), and finally monitoring infrastructure implemented in each router to collect information about the current state of the MPSoC. Monitoring hardware is already an integral part of our adaptive on-chip communication scheme presented in <ref type="bibr" target="#b11">[11]</ref>. The monitoring module implemented for our adaptive router requires 46 slices on a XILINX Virtex2 FPGA <ref type="bibr" target="#b21">[21]</ref>, an LUT (number of entries × 26 bits), an event input FIFO (5 × 12 bits), and a connection input FIFO (5 × 18 bits). The additional monitoring events for our ADAM scheme are added on top of this existing monitoring infrastructure and therefore, it increases the size of the LUT and FIFO. Detailed description of the monitoring module is out of the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS AND CASE STUDY ANALYSIS</head><p>We have evaluated our ADAM approach using different application scenarios: a robot application (Image Processing Line <ref type="bibr" target="#b18">[18]</ref>), some multi-media applications, and applications from TGFF <ref type="bibr" target="#b10">[10]</ref>. We show the performance in terms of execution time and the volume of the generated monitoring traffic and compare our results to state-of-the-art centralized approaches <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b19">19]</ref>. In addition, we compare our cluster-level mapping algorithm to an exhaustive offline mapping algorithm in order to see how far it is off from an optimum solution.</p><p>In Fig. <ref type="figure">6</ref>(a) we compare our approach to the centralized one <ref type="bibr" target="#b6">[6]</ref>. We have partitioned our mapping computation into several steps shown in Fig. <ref type="figure">6(b</ref>). The configuration parameters for this experiment are as follows: the average cluster size is 64 and the number of tasks is 48. In this experiment the number of cycles to check whether a task can be mapped to a tile is represented by "X" (it may differ depending on the instruction set). We consider that each task has to be checked for a possible assignment to each tile inside a virtual cluster while in the non-clustered approach the tiles of the whole NoC have to be considered. Therefore, our approach can reduce the mapping computation complexity e.g. on a 32x64 system we have an approx. 7.1 times lower computational effort compared to the simple nearest-neighbor (NN) heuristics proposed in <ref type="bibr" target="#b6">[6]</ref>. Fig. <ref type="figure">6</ref>(c) shows that our approach scales in the same way as the non-clustered architecture when we do not consider the clustering approach in our algorithm. ADAM 8x8 (our scheme) ADAM 8x8 (our scheme) centr. 8x8 (app. from <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref>) centr. 8x8 (app. from <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref>) distr. 8x8 distr. 8x8 ADAM 64x64 (our scheme) ADAM 64x64 (our scheme) centr. 64x64 (app. from <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref>) centr. 64x64 (app. from <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref>) distr. 64x64 distr. 64x64 ADAM 32x32 (our scheme) ADAM 32x32 (our scheme) centr. 32x32 (app. from <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref>) centr. 32x32 (app. from <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref>) distr. 32x32 distr. 32x32</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Amount of Data by Each Instance of Mapping</head><p>Figure <ref type="figure">7</ref>: Our ADAM approach compared to approaches <ref type="bibr">[7,</ref><ref type="bibr" target="#b19">19]</ref> Fig. <ref type="figure">7</ref> demonstrates the advantage of our approach when we consider the communication volume generated by the monitoring module of the router needed by the mapping algorithm. We compare our cluster-based distributed approach to a centralized approach <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b19">19]</ref> and a fully distributed approach (each tile acts as an individual cluster). The experimental setup is as follows: number of classes and PE types are 16, resource requirement encoding requires 1 Byte, task id encoding requires 4 Bytes, number of tasks encoding requires 4 Bytes, and bandwidth encoding requires 1 Byte of memory space. To calculate the mapping traffic produced by our approach we need to break down the communication into the following parts: (1) transmission of the task histogram thist[] to the GA, (2) transmission of the task graph to the CA of the suitable cluster, (3) reporting the cluster state to the CA, and (4) transmission of the cluster state to the GA. The experiment shows that our approach has noticeable advantages in reducing the amount of communication volume (10.7 times lower on a 64 × 64 NoC) caused by the mapping when the HMP SoCNoC has many tiles.  In Fig. <ref type="figure" target="#fig_7">8</ref> we present a comparison of the suitability of our clusterlevel mapping algorithm. It shows that our approach does not produce optimum results as they can be produced by the off-line exhaustive algorithm which requires a far higher computational effort. But relative to the consumed computation effort our approach provides a reasonable near-optimal solution. The communication volume serves as the optimization criteria for the mapping algorithm (it reduces the communication related energy consumption <ref type="bibr" target="#b15">[15]</ref>), and we found on an average a deviation of a mere 13.3% compared to the exhaustive mapping algorithm. To make the comparison to the off-line exhaustive mapping algorithm realistic, a homogeneous tile has been considered. The near-optimal result can be used for the run-time task mapping as this result may be traded-off with the adaptivity and the lower computational effort.</p><p>We have also evaluated our mapping algorithm by means of a robot application presented in <ref type="bibr" target="#b18">[18]</ref>. We found in our algorithm the near optimal communication volume to be 120.1 MB/s whereas, in the exhaustive off-line mapping algorithm it can be reduced to 106.9 MB/s. The result is acceptable as we are doing it at run-time using a heuristic algorithm and consuming 2 times lower execution cycles compared to NN heuristics. The Image Processing Line application takes only 11241 × X cycles using our ADAM algorithm orthogonal to any instruction set processor compared to NN heuristics (takes 20480 × X cycles) proposed in <ref type="bibr" target="#b6">[6]</ref> on a 32 × 64 NoC. Therefore, we observe that our run-time agent-based distributed application mapping approach reduces the overall monitoring-traffic compared to a centralized mapping scheme and requires less execution cycles compared to a non-clustered centralized approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>We have introduced the first scheme for a run-time application mapping in a distributed manner using an agent-based approach. We target adaptive NoC-based heterogeneous multi-processor systems. The ADAM scheme generates 10.7 times lower monitoring traffic compared to a centralized scheme like the ones proposed in <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b19">19]</ref> in a 64 × 64 NoC. Our scheme also has a smaller number of execution cycles compared to a non-clustered centralized approach.</p><p>In our experiments we achieve on an average 7.1 times lower computational effort for the run-time mapping algorithm compared to the simple nearest-neighbor (NN) heuristics proposed in <ref type="bibr" target="#b6">[6]</ref> on a 64 × 32 NoC. The flexibility of a run-time adaptive mapping, a 7.1 times lower computational effort and a 10.7 times lower monitoring traffic counterbalance the optimization result compared to an optimized run-time centralized mapping algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Flow of our ADAM approach</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Suitable cluster and binding example The matching of the two data objects nhistc and thist is the heart of Alg. 1 and is given below in Eq. (1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Task migration to support run-time application mappingIn case a suitable cluster cannot be found in Alg. 1, it starts looking for the clusters which support task migration. Task migration 2 as an integral part of our run-time mapping algorithm is demonstrated in Fig.3. The parent task sends a migration request to the CA and upon receiving the request it freezes the source tile, tiles connected to the source, and the destination tile for successful and transparent migration. Then, the migration is performed with all local data within the executing task, the state of the task and even the modified binary of the task (the binary of the application may need to be changed to make it executable for different instruction set processors). The feedback is then provided to the CA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparing ADAM to exhaustive off-line mapping algo.In Fig.8we present a comparison of the suitability of our clusterlevel mapping algorithm. It shows that our approach does not produce optimum results as they can be produced by the off-line exhaustive algorithm which requires a far higher computational effort. But relative to the consumed computation effort our approach provides a reasonable near-optimal solution. The communication volume serves as the optimization criteria for the mapping algorithm (it reduces the communication related energy consumption<ref type="bibr" target="#b15">[15]</ref>), and we found on an average a deviation of a mere 13.3% compared to the exhaustive mapping algorithm. To make the comparison to the off-line exhaustive mapping algorithm realistic, a homogeneous tile has been considered. The near-optimal result can be used for the run-time task mapping as this result may be traded-off with the adaptivity and the lower computational effort.We have also evaluated our mapping algorithm by means of a robot application presented in<ref type="bibr" target="#b18">[18]</ref>. We found in our algorithm the near optimal communication volume to be 120.1 MB/s whereas, in the exhaustive off-line mapping algorithm it can be reduced to 106.9 MB/s. The result is acceptable as we are doing it at run-time using a heuristic algorithm and consuming 2 times lower execution cycles compared to NN heuristics. The Image Processing Line application takes only 11241 × X cycles using our ADAM algorithm orthogonal to any instruction set processor compared to NN heuristics (takes 20480 × X cycles) proposed in<ref type="bibr" target="#b6">[6]</ref> on a 32 × 64 NoC. Therefore, we observe that our run-time agent-based distributed application mapping approach reduces the overall monitoring-traffic compared to a centralized mapping scheme and requires less execution cycles compared to a non-clustered centralized approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>the comp. res. req. when the task t is bound to tp (c) u[tp]: the total comp. res. req. for the PE type in CT G E(tpj, ti): computation energy when task ti is bound to tpj (d) n loop : constant, num. of matching loop iterations</figDesc><table><row><cell>cluster and binding)</cell><cell>(f),(g)</cell></row><row><cell>u(tp, t):</cell><cell></cell></row></table><note><p>1: for all ti ∈ CT G do // min energy binding (d) &amp; // thist calc. &amp; summrz. u(tp) in CT G 2: b</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>•</head><label></label><figDesc>The state information about all clusters are stored in a summarized format by the GAs (Table1and data object nhistc). More detailed information is stored in the CA (Table2).</figDesc><table><row><cell>field</cell><cell>req. memory</cell><cell>short description</cell></row><row><cell>tpPE q_tiles</cell><cell>log 2 #T ps log 2 #Cmax</cell><cell>PE type id, #T ps= #of PE type #Cmax = #of tiles in a cluster</cell></row><row><cell cols="2">r_reqtot log 2 #Cmax q_cl0 log 2 #Cmax . . .</cell><cell>total comp. reso. req. by the PE type #tiles in res. req. class (0, 1 n ] . . .</cell></row><row><cell cols="2">q_cln log 2 #Cmax</cell><cell>#tiles in res. req. class ( n-1 n , 1]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Global agent: entry of the cluster PE type LUT • Energy Model: To make a binding decision (see Def. 8), the amount of energy consumption for different PE types at different resource requirement levels is needed. To explain the energy model we take an example from Fig. 2 (b), where for the PE type tp2 the energy consumption is specified by two values: tp2 : (4X, 12X) that means that each PE of type tp2 consumes 4 units of energy (static energy consumption) in a fixed time when it uses no processing resources and 12 units of energy when it consumes the complete PE resources and otherwise E = u • (E [100%] -E [0%] ) + E [0%] . • thist[] and nhistc[] are two data objects that store the re-</figDesc><table><row><cell>t2 10</cell><cell>3 t1</cell><cell>7</cell><cell>t3</cell><cell>2 3 tpPE 1</cell><cell>4 X 1 X E[0%] 2 X</cell><cell>12 X 17 X E[100%] 11 X</cell><cell cols="2">= 17 X E[100%](tp3)</cell><cell>2 1 task</cell><cell cols="4">33 9 tp1 res. req. by tpPE 16 39 15 12 17 8 tp2 tp3 tp4</cell><cell>2 1 tpPE</cell><cell>1 1 1/5 resource req. by classes 1 1 2 2 1 0 1 15 2/5 3/5 4/5 5/5</cell></row><row><cell></cell><cell></cell><cell></cell><cell>5</cell><cell>4</cell><cell>5 X</cell><cell>21 X</cell><cell></cell><cell></cell><cell>3</cell><cell>51</cell><cell>22</cell><cell>49</cell><cell>21</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>5</cell></row><row><cell cols="2">t5 11</cell><cell></cell><cell>t4</cell><cell cols="3">(b) energy by resource req.</cell><cell></cell><cell></cell><cell>5 4</cell><cell>61 42</cell><cell>55 30</cell><cell>46 45</cell><cell>21 20</cell><cell>4</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>4</cell><cell>4</cell></row><row><cell cols="4">(a) task graph</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">(c) resource req. profile</cell><cell cols="2">(f) PE availability in a cluster</cell></row><row><cell cols="6">energy by tpPE tp2 tp3 tp4 task tp1</cell><cell>tpPE</cell><cell cols="5">1/5 resource req. by classes 2/5 3/5 4/5 5/5</cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell>t1</cell><cell>7</cell></row><row><cell>1 2</cell><cell cols="2">2.81 4.97</cell><cell>4.96 5.04</cell><cell>3.72 7.24</cell><cell>6.28 7.4</cell><cell>1 2</cell><cell>1 0</cell><cell>1 1</cell><cell>1 0</cell><cell>1 0</cell><cell>0 0</cell><cell></cell><cell></cell><cell></cell><cell>t2</cell><cell>3</cell><cell>t3</cell></row><row><cell>3</cell><cell cols="2">6.59</cell><cell>5.76</cell><cell>8.84</cell><cell>8.36</cell><cell>3</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>4 5</cell><cell cols="2">5.78 7.49</cell><cell>6.4 8.4</cell><cell>8.2 8.36</cell><cell>8.2 8.36</cell><cell cols="6">(e) task comp. res. reqirements 4 0 0 0 0 0</cell><cell></cell><cell cols="3">Legend PE type 1 t1 task t1</cell><cell>t5 11</cell><cell>t4</cell></row><row><cell cols="6">(d) energy consumption/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PE type 2</cell><cell>7</cell><cell>flow, with bw</cell><cell>(g) binding</cell></row><row><cell cols="5">min-energy binding</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p><p><p><p>source requirement histograms within the local memory of the CAs and GAs, thist for the required resources for the tasks and nhistc for the actual PE resource usage status of the cluster c (i.e. Fig.</p>2</p>(e), (f)). Each entry thist</p>[tp, k]  </p>gives the number of tasks of a given type that is part of resource requirement class ( k-1 n cl , k n cl ] and each entry nhistc[tp, k] gives the actual number of tiles of a given type in resource requirement class</p>( k-1 n cl , k n cl ].</p>• The output data is the selected virtual cluster where the application will be mapped to and the binding of the tasks to the PEs, ∀ti ∈ T : b(ti) ∈ T ps (see Def. 8).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Algorithm 2</head><label>2</label><figDesc>Run-time mapping CT G: input data, application CTG mpng: output data, mapping of tasks to tiles tile LU T,clu : state of the physical network T ps ∈ tile LU T,clu : types contained in model tpPE: type of a tile's PE, tpPE ∈ T ps model rs_avail(tpPE): gives the available computational resources of all PEs of the given type tpPE binding: ∀ti ∈ CT G : ∃b(ti), b : see Definition 8</figDesc><table><row><cell cols="2">sorted: T ps, asc, by rs_avail(tpPE) // sorting by</cell></row><row><cell cols="2">// avail. of PE types</cell></row><row><cell cols="2">1: for all a ∈ T ps do 2: f a = {fij ∈ tg | bound(ti, a) ∨ bound(tj, a)} 3: sort(f a , desc, by bw_req(fij ∈ f a ))</cell></row><row><cell>4:</cell><cell>for all f k ij ∈ f a do</cell></row><row><cell>5: 6: 7:</cell><cell>select n i , n j ∈ tile LU T,clu , for ti, tj by min(cmp) insert(n i , n j to mpng) end for</cell></row><row><cell cols="2">8: end for</cell></row><row><cell cols="2">9: allocate(mpng); update(tile LU T,clu by mpng)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 2 :</head><label>2</label><figDesc>Fine-grained tile information inside each cluster agent</figDesc><table><row><cell>).</cell><cell></cell><cell></cell></row><row><cell>field</cell><cell>req. memory</cell><cell>short description</cell></row><row><cell>id tpPE r_reqcomp</cell><cell>log 2 #N log 2 #T ps log 2 #Lv</cell><cell>tile id, Def. 2 type of tile's PE (Def. 8) computation resource req.</cell></row><row><cell cols="2">bw used All directions log 2 #Lv</cell><cell>communication bw. usage output port, e.g. North</cell></row><row><cell>q_vc</cell><cell></cell><cell>virtual channel quantity</cell></row><row><cell cols="2">All directions max. #VCs</cell><cell>output port, e.g. North</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Monitoring-traffic is defined in this paper as the traffic which is caused by collecting information about the state of the tiles, ni ∈ N (see Def.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p><ref type="bibr" target="#b2">2)</ref> </p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">De</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Networks on Chips: A new SoC paradigm</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="70" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Supporting task migration in multi-processor systems-onchip: a feasibility study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acquaviva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poggiali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DATE&apos;06: Proc. of the Conf. on Design, Automation and Test in Europe</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="15" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mobile agents for network management</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bieszczad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pagurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comm. surveys and tutorials</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="9" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Thousand core chips -A technology perspective</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC&apos;07: Proc. of the 44th annual Conf. on Design Automation</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="746" to="749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The computational complexity of the minimum weight processor assignment problem&quot;. WG&apos;04: Proc. of the 30th int. Workshop on Graph-theoretic concepts in computer science</title>
		<author>
			<persName><forename type="first">H</forename><surname>Broersma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paulusma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J M</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vlaardingerbroek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Woeginger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="189" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heuristics for dynamic task mapping in NoC-based heterogeneous MPSoCs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Calazans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Moraes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RSP&apos;07: Proc. of the 18th IEEE int. workshop on Rapid System Prototyping</title>
		<imprint>
			<date type="published" when="2007-05">May 2007</date>
			<biblScope unit="page" from="34" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">NoCGEN: A template based reuse methodology for networks on chip architecture</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parameswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VL-SID&apos;04: Proc. of the 17th int. Conf. on VLSI Design</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="717" to="720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incremental run-time application mapping for homogeneous NoCs with multiple voltage levels</title>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CODES+ISSS&apos;07: Proc. of the 5th IEEE/ACM int. Conf. on Hardware/software Codesign and system synthesis</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="161" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Route packets, not wires: Onchip interconnection networks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Towles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAC&apos;01: Proc. of the 38th Conf. on Design Automation</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="684" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">TGFF: Task graphs for free</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Rhodes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CODES/CASHE&apos;98: Proc. of the 6th int. workshop on Hardware/software Codesign</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="97" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Run-time adaptive on-chip communication scheme</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A A</forename><surname>Faruque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCAD &apos;07: Proc. of the 2007 IEEE/ACM int. Conf. on Computer-aided design</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A unified approach to constrained mapping and routing on networkon-chip architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goossens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rǎdulescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CODES+ISSS&apos;05: Proc. of the 3rd IEEE/ACM int. Conf. on Hardware/software Codesign and system synthesis</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On-chip networks: A scalable, communication-centric embedded system design paradigm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Henkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakradhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSID&apos;04: Proc. of the 17th int. Conf. on VLSI Design</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="845" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Autonomic computing: IBM&apos;s perspective on the state of information technology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Horn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>IBM Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploiting the routing flexibility for energy/performance aware mapping of regular NoC architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DATE&apos;03: Proc. of the Conf. on Design, Automation and Test in Europe</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="10688" to="10693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A two-step genetic algorithm for mapping task graphs to a network on chip architecture</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DSD&apos;03: Proc. of the Euromicro symposium on Digital Systems Design</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="180" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Centralized run-time resource management in a network-on-chip containing reconfigurable hardware tiles</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Marescaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Avasare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Verkest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Mignolet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DATE&apos;05: Proc. of the Conf. on Design, Automation and Test in Europe</title>
		<imprint>
			<date type="published" when="2005-03">March 2005</date>
			<biblScope unit="page" from="234" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image-based markerless 3D human motion capture using multiple cues</title>
		<author>
			<persName><forename type="first">P</forename><surname>Azad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asfour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dillmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the int. workshop on Vision Based Human-Robot Interaction</title>
		<meeting>of the int. workshop on Vision Based Human-Robot Interaction</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Run-time mapping of applications to a heterogeneous reconfigurable tiled system on chip architecture</title>
		<author>
			<persName><forename type="first">L</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hurink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Broersma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paulusma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wolkotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPL&apos;04: Proc. of the IEEE int. Conf. on Field-Programmable Technology</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="421" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Heterogeneous process migration: The Tui system</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Hutchinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software -Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="611" to="639" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Virtex2 datasheets</title>
		<author>
			<persName><surname>Xilinx</surname></persName>
		</author>
		<ptr target="http://www.xilinx.com/" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
