<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Adaptive Simulated Binary Crossover for Real-Parameter Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
							<email>deb@iitk.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Mechanical Engineering Indian Inst. of Tech. Kanpur Kanpur</orgName>
								<address>
									<postCode>208016</postCode>
									<settlement>PIN</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Karthik</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Mechanical Engineering Indian Inst. of Tech. Kanpur Kanpur</orgName>
								<address>
									<postCode>208016</postCode>
									<settlement>PIN</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tatsuya</forename><surname>Okabe</surname></persName>
							<email>okabe@jp.honda-ri.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Honda Research Institute Japan</orgName>
								<address>
									<addrLine>8-1 Honcho, Wako-shi Saitama</addrLine>
									<postCode>351-0188</postCode>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Adaptive Simulated Binary Crossover for Real-Parameter Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A37A6A7700E698BDCF7193116ECDF237</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.2.8 [Computing Methodologies]: Problem Solving</term>
					<term>Control Methods</term>
					<term>and Search Self-adaptation</term>
					<term>simulated binary crossover</term>
					<term>real-parameter optimization</term>
					<term>recombination operator</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Simulated binary crossover (SBX) is a real-parameter recombination operator which is commonly used in the evolutionary algorithm (EA) literature. The operator involves a parameter which dictates the spread of offspring solutions vis-a-vis that of the parent solutions. In all applications of SBX so far, researchers have kept a fixed value throughout a simulation run. In this paper, we suggest a self-adaptive procedure of updating the parameter so as to allow a smooth navigation over the function landscape with iteration. Some basic principles of classical optimization literature are utilized for this purpose. The resulting EAs are found to produce remarkable and much better results compared to the original operator having a fixed value of the parameter. Studies on both single and multiple objective optimization problems are made with success.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Most real-world optimization problems involve decision variables which are real-valued. Despite the dedicated realparameter EAs, such as evolution strategy, differential evolution etc., real-parameter GAs have gained adequate popularity in the recent past. The main challenge in developing an efficient real-parameter GA lies in devising a recombination operator in which two or more real-parameter vectors must be blended to create two or more offspring vectors of real numbers <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b7">7]</ref>. These recombination operators employ a non-uniform probability distribution around the parent solutions to create an offspring solution. A theoretical study <ref type="bibr" target="#b1">[1]</ref> attempted to find similarities among these operators.</p><p>In this paper, we concentrate on a particular recombination operator -the simulated binary crossover (SBX) operator <ref type="bibr" target="#b2">[2]</ref>. The SBX operator uses two parent vectors and apply the blending operator variable by variable to create two offspring solutions. The operator involves a parameter, called the distribution index (ηc), which is kept fixed to a non-negative value throughout a simulation run. If a large value of ηc is chosen, the resulting offspring solutions are close to the parent solutions. On the other hand, for a small value of ηc, solutions away from parents are likely to be created. Thus, this parameter has a direct effect in controlling the spread of offspring solutions. Since a search process of finding the minimum solution of a function landscape largely depends on controlling the spread (or diversity) of offspring solutions vis-a-vis the selection pressure introduced by the chosen selection operation, fixing the ηc parameter to an appropriate value is an important task.</p><p>Here, we suggest a self-adaptive procedure of updating the ηc parameter by using the extension-contraction concept in a classical optimization algorithm. If the created child solution is better than the participating parent solutions, the child solution is extended further in the hope of creating even a better solution. On the other hand, if a worse solution is created, a contraction is performed. Either task will result in a update of ηc, so that the newly-created extended or contracted offspring solution has an identical probability of creation with an updated η c . This modification procedure has been applied to three single-objective and three twoobjective optimization problems and compared with corresponding GAs with a fixed ηc value. In all cases, better performance of the suggested self-adaptive procedure is observed.</p><p>In the remainder of the paper, we briefly describe the SBX operator. Thereafter, we suggest the self-adaptive ηc update procedure and show simulation results on single-objective optimization problems. In each case, a parametric study with a parameter α is performed to find a suitable working range of this parameter. Then, a scale-up study by varying the number of decision variables is performed to demonstrate the polynomial complexity of the suggested algorithm. Finally, the self-adaptive update of ηc is extended to multi-objective optimization and results are discussed. Finally, conclusions from the study are made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SIMULATED BINARY CROSSOVER (SBX)</head><p>As the name suggests, the SBX operator <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b6">6]</ref> simulates the working principle of the single-point crossover operator on binary strings. In the above-mentioned studies, it was shown that this crossover operator respects the interval schemata processing <ref type="bibr" target="#b7">[7]</ref>, in the sense that common interval schemata between the parents are preserved in the offspring. The procedure of computing the offspring x (2,t) i is described as follows. A spread factor βi is defined as the ratio of the absolute difference in offspring values to that of the parents:</p><formula xml:id="formula_0">βi = ˛x(2,t+1) i -x (1,t+1) i x (2,t) i -x (1,t) i ˛. (1)</formula><p>First, a random number ui between 0 and 1 is created. Thereafter, from a specified probability distribution function, the ordinate βq i is found so that the area under the probability curve from zero to βq i is equal to the chosen random number ui. The probability distribution used to create an offspring is derived to have a similar search power to that in a single-point crossover in binary-coded GAs and is given as follows <ref type="bibr" target="#b2">[2]</ref>:</p><formula xml:id="formula_1">P(βi) = ( 0.5(ηc + 1)β ηc i , if βi ≤ 1; 0.5(ηc + 1) 1 β ηc+2 i , otherwise.<label>(2)</label></formula><p>Figure <ref type="figure" target="#fig_1">1</ref> shows the above probability distribution with ηc = 2 and 5 for creating offspring from two parent solutions (x (1,t) i = 2.0 and x (2,t) i = 5.0). In the above expressions, the distribution index ηc is any non-negative real number. A large value of ηc gives a higher probability for creating 'near-parent' solutions (thereby allowing a focussed search) and a small value of ηc allows distant solutions to be selected as offspring (thereby allowing to make diverse search). After obtaining βq i from the above probability distribu-tion, the offspring are calculated as follows:</p><formula xml:id="formula_2">x (1,t+1) i = 0.5 h (1 + βq i )x (1,t) i + (1 -βq i )x (2,t) i i , (3) x (2,t+1) i = 0.5 h (1 -βq i )x (1,t) i + (1 + βq i )x (2,t) i i . (4)</formula><p>The SBX operator biases solutions near each parent more favorably than solutions away from the parents. Essentially, the SBX operator has two properties:</p><p>1. The difference between the offspring is in proportion to the parent solutions.</p><p>2. Near-parent solutions are monotonically more likely to be chosen as offspring than solutions distant from parents.</p><p>An interesting aspect of this crossover operator is that for a fixed ηc the offspring have a spread which is proportional to that of the parent solutions " x</p><formula xml:id="formula_3">(2,t+1) i -x (1,t+1) i " = βq i " x (2,t) i -x (1,t) i " . (<label>5</label></formula><formula xml:id="formula_4">)</formula><p>In initial populations, where the solutions are randomly placed, making the difference in parents ((x</p><formula xml:id="formula_5">(2,t) i -x (1,t) i</formula><p>)) large, this allows to create a child solution which is also far away from the parents. However, when the solutions tend to converge due to the action of genetic operators (thereby making the parent difference small), distant solutions are not likely to occur, thereby focusing the search to a narrow region. As we discuss in the following section that this aspect of self-adaptive nature of SBX operator is not adequate alone in reaching near the optimum in large-sized and complex functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SELF-ADAPTIVE SBX</head><p>The SBX operator discussed above involves a parameter: the distribution index ηc. In most applications of SBX, a fixed value of ηc = 2 is used for single-objective optimization <ref type="bibr" target="#b2">[2]</ref>. For a fixed value of ηc, the difference between the created child solution and the closest parent solution depends on the net difference between the two parent solutions, thereby causing a self-adaptive property of such a operator <ref type="bibr" target="#b5">[5]</ref>. It has always been a research issue whether such a self-adaptive property is adequate in solving difficult optimization problems. Past studies of real-coded genetic algorithms with the SBX operator was not found to be suitable for multi-modal problems, such as Rastrigin's function <ref type="bibr" target="#b4">[4]</ref>. Here, we suggest a procedure for updating the ηc parameter adaptively to solve such problems.</p><p>To illustrate the modified procedure, let us consider Figure <ref type="figure" target="#fig_2">2</ref>, in which a typical child solution c is shown to be created from two parent solutions p1 and p2 by using SBX with a distribution index of ηc. Say, the random number used for this particular crossover operation is u (∈ (0, 1)). Then, if β (&gt; 1) corresponds to the spread factor for the specific case of crossover, we obtain the following from the definition of spread factor:</p><formula xml:id="formula_6">β = 1 + 2(c -p2) p2 -p1 . (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>By noting that Z β 1 0.5(ηc + 1) we obtain the following relationship:</p><formula xml:id="formula_8">β ηc+2 dβ = (u -0.5),</formula><formula xml:id="formula_9">ηc = - " 1 + log 2(1 -u) log β « . (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>We now get into four scenarios (resulting in equations 9 to 12), as discussed below.</p><p>If this child solution c is better than both parent solutions, we assume that the region in which the child solution is created is better than the region in which the parents solutions are and intend to extend the child solution further away from the closest parent solution (p2, in the case shown in the figure) by a factor α (&gt; 1). This idea is similar to that followed in Nelder and Meade's simplex search method <ref type="bibr" target="#b10">[10]</ref>, in which an intermediate solution is either expanded or contracted or kept the same depending on the function value of the solution compared to that of the previously computed solutions. Rechenberg's 1/5th rule also keeps track of proportion of successful mutations over a certain number of trials <ref type="bibr" target="#b13">[13]</ref>. If the success happens too often, the mutation strength is increased to create solutions away from the parent, else the mutation strength is reduced. By using α &gt; 1, the difference between the new child solution c with closest parent p2 is made α times than that between original child solution c and p2, such that</p><formula xml:id="formula_11">(c -p2) = α(c -p2).</formula><p>We then modify the distribution index to a value η c such that with this value and having the identical random number u, the modified child solution c gets created from parent solutions p1 and p2, thereby yielding</p><formula xml:id="formula_12">η c = - " 1 + log 2(1 -u) log β « . (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>Here, β is the corresponding distribution index, given by</p><formula xml:id="formula_14">β = 1 + 2(c -p2) (p2 -p1) , = 1 + α(β -1).</formula><p>Using the above relationship between β and β and using equations 7 and 8, we obtain the following update relationship for a child solution being found to be better than the nearest parent solution and the child lies outside the region bounded by parents:</p><formula xml:id="formula_15">η c = -1 + (ηc + 1) log β log (1 + α(β -1)) . (<label>9</label></formula><formula xml:id="formula_16">)</formula><p>To make the η c value meaningful and free from numerical underflow error, we restrict it within [0, 50], that is if η c &lt; 0 is obtained by the above equation, we set it to be zero and if η c &gt; 50 is used, we set it to be 50. This equation gives us an update procedure of ηc for providing a distribution index which is able to create children solutions in the right direction away from the parents. It is interesting to note that if a child c was created to the left of p1, a similar update relationship will also be achieved.</p><p>If the child solution c is worse than both parent solutions, we would like to move the modified child c to get closer to the parents and we may use 1/α instead of α in equation 6:</p><formula xml:id="formula_17">η c = -1 + (ηc + 1) log β log (1 + (β -1)/α) . (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>However, if a child solution is created inside the region bounded by both parents, a different update relationship will be obtained, since the SBX probability distribution function is different in this case. By following the above arguments, we obtain β = β α and the relationship for an improved child solution between ηc and η c values is obtained as follows:</p><formula xml:id="formula_19">η c = 1 + ηc α -1. (<label>11</label></formula><formula xml:id="formula_20">)</formula><p>Once again, we restrict its value within [0, 50] to avoid any computational error and to make η c meaningful. For a scenario of creating a worse child, the above update relationship changes to</p><formula xml:id="formula_21">η c = α(1 + ηc) -1. (<label>12</label></formula><formula xml:id="formula_22">)</formula><p>If the child solution c has a function value which is within the function value of the two parent solutions, we set η c = ηc.</p><p>To implement the update concept, we assign a ηc value within [η L c , η U c ] in the initial population. In all simulations here, we use η L c = η U c = 2. For a child solution, one random number is created and a corresponding β is computed. This β is used for all n variables and a child is created by variablewise application of the SBX operator. This results in a line-SBX operator which produces a child along the line joining the two parent vectors. Thereafter, depending on the event of whether a better child (than both parents) or a worse child (than both parents) is created, ηc is updated and is assigned to the corresponding child solution. We assign a new η c value to each child solution separately.</p><p>It is interesting to note that if α = 1 is used, all the above update of ηc procedure result in η c = ηc and the above procedure is identical to the fixed ηc (original SBX) procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Effect of mutation operator</head><p>In addition to the above modified SBX operator, a mutation operator can be used to perturb the created child c . In such an event, there is an extra solution evaluation per child creation. Solution c gets evaluated during the crossover operator and the mutated version of the modified solution c is evaluated. In our implementation, we add such extra function evaluations in the computation of performance of the modified procedure. However, if the mutation probability is so low that no variable gets mutated by the mutation operator, there is no extra evaluation recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SIMULATION RESULTS</head><p>We now apply the modified approach to three different unconstrained functions which are popularly used in the GA literature. Many studies in the literature on the chosen test problems use a population which is initialized symmetrically around the global minimum of the functions. When an algorithm with such a population uses recombination and mutation operators, which have a tendency to create solutions in the central region of the search space bounded by the population members, it finds an easier time converging to the global minimum. To avoid any such undue advantage from the operators, in all simulations here, the initial population is bounded in the range xi ∈ <ref type="bibr" target="#b10">[10,</ref><ref type="bibr">15]</ref> for all i, such that the global minimum is not bracketed in the initial population. This provides a stiff test to an algorithm to first get out of the region bounded by the initial population and then keep moving in the correct direction so as to reach the global minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sphere Function</head><p>The sphere function is the simplest of the three functions used in this study:</p><formula xml:id="formula_23">f (x) = n X i=1 x 2 i . (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>First, we employ the real-coded GA with the original fixedηc based SBX operator on the 30-variable sphere function with following parameter settings: population size = 150, pc = 0.9, ηc = 2, pm = 1/30, and ηm = 50. A run is terminated when a solution having a function value equal to 0.001 is found. Eleven runs are made from random initial populations. Figure <ref type="figure">3</ref> shows a typical variation of best population function value with the number of function evaluations. To investigate the effect of recombination operator alone, we make another set of runs with pm = 0 and a typical performance is also shown in the figure . Both results indicate that the fixed-ηc based GA is unable to find the true optimum in any reasonable number of evaluations for a 30-variable sphere function. However, it is worthwhile to mention here that after a variable-wise creation of two offspring vectors, if the variables values are swapped randomly between the two offsprings (similar to a uniform crossover operator or the crossover operator in differential evolution <ref type="bibr" target="#b12">[12]</ref>), a much quicker convergence with a fixed ηc = 2 can be obtained for variable-wise separable functions, like the sphere function <ref type="bibr" target="#b5">[5]</ref>. This is because variables can independently reach near the true optimum in different population members and a uniform swapping of such solutions can create a complete solution having near optimal variables values. However, this uniform-like crossover operation may not work well in rotated and more complex problems. In this paper, we only concentrate on the blending part of the operation and investigate whether the fixed nature of ηc or the selfadaptive nature of ηc is more effective without having any crossover-like swapping effect. Next, we employ our self-adaptive update procedure of ηc. All initial population members are initialized with ηc = 2 and then allowed to change based on our update procedure described above. All other parameters are the same as above and to investigate the effect of the self-adaptive recombination operator alone, we use pm = 0 and reduce the crossover probability to pc = 0.7. For the ηc update we use α = 1.50. A typical variation of the best population function value is shown in Figure <ref type="figure">3</ref> and is found to have good converging property. Table <ref type="table">1</ref> shows the best, median and worst number of function evaluations to reach a solution with f = 0.001 out of 11 runs. It is clear that compared to the fixed-ηc schemes, the self-adaptive scheme is able to steer the search towards the true minimum solution quickly and converge close to the minimum. It is clear that even with 300,000 function evaluations, the fixed ηc scheme is not able to find a near-optimum solution, whereas with a median of 184,050 function evaluations, a solution with three decimal places accuracy from the true optimum is found repeatedly in 11 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Parametric Study</head><p>Figure <ref type="figure" target="#fig_3">4</ref> does a parametric study with α in the range [1.05, 2.00]. Recall that the parameter α signifies the extent of change in the offspring solution performed to recompute the ηc parameter for an identical probability event of creating the modified solution. Once again, 11 runs are performed for every case and the best, median and worst number of function evaluations are shown in the figure. It can be said that the effect of α is not significant. Although there is a degradation of the median performance with increasing α, the performance is best in the range α ∈ [1.05, 1.50]. Thus, despite the introduction of a new parameter (α) for updating an existing parameter (ηc), the effect of the parameter α is not significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Scale-up Study</head><p>Finally, we perform a scalability study by varying the number of variables (n) from 20 to 200. In this study, we have used the following update of parameter due to the increase in number of variables: population size = 5n. All other parameters are kept the same as before and we use α = 1.50. Figure <ref type="figure">5</ref> shows that (i) the real-coded GA with self-adaptive recombination operator is able to find a solution close to the true minimum (within a tolerance of 0.001 in the function value) and (ii) the increase in number of function evaluations is polynomial to the increase in number of variables (O(n 2.21 )). The GA with the self-adaptive SBX operator suggested here does not exploit the variable separability of the objective functions. This is the reason why the proposed GA takes more number of evaluations than other approaches which favor the variable separability and unimodality of the sphere function <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b4">4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Rosenbrock Function</head><p>Next, we consider the Rosenbrock's function:</p><formula xml:id="formula_25">f (x) = n-1 X i=1 100(x 2 i -xi+1) + (xi -1) 2 . (<label>14</label></formula><formula xml:id="formula_26">)</formula><p>This function has the global minimum at xi = 1 for all i with a function value equal to zero. Near the minimum region, this function has a very small slope towards the minimum. This property of the landscape causes an algorithm to have a slow convergence to the minimum. Once again, we first employ the original SBX operator with a fixed ηc = 2 and initialize xi ∈ <ref type="bibr" target="#b10">[10,</ref><ref type="bibr">15]</ref> for all i. Figure <ref type="figure">6</ref> shows a typical variation of population-best function value with the number of function evaluations for the 30-variable Rosenbrock function with following parameter settings: population size = 150, pc = 0.9, pm = 1/30, and ηm = 50. The algorithm is terminated when a solution with a minimum function value of 0.001 is found. The procedure is not able to come close to the true minimum. When we use Scale-up study with number of variables for the sphere function.</p><p>Table <ref type="table">1</ref>: Performance of real-coded GAs with fixed and self-adaptive ηc update on 30-variable sphere function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Optimized function value (func. eval.) Original (pc = 0.9, pm = 0.033) 1.24e03 (300,000) 4.16e03 (300,000) 4.30e03 (300,000)</p><p>Original (pc = 0.9, pm = 0) 1.21e03 (300,000) 4.13e03 (300,000) 4.24e03 (300,000) Self-adp.(pc = 0.7, pm = 0) 10 -3 (151,800) 10 -3 (184,050) 10 -3 (213,450) pm = 0, a somewhat better performance is observed, but the procedure is unable to reach near to the global minimum. Now, we apply the self-adaptive recombination operator starting with ηc = 2 to all initial population members. We use α = 1.5 for the update procedure. Figure <ref type="figure">6</ref> shows a typical variation in the population-best function value. The self-adaptive property of the recombination operator is able to adjust the ηc adequately to navigate through the fitness landscape to reach near the global minimum. Table <ref type="table" target="#tab_1">2</ref> shows the best, median and worst performance out of 11 runs of original and self-adaptive GAs. For the self-adaptive case, we have shown results with α = 1.4, which produces the best result. With as many as 10 million function evaluations, the fixed ηc scheme is not able to find a near-optimum solution (in fact, the best solution has a function value of 6.85 (10 6 )), whereas with a median of about 6.9 million function evaluations, a solution with three decimal places accuracy from the true optimum is found repeatedly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Parametric Study</head><p>A parametric study on α is shown in Figure <ref type="figure">7</ref>. Although there is a upward trend in number of function evaluations with increasing α, with α ∈ [1.05, 1.50] the performance is better. Interestingly, in this problem also we find that the effect of α in a good range of values is not significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Scale-up Study</head><p>A scale-up study is made next by varying the number of variables from 20 to 200. Figure <ref type="figure" target="#fig_4">8</ref> shows that the number of function evaluations needed to reach up to three decimal places of accuracy varies as O(n 3.496 (log n) -9.147 ) by the proposed self-adaptive procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Rastrigin's Function</head><p>Next, we consider the Rastrigin's function which has many local optima and one global minimum at xi = 0 for i = 1, 2, . . . , n:</p><formula xml:id="formula_27">f (x) = n X i=1 x 2 i + 10 (1 -cos(2πxi)) .<label>(15)</label></formula><p>In an earlier study <ref type="bibr" target="#b4">[4]</ref>, this function was difficult to solve for global optimality using the real-coded GA with a parent centric recombination operator, particularly when the initial population did not bracket the global optimum. In this study, we initialize a population with each xi created randomly in <ref type="bibr" target="#b10">[10,</ref><ref type="bibr">15]</ref>, away from the global minimum solution.</p><p>In a single dimension, an algorithm has to overcome at least 10 different local optima to reach to the global minimum. With a larger variable size, exponentially more local optima must be overcome to reach the global minimum. First, we apply the real-coded GA with the original SBX operator on the 20-variable Rastrigin function with a standard parameter setting: population size = 100, pc = 0.9, ηc = 2, pm = 1/20, ηm = 50. GAs are run from 11 different initial populations till a maximum of 40,000 generations or till a solution having a function value of 10 -4 is obtained. Table <ref type="table" target="#tab_2">3</ref> shows the best function values obtained by the procedure. In this case, the best obtained function value (in 11 runs) with four million function evaluations is 319.523, whereas the globally best solution has a function value equal to zero. It is clear that no run is able to find a solution close to the global minimum. With pc = 0.7 and pm = 0.01, we obtain slightly better performance, but even now no solution close to the global minimum is found.</p><p>Next, we apply the real-coded GA with our proposed selfadaptive SBX operator with pm = 0.7 and pm = 0.01. All initial population members are initialized with ηc = 2 and then allowed to change using the proposed ηc update procedure described earlier. We use α = 1.5 here. Table <ref type="table" target="#tab_2">3</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Optimized function value (func. eval.) Original (pc = 0.9, pm = 0.033) 6.85e06 (10M) 7.44e06 (10M) 8.30e07 (10M) Original (pc = 0.9, pm = 0) 9.94e06 (10M) 4.94e07 (10M) 5.19e07 (10M) Self-adp.(pc = 0.7, pm = 0) 10 -3 (2,200,650) 10 -3 (6,832,950) 10 -3 <ref type="bibr" target="#b7">(7,</ref><ref type="bibr">836,</ref><ref type="bibr">300)</ref> that in all cases the self-adaptive update of ηc is able to find a solution with desired accuracy in a fraction of total evaluations used in the case of fixed-ηc procedures. Despite being started far away from the global minimum, the procedure is able to converge to the correct globally minimum solution. Figure <ref type="figure" target="#fig_5">9</ref> shows the decrease in best function value with number of function evaluations for a typical simulation run with a fixed ηc = 2 procedure (pc = 0.7, pm = 0.01) and with the self-adaptive procedure. The figure clearly shows that the fixed ηc run is poor in its performance, whereas the self-adaptive procedure steadily finds better and better solutions with function evaluations. To understand the effect of the proposed self-adaptive update of ηc, we record the ηc value of the top 15 percentile solutions in terms of their function values and show its variation with number of function evaluations in Figure <ref type="figure" target="#fig_5">9</ref>. The yaxis of this figure is made logarithmic. Although, the above ηc value seems to end at 10 -5 in the figure, the actual value recorded by the procedure is ηc = 0. An interesting aspect is that the ηc value seems to take a value zero at various stages of the simulation. The line corresponding to the best function value (marked as 'Adaptive SBX') indicates that there are a number of function values, especially within f = 10 to f = 1, in which the algorithm seems to get stuck for a large number of evaluations before finding a better solution. Within this range of function values, this function has one local minimum at every integer value of the function, thereby having a possibility to get stuck 10 times. Interestingly, every time the best population member gets stuck at a local minimum, the ηc of the best 15 percentile solution gets updated to zero, thereby increasing the spread of created solutions by the SBX operator. Since an ηc = 0 will be the smallest possible ηc which provides the maximum spread in created solutions, the algorithm finds that the best way to counteract a local statis is to increase the diversity of created solutions to the extent possible. However, as soon as a better solution is found, the ηc is immediately updated to a value close to one, thereby providing a more focussed search around population members. With an assigned fixed value of ηc over the entire simulation run, such a variation in spread in solutions in an offspring population is not possible. The proposed procedure seems to employ this principle adaptively and multiply in as many times as the algorithms get stuck to a locally optimal solution and improve from such a situation. In the absence of such an adaptive update of ηc with the original SBX operator, the corresponding GA was not able to improve its performance efficiently every time it gets stuck to a locally optimal solution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Parametric Study</head><p>A parametric study of α to investigate its effect on the performance of the proposed procedure is made next. For the 20-variable Rastrigin's function and with above parameter settings, 11 different runs are made. Figure <ref type="figure" target="#fig_6">10</ref> shows number of function evaluations needed to find a solution with a function value equal to or smaller than 10 -4 . It is interesting to note that for a large range of values of α (∈ [1.05, 8.00]), the performance of the proposed procedure remains fairly independent of α. However, the best performance seems to happen for α = 3 with best, median and worst number of function evaluations of 221,082, 342,741, and 718,680, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Scale-up Study</head><p>Motivated by the success of the self-adaptive SBX procedure on the 20-variable Rastrigin's function, we now try to solve larger size Rastrigin's function with n varying in <ref type="bibr">[20,</ref><ref type="bibr">200]</ref>. With an increase in n, the number of local minima in a particular range of the variable values increase exponentially and the resulting problem is likely to provide more difficulty to an optimization algorithm. Since a function with a larger number of variables should ideally require a larger population size for a GA initialized with a randomly created population <ref type="bibr" target="#b8">[8]</ref>, we use the following parametric update for different n: population size=5n, pm = 0.2/n, and pc = 0.7.</p><p>Here also, we initialize population with xi ∈ <ref type="bibr" target="#b10">[10,</ref><ref type="bibr">15]</ref>, so as to not bracket the global minimum in the initial population. We also use α = 1.5 for all n. We run till a solution with a function value equal to or smaller than 10 -4 is obtained. Figure <ref type="figure" target="#fig_8">11</ref> shows that the required number of function eval-uations increased polynomially (O(n 1.807 )) with n over the entire range of number of variables used in this study. It is  noteworthy that the proposed procedure is able to overcome exponentially many local minima to converge to the globally minimum solution with polynomially increasing number of function evaluations to as complex as a 200-variable Rastrigin's function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SELF-ADAPTIVE SBX FOR MULTI-OBJECTIVE OPTIMIZATION</head><p>Like the way we made the SBX operator self-adaptive for single-objective optimization, we extend the idea here for multi-objective optimization. The main difficulty arises in deciding when a child solution is better than a parent. Here, we simply use the idea of non-domination to decide on this matter. Let us consider Figure <ref type="figure" target="#fig_2">12</ref>. For the two parent objective vectors shown in the figure, if a child lies on the non-dominated shaded region (marked with 'A'), we call that the child to be better than the parents and we use the ηc update equations described earlier. On the other hand, if the child lies on the region marked as 'B' in the figure, we call that the child is worse than the parents and we use the appropriate equation (described earlier) to update ηc. If, however, the child lies on the region marked as 'C' in the figure, we do not update ηc. The remaining part of the NSGA-II algorithm <ref type="bibr" target="#b3">[3]</ref> is used as usual.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The probability density function for creating offspring under an SBX-ηc operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A schematic diagram showing the ηc update procedure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 3: Variation of populationbest function value with number of function evaluations for the 30variable sphere function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8:Scale-up study with number of variables for the Rosenbrock's function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Decrease in best population function value with number of function evaluations for the 20variable Rastrigin's function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Effect of parameter α on number of function evaluations to obtain the global minimum with four decimal places of accuracy for the 20-variable Rastrigin's function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: A polynomial increase in function evaluations with number of decision variables for the Rastrigin's function using proposed algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>shows</figDesc><table><row><cell></cell><cell>1e+08</cell><cell>Orig. (p_c=0.9, p_m=0.033)</cell><cell></cell><cell></cell><cell>1.2e+07</cell><cell></cell><cell>1e+09</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.1e+07</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1e+06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Function Value</cell><cell>1 100 10000</cell><cell>Self-adaptive Orig. (p_c=0.9,p_m=0)</cell><cell></cell><cell>Function Evaluations</cell><cell>4e+06 5e+06 6e+06 7e+06 8e+06 9e+06 1e+07</cell><cell>Function Evaluations</cell><cell>1e+07 1e+08</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.01</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3e+06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>2e+06 Function Evaluations 4e+06 6e+06 8e+06</cell><cell>1e+07</cell><cell></cell><cell>2e+06</cell><cell>1 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2</cell><cell>1e+06</cell><cell>20</cell><cell>30</cell><cell>50</cell><cell>80</cell><cell>100</cell><cell>200</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>α</cell><cell></cell><cell></cell><cell cols="4">Number of Variables</cell></row><row><cell cols="4">Figure 6: Variation of population-best function value with number of function evaluations for the 30-variable Rosenbrock's function.</cell><cell cols="3">Figure 7: Parametric study of α for the 30-variable Rosenbrock's func-tion.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 : Performance of real-coded GAs with fixed and self-adaptive ηc update on 30-variable Rosenbrock's function.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 : Performance of real-coded GAs with fixed and self-adaptive ηc update on 20-variable Rastrigin's function.</head><label>3</label><figDesc>Self-adp.(pc = 0.7, pm = 0.01) 10 -4 (287,822) 10 -4 (429,511) 10 -4 (569,597)</figDesc><table><row><cell>Method</cell><cell cols="3">Optimized function value (func. eval.)</cell></row><row><cell>Original (pc = 0.9, pm = 0.05)</cell><cell>319.523 (4M)</cell><cell>338.093 (4M)</cell><cell>342.363 (4M)</cell></row><row><cell>Original (pc = 0.7, pm = 0.01)</cell><cell>124.368 (4M)</cell><cell>210.929 (4M)</cell><cell>335.380 (4M)</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SIMULATION RESULTS</head><p>Here, we show the working of NSGA-II with the selfadaptive SBX on three test problems: 30-variable ZDT1 and ZDT2 and 12-variable DTLZ2 problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">ZDT1, ZDT2 and DTLZ2 Problems</head><p>We use the hyper-volume measure to indicate the performance of a procedure. We compare the performance of the self-adaptive procedure with NSGA-II having the fixed-ηc based SBX procedure with standard setting: ηc = 15 and ηm = 20. We use the following parameter setting for selfadaptive EA: population size = 100, pc = 0.9, pm = 1/30, pm = 0 and maximum number of generations = 500. We initialize all population members with ηc = 2, as before. Table <ref type="table">4</ref> shows the hyper-volume measure for various α values with the self-adaptive procedure. We observe that with α values near 1.70, the performance of the self-adaptive NSGA-II is better than the fixed-ηc based NSGA-II. Table <ref type="table">4</ref> also shows the performance for 30-variable ZDT2 problem. Here, we observe that for α values larger than 1.20 the performance of the self-adaptive NSGA-II is better.</p><p>For the three-objective DTLZ2 problem, selfadaptive EA obtained better hyper-volume values of 0.57461, 0.56975 and 0.56597, compared to 0.55993, 0.55645 and 0.55539 as best, median and worst values obtained using original fixedηc EA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>In this paper, we have suggested a self-adaptive procedure for updating the distribution index ηc used in the simulated binary crossover or SBX operator which is a commonly-used real-parameter recombination operator. The update procedure mimics the extension-contraction concept in Nelder and Meade's simplex search procedure and also follows, in principle, Rechenberg's 1/5-th update rule. On three singleobjective optimization problems and on three two-objective optimization problems, the suggested procedure is found to be perform much better than the original SBX procedure. Further investigations are now needed for solving problems having a linkage among variables and problems having more than two objectives. A similar self-adaptive idea can also be used with other real-parameter recombination operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGMENT</head><p>This study is supported by a research grant from Honda R&amp;D, Japan.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the desired behavior of self-adaptive evolutionary algorithms</title>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature VI (PPSN-VI)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simulated binary crossover for continuous search space</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="148" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fast and elitist multi-objective genetic algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A computationally efficient evolutionary algorithm for real-parameter optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="371" to="395" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self-adaptation in real-parameter genetic algorithms with simulated binary crossover</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-99)</title>
		<meeting>the Genetic and Evolutionary Computation Conference (GECCO-99)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="172" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-coded genetic algorithms with simulated binary crossover: Studies on multi-modal and multi-objective problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="431" to="454" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Real-coded genetic algorithms and interval-schemata</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Eshelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Genetic Algorithms 2 (FOGA-2)</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="187" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Genetic algorithms, noise, and the sizing of populations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="362" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Theoretical analysis of simplex crossover for real-coded genetic algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Higuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tsutsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature (PPSN-VI)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="365" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A simplex method for function minimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="308" to="313" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A real-coded genetic algorithm for function optimization using unimodal normal distribution crossover</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Genetic Algorithms (ICGA-7)</title>
		<meeting>the Seventh International Conference on Genetic Algorithms (ICGA-7)</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Differential Evolution: A Practical Approach to Global Optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Evolutionsstrategie: Optimierung Technischer Systeme nach Prinzipien der Biologischen Evolution</title>
		<author>
			<persName><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Frommann-Holzboog Verlag</publisher>
			<pubPlace>Stuttgart</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
