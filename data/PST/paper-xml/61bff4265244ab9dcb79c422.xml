<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Constraint-based graph network simulator</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yulia</forename><surname>Rubanova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alvaro</forename><surname>Sanchez-Gonzalez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tobias</forename><surname>Pfaff</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
						</author>
						<title level="a" type="main">Constraint-based graph network simulator</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the area of physical simulations, nearly all neural-network-based methods directly predict future states from the input states. However, many traditional simulation engines instead model the constraints of the system and select the state which satisfies them. Here we present a framework for constraint-based learned simulation, where a scalar constraint function is implemented as a graph neural network, and future predictions are computed by solving the optimization problem defined by the learned constraint. Our model achieves comparable or better accuracy to top learned simulators on a variety of challenging physical domains, and offers several unique advantages. We can improve the simulation accuracy on a larger system by applying more solver iterations at test time. We also can incorporate novel hand-designed constraints at test time and simulate new dynamics which were not present in the training data. Our constraint-based framework shows how key techniques from traditional simulation and numerical methods can be leveraged as inductive biases in machine learning simulators.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Consider a bowling ball colliding with a bowling pin. You might explain this event through a pair of forces being generated: one causes the pin to move, the other one causes the ball to careen away. This approach is analogous to physical simulators that apply an explicit forward model to calculate a future state directly from the current one, i.e. by numerically integrating equations of motion. An alternative, but equally valid, way to explain the collision is in terms of constraint satisfaction: the ball and pin cannot occupy the same location at the same time, and their combined energies and momenta must be conserved. The post-collision trajectories are the only way the future can unfold without * Equal contribution 1 DeepMind, London, UK. Correspondence to: Yulia Rubanova &lt;rubanova@deepmind.com&gt;, Alvaro Sanchez-Gonzalez &lt;alvarosg@deepmind.com&gt;. violating these constraints. This approach is analogous to the constraint-based simulators that generate a prediction by searching for a future state that respects all the constraints.</p><p>Both families of simulators-those based on explicit, forward functions versus those which define the dynamics implicitly, via constraints-are widely used in physics, engineering, and graphics. In principle they can model the same types of dynamics. In practice these simulators strike different trade-offs that determine which one is preferred in different domains. Explicit methods are popular for large systems with (mostly) independent local effects where space and time derivatives are relatively smooth. By contrast, implicit approaches are often preferred for systems with strong interactions, such rigid and stiff dynamics, and more accurate solutions can often be found by using more solver iterations or more sophisticated solvers. In machine learning, so far almost all methods for learned simulation have focused on explicit forward models <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021)</ref>, with few exceptions <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>.</p><p>Here we present a framework for learning to simulate complex dynamics via constraint satisfaction. Our "Constraintbased Graph Network Simulator" (C-GNS) defines a single learned constraint function that indicates whether a future state is consistent with the current and previous states. Conditioning on the previous states allows our method to capture the time dynamics within its learned constraint function. We implement the constraint function as a Graph Neural Network <ref type="bibr">(GNN, Bronstein et al. (2017)</ref>; <ref type="bibr" target="#b7">Battaglia et al. (2018)</ref>). To predict the future state, we use a gradient-based solver that iteratively refines a proposed state to minimize the learned constraint. We train the model end-to-end by backpropagating the loss gradients through the solver. Crucially, our model is trained directly on observed trajectory data and does not require knowledge of the true underlying constraints which govern the system dynamics. The learned constraint function only needs to yield the same solution as the true constraints, while their objective landscapes may differ (e.g., the learned constraint function may be convex, as in Figure <ref type="figure" target="#fig_24">1</ref>(c), while the true constraint may not be).</p><p>We tested C-GNS on several physical simulation domains: ropes, bouncing balls and irregular rigids, and splashing fluids. We found that C-GNS produced more accurate rollouts than the state-of-the-art Graph Net Simulator (Sanchez-arXiv:2112.09161v2 <ref type="bibr">[cs.</ref>LG] 28 Jan 2022 GNN f C &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k Z k Y F 8 7 4 9 t + 4 e N J p c L 8 A / 9 X 3 k S M = " &gt; A A A B 8 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 B I v g q S R S 0 G O x F 4 8 V 7 A c 0 o W y 2 m 3 b p Z h N 2 J 2 I J + R t e P C j i 1 T / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u 0 X G + r d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p 6 j h V l H V o L G L V D 4 h m g k v W Q Y 6 C 9 R P F S B Q I 1 g u m r b n f e 2 R K 8 1 g + 4 C x h f k T G k o e c E j S S F w 4 z D 9 k T Z q 0 8 H 1 Z r T t 1 Z w F 4 n b k F q U K A 9 r H 5 5 o 5 i m E Z N I B d F 6 4 D o J + h l R y K l g e c V L N U s I n Z I x G x g q S c S 0 n y 1 u z u 0 L o 4 z s M F a m J N o L 9 </p><formula xml:id="formula_0">f d E R i K t Z 1 F g O i O C E 7 3 q z c X / v E G K 4 Y 2 f c Z m k y C R d L g p T Y W N s z w O w R 1 w x i m J m C K G K m 1 t t O i G K U D Q x V</formula><formula xml:id="formula_1">Q j v H h Q x K v f 4 8 2 / c Z L s Q R M L G o q q b</formula><p>r q 7 g l h w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 4 S x b D B I h G p d k A 1 C i 6 x Y b g R 2 I 4 V 0 j A Q 2 A r G N z O / 9 Y R K 8 0 j e m 0 m M f k i H k g 8 4 o 8 Z K r Y f H t M z P p 7 1 i y a 2 4 c 5 B V 4 m W k B B n q v e J X t x + x J E R p m K B a d z w 3 N n 5 K l e F M 4 L T Q T T T G l I 3 p E D u W S h q i 9 t P 5 u V N y Z p U + G U T K l j R k r v 6 e S G m o 9 S Q M b G d I z U g v e z P x P 6 + T m M G V n 3 I Z J w Y l W y w a J I K Y i M x + J 3 2 u k B k x s Y Q y x e 2 t h I 2 o o s z Y h A o 2 B G / 5 5 V X S v K h 4 1 U r 1 r l q q X W d x 5 O E E T q E M H l x C D W 6 h D g 1 g M I Z n e I U 3 J 3 Z e n H f n Y 9 G a c 7 K Z Y / g D 5 / M H v s C P M A = = &lt; / l a t e x i t &gt; X t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 4 / c S h L n p c 3 G 1 u 2 g o 1 / x M g S g s 0 s = " &gt; A A A B 8 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o M e i F 4 8 V 7 A e 2 o W y 2 m 3 b p Z h N 3 J 0 I J / R d e P C j i 1 X / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G N z O / / c S 1 E b G 6 x 0 n C / Y g O l Q g F o 2 i l h 0 4 / 6 0 n + S H D a L 1 f c q j s H W S V e T i q Q o 9 E v f / U G M U s j r p B J a k z X c x P 0 M 6 p R M M m n p V 5 q e E L Z m A 5 5 1 1 J F I 2 7 8 b H 7 x l J x Z Z U D C W N t S S O b q 7 4 m M R s Z M o s B 2 R h R H Z t m b i f 9 5 3 R T D K z 8 T K k m R K 7 Z Y F K a S Y E x m 7 5 O B 0 J y h n F h C m R b 2 V s J G V F O G N q S S D c F b f n m V t C 6 q X q 1 a u 6 t V 6 t d 5 H E U 4 g V M 4 B w 8 u o Q 6 3 0 I A m M F D w D K / w 5 h j n x X l 3 P h a C F H A q W J r v x p p F h I 7 J k H U M l S R g 2 k t m h 6 f 4 x C h 9 P A i V K Q l 4 p v 6 e S E i g 9 S T w T W d A Y K Q X v a n 4 n 9 e J Y X D h J V x G M T B J 5 4 s G s c A Q 4 m k K u M 8 V o y A m h h C q u L k V 0 x F R h I L J K m 9 C c B d f X i a N s 7 J b K V f u K s X q V R Z H D h 2 h Y 1 R C L j p H V X S D a q i O K I r R M 3 p F b 9 a T 9 W K 9 W x / z 1 h U r m z l E f 2 B 9 / g A d 6 p K 9 &lt; / l a t e x i t &gt; Y (0) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 U Y 9 T z o 0 x S g u D E f P u Y b W H G s R n h 0 = " &gt; A A A B 7 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 F X A n o M e v E Y w T w k W c P s Z J I M m Z 1 d Z n q F s O Q j v H h Q x K v f 4 8 2 / c Z L s Q R M L G o q q b r q 7 g l g K g 6 7 7 7 e T W 1 j c 2 t / L b h Z 3 d v f 2 D 4 u F R 0 0 S J Z r z B I h n p d k A N l 0 L x B g q U v B 1 r T s N A 8 l Y w v p n 5 r S e u j Y j U P U 5 i 7 o d 0 q M R A M I p W a j 0 8 p m X 3 f N o r l t y K O w d Z J V 5 G S p C h 3 i t  </p><formula xml:id="formula_2">+ d f s R S 0 K u k E l q T M d z Y / R T q l E w y a e F b m J 4 T N m Y D n n H U k V D b v x 0 f u 6 U n F m l T w a R t q W Q z N X f E y k N j Z m E g e 0 M K Y 7 M s j c T / / M 6 C Q 6 u / F S o O E G u 2 G L R I J E E I z L 7 n f S F 5 g z l x B L K t L C 3 E j a i m j K 0 C R V s C N 7 y y 6 u k e V H x q p X q X b V U u 8 7 i y M M J n E I Z P L i E G t x C H R r A Y A z P 8 A p v T u y 8 O O / O x 6 I 1 5 2 Q z x / A H z u c P Z + q O 9 w = = &lt; / l a t e x i t &gt; Y = r Y f C (X t , Y )| Y =Y (i) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N k u D H 4 G M V A h C g 8 V u Q G 4 A A L M i 2 S w = " &gt; A A A C N H i c b V B N S x x B E O 3 R x J h N N K s e c 2 m y B F a I y 0 x Y M B d B 9 B L I x U B W d 9 j Z D D U 9 N d r Y 0 z N 2 1 4 j L M D / K i z 8 k F w n k E J F c 8 x v S u + 4 h f h Q 0 v H 6 v X n X X S 0 o l L f n + T 2 9 h 8 d n z p R f L L 1 u v X q + s v m m v r R / a o j I C B 6 J Q h R k m Y F F J j Q O S p H B Y G o Q 8 U X i U n O 5 P 9 a N z N F Y W + h t N S h z n c K x l J g W Q o + L 2 l y h F R c B D v s O 3 I u W M K f B I Q 6 I g D n k W 1 x H h B d X 7 T d M d u o v C M 0 7 N B x 5 u 8 s i 4 u R T X 4 U 7 4 v e 7 K z a a J 2 x 2 / 5 8 + K P w b B H H T Y v A 7 i 9 o 8 o L U S V o y a h w N p R 4 J c 0 r s G Q F A q b V l R Z L E G c w j G O H N S Q o x 3 X s 6 U b / t 4 x K c 8 K 4 4 4 m P m P / d 9 S Q W z v J E 9 e Z A 5 3 Y h 9 q U f E o b V Z R 9 G t d S l x W h F n c P Z Z X i V P B p g j y V B g W p i Q M g j H R</formula><formula xml:id="formula_3">x W M S q G 1 C N g k t s G W 4 E d h O F N A o E d o L J 7 d z v P K H S P J a P Z p q g H 9 G R 5 C F n 1 F j p o T v w B u W K W 3 U X I O v E y 0 k F c j Q H 5 a / + M G Z p h N I w Q b X u e W 5 i / I w q w 5 n A W a m f a k w o m 9 A R 9 i y V N E L t Z 4 t T Z + T C K k M S x s q W N G S</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Updater</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Xt</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H J / a w Z 5   </p><formula xml:id="formula_4">X F r 1 c D f r u V A e J Q c O I i x k = " &gt; A A A B 8 H i c b V D L S g N B E O z 1 G e M r 6 t H L Y B A 8 h V 0 J 6 D H o x W M E 8 5 B k C b O T S T J k Z n a Z 6 R X C k q / w 4 k E R r 3 6 O N / / G S b I H T S x o K K q 6 6 e 6 K E i k s + v 6 3 t 7 a + s b m 1 X d g p 7 u 7 t H x y W j o 6 b N k 4 N 4 w 0 W y 9 i 0 I 2 q 5 F J o 3 U K D k 7 c R w q i L J W 9 H 4 d u a 3 n r i x I t Y P O E l 4 q O h Q i 4 F g F J 3 0 2 B 1 R z N r T H v Z K Z b / i z 0 F W S Z C T M u S o 9 0 p f 3 X 7 M U s U 1 M k m t 7 Q R + g m F G D Q o m + b T Y T S 1 P K B v T I e 8 4 q q n i N s z m B 0 / J u V P 6 Z B A b V x r J X P 0 9 k V F l 7 U R F r l N R H N l l b y b + 5 3 V S H F y H m d B J i l y z x a J B K g n G Z P Y 9 6 Q v D G c q J I 5 Q Z 4 W 4 l b E Q N Z e g y K r o Q g u W X V 0 n z s h J U K 9 X</formula><formula xml:id="formula_5">b t r J f i h Z f 1 y h W 3 6 s 5 B V o m X k w r k a P T K X 9 1 + x J K Q K 2 S S G t P x 3 B j 9 l G o U T P K s 1 E 0 M j y k b 0 y H v W K p o y I 2 f z o / O y J l V + m Q Q a V s K y V z 9 P Z H S 0 J h p G N j O k O L I L H s z 8 T + v k + D g 2 k + F i h P k i i 0 W D R J J M C K z B E h f a M 5 Q T i 2 h T A t 7 K 2 E j q i l D m 1 P J h u A t v 7 x K W p d V</formula><formula xml:id="formula_6">m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G N z O / / c S 1 E b G 6 x 0 n C / Y g O l Q g F o 2 i l h 0 4 / 6 0 n + S H D a L 1 f c q j s H W S V e T i q Q o 9 E v f / U G M U s j r p B J a k z X c x P 0 M 6 p R M M m n p V 5 q e E L Z m A 5 5 1 1 J F I 2 7 8 b H 7 x l J x Z Z U D C W N t S S O b q 7 4 m M R s Z M o s B 2 R h R H Z t m b i f 9 5 3 R T D K z 8 T K k m R K 7 Z Y F K a S Y E x m 7 5 O B 0 J y h n F h C m R b 2 V s J G V F O G N q S S D c F b f n m V t C 6 q X q 1 a u 6 t V 6 t d</formula><formula xml:id="formula_7">q P q A a B Z f Y M t w I v E 8 U 0 i g Q 2 A n G N z O / 8 4 R K 8 1 j e m U m C f k S H k o e c U W O l 5 k O / X H G r 7 h x k l X g 5 q U C O R r / 8 1 R v E L I 1 Q G i a o 1 l 3 P T Y y f U W U 4 E z g t 9 V K N C W V j O s S u p Z J G q P 1 s f u i U n F l l Q M J Y 2 Z K G z N X f E x m N t J 5 E g e 2 M q B n p Z W 8 m / u d 1 U x N e + R m X S W p Q s s W i M B X E x G T 2 N R l w h c y I i S W U K W 5 v J W x E F W X G Z l O y I X j L L 6 + S 9 k X V q 1 V r z V q l f p 3 H U Y Q T O I V z 8 O A S 6 n A L D W g B A 4</formula><p>R n e I U 3 5 9 F 5 c d 6 d j 0 V r w c l n j u E P n M 8 f u Y O M 5 A = = &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Xt+1</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a j</p><formula xml:id="formula_8">L q f C Z o v 3 o 6 F T n f b 5 4 h 4 x E y G I 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B Z B E E o i B T 0 W v X i s Y G u h D W W z 3 b Z L N 5 u 4 O y m U k N / h x Y M i X v 0 x 3 v w 3 b t s c t P X B w O O 9 G W b m B b E U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o k S z X i T R T L S 7 Y A a L o X i T R Q o e T v W n I a B 5 I / B + H b m P 0 6 4 N i J S D z i N u R / S o R I D w S h a y e + O K K b t r J f i h Z f 1 y h W 3 6 s 5 B V o m X k w r k a P T K X 9 1 + x J K Q K 2 S S G t P x 3 B j 9 l G o U T P K s 1 E 0 M j y k b 0 y H v W K p o y I 2 f z o / O y J l V + m Q Q a V s K y V z 9 P Z H S 0 J h p G N j O k O L I L H s z 8 T + v k + D g 2 k + F i h P k i i 0 W D R J J M C K z B E h f a M 5 Q T i 2 h T A t 7 K 2 E j q i l D m 1 P J h u A t v 7 x K W p d V r 1 a t 3 d c q 9 Z s 8 j i K c w C m c g w d X U I c 7 a E A T G D z B M 7 z C m z N x X p x 3 5 2 P R W n D y m W P 4 A + f z B 7 o Y k h M = &lt; / l a t e x i t &gt; Solver (a) (c) Solver (b) Ŷ = Y (N ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E r h t h i E 4 w c y O R 5 L h K X 4 L n v m T k N M = " &gt; A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L B a h X k o i B b 0 I R S + e p I L 9 o o 1 l s 9 2 2 S z e b s D s R a s g v 8 e J B E a / + F G / + G 7 d t D t r 6 Y O D x 3 g w z 8 / x I c A 2 O 8 2 2 t r K 6 t b 2 z m t v L b O 7 t 7 B X v / o K H D W F F W p 6 E I V c s n m g k u W R 0 4 C N a K F C O B L 1 j T H 1 9 P / e Y j U 5 q H 8 h 4 m E f M C M p R 8 w C k B I / X s Q n d E I G m n l + 2 H p H R 7 m v b s o l N 2 Z s D L x M 1 I E W W o 9 e y v b j + k c c A k U E G 0 7 r h O B F 5 C F H A q W J r v x p p F h I 7 J k H U M l S R g 2 k t m h 6 f 4 x C h 9 P A i V K Q l 4 p v 6 e S E i g 9 S T w T W d A Y K Q X v a n 4 n 9 e J Y X D h J V x G M T B J 5 4 s G s c A Q 4 m k K u M 8 V o y A m h h C q u L k V 0 x F R h I L J K m 9 C c B d f X i a N s 7 J b K V f u K s X q V R Z H D h 2 h Y 1 R C L j p H V X S D a q i O K I r R M 3 p F b 9 a T 9 W K 9 W x / z 1 h U r m z l E f 2 B 9 / g A d 6 p K 9 &lt; / l a t e x i t &gt; Y (0)</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 U Y 9 T z o 0    </p><formula xml:id="formula_9">x S g u D E f P u Y b W H G s R n h 0 = " &gt; A A A B 7 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 F X A n o M e v E Y w T w k W c P s Z J I M m Z 1 d Z n q F s O Q j v H h Q x K v f 4 8 2 / c Z L s Q R M L G o q q b r q 7 g l g K g 6 7 7 7 e T W 1 j c 2 t / L b h Z 3 d v f 2 D 4 u F R 0 0 S J Z r z B I h n p d k A N l 0 L x B g q U v B 1 r T s N A 8 l Y w v p n 5 r S e u j Y j U P U 5 i 7 o d 0 q M R A M I p W a j 0 8 p m X 3 f N o r l t y K O w d Z J V 5 G S p C h 3 i t + d f s R S 0 K u k E l q T M d z Y / R T q l E w y a e F b m J 4 T N m Y D n n H U k V D b v x 0 f u 6 U n F m l T w a R t q W Q z N X f E y k N j Z m E g e 0 M K Y 7 M s j c T / / M 6 C Q 6 u / F S o O E G u 2 G L R I J E E I z L 7 n f S F 5 g z l x B L K t L C 3 E j a i m j K 0 C R V s C N 7 y y 6 u k e V H x q p X q X b V U u 8 7 i y M M J n E I Z P L i E G t x C H R</formula><formula xml:id="formula_10">D I f f A = " &gt; A A A B 6 H i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 4 k o m X Q x j I B 8 w H J E f Y 2 c 8 m a v b 1 j d 0 8 I R 8 D e x k I R W 3 + S n f / G z U e h i Q 8 G H u / N M D M v S A T X x n W / n d z a + s b m V n 6 7 s L O 7 t 3 9 Q P D x q 6 j h V D B s s F r F q B 1 S j 4 B I b h h u B 7 U Q h j Q K B r W B 0 O / V b j 6 g 0 j + W 9 G S f o R 3 Q g e c g Z N V a q 6 1 6 x 5 J b d G c g q 8 R a k B A v U e s W v b j 9 m a Y T S M E G 1 7 n h u Y v y M K s O Z w E m h m 2 p M K B v R A X Y s l T R C 7 W e z Q y f k z C p 9 E s b K l j R k p v 6 e y G i k 9 T g K b G d E z V A v e 1 P x P 6 + T m v D a z 7 h M U o O S z R e F q S A m J t O v S Z 8 r Z E a M L a F M c X s r Y U O q K D M</formula><formula xml:id="formula_11">L 0 T S O S d o K 4 p J i R a c G K B Y k Q H q M h 6 S s M k E + E n W S 7 T O G x c l z o h V y d Q M L M / T 2 R I F + I i e + o T h / J k V i s p e Z / t X 4 s v Q s 7 o U E U S x L g 2 U N e z K A M Y R o M d C k n W L K J A o Q 5 V X + F e I Q 4 w l L F V 1 A h m I s</formula><formula xml:id="formula_12">f d E R i K t Z 1 F g O i O C E 7 3 q z c X / v E G K 4 Y 2 f c Z m k y C R d L g p T Y W N s z w O w R 1 w x i m J m C K G K m 1 t t O i G K U D Q x V U w I 7 u r L 6 6 R 7 V X</formula><formula xml:id="formula_13">f P u Y b W H G s R n h 0 = " &gt; A A A B 7 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 F X A n o M e v E Y w T w k W c P s Z J I M m Z 1 d Z n q F s O Q j v H h Q x K v f 4 8 2 / c Z L s Q R M L G o q q b</formula><p>r q 7 g l g K g 6 7 7 7 e T W 1 j c 2 t / L b h Z 3 d v f 2 D 4 u F R 0 0 S J Z r z B I h n p d k A N l 0 L x B g q U v B 1 r T s N A 8 l Y w v p n 5 r S e u j Y j U P U 5 i 7 o d 0 q M R A M I p W a j 0 8 p m X 3 f N o r l t y  Gonzalez et al., 2020) with a comparable number of parameters, and than Neural Projections <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>.</p><formula xml:id="formula_14">K O w d Z J V 5 G S p C h 3 i t + d f s R S 0 K u k E l q T M d z Y / R T q l E w y a e F b m J 4 T N m Y D n n H U k V D b v x 0 f u 6 U n F m l T w a R t q W Q z N X f E y k N j Z m E g e 0 M K Y 7 M s j c T / / M 6 C Q 6 u / F S o O E G u 2 G L R I J E E I z L 7 n f S F 5 g z l x B L K t L C 3 E j a i m j K 0 C R V s C N 7 y y 6 u k e V H x q p X q X b V U u 8 7 i y M M J n E I Z P L i E G t x C H R</formula><formula xml:id="formula_15">m t v L b O 7 t 7 B X v / o K H D W F F W p 6 E I V c s n m g k u W R 0 4 C N a K F C O B L 1 j T H 1 9 P / e Y j U 5 q H 8 h 4 m E f M C M p R 8 w C k B I / X s Q n d E I G m n l + 2 H p H R 7 m v b s o l N 2 Z s D L x M 1 I E W W o 9 e y v b j + k c c A k U E G 0 7 r h O B F 5 C F H A q W J r v x p p F h I 7 J k H U M l S R g 2 k t m h 6 f 4 x C h 9 P A i V K Q l 4 p v 6 e S E i g 9 S T w T W d A Y K Q X v a n 4 n 9 e J Y X D h J V x G M T B J 5 4 s G s c A Q 4 m k K u M 8 V o y A m h h C q u L k V 0 x F R h I L J K m 9 C c B d f X i a N s 7 J b K V f u K s X q V R Z H D h 2 h Y 1 R C L j p H V X S D a q i O K I r</formula><p>We demonstrate several unique features of our model. First, the constraint function is decoupled from the procedure for satisfying it. The user can choose different solvers or invest different amounts of computation to improve the solution.</p><p>We show that C-GNS can use additional solver iterations at test time to improve its predictive accuracy, striking desired speed-accuracy trade-offs. Second, our model allows to incorporate new, hand-designed constraints at test time and satisfy them jointly alongside its learned constraints. These properties have not been reported previously for explicit forward models or Neural Projections by <ref type="bibr" target="#b45">Yang et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and related work</head><p>Constraint solvers are central to many physics simulators. Most rigid-body and game engines use constraints to model joints, collision and contact <ref type="bibr" target="#b4">(Baraff, 1994)</ref>. Position-based <ref type="bibr" target="#b30">(Müller et al., 2007)</ref> and projective dynamics <ref type="bibr" target="#b8">(Bouaziz et al., 2014)</ref> are popular methods that express the time dynamics purely as constraints and can simulate a wide range of physical systems such as rigids, soft-bodies, fluids and cloth <ref type="bibr" target="#b25">(Macklin et al., 2014a;</ref><ref type="bibr" target="#b38">Thomaszewski et al., 2009)</ref>.</p><p>There is a rapid growth of machine learning methods for accelerating scientific simulation of complex systems, such as turbulence <ref type="bibr" target="#b37">(Stachenfeld et al., 2021;</ref><ref type="bibr" target="#b37">Kochkov et al., 2021)</ref> and aerodynamics <ref type="bibr" target="#b39">(Thuerey et al., 2020;</ref><ref type="bibr" target="#b22">Zhang et al., 2018)</ref>.</p><p>Particularly, a learned simulator based on graph neural networks is a popular approach for modelling a wide range of systems, from articulated dynamics (Sanchez-Gonzalez et al., 2018) to particle-based physics <ref type="bibr" target="#b29">(Mrowca et al., 2018;</ref><ref type="bibr" target="#b21">Li et al., 2019;</ref><ref type="bibr" target="#b36">Sanchez-Gonzalez et al., 2020)</ref> and meshbased continuum systems <ref type="bibr" target="#b32">(Pfaff et al., 2021;</ref><ref type="bibr" target="#b13">De Avila Belbute-Peres et al., 2020)</ref>. Combining learning algorithms with principles from physics and numerical methods can improve sample complexity, computational efficiency, and generalization <ref type="bibr" target="#b44">(Wu et al., 2018;</ref><ref type="bibr" target="#b19">Karniadakis et al., 2021;</ref><ref type="bibr" target="#b10">Chen et al., 2018;</ref><ref type="bibr" target="#b33">Rubanova et al., 2019)</ref>. Imposing Hamiltonian <ref type="bibr" target="#b18">(Greydanus et al., 2019;</ref><ref type="bibr" target="#b35">Sanchez-Gonzalez et al., 2019;</ref><ref type="bibr" target="#b11">Chen et al., 2019)</ref> and Lagrangian <ref type="bibr" target="#b24">(Lutter et al., 2019;</ref><ref type="bibr" target="#b12">Cranmer et al., 2020;</ref><ref type="bibr" target="#b16">Finzi et al., 2020)</ref> mechanics in learned simulators offers unique speed/accuracy tradeoffs and can preserve symmetries more effectively.</p><p>Outside of the scope of physical simulations, recent methods were proposed for learning implicit functions (see "Deep Implicit Layers" tutorial by <ref type="bibr" target="#b15">Duvenaud et al. (2020)</ref> for an excellent survey). Such models can play games <ref type="bibr" target="#b0">(Amos &amp; Kolter, 2017;</ref><ref type="bibr" target="#b42">Wang et al., 2019)</ref>, optimize power flow <ref type="bibr" target="#b14">(Donti et al., 2021)</ref>, support robotic planning <ref type="bibr" target="#b23">(Loula et al., 2020)</ref>, and perform combinatorial optimization <ref type="bibr" target="#b5">(Bartunov et al., 2020)</ref>. Deep Equilibrium Models <ref type="bibr" target="#b2">(Bai et al., 2019;</ref><ref type="bibr">2020)</ref> use implicit differentiation technique to reduce the cost of computing the gradients through the solver.</p><p>Despite the popularity of traditional constraint-based simulators, only a single work that projects positional variables on a learned constraint manifold has been reported <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>. See Section 4.4 for a detailed comparison between our model and <ref type="bibr" target="#b45">Yang et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Simulation basics</head><p>A physical trajectory, measured at discrete time intervals, is a sequence of states, (X 1 , . . . , X T ), where X t may contain properties of elements of the system such as the positions, instantaneous velocities, masses, etc. A physical simulator s is a function that maps current and/or previous state(s), which we term the context X ≤t<ref type="foot" target="#foot_0">1</ref> , to a predicted future state Xt+1 = s(X ≤t )<ref type="foot" target="#foot_1">2</ref> (see Figure <ref type="figure" target="#fig_24">1a</ref>). A simulated physical trajectory termed a rollout (X t , Xt+1 Xt+2 , . . . ), can be generated by repeatedly applying s to its own predicted state, Xt+1 = s(X ≤t ).</p><p>Simulators are often comprised of a PREDICTOR and an UPDATER mechanism. The PREDICTOR maps the context X ≤t to an update value Ŷ that represents information about the system's temporal evolution at the current time (e.g., new positions, velocities or accelerations). Then the UP-DATER mechanism uses Ŷ to update the current state to the next state: Xt+1 = UPDATER(X ≤t , Ŷ ), e.g. updating current positions and velocities represented by X t with new velocities and accelerations represented by Ŷ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Explicit simulators</head><p>Across science, engineering, and graphics, a popular class of simulators <ref type="bibr" target="#b40">(Todorov et al., 2012;</ref><ref type="bibr" target="#b28">Monaghan, 2005;</ref><ref type="bibr" target="#b27">Mirtich &amp; Canny, 1995;</ref><ref type="bibr" target="#b43">Witkin et al., 1990)</ref> are defined explicitly: the state update Ŷ is predicted directly from X ≤t using an explicit forward function Ŷ = f D (X ≤t ). Among the learned simulators, the forward function f D is typically implemented using a graph neural network (GNN) that allows simulators to scale well to large graphs of 1000s of nodes and support generalization to systems with different shapes and sizes <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021;</ref><ref type="bibr" target="#b6">Battaglia et al., 2016)</ref>. We call the explicit GNNbased model Forward GNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Constraint-based implicit simulators</head><p>In this paper we explore the learned simulators based on implicit formulations of the dynamics. Instead of predicting the desired state directly, our implicit simulator uses a differentiable constraint function c = f C (X ≤t , Y ), where c is a scalar that quantifies how well a proposed state update Y agrees with X ≤t . A future prediction is generated in two stages: 1) apply a solver (gradient descent or a zero-finding algorithm) to find a Ŷ that satisfies the constraint function, and 2) use the value Ŷ in the UPDATER to update X t to Xt+1 . Our constraint function f C is defined as a trainable neural network with a non-negative scalar output. It represents an approximation for all the physical constraints in the system, including the time dynamics.</p><p>As illustrated in Figure <ref type="figure" target="#fig_24">1</ref>(b), we formulate our constraintsolving procedure via an iterative method that starts with an initial proposal Y (0) . On the i-th iteration, the solver uses the gradient of</p><formula xml:id="formula_16">f C w.r.t. Y to compute a change to the proposal, δY = −λ ∇ Y f C (X ≤t , Y )| Y =Y (i) .</formula><p>Then, δY is used to revise the proposal: Y (i+1) = Y (i) + δY . This process repeats for N steps, and the final proposal value is considered to be the PREDICTOR's output Ŷ = Y (N ) .</p><p>We define the solution as the minimum of the constraint function Ŷ = argmin Y f C (X ≤t , Y ). We use gradient de-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BoxBath</head><p>Bouncing Balls Bouncing Rigids Rope scent with the fixed step size λ to find the solution Ŷ . We refer to our Constraint-based Graph Network Simulator with gradient descent solver as C-GNS-GD.</p><p>This general formulation of constraint-based learned simulation can be trained by backpropagating loss gradients through the solver iterations<ref type="foot" target="#foot_2">3</ref> . The computational budget of the forward pass can be varied via the number of solver iterations N , as we further explore in Section 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Explicit iterative simulators</head><p>As a hybrid between forward and constraint-based simulators, we also introduce Iterative GNN model. Similarly to C-GNS-GD, this model iteratively refines the proposed state update, but at each iteration δY is predicted directly by a graph neural network δY = f DI (X ≤t , Ŷ ), instead of being computed through a gradient. We use this hybrid model to separately study the effect of pure iterations versus iterative constraint-based optimization (Section 5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental task domains</head><p>We tested our approach on a variety of physical environments, shown in Figure <ref type="figure" target="#fig_13">2</ref>. We generated the data for our ROPE, BOUNCING BALLS and BOUNCING RIGIDS datasets using the MuJoCo physics simulator <ref type="bibr" target="#b40">(Todorov et al., 2012)</ref>.</p><p>We also tested our model on BOXBATH dataset with 1024 particles from <ref type="bibr" target="#b21">(Li et al., 2019)</ref> to explore the scaling capabilities of the model. These environments involve a diverse set of physical constraints: 'hard' constraints on preserving the rigid shapes and resolving collisions, and 'soft' constraints on fluid movement, handling gravity and preserving the momentum. The simulations consist of 150 time steps for BOXBATH and 160 time steps for other datasets.</p><p>Representing the physical system Our experimental domains consist of interacting point-like elements: sized objects, fluid particles or mesh vertices. The datasets contain the positions of each element: P t = (p j t ) j=1...J , where J is the number of elements, and p j t is the j-th element's po-sition at time t. Note that our datasets do not contain the instantaneous velocities. Instead, the velocity information can be estimated by changes in the position, as described below. Additionally, we represent the static properties of the physical elements (masses, material types, etc.) as Z to keep it distinct from the dynamic state information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation of the C-GNS model</head><p>In our implementation, the state X t consists of the positions P t and the static information Z. The input context is a sequence of the most recent positions and the static properties:</p><formula xml:id="formula_17">X ≤t := (Z, P t−3 , P t−2 , P t−1 , P t ).</formula><p>To represent the dynamics, we set the update Y to be the change in position over time V t+1 = (v j t+1 ) j=1...J ≡ (p j t+1 − p j t ) j=1...J , which we informally call "velocity", estimated as a backward difference. The update mechanism Xt+1 = UPDATER(X ≤t , Ŷ ) simply becomes Pt+1 = P t + Vt+1 , where Vt+1 is the output of a PREDICTOR. For BOXBATH, we set the update Y to the acceleration, for the sake of consistency with Sanchez-Gonzalez et al. ( <ref type="formula">2020</ref>) (see details in Supplementary Section A.2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GNN-based constraint function</head><p>We represent the context X ≤t and a proposed update Y (i) as a graph where the nodes correspond to different elements, such as objects or particles, and the edges correspond to the possible pairwise interactions between them. The function f C takes the input graph containing X ≤t and Y (i) and outputs a scalar value c.</p><p>To construct the graph features from the context X ≤t , we enforce translation-invariance and do not explicitly provide absolute positions P t as the input to the network. The features for the node j, [z j , v j t−2 , v j t−1 , v j t ], include a sequence of three most recent position changes (i.e. velocities) v j t = p j t − p j t−1 and static properties z j . To construct the edge feature from nodes j to k, we provide the relative displacement vector between the nodes' positions, e jk t = p k t − p j t . Finally, to represent Y (i) , we concatenate the proposed update for node j from the i-th solver iteration y j,(i) (velocity or acceleration) to the node features.</p><p>We implement the function f C as a graph network (GNN) similar to <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020)</ref>. We encode nodes and edges of the input graph using MLPs. Then, we process the graph with a GNN consisting of a sequence of message-passing (MP) layers without global updates. Next, we compute the scalar values c j for each node by running an MLP decoder on the node outputs of the GNN. We square the values c j to make them non-negative. Finally, we obtain a single scalar constraint c for the entire graph by averaging the per-node values c</p><formula xml:id="formula_18">= f C (X ≤t , Ŷ ) = 1 J J j=1 (c j ) 2 .</formula><p>Optimizing the constraint We initialize Y (0) to the most recent velocity V t , as we expect it to be a good prior for  the future velocity. In BOXBATH, where Y represents the acceleration, we initialize Y (0) to a zero vector. We use autodifferentiation in JAX to compute the constraint gradient ∇ Y f C . For the gradient descent solver, we use a fixed step size λ = 0.001. We used N = 5 iterations during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Training and evaluation</head><p>We compute the L 2 loss between the predicted update Ŷ from the last solver iteration and the corresponding groundtruth update, averaged over all nodes. Note that it is straightforward to compute the ground-truth update from the dataset.</p><p>For example, if Y represents the velocity, the update is simply the difference between the future and current positions.</p><p>To further incentivize to convergence to the ground-truth, we experimented with an additional loss between each intermediate update Y (i) and the ground-truth with exponential decay weights (details in Section A.3). We use the additional loss only in the generalization experiments in Section 5.4, labeled with α = 0.25. For other experiments, the additional loss had little effect on the MSE error (Figure <ref type="figure" target="#fig_21">7</ref>).</p><p>We train the model on one-step prediction task using standard backpropagation with the Adam optimizer. At test time, we evaluate 1-step and rollout errors between predicted and ground truth trajectories. The rollout is computed by iteratively applying the model on the previous predictions, starting from the initial time step sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Neural Projections and related ablations</head><p>The only related work involving learned constraint-based simulation that we are aware of is Neural Projections (NP, <ref type="bibr" target="#b45">Yang et al. (2020)</ref>). While it inspired this work, Neural Projections has key differences from our approach, and is fundamentally limited in ways that make it insufficient as a general-purpose learned simulator.</p><p>Neural Projections operates directly on the absolute positions of the particles. First, the model uses an Euler step to propose a future position of the particles based on the previous position, estimated velocity and known external forces.</p><p>Then the model refines the proposal by iteratively projecting it onto a learned constraint manifold, implemented as a multilayer perceptron (MLP). In our framework, this would be equivalent to (1) setting the optimized update Y to be the future positions of the system Y := P t+1 (the UPDATER becomes the identity function), ( <ref type="formula">2</ref> Finally, Neural Projections uses an MLP as a constraint function that takes the concatenated features for all of the particles and outputs a constraint value. Compared to GNNs, MLP-based simulators have been shown to be sub-optimal to model particle systems <ref type="bibr" target="#b6">(Battaglia et al., 2016;</ref><ref type="bibr" target="#b34">Sanchez-Gonzalez et al., 2018)</ref>. Neural Projection paper <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> includes a heuristic parameter-sharing scheme to allow variable number of particles, but it requires manually grouping subsets of the state. It is not clear how this heuristic would scale to large systems with dynamically changing interactions. We also created ablated versions of our model that uses an MLP-based constraint function instead of a GNN: C-MLP-GD and C-MLP-FP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Comparison to existing baselines</head><p>Our experimental results show that the performance of C-GNS-GD is generally better than the existing baselines on the datasets we tested. <ref type="foot" target="#foot_3">4</ref> Figure <ref type="figure" target="#fig_15">3</ref> demonstrates that C-GNS-GD has the lowest 1-step and rollout MSE across all datasets, compared to Neural Projections <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> and Forward GNN <ref type="bibr" target="#b32">(Pfaff et al., 2021)</ref> with a comparable number of parameters<ref type="foot" target="#foot_4">5</ref> . See Supplementary Table <ref type="table">B</ref>.1 for numerical results. Qualitatively, we observed that for Forward GNN, the box in BOXBATH "melts" over time, as the forward model cannot preserve its rigid shape (see Videos). By contrast, the comparable C-GNS-GD effectively maintains the rigid shape of the cube. We further explore the comparison to a larger Forward GNN with up to 5x more parameters in Sections 5.4 and 5.7. These results suggest that constraintbased learned simulators are a competitive alternative to explicit forward simulators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Interpreting the learned constraints</head><p>To better understand the learned constraint f C in the C-GNS-GD, we visualized how the output of f C changes as a function of Y . We varied the proposed update Y (velocity in 2D space) for a particular node while holding the updates Y for other nodes fixed. Figure <ref type="figure" target="#fig_16">4</ref>(a) shows the learned constraint for a node from the ROPE dataset. The network learns a "funnel" shape of the constraint that is easy to minimize with gradient descent. The constraint has a single minimum that is near the ground-truth point (the white cross). It is expected, as there is only one valid next state of the system. The sequence of points represents the proposed updates Y (i) from the solver, demonstrating that the solver reaches the ground-truth in five iterations, as expected. Note that we did not enforce the "funnel" shape of the constraint.</p><p>Figure <ref type="figure" target="#fig_16">4</ref>(b) shows the learned constraint f C for several nodes in BOUNCING BALLS. For the red ball, which is far from other balls, the constraint has a "funnel" shape, similarly to the ROPE example. For the balls that have another object nearby, the constraint value is high in the area occupied by that object, indicating that overlapping with another object would result in an invalid physical state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Constraint convergence to the minimum point</head><p>A natural question is: does the gradient descent (GD) solver converge to the minimum? Supplementary Figure <ref type="figure">B</ref>.2 demonstrates that the constraint value in C-GNS-GD approaches a constant in five or more solver iterations. It is expected, as the model was trained in conjunction with the GD solver with five iterations. Using a loss on the intermediate updates with α=0.25 further improves the convergence. We found that this loss is crucial for the generalization (Section 5.4), but does not affect the MSE otherwise (Figure <ref type="figure" target="#fig_21">7</ref>).</p><p>We also investigate whether other gradient-based solvers are able to optimize the constraint function learned by C-GNS-GD (α=0.25) model at test time <ref type="bibr">(Figure B.3)</ref>. Other solvers, such as quasi-Newton BFGS method, find the solution with a similar constraint value and a similar MSE error to the GD solver. This finding suggests that it is sufficient to train the C-GNS model with GD solver with a fixed number of iterations in order to learn a well-behaved constraint function with the minimum near the ground-truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Generalizing to larger systems with more iterations</head><p>A unique feature of our C-GNS-GD model is that the number of solver iterations can be increased to potentially improve the quality of the model's predictions. We explore this property on the rope simulation in two settings: on the same dataset used during the training and on a generalization to the ropes with twice as many nodes. We compare the generalization of C-GNS-GD model to the Iterative GNN (Section 3.4) which also iteratively refines the solution, but does not use the constraint gradients. For this section, we use an additional loss (α = 0.25) on intermediate updates  . We emphasize that this experiment was performed on a new dataset and with more solver iterations on each of 160 steps of the rollout -none of these conditions were observed at training time.</p><formula xml:id="formula_19">Y (i)</formula><p>Note also that this result is achieved with a shallow C-GNS-GD model with 2 message-passing layers that spans 1/10 of the rope length on generalization task. By contrast, the performance of the Iterative GNN (blue) with the same number of MP layers stays the same for N test &gt; 4. It demonstrates that C-GNS-GD can leverage extra computational resources at test time, because of the inductive bias that the solver should (approximately) converge to a solution.</p><p>In Figure <ref type="figure" target="#fig_19">5a</ref>-b we also compared C-GNS-GD to the Forward GNN with the same number of parameters (2 MP, grey line). We find that the C-GNS-GD has an order of magnitude better performance, on both the ROPE and the generalization dataset. Next, we compared C-GNS-GD to a deeper Forward GNN with 10 MP (black line). Even though the state-of-the-art Forward GNN (10 MP) is slightly better on the ROPE dataset (Figure <ref type="figure" target="#fig_19">5a</ref>), C-GNS-GD achieves about 50% lower error when generalizing to the larger system by leveraging additional optimization iterations (Figure <ref type="figure" target="#fig_19">5b</ref>).</p><p>In this section we showed that by increasing the number of iterations N at test time, C-GNS-GD can achieve more accurate solutions without re-training or fine-tuning the model.</p><p>To our knowledge this is the first demonstration of leveraging additional resources to improve generalization to a larger system in the domain of learned physical simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Incorporating novel constraints at test time</head><p>A unique advantage of the constraint-based model is that we can incorporate additional, hand-designed constraints at test time without any fine-tuning on the model. To do so, we simply take a weighted sum of the hand-designed constraints and the learned constraint f C and run the forward evaluation to find the solution of the joint constraint.</p><p>We designed three constraint functions for the ROPE dataset that represent the "forbidden" regions of the space: a vertical wall, a horizontal floor, and a disk-shaped region (Figure <ref type="figure" target="#fig_20">6</ref>). The hand-designed constraints are non-negative and increase quadratically as the rope nodes enter the "forbidden" region.</p><p>Figure <ref type="figure" target="#fig_20">6</ref> shows that the model resolves the collisions between the rope and the obstacle. This behavior is new: there are no examples of the rope interacting with other objects in the training data. Note that satisfying the additional constraint may require to slightly violate the learned constraint, which is trained on the ropes moving solely under gravity.</p><p>In some rollouts, the model finds the solution where the rope links change in length to avoid the obstacle. To prevent this, we add a second hand-designed constraint to preserve the lengths of the rope links (see Videos).</p><p>More broadly, this is a powerful example of how constraintbased models can generalize to behaviors outside of their training data, and solve both for the learned dynamics and arbitrary desired constraints. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model variant</head><formula xml:id="formula_20">f C Solution Use X ≤t ? specification Neural Projections MLP fC = 0 fC(Y ) C-MLP-FP MLP fC = 0 fC(X ≤t , Y ) C-MLP-GD MLP argmin fC fC(X ≤t , Y ) C-GNS-FP GNN fC = 0 fC(X ≤t , Y ) C-GNS-GD fC(Y ) GNN argmin fC fC(Y ) C-GNS-GD GNN argmin fC fC(X ≤t , Y )</formula><p>Table <ref type="table">1</ref>. Model ablations. The "Model variant" column lists the names of Neural Projections, our model, and the ablated models.</p><p>The "fC" column indicates whether the constraint function was an MLP or GNN. The "Solution specification" column indicates how the solution was defined, i.e., as the zero point or minimum of the constraint function. The "Use X ≤t ?" column indicates whether or not the constraint function operated over the previous states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Examining differences from Neural Projections</head><p>We demonstrate that our model's key differences from Neural Projections <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> provide substantial improvements in performance. We provide ablations of our C-GNS-GD for each of these differences (conditioning on past states, using GNNs, using gradient descent), as summarized in Table <ref type="table">1</ref>. Figure <ref type="figure" target="#fig_21">7</ref> shows that C-GNS-GD has several orders of magnitude lower rollout error compared to Neural Projection. Each of our ablations towards Neural Projection had higher error than C-GNS-GD. Parameterising the constraint with a GNN instead of an MLP yields the largest improvement on all datasets, particularly on ROPE.</p><p>We found that FP-based models were difficult to train. Notice that the FP models (C-GNS-FP and C-MLP-FP) suffer from instability across seeds. We speculate that the FP algorithm makes the training challenging because the step size λ is proportional to f C . This may cause poor zero-finding early in training when the f C is not yet informative. Additionally, we find that C-GNS-FP algorithm becomes unstable in the areas with shallow constraint gradients, perhaps because its λ depends on the inverse of the gradient's norm. We report comparisons between C-GNS-GD and Iterative GNN in Supplementary Figures B.6 and B.5. The Iterative GNN has higher 1-step error than C-GNS-GD on all our datasets and is competitive in terms of the rollout error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.">Further Comparison to Forward GNN</head><p>We explored how varying the number of MP layers and solver iterations N at training time influenced the performance of C-GNS-GD compared to Forward GNN in our ROPE dataset (Supplementary Figure B.7). Even when training with one iteration of the solver, C-GNS-GD outperforms the Forward GNN with the same number of MP layers. The performance further improves if we train C-GNS-GD with more iterations (from 1 to 5), while using exactly the same number of model parameters. In comparison to deeper Forward GNN (right-most facet), C-GNS-GD with 4 MP layers and 5 iterations has similar 1-step and full rollout MSE to a Forward GNN with 10 MP layers, demonstrating that C-GNS-GD generally requires 2.5 times fewer MP layers than Forward GNN to achieve comparable performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We presented a general-purpose framework for constraintbased learned simulation, where a learned constraint function implicitly represents the time dynamics of the physical system and future predictions are generated via a constraint solver. We implemented our constraint function as a graph network and used gradient descent as the constraint solver.</p><p>Our results showed that our C-GNS has competitive or better performance compared to previous learned simulators in a variety of challenging physical simulation problems. We demonstrated unique abilities of C-GNS to generalize to novel, hand-designed constraints and improve the simulation accuracy on larger systems at test time by increasing solver iterations. These properties have not been previously demonstrated in the space of learned physical simulations.</p><p>Implicit constraint-based models have stronger inductive biases, compared to explicit forward simulators, offering trade-offs between expressivity, adaptive computation and allowing to incorporate manual constraint terms. One inductive bias is parameter-sharing: the gradient ∇ Y f C in C-GNS effectively ties the parameters across N solver iterations. In principle, a deep forward simulator can be more expressive than C-GNS: each layer in the unshared forward model could take values of the shared parameters of C-GNS.</p><p>In practice, C-GNS requires 2.5 times fewer MP layers to achieve a comparable test performance to the forward simulator with 10 MP layers (Section 5.7). Another inductive bias is that C-GNS searches for a solution that converges to the fixed point. This property makes it easy and natural to incorporate novel hand-designed constraints at test time, and generalize to more solver iterations and larger systems.</p><p>One key area for further improvements in constraint-based models is the runtime. Our model applies the gradient descent solver in the forward pass, requiring 2N -times longer computation time (N is the number of solver iterations) compared to the forward model with the same number of parameters. The multiplier 2 is due to the computation of the constraint gradient via vector-Jacobian product (VJP). Similar iterative models, such as Deep Equilibrium models (DEQ, <ref type="bibr" target="#b2">Bai et al. (2019)</ref>), suffer from similar issues. Different techniques may help reduce the runtime and the memory cost: using more efficient, adaptive solvers or alternative ways to compute the gradient of the solution (e.g., implicit differentiation <ref type="bibr" target="#b22">(Liao et al., 2018)</ref>, as used in DEQs).</p><p>One area where constraint-based simulation may be especially effective is in systems with hard constraints that require finding the equilibrium state of many local constraints and might leverage the adaptive computation. Domains with global constraints might also benefit from using constraintbased simulators, as it is easier to compute the constraint value than to directly propose the state that satisfies it.</p><p>Overall, the performance, generality and unique advantages of constraint-based learned simulation make it an important new direction of machine learning methods for complex simulation problems in science and engineering.</p><p>Zhang, Y., Sung, W. J., and Mavris, D. N. Application of convolutional neural network to predict airfoil lift coefficient. In 2018 AIAA/ASCE/AHS/ASC Structures, <ref type="bibr">Structural Dynamics, and</ref><ref type="bibr">Materials Conference, pp. 1903, 2018.</ref> We clip the distance to the wall at a fixed maximum value so that this feature cannot be exploited by the network to infer the absolute position within the box. For BOUNCING BALLS and BOUNCING RIGIDS we clip the distance at 2.0, and for BOXBATH at 0.08. For the constraint-based and iterative models, we update the distances to the walls after every step of constraint optimization or iteration, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2. EDGE FEATURES</head><p>To construct each input edge feature, we use the concatenated displacement vectors e jk t = p k t − p j t between the most recent positions at time point t for the nodes j and k connected by the edge. Through the ablation studies, we found that it is sufficient to provide the displacements between the nodes only for the most recent time point t.</p><p>For BOXBATH, we also provide the vector norm of the relative distances (not just the vector itself) as an additional edge feature to match <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020)</ref>.</p><p>Note that we do not provide the "rest shapes" (the ground-truth distances of the nodes) for the rigid structures or the rope. When generating a rollout, the model only observes the pairwise displacements/distances between nodes predicted in the previous steps. This makes the rollout prediction more challenging, as the rigid shape might gradually drift from true "rest shape" during the rollout, and there is no way to recover the original shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.3. FURTHER DETAILS</head><p>Parameterizing the update Y For ROPE, BOUNCING BALLS, BOUNCING RIGIDS we use the velocity (defined as difference between the positions at adjacent time points) as the update Y . At the first iterations, Y (0) is initialized to the previous velocity V t . For BOXBATH, we use normalized acceleration of the particle as the update Y to better match the approach in <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021)</ref>. The acceleration is estimated as a backward difference:</p><formula xml:id="formula_21">A t+1 = V t+1 − V t = P t+1 − 2P t + P t−1 .</formula><p>In this case, the UPDATER takes the form Pt+1 = P t + V t + Ât+1 = 2P t − P t−1 + Ât+1 , where Ât+1 is produced by the PREDICTOR. The update Y (0) is initialized to a zero vector on the first iteration. In both cases, the proposed Y is concatenated as an extra node feature at each optimization iteration.</p><p>Normalization For BOXBATH we found it was important to normalize inputs and targets to zero-mean unit-variance (as in <ref type="bibr" target="#b36">Sanchez-Gonzalez et al. (2020)</ref>). In the other datasets, the scale of the features was already close to zero-mean unit-variance, except for the input/target velocities in BOUNCING BALLS and BOUNCING RIGIDS, so we scaled them by a factor of 100.</p><p>Noise To stabilize rollouts in BOXBATH, we added noise to the input sequences in the same manner, and with the same magnitude, as in <ref type="bibr" target="#b21">(Li et al., 2019;</ref><ref type="bibr" target="#b36">Sanchez-Gonzalez et al., 2020)</ref>.</p><p>Fixed particles Some of the datasets contain fixed nodes that do not change the position, such as the "pinned" node in the ROPE. As our GNN models are translation invariant, they do not observe absolute positions of the nodes and cannot correct the position of the fixed nodes. Therefore, we prevent the update for the fixed nodes by using stop gradient for gradient-based constraint models, similarly to <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>. For non-constraint-based models, we override fixed particles positions to remain static during a rollout for all models. We also mask out fixed particles from the loss computation. Note that excluding the fixed particles from the predicted output is a standard practice <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Model Implementation</head><p>Computing the constraint gradients To compute the gradients of the constraint scalars for the batch of graphs, we use the vector-Jacobian product (VJP) function using JAX. VJP does not explicitly construct a Jacobian, and its asymptotic computational cost is the same as the forward evaluation of the constraint function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constraint function</head><p>To construct f C , we first encode the nodes and edges of the graph using MLP encoders. Then, we process the graph using a GNN model from <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021)</ref>. The GNN model has residual connections on each message-passing layer and does not use global updates. Next, we decode the node outputs of the graph network using an MLP decoder with a scalar output to compute the per-node values {c j |j = 1 . . . J}. Finally, to obtain the scalar constraint value for the entire graph, we use the mean aggregation for the per-node values c = f C (X ≤t , Ŷ ) = 1 J J j=1 (c j ) 2 . For gradient descent solver, we take a square of per-node outputs before aggregating them. For fast projections, we simply take the sum of per-node outputs.</p><p>We use a fixed learning rate of 0.001 for gradient descent-based constraint solvers. We did not find the model to be very sensitive to this value of the learning rate. We speculate this is because the model can indirectly control the learning rate by learning an arbitrary scaling factor for the constraint function. We use five iterations of the solver for both gradient descent and fast projection solvers during the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss</head><p>In most experiments we used the MSE loss between the output of the last iteration Ŷ (N ) and the corresponding ground-truth state updates on node positions. In section 5.4 we used the additional MSE loss between intermediate states Ŷ (i) and the ground-truth point, with exponentially decaying weights L interm = α N −i MSE( Ŷ (i) , T ), where T is the ground-truth, N is the number of solver iterations, α is a parameter in (0,1]. The goal of the weighted loss is to encourage the solver to reach the solution in fewer iterations. Earlier iterations have a smaller weight and are penalized less for being farther from the ground-truth. The loss on the last iteration is the same as our standard MSE loss between the last iteration and the ground-truth, as the weight on N -th iterations is α N −N = 1.</p><p>The results on the MSE error and constraint values and gradients with different choices of α are provided on Supplementary Figure B.9. We used α = 0.25 for both C-GNS-GD and Iterative GNN in Section 5.4.</p><p>Fast Projections Fast Projection (FP) algorithm <ref type="bibr" target="#b17">(Goldenthal et al., 2007)</ref> is a zero-finding algorithm, for constraint functions whose solutions are defined as, f C (X ≤t , Y ) = 0. FP uses an adaptive step</p><formula xml:id="formula_22">λ = − f C (X ≤t , Y (i) ) ∇ Y f C (X ≤t , Y )| Y =Y (i) 2 .</formula><p>Then FP updates the proposed state analogous to our C-GNS-GD model,</p><formula xml:id="formula_23">δY = −λ ∇ Y f C (X ≤t , Y )| Y =Y (i) Y (i+1) = δY + Y (i)</formula><p>For our experiments with Fast Projection, we use N = 5 iterations during training, same as for the gradient descent solver.</p><p>Forward GNN For the Forward GNN, we use the Graph Network Simulator (GNS) model <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021)</ref>.</p><p>The PREDICTOR takes only the context X ≤t and directly outputs the update Ŷ . For Forward GNN, the update Y is set to the acceleration A t+1 = V t+1 − V t = P t+1 − 2P t + P t−1 , for consistency with the previous work. Then the update rule in the UPDATER becomes</p><formula xml:id="formula_24">Pt+1 = P t + V t + Ât+1 = 2P t − P t−1 + Ât+1 .</formula><p>The graph with the context X ≤t is built similarly to the one for C-GNS-GD. After the graph is processed by the graph network, the model uses a per-node MLP decoder to output the update values for each node (ŷ j ) j=1...J</p><p>Iterative GNN In the Iterative GNN, the function f DI takes both the context X ≤t and the proposed update Y (i) and outputs a change to the proposed update δY . Then, the model computes the update variable for the next iteration as</p><formula xml:id="formula_25">Y (i+1) = Y (i) + δY .</formula><p>The PREDICTOR outputs the update variable from the last iteration Y (N ) .</p><p>The input to the f DI at each iteration i is constructed the same way as in C-GNS. We take the graph representing the context X ≤t and concatenate the proposed update Y (i) to each node vector. We use a GNS model with a per-node decoder from <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020;</ref><ref type="bibr" target="#b32">Pfaff et al., 2021)</ref> to process the input graph and output δY for each node.</p><p>We set meaning of the update Y similarly to the C-GNS: Y represents the future velocity V t+1 on ROPE, BOUNCING BALLS and BOUNCING RIGIDS; and acceleration A t+1 for BOXBATH. The corresponding UPDATER is also the same as in C-GNS (see Section 4.2). For the first iteration, we initialize Y (0) to the most recent velocity V t , or to a zero vector if Y represents the acceleration (BOXBATH).</p><p>C-GNS-GD-f C (Y ) This model is similar to C-GNS-GD, except the past states X ≤t are not provided as part of the input. For this ablation, the model directly optimizes the positional information of the future state, similarly to <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>, rather than velocity or acceleration. Thus, the update Y is set to the positions P t+1 , as in the Neural Projections model. The corresponding UPDATER becomes simply an identity function.</p><p>To construct the input graph, we use only the positional information of the proposed future state P t+1 and static properties Z. Thus, the node features do not include any information about the past states, nor the proposed approximate future velocity V t+1 = P t+1 − P t . For the edge features, we use the relative displacement vector between the positions of the nodes j and k for the future state e jk t+1 = p k t+1 − p j t+1 .</p><p>Neural Projections, C-MLP-FP and C-MLP-GD For the models with MLP-based constraint function we use a similar setup to <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>. We concatenate the features for each node into a single vector and run an MLP to produce a scalar constraint output. For Neural Projections, we include only absolute positions of the nodes into the input. For C-MLP-FP and C-MLP-GD we additionally use the context of the past states, including absolute positions, velocities and distances to the walls for each node. MLP-based models are not provided with explicit pairwise position displacements between the particles, which for the GNN-based models would be in the edge features of the graph. Therefore, we include absolute positions as input to the MLP-based models instead. Next, MLP-based models take a fixed-sized inputs by construction and cannot handle the scenes with variable number of nodes without additional state segmentation schemes. We adapted the MLP-based models to handle scenes with variable number of nodes by padding with zeros up to the maximum state size.</p><p>We did not report results for MLP-based models on BOXBATH: MLP models take the concatenated input of node embeddings in order, and on the datasets with 1024 nodes like BOXBATH the model is likely to overfit to the specific ordering of the particles and would be unlikely to yield competitive performance. Additionally, the input vector optimized by the solver would have 1024 × 32 elements resulting in very small gradients for each element.</p><p>Hand-designed constraints We make the hand-designed constraints to be non-negative and such that the minimum of the constraint results in the desired behavior. We parameterize these constraints with a c j hand = (ReLU(−D(p j ))) 2 , where D(p j ) is the signed distance between the position of the node j and the boundary of the obstacle. If D(p j ) &gt; 0, the node is outside of the obstacle, and the constraint is zero. If D(p j ) &lt; 0, the node overlaps with an obstacle, and the constraint for this node becomes positive. We compute the total constraint for the entire graph as the average of per-node values: c hand = 1 J J j=1 c j hand . We optimize the weighted sum of the learned and hand-designed constraints: c hand + W c, where W is a constant weight, selected for each hand-designed constraint separately. Note that the hand-designed constraints and the constraints learned by the network can have different scales, and we use the weight W to bring the two constraints roughly on the same scale. We ran a grid search to find the appropriate weight W .</p><p>In some cases, optimizing the joint constraint resulted in an unexpected behavior: the rope shrinks or expands to avoid the obstacle instead of moving around it or stopping at the obstacle. This effect can be explained as follows. Recall that in the ROPE dataset used for training, the ropes do not collide with any obstacles, and the only valid next step is to continue moving under the force of gravity. When we optimize the the hand-designed obstacle constraints together with the learned constraint, the solution would inevitably violate the learned constraint, under which the rope would continue moving under gravity. In some cases, the model chooses to violate the learned constraint by changing the relative distances between the rope nodes, instead of changing the dynamics.</p><p>To incentivize the model to preserve the node distances, we add the second hand-designed constraint on the relative distances between the nodes. First, we compute the norm of the distances between each pair of adjacent nodes at the current time point and at the first time point of the simulation. Then we set the constraint to the squared difference between the distance norms at the two time steps, and average for all pairs of adjacent nodes. This constraint is minimized when the distances between each pair of nodes remain the same. See Videos for the rollouts with obstacle constraint only and the rollouts with both obstacle and distance constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Hyperparameters</head><p>Choice of the number of message-passing layers We chose the smallest possible number of message passing (MP) steps that would allow the C-GNS family of models to solve the task with 5 optimization iterations (2 MP for ROPE, 1MP steps for all other datasets). We then compared this model to a Forward GNN (GNS) with the same architecture and number of parameters for the main result. A full comparison of Forward GNN and C-GNS across multiple values of message passing steps and optimization iterations on ROPE is available in Figure B.7.</p><p>For all GNNs, we used a residual connection for the nodes and edges on each message-passing layer. GNNs have only node and edge updates and do not use global updates.</p><p>Choice of the activation function We noticed that the choice of the activation function affected the Fast Projection method more than Gradient Descent. For each dataset, we chose the activation function for which Fast Projection algorithm (C-GNS-FP) was more stable (more random seeds converged). Then we used the same activation function for other models, including Gradient Descent (C-CNS-GD), as the choice of the activation function had little impact on the performance for other models.</p><p>Rope For GNN-based models, we used 2 message-passing steps. We use the latent size of 32 for nodes and edges. The MLPs for processing nodes and edges, as well as node encoder and decoder MLPs, have 3 hidden layers with 256 hidden units each. We used softplus activation and a LayerNorm <ref type="bibr" target="#b1">(Ba et al., 2016)</ref>.</p><p>Bouncing Balls For GNN-based models, we used 1 message-passing step. We use the latent size of 32 for nodes and edges. The MLPs for processing nodes and edges, as well as node encoder and decoder MLPs, have 3 hidden layers with 256 hidden units each. We use softplus activation and LayerNorm after every MLP, except the final decoder.</p><p>Bouncing Rigids For GNN-based models, we used 1 message-passing step. We use the latent size of 32 for nodes and edges. The MLPs for processing nodes and edges, as well as node encoder and decoder MLPs, have 3 hidden layers with 256 hidden units each. We use tanh activation and LayerNorm after every MLP, except the final decoder.</p><p>Box Bath For GNN-based models, we used 1 message-passing step. All other hyperparameters are as in <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020)</ref>. The GNNs' node and edge function MLPs each had 2 hidden layers with 128 hidden units, and hidden node and edge latent sizes of 128 each. We use softplus activation and LayerNorm after every MLP, except the final decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models with MLP constraints</head><p>For MLP-based models (Neural Projecitons, C-MLP-FP and C-MLP-GD), we used an MLP with 5 hidden layers and 256 hidden units, following the architecture in <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>. We used softplus activation with no LayerNorm.</p><p>Training We train the models for 1M steps on ROPE, BOUNCING BALLS and BOUNCING RIGIDS. We used the Adam optimizer with an initial learning rate of 0.0001, and a decay factor of 0.7 applied with a schedule at steps <ref type="bibr">(1e5, 2e5, 4e5, 8e5)</ref>. We use a batch size of 64. We trained for 2.5M steps for the experiments studying the number of solver iterations. On BOX BATH we trained for 2.5M steps with a batch size of 2, and a learning rate starting at 0.001 and decaying continuously at a rate of 0.1 every 1M steps, as in <ref type="bibr" target="#b36">Sanchez-Gonzalez et al. (2020)</ref>.</p><p>A.5. Limitations of "Neural Projections" <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> The Neural Projections (NP) by <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> is another approach involving learned constraint-based simulation. However, it has several fundamental limitations that make it insufficient as a general-purpose learned simulator. Here we elaborate on these limitations, briefly described in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitation of static constraints</head><p>The learned constraint in NP model depends only on the proposed future positions (i.e. the "static" state). Thus, NP cannot represent constraints that depend on two or more states across time by construction. For example, NP's constraint function on its own cannot model the time dynamics of a single particle with constant velocity, which is presumably why NP applies an Euler step to initialize the first proposal that is passed to the constraint solver. NP is also in principle not well suited to model elastic collisions properly, as illustrated in Figure A.1. In the top scenario, the Euler step proposes the ball moves past the thin wall. Since NP's constraint function does not regard this as a constraint violation, the ball will continue moving ahead as if the wall does not exist. In the bottom scenario, the Euler step places the ball within the wall, and because the nearest constraint-satisfying position for the ball is at the edge of the wall, the approach would, in principle, only correct the position of the ball until the ball stops overlapping the wall as the solution, leaving the ball right next to the wall, regardless of the ball's initial position and velocity before the wall collision.</p><p>More generally, NP cannot enforce constraints or symmetries defined over time, such as energy preservation: once the Euler step breaks energy preservation, the proposed future state does not contain enough information about the energy of the previous state to be able to identify a constraint violation and resolve it in a way that is consistent with the true dynamics.</p><p>Neural Projection also incorporates external forces, such as gravity, by directly updating the velocities before the Euler step, which is probably necessary because, again, NP's constraint function cannot enforce external effects which involve time (e.g., force and acceleration relate to the second time derivative of the position). This is a strong assumption: it means NP must be provided with such temporal effects explicitly, along with the appropriate hard-coded update mechanism, outside of the learnable part of the architecture. Similar to these examples, there are many other types of dynamics that cannot be expressed as constraint satisfaction over the predicted state from an initial Euler proposal, so overall NP cannot be considered a general-purpose learned simulator.</p><p>By contrast, because our approach's constraint function takes both the proposed future state and history as input, i.e., f C (X ≤t , Y ), our method can, in principle, capture any time dynamics which explicit forward simulators can.</p><p>Hard-coded Euler step NP relies on an Euler step to generate the initial proposed future state for the solver. Given that forward Euler is a relatively inaccurate integrator, when the Euler proposal is not accurate, the constraint function's lack of access to the previous state makes it difficult for NP to recover.</p><p>In our approach, the initial proposal to the solver is less important, because the constraint function can capture all aspects of the dynamics. For this reason, we simply initialized the proposal to the most recent velocity given as input (or zero acceleration for BOXBATH). However it is possible to generate initial proposals accounting for external forces or a more sophisticated dynamics prediction mechanism (e.g., an explicit forward simulator).</p><p>MLP network and the hard-coded grouping technique NP uses an MLP network as the constraint function, and serializes and concatenates all input features into a vector before passing to the MLP. Generally this approach is not scalable to even moderately large systems (e.g., the ≥ 1000 nodes in BOXBATH) or systems which vary greatly in size (thus requiring significant padding), for similar reasons that serializing images and passing them to an MLP is inferior to CNN-and Transformer-based methods. <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> do present a scheme for grouping subsets of the input state and passing them to a shared constraint MLP, which is likely intended to overcome the above weakness, however this is more of a heuristic that takes a partial step toward a more mainstream, full-fledged sharing approach, such as our GNN constraint function.</p><p>Lack of translation and permutation equivariance. One of the fundamental properties for modeling physical dynamics is translation equivariance, as the laws of physics do not change based on position in space. Similarly, bodies in a physical system are equivariant to permutations: re-indexing them does not affect the dynamics. <ref type="bibr" target="#b45">(Yang et al., 2020)</ref>'s implementation of NP lack inductive biases for translation and permutation equivariance, which may lead to poor sample complexity of learning and overfitting.</p><p>Zero-finding Fast Projections algorithm NP uses the Fast Projection (FP) algorithm <ref type="bibr" target="#b17">(Goldenthal et al., 2007)</ref> to find zero points in its constraint function. In practice we found that using FP, i.e., in our C-MLP-FP and C-GNS-FP model variants, to train less stably across seeds, and harder to train with deeper networks (see the variance of random seeds in Figure <ref type="figure" target="#fig_15">3</ref>, and trends in Figure B.8). We speculate that because FP's step size is proportional to ratio of the constraint function's value over the squared norm of its gradient, if, early in training, the learned constraint value is large and/or the constraint gradient norm is small, the FP algorithm may take large steps which contribute to the unstable training.</p><formula xml:id="formula_26">X t 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L l u d o u Y L T / B W l L d H l y 1 R e p C F c U E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R i h 4 L X v R W w X 5 A G 8 p m u 2 m X b j Z h d y K U 0 B / h x Y M i X v 0 9 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D v z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W a n f 6 G V 5 4 0 3 6 5 4 l b d O c g q 8 X J S g R y N f v m r N 4 h Z G n G F T F J j u p 6 b o J 9 R j Y J J P i 3 1 U s M T y s Z 0 y L u W K h p x 4 2 f z c 6 f k z C o D E s b a l k I y V 3 9 P Z D Q y Z h I F t j O i O D L L 3 k z 8 z + u m G N 7 4 m V B J i l y x x a I w l Q R j M v u d D I T m D O X E E s q 0 s L c S N q K a M r Q J l W w I 3 v L L q 6 R 1 W f V q 1 a u H W q V + n 8 d R h B M</formula><p>4 h X P w 4 B r q c A c N a A K D M T z D K 7 w 5 i f P i v D s f i 9 a C k 8 8 c w x 8 4 n z / m A I 9 Q &lt; / l a t e x i t &gt; E u le r &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N t K n j l W n J 4 6 3 7 W o t 2 N 4 8 W G 7 e + V Y = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 B I v g q S S i 6 L E g g t 4 q 2 A 9 o Q t l s p + 3 S z S b s z o o l 9 G 9 4 8 a C I V / + M N / + N 2 z Y H b X 0 w 8 H h v h p l 5 U S q 4 R s / 7 d g o r q 2 v r G 8 X N 0 t b 2 z u 5 e e f + g q R O j G D R Y I h L V j q g G w S U 0 k K O A d q q A x p G A V j S 6 n v q t R 1 C a J / I B x y m E M R 1 I 3 u e M o p W C A O E J s x s j Q E 2 6 5 Y p X 9 W Z w l 4 m f k w r J U e + W v 4 J e w k w M E p m g W n d 8 L 8 U w o w o 5 E z A p B U Z D S t m I D q B j q a Q x 6 D C b 3 T x x T 6 z S c / u J s i X R n a m / J z I a a z 2 O I 9 s Z U x z q R W 8 q / u d 1 D P a v w o z L 1 C B I N l / U N 8 L F x J 0 G 4 P a 4 A o Z i b A l l i t t b X T a k i j K 0 M Z V s C P 7 i y 8 u k e V b 1 z 6 s X 9 + e V 2 l 0 e R 5 E c k W N y S n x y S W r k l t R J g z C S k m f y S t 4 c 4 7 w 4 7 8 7 H v L X g 5 D O H 5 A + c z x + c q Z I X &lt; / l a t e x i t &gt; X t &lt; l a t e x i t s h a 1 _ b a s e 6</p><formula xml:id="formula_27">4 = " Z S m Y B D T 3 W 6 k c M Y x F 6 G d j i u e 6 E X Q = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o s e C F 0 9 S 0 X 5 A G 8 p m u 2 m X b j Z h d y K U 0 J / g x Y M i X v 1 F 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D P z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W e u j 0 s V + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h t d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V L 1 a 9 f K + V q n f 5 X E U 4 Q R O 4 R w 8 u I I 6 3 E I D m s B g C M / w C m + O d F 6 c d + d j 0 V p w 8 p l j + A P n 8 w d G s I 3 X &lt; / l a t e x i t &gt; X t+1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g z F Q r / 5 G D U y 5 x n s X N D x a 1 c v m i 6 E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B Z B E E o i F T 0 W v H i S C v Y D 2 l A 2 2 0 2 7 d L M J u x O h h P 4 I L x 4 U 8 e r v 8 e a / c d v m o K 0 P B h 7 v z T A z L 0 i k M O i 6 3 0 5 h b X 1 j c 6 u 4 X d r Z 3 d s / K B 8 e t U y c a s a b L J a x 7 g T U c C k U b 6 J A y T u J 5 j Q K J G 8 H 4 9 u Z 3 3 7 i 2 o h Y P e I k 4 X 5 E h 0 q E g l G 0 U r v T z / D C m / b L F b f q z k F W i Z e T C u R o 9 M t f v U H M 0 o g r Z J I a 0 / X c B P 2 M a h R M 8 m m p l x q e U D a m Q 9 6 1 V N G I G z + b n z s l Z 1 Y Z k D D W t h S S u f p 7 I q O R M Z M o s J 0 R x Z F Z 9 m b i f 1 4 3 x f D G z 4 R K U u S K L R a F q S Q Y k 9 n v Z C A 0 Z y g n l l C m h b 2 V s B H V l K F N q G R D 8 J Z f X i W t y 6 p X q 1 4 9 1 C r 1 + z y O I p z A K Z y D B 9 d Q h z t o Q B M Y j O E Z X u H N S Z w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 H W P U w = = &lt; / l a t e x i t &gt; X t 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L l u d o u Y L T / B W l L d H l y 1 R e p C F c U E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R i h 4 L X v R W w X 5 A G 8 p m u 2 m X b j Z h d y K U 0 B / h x Y M i X v 0 9 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D v z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W a n f 6 G V 5 4 0 3 6 5 4 l b d O c g q 8 X J S g R y N f v m r N 4 h Z G n G F T F J j u p 6 b o J 9 R j Y J J P i 3 1 U s M T y s Z 0 y L u W K h p x 4 2 f z c 6 f k z C o D E s b a l k I y V 3 9 P Z D Q y Z h I F t j O i O D L L 3 k z 8 z + u m G N 7 4 m V B J i l y x x a I w l Q R j M v u d D I T m D O X E E s q 0 s L c S N q K a M r Q J l W w I 3 v L L q 6 R 1 W f V q 1 a u H W q V + n 8 d R h B M 4 h X P w 4 B r q c A c N a A K D M T z D K 7 w 5 i f P i v D s f i 9 a C k 8 8 c w x 8 4 n z / m A I 9 Q &lt; / l a t e x i t &gt;</formula><p>The correct solution, which our approach can handle E u le r &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N t K n j l W n J 4 6 3 7 W o t 2 N 4 8 W G 7 e + V Y = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 B I v g q S S i 6 L E g g t 4 q 2 A 9 o Q t l s p + 3 S z S b s z o o l 9 G 9 4 8 a C I V / + M N / + N 2 z Y H b X 0 w 8 H h v h p l 5 U S q 4 R s / 7 d g o r q 2 v r G 8 X N 0 t b 2 z u 5 e e f + g q R O j G D R Y I h L V j q g G w S U 0 k K O A d q q A x p G A V j S 6 n v q t R 1 C a J / I B x y m E M R 1 I 3 u e M o p W C A O E J s x s j Q E 2 6 5 Y p X 9 W Z w l 4 m f k w r J U e + W v 4 J e w k w M E p m g W n d 8 L 8 U w o w o 5 E z A p B U Z D S t m I D q B j q a Q x 6 D C b 3 T x x T 6 z S c / u J s i X R n a m / J z I a a z 2 O I 9 s Z U x z q R W 8 q / u d 1 D P a v w o z L 1 C B I N l / U N 8 L F x J 0 G 4 P a 4 A o Z i b A l l i t t b X T a k i j K 0 M Z V s C P 7 i y 8 u k e V b 1 z 6 s X 9 + e V 2 l 0 e R 5 E c k W N y S n x y S W r k l t R J g z C S k m f y S t 4 c 4 7 w 4 7 8 7 H v L X g 5 D O H 5 A + c z x + c q Z I X &lt; / l a t e x i t &gt; Iterations of the constraint solver E u le r &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N t K n j l W n J 4 6 3 7 W o t 2 N 4 8 W G 7 e + V Y = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 B I v g q S S i 6 L E g g t 4 q 2 A 9 o Q t l s p + 3 S z S b s z o o l 9 G 9 4 8 a C I V / + M N / + N 2 z Y H b X 0 w 8 H h v h p l 5 U S q 4 R s / 7 d g o r q 2 v r G 8 X N 0 t b 2 z u 5 e e f + g q R O j G D R Y I h L V j q g G w S U 0 k K O A d q q A x p G A V j S 6 n v q t R 1 C a J / I B x y m E M R 1 I 3 u e M o p W C A O E J s x s j Q E 2 6 5 Y p X 9 W Z w l 4 m f k w r J U e + W v 4 J e w k w M E p m g W n d 8 L 8 U w o w o 5 E z A p B U Z D S t m I D q B j q a Q x 6 D C b 3 T x x T 6 z S c / u J s i X R n a m / J z I a a z 2 O I 9 s Z U x z q R W 8 q / u d 1 D P a v w o z L 1 C B I N l / U N 8 L F x J 0 G 4 P a 4 A o Z i b A l l i t t b X T a k i j K 0 M Z V s C P 7 i y 8 u k e V b 1 z 6 s X 9 + e V 2 l 0 e R 5 E c k W N y S n x y S W r k l t R J g z C S k m f y S t 4 c 4 7 w 4 7 8 7 H v L X g 5 D O H 5 A + c z x + c q Z I X &lt; / l a t e x i t &gt; E u le r &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N t K n j l W n J 4 6 3 7 W o t 2 N 4 8 W G 7 e + V Y = " &gt; A A A B 8 3 i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 B I v g q S S i 6 L E g g t 4 q 2 A 9 o Q t l s p + 3 S z S b s z o o l 9 G 9 4 8 a C I V / + M N / + N 2 z Y H b X 0 w 8 H h v h p l 5 U S q 4 R s / 7 d g o r q 2 v r G 8 X N 0 t b 2 z u 5 e e f + g q R O j G D R Y I h L V j q g G w S U 0 k K O A d q q A x p G A V j S 6 n v q t R 1 C a J / I B x y m E M R 1 I 3 u e M o p W C A O E J s x s j Q E 2 6 5 Y p X 9 W Z w l 4 m f k w r J U e + W v 4 J e w k w M E p m g W n d 8 L 8 U w o w o 5 E z A p B U Z D S t m I D q B j q a Q x 6 D C b 3 T x x T 6 z S c / u J s i X R n a m / J z I a a z 2 O I 9 s Z U x z q R W 8 q / u d 1 D P a v w o z L 1 C B I N l / U N 8 L F x J 0 G 4 P a 4 A o Z i b A l l i t t b X T a k i j K 0 M Z V s C P 7 i y 8 u k e V b 1 z 6 s X 9 + e V 2 l 0 e R 5 E c k W N y S n x y S W r k l t R J g z C S k m f y S t 4 c 4 7 w 4 7 8 7 H v L X g 5 D O H 5 A + c z x + c q Z I X &lt; / l a t e x i t &gt;   <ref type="bibr" target="#b45">(Yang et al., 2020)</ref> (a) Collision with a thin wall. The Euler step in NP would propose that the ball moves through the wall. Because NP's constraint fC(Euler(Xt−1)) depends only on the state proposed by the Euler step, it cannot determine that there was a collision between time points t − 1 and t. The ball will remain on the other side of the wall and will continue moving forward in later time steps. (b) Collision with a thick wall. The Euler step in NP would propose that the ball moves into the wall, which should violate the learned constraint. The constraint-solver in NP would then move the ball to the nearest point where the constraint is not violated -the position where the ball touches the wall. As the constraint operates only on the position of the ball, but not on the previous positions or velocities, the ball would always be predicted as just touching the wall, rather than bouncing off the wall.</p><formula xml:id="formula_28">X t 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L l u d o u Y L T / B W l L d H l y 1 R e p C F c U E = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R i h 4 L X v R W w X 5 A G 8 p m u 2 m X b j Z h d y K U 0 B / h x Y M i X v 0 9 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D v z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W a n f 6 G V 5 4 0 3 6 5 4 l b d O c g q 8 X J S g R y N f v m r N 4 h Z G n G F T F J j u p 6 b o J 9 R j Y J J P i 3 1 U s M T y s Z 0 y L u W K h p x 4 2 f z c 6 f k z C o D E s b a l k I y V 3 9 P Z D Q y Z h I F t j O i O D L L 3 k z 8 z + u m G N 7 4 m V B J i l y x x a I w l Q R j M v u d D I T m D O X E E s q 0 s L c S N q K a M r Q J l W w I 3 v L L q 6 R 1 W f V q 1 a u H W q V + n 8 d R h B M 4 h X P w 4 B r q c A c N a A K D M T z D K 7 w 5 i f P i v D s f i 9 a C k 8 8 c w x 8 4 n z / m A I 9 Q &lt; / l a t e x i t &gt; X t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z S m Y B D T 3 W 6 k c M Y x F 6 G d j i u e 6 E X Q = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o s e C F 0 9 S 0 X 5 A G 8 p m u 2 m X b j Z h d y K U 0 J / g x Y M i X v 1 F 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Investigating the convergence properties of the C-GNS-GD model</head><p>In this section we investigate the convergence properties of the constraint function learned by C-GNS-GD on the examples from the ROPE dataset, with and without the additional loss on intermediate states (see details in Section A.3). We train the models with 5 solver iterations and run the solver with up to 15 iterations at test time. Figure B.2 demonstrates that in C-GNS-GD with both versions of the loss, the constraint value converges to the constant value, and the gradient norm converges to zero. The model with the loss on intermediate states with α = 0.25 converges in fewer iterations. for all the solvers we tested. We used solvers from SciPy <ref type="bibr" target="#b41">(Virtanen et al., 2020)</ref>, including Conjugate Gradient algorithm (CG, first order, <ref type="bibr" target="#b31">Nocedal &amp; Wright (2006)</ref>), the Broyden-Fletcher-Goldfarb-Shanno algorithm (BFGS, second order method, <ref type="bibr" target="#b31">Nocedal &amp; Wright (2006)</ref>) and the Newton Conjugate Gradient algorithm (Newton-CG, second order method, <ref type="bibr" target="#b31">Nocedal &amp; Wright (2006)</ref>). We used default SciPy settings for these solvers.</p><p>The model converges when using CG (blue), BFGS (green) and Newton-CG (purple) solvers, reaching a similar mean squared error as gradient descent (dark red), indicating that the learned constraint function is robust to the choice of optimization procedure. Note that Newton-CG solver also requires computing the Hessian of the constraint function, which we also obtained via auto-differentiation of the learned constraint. The convergence of Newton-CG suggests that the second order gradients of the learned constraint function are also well-behaved, even though they were never computed during training.</p><p>Next, we varied the learning rate (lr) of the gradient descent solver from the 0.001 value used during the training. As expected, halving the learning rate of gradient descent (lr=0.0005, orange) results in slower convergence, taking 15 iterations to reach a similar mean square error to GD(lr=0.001, dark red). On the other hand, with doubled learning rate (lr=0.002, black) the solver does not converge. We speculate that the model with lr=0.001 learned a constraint function that is sufficiently steep to converge to the minimum as quickly as possible with a learning rate of 0.001, and larger values of the learning rate may be detrimental. This is possible because the model is free to learn any scale for the constraint (and its gradients), which is equivalent to re-scaling the training learning rate. We informally tested this hypothesis by verifying that the model performance is not very sensitive to the training learning rate (although very large values make training more unstable).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>U w I 7 u r L 6 6 R 7 V X c b 9 c Z 9 o 9 a 8 L e I o w x m c w y W 4 c A 1 N u I M 2 d I B C A s / w C m 9 W a r 1 Y 7 9 b H s r V k F T O n 8 A f W 5 w + e t Z I S &lt; / l a t e x i t &gt; Y (i) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F g D t D k Q u j O E F 3 Z M 1 C 6 w B i 9 5 / Q 5 Y = " &gt; A A A B 7 n i c b V D L S g N B E O y N r x h f U Y 9 e B o M Q L 2 F X A n o M e v E Y w T w k W c P s p J M M m Z 1 d Z m a F s O</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>t B S e f O Y Y / c D 5 / A H G k k M Y = &lt; / l a t e x i t &gt; Ŷ = Y (N ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E r h t h i E 4 w c y O R 5 L h K X 4 L n v m T k N M = " &gt; A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L B a h X k o i B b 0 I R S + e p I L 9 o o 1 l s 9 2 2 S z e b s D s R a s g v 8 e J B E a / + F G / + G 7 d t D t r 6 Y O D x 3 g w z 8 / x I c A 2 O 8 2 2 t r K 6 t b 2 z m t v L b O 7 t 7 B X v / o K H D W F F W p 6 E I V c s n m g k u W R 0 4 C N a K F C O B L 1 j T H 1 9 P / e Y j U 5 q H 8 h 4 m E f M C M p R 8 w C k B I / X s Q n d E I G m n l + 2 H p H R 7 m v b s o l N 2 Z s D L x M 1 I E W W o 9 e y v b j + k c c A k U E G 0 7 r h O B F 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>/ 5 e I E D A h y O b d c C M H D l R + D w 4 + 9 o N / r f + 1 3 d v f m c S y z t + w d 6 7 K A b b N d 9 p k d s A E T 7 J J d s 9 / s x r v y f n m 3 3 p + 7 1 g V v 7 t l g 9 8 r 7 + w 9 4 e a o t &lt; / l a t e x i t &gt; Updater Solver iterations X 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p f o x s 8 r s C / m o P 7 9 H B U V B d U / M h t I = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k U I 9 F L x 4 r 2 g 9 o Q 9 l s J + 3 S z S b s b o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k r e N U M W y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>h / p 7 I a K T 1 N A p s Z 0 T N W K 9 6 c / E / r 5 e a 8 N r P u E x S g 5 I t F 4 W p I C Y m 8 7 / J k C t k R k w t o U x x e y t h Y 6 o o M z a d k g 3 B W 3 1 5 n b S v q l 6 t W r u v V R o 3 e R x F O I N z u A Q P 6 t C A O 2 h C C x i M 4 B l e 4 c 0 R z o v z 7 n w s W w t O P n M K f + B 8 / g D d J 4 2 H &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>7 a r l 2 k 8 d R g F M 4 g w s I 4 A p q c A d 1 a A A D B c / w C m + e 8 V 6 8 d + 9 j 0 b r m 5 T M n 8 A f e 5 w 8 R 3 5 C X &lt; / l a t e x i t &gt; Xt+1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a j L q f C Z o v 3 o 6 F T n f b 5 4 h 4 x E y G I 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B Z B E E o i B T 0 W v X i s Y G u h D W W z 3 b Z L N 5 u 4 O y m U k N / h x Y M i X v 0 x 3 v w 3 b t s c t P X B w O O 9 G W b m B b E U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o k S z X i T R T L S 7 Y A a L o X i T R Q o e T v W n I a B 5 I / B + H b m P 0 6 4 N i J S D z i N u R / S o R I D w S h a y e + O K K</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>r 1 a t 3 d c q 9 Z s 8 j i K c w C m c g w d X U I c 7 a E A T G D z B M 7 z C m z N x X p x 3 5 2 P R W n D y m W P 4 A + f z B 7 o Y k h M = &lt; / l a t e x i t &gt; Predictor X t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 4 / c S h L n p c 3 G 1 u 2 g o 1 / x M g S g s 0 s = " &gt; A A A B 8 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o M e i F 4 8 V 7 A e 2 o W y 2 m 3 b p Z h N 3 J 0 I J / R d e P C j i 1 X / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>5 H E U 4 g V M 4 B w 8 u o Q 6 3 0 I A m M F D w D K / w 5 h j n x X l 3 P h a t B S e f O Y Y / c D 5 / A H G k k M Y = &lt; / l a t e x i t &gt; Y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p m d X a Q t x / R k b j E E j 0 J j G 9 4 u n d S A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o M e i F 4 8 t 2 F Z p Q 9 l s J + 3 a z S b s b o Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o r e N U M W y x W M T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>r A Y A z P 8 A p v T u y 8 O O / O x 6 I 1 5 2 Q z x / A H z u c P Z + q O 9 w = = &lt; / l a t e x i t &gt; s &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U B G T a M 5 K U B S j P j n s 6 O D 1 k P</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>2 m 4 I N w V t + e Z U 0 L 8 p e p X x Z r 5 S q N 0 / z O P J w A q d w D h 5 c Q R X u o A Y N Y I D w D K / w 5 j w 4 L 8 6 7 8 z F v z T m L C I / h D 5 z P H w d M j X 8 = &lt; / l a t e x i t &gt; s &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U B G T a M 5 K U B S j P j n s 6 O D 1 k PD I f f A = " &gt; A A A B 6 H i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 4 k o m X Q x j I B 8 w H J E f Y 2 c 8 m a v b 1 j d 0 8 I R 8 D e x k I R W 3 + S n f / G z U e h i Q 8 G H u / N M D M v S A T X x n W / n d z a + s b m V n 6 7 s L O 7 t 3 9 Q P D x q 6 j h V D B s s F r F q B 1 S j 4 B I b h h u B 7 U Q h j Q K B r W B 0 O / V b j 6 g 0 j + W 9 G S f o R 3 Q g e c g Z N V a q 6 1 6 x 5 J b d G c g q 8 R a k B A v U e s W v b j 9 m a Y T S M E G 1 7 n h u Y v y M K s O Z w E m h m 2 p M K B v R A X Y s l T R C 7 W e z Q y f k z C p 9 E s b K l j R k p v 6 e y G i k 9 T g K b G d E z V A ve 1 P x P 6 + T m v D a z 7 h M U o O S z R e F q S A m J t O v S Z 8 r Z E a M L a F M c X s r Y U O q K D M 2 m 4 I N w V t + e Z U 0 L 8 p e p X x Z r 5 S q N 0 / z O P J w A q d w D h 5 c Q R X u o A Y N Y I D w D K / w 5 j w 4 L 8 6 7 8 z F v z T m L C I / h D 5 z P H w d M j X 8 = &lt; / l a t e x i t &gt; C-GNS Y (i+1) = Y (i) + Y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / b g 2 f s B d T z + / l m b x Q 9 J d R o 3 4 Q G o = " &gt; A A A C C 3 i c b Z D L S g M x F I Y z 9 V b r b d S l m 7 R F q B T K j F R 0 I x T d u K x g b 3 T G k s l k 2 t D M h S Q j l K F 7 N 7 6 K G x e K u P U F 3 P k 2 Z q Z d a O s P g S / / O Y f k / E 7 E q J C G 8 a 3 l V l b X 1 j f y m 4 W t 7 Z 3 d P X 3 / o C 3 C m G P S w i E L e d d B g j A a k J a k k p F u x A n y H U Y 6 z v g 6 r X c e C B c 0 D O 7 k J C K 2 j 4 Y B 9 S h G U l k D v d S 7 T y q 0 a p 5 M r e K l V c x u K V e t o u U S J h H s D f S y U T M y w W U w 5 1 A G c z U H + p f l h j j 2 S S A x Q 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>r L 0 P 7 t G b W a 2 e 3 9 X L j a h 5 H H h y B E q g A E 5 y D B r g B T d A C G D y C Z / A K 3 r Q n 7 U V 7 1 z 5 m r T l t P n M I / k j 7 / A H j z J h w &lt; / l a t e x i t &gt; f C &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k Z k Y F 8 7 4 9 t + 4 e N J p c L 8 A / 9 X 3 k S M = " &gt; A A A B 8 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 B I v g q S R S 0 G O x F 4 8 V 7 A c 0 o W y 2 m 3 b p Z h N 2 J 2 I J + R t e P C j i 1 T / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u 0 X G + r d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p 6 j h V l H V o L G L V D 4 h m g k v W Q Y 6 C 9 R P F S B Q I 1 g u m r b n f e 2 R K 8 1 g + 4 C x h f k T G k o e c E j S S F w 4 z D 9 k T Z q 0 8 H 1 Z r T t 1 Z w F 4 n b k F q U K A 9 r H 5 5 o 5 i m E Z N I B d F 6 4 D o J + h l R y K l g e c V L N U s I n Z I x G x g q S c S 0 n y 1 u z u 0 L o 4 z s M F a m J N o L 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>c b 9 c Z 9 o 9 a 8 L e I o w x m c w y W 4 c A 1 N u I M 2 d I B C A s / w C m 9 W a r 1 Y 7 9 b H s r V k F T O n 8 A f W 5 w + e t Z I S &lt; / l a t e x i t &gt; Y (0) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 U Y 9 T z o 0 x S g u D E</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>r A Y A z P 8 A p v T u y 8 O O / O x 6 I 1 5 2 Q z x / A H z u c P Z + q O 9 w = = &lt; / l a t e x i t &gt; Ŷ = Y (N ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E r h t h i E 4 w c y O R 5 L h K X 4 L n v m T k N M = " &gt; A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L B a h X k o i B b 0 I R S + e p I L 9 o o 1 l s 9 2 2 S z e b s D s R a s g v 8 e J B E a / + F G / + G 7 d t D t r 6 Y O D x 3 g w z 8 / x I c A 2 O 8 2 2 t r K 6 t b 2 z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Figure 1. (a) Learned simulator schematics. A simulator s maps X ≤t to a future state Xt+1. The PREDICTOR takes X ≤t and returns Ŷ which represents information about the system's temporal evolution. An UPDATER uses Ŷ to update Xt to Xt+1. (b) Constraint-based Graph Network simulator (C-GNS). The PREDICTOR iteratively solves for a Ŷ to satisfy a constraint function fC using ∇Y fC. (c) Constraint optimization on two colliding balls. The heatmap color shows the value of learned constraint fC as we vary the update Y for the blue ball. The colored points on the heatmap show the iterations of the solver as it minimizes the constraint fC (from Y (0) to Y (N ) ), indicating that the blue ball should bounce downwards to resolve the collision. The learned fC has a "funnel" shape around the correct next state of the ball.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Renderings of the physical environments. Videos of the model rollouts are available at: sites.google.com/view/constraint-based-simulator.</figDesc><graphic url="image-8.png" coords="3,412.72,43.49,103.99,104.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>4 and Figure B.7).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Comparison to the existing baselines. Top row: 1-step test MSE on node positions. Bottom row: full-rollout test MSE (160-step). The bar height represents the median MSEs over random seeds. The black crosses show the MSE metric for each random seed. We found Neural Projections could not effectively scale to BOXBATH (see Section 4.4). All the plots except BOX-BATH are on log scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Visualization of the learned constraint. The heatmaps show the values of the learned constraint fC as a function of the update Y for one of the nodes, keeping other nodes fixed. (a) An example from Rope simulation. The learned constraint function has a "funnel" shape, where the minimum coincides with the only valid next state of the simulation (ground-truth, shown as the white cross). The colored points represent the iterations of the gradient descent solver as it minimizes the learned constraint: from the initial Y (0) (yellow) to final Y (5) (green). (b) An example from Bouncing Balls. The red ball is far from other balls, and its constraint fC represents a smooth funnel centered around the ground-truth (white cross). For orange and blue balls, the constraint fC has high values in the areas occupied by another ball, indicating that the current ball cannot overlap with it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>) making the constraint function depend on the update only: f C (Y ) and (3) initializing Y(0) to the output of the Euler step.Crucially, the Neural Projections constraint function only measures how much the current set of proposed positions of the particles violates the learned constraints without context about past states X ≤t . Thus, the model cannot correctly resolve scenarios such as the elastic collisions, as the constraint function does not have access to the dynamics (i.e. how the proposed state relates to the previous state, illustrated in Supplementary Figure A.1). This weakness renders Neural Projections insufficient for general-purpose physical simulations. Our model, on the contrary, does not have this issue, because the constraint function is always conditioned on the past context f C (X ≤t , Y ), which allows to model time dynamics as a part of the learned constraint. To study the effect of this difference, we provide an ablation to our model C-GNS-GD-f C (Y ) that uses only the positional information of the future state and does not have access to the context X ≤t (details in the Supplementary Section A.3) Next, Neural Projections defines the constraint solution as f C (Y ) = 0, and uses the zero-finding "Fast Projection" algorithm(FP, Goldenthal et al. (2007)) to find a solution. In contrast, our model defines the solution as a minimization problem, i.e., Ŷ = argmin Y f C (X ≤t , Y ), solved by a gradient descent. To explore these choices, we also tested an FP-based version of our model: C-GNS-FP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>to further incentivize the convergence to the groundtruth point. See Supplementary Figure B.4 for the similar Rollout examples with different number of iterations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Generalization to more solver iterations and larger ROPE systems at test time. (a) Test rollout MSE for ropes with the same lengths as those during training (5-10 nodes) (b) Test rollout MSE for larger ropes (20 nodes). The x-axis indicate the number of solver iterations at test time. Vertical dashed line marks 5 iterations used at training. The y-axis represents MSE values. The horizontal black and grey lines show the performance of the Forward GNN models, which do not have an equivalent of iterations. (c) Example of the generalization rollouts from C-GNS-GD with a different number of solver iterations used at test time at every time step. The rope examples shown at time points T = {20, 60, 100} of the rollout. These rollouts are from a single C-GNS-GD model trained with 5 iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Adding hand-designed constraints. (a) The ground truth sequence of rope simulation 14 time steps. (b) The rollout from C-GNS-GD trained on the ROPE dataset, without added constraints. (c) The C-GNS-GD's rollout, with wall, floor, and disk-shaped obstacles, imposed at test time via hand-designed constraint functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Ablations towards Neural Projections model. Y axis shows full-rollout test MSE on the node positions. The bars represent the median MSE over random seeds. The black crosses show the MSE metric for each random seed.All plots except BOXBATH are on log scale. We crop the Y axis if it exceeds the median MSE of C-GNS-GD by 5 fold. The results are not shown for MLP-based models on BOXBATH, as these models could not effectively scale to a large system (see Section 4.4). See Supplement for 1-step MSE errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>R n E a B 5 O 1 g f D P z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W e u j 0 s V + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h t d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V L 1 a 9 f K + V q n f 5 X E U 4 Q R O 4 Rw 8 u I I 6 3 E I D m s B g C M / w C m + O d F 6 c d + d j 0 V p w 8 p l j + A P n 8 w d G s I 3 X &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " Z S m Y B D T 3 W 6k c M Y x F 6 G d j i u e 6 E X Q = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o s e C F 0 9 S 0 X 5 A G 8 p m u 2 m X b j Z h d y K U 0 J / g x Y M i X v 1 F 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D P z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W e u j 0 s V + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h t d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V L 1 a 9 f K + V q n f 5 X E U 4 Q R O 4 Rw 8 u I I 6 3 E I D m s B g C M / w C m + O d F 6 c d + d j 0 V p w 8 p l j + A P n 8 w d G s I 3 X &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure A. 1 .</head><label>1</label><figDesc>Figure A.1. cases of Neural Projections<ref type="bibr" target="#b45">(Yang et al., 2020)</ref> (a) Collision with a thin wall. The Euler step in NP would propose that the ball moves through the wall. Because NP's constraint fC(Euler(Xt−1)) depends only on the state proposed by the Euler step, it cannot determine that there was a collision between time points t − 1 and t. The ball will remain on the other side of the wall and will continue moving forward in later time steps. (b) Collision with a thick wall. The Euler step in NP would propose that the ball moves into the wall, which should violate the learned constraint. The constraint-solver in NP would then move the ball to the nearest point where the constraint is not violated -the position where the ball touches the wall. As the constraint operates only on the position of the ball, but not on the previous positions or velocities, the ball would always be predicted as just touching the wall, rather than bouncing off the wall.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure B. 2 .</head><label>2</label><figDesc>Figure B.2. The constraint value and gradient norm across the number of solver iterations on the example from the ROPE dataset. The results are shown for two models: C-GNS-GD with the MSE loss on the last iteration only(pale red) and C-GNS-GD (α=0.25) model with the additional decaying loss on intermediate states (dark red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Top row: 1-step test MSE on node positions. Bottom row: full-rollout test MSE (160-step). The bar height represents the median MSEs over random seeds. The black crosses show the MSE metric for each random seed. We found Neural Projections could not effectively scale to BOXBATH (see Section 4.4). All the plots except BOX-BATH are on log scale.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Despite that physics is Markovian, we use X ≤t as input because our framework can also apply to non-Markovian dynamic processes. Providing previous states can also be helpful when there are hidden properties of the system which are only identifiable over a sequence of observed states, for example when a state does not contain instantaneous velocities, such as in our environments.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">  2  We loosely use the hat notation (e.g. X) for the quantities that are predicted by the model.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">Implicit differentiation at the solution point, mentioned in Section 2, is applicable as well but we did not explore this direction.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">Videos of the model rollouts are available at sites.google.com/view/constraint-based-simulator</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">To make Forward GNN comparable to C-GNS-GD, we use the same number of MP layers in both models (2 MP layers for ROPE, 1 MP for other datasets)</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>A. Implementation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. The datasets</head><p>We generate the ROPE, BOUNCING BALLS and BOUNCING RIGIDS datasets using the MuJoCo physics simulator, with a timestep of 0.001, and recording every 30th time step for our datasets. Our MuJoCo datasets contain 8000/100/100 train/validation/test trajectories of 160 time points each. We show examples of the rollouts for each environment in Supplementary Figure <ref type="figure">B</ref>.1 and Videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROPE</head><p>The rope is a mass-spring system, where the masses are represented by nodes, and the springs are represented by edges. We randomly sample the number of masses from the discrete interval <ref type="bibr">[5,</ref><ref type="bibr">10]</ref>, and the rest length of the springs from the interval [0.6, 1.1]. The springs have effectively infinite stiffness, and thus maintain their rest lengths during the simulation. The rope is fixed in space at one end, and the rest moves under the force of gravity in 2D space.</p><p>BOUNCING BALLS The bouncing balls are a 2D particle system confined to a square box, where interactions between the balls, and between the balls and walls, are simulated as rigid collisions. The number of balls is randomly sampled from the discrete interval <ref type="bibr">[5,</ref><ref type="bibr">10]</ref>, and the radii of each ball from the interval <ref type="bibr">[0.11, 0.3]</ref>. The size of the box is fixed to 5x5 in MuJoCo coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BOUNCING RIGIDS</head><p>The bouncing rigids are similar to BOUNCING BALLS, except all the balls are connected to each other with rigid bars. We randomly sample the number of balls from the discrete interval <ref type="bibr">[3,</ref><ref type="bibr">6]</ref>.</p><p>BOXBATH This dataset is from <ref type="bibr" target="#b21">(Li et al., 2019)</ref>, and simulates 3D fluid particle dynamics within a box, with a rigid cube comprised of particles floating on the surface of the fluid, using the NVIDIA FleX physics engine <ref type="bibr" target="#b26">(Macklin et al., 2014b)</ref>. Each simulation contains 960 fluid particles and 64 particles representing the cube. The dataset contains 2700/10/100 training/validation/test trajectories with 150 time steps each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Constructing the input graph</head><p>We construct the input graph such that the representation is translation invariant, motivated by the idea that the laws of physics do not change based on position in space. To do so, we never provide absolute positions of the nodes in the input to the GNN. Instead, we use velocities (position differences across time) as node features and pairwise position differences between the nodes as edge features, as described below and in the main text. In preliminary work, we found that providing absolute positions to the models causes poorer generalization, especially in larger environments, such as a longer rope.</p><p>In BOUNCING RIGIDS and BOUNCING BALLS we use a fully-connected graph. In ROPE we add edges between nodes that are adjacent within the rope. In BOXBATH we add edges between particles that are within a radius of 0.08 from within each other, and then recompute these edges at every step of a rollout according to the updated positions (as in Sanchez-Gonzalez et al. ( <ref type="formula">2020</ref>)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1. NODE FEATURES</head><p>To construct each input node feature, we use the concatenation of the three most recent velocities (position differences) of the node, concatenated with the static parameters (context</p><p>for experiments with different number of time points. We use five most recent velocities for BOXBATH to match the paradigm in <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020)</ref>. For the constraint-based models, e.g. C-GNS-GD, we also concatenate the optimized update Y to the node features, as Y represents velocity or acceleration for each node.</p><p>We provide an additional one-hot node feature indicating the node type (e.g. rigid, fluid, fixed). For BOUNCING BALLS and BOUNCING RIGIDS, we provide the radius of the object as an additional node feature. Note, because the edges' relative positional displacement and distance features are computed between centers of the nodes, the model must factor in the object size feature to determine whether a collision is happening.</p><p>Handling walls To handle the walls, we include the Euclidean distance between the center of the node to each of wall as additional node features, treating the wall as a plain, similarly to <ref type="bibr" target="#b36">(Sanchez-Gonzalez et al., 2020)</ref>.  Constraint-based graph network simulator Table <ref type="table">B</ref>.1. Median performance of the models on different datasets. The standard deviation from the median is shown over 5 random seeds. We do not show the results for the models where the median value, or standard deviation is more than 1000 times larger than the best model in each column. Note that the tables use different scales to demonstrate the errors on 1-step error, 10-step rollouts and full rollouts. Results are not shown for MLP models on BOXBATH. We omit the results for the models where the median error is more than 4 orders of magnitude larger than the median error of the C-GNS-GD model.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Supplementary plots and tables</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optnet: Differentiable optimization as a layer in neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Layer normalization</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01377</idno>
		<title level="m">Deep equilibrium models</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08656</idno>
		<title level="m">Multiscale deep equilibrium models</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast contact force computation for nonpenetrating rigid bodies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Baraff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st annual conference on Computer graphics and interactive techniques</title>
				<meeting>the 21st annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Continuous latent search for combinatorial optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning Meets Combinatorial Algorithms at NeurIPS2020</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Interaction networks for learning about objects, relations and physics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno>ArXiv, abs/1612.00222</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Relational inductive biases, deep learning, and graph networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Projective dynamics: Fusing constraint projections for fast simulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pauly</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07366</idno>
		<title level="m">Neural ordinary differential equations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Symplectic recurrent neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13334</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greydanus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Spergel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04630</idno>
		<title level="m">Lagrangian neural networks</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combining differentiable PDE solvers and graph neural networks for fluid flow prediction</title>
		<author>
			<persName><forename type="first">De</forename><surname>Avila Belbute-Peres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Economon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
				<editor>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07">Jul 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Dc3: A learning method for optimization with hard constraints</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Donti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.12225</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep implicit layers -neural odes, deep equilibrium models, and beyond</title>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="http://implicit-layers-tutorial.org/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Simplifying hamiltonian and lagrangian neural networks via explicit constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.13581</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient simulation of inextensible cloth</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goldenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bercovier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grinspun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2007 papers</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hamiltonian neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Greydanus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dzamba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="15379" to="15389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Physics-informed machine learning</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Kevrekidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Physics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="422" to="440" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Machine learning-accelerated computational fluid dynamics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kochkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alieva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Brenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning particle dynamics for manipulating rigid bodies, deformable objects, and fluids</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tedrake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reviving and improving recurrent back-propagation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pitkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning constraint-based planning models from demonstrations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Loula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/RSJ International Conference on Intellitgent Robots and Systems (IROS)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5410" to="5416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Lutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04490</idno>
		<title level="m">Deep lagrangian networks: Using physics as model prior for deep learning</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unified particle physics for real-time applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Macklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2014">2014a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unified particle physics for real-time applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Macklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1145/2601097.2601152</idno>
		<ptr target="https://doi.org/10.1145/2601097.2601152" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<idno type="ISSN">0730-0301</idno>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014-07">jul 2014b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Impulse-based simulation of rigid bodies</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mirtich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
		<idno type="DOI">10.1145/199404.199436</idno>
		<ptr target="https://doi.org/10.1145/199404.199436" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1995 Symposium on Interactive 3D Graphics, I3D &apos;95</title>
				<meeting>the 1995 Symposium on Interactive 3D Graphics, I3D &apos;95<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">181</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Smoothed particle hydrodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Monaghan</surname></persName>
		</author>
		<idno type="DOI">10.1088/0034-4885/68/8/R01</idno>
	</analytic>
	<monogr>
		<title level="j">Reports on Progress in Physics</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">1703</biblScope>
			<date type="published" when="2005-07">07 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Mrowca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Yamins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08047</idno>
		<title level="m">Flexible neural representation for physics prediction</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Position based dynamics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Heidelberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hennix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="118" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Numerical Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>2e edition</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning mesh-based simulation with graph networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=roNqYL0_XP" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Latent odes for irregularly-sampled time series</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Neural Information Processing Systems</title>
				<meeting>the 33rd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5320" to="5330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph networks as learnable physics engines for inference and control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Merel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4470" to="4479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Hamiltonian graph networks with ode integrators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12790</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to simulate complex physics with graph networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v119/sanchez-gonzalez20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
				<editor>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07">Jul 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Learned coarse models for efficient turbulence simulation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fielding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kochkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.15275</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Continuumbased strain limiting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Thomaszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pabst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Strasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="569" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep learning methods for reynolds-averaged navier-stokes simulations of airfoil flows</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thuerey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weißenow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Prantl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA Journal</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Mujoco: A physics engine for model-based control</title>
		<author>
			<persName><forename type="first">E</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="5026" to="5033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Scipy 1.0: fundamental algorithms for scientific computing in python</title>
		<author>
			<persName><forename type="first">P</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haberland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weckesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver</title>
		<author>
			<persName><forename type="first">P.-W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Donti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6545" to="6554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Interactive dynamics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Welch</surname></persName>
		</author>
		<idno type="DOI">10.1145/91394.91400</idno>
		<ptr target="https://doi.org/10.1145/91394.91400" />
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<idno type="ISSN">0097-8930</idno>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1990-02">feb 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Physics-informed machine learning approach for augmenting turbulence models: A comprehensive framework</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Paterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Fluids</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">74602</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning physical constraints with neural projections</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/37bc5e7fb6931a50b3464ec66179085f-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5178" to="5189" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
