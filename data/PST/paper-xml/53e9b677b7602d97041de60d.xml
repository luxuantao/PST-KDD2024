<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">ETIS) Lab</orgName>
								<orgName type="institution">University of Cergy-Pontoise</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Graduate School in Electronic and Electrical Engineering (ENSEA)</orgName>
								<address>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Graduate School in Electronic and Electrical Engineering (ENSEA)</orgName>
								<orgName type="laboratory">Neurocybernetic Team, Image and Signal Processing (ETIS) Lab</orgName>
								<orgName type="institution">University of Cergy-Pontoise</orgName>
								<address>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">French Institute of Health and Medical Research (INSERM)</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Graduate School in Electronic and Electrical Engineering (ENSEA)</orgName>
								<orgName type="department" key="dep2">Equipe Dévelopment et Psychopathologie</orgName>
								<orgName type="laboratory">Neurocybernetic Team, Image and Signal Processing (ETIS) Lab</orgName>
								<orgName type="institution">University of Cergy-Pontoise</orgName>
								<address>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">UMR CNRS 7593</orgName>
								<orgName type="institution">Hopital de la Salpétriêre</orgName>
								<address>
									<addrLine>Pavillon Clérambault</addrLine>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5AEB53A55DE8652AC1DCE6A8B62A93EB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning and Communication via Imitation: An</head><p>Autonomous Robot Perspective Pierre Andry, Philippe Gaussier, Member, IEEE, Sorin Moga, Jean Paul Banquet, and Jacqueline Nadel</p><p>Abstract-This paper proposes a neural network architecture designed to exhibit learning and communication capabilities via imitation. Our architecture allows a "protoimitation" behavior using the "perception ambiguity" inherent in real environments. In the perspective of turntaking and gestural communication between two agents, new experiments on movement synchronization in an interaction game are presented. Synchronization is obtained as a global attractor depending on the coupling between agents' dynamic. We also discuss the nonsupervised context of the imitation process and we present new experiments in which the same architecture is able to learn perception-action associations without any explicit reinforcement. The learning is based on the ability to detect novelty or irregularities in the communication rhythm.</p><p>Index Terms-Autonomous learning, imitation, implicit reinforcement, interaction, neural network, synchronization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I MITATION is a powerful learning paradigm for autonomous systems. As a capability of learning by observation, imitation can improve and speed up the learning of sensory-motor associations. In order to design a neural architecture able to learn via imitation, we are mainly interested by the first levels of imitation <ref type="bibr" target="#b29">[30]</ref>. These levels concern low-level imitations, i.e., reproduction of meaningless and simple movements. This "protoimitation" level plays a key role in understanding the principles of the perception-action mechanism necessary to perform higher order behaviors. But imitation also has a communicative function <ref type="bibr" target="#b0">[1]</ref>. As observed among nonverbal children <ref type="bibr" target="#b19">[20]</ref>, imitation is a powerful tool for gestural interactions consisting of initiations of motor sequences by one child and synchronous re-enactments by the other child (Fig. <ref type="figure" target="#fig_0">1</ref>). The imitative capabilities involved in earlier stages of learning and communication lead us to find out how our previous protoimitation model can Reproduction from <ref type="bibr" target="#b19">[20]</ref>.</p><p>be used to understand interactions in a human-machine or a machine-machine loop. In Section II, we present a brief account of recent knowledge of imitation in the field of developmental psychology. We focus on what is necessary for an architecture to learn and communicate via imitation. Therefore, we review only the early stages of imitation as observed among neonates and infants, rather than the more sophisticated capabilities involved in planning imitation at a program level. Section III summarizes the key features of the neural network architecture developed in previous works <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b11">[12]</ref>, where imitation was used as a tool to simplify the learning of motor sequences. Based on this architecture, we present in Section IV, a new architecture allowing synchronization capabilities in the perspective of gestural communication and turntaking between two agents. We show that synchronization can be obtained from a simple modulation of the perception-action loop: perception can be seen as an energy exchange between the interacting systems. Finally, we demonstrate in Section V that the rhythm of the interaction carries out implicit information that can then be used to build a powerful reward signal. This signal is then used to learn an arbitrary set of sensory-motor associations in reinforcement learning <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DEVELOPMENTAL PSYCHOLOGY BACKGROUND</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Traditional View: Deferred Imitation as a Building Block for Representational Capabilities</head><p>Up until the 1970s, two claims have framed developmental studies on imitation. First, generations of developmental psychologists have followed Guillaume's definition of imitation <ref type="bibr" target="#b13">[14]</ref>, which implies that imitation should require at least an elementary level of representation. As a consequence, most developmental psychologists in the 1950s have denied any ontogenetic value to immediate imitation and have emphasized instead the developmental role of deferred imitation. Defined as the delayed reenactment of an absent motor model, deferred imitation was considered by Piaget <ref type="bibr" target="#b23">[24]</ref> and most of contemporary child psychologists, as a determinant building block for emerging representational capabilities, thus serving mentalization. As a second claim, true imitation had to be novel and not already in the repertoire. This led to see imitation as a special case of observational learning occurring without incentives, without trial and error, and requiring no reinforcement <ref type="bibr" target="#b2">[3]</ref>. Within this framework, the developmental benefits of imitation are 1) to provide an alternative to expensive trial-and-error learning; 2) to facilitate the rapid acquisition of adaptive behavior in the young; 3) to allow a direct incorporation of the learned repertoire of the society <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Current View: Immediate Imitation as Serving Two Functions: Learning and Communication</head><p>Developmental studies carried out since the 1970s have completely altered the theoretical basis for understanding the contribution of imitation to development. The emphasis has been on the innate origin of imitation in humans <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, and on the contribution of perceptual systems as channels of information, which enable the infant to imitate through perception-action linkage <ref type="bibr" target="#b17">[18]</ref>. Explaining neonatal imitation requires a theory of perception-action coupling accounting for how coordinated behaviors emerge between individuals and how more advanced forms of imitation develop. Immediate imitation has thus been rehabilitated. It is clear now that it is not the unintelligent process Piaget described but rather a way to learn new "know-how" as well as to communicate. Through perceptual information exchange, immediate imitation does not only serve the social transmission of culturally accumulated characteristics but also individual identification <ref type="bibr" target="#b18">[19]</ref>, communication, and role-taking <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Indeed, as shown by Nadel <ref type="bibr" target="#b19">[20]</ref>, preverbal children use imitation in their social exchanges as a way to take turns, switch roles (imitator versus imitated), and to share topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. STARTING POINT FOR AN "IMITATING BEHAVIOR" IMPLEMENTATION</head><p>Inspired by developmental data, our model of an imitative autonomous system is designed to learn perception-action coupling, and to take part in a communication process via imitation. In a long-term perspective, the system should respond to the teacher's expectancies as in the "do as I do" test proposed by Hayes and Hayes <ref type="bibr" target="#b29">[30]</ref>, communicating according to a "start and end" signal given by the teacher. Moreover, the system should also be capable of spontaneous imitation generated by an internal motivation or simply triggered by novelty detection.</p><p>Spontaneous imitation may be an essential part of the social interactions among a population of robots <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Imitation Triggered by a Perception Ambiguity</head><p>Intentions, emotions, identity, consciousness of self, or supramodal levels are often mentioned as notions involved in imitation, but these words are not fully understood, and very hard to consider for designing autonomous systems. So the first question that arises is: Is it possible to design a simple architecture (related to the complexity of the notions involved), which could exhibit basic imitation capabilities, e.g., a type of protoimitation? This architecture could be a starting point to explore more complex behaviors. We assume that imitation can be triggered by a perception ambiguity. "Perception ambiguity" must be understood here as a difficulty to discriminate objects (is this my arm or another's arm?), or to decide between different interpretations (is this a useful object or an obstacle?). Perception ambiguity was first introduced by Gestaltists, assuming that local features in a perceived scene were always ambiguous (only the global contextual information and the dynamic of the perception-action loop allow to suppress ambiguity). In the present issue, we consider that the available information is egocentric (relative to the system's position). For instance, an imitation behavior of an artificial arm controlled by vision can be obtained when the robot learns the visuo-motor coordination between its camera and its mechanical hand. During this learning phase, the robot creates a correspondence between a given position of its hand in the visual field and the angular position of the different joints. Assuming that the perception module of this system is quite simple (using for example movement detection), let us now suppose that this robot looks somewhere else and perceives (Fig. <ref type="figure">2</ref>) another artificial arm or simply a hand moving in its visual field (narrow field of view). Because our robot will try to reduce the differences between the representations it supposes to have of its arm, it will perform a similar movement as the hand. Moreover, if the sequence of movements is stored and associated with the satisfaction of a particular motivation, it can be triggered later. An external observer will consider that the robot has learned, via imitation, the behavior of the hand. To sum up, it is proposed that an imitation behavior can be induced by the ambiguity on the identification of the perceived extremity and the minimization of the error between the visual and the motor positions (homeostasis principle <ref type="bibr" target="#b1">[2]</ref>). This proposed control principle is close to the "low-level resonance" mechanism, mentioned by Rizzolatti <ref type="bibr" target="#b25">[26]</ref>. Experiments show that the same motor neurons (situated in the "rostral part of the inferior parietal lobule" of monkeys <ref type="bibr" target="#b25">[26]</ref>) are activated when a monkey observes or produces meaningless arm movements, regardless of the execution context. According to Rizzolatti, such a "low-level resonance" account for low-level imitating faculties. This direct link between perception and action could allow imitation capabilities without high-level notions of "self" and "others." Nevertheless, our approach is not aimed to perform exact physical motion reproduction between identical arms. We assume that some important information (such as the motion and the dynamic of the model) are sufficient to induce the premises of imitation. The perception ambiguity Fig. <ref type="figure">2</ref>. Protoimitation principle applied to a robotic arm. In a learning phase, a controller robot learns the correspondence between its arm proprioception (the joint position) and its position in its visual field. To do this, the controller detects movement. Once the associations are learned, if the robot focuses its attention on a human teacher's moving hand, it will reproduce the teacher's simple movement just because it will perceive a difference between its proprioceptive and visual information. It will try to reduce the proprioceptive error of its arm position according to what it believes to be the visual information linked to its arm, i.e., the detection of movement in the visual field). An external observer will then deduce that the learner robot is imitating the teacher.</p><p>simply suppresses the need of recognizing others to initiate some simple group dynamics. It allows gestural imitation (or meaningless imitation) between systems having very different morphologies (robots, humans, animals…). The fidelity of the reproduction is of course dependent on the experimental setup, where distances, perspectives, and positions can influence the perception and, therefore, the quality of the reproduction (amplitude of the movement's trajectories). Short distances and same body orientations of the imitator and the imitated, will favor the quality of imitation, such as in sports and dance tutorials. Being able to imitate a movement, whatever the posture is, would imply, for instance, using a mapping mechanism allowing to store an invariant representation of the action to be performed (the trajectory should be stored independently of the effector and posture). The solution to a real and more complex imitation must take into account the "effect level" of imitation (where actions of the imitator achieved the same effect as the imitated <ref type="bibr" target="#b21">[22]</ref>). These imitations require the understanding of the goal of the perceived actions. We assume that our protoimitation mechanism associated with an invariant representation of actions and the capability of learning objects affordances could be a way, in future works, to address correctly complex imitation problems (see, for instance, <ref type="bibr" target="#b9">[10]</ref>). In the present works we only investigate the basic features necessary for simple unsupervised interactions between two autonomous agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Learning and Reproducing Temporal Motor Sequences</head><p>We summarize here previous work <ref type="bibr" target="#b11">[12]</ref> using perception ambiguity to teach a robot different "dances." This work is very important for the present paper since it is a prerequisite for the new architectures developed in Sections IV and V for communication capabilities (synchronization of agents gestures in an imitation game) and rhythm prediction. We used a mobile (six-wheeled) robot, whose control architecture (Fig. <ref type="figure">3</ref>) tries to reduce the difference of speed between the information of the visual flow and the information of the wheel speed (homeostasis principle <ref type="bibr" target="#b1">[2]</ref>). If the robot is still, then any movement in the visual field will make the control system consider that Fig. <ref type="figure">3</ref>. Model allowing protoimitation. The system is designed as a PerAc block. The "transition learning and prediction" mechanism is a perception level modulating the "sensory-motor pathway." The PO group of neurons learns the transitions between the past event (activity of the TB neurons) and the present one (activity of the TD neurons). The link between PO and motor output (MO) group ensures the reproduction of a learned sequence. this still position is an error. The control system will try to cancel these changes by modifying its wheel speed; a tracking behavior emerges. Our mobile robot is following the detected movements in its optical field, i.e., it "imitates" the moves of the human teacher, but, more than a simple reproduction, the system also learns the whole trajectory made by the teacher, in order to reproduce it later. By "whole trajectory," we refer to the entire temporal sequence of motor actions. The robot learns to reproduce its own sequence of actions primarily induced by the tracking behavior. To do this, the control architecture of the robot is based on a neural network which learns and predicts the temporal succession of events. This is inspired by the functions of two brain structures involved in memory and time learning: the cerebellum and the hippocampus (see <ref type="bibr" target="#b3">[4]</ref> for more neurobiological references). The network is made of three groups of neurons (Fig. <ref type="figure" target="#fig_1">4</ref>):</p><p>1) time derivation (TD) group;</p><p>2) time base (TB) group;</p><p>3) prediction output (PO) group. Here, TB is stimulated at t = 0.</p><p>The TB keeps a temporal trace of a past event. It is a set of neurons whose activity time course looks like a wavelet basis. The TB neurons are triggered in batteries with each battery corresponding to a line of neurons. In the experiment, 15 cells constitute a battery. Temporal activity of six cells of one of the batteries is presented in Fig. <ref type="figure" target="#fig_2">5</ref>. The activation of a TB cell is computed as follows:</p><formula xml:id="formula_0">Act (1)</formula><p>where position of the cell in the group (the th cell of the th battery); and time constant and the standard deviation associated to the th cell; instant of the activation of the th line of neurons. The TD group performs the derivation of the input signal. TD activates TB at the beginning of an input event. The PO group receives information from TD (the present event) and TB (a temporal trace of the past event). The timing between the past and present events is learned in the TB-PO connection weights. The strength between a PO neuron and a TB battery is modified according to if Act unmodified otherwise.</p><p>(</p><formula xml:id="formula_1">)<label>2</label></formula><p>Because of the connectivity between TD, TB, and PO, each PO neuron can learn a given transition between two events. To possible events corresponds neurons in PO. The potential of a PO neuron is the sum of the information coming from TD and the delayed activity in TB. The potential of a PO neuron is computed as Pot Act Act (3) Fig. <ref type="figure">6</ref>. Learning sequences of movements via imitation. The robot follows its human teacher and learns the timing of its own movements. The sequence is then associated to a given motivation. Later, the robot will be able to reproduce the sequence according to the satisfaction of the motivation.</p><p>is the activity of the cell of the battery of TB. is the connection strength between the neuron and the neuron. One neuron of PO is linked with all of the neurons of a battery of TB.</p><p>is the corresponding TD neuron of a neuron and the strength of link between them. A PO neuron only fires when its potential reaches its maximum value, which corresponds to the prediction of a new pattern Act Pot (4) if and otherwise.</p><p>(</p><p>Hence, after a first sequence of actions (Fig. <ref type="figure">6</ref>), a motor neuron will be activated by the input and will also receive information from the transition prediction group (PO). Then, a simple conditioning rule allows the activated neuron to react the next time the action is predicted even if the input does not provide any information. Moreover, if the sequence of movements induces a positive reward, the past predicted transitions and their associated movements are reinforced. Thus, the robot learns to imitate the behavior (here, the sequence of movements) of the teacher according to an activated motivation. More details about the robotic issues such as the tracking system, the vision filtering, or how the system copes with multiple trajectories can be found in <ref type="bibr" target="#b11">[12]</ref>. Such a robotic experiment is, of course, dependent on the experimental setup and the system being sensible to the perception ambiguity. Therefore, a lot of parts of the experimental setup still have to be controlled by the human teacher: the speed of the demonstration, the distances, etc. Practically, the teacher also controls the succession of the perceptions of the robot. At learning phase, step-by-step perceptions induce the actions to be learned. At reproduction phase, an initial perception triggers the demonstration. The start of an experiment is also explicitly signaled by the teacher (he touches a specific sensor of the robot) which induces the following consequences.</p><p>1) The teacher decides when the learning experiment begins and stops. 2) He explicitly gives the robot the information (as a reward) about the end of the learning. 3) He also gives a signal to induce the reproduction of the sequence. These steps assume that the experimenter is a human agent. Adding to the robot the capability to perceive or predict the end of the experiment would improve its autonomy, allowing it to decide spontaneous learning via imitation of others. Such an ability could be a great improvement among a group of robots. They could learn from each other new skills, as a kind of social transmission <ref type="bibr" target="#b29">[30]</ref>. This statement led us to turn to the communicative function of imitation in young children, who initiate actions in order to be imitated, observe, and reproduce the other's action without any explicit "end of pattern" signal and with internal capabilities to modulate self actions according to the other participant of the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. INTERACTION BETWEEN TWO SYSTEMS: SYNCHRONIZATION EFFECTS</head><p>In this section, we investigate interactions between two simulated robots that have prior knowledge of the same sequence of actions. This situation is inspired by games among young children where immediate gestural imitations are performed quasisimultaneously (Fig. <ref type="figure" target="#fig_0">1</ref>). Such interactions involve the capability of motor synchronization where the same sequences of actions are executed at the same time. The synchrony can be seen as an attractor of a cyclic interaction game between two or more agents. We study here the overall dynamic of a loop made of two identical systems with perception and action groups interconnected (Fig. <ref type="figure" target="#fig_3">7</ref>) in order to understand which minimal features need to be added to our architecture. Sections IV-A and B explain how minor improvements of the architecture can reach a trade-off between independent production and adaptive production according to the other, i.e., synchronization. The problem is how to use the sensory-motor pathway for synchronization, since it must be inhibited to avoid cyclic perturbation due to the interconnection. The developed solution is inspired by the "entrainment" phenomenon observed by Huyggens in 1665, in which two pendulum clocks placed on the same support synchronize themselves ("clock synchronization"). In our simulations, perception is similar to the physical wave transmitted by the support; it energizes the system's actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Avoiding Interferences in the Reflex Pathway</head><p>Let us suppose that both systems use the "transition learning and prediction" mechanism detailed in Section III. To simplify the analysis and the simulations, perception and action signals are supposed to have binary values. The output of the first system is connected to the input of the second one and vice  versa (this simulates perfect perceptions of the other's action). Both systems have learned separately the same sequence of actions (e,g., transitions , , are learned, allowing the production of the action sequence and so on).</p><p>In a machine-machine loop (Fig. <ref type="figure" target="#fig_3">7</ref>), the direct pathway connecting perception to action of both systems plays an important role. It is critical for the learning process but also interferes with the simple production of a given sequence. Thus, after learning, this sensory-motor pathway must be inhibited (Fig. <ref type="figure" target="#fig_4">8</ref>), in order to allow an independent and complete production of the sequence without perturbations. The inhibition is realized by connecting "nonnovelty detection" (ND) neurons (Fig. <ref type="figure" target="#fig_5">9</ref>) to the input group. Once activated, these neurons remain potentialized [due to self feedback <ref type="bibr" target="#b5">(6)</ref>] inducing permanent inhibition of the corresponding input neuron. PO neurons act as "decision cells," triggering the inhibition when the system has completed its learning phase. The activity of the PO cells tells if an event was learned or not. The potential of the ND cells is computed as follows (only one PO cell fires at a time):</p><formula xml:id="formula_3">Pot Pot Act (6)</formula><p>where is the value of the recurrent connection (see Appendix B for numerical value).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Act</head><p>Pot <ref type="bibr" target="#b6">(7)</ref> </p><formula xml:id="formula_4">with if otherwise. (<label>8</label></formula><formula xml:id="formula_5">)</formula><p>is a threshold which sets the number of times the system can produce a sequence before the activation of ND cells and, therefore, the inhibition of the perception. The weights of the connections between ND cells and the input neurons will affect the value of the inhibition. A complete inhibition ensures an independent production: the "transition learning and prediction" network drives the system. However, it also cuts the system from the interaction. It is no longer possible to modulate the production according to the perceptions. So, the inhibition must only be partial (the weights of the connections between ND and input neurons are less than 1); the input signal must not be strong enough to induce motor reaction by itself. It must be, nevertheless, present in order to modulate the timing of the motor production.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Modulation of the Motor Production Timing</head><p>By "modulating" we mean changing the timing of the sequence in order to obtain synchronous production. This capability to synchronize could be a basis for more complex sensory-motor interactions.Inordertoproducesimultaneousactions,eachsystemhas to modulate its production speed in the manner of a phase locking loop mechanism (PLL). Accelerating or slowing the production is enough to obtain synchronization. We choose to enhance our architecture in order to provide our system the benefit of its perception to accelerate its production (slowing would have been much more complex to implement because it needs to add a negative energy to the system). If the system predicts earlier the motor activations, it will be able to "know" in advance the next action to perform and an incoming perception of this precise action will allow triggering it earlier. The following equation is used for an incremental learning of the TB-PO connections [instead of the "one-shoot learning" of (2)]:</p><formula xml:id="formula_6">Act Pot Act (<label>9</label></formula><formula xml:id="formula_7">)</formula><p>where is the learning rate of the system. This equation (a classical conditioning rule <ref type="bibr" target="#b24">[25]</ref>) induces a less accurate but earlier prediction of the motor event if the learning process is stopped after two or three presentations of the sequence. The integration of the PO output is done by a group of neurons called IG (Fig. <ref type="figure" target="#fig_6">10</ref>) according to the following equations: </p><formula xml:id="formula_8">Pot Pot Act reset<label>(10)</label></formula><p>A given MO neuron triggers the activation of a given action. The potential of MO neurons is computed as follows:</p><formula xml:id="formula_10">Pot Act Act (<label>14</label></formula><formula xml:id="formula_11">)</formula><p>It simply sums two incoming informations including the following.</p><p>• A signal from IG neurons that can trigger activation whenever it reaches a fixed threshold. Alone, the system is able to produce a learned sequence.</p><formula xml:id="formula_12">Act Pot (<label>15</label></formula><formula xml:id="formula_13">) if otherwise. (<label>16</label></formula><formula xml:id="formula_14">)</formula><p>• The integrated (but partially inhibited) perception signal from input neurons, i.e., Per, whose value is not high enough to overshoot the threshold.</p><formula xml:id="formula_15">Pot Pot Act (<label>17</label></formula><formula xml:id="formula_16">)</formula><p>where value of the recurrent connection (the potentiation is decreasing after activation); binary activity of the other system's MO neuron (direct connection). 1   Act Pot <ref type="bibr" target="#b17">(18)</ref> In normal functioning, the PO prediction is integrated by the IG neurons. Activity of IG neurons increases due to self feedback and triggers the action when the threshold of MO neuron is exceeded (Fig. <ref type="figure" target="#fig_7">11</ref>). If a perception event occurs between the proposal of an action prediction and the triggering of the action, it will result in an acceleration of the system. Perception thus results in an earlier triggering of the chosen action (overshoot of the motor threshold). Finally, the connections between IG and MO groups change according to a conditioning rule (an LMS equation <ref type="bibr" target="#b24">[25]</ref>). It modulates the efficiency of IG activity on MO potential according to the right timing of the sequence during learning phase</p><formula xml:id="formula_17">Act Pot Act (<label>19</label></formula><formula xml:id="formula_18">)</formula><p>where is the learning rate of the system. Between two systems producing the same sequence, the effect of connecting action to perception induces a step-by-step adjustment of the sequence production until synchronization is achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results of Simulated Experiments</head><p>Simulations were performed according to two experimental protocols.</p><p>1) A first series of experiments tested the synchronization of our architecture with a simple generator of time-fixed sequences [Fig. <ref type="figure" target="#fig_8">12(a)</ref>]. Once the sequence is learned, we tested the system's production simultaneously with the generator. The system was triggered at random instants while the generator produced its sequence recurrently. 1 [x] = x if x &gt; 0; 0 otherwise. 2) In a second series of experiments, two copies of our architecture were used [Fig. <ref type="figure" target="#fig_8">12(b)</ref>]. Both had learned the same sequence (from a fixed sequence generator). Both systems were switched at random instants. Each architecture was a separate application, designed and simulated using Leto and Prometheus software involving parallel virtual machine (PVM) software.<ref type="foot" target="#foot_0">2</ref> For both experiments, synchronization is an attractor of the interactions. The conditions and speed of convergence toward this attractor are directly dependent of the detailed equations. Synchronization is here an example of a stable state which can be obtained by controlling parameters and equations of the systems forming parts of the whole dynamic.</p><p>In Section V, we will use the fundamental properties of interactive systems, such as synchronization, to build a nonexplicit Fig. <ref type="figure" target="#fig_0">13</ref>. Simple associative network with one to all connections. The human teacher activates the input neurons by pressing the computer's numerical keys. The network proposes "motor" responses displayed on the computer screen. Bold links are those to be learned during the game (the rules to be discovered by the system).</p><p>reward signal from the rhythm of the interaction. We will show this network can easily be derived from the "transition learning and prediction" neural network used in the previous experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. LEARNING NEW SENSORY-MOTOR ASSOCIATIONS WITHOUT EXPLICIT REINFORCEMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Description of the Problem</head><p>A simplified of our neural network can be adapted to the prediction of the rhythm exchange in a student-teacher interaction. The current application concerns rhythm prediction, used as an internal reinforcement signal in order to permit autonomous learning. In a simple association problem (Fig. <ref type="figure" target="#fig_0">13</ref>), sensory input has to be associated with a given motor response. Here, we consider the simplest application, where each input and output is only coded by a single neuron. As shown in Fig. <ref type="figure" target="#fig_0">13</ref>, we have three input neurons and three output neurons. The input neurons could represent the detection of a perceived movement, and the output neurons the execution of possible motor responses. Via interactions, the system has to learn to propose the correct, i.e., similar, response according to the stimulus input. For example, if input 1 is activated, the system has to produce the output A. If input 2 is presented, then output B should be the response, and so on.</p><p>The task can be viewed as a game: on one side, the human participant, i.e., the teacher, expects the associations to be performed. By activating one of the keys of the numerical keyboard of a computer, he directly activates the correspondent input of the network (we call this action a "key pression" or "key activation"). On the other side, the system, detecting an activated input, has to choose and associate it to one of the three possible responses. During the game, there is no way for the teacher to give the learner any explicit reward (no kind of meaningful "explicit key"). The system will have to discover by itself the reinforcement information in the data flow, which is only a temporal series of inputs. In Sections V-B and C we show that learning rules based on a simple correlation mechanism <ref type="bibr" target="#b7">[8]</ref> is not enough. However, the prediction mechanism described previously can be used to build an internal reward efficient enough to control a simple reinforcement learning mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Can a Simple Correlation Rule do the Task?</head><p>A working hypothesis can be the use of a Hebbian learning rule. Associations between correlated active input and output could be learned according to the following rule: <ref type="bibr" target="#b19">(20)</ref> where term of constant passive decay; term of active decay (decrease of the associations between the activated input and the nonactivated outputs-forgetting); learning rate ; activity of the input neuron ; value of the output neuron ; value of the weight between and (simulations made with weights were initialized at random low values). Although this rule permits the learning of sensory-motor correlations, it constrains the experiment on one main point: here the teacher has to adapt his way of playing to the system propositions to permit correct correlations to be learned. The teacher has to wait, drive, and teach the learner (see previous similar works <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>). Emphasizing nonexplicit reinforcement, we consider that this rule generates too much asymmetry between the teacher and the learner. Indeed, with this rule, the "game" turns into a dynamics where the system proposes a motor output, and then, the teacher answers with the right input, thus reinforcing the weight of the corresponding link, and weakening the weight of the noncorrelated input (active forgetting). Instead of this explicit and immediate reinforcement (the correlation) depending on the teacher, we think that our system could build a nonexplicit reward information from the dynamics of the interaction while testing different associations. Then, it could learn the correct associations. We use a probabilistic conditioning rule (PCR) <ref type="bibr" target="#b12">[13]</ref>, which has been experimented on delayed conditional learning, where the system had to test and evaluate the credibility of possible rules before learning them. This rule computes a credibility value associated to each connection. The credibility is used to switch the weight according to a reward value (details of the algorithm are shown in Appendixes A and B). If we want the reward to be nonexplicit, we should rather see the experiment as: the teacher is producing a motor output, i.e., the system input, and expects responses from the other part to continue the interaction process. The system responds and then evaluates the temporal regularity in the teacher's behavior. If the rhythm has changed, there is a good probability that the associated input-output (I/O) weights of the network have changed. To go further, the teacher will be considered as another player whose reactions change during the game according to how quickly the system learns. If correct associations are learned, the teacher tends to continue to play at nearly the same rhythm, but if a wrong response occurs, there is a strong probability that the teacher makes a break to "say something" or express his Fig. <ref type="figure" target="#fig_1">14</ref>. Presentation of the system used to learn and predict delays between the teacher's game. The result of the comparison between the prediction (PO cell activity) and the effective input (derived in TD) is directly connected to the reward evaluation modulating the learning of associative connections between inputs and outputs.</p><p>disagreement. He may also change the rhythm (as an extreme situation, the teacher could give up the game). In such a game, the rhythm of the key activation is the only information that can be used to adjust the learning. If the student is able to correctly predict the rhythm, there is no need for it to understand the meaning of the words pronounced when a disagreement occurs. A break in the rhythm is sufficient to provide an error signal. This model only requires a nonverbal context and low-level cognitive capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Predicting the Rhythm as a Reward Signal</head><p>If the rhythm prediction is correct, the system can maintain its learning of the current presented association. If the prediction is wrong, it may set the association as noncredible and decrease the corresponding weight.</p><p>In order to maintain the rhythm prediction, we again use the "transition learning and prediction" system depicted in Fig. <ref type="figure" target="#fig_1">4</ref>. As shown in Fig. <ref type="figure" target="#fig_1">14</ref> the three components TD, TB, and PO are used to learn the time delay between two keys activations. TD "pulses" each time a key is pressed, initializing the activity of TB. During the interval between two key activations, TB cells are firing according to (1) as shown in Fig. <ref type="figure" target="#fig_2">5</ref>. When the next key is pressed, PO is activated, the connections (between PO and TB) corresponding to the currently activated cell of TB are reinforced <ref type="bibr" target="#b1">(2)</ref>, and the delay is learned. The system is then able to predict the instant of the next key pressure. We use the prediction information of PO to do so: the analogical activity of a single PO cell (4) and the binary prediction information <ref type="bibr" target="#b4">(5)</ref>. Fig. <ref type="figure" target="#fig_9">15</ref> shows how the system maintains the two information during an experiment with a human teacher.</p><p>The activity of the PO cell is then summed with the output of TD, to compare the prediction with the real event. If we take the PO activity (Fig. <ref type="figure" target="#fig_9">15</ref>) as an inhibitory activity summed to the event, we directly obtain an error message, which is proportional to the prediction mismatch Error Act Pot ( <ref type="formula">21</ref>) By multiplying the prediction information by the TD output, we obtain a binary success value Success Act Act <ref type="bibr" target="#b21">(22)</ref> where Act Act are binary values 0, 1 (a value of 1 indicates a matching between the system's prediction and the teacher's rhythm). Error and success information are then compared to modulate directly the learning of the associative network Reward if Success error if Error otherwise <ref type="bibr" target="#b22">(23)</ref> where is a value that is high enough to induce an instantaneous weight modification (see Appendix B for numerical values). Fig. <ref type="figure" target="#fig_10">16</ref> shows a complete trial, with the input train of the human key activations. For each activation, the system gives a response (randomly at start). Then, it learns from the other's behavior. Interruptions in the human actions are visible, and the middle graph shows the success/error information extracted by the predicting system. Experiments lasted about 4 min. The network always succeeds in learning the three correct associations. Most of the time, an experiment starts with wrong associations due to the random weightsinitialized onthenetworklinks.This explainstheplayer's numerous breaks (Fig. <ref type="figure" target="#fig_10">16</ref>). When the first association is discovered, the learning of the others is facilitated by the decreasing number of possible associations: in this nonverbal communication perspective, a dynamic learning is possible. Here, the system is able to detect novelty in the teacher's behavior, and to use this novelty as an implicit reward signal for learning. Novelty is defined as a nonexpected break in the rhythm perceived at the system's inputs. This could help to "locate" important events or to learn properties on objects or surrounding entities. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>The main contribution of this paper is a novel approach for building autonomous systems able to imitate actions of increasing complexity and to distinguish between imitation of novel and previously learned actions. Our approach challenges the classical view, which focuses on how a robot can imitate and capture the meaning of a movement, and which delineates the learning phases by specific signals. To achieve our goals, we postulate the imitation capabilities of our system are based on a homeostatic principle. The variations of the perceptive flow are interpreted as a signal of error. In an effort to reduce this signal, the system produces an imitative behavior. We believe that this simple principle can be useful to build systems that are really able to process in an autonomous way different levels of imitation, such as following a path, reproducing the movement of an arm, or imitating complex actions like opening a door, cooking, or building a complex machinery. When the system has to perform the immediate imitation of an already learned behavior, uncoupling perception and action appeared to be decisive in order to prevent perceptive interferences. Although the current assumption underlying robotic works on imitation is that distinctive capabilities should characterize teacher and imitator systems, our model shows the interest to implement systems with similar basic imitative capabilities. Indeed, if both simulated systems come to perform a similar action, this induces a phase lock on this action, which will facilitate further introduction of turntaking and learning from each other.</p><p>In this work, the collaboration with a psychologist has been crucial since we have tried to understand some of the fundamental properties of young infants involved in imitation games and interaction situations. We have discovered that immediate imitation is much more complex than previously thought and that its double role in learning and communica-tion was of a very high importance for robot learning. This collaborative work inspired us to come up with the idea that an autonomous system could generate by itself its own reward signal for learning. It also inspired us the exploitation of the temporal properties (prediction, synchronization) of our model for interaction purposes. Of course, the simulations presented in this paper are quite simple, in comparison with the complex cognitives faculties of the young infants, but we think that basic skills such as synchronization and rhythm detection are a possible step toward the understanding of social capabilities (it could be the kind of information babies use to detect the correspondence of their behavior with their caregivers).</p><p>Moreover, we can notice that our neural network (NN) architecture is based on previous works on hippocampus modeling <ref type="bibr" target="#b4">[5]</ref>. In these models, we claim that the hippocampus is not just a working memory or, at the opposite, a cognitive map, <ref type="bibr" target="#b22">[23]</ref> but a structure where transitions between states or places are stored and predicted. This model could explain the role of the hippocampus during conditioning learning <ref type="bibr" target="#b26">[27]</ref> and the recent puzzling results in spatial navigation <ref type="bibr" target="#b28">[29]</ref>, and of course, it provides the fundamental elements we need for learning by imitation and learning by interaction. Note that this structure is only necessary in the learning phase and not in a simple imitation or reproduction phase (in a more detailed model the definitive learning of the sequences should be performed in other structures). Finally, we are interested in the idea that imitation capabilities could be progressively built up from very simple sensory-motor schemes, since it would promote important advances in man-machine interface and robot learning. Moreover, a robot could be considered a good heuristic tool to propose new behavioral therapies given the present imitative capabilities in children with autism who are supposed to face problems with human models.</p><p>Our future works will focus on real size robotic experiments using mobile robots with mechanical arms. We will have to understand how to add to our neural model structures allowing to learn categories of actions at the program level. We hope the developed architecture will be able to exhibit different phases of developments that we will be able to compare with babies development. Hence, we will perhaps be able to help in the understanding of mental development problems like children with autism: is autism linked to a problem of theory of mind, to the sensory-motor level, to the management of novelty detection, or even to the capability to mobilize or express internal states? This kind of questioning is perhaps unfamiliar for engineers since we know we are really far away from building nonautistic robots, but, it is clear that all the new results in psychology and neuroimagery will be of high interest to improve current robot controllers. At the same time, robotics experiments appear more and more as a new way to perform synthetic simulations of psychological and neurobiological models and are promised to be an important development in the field of cognitive sciences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A PCR ALGORITHM</head><p>The PCR is useful for conditioned learning with a delayed reward (a complete description of the algorithm can be found in <ref type="bibr" target="#b12">[13]</ref>). Binary weights are associated with a probability</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Young children interacting and turntaking. Imitation deserves a communication purpose, where synchronization and rhythm matter.Reproduction from<ref type="bibr" target="#b19">[20]</ref>.</figDesc><graphic coords="1,302.16,167.61,250.00,165.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Detailed connectivity of the event prediction network. The circle size in TB is associated to the time constants (m ) of the neurons.</figDesc><graphic coords="3,305.46,288.72,242.40,203.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Time activity of a group of cells that allows to measure time in the TB.</figDesc><graphic coords="4,40.14,62.28,250.08,193.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Interconnection of two systems. System 1 and 2 have the same architecture. Each system has learned perception-action associations. The two systems must produce outputs (the same sequence of motor outputs for example) at the same time.</figDesc><graphic coords="5,46.38,62.28,234.48,81.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Introduction of new elements to allow synchronization between agents. "Nonnovelty detection" (ND) and Integration (IG) groups are used to control the internal dynamic of the system.</figDesc><graphic coords="5,307.26,62.28,238.80,174.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Mechanism allowing to inhibit the perception-action pathway. The triggering information comes from the corresponding PO neurons, firing if the corresponding event is implicated in the production of a sequence. Recurrent connections on ND neurons then maintain the inhibition on the inputs.</figDesc><graphic coords="5,305.70,305.28,241.92,168.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Motor output (MO) group triggers the motor output when integrated prediction overshoots a given threshold. If an input information (also integrated) happens during the integration of prediction, the summing potential of MO reaches the threshold early: the system accelerates.</figDesc><graphic coords="6,308.04,62.28,240.24,156.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. Activity of PO and IG cells during the production of a sequence: PO cell fires for a transition. The maximum of its potential generates an activation spike. This spike will be integrated (IG) until the MO neurons reach the threshold, triggering the motor activation.</figDesc><graphic coords="7,48.06,62.28,231.12,182.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 12 .</head><label>12</label><figDesc>Fig.12. Interaction between two systems: Upper panel (a) shows the synchronization phase of our system (gray) on a fixed sequence (black). (b) Lower panel graph shows the very quick synchronization between two identical systems (gray and black). A small perturbation occurred near iteration 730 due to the temporary loss of messages between stations (via PVM). Perfect synchronization is quickly recovered.</figDesc><graphic coords="7,305.94,272.58,241.44,190.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Example of a 20 s experimental scenario. Upper graph: Each pulse indicates when the teacher presses a key (only the information of time is given).A constant rhythm is maintained for the first five strikes (time period = A), then is broken (according to a bad system's response for example). Middle graph: Pulses show the system's binary prediction of the teacher's play. Each pulse happened just before the teacher's key activations. The star means a prediction error due to the break. Bottom graph: Activity of the PO cell. Maxima of activity trigger pulses of prediction. After the rhythm break, the new delay B is learned.</figDesc><graphic coords="9,308.70,62.28,235.92,198.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Learning process during a whole experiment (about 200 s). Upper panel graph: Action frequency of the human player. Middle panel graph: Variation of the reinforcement signal according to the rhythm prediction. Positives values are caused by a successful prediction of the time interval between two activations, while negative ones are due to prediction error. These reinforcement variations act on the update of the associative weight. Lower panel graph: Evaluation of the learning level. A well-learned association gives 1 point, an unlearned one gives 0 points, while a bad learned one loses 1 point.</figDesc><graphic coords="10,47.40,62.28,235.44,188.40" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The PVM software creates a virtual machine from a set of computers.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The author gratefully acknowledges J. L. Contreras-Vidal for improving the English of the paper and G. Bugman, A. Revel, M. Quoy, I. Fijalkow, and K. Dautenhahn for their interesting comments about this work.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is part of the French program "Cognitic" (Action Concertee Incitative Cognitique, COG 156), involving neuroimaging, modeling, behavioral, and clinical studies. P. Andry, P. Gaussier, and S. Moga are with the Neurocybernetic Team, Image and Signal Processing (</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>which measures the certainty of the weight . If and <ref type="bibr" target="#b23">(24)</ref> When the reward signal varies, probabilities are updated and weights can be modified according to the certainty value.</p><p>If Reward Reward <ref type="bibr" target="#b24">(25)</ref> If there is no reinforcement variation neither the probabilities nor the weights are modified but information about the correlation between the input and the output of the weight go on being stored.</p><p>(</p><p>where , , updated with (26); ; delayed conditioning learning rate; constant fixed by the experimenter; random value in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B EXPERIMENTAL PARAMETERS</head><p>The parameter is the global learning rate used in the simulator:</p><p>. Parameters for Section IV simulations Parameters for Section V simulations </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imitation: Learning and communication</title>
		<author>
			<persName><forename type="first">P</forename><surname>Andry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth Int. Conf. Simulation Adaptive Behavior SAB</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Meyer</surname></persName>
		</editor>
		<meeting>Sixth Int. Conf. Simulation Adaptive Behavior SAB<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Design for a Brain</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Ashby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960">1960</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bandura</surname></persName>
		</author>
		<title level="m">Psychological Modeling: Conflicting Theories</title>
		<meeting><address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<publisher>Aldine-Atherton</publisher>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The cortical-hippocampal system as a multirange temporal processor: A neural model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Banquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fundamentals of Neural Network Modeling for Neuropsychologists</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Park</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Levin</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Space-time, order, and hierarchy in fronto-hippocamal system: A neural basis of personality</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Banquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Science Perspectives on Personality and Emotion</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Mattews</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="123" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Experiments on human-robot communication with robota, an imitative learning and communicating robot</title>
		<author>
			<persName><forename type="first">A</forename><surname>Billard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Socially Situated Intell. Workshop, Part Fifth Int. Conf. Simulation Adaptive Behavior</title>
		<meeting>Socially Situated Intell. Workshop, Part Fifth Int. Conf. Simulation Adaptive Behavior</meeting>
		<imprint>
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transmittimg communication skills throught imitation in autonomous robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Billard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth Euro. Workshop Learning Robots</title>
		<meeting>Sixth Euro. Workshop Learning Robots</meeting>
		<imprint>
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to communicate through imitation in autonomous robots</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Conf. Artif</title>
		<meeting>7th Int. Conf. Artif</meeting>
		<imprint>
			<date type="published" when="1997-10">Oct. 1997</date>
			<biblScope unit="page" from="763" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Neonatal imitation: Existence, mechanisms and motives</title>
		<author>
			<persName><forename type="first">G</forename><surname>Butterworth</surname></persName>
		</author>
		<editor>Cambridge, U.K.</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge Univ. Press</publisher>
			<biblScope unit="page" from="63" to="88" />
		</imprint>
	</monogr>
	<note>in Imitation in Infancy</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Complex continuous meaningful humanoid interaction: A multi sensory-cue based approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kuniyoshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Automat</title>
		<meeting>IEEE Int. Conf. Robot. Automat</meeting>
		<imprint>
			<date type="published" when="2000-04">Apr. 2000</date>
			<biblScope unit="page" from="2235" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Getting to know each other-artificial social intelligence for autonomous robots</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot. Autonom. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="333" to="356" />
			<date type="published" when="1995-12">Dec. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From perception-action loops to imitation processes: A bottom-up approach of learning by imitation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="701" to="727" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Living in a partially structured environment: How to bypass the limitation of classical reinforcement techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot. Autonom. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="225" to="250" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Guillaume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">L&apos;imitation Chez L&apos;enfant</title>
		<imprint>
			<date type="published" when="1925">1925</date>
			<publisher>Alcan</publisher>
			<pubPlace>Paris, France</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Genesis and development of early infant mimesis to facial and vocal models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kugiumutzakis</surname></persName>
		</author>
		<editor>Cambridge, U.K.</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge Univ. Press</publisher>
			<biblScope unit="page" from="36" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The origin and development of imitation in the first sixth month of life</title>
		<author>
			<persName><forename type="first">O</forename><surname>Maratos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. British Psychol. Soc. Annu. Meet</title>
		<imprint>
			<date type="published" when="1973-04">Apr. 1973</date>
			<pubPlace>Liverpool, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imitation of facial and manual gestures by humans neonates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Meltzoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="75" to="82" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explaining facial imitation: A theoretical model</title>
	</analytic>
	<monogr>
		<title level="j">Early Develop. Parenting</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Persons and representation: Why infants imitation is important for theories of human development</title>
		<editor>Cambridge, U.K.</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge Univ. Press</publisher>
			<biblScope unit="page" from="9" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The functional use of imitation in preverbal infants and nonverbal children with autism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nadel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Imitative Mind: Development, Evolution, and Brain Bases</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Meltzoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Prinz</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The evolving nature of imitation as a format for communication</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nadel</surname></persName>
		</author>
		<editor>Cambridge, U.K.</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge Univ. Press</publisher>
			<biblScope unit="page" from="209" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mapping between dissimilar bodies: Affordances and the algebraic foundations of imitation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Nehaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Euro. Workshop Learning Robots</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Demiris</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Birk</surname></persName>
		</editor>
		<meeting>7th Euro. Workshop Learning Robots</meeting>
		<imprint>
			<date type="published" when="1998-07">July 1998</date>
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The hippocampal cognitive map and navigational strategies</title>
		<author>
			<persName><forename type="first">J</forename><surname>O'keefe</surname></persName>
		</author>
		<editor>Brain and Space, J. Paillard</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Oxford Univ. Press</publisher>
			<biblScope unit="page" from="273" to="295" />
			<pubPlace>London, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Piaget</surname></persName>
		</author>
		<title level="m">La Formation du Symbole Chez L&apos;enfant</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Delachaux et Niestle</publisher>
			<date type="published" when="1945">1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non reinforcement</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rescola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Classical Conditioning II: Current Research and Theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Appleton</publisher>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">From mirror neurons to imitation: Facts and speculations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Imitative Mind: Development, Evolution, and Brain Bases</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Meltzoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Prinz</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural mechanism of classical conditioning in mammals</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil. Trans. R. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="161" to="170" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Q-learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evidence for extrahippocampal involvement in place learning and hippocampal involvement in path integration</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Q</forename><surname>Whishaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Jarrard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="513" to="524" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the nature and evolution of imitation in the animal kingdom: Reappraisal of a century of research</title>
		<author>
			<persName><forename type="first">A</forename><surname>Whiten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in the Study of Behavior</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Slater</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="239" to="283" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
