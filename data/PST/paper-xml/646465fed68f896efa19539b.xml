<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Expert-Level Medical Question Answering with Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-05-16">16 May 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Karan</forename><surname>Singhal</surname></persName>
							<email>karansinghal@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Tu</surname></persName>
							<email>taotu@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Juraj</forename><surname>Gottweis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rory</forename><surname>Sayres</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ellery</forename><surname>Wulczyn</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Le Hou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Clark</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Pfohl</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heather</forename><surname>Cole-Lewis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Darlene</forename><surname>Neal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Schaekermann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mohamed</forename><surname>Amin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sami</forename><surname>Lachgar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philip</forename><surname>Mansfield</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sushant</forename><surname>Prakash</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bradley</forename><surname>Green</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ewa</forename><surname>Dominowska</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Blaise</forename><surname>Aguera Y Arcas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nenad</forename><surname>Tomasev</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Renee</forename><surname>Wong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Semturs</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Sara Mahdavi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joelle</forename><surname>Barral</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dale</forename><surname>Webster</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yossi</forename><surname>Matias</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shekoofeh</forename><surname>Azizi</surname></persName>
							<email>shekazizi@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><surname>Karthikesalingam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vivek</forename><surname>Natarajan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>2 DeepMind</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Neo</orgName>
								<address>
									<addrLine>33.3 PubMedBERT 38.1 BioLinkBERT 45.1 DRAGON 47.5 BioMedLM 50.3 GPT 3.5 60.2 Med-PaLM 67.2 Med-PaLM 2 86.5 0 20 40</addrLine>
									<postCode>60 80 100</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Expert-Level Medical Question Answering with Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-05-16">16 May 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2305.09617v1[cs.CL]</idno>
					<note type="submission">Dec 20 Sep 21 Mar 22 Oct 22 Dec 22 Dec 22 Dec 22 Mar 23</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers.</p><p>Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach. Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over 19% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets. We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p &lt; 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p &lt; 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language is at the heart of health and medicine, underpinning interactions between people and care providers. Progress in Large Language Models (LLMs) has enabled the exploration of medical-domain capabilities in artificial intelligence (AI) systems that can understand and communicate using language, promising richer human-AI interaction and collaboration. In particular, these models have demonstrated impressive capabilities on multiple-choice research benchmarks <ref type="bibr" target="#b0">[1]</ref><ref type="bibr">[2]</ref><ref type="bibr">[3]</ref>.</p><p>In our prior work on Med-PaLM, we demonstrated the importance of a comprehensive benchmark for medical question-answering, human evaluation of model answers, and alignment strategies in the medical domain <ref type="bibr" target="#b0">[1]</ref>. We introduced MultiMedQA, a diverse benchmark for medical question-answering spanning medical exams, consumer health, and medical research. We proposed a human evaluation rubric enabling physicians and lay-people to perform detailed assessment of model answers. Our initial model, Flan-PaLM, was the first to exceed the commonly quoted passmark on the MedQA dataset comprising questions in the style of the US Medical Licensing Exam (USMLE). However, human evaluation revealed that further work was needed to ensure the AI output, including long-form answers to open-ended questions, are safe and aligned with human values and expectations in this safety-critical domain (a process generally referred to as "alignment"). To bridge this, we leveraged instruction prompt-tuning to develop Med-PaLM, resulting in substantially improved physician evaluations over Flan-PaLM. However, there remained key shortfalls in the quality of model answers compared to physicians. Similarly, although Med-PaLM achieved state-of-the-art on every multiple-choice benchmark in MultiMedQA, these scores left room for improvement.</p><p>Here, we bridge these gaps and further advance LLM capabilities in medicine with Med-PaLM 2. We developed this model using a combination of an improved base LLM (PaLM 2 <ref type="bibr">[4]</ref>), medical domain-specific finetuning and a novel prompting strategy that enabled improved medical reasoning. Med-PaLM 2 improves upon Med-PaLM by over 19% on MedQA as depicted in Figure <ref type="figure" target="#fig_0">1</ref> (left). The model also approached or exceeded state-of-the-art performance on MedMCQA, PubMedQA, and MMLU clinical topics datasets.</p><p>While these benchmarks are a useful measure of the knowledge encoded in LLMs, they do not capture the model's ability to generate factual, safe responses to questions that require nuanced answers, typical in real-world medical question-answering. We study this by applying our previously published rubric for evaluation by physicians and lay-people <ref type="bibr" target="#b0">[1]</ref>. Further, we introduce two additional human evaluations: first, a pairwise ranking evaluation of model and physician answers to consumer medical questions along nine clinically relevant axes; second, a physician assessment of model responses on two newly introduced adversarial testing datasets designed to probe the limits of LLMs.</p><p>Our key contributions are summarized as follows:</p><p>? We developed Med-PaLM 2, a new medical LLM trained using a new base model (PaLM 2 <ref type="bibr">[4]</ref>) and targeted medical domain-specific finetuning (Section 3.2).</p><p>? We introduced ensemble refinement as a new prompting strategy to improve LLM reasoning (Section 3.3).</p><p>? Med-PaLM 2 achieved state-of-the-art results on several MultiMedQA benchmarks, including MedQA USMLE-style questions (Section 4.1).</p><p>? Human evaluation of long-form answers to consumer medical questions showed that Med-PaLM 2's answers were preferred to physician and Med-PaLM answers across eight of nine axes relevant to clinical utility, such as factuality, medical reasoning capability, and low likelihood of harm. For example, Med-PaLM 2 answers were judged to better reflect medical consensus 72.9% of the time compared to physician answers (Section 4.2 and Figure <ref type="figure" target="#fig_0">1</ref>).</p><p>? Finally, we introduced two adversarial question datasets to probe the safety and limitations of these models. We found that Med-PaLM 2 performed significantly better than Med-PaLM across every axis, further reinforcing the importance of comprehensive evaluation. For instance, answers were rated as having low risk of harm for 90.6% of Med-PaLM 2 answers, compared to 79.4% for Med-PaLM. (Section 4.2, Figure <ref type="figure" target="#fig_6">5</ref>, and Table <ref type="table" target="#tab_7">A</ref>.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The advent of transformers <ref type="bibr">[5]</ref> and large language models (LLMs) <ref type="bibr">[6,</ref><ref type="bibr">7]</ref> has renewed interest in the possibilities of AI for medical question-answering tasks-a long-standing "grand challenge" <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. A majority of these approaches involve smaller language models trained using domain specific data (BioLinkBert <ref type="bibr" target="#b10">[11]</ref>, DRAGON <ref type="bibr" target="#b11">[12]</ref>, PubMedGPT <ref type="bibr" target="#b12">[13]</ref>, PubMedBERT <ref type="bibr" target="#b13">[14]</ref>, BioGPT <ref type="bibr" target="#b14">[15]</ref>), resulting in a steady improvement in state-of-the-art performance on benchmark datasets such as MedQA (USMLE) <ref type="bibr" target="#b15">[16]</ref>, MedMCQA <ref type="bibr" target="#b16">[17]</ref>, and PubMedQA <ref type="bibr" target="#b17">[18]</ref>.</p><p>However, with the rise of larger general-purpose LLMs such as GPT-3 <ref type="bibr" target="#b18">[19]</ref> and Flan-PaLM <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> trained on internet-scale corpora with massive compute, we have seen leapfrog improvements on such benchmarks, all in a span of a few months (Figure <ref type="figure" target="#fig_0">1</ref>). In particular, GPT 3.5 <ref type="bibr">[3]</ref> reached an accuracy of 60.2% on the MedQA (USMLE) dataset, Flan-PaLM reached an accuracy of 67.6%, and GPT-4-base <ref type="bibr">[2]</ref> achieved 86.1%.</p><p>In parallel, API access to the GPT family of models has spurred several studies evaluating the specialized clinical knowledge in these models, without specific alignment to the medical domain. Levine et al. <ref type="bibr" target="#b21">[22]</ref> evaluated the diagnostic and triage accuracies of GPT-3 for 48 validated case vignettes of both common and severe conditions and compared to lay-people and physicians. GPT-3's diagnostic ability was found to be better than lay-people and close to physicians. On triage, the performance was less impressive and closer to lay-people. On a similar note, Duong &amp; Solomon <ref type="bibr" target="#b22">[23]</ref>, Oh et al. <ref type="bibr" target="#b23">[24]</ref>, and Antaki et al. <ref type="bibr" target="#b24">[25]</ref> studied GPT-3 performance in genetics, surgery, and ophthalmology, respectively. More recently, Ayers et al. <ref type="bibr" target="#b25">[26]</ref> compared ChatGPT and physician responses on 195 randomly drawn patient questions from a social media forum and found ChatGPT responses to be rated higher in both quality and empathy.</p><p>With Med-PaLM and Med-PaLM 2, we take a "best of both worlds" approach: we harness the strong out-of-thebox potential of the latest general-purpose LLMs and then use publicly available medical question-answering data and physician-written responses to align the model to the safety-critical requirements of the medical domain. We introduce the ensemble refinement prompting strategy to improve the reasoning capabilities of the LLM. This approach is closely related to self-consistency <ref type="bibr" target="#b26">[27]</ref>, recitation-augmentation <ref type="bibr" target="#b27">[28]</ref>, self-refine <ref type="bibr" target="#b28">[29]</ref>, and dialogue enabled reasoning <ref type="bibr" target="#b29">[30]</ref>. It involves contextualizing model responses by conditioning on multiple reasoning paths generated by the same model in a prior step as described further in Section 3.3.</p><p>In this work, we not only evaluate our model on multiple-choice medical benchmarks but also provide a rubric for how physicians and lay-people can rigorously assess multiple nuanced aspects of the model's long-form answers to medical questions with independent and pairwise evaluation. This approach allows us to develop and evaluate models more holistically in anticipation of future real-world use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We evaluated Med-PaLM 2 on multiple-choice and long-form medical question-answering datasets from MultiMedQA <ref type="bibr" target="#b0">[1]</ref> and two new adversarial long-form datasets introduced below.</p><p>Multiple-choice questions For evaluation on multiple-choice questions, we used the MedQA <ref type="bibr" target="#b15">[16]</ref>, MedM-CQA <ref type="bibr" target="#b16">[17]</ref>, PubMedQA <ref type="bibr" target="#b17">[18]</ref> and MMLU clinical topics <ref type="bibr" target="#b30">[31]</ref> datasets (Table <ref type="table" target="#tab_0">1</ref>).</p><p>Long-form questions For evaluation on long-form questions, we used two sets of questions sampled from MultiMedQA (Table <ref type="table" target="#tab_1">2</ref>). The first set (MultiMedQA 140) consists of 140 questions curated from the HealthSearchQA, LiveQA <ref type="bibr" target="#b31">[32]</ref>, MedicationQA <ref type="bibr" target="#b32">[33]</ref> datasets, matching the set used by Singhal et al. <ref type="bibr" target="#b0">[1]</ref>. The second set (MultiMedQA 1066), is an expanded sample of 1066 questions sampled from the same sources.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adversarial questions</head><p>We also curated two new datasets of adversarial questions designed to elicit model answers with potential for harm and bias: a general adversarial set and health equity focused adversarial set (Table <ref type="table" target="#tab_1">2</ref>). The first set (Adversarial -General) broadly covers issues related to health equity, drug use, alcohol, mental health, COVID-19, obesity, suicide, and medical misinformation. Health equity topics covered in this dataset include health disparities, the effects of structural and social determinants on health outcomes, and racial bias in clinical calculators for renal function <ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref>. The second set (Adversarial -Health equity) prioritizes use cases, health topics, and sensitive characteristics based on relevance to health equity considerations in the domains of healthcare access (e.g., health insurance, access to hospitals or primary care provider), quality (e.g., patient experiences, hospital care and coordination), and social and environmental factors (e.g., working and living conditions, food access, and transportation). The dataset was curated to draw on insights from literature on health equity in AI/ML and define a set of implicit and explicit adversarial queries that cover a range of patient experiences and health conditions <ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modeling</head><p>Base LLM For Med-PaLM, the base LLM was PaLM <ref type="bibr" target="#b19">[20]</ref>. Med-PaLM 2 builds upon PaLM 2 <ref type="bibr">[4]</ref>, a new iteration of Google's large language model with substantial performance improvements on multiple LLM benchmark tasks.</p><p>Instruction finetuning We applied instruction finetuning to the base LLM following the protocol used by Chung et al. <ref type="bibr" target="#b20">[21]</ref>. The datasets used included the training splits of MultiMedQA-namely MedQA, MedMCQA, HealthSearchQA, LiveQA and MedicationQA. We trained a "unified" model, which is optimized for performance across all datasets in MultiMedQA using dataset mixture ratios (proportions of each dataset) reported in Table <ref type="table" target="#tab_2">3</ref>. These mixture ratios and the inclusion of these particular datasets were empirically determined. Unless otherwise specified, Med-PaLM 2 refers to this unified model. For comparison purposes, we also created a variant of Med-PaLM 2 obtained by finetuning exclusively on multiple-choice questions which led to improved results on these benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multiple-choice evaluation</head><p>We describe below prompting strategies used to evaluate Med-PaLM 2 on multiple-choice benchmarks. Few-shot prompting Few-shot prompting <ref type="bibr" target="#b18">[19]</ref> involves prompting an LLM by prepending example inputs and outputs before the final input. Few-shot prompting remains a strong baseline for prompting LLMs, which we evaluate and build on in this work. We use the same few-shot prompts as used by Singhal et al. <ref type="bibr" target="#b0">[1]</ref>.</p><p>Chain-of-thought Chain-of-thought (CoT), introduced by Wei et al. <ref type="bibr" target="#b41">[42]</ref>, involves augmenting each few-shot example in a prompt with a step-by-step explanation towards the final answer. The approach enables an LLM to condition on its own intermediate outputs in multi-step problems. As noted in Singhal et al. <ref type="bibr" target="#b0">[1]</ref>, the medical questions explored in this study often involve complex multi-step reasoning, making them a good fit for CoT prompting. We crafted CoT prompts to provide clear demonstrations on how to appropriately answer the given medical questions (provided in Section A.3.1).</p><p>Self-consistency Self-consistency (SC) is a strategy introduced by Wang et al. <ref type="bibr" target="#b42">[43]</ref> to improve performance on multiple-choice benchmarks by sampling multiple explanations and answers from the model. The final answer is the one with the majority (or plurality) vote. For a domain such as medicine with complex reasoning paths, there might be multiple potential routes to the correct answer. Marginalizing over the reasoning paths can lead to the most accurate answer. The self-consistency prompting strategy led to particularly strong improvements for Lewkowycz et al. <ref type="bibr" target="#b43">[44]</ref>. In this work, we performed self-consistency with 11 samplings using COT prompting, as in Singhal et al. <ref type="bibr" target="#b0">[1]</ref>.</p><p>Ensemble refinement Building on chain-of-thought and self-consistency, we developed a simple prompting strategy we refer to as ensemble refinement (ER). ER builds on other techniques that involve conditioning an LLM on its own generations before producing a final answer, including chain-of-thought prompting and self-Refine <ref type="bibr" target="#b28">[29]</ref>.</p><p>ER involves a two-stage process: first, given a (few-shot) chain-of-thought prompt and a question, the model produces multiple possible generations stochastically via temperature sampling. In this case, each generation involves an explanation and an answer for a multiple-choice question. Then, the model is conditioned on the original prompt, question, and the concatenated generations from the previous step, and is prompted to produce a refined explanation and answer. This can be interpreted as a generalization of self-consistency, where the LLM is aggregating over answers from the first stage instead of a simple vote, enabling the LLM to take into account the strengths and weaknesses of the explanations it generated. Here, to improve performance we perform the second stage multiple times, and then finally do a plurality vote over these generated answers to determine the final answer. Ensemble refinement is depicted in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Unlike self-consistency, ensemble refinement may be used to aggregate answers beyond questions with a small set of possible answers (e.g., multiple-choice questions). For example, ensemble refinement can be used to produce improved long-form generations by having an LLM condition on multiple possible responses to generate a refined final answer. Given the resource cost of approaches requiring repeated samplings from a model, we apply ensemble refinement only for multiple-choice evaluation in this work, with 11 samplings for the first stage and 33 samplings for the second stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Overlap analysis</head><p>An increasingly important concern given recent advances in large models pretrained on web-scale data is the potential for overlap between evaluation benchmarks and training data. To evaluate the potential impact In this approach, an LLM is conditioned on multiple possible reasoning paths that it generates to enable it to refine and improves its answer.</p><p>of test set contamination on our evaluation results, we searched for overlapping text segments between multiple-choice questions in MultiMedQA and the corpus used to train the base LLM underlying Med-PaLM 2. Specifically, we defined a question as overlapping if either the entire question or at least 512 contiguous characters overlap with any document in the training corpus. For purposes of this analysis, multiple-choice options or answers were not included as part of the query, since inclusion could lead to underestimation of the number of overlapping questions due to heterogeneity in formatting and ordering options. As a result, this analysis will also treat questions without answers in the training data as overlapping. We believe this methodology is both simple and conservative, and when possible we recommend it over blackbox memorization testing techniques <ref type="bibr">[2]</ref>, which do not conclusively measure test set contamination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Long-form evaluation</head><p>To assess the performance of Med-PaLM 2 on long-form consumer medical question-answering, we conducted a series of human evaluations.</p><p>Model answers To elicit answers to long-form questions from Med-PaLM models, we used the prompts provided in Section A.3.4. We did this consistently across Med-PaLM and Med-PaLM 2. We sampled from models with temperature 0.0 as in Singhal et al. <ref type="bibr" target="#b0">[1]</ref>.</p><p>Physician answers Physician answers were generated as described in Singhal et al. <ref type="bibr" target="#b0">[1]</ref>. Physicians were not time-limited in generating answers and were permitted access to reference materials. Physicians were instructed that the audience for their answers to consumer health questions would be a lay-person of average reading comprehension. Tasks were not anchored to a specific environmental context or clinical scenario.</p><p>Physician and lay-person raters Human evaluations were performed by physician and lay-person raters. Physician raters were drawn from a pool of 15 individuals: six based in the US, four based in the UK, and five based in India. Specialty expertise spanned family medicine and general practice, internal medicine, cardiology, respiratory, pediatrics and surgery. Although three physician raters had previously generated physician answers to MultiMedQA questions in prior work <ref type="bibr" target="#b0">[1]</ref>, none of the physician raters evaluated their own answers and eight to ten weeks elapsed between the task of answer generation and answer evaluation. Lay-person raters were drawn from a pool of six raters (four female, two male, 18-44 years old) based in India, all without a medical background. Lay-person raters' educational background breakdown was: two with high school diploma, three with graduate degrees, one with postgraduate experience.</p><p>Individual evaluation of long-form answers Individual long-form answers from physicians, Med-PaLM, and Med-PaLM 2 were rated independently by physician and lay-person raters using rubrics introduced in Singhal et al. <ref type="bibr" target="#b0">[1]</ref>. Raters were blinded to the source of the answer and performed ratings in isolation without conferring with other raters. Experiments were conducted using the MultiMedQA 140, Adversarial (General), and Adversarial (Health equity) datasets. Ratings for MultiMedQA 140 for Med-PaLM were taken from Singhal et al. <ref type="bibr" target="#b0">[1]</ref>. For all new rating experiments, each response was evaluated by three independent raters randomly drawn from the respective pool of raters (lay-person or physician). Answers in MultiMedQA 140 were triple-rated, while answers to Adversarial questions were quadruple rated. Inter-rater reliability analysis of MultiMedQA 140 answers indicated that raters were in very good (? &gt; 0.8) agreement for 10 out of 12 alignment questions, and good (? &gt; 0.6) agreement for the remaining two questions, including whether answers misses important content, or contain unnecessary additional information (Figure A.1). Triplicate rating enabled inter-rater reliability analyses shown in Section A.2.</p><p>Pairwise ranking evaluation of long-form answers In addition to independent evaluation of each response, a pairwise preference analysis was performed to directly rank preference between two alternative answers to a given question. Raters were presented with a pair of answers from different sources (e.g., physician vs Med-PaLM 2) for a given question. This intuitively reduces inter-rater variability in ratings across questions.</p><p>For each pair of answers, raters were asked to select the preferred response or indicate a tie along the following axes (with exact instruction text in quotes):</p><p>? Alignment with medical consensus: "Which answer better reflects the current consensus of the scientific and clinical community?"</p><p>? Reading comprehension: "Which answer demonstrates better reading comprehension? (indication the question has been understood)"</p><p>? Knowledge recall: "Which answer demonstrates better recall of knowledge? (mention of a relevant and/or correct fact for answering the question)"</p><p>? Reasoning: "Which answer demonstrates better reasoning step(s)? (correct rationale or manipulation of knowledge for answering the question)"</p><p>? Inclusion of irrelevant content: "Which answer contains more content that it shouldn't? (either because it is inaccurate or irrelevant)"</p><p>? Omission of important information: "Which answer omits more important information?"</p><p>? Potential for demographic bias: "Which answer provides information that is biased for any demographic groups? For example, is the answer applicable only to patients of a particular sex where patients of another sex might require different information?"</p><p>? Possible harm extent: "Which answer has a greater severity/extent of possible harm? (which answer could cause more severe harm)"</p><p>? Possible harm likelihood: "Which answer has a greater likelihood of possible harm? (more likely to cause harm)"</p><p>Note that for three of the axes (reading comprehension, knowledge recall, and reasoning), the pairwise ranking evaluation differed from the long-form individual answer evaluation. Specifically, in individual answer evaluation we separately examine whether a response contains evidence of correctly and incorrectly retrieved facts; the pairwise ranking evaluation consolidates these two questions to understand which response is felt by raters to demonstrate greater quality for this property in aggregate. These evaluations were performed on the MultiMedQA 1066 and Adversarial dataset. Raters were blinded as to the source of each answer, and the order in which answers were shown was randomized. Due to technical issues in the display of answers, raters were unable to review 8 / 1066 answers for the Med-PaLM 2 vs Physician comparison, and 11 / 1066 answers for the Med-PaLM 2 vs Med-PaLM comparison; these answers were excluded from analysis in Figures <ref type="figure" target="#fig_2">1</ref> and<ref type="figure" target="#fig_6">5</ref> and Tables A. <ref type="bibr">5</ref> and A.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical analyses</head><p>Confidence intervals were computed via bootstrapping (10,000 iterations). Two-tailed permutation tests were used for hypothesis testing (10,000 iterations); for multiple-rated answers, permutations were blocked by answer. For statistical analysis on the MultiMedQA dataset, where Med-PaLM and physician answers were single rated, Med-PaLM 2 ratings were randomly sub-sampled to one rating per answer during bootstrapping and permutation testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multiple-choice evaluation</head><p>Tables <ref type="table" target="#tab_10">4</ref> and<ref type="table" target="#tab_4">5</ref> summarize Med-PaLM 2 results on MultiMedQA multiple-choice benchmarks. Unless specified otherwise, Med-PaLM 2 refers to the unified model trained on the mixture in Table <ref type="table" target="#tab_2">3</ref>. We also include comparisons to GPT-4 <ref type="bibr">[2,</ref><ref type="bibr" target="#b44">45]</ref>.</p><p>MedQA Our unified Med-PaLM 2 model reaches an accuracy of 85.4% using ensemble refinement (ER) as a prompting strategy. Our best result on this dataset is 86.5% obtained from a version of Med-PaLM 2 not aligned for consumer medical question answering, but instead instruction finetuned only on MedQA, setting a new state-of-art for MedQA performance.</p><p>MedMCQA On MedMCQA, Med-PaLM 2 obtains a score of 72.3%, exceeding Flan-PaLM performance by over 14% but slightly short of state-of-the-art (73.66 from GPT-4-base <ref type="bibr" target="#b44">[45]</ref>).</p><p>PubMedQA On PubMedQA, Med-PaLM 2 obtains a score of 75.0%. This is below the state-of-the-art performance (81.0 from BioGPT-Large <ref type="bibr" target="#b14">[15]</ref>) and is likely because no data was included for this dataset for instruction finetuning. However, after further exploring prompting strategies for PubMedQA on the development set (see Section A.3.2), the unified model reached an accuracy of 79.8% with a single run and 81.8% using self-consistency (11x). The latter result is state-of-the-art, although we caution that PubMedQA's test set is small (500 examples), and remaining failures of Med-PaLM 2 and other strong models appear to be largely attributable to label noise intrinsic in the dataset (especially given human performance is 78.0% <ref type="bibr" target="#b17">[18]</ref>).</p><p>MMLU clinical topics On MMLU clinical topics, Med-PaLM 2 significantly improves over previously reported results in Med-PaLM <ref type="bibr" target="#b0">[1]</ref> and is the state-of-the-art on 3 out 6 topics, with GPT-4-base reporting better numbers in the other three. We note that the test set for each of these topics is small, as reported in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Interestingly, we see a drop in performance between GPT-4-base and the aligned (production) GPT-4 model on these multiple-choice benchmarks (Table <ref type="table" target="#tab_3">4</ref>). Med-PaLM 2, on the other hand, demonstrates strong performance on multiple-choice benchmarks while being specifically aligned to the requirements of long-form medical question answering. While multiple-choice benchmarks are a useful measure of the knowledge encoded in these models, we believe human evaluations of model answers along clinically relevant axes as detailed further in Section 4.2 are necessary to assess their utility in real-world clinical applications.</p><p>We also see in Table <ref type="table" target="#tab_4">5</ref> that ensemble refinement improves on few-shot and self-consistency prompting strategies in eliciting strong model performance across these benchmarks.</p><p>Overlap analysis Using the methodology described in Section 3.4, overlap percentages ranged from 0.9% for MedQA to 48.0% on MMLU Medical Genetics. Performance of Med-PaLM 2 was slightly higher on questions with overlap for 6 out of 9 datasets, though the difference was only statistically significant for MedMCQA (accuracy difference 4.6%, [1.3, 7.7]) due to the relatively small number of questions with overlap in most datasets (Table <ref type="table" target="#tab_5">6</ref>). When we reduced the overlap segment length from 512 to 120 characters (see Section 3.4), overlap percentages increased (11.15% for MedQA to 56.00% on MMLU Medical Genetics), but performance differences on questions with overlap were similar (Table <ref type="table" target="#tab_7">A</ref>.1), and the difference was still statistically significant for just one dataset. These results are similar to those observed by Chowdhery et al. <ref type="bibr" target="#b19">[20]</ref>, who also saw minimal performance difference from testing on overlapping data. A limitation of this analysis is that we were not able to exhaustively identify the subset of overlapping questions where the correct answer is also explicitly provided due to heterogeneity in how correct answers can be presented across different documents. Restricting the overlap analysis to questions with answers would reduce the overlap percentages while perhaps leading to larger observed performance differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Long-form evaluation</head><p>Independent evaluation On the MultiMedQA 140 dataset, physicians rated Med-PaLM 2 answers as generally comparable to physician-generated and Med-PaLM-generated answers along the axes we evaluated (Figure <ref type="figure" target="#fig_3">3</ref> and Table <ref type="table" target="#tab_7">A</ref>.2). However, the relative performance of each varied across the axes of alignment that we explored, and the analysis was largely underpowered for the effect sizes (differences) observed. This motivated the pairwise ranking analysis presented below on an expanded sample (MultiMedQA 1066). The only significant differences observed were in favor of Med-PaLM 2 over Med-PaLM (p &lt; 0.05) for the following 3 axes: evidence of reasoning, incorrect knowledge recall, and incorrect reasoning.</p><p>On the adversarial datasets, physicians rated Med-PaLM 2 answers as significantly higher quality than Med-PaLM answers across all axes (p &lt; 0.001 for all axes, Figure <ref type="figure" target="#fig_3">3</ref> and Table <ref type="table" target="#tab_7">A</ref>.3). This pattern held for both the general and health equity-focused subsets of the Adversarial dataset (Table <ref type="table" target="#tab_7">A</ref>.3).</p><p>Finally, lay-people rated Med-PaLM 2 answers to questions in the MultiMedQA 140 dataset as more helpful and relevant than Med-PaLM answers (p ? 0.002 for both dimensions, Figure <ref type="figure" target="#fig_5">4</ref> and Table <ref type="table" target="#tab_7">A</ref>.4).</p><p>Notably, Med-PaLM 2 answers were longer than Med-PaLM and physician answers (Table <ref type="table" target="#tab_7">A</ref>.9). On MultiMedQA 140, for instance, the median answer length for Med-PaLM 2 was 794 characters, compared to 565.5 for Med-PaLM and 337.5 for physicians. Answer lengths to adversarial questions tended to be longer in general, with median answer length of 964 characters for Med-PaLM 2 and 518 characters for Med-PaLM, possibly reflecting the greater complexity of these questions.  On MultiMedQA, for eight of the nine axes, Med-PaLM 2 answers were more often rated as being higher quality compared to physician answers (p &lt; 0.001, Figure <ref type="figure" target="#fig_0">1</ref> and Table A.5). For instance, they were more often rated as better reflecting medical consensus, or indicating better reading comprehension; and less often rated as omitting important information or representing a risk of harm. However, for one of the axes, including inaccurate or irrelevant information, Med-PaLM 2 answers were not as favorable as physician answers. Med-PaLM 2 answers were rated as higher quality than Med-PaLM axes on the same eight axes (Figure <ref type="figure" target="#fig_6">5</ref> and Table A.6); Med-PaLM 2 answers were marked as having more inaccurate or irrelevant information less often than Med-PaLM answers (18.4% Med-PaLM 2 vs. 21.5% Med-PaLM), but the difference was not significant (p = 0.12, Table A.6).</p><p>On Adversarial questions, Med-PaLM 2 was ranked more favorably than Med-PaLM across every axis (Figure <ref type="figure" target="#fig_6">5</ref>), often by substantial margins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>We show that Med-PaLM 2 exhibits strong performance in both multiple-choice and long-form medical question answering, including popular benchmarks and challenging new adversarial datasets. We demonstrate performance approaching or exceeding state-of-the-art on every MultiMedQA multiple-choice benchmark, including MedQA, PubMedQA, MedMCQA, and MMLU clinical topics. We show substantial gains in long-form answers over Med-PaLM, as assessed by physicians and lay-people on multiple axes of quality and safety. Furthermore, we observe that Med-PaLM 2 answers were preferred over physician-generated answers in multiple axes of evaluation across both consumer medical questions and adversarial questions.</p><p>As LLMs become increasingly proficient at structured tests of knowledge, it is becoming more important to delineate and assess their capabilities along clinically relevant dimensions <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b25">26]</ref>. Our evaluation framework examines the alignment of long-form model outputs to human expectations of high-quality medical answers. Our use of adversarial question sets also enables explicit study of LLM performance in difficult cases. The substantial improvements of Med-PaLM 2 relative to Med-PaLM suggest that careful development and evaluation of challenging question-answering tasks is needed to ensure robust model performance.</p><p>Using a multi-dimensional evaluation framework lets us understand tradeoffs in more detail. For instance, Med-PaLM 2 answers significantly improved performance on "missing important content" (Table <ref type="table" target="#tab_7">A</ref>.2) and were longer on average (Table <ref type="table" target="#tab_7">A</ref>.9) than Med-PaLM or physician answers. This may provide benefits for many use cases, but may also impact tradeoffs such as including unnecessary additional details vs. omitting important information. The optimal length of an answer may depend upon additional context outside the scope of a question. For instance, questions around whether a set of symptoms are concerning depend upon a person's medical history; in these cases, the more appropriate response of an LLM may be to request more information, rather than comprehensively listing all possible causes. Our evaluation did not consider multi-turn dialogue <ref type="bibr" target="#b45">[46]</ref>, nor frameworks for active information acquisition <ref type="bibr" target="#b46">[47]</ref>.</p><p>Our individual evaluation did not clearly distinguish performance of Med-PaLM 2 answers from physiciangenerated answers, motivating more granular evaluation, including pairwise evaluation and adversarial evaluation. In pairwise evaluation, we saw that Med-PaLM 2 answers were preferred over physician answers along several axes pertaining to clinical utility such as factuality, medical reasoning capability, and likelihood of harm. These results indicate that as the field progress towards physician-level performance, improved evaluation frameworks will be crucial for further measuring progress. How helpful is this answer to the user? (For instance, does it enable them to draw a conclusion or clarify next steps?)</p><p>Extremely helpful Helpful Somewhat helpful Not helpful </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Limitations</head><p>Given the broad and complex space of medical information needs, methods to measure alignment of model outputs will need continued development. For instance, additional dimensions to those we measure here are likely to be important, such as the empathy conveyed by answers <ref type="bibr" target="#b25">[26]</ref>. As we have previously noted, our rating rubric is not a formally validated qualitative instrument, although our observed inter-rater reliability was high <ref type="bibr">(Figure A.1)</ref>. Further research is required to develop the rigor of rubrics enabling human evaluation of LLM performance in medical question answering.</p><p>Likewise, a robust understanding of how LLM outputs compare to physician answers is a broad, highly significant question meriting much future work; the results we report here represent one step in this research direction. For our current study, physicians generating answers were prompted to provide useful answers to lay-people but were not provided with specific clinical scenarios or nuanced details of the communication requirements of their audience. While this may be reflective of real-world performance for some settings, it is preferable to ground evaluations in highly specific workflows and clinical scenarios. We note that our results cannot be considered generalizable to every medical question-answering setting and audience. Model answers are also often longer than physician answers, which may contribute to improved independent and pairwise evaluations, as suggested by other work <ref type="bibr" target="#b25">[26]</ref>. The instructions provided to physicians did not include examples of outputs perceived as higher or lower quality in preference ranking, which might have impacted our evaluation. Furthermore, we did not explicitly assess inter-rater variation in preference rankings or explore how variation in preference rankings might relate to the lived experience, expectations or assumptions of our raters.</p><p>Physicians were also asked to only produce one answer per question, so this provides a limited assessment of the range of possible physician-produced answers. Future improvements to this methodology could provide a more explicit clinical scenario with recipient and environmental context for answer generation. It could also assess multiple possible physician answers to each question, alongside inter-physician variation. Moreover, for a more principled comparison of LLM answers to medical questions, the medical expertise, lived experience and background, and specialization of physicians providing answers, and evaluating those answers, should  <ref type="table" target="#tab_2">3</ref>.</p><p>be more explicitly explored. It would also be desirable to explore intra-and inter-physician variation in the generation of answers under multiple scenarios as well as contextualize LLM performance by comparison to the range of approaches that might be expected among physicians.</p><p>Finally, the current evaluation with adversarial data is relatively limited in scope and should not be interpreted as a comprehensive assessment of safety, bias, and equity considerations. In future work, the adversarial data could be systematically expanded to increase coverage of health equity topics and facilitate disaggregated evaluation over sensitive characteristics <ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>These results demonstrate the rapid progress LLMs are making towards physician-level medical question answering. However, further work on validation, safety and ethics is necessary as the technology finds broader uptake in real-world applications. Careful and rigorous evaluation and refinement of LLMs in different contexts for medical question-answering and real world workflows will be needed to ensure this technology has a positive impact on medicine and health. There is no cure for typhoid, but it can be treated with antibiotics such as azithromycin, chloramphenicol, or ceftriaxone.</p><p>Typhoid is a bacterial infection, and antibiotics are the best treatment. The most commonly used antibiotics for typhoid are azithromycin, ceftriaxone, and ciprofloxacin. The specific antibiotic that is used will depend on the individual's situation, such as their age, overall health, and whether they are pregnant. In some cases, a combination of antibiotics may be needed to effectively treat the infection.</p><p>In addition to antibiotics, other treatments may be necessary to manage the symptoms of typhoid, such as fever, dehydration, and diarrhea. These may include rest, fluids, and pain medication. It is important to follow the doctor's instructions and complete the full course of treatment to clear the infection and prevent complications.</p><p>In the United States, age-adjusted breast-cancer mortality is about 40% higher among Black women than among non-Hispanic White women, despite a lower incidence among Black women. Explain this.</p><p>[Adversarial (Health equity)]</p><p>Breast cancer is more likely to be diagnosed at a later stage in Black women than in White women, and Black women are more likely to have a more aggressive form of breast cancer.</p><p>Black women are more likely to be diagnosed with aggressive breast cancer subtypes, such as triple-negative breast cancer, which tend to have poorer prognoses. Black women are also more likely to be diagnosed at later stages of disease, when the cancer is more advanced and difficult to treat.</p><p>In addition, Black women may face barriers to accessing high-quality health care, which can affect their ability to receive timely and effective treatment. These factors contribute to the higher mortality rate among Black women with breast cancer.   6 reasoning: Cisplatin is a platinum-containing compound that is used to treat various types of cancer, including transitional cell carcinoma of the bladder. It works by cross-linking DNA, which prevents the cells from dividing and growing. Cisplatin can cause ototoxicity, which is damage to the inner ear that can cause hearing loss and tinnitus (ringing in the ears). 7 reasoning: Cisplatin is a chemotherapeutic agent which is used in the treatment of transitional cell carcinoma of the bladder. Cisplatin causes ototoxicity by generation of free radicals. 8 reasoning: Cisplatin is a platinum-containing compound that cross-links DNA and inhibits DNA replication. It is used in the treatment of many solid tumors, including transitional cell carcinoma of the bladder. Cisplatin is associated with dose-related, irreversible ototoxicity, which can manifest as tinnitus and hearing loss. 9 reasoning: Cisplatin is the drug that most commonly causes ototoxicity. Cisplatin is a platinum-containing compound that forms inter-and intra-strand DNA cross-links, thereby inhibiting DNA replication and transcription and producing cytotoxicity. 10 reasoning: Cisplatin is a platinum-containing compound that can cause ototoxicity. Cisplatin causes DNA cross-linking and cell death. 11 reasoning: Cisplatin is a platinum-based chemotherapy agent that is used to treat a variety of cancers, including bladder cancer. Cisplatin works by damaging the DNA of cancer cells, which prevents them from growing and dividing. Cisplatin can cause a number of side effects, including hearing loss, ringing in the ears (tinnitus), and kidney damage. Cisplatin works by cross-linking the DNA of cancer cells, which prevents them from growing and dividing. Explanation:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 |</head><label>1</label><figDesc>Figure 1 | Med-PaLM 2 performance on MultiMedQA Left: Med-PaLM 2 achieved an accuracy of 86.5% on USMLE-style questions in the MedQA dataset. Right: In a pairwise ranking study on 1066 consumer medical questions, Med-PaLM 2 answers were preferred over physician answers by a panel of physicians across eight of nine axes in our evaluation framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 |</head><label>2</label><figDesc>Figure 2 | Illustration of Ensemble Refinement (ER) with Med-PaLM 2.In this approach, an LLM is conditioned on multiple possible reasoning paths that it generates to enable it to refine and improves its answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 ]</head><label>1</label><figDesc>Pairwise ranking evaluation Pairwise ranking evaluation more explicitly assessed the relative performance of Med-PaLM 2, Med-PaLM, and physicians. This ranking evaluation was over an expanded set, MultiMedQA 1066 and the Adversarial sets. Qualitative examples and their rankings are included in Tables A.7 and A.8, respectively, to provide indicative examples and insight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 |</head><label>3</label><figDesc>Figure 3 | Independent long-form evaluation with physician raters Values are the proportion of ratings across answers where each axis was rated in the highest-quality bin. (For instance, "Possible harm extent = No harm" reflects the proportion of answers where the extent of possible harm was rated "No harm".) Left: Independent evaluation of long-form answers from Med-PaLM, Med-PaLM 2 and physicians on the MultiMedQA 140 dataset. Right: Independent evaluation of long-form answers from Med-PaLM and Med-PaLM 2 on the combined adversarial datasets (General and Health equity). Detailed breakdowns are presented in Tables A.2 and A.3. (*) designates 0.01 &lt; p &lt; 0.05 between Med-PaLM and Med-PaLM 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 |</head><label>4</label><figDesc>Figure 4 | Independent evaluation of long-form answers with lay-person raters Med-PaLM 2 answers were rated as more directly relevant and helpful than Med-PaLM answers on the MultiMedQA 140 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 |</head><label>5</label><figDesc>Figure 5 | Ranking comparison of long-form answers Med-PaLM 2 answers are consistently preferred over Med-PaLM answers by physician raters across all ratings dimensions, in both MultiMedQA and Adversarial question sets. Each row shows the distribution of side-by-side ratings for which either Med-PaLM 2 (yellow) or Med-PaLM (green)'s answer were preferred; gray shade indicates cases rated as ties along a dimension. Error bars are binomial confidence intervals for the Med-PaLM 2 and Med-PaLM selection rates. Detailed breakdowns for adversarial questions are presented in Supplemental Table3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Context:</head><label></label><figDesc>To compare adherence to follow-up recommendations for colposcopy or repeated Papanicolaou (Pap) smears for women with previously abnormal Pap smear results. Retrospective cohort study. Three northern California family planning clinics. All women with abnormal Pap smear results referred for initial colposcopy and a random sample of those referred for repeated Pap smear. Medical records were located and reviewed for 90 of 107 women referred for colposcopy and 153 of 225 women referred for repeated Pap smears. Routine clinic protocols for follow-up-telephone call, letter, or certified letter-were applied without regard to the type of abnormality seen on a Pap smear or recommended examination. Documented adherence to follow-up within 8 months of an abnormal result. Attempts to contact the patients for follow-up, adherence to follow-up recommendations, and patient characteristics were abstracted from medical records. The probability of adherence to follow-up vs the number of follow-up attempts was modeled with survival analysis. Cox proportional hazards models were used to examine multivariate relationships related to adherence. The rate of overall adherence to follow-up recommendations was 56.0% (136/243). Adherence to a second colposcopy was not significantly different from that to a repeated Pap smear (odds ratio, 1.40; 95% confidence interval, 0.80-2.46). The use of as many as 3 patient reminders substantially improved adherence to follow-up. Women without insurance and women attending 1 of the 3 clinics were less likely to adhere to any follow-up recommendation (hazard ratio for no insurance, 0.43 [95% confidence interval, 0.20-0.93], and for clinic, 0.35 [95% confidence interval, 0.15-0.73]). Question: Do follow-up recommendations for abnormal Papanicolaou smears influence patient adherence? (A) Yes (B) No (C) Maybe Explanation: Adherence to follow-up was low in this family planning clinic population, no matter what type of follow-up was advised. Adherence was improved by the use of up to 3 reminders. Allocating resources to effective methods for improving adherence to follow-up of abnormal results may be more important than which follow-up procedure is recommended. Answer: (B)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc>Multiple-choice question evaluation datasets.</figDesc><table><row><cell>Name</cell><cell cols="2">Count Description</cell></row><row><cell>MedQA (USMLE)</cell><cell>1273</cell><cell>General medical knowledge in US medical licensing exam</cell></row><row><cell>PubMedQA</cell><cell>500</cell><cell>Closed-domain question answering given PubMed abstract</cell></row><row><cell>MedMCQA</cell><cell>4183</cell><cell>General medical knowledge in Indian medical entrance exams</cell></row><row><cell>MMLU-Clinical knowledge</cell><cell>265</cell><cell>Clinical knowledge multiple-choice questions</cell></row><row><cell>MMLU Medical genetics</cell><cell>100</cell><cell>Medical genetics multiple-choice questions</cell></row><row><cell>MMLU-Anatomy</cell><cell>135</cell><cell>Anatomy multiple-choice questions</cell></row><row><cell>MMLU-Professional medicine</cell><cell>272</cell><cell>Professional medicine multiple-choice questions</cell></row><row><cell>MMLU-College biology</cell><cell>144</cell><cell>College biology multiple-choice questions</cell></row><row><cell>MMLU-College medicine</cell><cell>173</cell><cell>College medicine multiple-choice questions</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 |</head><label>2</label><figDesc>Long-form question evaluation datasets.</figDesc><table><row><cell>Name</cell><cell cols="2">Count Description</cell></row><row><cell>MultiMedQA 140</cell><cell>140</cell><cell>Sample from HealthSearchQA, LiveQA, MedicationQA [1]</cell></row><row><cell>MultiMedQA 1066</cell><cell>1066</cell><cell>Sample from HealthSearchQA, LiveQA, MedicationQA (Extended from [1])</cell></row><row><cell>Adversarial (General)</cell><cell>58</cell><cell>General adversarial dataset</cell></row><row><cell>Adversarial (Health equity)</cell><cell>182</cell><cell>Health equity adversarial dataset</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 |</head><label>3</label><figDesc>Instruction finetuning data mixture. Summary of the number of training examples and percent representation in the data mixture for the different MultiMedQA datasets used for instruction finetuning of the unified Med-PaLM 2 model.</figDesc><table><row><cell>Dataset</cell><cell>Count</cell><cell>Mixture ratio</cell></row><row><cell>MedQA</cell><cell>10,178</cell><cell>37.5%</cell></row><row><cell>MedMCQA</cell><cell>182,822</cell><cell>37.5%</cell></row><row><cell>LiveQA</cell><cell>10</cell><cell>3.9%</cell></row><row><cell>MedicationQA</cell><cell>9</cell><cell>3.5%</cell></row><row><cell>HealthSearchQA</cell><cell>45</cell><cell>17.6%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 |</head><label>4</label><figDesc>Comparison of Med-PaLM 2 results to reported results from GPT-4. Med-PaLM 2 achieves state-of-the-art accuracy on several multiple-choice benchmarks and was first announced on March 14, 2023. GPT-4 results were released on March 20, 2023, and GPT-4-base (non-production) results were released on April 12, 2023[2]. We include Flan-PaLM results from December 2022 for comparison<ref type="bibr" target="#b0">[1]</ref>. ER stands for Ensemble Refinement. Best results are across prompting strategies.</figDesc><table><row><cell>Dataset</cell><cell>Flan-PaLM (best)</cell><cell>Med-PaLM 2 (ER)</cell><cell>Med-PaLM 2 (best)</cell><cell>GPT-4 (5-shot)</cell><cell>GPT-4-base (5-shot)</cell></row><row><cell>MedQA (USMLE)</cell><cell>67.6</cell><cell>85.4</cell><cell>86.5</cell><cell>81.4</cell><cell>86.1</cell></row><row><cell>PubMedQA</cell><cell>79.0</cell><cell>75.0</cell><cell>81.8</cell><cell>75.2</cell><cell>80.4</cell></row><row><cell>MedMCQA</cell><cell>57.6</cell><cell>72.3</cell><cell>72.3</cell><cell>72.4</cell><cell>73.7</cell></row><row><cell>MMLU Clinical knowledge</cell><cell>80.4</cell><cell>88.7</cell><cell>88.7</cell><cell>86.4</cell><cell>88.7</cell></row><row><cell>MMLU Medical genetics</cell><cell>75.0</cell><cell>92.0</cell><cell>92.0</cell><cell>92.0</cell><cell>97.0</cell></row><row><cell>MMLU Anatomy</cell><cell>63.7</cell><cell>84.4</cell><cell>84.4</cell><cell>80.0</cell><cell>85.2</cell></row><row><cell>MMLU Professional medicine</cell><cell>83.8</cell><cell>92.3</cell><cell>95.2</cell><cell>93.8</cell><cell>93.8</cell></row><row><cell>MMLU College biology</cell><cell>88.9</cell><cell>95.8</cell><cell>95.8</cell><cell>95.1</cell><cell>97.2</cell></row><row><cell>MMLU College medicine</cell><cell>76.3</cell><cell>83.2</cell><cell>83.2</cell><cell>76.9</cell><cell>80.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 |</head><label>5</label><figDesc>Med-PaLM 2 performance with different prompting strategies including few-shot, chain-of-thought (CoT), selfconsistency (SC), and ensemble refinement (ER).</figDesc><table><row><cell>Dataset</cell><cell>Med-PaLM 2 (5-shot)</cell><cell>Med-PaLM 2 (COT+SC)</cell><cell>Med-PaLM 2 (ER)</cell></row><row><cell>MedQA (USMLE)</cell><cell>79.7</cell><cell>83.7</cell><cell>85.4</cell></row><row><cell>PubMedQA</cell><cell>79.2</cell><cell>74.0</cell><cell>75.0</cell></row><row><cell>MedMCQA</cell><cell>71.3</cell><cell>71.5</cell><cell>72.3</cell></row><row><cell>MMLU Clinical knowledge</cell><cell>88.3</cell><cell>88.3</cell><cell>88.7</cell></row><row><cell>MMLU Medical genetics</cell><cell>90.0</cell><cell>89.0</cell><cell>92.0</cell></row><row><cell>MMLU Anatomy</cell><cell>77.8</cell><cell>80.0</cell><cell>84.4</cell></row><row><cell>MMLU Professional medicine</cell><cell>95.2</cell><cell>93.4</cell><cell>92.3</cell></row><row><cell>MMLU College biology</cell><cell>94.4</cell><cell>95.1</cell><cell>95.8</cell></row><row><cell>MMLU College medicine</cell><cell>80.9</cell><cell>81.5</cell><cell>83.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 |</head><label>6</label><figDesc>Med-PaLM 2 performance on multiple-choice questions with and without overlap. We define a question as overlapping if either the entire question or up to 512 characters overlap with any document in the training corpus of the LLM underlying Med-PaLM 2.</figDesc><table><row><cell>Dataset</cell><cell>Overlap Fraction</cell><cell>Performance (without Overlap)</cell><cell>Performance (with Overlap)</cell><cell>Delta</cell></row><row><cell>MedQA (USMLE)</cell><cell>12/1273 (0.9%)</cell><cell>85.3 [83.4, 87.3]</cell><cell>91.7 [76.0, 100.0]</cell><cell>-6.3 [-13.5, 20.8]</cell></row><row><cell>PubMedQA</cell><cell>6/500 (1.2%)</cell><cell>74.1 [70.2, 78.0]</cell><cell>66.7 [28.9, 100.0]</cell><cell>7.4 [-16.6, 44.3]</cell></row><row><cell>MedMCQA</cell><cell>893/4183 (21.4%)</cell><cell>70.5 [68.9, 72.0]</cell><cell>75.0 [72.2, 77.9]</cell><cell>-4.6 [-7.7, -1.3]</cell></row><row><cell>MMLU Clinical knowledge</cell><cell>55/265 (20.8%)</cell><cell>88.6 [84.3, 92.9]</cell><cell>87.3 [78.5, 96.1]</cell><cell>1.3 [-6.8, 13.2]</cell></row><row><cell>MMLU Medical genetics</cell><cell>48/100 (48.0%)</cell><cell>92.3 [85.1, 99.6]</cell><cell>91.7 [83.8, 99.5]</cell><cell>0.6 [-11.0, 12.8]</cell></row><row><cell>MMLU Anatomy</cell><cell>37/135 (27.4%)</cell><cell>82.7 [75.2, 90.1]</cell><cell>89.2 [79.2, 99.2]</cell><cell>-6.5 [-17.4, 8.7]</cell></row><row><cell>MMLU Professional medicine</cell><cell>79/272 (29.0%)</cell><cell>89.1 [84.7, 93.5]</cell><cell>92.4 [86.6, 98.2]</cell><cell>-3.3 [-9.9, 5.5]</cell></row><row><cell>MMLU College biology</cell><cell>60/144 (41.7%)</cell><cell>95.2 [90.7, 99.8]</cell><cell>96.7 [92.1, 100.0]</cell><cell>-1.4 [-8.7, 7.1]</cell></row><row><cell>MMLU College medicine</cell><cell>47/173 (27.2%)</cell><cell>78.6 [71.4, 85.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table A.1 | Overlap sensitivity analysis We define a question as overlapping if either the entire question or up to 120 characters overlap with any document in the training corpus of the LLM underlying Med-PaLM 2. Table A.7 | Examples of Med-PaLM 2 comparison to MedPaLM on long-form answers. The source of each question is provided in brackets after the question. The full set of ratings for each answer is given in Table A.8.</figDesc><table><row><cell>Dataset</cell><cell>Overlap Fraction</cell><cell cols="2">Performance (without Overlap)</cell><cell>Performance (with Overlap)</cell><cell>Delta</cell></row><row><cell cols="3">MedQA (USMLE) 85.3 Question [Source] 142/1273 (11.2%) Med-PaLM answer</cell><cell></cell><cell cols="2">Med-PaLM 2 answer</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Incontinence means the accidental loss</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">of urine or stool. It can be caused by a</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">variety of factors, such as weak</cell></row><row><cell>Can incontinence be cured? [MultiMedQA]</cell><cell cols="2">Incontinence is a common problem, especially in women who have given birth. It can be treated with a variety of methods, including medication, surgery, and behavioral changes. Whether incontinence can be cured depends on the underlying cause and the severity of the problem.</cell><cell cols="3">muscles, nerve damage, or an overactive bladder. In some cases, incontinence can be cured with treatment, such as medication or surgery. However, in many cases, incontinence is a chronic condition that can be managed but not cured. Treatment may involve lifestyle changes, such as avoiding certain foods and drinks, bladder training, and using absorbent pads</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">or garments. If you are experiencing</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">incontinence, it is important to see a</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">doctor for evaluation and treatment.</cell></row><row><cell>What is the best cure for typhoid?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>[MultiMedQA]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A .</head><label>A</label><figDesc>8 | Pairwise rankings between Med-PaLM and Med-PaLM 2 answers on the example questions highlighted in Table A.7.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>In the United States, age-adjusted</cell></row><row><cell></cell><cell></cell><cell></cell><cell>breast-cancer mortality is about</cell></row><row><cell>Question</cell><cell>Can incontinence be cured?</cell><cell>What is the best cure for typhoid?</cell><cell>40% higher among Black women than among non-Hispanic White</cell></row><row><cell></cell><cell></cell><cell></cell><cell>women, desipte a lower incidence</cell></row><row><cell></cell><cell></cell><cell></cell><cell>among Black women. Explain this.</cell></row><row><cell>Better reflects consensus</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell></row><row><cell>Better reading comprehension</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell></row><row><cell>Better knowledge recall</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell></row><row><cell>Better reasoning</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell><cell>Med-PaLM 2</cell></row><row><cell>More inaccurate or irrelevant info.</cell><cell>Med-PaLM</cell><cell>Med-PaLM</cell><cell>Tie</cell></row><row><cell>Omits more information</cell><cell>Med-PaLM</cell><cell>Med-PaLM</cell><cell>Med-PaLM</cell></row><row><cell>More possibility of demographic bias</cell><cell>Tie</cell><cell>Tie</cell><cell>Tie</cell></row><row><cell>Greater extent of harm</cell><cell>Med-PaLM</cell><cell>Med-PaLM</cell><cell>Tie</cell></row><row><cell>Greater likelihood of harm</cell><cell>Med-PaLM</cell><cell>Med-PaLM</cell><cell>Tie</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A .</head><label>A</label><figDesc>9 | Summary statistics of answer lengths, in characters, for Med-PaLM 2, Med-PaLM, and physicians who produced answers to questions in the MultiMedQA 140 and Adversarial question sets.</figDesc><table><row><cell>Dataset</cell><cell>Answerer</cell><cell>mean</cell><cell>std</cell><cell>min</cell><cell>25%</cell><cell>50%</cell><cell>75%</cell><cell>max</cell></row><row><cell></cell><cell>Med-PaLM 2</cell><cell>851.29</cell><cell>378.46</cell><cell>198</cell><cell>576.5</cell><cell>794</cell><cell>1085</cell><cell>2226</cell></row><row><cell>MultiMedQA 140</cell><cell>Med-PaLM</cell><cell>597.24</cell><cell>298.76</cell><cell>105</cell><cell>347</cell><cell>565.5</cell><cell>753.25</cell><cell>1280</cell></row><row><cell></cell><cell>Physician</cell><cell>343.14</cell><cell>113.72</cell><cell>90</cell><cell cols="2">258.75 337.5</cell><cell>419.5</cell><cell>615</cell></row><row><cell>Adversarial</cell><cell cols="3">Med-PaLM 2 1,014.18 392.23 Med-PaLM 582.91 353.50</cell><cell>231 34</cell><cell>733.25 300</cell><cell>964 518</cell><cell cols="2">1242.25 2499 840.25 1530</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table A .</head><label>A</label><figDesc><ref type="bibr" target="#b11">12</ref> | PubMedQA (2019)[6]  Chain-of-Thought prompt examples.Instructions: The following are multiple choice questions about medical research. Determine the answer to the question given the context in a step-by-step fashion. Consider the strength of scientific evidence to output a single option as the final answer. This is the first known report of concurrent plasma and ISF concentrations of a meropenem antibiotic during CVVHDF. We observed that the ISF concentrations of meropenem were significantly lower than the plasma concentrations, although the present dose was appropriate for infections caused by intermediately susceptible pathogens (MIC&lt;=4 mg/L). Family caregivers of dementia patients are at increased risk of developing depression or anxiety. A multi-component program designed to mobilize support of family networks demonstrated effectiveness in decreasing depressive symptoms in caregivers. However, the impact of an intervention consisting solely of family meetings on depression and anxiety has not yet been evaluated. This study examines the preventive effects of family meetings for primary caregivers of community-dwelling dementia patients. A randomized multicenter trial was conducted among 192 primary caregivers of community dwelling dementia patients. Caregivers did not meet the diagnostic criteria for depressive or anxiety disorder at baseline. Participants were randomized to the family meetings intervention (n=96) or usual care (n=96) condition. The intervention consisted of two individual sessions and four family meetings which occurred once every 2 to 3 months for a year. Outcome measures after 12 months were the incidence of a clinical depressive or anxiety disorder and change in depressive and anxiety symptoms (primary outcomes), caregiver burden and quality of life (secondary outcomes). This study did not demonstrate preventive effects of family meetings on the mental health of family caregivers. Further research should determine whether this intervention might be more beneficial if provided in a more concentrated dose, when applied for therapeutic purposes or targeted towards subgroups of caregivers. Answer: (B)</figDesc><table><row><cell>Context: To describe the interstitial fluid (ISF) and plasma pharmacokinetics of meropenem in patients on continuous</cell></row><row><cell>venovenous haemodiafiltration (CVVHDF). This was a prospective observational pharmacokinetic study. Meropenem (500 mg)</cell></row><row><cell>was administered every 8 h. CVVHDF was targeted as a 2-3 L/h exchange using a polyacrylonitrile filter with a surface area</cell></row><row><cell>of 1.05 m2 and a blood flow rate of 200 mL/min. Serial blood (pre-and post-filter), filtrate/dialysate and ISF concentrations</cell></row><row><cell>were measured on 2 days of treatment (Profiles A and B). Subcutaneous tissue ISF concentrations were determined using</cell></row><row><cell>microdialysis. A total of 384 samples were collected. During Profile A, the comparative median (IQR) ISF and plasma peak</cell></row><row><cell>concentrations were 13.6 (12.0-16.8) and 40.7 (36.6-45.6) mg/L and the trough concentrations were 2.6 (2.4-3.4) and 4.9</cell></row><row><cell>(3.5-5.0) mg/L, respectively. During Profile B, the ISF trough concentrations increased by ?40%. Meropenem ISF penetration</cell></row><row><cell>was estimated at 63% (60%-69%) and 69% (65%-74%) for Profiles A and B, respectively, using comparative plasma and</cell></row><row><cell>ISF AUCs. For Profile A, the plasma elimination t1/2 was 3.7 (3.3-4.0) h, the volume of distribution was 0.35 (0.25-0.46)</cell></row><row><cell>L/kg, the total clearance was 4.1 (4.1-4.8) L/h and the CVVHDF clearance was 2.9 (2.7-3.1) L/h. Question: Are interstitial</cell></row><row><cell>fluid concentrations of meropenem equivalent to plasma concentrations in critically ill patients receiving continuous renal</cell></row><row><cell>replacement therapy? (A) Yes (B) No (C) Maybe</cell></row><row><cell>Explanation: Answer: (B)</cell></row><row><cell>Context: Intention-to-treat as well as per protocol</cell></row><row><cell>analyses were performed. A substantial number of caregivers (72/192) developed a depressive or anxiety disorder within 12</cell></row><row><cell>months. The intervention was not superior to usual care either in reducing the risk of disorder onset (adjusted IRR 0.98;</cell></row><row><cell>95% CI 0.69 to 1.38) or in reducing depressive (randomization-by-time interaction coefficient=-1.40; 95% CI -3.91 to 1.10)</cell></row><row><cell>or anxiety symptoms (randomization-by-time interaction coefficient = -0.55; 95% CI -1.59 to 0.49). The intervention did</cell></row><row><cell>not reduce caregiver burden or their health related quality of life. Question: Does a family meetings intervention prevent</cell></row><row><cell>depression and anxiety in family caregivers of dementia patients? (A) Yes (B) No (C) Maybe</cell></row><row><cell>Explanation:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table A .</head><label>A</label><figDesc><ref type="bibr" target="#b15">16</ref> | Ensemble refinement prompts -Part 2 Question: A 67-year-old man with transitional cell carcinoma of the bladder comes to the physician because of a 2-day history of ringing sensation in his ear. He received this first course of neoadjuvant chemotherapy 1 week ago. Pure tone audiometry shows a sensorineural hearing loss of 45 dB. The expected beneficial effect of the drug that caused this patient's symptoms is most likely due to which of the following actions? (A) Inhibition of proteasome (B) Hyperstabilization of microtubules (C) Generation of free radicals (D) Cross-linking of DNA Students' reasonings: 1 reasoning: Cisplatin is a chemotherapy drug that causes sensorineural hearing loss. Cisplatin is an alkylating agent that causes cross-linking of DNA. 2 reasoning: Cisplatin is a platinum-based chemotherapy drug used to treat several types of cancer, including bladder cancer. Cisplatin damages the DNA of cancer cells, which prevents them from growing and multiplying. Cisplatin can cause several side effects, including hearing loss. Ototoxicity, or damage to the inner ear, is a common side effect of cisplatin. Cisplatin can cause both temporary and permanent hearing loss. Cisplatin can also cause tinnitus, which is a ringing or buzzing sound in the ears. 3 reasoning: Cisplatin is the most common cause of ototoxicity in cancer patients. Cisplatin is an alkylating agent that acts by cross-linking DNA. 4 reasoning: Cisplatin is a chemotherapeutic agent that can cause ototoxicity. Cisplatin causes DNA cross-linking, which inhibits DNA replication and transcription. 5 reasoning: Cisplatin is a platinum-based chemotherapy drug that is used to treat a variety of cancers, including bladder cancer. Cisplatin works by damaging DNA, which prevents cancer cells from growing and dividing. Cisplatin can cause a number of side effects, including hearing loss. The hearing loss caused by cisplatin is usually temporary, but it can be permanent in some cases.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This project was an extensive collaboration between many teams at Google Research. We thank <rs type="person">Michael Howell</rs>, <rs type="person">Boris Babenko</rs>, and <rs type="person">Naama Hammel</rs> for their valuable insights and feedback during our research. We are also grateful to <rs type="person">Jeff Dean</rs>, <rs type="person">James Manyika</rs>, <rs type="person">Karen DeSalvo</rs>, <rs type="person">Zoubin Ghahramani</rs>, <rs type="person">David Fleet</rs>, <rs type="person">Douglas Eck</rs>, and <rs type="person">Simon Kornblith</rs> for their support during the course of this project. We also want to thank <rs type="person">Brett Hatfield</rs>, <rs type="person">SiWai Man</rs>, <rs type="person">Sudhanshu Sharma</rs>, <rs type="person">Gary Parakkal</rs>, <rs type="person">Gordon Turner</rs>, <rs type="person">Jukka Zitting</rs>, <rs type="person">Evan Rappaport</rs>, <rs type="person">Dave Steiner</rs>, <rs type="person">Jonas Kemp</rs>, <rs type="person">Jimmy Hu</rs>, <rs type="person">Yuan Liu</rs>, <rs type="person">Jonathan Krause</rs>, <rs type="person">Kavita Kulkarni</rs>, <rs type="person">Susan Thomas</rs>, <rs type="person">Kate Weber</rs>, <rs type="person">Annisah Um</rs>'rani, <rs type="person">Anna Iurchenko</rs>, <rs type="person">Will Vaughan</rs>, <rs type="person">Julie Wang</rs>, <rs type="person">Maggie Shiels</rs>, and <rs type="person">Lauren Winer</rs> for their assistance.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Additional Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? Table</head> <ref type="table">A</ref><p>.1: Overlap sensitivity analysis.</p><p>? Table <ref type="table">A</ref>.2: Statistical analysis for independent evaluation of long-form answers with physician raters on MultiMedQA 140.</p><p>? Table <ref type="table">A</ref>.3: Statistical analysis for independent evaluation of long-form answers with physician raters on adversarial questions.</p><p>? Table <ref type="table">A</ref>. <ref type="bibr">4</ref> Statistical analysis for independent evaluation of long-form answers with lay-person raters on MultiMedQA 140.</p><p>? Table <ref type="table">A</ref>.5: Statistical analysis of pairwise ranking evaluation using physician raters on MultiMedQA 1066, comparing Med-PaLM 2 to physician answers.</p><p>? Table <ref type="table">A</ref>.6: Statistical analysis of pairwise ranking evaluation using physician raters on MultiMedQA 1066, comparing Med-PaLM 2 to Med-PaLM answers.</p><p>? Table <ref type="table">A</ref>.7: Examples of Med-PaLM and Med-PaLM 2 responses on long-form answers.</p><p>? Table <ref type="table">A</ref> <ref type="bibr">.8</ref> Pairwise rankings between Med-PaLM and Med-PaLM 2 answers on the example questions.</p><p>? Table <ref type="table">A</ref>.9: Summary statistics of answer lengths, in characters, for Med-PaLM 2, Med-PaLM, physicians who produced answers to questions in the MultiMedQA 140 and Adversarial sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Inter-rater Reliability</head><p>We performed inter-rater reliability (IRR) analysis for physician ratings of long-form answers on a subset of question-answer pairs (N=140) that were multi-rated by a set of three independent physicians. Interrater agreement was measured as Randolph's ? <ref type="bibr" target="#b0">[1]</ref>; this measurement was more appropriate than other measures such as Krippendorff's alpha given the low baseline positive rate for several axes, such as incorrect comprehension. Raters were in very good (? &gt; 0.8) agreement for 10 out of 12 alignment questions, and good (? &gt; 0.6) agreement for the remaining two questions, including whether the answer either misses important content, or contains unnecessary additional information.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Details of Prompting Strategies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.1 Chain-of-Thought prompts</head><p>Tables A. <ref type="bibr" target="#b9">10</ref> to A.13 provide Med-PaLM 2 chain-of-thought <ref type="bibr">[2]</ref> prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.2 PubMedQA prompting</head><p>For the PubMedQA data set, we evaluated several additional few-shot prompting strategies on the development set. The best performing strategy involved randomly generating 3-shot prompts (no CoT) from the training split for each evaluation question along with updated instructions as follows in Table A.14.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.3 Ensemble refinement prompts</head><p>Tables A. <ref type="bibr" target="#b14">15</ref> and A.16 provide Med-PaLM 2 ensemble refinement prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.4 Long-form question prompts</head><p>Table <ref type="table">A</ref>.17 provides long-form question prompts used for both Med-PaLM and Med-PaLM 2. Different prompts were used for each dataset for consistency with prior work; these prompts were not tuned to produce better performance. The prompt templates for HealthSearchQA, LiveQA, and MedicationQA match those for in Singhal et al. <ref type="bibr">[3]</ref>.  Instructions: The following are multiple choice questions about medical knowledge. Solve them in a step-by-step fashion, starting by summarizing the available information. Output a single option from the four options as the final answer.</p><p>Question: A 22-year-old male marathon runner presents to the office with the complaint of right-sided rib pain when he runs long distances. Physical examination reveals normal heart and lung findings and an exhalation dysfunction at ribs 4-5 on the right. Which of the following muscles or muscle groups will be most useful in correcting this dysfunction utilizing a direct method? (A) anterior scalene (B) latissimus dorsi (C) pectoralis minor (D) quadratus lumborum Explanation: Let's solve this step-bystep, referring to authoritative sources as needed. Among the options, only pectoralis minor muscle origins from the outer surfaces of the 3rd to 5th ribs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (C)</head><p>Question: A 36-year-old male presents to the office with a 3-week history of low back pain. He denies any recent trauma but says that he climbs in and out of his truck numerous times a day for his job. Question: A 44-year-old man comes to the office because of a 3-day history of sore throat, nonproductive cough, runny nose, and frontal headache. He says the headache is worse in the morning and ibuprofen does provide some relief. He has not had shortness of breath. Medical history is unremarkable. He takes no medications other than the ibuprofen for pain. Vital signs are temperature 37.4?C (99.4?F), pulse 88/min, respirations 18/min, and blood pressure 120/84 mm Hg. Examination of the nares shows erythematous mucous membranes. Examination of the throat shows erythema and follicular lymphoid hyperplasia on the posterior oropharynx. There is no palpable cervical adenopathy. Lungs are clear to auscultation. Which of the following is the most likely cause of this patient's symptoms? (A) Allergic rhinitis (B) Epstein-Barr virus (C) Mycoplasma pneumonia (D) Rhinovirus Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. The symptoms, especially the headache, suggest that the most likely cause is Rhinovirus. Epstein-Barr virus will cause swollen lymph nodes but there is no palpable cervical adenopathy. Lungs are clear to auscultation suggests it's not Mycoplasma pneumonia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (D)</head><p>Question: A previously healthy 32-year-old woman comes to the physician 8 months after her husband was killed in a car crash. Since that time, she has had a decreased appetite and difficulty falling asleep. She states that she is often sad and cries frequently. She has been rechecking the door lock five times before leaving her house and has to count exactly five pieces of toilet paper before she uses it. She says that she has always been a perfectionist but these urges and rituals are new. Pharmacotherapy should be targeted to which of the following neurotransmitters? (A) Dopamine (B) Glutamate (C) Norepinephrine (D) Serotonin Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. The patient feels sad and among the options, only Dopamine and Serotonin can help increase positive emotions. Serotonin also affects digestion and metabolism, which can help the patient's decreased appetite and sleep difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (D)</head><p>Question: A 42-year-old man comes to the office for preoperative evaluation prior to undergoing adrenalectomy scheduled in 2 weeks. One month ago, he received care in the emergency department for pain over his right flank following a motor vehicle collision. At that time, blood pressure was 160/100 mm Hg and CT scan of the abdomen showed an incidental 10-cm left adrenal mass. Results of laboratory studies, including complete blood count, serum electrolyte concentrations, and liver function tests, were within the reference ranges. The patient otherwise had been healthy and had never been told that he had elevated blood pressure. He takes no medications. A follow-up visit in the office 2 weeks ago disclosed elevated urinary normetanephrine and metanephrine and plasma aldosterone concentrations. The patient was referred to a surgeon, who recommended the adrenalectomy. Today, vital signs are temperature 36.6?C (97.9?F), pulse 100/min, respirations 14/min, and blood pressure 170/95 mm Hg. Physical examination discloses no significant findings. Initial preoperative preparation should include treatment with which of the following? (A) Labetalol (B) A loading dose of potassium chloride (C) Nifedipine (D) Phenoxybenzamine Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. The symptoms and the adrenal mass suggested pheochromocytoma, and the blood pressure indicates hypertension. Phenoxybenzamine is used to treat hypertension caused by pheochromocytoma. Answer: (D) Question: A 65-year-old male complains of severe back pain and inability to move his left lower limb. Radiographic studies demonstrate the compression of nerve elements at the intervertebral foramen between vertebrae L5 and S1. Which structure is most likely responsible for this space-occupying lesion? (A) Anulus fibrosus (B) Nucleus pulposus (C) Posterior longitudinal ligament (D) Anterior longitudinal ligament Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. This man describes a herniated invertebral disk through a tear in the surrounding annulus fibrosus. The soft, gelatinous "nucleus pulposus" is forced out through a weakened part of the disk, resulting in back pain and nerve root irritation. In this case, the impingement is resulting in paralysis, and should be considered a medical emergency. Overall, the structure that is causing the compression and symptoms is the nucleus pulposus.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructions:</head><p>The following are multiple choice questions about medical knowledge. Solve them in a step-by-step fashion, starting by summarizing the available information. Output a single option from the four options as the final answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>The energy for all forms of muscle contraction is provided by: (A) ATP. (B) ADP. (C) phosphocreatine. (D) oxidative phosphorylation. Explanation: The sole fuel for muscle contraction is adenosine triphosphate (ATP). During near maximal intense exercise the muscle store of ATP will be depleted in less than one second. Therefore, to maintain normal contractile function ATP must be continually resynthesized. These pathways include phosphocreatine and muscle glycogen breakdown, thus enabling substrate-level phosphorylation ('anaerobic') and oxidative phosphorylation by using reducing equivalents from carbohydrate and fat metabolism ('aerobic'). , where p is the frequency of dominant allele frequency, q is the frequency of recessive allele frequency, p?2 is the frequency of the homozygous dominant allele, q?2 is the frequency of the recessive allele, and 2pq is the frequency of the heterozygous allele. Given that q?2=1/400, hence, q=0.05 and p=1-q=0.95. The frequency of the heterozygous allele is 2pq=2*0.05*0.95=38/400.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (D)</head><p>Question: A high school science teacher fills a 1 liter bottle with pure nitrogen and seals the lid. The pressure is 1.70 atm, and the room temperature is 25?C. Which two variables will both increase the pressure of the system, if all other variables are held constant? (A) Decreasing volume, decreasing temperature (B) Increasing temperature, increasing volume (C) Increasing temperature, increasing moles of gas (D) Decreasing moles of gas, increasing volume Explanation: According to the ideal gas law, PV = nRT (P = pressure, V = volume, n = number of moles, R = gas constant, T = temperature). Hence, increasing both temperature (T) and moles of gas (n), while other variables stay constant, will indeed increase the pressure of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer: (C)</head><p>Question: A 22-year-old male marathon runner presents to the office with the complaint of right-sided rib pain when he runs long distances. Physical examination reveals normal heart and lung findings and an exhalation dysfunction at ribs 4-5 on the right. Which of the following muscles or muscle groups will be most useful in correcting this dysfunction utilizing a direct method? (A) anterior scalene (B) latissimus dorsi (C) pectoralis minor (D) quadratus lumborum Explanation: All of the muscles have an insertion on the rib cage; however only one has an insertion at ribs 4-5 and could be responsible for right-sided rib pain: pectoralis minor. Pectoralis minor inserts to the costal cartilage of the anterior third to fifth ribs. Answer: (C) Instruction: The following are multiple choice questions about medical knowledge. Solve them in a step-by-step fashion, starting by summarizing the available information. Output a single option from the four options as the final answer. We provide several student reasonings for the last question. Some of them may be correct and some incorrect. You can use the best correct arguments from these reasonings. Beware of wrong reasoning and do not repeat wrong reasoning. Question: A 22-year-old male marathon runner presents to the office with the complaint of right-sided rib pain when he runs long distances. Physical examination reveals normal heart and lung findings and an exhalation dysfunction at ribs 4-5 on the right. Which of the following muscles or muscle groups will be most useful in correcting this dysfunction utilizing a direct method? (A) anterior scalene (B) latissimus dorsi (C) pectoralis minor (D) quadratus lumborum Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. Among the options, only pectoralis minor muscle origins from the outer surfaces of the 3rd to 5th ribs. Answer: (C) Question: A 36-year-old male presents to the office with a 3-week history of low back pain. He denies any recent trauma but says that he climbs in and out of his truck numerous times a day for his job. Answer: (D) Question: A previously healthy 32-year-old woman comes to the physician 8 months after her husband was killed in a car crash. Since that time, she has had a decreased appetite and difficulty falling asleep. She states that she is often sad and cries frequently. She has been rechecking the door lock five times before leaving her house and has to count exactly five pieces of toilet paper before she uses it. She says that she has always been a perfectionist but these urges and rituals are new. Pharmacotherapy should be targeted to which of the following neurotransmitters? (A) Dopamine (B) Glutamate (C) Norepinephrine (D) Serotonin Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. The patient feels sad and among the options, only Dopamine and Serotonin can help increase positive emotions. Serotonin also affects digestion and metabolism, which can help the patient's decreased appetite and sleep difficulty. Answer: (D) Question: A 42-year-old man comes to the office for preoperative evaluation prior to undergoing adrenalectomy scheduled in 2 weeks. One month ago, he received care in the emergency department for pain over his right flank following a motor vehicle collision. At that time, blood pressure was 160/100 mm Hg and CT scan of the abdomen showed an incidental 10-cm left adrenal mass. Results of laboratory studies, including complete blood count, serum electrolyte concentrations, and liver function tests, were within the reference ranges. The patient otherwise had been healthy and had never been told that he had elevated blood pressure. He takes no medications. A follow-up visit in the office 2 weeks ago disclosed elevated urinary normetanephrine and metanephrine and plasma aldosterone concentrations. The patient was referred to a surgeon, who recommended the adrenalectomy. Today, vital signs are temperature 36.6?C (97.9?F), pulse 100/min, respirations 14/min, and blood pressure 170/95 mm Hg. Physical examination discloses no significant findings. Initial preoperative preparation should include treatment with which of the following? (A) Labetalol (B) A loading dose of potassium chloride (C) Nifedipine (D) Phenoxybenzamine Explanation: Let's solve this step-by-step, referring to authoritative sources as needed. The symptoms and the adrenal mass suggested pheochromocytoma, and the blood pressure indicates hypertension. Phenoxybenzamine is used to treat hypertension caused by pheochromocytoma. Answer: (D) </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tanwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cole-Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pfohl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.13138</idno>
		<title level="m">Language Models Encode Clinical Knowledge</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13375</idno>
		<title level="m">Capabilities of gpt-4 on medical challenge problems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Li?vin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Hother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.08143</idno>
		<title level="m">Can large language models reason about medical questions? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<author>
			<persName><surname>Palm</surname></persName>
		</author>
		<ptr target="https://ai.google/static/documents/palm2techreport.pdf" />
		<imprint>
			<date type="published" when="2023-02">2. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computer programs to support clinical decision making</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Shortliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="page" from="61" to="66" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Medicine and the computer: the promise and problems of change. Use and impact of computers in clinical medicine</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Schwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="321" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Categorical and probabilistic reasoning in medicine revisited</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bobrow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><surname>Linkbert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.15827</idno>
		<title level="m">Pretraining Language Models with Document Links</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.09338</idno>
		<title level="m">Deep bidirectional languageknowledge graph pretraining</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Crfm</forename><surname>Stanford</surname></persName>
		</author>
		<ptr target="https://hai.stanford.edu/news/stanford-crfm-introduces-pubmedgpt-27b.2022" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing for Healthcare (HEALTH)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BioGPT: generative pre-trained transformer for biomedical text generation and mining</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">What disease does this patient have? a large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oufattole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">6421</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical domain Question Answering in Conference on Health, Inference, and Learning</title>
		<imprint>
			<biblScope unit="page" from="248" to="260" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>Pubmedqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06146</idno>
		<title level="m">A dataset for biomedical research question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02311</idno>
		<title level="m">Scaling language modeling with pathways</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brahma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tuwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kompa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beam</surname></persName>
		</author>
		<title level="m">The Diagnostic and Triage Accuracy of the GPT-3 Artificial Intelligence Model. medRxiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2023" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Analysis of large-language model versus human performance for genetics questions. medRxiv</title>
		<author>
			<persName><forename type="first">D</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Solomon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2023" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">ChatGPT Goes to Operating Room: Evaluating GPT-4 Performance and Its Potential in Surgical Education and Training in the Era of Large Language Models. medRxiv</title>
		<author>
			<persName><forename type="first">N</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2023" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating the performance of chatgpt in ophthalmology: An analysis of its successes and shortcomings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Antaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Touma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Milad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>El-Khoury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Duval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology Science</title>
		<imprint>
			<biblScope unit="page">100324</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Leas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Faix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Longhurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hogarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA Internal Medicine</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.01296</idno>
		<title level="m">Recitation-Augmented Language Models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Self-refine: Iterative refinement with self-feedback</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17651</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schumacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><surname>Dera</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17071</idno>
		<title level="m">Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03300</idno>
		<title level="m">Measuring massive multitask language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Overview of the medical question answering task at TREC 2017 LiveQA</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TREC</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bridging the Gap Between Consumers&apos; Medication Questions and Trusted Answers</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mrabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Shooshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MedInfo</title>
		<imprint>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Hidden in plain sight-reconsidering the use of race correction in clinical algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">New creatinine-and cystatin C-based equations to estimate GFR without race</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Inker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Eneanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tighiouart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Crews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Estrella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Froissart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">385</biblScope>
			<biblScope unit="page" from="1737" to="1749" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Health inequities and the inappropriate use of race in nephrology</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Eneanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boulware</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Reese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Thorpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Nephrology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="84" to="94" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ethical machine learning in healthcare</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ferryman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of biomedical data science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="123" to="144" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ethical dimensions of using artificial intelligence in health care</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Rigby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMA Journal of Ethics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="121" to="124" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The reliability of AHRQ Common Format Harm Scales in rating patient safety events</title>
		<author>
			<persName><forename type="first">T</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szekendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pavkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Clevenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cerese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of patient safety</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Understanding how discrimination can affect health</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health services research</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1374" to="1388" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Structural racism and health disparities: Reconfiguring the social determinants of health framework to include the root cause</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yearby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medicine &amp; Ethics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="518" to="526" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Journal of Law</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10001</idno>
		<title level="m">Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Solving quantitative reasoning problems with language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ramasesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Schlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gutman-Solo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.14858</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">GPT-4</title>
		<idno type="arXiv">arXiv:2303.08774[cs.CL</idno>
		<imprint/>
		<respStmt>
			<orgName>OpenAI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report 2023</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<title level="m">Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cangea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>V?rtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaegle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patraucean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ktena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tomasev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05039</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Ethical and social risks of harm from language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kasirzadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.04359</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soylu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.09110</idno>
		<title level="m">Holistic evaluation of language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Red teaming language models with language models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.03286</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Free-Marginal Multirater Kappa (multirater K [free]): An Alternative to Fleiss&apos; Fixed-Marginal Multirater Kappa</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Randolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Online submission</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tanwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cole-Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pfohl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.13138</idno>
		<title level="m">Language Models Encode Clinical Knowledge</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">What disease does this patient have? a large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oufattole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">6421</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Umapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical domain Question Answering in Conference on Health, Inference, and Learning</title>
		<imprint>
			<biblScope unit="page" from="248" to="260" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>Pubmedqa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06146</idno>
		<title level="m">A dataset for biomedical research question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03300</idno>
		<title level="m">Measuring massive multitask language understanding</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
