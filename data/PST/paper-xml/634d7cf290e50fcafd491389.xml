<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LOT: A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
							<email>j-guan19@mails.tsinghua.edu</email>
							<affiliation key="aff0">
								<orgName type="department">DCST</orgName>
								<orgName type="institution">The CoAI group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhuoer</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DCST</orgName>
								<orgName type="institution">The CoAI group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yamei</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DCST</orgName>
								<orgName type="institution">The CoAI group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Huawei Technologies Co., Ltd</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruilin</forename><surname>He</surname></persName>
							<email>heruilin@huawei.com</email>
						</author>
						<author>
							<persName><forename type="first">Xiaoxi</forename><surname>Mao</surname></persName>
							<email>maoxiaoxi@corp.netease.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Netease Fuxi AI Lab</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Changjie</forename><surname>Fan</surname></persName>
							<email>fanchangjie@corp.netease.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Netease Fuxi AI Lab</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
							<email>aihuang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">DCST</orgName>
								<orgName type="institution">The CoAI group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LOT: A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1162/tacl</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Standard multi-task benchmarks are essential for developing pretraining models that can generalize to various downstream tasks. Existing benchmarks for natural language processing (NLP) usually focus only on understanding or generating short texts. However, long text modeling requires many distinct abilities in contrast to short texts, such as the modeling of long-range discourse and commonsense relations, and the coherence and controllability of generation. The lack of standardized benchmarks makes it difficult to assess these abilities of a model and fairly compare different models, especially Chinese models. Therefore, we propose a story-centric benchmark named LOT for evaluating Chinese long text modeling, which aggregates two understanding tasks and two generation tasks. We construct new datasets for these tasks based on human-written Chinese stories with hundreds of words. Furthermore, we release an encoder-decoder-based Chinese long text pretraining model named LongLM with up to 1 billion parameters. We pretrain LongLM on 120G Chinese novels with two generative tasks including text infilling and conditional continuation. Extensive experiments show that LongLM outperforms similar-sized pretraining models substantially on both the understanding and generation tasks in LOT.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pretrained language models have achieved significant advances in various natural language understanding (NLU) and generation (NLG) tasks <ref type="bibr" target="#b13">(Devlin et al., 2019;</ref><ref type="bibr" target="#b37">Radford et al., 2019)</ref>. Standard benchmarks such as GLUE <ref type="bibr">(Wang et al., 2019)</ref> further boost the improvement and fast iteration of pretrained models. Popular benchmarks usually aggregate multiple tasks to spur the progress of generalizable models. But these benchmarks focus mainly on understanding or generating short texts. For example, the GLUE tasks take at most two sentences as input. And most tasks in NLG benchmarks such as GLGE <ref type="bibr" target="#b30">(Liu et al., 2020)</ref> and GEM <ref type="bibr" target="#b18">(Gehrmann et al., 2021)</ref> require generating only several words (e.g., dialogue generation). Although there have been many models pretrained on long texts such as GPT3 <ref type="bibr">(Brown et al., 2020)</ref> and CPM <ref type="bibr" target="#b55">(Zhang et al., 2020)</ref>, the lack of benchmark datasets makes it difficult to fully assess and compare their abilities of long text modeling.</p><p>In this paper, we present LOT, a benchmark for evaluating Chinese LOng Text understanding and generation. As shown in Table <ref type="table" target="#tab_0">1</ref>, modeling long texts requires many distinct abilities compared to short texts, including (1) commonsense reasoning regarding characters' reaction and intention, and knowledge about physical objects (e.g., ''river'') and abstract concepts (e.g., ''irony''); (2) modeling discourse-level features such as inter-sentence relations (e.g., causality) and global discourse structures (e.g., the order of events); and (3) the generation coherence and controllability, which require both maintaining a coherent plot and adhering to controllable attributes (e.g., topics). Accordingly, LOT contains two understanding tasks and two generation tasks regarding the above abilities. We construct new datasets for these tasks based on various kinds of stories such as fables and fairy tales collected from public web resources, Effendi's son is eccentric, always behaving opposed to what Effendi has ordered him to do. Familiar to his son's temper, Effendi usually communicates using irony. One day, the father and son were blocked by a river after purchasing flour from a mill. And while they were crossing the river, one bag on the donkey's back lost its weight and leaned. Effendi told his son with irony:''My boy! drop the sack into the river!'' The son heard the words and thought:''I have been opposed to my father for so many years. For this only time, I have to obey him.'' Therefore, he followed Effendi's words and indeed pushed the sack into the river. ''My boy! What are you doing?''Effendi shouted in anger.'' ... considering that stories usually contain abundant commonsense and discourse relations. All these tasks require processing stories with hundreds of words. Note that LOT does not involve extra-long texts with thousands of words since the complicated linguistic phenomena in these texts make it hard to test individual abilities and guide the improvement of generation models.</p><p>Furthermore, we release LongLM, a Chinese Long text pretraining Language Model. LongLM is a Transformer-based model with an encoderdecoder architecture. LongLM has three different versions ranging from 60 million to 1 billion parameters. We pretrain LongLM on 120G Chinese novels with two generative tasks, including text infilling <ref type="bibr" target="#b26">(Lewis et al., 2020)</ref> and conditional continuation <ref type="bibr" target="#b36">(Radford et al., 2018)</ref>. The pretraining data do not include other types of texts (e.g., news, Wiki-texts) since we mainly focus on commonsense and discourse relations within general long texts instead of factual and technical knowledge. To the best of our knowledge, LongLM is the first pretraining model of the same size scale that focuses on modeling long-form stories. Extensive experiments on LOT show that LongLM outperforms strong baselines substantially on both the understanding and generation tasks. However, we also observe that LongLM is still far behind human performance, which requires better semantic representations of events and deeper modeling of the commonsense and discourse relations between them. We summarize the main contributions of this paper as follows: I. We propose a new story-centric benchmark LOT for evaluating Chinese long text understanding and generation. LOT consists of four tasks for testing the fundamental abilities to model long texts. We also present new datasets for these tasks. II. We release a new Chinese pretraining model named LongLM. Experiment results demonstrate the strong performance of LongLM on LOT, but there still exists considerable room for improvement.<ref type="foot" target="#foot_1">1</ref> 2 Related Work NLP Benchmarks Recently, there have been a lot of multi-task benchmarks proposed to drive the progress of generalizable models. The benchmarks usually aggregate multiple model-agnostic tasks under a unified framework, enabling researchers to fairly compare different models. SentEval <ref type="bibr" target="#b10">(Conneau and Kiela, 2018)</ref> gathered multiple classification tasks involving either one or two sentences as inputs to evaluate sentence representations. DiscoEval <ref type="bibr" target="#b9">(Chen et al., 2019)</ref> extended these tasks to the discourse level regarding inter-sentence relations. GLUE <ref type="bibr">(Wang et al., 2019)</ref> included more diverse tasks such as natural language inference <ref type="bibr" target="#b42">(Rocktäschel et al., 2016)</ref>. <ref type="bibr" target="#b44">Sarlin et al. (2020)</ref> proposed SuperGLUE as a more challenging counterpart of GLUE by introducing multi-sentence tasks. But the additional tasks are only limited to the formats of coreference resolution and question answering. In addition to these English benchmarks, many benchmarks were proposed to evaluate NLU for other languages, such as CLUE <ref type="bibr" target="#b51">(Xu et al., 2020a)</ref> for Chinese. Moreover, GLGE <ref type="bibr" target="#b30">(Liu et al., 2020)</ref> and GEM <ref type="bibr" target="#b18">(Gehrmann et al., 2021)</ref> were proposed for evaluating NLG models across diversified generation tasks such as text summarization and personalizing dialogue. However, there is no benchmark designed specifically for long text modeling, especially Chinese. Additionally, the above benchmarks were originally designed to cover as diverse task formats as possible. In contrast, we design the LOT tasks with the guidance of necessary abilities for long text modeling as suggested by <ref type="bibr" target="#b41">Ribeiro et al. (2020)</ref>, making it easier to figure out where models are failing, and how to improve them.</p><p>Long Text Datasets Previous studies in the field of long text modeling have frequently focused on the ROCStories <ref type="bibr" target="#b33">(Mostafazadeh et al., 2016)</ref> and WritingPrompts <ref type="bibr" target="#b14">(Fan et al., 2018)</ref> datasets. ROCStories contains 100k artificial five-sentence stories, while WritingPrompts consists of 300K pairs of prompts and stories with hundreds of words. Recent works collected stories with thousands of words to model longer-range dependencies, such as WikiText-103 <ref type="bibr" target="#b32">(Merity et al., 2016)</ref>, roleplayerguild <ref type="bibr" target="#b31">(Louis and Sutton, 2018)</ref>, PG-19 <ref type="bibr" target="#b38">(Rae et al., 2020)</ref>, STORIUM <ref type="bibr" target="#b1">(Akoury et al., 2020)</ref>, and Long-Range Arena <ref type="bibr" target="#b47">(Tay et al., 2020)</ref>. However, these datasets are written in English. LOT will drive the development of Chinese language models. Moreover, LOT does not include datasets of extra-long texts, like PG-19, for the following two reasons: (1) Extra-long texts are far beyond the scope of current machine learning models because the discourse-level linguistic phenomena are entangled and complicated in these texts. Therefore, extra-long texts usually serve for computing perplexity of language models <ref type="bibr" target="#b12">(Dai et al., 2019)</ref> but hardly provide fine-grained guidance for improving model designs. (2) LOT aims not to spur research on building fuller connections across tokens within an extra-long sequence, but to drive the progress of machines in the aforementioned fundamental abilities for long text modeling.</p><p>Story Understanding and Generation LOT is centered on fundamental abilities for long text modeling and thus includes four story understanding and generation tasks concerning commonsense and discourse relations. Recent studies have proposed various tasks to evaluate story understanding and generation. First, story ending selection <ref type="bibr" target="#b33">(Mostafazadeh et al., 2016)</ref>, story ending generation <ref type="bibr" target="#b22">(Guan et al., 2019)</ref>, and story completion <ref type="bibr" target="#b50">(Wang and Wan, 2019)</ref> focused on the commonsense reasoning ability on inter-event causal and temporal relations. Second, <ref type="bibr" target="#b9">Chen et al. (2019)</ref> evaluated the ability to model discourse relations by predicting the position of a sentence or a paragraph in a text. Third, some works focused on the coherence of story generation conditioned on short prompts <ref type="bibr" target="#b14">(Fan et al., 2018)</ref>, titles <ref type="bibr" target="#b54">(Yao et al., 2019)</ref> and beginnings <ref type="bibr">(Guan et al., 2020)</ref>. Fourth, some studies centered on controllability, that is, the imposing of controllable attributes on story generation such as keywords <ref type="bibr" target="#b52">(Xu et al., 2020b)</ref>, emotional trajectories <ref type="bibr" target="#b4">(Brahman and Chaturvedi, 2020)</ref>, outlines <ref type="bibr" target="#b40">(Rashkin et al., 2020)</ref>, and styles <ref type="bibr" target="#b24">(Kong et al., 2021)</ref>. LOT is a comprehensive benchmark to test the above abilities for Chinese long text modeling.</p><p>On the other hand, LOT does not involve those tasks that require learning more particular features of stories, such as event chains <ref type="bibr" target="#b6">(Chambers and Jurafsky, 2008)</ref>, character types <ref type="bibr" target="#b2">(Bamman et al., 2013)</ref>, inter-character relations <ref type="bibr" target="#b8">(Chaturvedi et al., 2016</ref><ref type="bibr" target="#b7">(Chaturvedi et al., , 2017))</ref>, social networks <ref type="bibr" target="#b0">(Agarwal et al., 2013)</ref>, and abstractive structures <ref type="bibr" target="#b15">(Finlayson, 2012)</ref>. Non-neural story generation models usually retrieved events from a knowledge base with pre-specified semantic relations based on handcrafted rules <ref type="bibr" target="#b27">(Li et al., 2013)</ref>, which are costly and lack generalization. In this paper, we focus mainly on evaluating neural models for story understanding and generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LOT Benchmark</head><p>We design LOT as an aggregation of two understanding tasks including Cloze Test (ClozeT) and Sentence Position Prediction (SenPos), and two generation tasks including Plot Completion (PlotCom) and Outline-conditioned Generation (OutGen). We show the task descriptions and data statistics in Tables <ref type="table" target="#tab_3">2 and 3</ref>, respectively. We use the jieba tokenizer<ref type="foot" target="#foot_2">2</ref> for word tokenization.</p><p>We design LOT based on the following principles: (1) Task Diversity: The tasks vary in task formats, types and lengths of inputs and outputs, and focused abilities, making LOT a comprehensive framework for evaluating the generalization of models. (2) Task Difficulty: The tasks take hundreds of words as inputs or outputs, and do not involve domain-specific knowledge about science, films, and so forth. Therefore, they are beyond the scope of current state-of-the-art models, but are solvable by most Chinese native speakers. (3) Task Formulation: The tasks have been well formulated in prior studies and agreed to be challenging but meaningful. We introduce new Chinese datasets for these tasks, which are constructed to focus more specifically on testing   a certain ability than original datasets. (4) Automatic Evaluation: These tasks have reliable automatic metrics to evaluate the focused abilities.We exclude open-ended generation tasks such as story generation from titles, which is difficult to automatically evaluate <ref type="bibr" target="#b23">(Guan et al., 2021)</ref> because the tasks suffer from the notorious one-to-many issue: There are many plausible outputs for the same input <ref type="bibr" target="#b56">(Zhao et al., 2017)</ref>.</p><p>We constructed datasets for LOT through automatic and manual annotation. First, we crawled human-written stories from public web pages as the data source. These stories are under licenses that allow use and redistribution for research purposes. Then, we hired a commercial team to create the LOT examples. The team is led by a professional screenwriter and has taken on hundreds of NLP annotation projects. All annotators are native Chinese speakers and well-trained for the annotation tasks. We show the full list of the source web pages and the annotation details in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cloze Test</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mostafazadeh et al. (2016) introduced the Story</head><p>Cloze Test (SCT) task for evaluating story comprehension, which requires selecting the right ending from two candidates for a four-sentence leading context. However, SCT suffers from the following issues: (1) Its dataset is artificial and contains innate biases between right and wrong endings in some features such as lengths <ref type="bibr" target="#b45">(Schwartz et al., 2017;</ref><ref type="bibr" target="#b46">Sharma et al., 2018)</ref>. Such biases may leak information about the target labels.</p><p>(2) SCT focuses on reasoning only endings but neglects other types of reasoning, such as abductive reasoning <ref type="bibr" target="#b3">(Bhagavatula et al., 2019)</ref>, which requires reasoning what happens between observed beginnings and endings. (3) SCT limits the scope of commonsense reasoning to realistic events. The limitation may be neither necessary nor sufficient. For example, ''Cupid can fly'' can A goblin had buried a treasure under the ground. After that, he received a long flight mission from the Devil King. The goblin began to worry about how to guard the treasure during his mission. The goblin thought for a long time and decided to give the treasure to a miser. The miser clung to his vault even when he was asleep, so the goblin trusted him very much • • • Table <ref type="table">4</ref>: An example for selecting a sentence that can be reasoned based on the context and common sense (in red). We also highlight a sentence that does not satisfy the requirement in green, which introduces a new character ''the Devil King''. be reasoned based on common sense although it is not realistic, while some story settings may be realistic but fail to be reasoned only based on the context and common sense, as shown in Table <ref type="table">4</ref>. Therefore, when constructing our ClozeT dataset, we adopt the following approaches to alleviate the above issues: (1) All examples are derived from existing human-written stories. (2) We allow annotators to create examples where the removed sentence is initially in the middle of the story. (3) We change the scope of commonsense reasoning to all events that embody characters' reaction and intention, or the nature of physical objects and concepts. Table <ref type="table">6</ref> shows two ClozeT examples. Furthermore, we also conducted experiments to investigate the potential biases of our dataset in Section 5.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Story Filtering</head><p>To ensure the quality of LOT examples, we asked annotators to judge whether each crawled story meets the following definition: ''anything which is told in the form of a coherent event sequence involving several specific and related characters'' <ref type="bibr" target="#b33">(Mostafazadeh et al., 2016)</ref>. We provided detailed cases for annotators to instruct them about this definition. Then, annotators needed to refine those stories which do not meet the definition by rewriting the plots. They should also clean up the stories by the following heuristics: (1) refusing examples that may violate ethical principles (e.g., discrimination); (2) deleting noisy words (e.g., links); (3) changing slang and informal words into standard modern Chinese; (4) rewriting all dialogues to objective events. Finally, we collected 2,427 high-quality Text: I couldn't control my anger very well.[1]My parents would yell at me, and i ran to my room.[2]I buried my head in a pillow and screamed.[3]I threw my pillow and hit it hard.</p><p>Removed Sentence: I tried to express my anger. Chinese stories, which will be used to construct the datasets for the ClozeT, PlotCom, and OutGen tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Construction</head><p>We presented the stories to another group of annotators to construct the ClozeT dataset. For each story, they should select a sentence as the right candidate that can be reasoned based on the context and common sense. Table <ref type="table">4</ref> shows an example presented to the annotators to illustrate how to judge whether a sentence satisfies this requirement. Then, the annotators rewrite the sentence into another one as the wrong candidate that maintains a good topical relatedness with the context but violates common sense. The wrong candidates should either embody unreasonable reactions or intentions, or violate the nature of physical objects or concepts. And we require annotators not to select the first sentence, which usually aims to introduce story settings instead of narrating an event. We browse through the annotation results and give the annotators detailed feedback before approving their submissions. Finally, we collected 1,232 examples in total and split them for training, validation and testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sentence Position Prediction</head><p>We use the sentence position prediction task <ref type="bibr" target="#b9">(Chen et al., 2019)</ref> to evaluate the ability to capture inter-sentence relations (e.g., causality). We formulate the task as follows: Given a text with a sentence removed, models should choose the correct position of the sentence in the text from multiple candidates. <ref type="bibr" target="#b9">Chen et al. (2019)</ref> constructed an English dataset for this task by randomly removing sentences from existing texts. However, such examples may be invalid since a sentence may have multiple plausible positions in a text, Table <ref type="table">6</ref>: Two ClozeT examples. The right candidates are extracted from the original stories (at the position of ''[MASK]'') while the wrong candidates are written by crowd-sourced annotators. The first example focuses on common sense regarding the fox's reaction to the silly wolf 's behavior, while the second example focuses on common sense regarding the relations between palace and prince. We highlight the entities and events related to the commonsense relations in red, and those which violate common sense in the wrong candidates in green.</p><p>as illustrated in Table <ref type="table" target="#tab_4">5</ref>. Therefore, we construct the dataset for our task based on the following pipeline: (1) extracting paragraphs with less than 500 words from crawled stories; (2) randomly selecting a sentence to remove for each paragraph, and regarding all positions between two adjacent sentences as candidates 3 ; and (3) asking annotators to refine part of the auto-constructed examples as the validation and test sets, and the remaining as the training set. Table <ref type="table" target="#tab_5">7</ref> shows two SenPos examples.</p><p>Dataset Construction We asked annotators to refine each example so that the removed sentence has only one reasonable position in the text. We did not allow annotators to select the first or last sentence of the original text as the removed sentence because they usually contain obvious wording features (e.g., ''once upon a time,'' ''they lived happily together''), which may make this task trivial. Unlike ClozeT, we allowed the texts for SenPos to be incomplete or include dialogues that also embody rich inter-sentence relations. Finally, we collected 1,663 examples for validation and testing through human annotation. And we 3 We set the minimum length of the removed sentence to 10 Chinese characters, and we merge a sentence in a story with its neighbors if it contains less than 10 characters. constructed 20,000 examples automatically for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Plot Completion</head><p>We use the Plot Completion task <ref type="bibr" target="#b50">(Wang and Wan, 2019)</ref> to test the ability to make inferences based on common sense. We formulate this task as follows: Given a story with a sentence removed, models should generate a sentence to complete the story and make it reasonable and coherent.</p><p>Dataset Construction Prior studies <ref type="bibr" target="#b50">(Wang and Wan, 2019;</ref><ref type="bibr" target="#b35">Paul and Frank, 2021)</ref> automatically constructed datasets for this task based on existing datasets by randomly removing one sentence from a story. However, as shown in Table <ref type="table">4</ref>, not all sentences in a story can be reasoned only based on the context and common sense. Therefore, we only used the above automatic method to construct the training data. And we adapted the ClozeT data to this task for validation and testing, since annotators have marked out the qualified sentences. Specifically, we randomly sampled some ClozeT examples and took the incomplete story of each example as input, and the right candidate as the target sentence to be generated. The first/second example focuses on testing the ability to capture the inter-sentence causal/temporal relations, respectively. We highlight the entities and events implying the relations in red.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Outline-conditioned Generation</head><p>Prior work tended to test the ability of long text generation through story generation conditioned on inputs with limited information such as titles <ref type="bibr" target="#b54">(Yao et al., 2019)</ref>. However, these tasks are extremely open-ended so that it is difficult to reliably measure the generation quality using automatic metrics <ref type="bibr">(Guan and Huang, 2020)</ref>. To alleviate the issue, we introduce the Outline-conditioned Generation task <ref type="bibr" target="#b40">(Rashkin et al., 2020)</ref>, which requires generating a coherent long-form story conditioned on an outline of characters and events. We formulate the outline as a set of out-of-order phrases, which not only narrows down the set of plausible stories but also serves for testing the controllability and planning ability of models to arrange the given events reasonably at the discourse level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Construction</head><p>We built the dataset for this task automatically based on filtered stories. We followed <ref type="bibr" target="#b40">Rashkin et al. (2020)</ref> to extract the outline of a story using the RAKE algorithm <ref type="bibr" target="#b43">(Rose et al., 2010)</ref>. We extract at most eight phrases for each story, and each phrase contains no more than eight words. For example, the outline for the story in Table <ref type="table" target="#tab_0">1</ref> is {''told his son with irony,'' ''purchasing flour from a mill,'' ''crossing the river,'' ''drop the sack into the river,'' ''indeed pushed the sack,'' ''familiar to his son's temper,'' ''shouted,'' ''one bag''}. The outline can serve as discourse-level guidance for generation models, which should rearrange the events reasonably and generate a story with a good global discourse structure, rather than focus on modeling only the local coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Overall Score</head><p>Existing benchmarks usually summarize the performance of a model as a single score by averaging all metric scores without considering task difficulties. To encourage models to progress on those tasks where there is a more significant gap between machines and humans, we propose to average metric scores with different weights. Suppose that there are a total of M metrics for all tasks, we derive the overall score as follows:</p><formula xml:id="formula_0">S = M i=1 w i M j=1 w j S i ,</formula><p>(1)</p><formula xml:id="formula_1">w i = H i B i , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where H i , B i , and S i are the score of humans, a pre-selected baseline, and the evaluated model for the i-th metric, respectively, and w i is the weight for this metric. Intuitively, the metric scores where the baseline model has a larger gap with humans will have a larger weight when computing the overall score. We use BERT and GPT2 as the baseline models for the understanding and generation tasks in LOT, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Long Text Pretraining Model</head><p>To provide more flexibility on both understanding and generation tasks, we build LongLM following the original encoder-decoder design of Transformer <ref type="bibr" target="#b48">(Vaswani et al., 2017)</ref> with three different sizes, as shown in Table <ref type="table" target="#tab_7">8</ref>. We follow <ref type="bibr" target="#b11">Cui et al. (2020)</ref> to use a sentencepiece vocabulary of 32,000 wordpieces <ref type="bibr" target="#b25">(Kudo and Richardson, 2018)</ref>. And we set the maximum sequence length to 512 for both the encoder and decoder.</p><p>Pretraining Data We collect 120G novels as the pretraining data for LongLM, which cover various topics such as romance, military, and so on. Since a novel is usually much longer than the maximum input and output length of LongLM, we split a novel into multiple segments for pretraining.</p><p>Pretraining Tasks Encoder-decoder models are trained typically by maximizing the likelihood of the target output given an input. To improve capacities of both the encoder and decoder, we propose to train LongLM with two pretraining tasks including text infilling <ref type="bibr" target="#b39">(Raffel et al., 2020)</ref> and conditional continuation <ref type="bibr" target="#b37">(Radford et al., 2019)</ref>.</p><p>For the first task, the input is a text where a number of spans are sampled and replaced by special tokens with unique IDs, while the output is the spans delimited by the special tokens used in the input. The lengths of masked spans are drawn from a Poisson distribution with λ=3 and all masked tokens compress 15% of the original texts. As for the second task, the input and output are, respectively, the front and back half of a text, which is split into two parts randomly. We show an example of the pretraining tasks in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pretraing Details</head><p>We set the learning rate to 1e-4 with the Adam optimizer and the batch size  to 1,000. We pretrained LongLM for 2.5M steps.</p><p>It took about two months to train the largest model using eight NVIDIA V100 GPUs.</p><p>Model Performance To assess the performance of LongLM on the pretraining tasks, we randomly separated out 1,000 texts from the initial pretraining data for testing, which were never seen in the pretraining phase. We used perplexity and BLEU-n (n = 3, 4) to evaluate both pretraining tasks. And we generated outputs using the greedy decoding algorithm for the text infilling task, and top-k sampling <ref type="bibr" target="#b14">(Fan et al., 2018)</ref> with k = 40 and a softmax temperature of 0.7 <ref type="bibr" target="#b19">(Goodfellow et al., 2014)</ref> for the conditional continuation task. As shown in Table <ref type="table">9</ref>, the performance improves substantially as the number of parameters increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we tested LongLM and existing models on LOT with automatic and manual evaluation. Furthermore, we conducted extensive experiments to investigate the potential biases of the ClozeT and SenPos datasets (Section 5.5), and measure the overlap between training and testing data (Section 5.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluated Models</head><p>We evaluated the following models, which are implemented based on the register models of HuggingFace Transformers: 4 (1) Vanilla Transformer: It has the same architecture as BERT base except that the number of layers is set to 3 <ref type="bibr" target="#b48">(Vaswani et al., 2017)</ref>.</p><p>(2) BERT: It is implemented based on the bert-base-Chinese register model <ref type="bibr" target="#b13">(Devlin et al., 2019)</ref>.</p><p>(3) RoBERTa: It is implemented based on the hfl/chinese-roberta-wwm-ext register model <ref type="bibr" target="#b11">(Cui et al., 2020)</ref>. (4) GPT2: It is implemented based on the uer/gpt2-chinese-cluecorpussmall register model <ref type="bibr" target="#b57">(Zhao et al., 2019)</ref>. (5) mT5: It is implemented based on the google/mt5-base register model <ref type="bibr">(Xue et al., 2021)</ref>. We set all the baseline models to the base version due to limited computational resources.</p><p>To show the generic benefits of the pretraining data of LongLM for long text modeling, we pretrained a left-to-right language model from scratch on the data with the standard language modeling objective. This model has the same architecture as GPT2 base and is denoted as GPT2 † base . Moreover, we evaluated two task-specific pretraining models including PlotMachines (PM) <ref type="bibr" target="#b40">(Rashkin et al., 2020)</ref> and Plan&amp;Write (PW) <ref type="bibr" target="#b54">(Yao et al., 2019)</ref>, and two typical non-pretrained models including ConvS2S <ref type="bibr" target="#b17">(Gehring et al., 2017)</ref> and Fusion <ref type="bibr" target="#b14">(Fan et al., 2018)</ref> on the generation tasks in LOT. We used GPT2 base as the backbone model of PM and PW. For PM, we regard input sentences (for PlotCom) or input phrases (for OutGen) as the plot elements used in the memory network, and update the memory representations at each step of decoding. As for PW, we take a keyword extracted from the target sentence using the RAKE algorithm (for PlotCom) or the sorted input phrases in order (for OutGen) as the intermediate representations for planning. We implemented these models based on the codes provided by the original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment Settings</head><p>Understanding Tasks For both tasks, we encode the input of each example and then predict a distribution over all candidates by normalizing the dot-product values between the representations of each candidate and the context. We use the candidate with the maximum probability as the prediction result. For ClozeT, we represent 4 https://huggingface.co/models. a candidate using the hidden state at the end of it, and we regard the hidden state at the position of the removed sentence appearing in the original text as the context representation. And for SenPos, we take the hidden state at each candidate position as the candidate representation and the hidden state at the end of the removed sentence as the context representation. When evaluating mT5 and LongLM, we feed the same input into the encoder and decoder <ref type="bibr" target="#b26">(Lewis et al., 2020)</ref> and use the hidden states of the decoder for prediction in the above way.</p><p>Generation Tasks For PlotCom, we take the incomplete story of an example as input to generate the missing sentence. And for OutGen, we concatenate all phrases in an outline with special tokens as input to generate a story.</p><p>Hyper-Parameters For all models, we set the batch size to 12, the maximum sequence length to 512, and the learning rate to 3e-5. We decode outputs use top-k sampling with k = 40 and a softmax temperature of 0.7 for the generation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Automatic Evaluation</head><p>Metrics We use accuracy to evaluate the understanding tasks. As for generation tasks, we use BLEU-n (B-n) and Distinct-n (D-n) to evaluate the n-gram overlap with ground-truth texts <ref type="bibr" target="#b34">(Papineni et al., 2002)</ref> and n-gram generation diversity <ref type="bibr" target="#b28">(Li et al., 2016)</ref>, respectively. We set n = 1, 2 for both generation tasks. Additionally, we also use the following two metrics to evaluate OutGen: (1) Coverage (Cover): It is used to evaluate the generation controllability, which is computed as the average Rouge-L recall score <ref type="bibr" target="#b29">(Lin, 2004)</ref> between the generated text and each input phrase. A higher coverage score indicates the generated text covers more input phrases. (2) Order: It is used to measure the gap between the positional orders of input phrases appearing in the generated texts and ground-truth texts. Specifically, we compute the order score as the average ratio of the number of inversions in the generated story to the number of all position pairs of any two phrases. An inversion refers to a position pair that are out of the ground-truth order. And we use the position of the longest common subsequence between a story and a phrase as the position of the phrase in the story. Because an input phrase does not always appear in the generated story,  we regard all position pairs of such a phrase and others as inversions.</p><p>Results Tables <ref type="table" target="#tab_12">10 and 11</ref> show the results on the understanding and generation tasks, respectively. To obtain the human performance on the understanding tasks, we randomly sampled 100 examples from the validation set or test set and hired three crowd-sourced annotators (native Chinese speakers) to do these tasks. We made final decisions among them through majority voting. All results show an almost perfect inter-annotator agreement with Fleiss's κ &gt; 0.85 <ref type="bibr">(Fleiss and Joseph, 1971)</ref>. For generation tasks, we regard the scores of ground-truth texts as human performance.</p><p>We summarize the evaluation results as follows: (1) Pretrained models have significantly better performance than non-pretrained models. (2)</p><p>LongLM large outperforms other baselines substantially on both the understanding and generation tasks. LongLM base /LongLM small achieves better overall scores with half fewer parameters than mT5/GPT2. (3) By comparing GPT2 † and GPT2, we can derive that our pretraining data can effectively improve the ability to model long texts. (4) LongLM small has a better performance than GPT2 † on the understanding tasks, and is comparable with GPT2 † on the generation tasks, suggesting the benefits of the encoder-decoder framework and the text infilling task. (5) It is still extremely challenging for all models to capture the commonsense and inter-sentence discourse relations between events in long texts for tackling the ClozeT and SenPos tasks. Furthermore, we investigate how the size of training data influences the accuracy of BERT for SenPos. The result in Figure <ref type="figure" target="#fig_1">2</ref> indicates the necessity to develop better representations of discourse relations instead of relying only on increasing the data size. (6) The results on the generation tasks show that LongLM does well in generating more word overlaps with references than similar-sized baselines for both tasks, and covers more input phrases and arranges them in correct orders for OutGen. But LongLM underperforms GPT2-based models in terms of diversity on PlotCom. (7) Dynamically tracking plot states (i.e., PM) does not bring significant improvement on the generation tasks compared with GPT2, suggesting that it may require modeling the discourse structure explicitly to tackle the generation tasks. And the superiority of PW to GPT2 on OutGen further indicates the benefit of modeling discourse-level features. In summary, we believe LOT will serve as an effective evaluation for capturing the commonsense and discourse relations of long texts beyond the surface events, and generating coherent and controllable long-form texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Manual Evaluation</head><p>Because automatic metrics may be unreliable for evaluating NLG <ref type="bibr">(Guan and Huang, 2020)</ref>, we conducted a point-wise manual evaluation to measure the disparity between machines and humans for the generation tasks in LOT. For each task, we randomly sampled 100 examples from the test set and obtained 100 ground-truth texts and 300 generated texts from three typical models including GPT2 base , mT5 base and  LongLM large . For each text along with the input, we hired three crowd-sourced workers to judge its quality with a binary score (1 for good, and 0 otherwise) in terms of three aspects: (1) grammaticality (intra-sentence grammar quality of generated texts), ( <ref type="formula" target="#formula_1">2</ref>) coherence (causal and temporal dependencies within generated texts), and (3) relatedness to inputs (reasonable logical connections to the input context for PlotCom; and reasonable utilization of input phrases for Out-Gen). These aspects are independently evaluated. We made final decisions among three annotators through majority voting. We show the annotation instructions in the appendix.</p><formula xml:id="formula_3">Models # P PlotCom OutGen Overall B-1 B-2 D-1 D-2 B-1 B-2 D-1 D-</formula><p>Table <ref type="table" target="#tab_14">12</ref> shows the evaluation results. For both tasks, LongLM outperforms GPT2 and mT5 significantly in all aspects (p &lt; 0.05, sign test). However, it is difficult for all models to generate a logical completion for PlotCom (relatedness score &lt; 0.1), showing their poor ability to capture commonsense and inter-sentence relations. And the big gap between LongLM and humans also proves both tasks challenging to existing generation models. We also observe the positive correlation between the manual evaluation and automatic evaluation (Table <ref type="table" target="#tab_12">11</ref>), suggesting that it may be acceptable to use automatic evaluation to compare and improve models on the generation tasks in LOT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Bias Investigation</head><p>It is essential to investigate potential biases of a dataset, which may leak information about target   do not exist such paired markers in an example or there are multiple eligible candidates, this baseline will randomly choose one. The setting of this baseline for SenPos is similar to ClozeT. We manually define 24 marker pairs for this baseline.</p><p>(7) BERT w/o Context: We fine-tuned BERT to directly choose without taking the context as input <ref type="bibr" target="#b45">(Schwartz et al., 2017)</ref>. (8) BERT w/o Long:</p><p>It is used to study whether solving these tasks requires modeling long-range dependencies. For ClozeT, we fine-tuned BERT to choose with only the adjacent sentences of the removed sentence as input. And for SenPos, we encoded each position and its adjacent sentences respectively using BERT and then took the hidden states at these positions for prediction. These baselines cover different levels of features ranging from the token level (e.g., Length), the sentence level (e.g., Sentiment), to the discourse level (e.g., Discourse Markers, BERT w/o Context). We believe that these baselines will provide a comprehensive inspection for the potential biases of our datasets.</p><p>As shown in Table <ref type="table" target="#tab_15">13</ref>, both tasks can not be trivially solved by these baselines, suggesting that the datasets may be free of biases in terms of the above features. Therefore, we believe that the tasks can focus on testing the ability of models to capture long-range commonsense and discourse relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Memorization Investigation</head><p>Overlap between training and test data may result in an over-reporting of the generalization performance of machines. Therefore, it is necessary to investigate how many test data also show up in the training data. To this end, we follow   <ref type="bibr" target="#b37">Radford et al. (2019)</ref> to measure the overlap between two datasets by calculating the percentage of 8-grams from one that are also in the other. We use the jieba tokenizer for tokenization. Table <ref type="table" target="#tab_17">14</ref> shows the overlapping analysis for test sets of the four tasks in LOT. We can see that all test sets have less than 1% overlap with their own training sets. Notably, there are 17 test examples of SenPos that contain more than 10% overlapped 8-grams with the training set. This is because a training example and a test example may come from the same story, and thus they share similar information (e.g., characters, locations). A test example contains at most 60.98% overlapped 8-grams, suggesting that the training set and test set do not include exactly the same example. As for the pretraining data of LongLM, the test sets of ClozeT and PlotCom still have less than 1% overlap. However, there are dozens of test examples in SenPos and OutGen that contain more than 10% overlapped 8-grams. Through manual inspection of the overlaps, we found that they mainly come from idioms, proverbs and classic   <ref type="table" target="#tab_19">15</ref>.</p><p>fairy tales, which may be part of some novels in the pretraining data.</p><p>To investigate how the overlapping data influence the measurement of models' performance, we re-evaluated LongLM large on the test sets of SenPos and OutGen with exclusion of the examples that have more than 10% overlapped 8-grams with the training sets or pretraining data. We also used mT5 base as a baseline in the same setting of LongLM. The results for SenPos and Out-Gen are shown in Tables <ref type="table" target="#tab_20">15 and 16</ref>, respectively. The change of accuracy or BLEU-1 score is very marginal for both mT5 and LongLM when excluding the overlapping data, suggesting that the superior performance of LongLM is rarely attributable to the memorization of training data. Therefore, we believe that it is fair to compare LongLM and other models on these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We present LOT, a story-centric benchmark for Chinese long text understanding and generation. LOT includes two story understanding tasks and two story generation tasks, which comprehensively investigate the abilities of commonsense reasoning, controllable generation, and modeling inter-sentence relations and the global discourse structures. We provide standard datasets for the four tasks, which are constructed based on human-written stories processed by automatic and manual annotation. Furthermore, we release a new Chinese long text pretraining model LongLM, which outperforms strong baseline models substantially on both the understanding and generation tasks in LOT. The LOT benchmark and the pretraining model will encourage further research on Chinese long text modeling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schematic of the pretraining tasks. &lt;X&gt; and &lt;Y&gt; is the special tokens used for masking spans. &lt;Z&gt; is the ''end of sequence'' token.</figDesc><graphic url="image-1.png" coords="8,308.68,58.02,215.88,103.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Accuracy of BERT for SenPos as the size of training data increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A long text example. The concepts and events concerning commonsense and discourse relations are highlighted in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overview of the tasks in LOT for the abilities they test, inputs and outputs, and the evaluation metrics. Dist and Cover refer to Distinct and Coverage (Section 5.3), respectively.</figDesc><table><row><cell>Datasets</cell><cell>Train</cell><cell>Val</cell><cell>Test</cell></row><row><cell cols="2">Task: ClozeT</cell><cell></cell><cell></cell></row><row><cell># Examples</cell><cell>644</cell><cell>294</cell><cell>294</cell></row><row><cell>Vocabulary Size</cell><cell>9k</cell><cell>7k</cell><cell>7k</cell></row><row><cell>Avg. # Char in Input Text</cell><cell cols="3">139.07 138.95 141.15</cell></row><row><cell>Avg. # Word in Input Text</cell><cell>89.28</cell><cell>89.03</cell><cell>90.20</cell></row><row><cell>Avg. # Sent in Input Text</cell><cell>5.95</cell><cell>5.94</cell><cell>5.95</cell></row><row><cell>Avg. # Word in Candidate</cell><cell>15.60</cell><cell>16.38</cell><cell>15.75</cell></row><row><cell cols="2">Task: SenPos</cell><cell></cell><cell></cell></row><row><cell># Examples</cell><cell>20,000</cell><cell>800</cell><cell>863</cell></row><row><cell>Vocabulary Size</cell><cell>147k</cell><cell>10k</cell><cell>22k</cell></row><row><cell>Avg. # Char in Input Text</cell><cell cols="3">289.59 258.48 258.52</cell></row><row><cell>Avg. # Word in Input Text</cell><cell cols="3">254.11 224.20 223.25</cell></row><row><cell>Avg. # Sent in Input Text</cell><cell>9.61</cell><cell>8.43</cell><cell>8.44</cell></row><row><cell>Avg. # Word in Removed Sent</cell><cell>30.48</cell><cell>29.28</cell><cell>30.26</cell></row><row><cell>Avg. # Candidate Positions</cell><cell>8.05</cell><cell>6.91</cell><cell>6.91</cell></row><row><cell cols="2">Task: PlotCom</cell><cell></cell><cell></cell></row><row><cell># Examples</cell><cell>13,099</cell><cell>465</cell><cell>464</cell></row><row><cell>Vocabulary Size</cell><cell>22k</cell><cell>8k</cell><cell>8k</cell></row><row><cell>Avg. # Char in Input Text</cell><cell cols="3">164.35 137.67 133.26</cell></row><row><cell>Avg. # Word in Input Text</cell><cell>105.48</cell><cell>87.56</cell><cell>84.98</cell></row><row><cell>Avg. # Sent in Input Text</cell><cell>7.17</cell><cell>5.59</cell><cell>5.48</cell></row><row><cell>Avg. # Word in Output Sent</cell><cell>15.08</cell><cell>15.96</cell><cell>16.15</cell></row><row><cell cols="2">Task: OutGen</cell><cell></cell><cell></cell></row><row><cell># Examples</cell><cell>1,456</cell><cell>242</cell><cell>729</cell></row><row><cell>Vocabulary Size</cell><cell>19k</cell><cell>6k</cell><cell>12k</cell></row><row><cell>Avg. # Word in Input Title</cell><cell>4.64</cell><cell>4.89</cell><cell>4.64</cell></row><row><cell>Avg. # Word in Input Outline</cell><cell>19.20</cell><cell>19.05</cell><cell>19.47</cell></row><row><cell>Avg. # Phrase in Input Outline</cell><cell>8.00</cell><cell>8.00</cell><cell>8.00</cell></row><row><cell>Avg. # Char in Output Text</cell><cell cols="3">169.94 169.80 170.49</cell></row><row><cell>Avg. # Word in Output Text</cell><cell cols="3">108.91 108.68 109.04</cell></row><row><cell>Avg. # Sent in Output Text</cell><cell>7.20</cell><cell>7.11</cell><cell>7.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Data statistics of LOT tasks. The abbreviation char/sent/len is short for character/sentence/length, respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>A poor example for the SenPos task. The removed sentence has multiple reasonable positions including [2] and [3] in the original text.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 :</head><label>7</label><figDesc>Two SenPos examples. The special tokens from [1] to [9] refer to the candidate positions.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Hyper-parameter settings for different versions of LongLM. d m , d ff , and d kv are the dimension of hidden states, the feed forward layers, and the keys/values in the self-attention layers, respectively. n h is the number of attention heads. n e and n d denote the number of hidden layers for the encoder and decoder, respectively. # P is the number of parameters.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Accuracy (%) on the understanding tasks in LOT. # P means the number of parameters. The best performance is in bold and the second best is underlined. w i is the metric weight with BERT as the baseline model when computing the overall score.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Evaluation results on the generation tasks in LOT. # P means the number of parameters. The best performance is in bold and the second best is underlined. w i is the metric weight with GPT2 base as the baseline model when computing the overall score.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12</head><label>12</label><figDesc></figDesc><table><row><cell>Baselines</cell><cell>ClozeT</cell><cell>SenPos</cell></row><row><cell>Random</cell><cell>50.00</cell><cell>16.03</cell></row><row><cell>Majority</cell><cell>52.72</cell><cell>16.24</cell></row><row><cell>Length</cell><cell>52.72</cell><cell>16.45</cell></row><row><cell>BLEU-1/2</cell><cell>46.94/48.98</cell><cell>14.14/14.95</cell></row><row><cell>Sentiment</cell><cell>50.34</cell><cell>16.49</cell></row><row><cell>Discouse Markers</cell><cell>45.92</cell><cell>9.15</cell></row><row><cell>BERT w/o Context</cell><cell>57.82</cell><cell>18.08</cell></row><row><cell>BERT w/o Long</cell><cell>62.24</cell><cell>19.00</cell></row><row><cell>BERT</cell><cell>69.39</cell><cell>43.68</cell></row><row><cell>: Manual evaluation results for PlotCom</cell><cell></cell><cell></cell></row><row><cell>and OutGen in terms of grammaticality (Gram),</cell><cell></cell><cell></cell></row><row><cell>coherence (Cohe), and relatedness (Relat). The</cell><cell></cell><cell></cell></row><row><cell>best performance is highlighted in bold. All</cell><cell></cell><cell></cell></row><row><cell>results show a fair inter-annotator agreement</cell><cell></cell><cell></cell></row><row><cell>with Fleiss' κ &gt; 0.2.</cell><cell></cell><cell></cell></row><row><cell>labels and enable models to easily use short-</cell><cell></cell><cell></cell></row><row><cell>cuts to handle complex inputs without actually</cell><cell></cell><cell></cell></row><row><cell>mastering the focused abilities (Ribeiro et al.,</cell><cell></cell><cell></cell></row><row><cell>2020). Therefore, we experimented with the fol-</cell><cell></cell><cell></cell></row><row><cell>lowing baselines to inspect the ClozeT and SenPos</cell><cell></cell><cell></cell></row><row><cell>datasets: (1) Random: It chooses a candidate ran-</cell><cell></cell><cell></cell></row><row><cell>domly. (2) Majority: It chooses the candidate</cell><cell></cell><cell></cell></row><row><cell>with an index that is most frequently selected in</cell><cell></cell><cell></cell></row><row><cell>the training set. (3) Length: For ClozeT, it chooses</cell><cell></cell><cell></cell></row><row><cell>the candidate that contains more words; And for</cell><cell></cell><cell></cell></row><row><cell>SenPos, it chooses the position of which the adja-</cell><cell></cell><cell></cell></row><row><cell>cent sentences have the closest number of words to</cell><cell></cell><cell></cell></row><row><cell>the removed sentence. (4) BLEU-n: For ClozeT,</cell><cell></cell><cell></cell></row><row><cell>it chooses the candidate with a higher BLEU-n</cell><cell></cell><cell></cell></row><row><cell>score (Papineni et al., 2002) with the context;</cell><cell></cell><cell></cell></row><row><cell>And for SenPos, it chooses the position of which</cell><cell></cell><cell></cell></row><row><cell>the adjacent sentences have the largest average</cell><cell></cell><cell></cell></row><row><cell>BLEU-n score with the removed sentence (n =</cell><cell></cell><cell></cell></row><row><cell>1,2). (5) Sentiment: For ClozeT, it chooses the</cell><cell></cell><cell></cell></row><row><cell>candidate with a higher sentiment score computed</cell><cell></cell><cell></cell></row><row><cell>by an off-the-shelf Chinese sentiment analyzer; 5</cell><cell></cell><cell></cell></row><row><cell>for SenPos, it chooses the position where the aver-</cell><cell></cell><cell></cell></row><row><cell>age sentiment score of its adjacent two sentences</cell><cell></cell><cell></cell></row><row><cell>is the closest to the score of the removed sentence.</cell><cell></cell><cell></cell></row><row><cell>(6) Discourse Markers: For ClozeT, it chooses</cell><cell></cell><cell></cell></row><row><cell>the candidate where its adjacent sentences contain</cell><cell></cell><cell></cell></row><row><cell>a discourse marker matching with it. For example,</cell><cell></cell><cell></cell></row><row><cell>if ''because'' occurs in the sentence before</cell><cell></cell><cell></cell></row><row><cell>the position of the candidates, this baseline will</cell><cell></cell><cell></cell></row><row><cell>choose the candidate that contains ''so''. 6 If there</cell><cell></cell><cell></cell></row></table><note>5 https://github.com/isnowfy/snownlp. 6 Different from English, paired discourse markers like ''because''-''so'' should be used together in Chinese.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :</head><label>13</label><figDesc>Accuracy (%) of different baselines on the test sets of ClozeT and SenPos for bias investigation. We use the results of BERT as a reference.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 :</head><label>14</label><figDesc>Overlapping analysis for the test sets of the four tasks with respect to their own training sets or the pretraining data of LongLM. We compute the following statistics: (1) Percent: the percentage of 8-grams from the test set that are also in the training sets or the pretraining data;(2) # 8-grams: the number of overlapped 8-grams; (3) # Exam: the number of examples that contain at least one overlapped 8-gram;(4) # Exam &gt;10% : the number of examples that have more than 10% overlapped 8-grams. (4) Max Percent: the maximum percentage of overlapped 8-grams from an example.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 15 :</head><label>15</label><figDesc>Accuracy on the test set of SenPos. Total means using the whole test set while w/o Overlap means excluding the examples that have more than 10% overlapped 8-grams with the training set or pretraining data from the test set. # Exam is the number of examples. Δ denotes the change of accuracy when excluding the overlapping data compared with using the total test set.</figDesc><table><row><cell>OutGen</cell><cell>Total</cell><cell>w/o Overlap (Pretraining Data)</cell><cell>Δ</cell></row><row><cell># Exam</cell><cell>729</cell><cell>703</cell><cell>N/A</cell></row><row><cell>mT5 base</cell><cell>36.33</cell><cell>36.45</cell><cell>+0.12</cell></row><row><cell>LongLM large</cell><cell>42.10</cell><cell>42.22</cell><cell>+0.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 16 :</head><label>16</label><figDesc>BLEU-1 score on the test set of OutGen. Other notations are the same as Table</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Transactions of the Association for Computational Linguistics, vol. 10, pp. 434-451, 2022. https://doi.org/10.1162/tacl a 00469 Action Editor: Dipanjan Das. Submission batch: 10/2021; Revision batch: 12/2021; Published 4/2022. c 2022 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">The LOT benchmark, the pretraining resources, and the appendix are available at https://github.com/thu -coai/LOT-LongLM.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">https://github.com/fxsjy/jieba.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the National Science Foundation for Distinguished Young Scholars (no. 62125604) and the NSFC projects (Key project no. 61936010 and regular project no. 61876096). This work was also supported by the Guoqiang Institute of Tsinghua University, with grant nos. 2019GQG1 and 2020GQG0005. We would also like to thank our action editor, Dipanjan Das, and the anonymous reviewers for their invaluable suggestions and feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic extraction of social networks from literary text: A case study on alice in wonderland</title>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anup</forename><surname>Kotalwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
				<meeting>the Sixth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1202" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">STORIUM: A Dataset and evaluation platform for machine-in-the-loop story generation</title>
		<author>
			<persName><forename type="first">Nader</forename><surname>Akoury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shufan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Hood</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.525</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.emnlp-main.525" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6470" to="6484" />
		</imprint>
	</monogr>
	<note>Online, Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning latent personas of film characters</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="352" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Abductive commonsense reasoning</title>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling protagonist emotions for emotion-aware storytelling</title>
		<author>
			<persName><forename type="first">Faeze</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.426</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.emnlp-main.426" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5277" to="5294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ilya Sutskev</title>
		<imprint/>
	</monogr>
	<note>and Dario Amodei. 2020. Language models are few-shot learners</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised learning of narrative event chains</title>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
				<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised learning of evolving relationships between literary characters</title>
		<author>
			<persName><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling evolving relationships between characters in literary novels</title>
		<author>
			<persName><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluation benchmarks and learning criteria for discourse-aware sentence representations</title>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zewei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1060</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1060" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="649" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Senteval: An evaluation toolkit for universal sentence representations</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation</title>
				<meeting>the Eleventh International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Revisiting pre-trained models for Chinese natural language processing</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="657" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Transformer-xl: Attentive language models beyond a fixed-length context</title>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2978" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hierarchical neural story generation</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning narrative structure from annotated folktales</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><surname>Finlayson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Fleis</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0031619</idno>
		<ptr target="https://doi.org/10.1037/h0031619" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="378" to="382" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tosin</forename><surname>Adewumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karmanya</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Sasanka Ammanamanchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aremu</forename><surname>Anuoluwapo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghavi</forename><surname>Khyathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miruna</forename><surname>Chandu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Clinciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaustubh</forename><forename type="middle">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Dhole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esin</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Emezue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Gangal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Garbacea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufang</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfeng</forename><surname>Jhamtani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shailza</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Jolly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounica</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khyati</forename><surname>Maddela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saad</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><surname>Mahamood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasad</forename><surname>Bodhisattwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Henrique</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><surname>Mille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moin</forename><surname>Emiel Van Miltenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rubungo</forename><surname>Nikolaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salomey</forename><surname>Andre Niyongabo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Osei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">Perez</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niranjan</forename><surname>Beltrachini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Diego</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sashank</forename><surname>Santhanam</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.gem-1.10</idno>
		<idno type="arXiv">arXiv:2102.01672</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.gem-1.10" />
		<title level="m">The GEM benchmark: Natural language generation, its evaluation and metrics</title>
				<editor>
			<persName><forename type="first">João</forename><surname>Sedoc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thibault</forename><surname>Sellam</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Samira</forename><surname>Shaikh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marco</forename><surname>Antonio Sobrevilla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hendrik</forename><surname>Cabezudo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nishant</forename><surname>Strobelt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wei</forename><surname>Subramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Diyi</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Akhila</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jiawei</forename><surname>Yerukola</surname></persName>
		</editor>
		<editor>
			<persName><surname>Zhou</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A knowledgeenhanced pretraining model for commonsense story generation</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00302</idno>
		<ptr target="https://doi.org/10.1162/tacl_a_00302" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="93" to="108" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">UNION: An unreferenced metric for evaluating open-ended story generation</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.736</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.emnlp-main.736" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="9157" to="9166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Story ending generation with incremental encoding and commonsense knowledge</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33016473</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33016473" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6473" to="6480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">OpenMEVA: A benchmark for evaluating open-ended story generation metrics</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhexin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoer</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zitao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbiao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changjie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.500</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.acl-long.500" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<title level="s">Long Papers</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6394" to="6407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stylized story generation with style-guided planning</title>
		<author>
			<persName><forename type="first">Xiangzhe</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziquan</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.215</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.findings-acl.215" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2430" to="2436" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2012</idno>
		<ptr target="https://doi.org/10.18653/v1/D18-2012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.acl-main.703" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Story generation with crowdsourced plot graphs</title>
		<author>
			<persName><forename type="first">Boyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Lee-Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter</title>
				<meeting>the 2016 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
				<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Dayiheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhen</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiusheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruofei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winnie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11928</idno>
		<title level="m">GLGE: A new general language generation evaluation benchmark</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep dungeons and dragons: Learning character-action interactions from role-playing game transcripts</title>
		<author>
			<persName><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2111</idno>
		<ptr target="https://doi.org/10.18653/v1/N18-2111" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Short Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="708" to="713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.07843</idno>
		<title level="m">Pointer sentinel mixture models</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1098</idno>
		<ptr target="https://doi.org/10.18653/v1/N16-1098" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
				<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">BLEU: A method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
				<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">COINS: Dynamically generating COntextualized inference rules for narrative story completion</title>
		<author>
			<persName><forename type="first">Debjit</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.395</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.acl-long.395" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<title level="s">Long Papers</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5086" to="5099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Improving language understanding with unsupervised learning</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Compressive transformers for long-range sequence modelling</title>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Potapenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chloe</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Hillier</surname></persName>
		</author>
		<author>
			<persName><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Plotmachines: Outlineconditioned generation with dynamic plot state tracking</title>
		<author>
			<persName><forename type="first">Asli</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.349</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.emnlp-main.349" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4274" to="4295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Behavioral testing of NLP models with CheckList</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.442</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.acl-main.442" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Reasoning about entailment with neural attention</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Kociský</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1509.06664" />
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations, ICLR 2016</title>
				<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-02">2016. May 2-4, 2016</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automatic keyword extraction from individual documents</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Cowley</surname></persName>
		</author>
		<idno type="DOI">10.1002/9780470689646.ch1</idno>
		<ptr target="https://doi.org/10.1002/9780470689646.ch1" />
	</analytic>
	<monogr>
		<title level="m">Text Mining: Applications and Theory</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Superglue: Learning feature matching with graph neural networks</title>
		<author>
			<persName><forename type="first">Paul-Edouard</forename><surname>Sarlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00499</idno>
		<ptr target="https://doi.org/10.1109/CVPR42600.2020.00499" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4938" to="4947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The effect of different writing tasks on linguistic style: A case study of the ROC story cloze task</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leila</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K17-1004</idno>
		<ptr target="https://doi.org/10.18653/v1/K17-1004" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
				<meeting>the 21st Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017. CoNLL 2017</date>
			<biblScope unit="page" from="15" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Tackling the story ending biases in the story cloze test</title>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omid</forename><surname>Bakhshandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2119</idno>
		<ptr target="https://doi.org/10.18653/v1/P18-2119" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="752" to="757" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Long range arena: A benchmark for efficient transformers</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dara</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5446</idno>
		<ptr target="https://doi.org/10.18653/v1/W18-5446" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">T-CVAE: Transformer-based conditioned variational autoencoder for story completion</title>
		<author>
			<persName><forename type="first">Tianming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019</title>
				<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10">2019. August 10-16, 2019</date>
			<biblScope unit="page" from="5233" to="5239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">CLUE: A Chinese language understanding evaluation benchmark</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yechen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
				<meeting>the 28th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020a</date>
			<biblScope unit="page" from="4762" to="4772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">MEGATRON-CNTRL: Controllable story generation with external knowledge using large-scale language models</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020b. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="2831" to="2845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Aditya Barua, and Colin Raffel. 2021. mt5: A massively multilingual pre-trained text-to-text transformer</title>
		<author>
			<persName><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Siddhant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Plan-and-write: Towards better automatic storytelling</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33017378</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33017378" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7378" to="7385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Xiaoyan Zhu, and Maosong Sun</title>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusheng</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haozhe</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanchao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaozhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoyang</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huanqi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenbo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aiopen.2021.07.001</idno>
		<idno type="arXiv">arXiv:2012.00413</idno>
		<ptr target="https://doi.org/10.1016/j.aiopen.2021.07.001" />
	</analytic>
	<monogr>
		<title level="m">CPM: A large-scale generative Chinese pre-trained language model</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">UER: An open-source toolkit for pre-training models</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinbin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haotang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyong</forename><surname>Du</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3041</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-3041" />
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP 2019241</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
