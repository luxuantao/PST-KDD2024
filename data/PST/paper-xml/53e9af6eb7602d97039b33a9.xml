<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved diagnostics for the incipient faults in analog circuits using LSSVM based on PSO algorithm with Mahalanobis distance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-01-09">9 January 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Bing</forename><surname>Long</surname></persName>
							<email>longbing@uestc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Automation Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China (UESTC)</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weiming</forename><surname>Xian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China (UESTC)</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China (UESTC)</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Houjun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China (UESTC)</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved diagnostics for the incipient faults in analog circuits using LSSVM based on PSO algorithm with Mahalanobis distance</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-01-09">9 January 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">BB4747CEA234AC0738EFF5A901652CDC</idno>
					<idno type="DOI">10.1016/j.neucom.2013.11.012</idno>
					<note type="submission">Received 26 December 2012 Received in revised form 5 September 2013 Accepted 11 November 2013 Communicated by J. Vandewalle</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Analog circuits Diagnostics Feature vector selection Least squares support vector machine Mahalanobis distance Particle swarm optimization</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diagnostics of incipient faults for analog circuits is very important, yet very difficult. Traditionally, the soft faults can only be diagnosed under the occurrence of large variation of component parameters. In this paper, a novel approach for diagnosing incipient faults in analog circuits is proposed. First, a statistical property feature vector composed of range, mean, standard deviation, skewness, kurtosis, entropy and centroid is proposed. Then, the least squares support vector machine (LSSVM) is used for diagnostics of the incipient faults. Conventionally, multi-fault diagnosis for analog circuits based on SVM usually used a single feature vector to train all binary SVM classifier. However, in fact, each binary SVM classifier has different classification accuracy for different feature vectors. Thus, the particle swarm optimization (PSO) based on Mahalanobis distance (MD) is proposed to select a near-optimal feature vector for each binary classifier. The experimental results for three analog circuits show: (1) the accuracy using the near-optimal feature vectors is better than the accuracy using a single feature vector, and is also better than the accuracy using the optimal single feature vector; (2) the accuracy using the near-optimal feature vectors is close to the accuracy using the optimal feature vectors selected by the exhaustive method; (3) the accuracy using the near-optimal feature vectors based on LSSVM is better than the accuracy obtained by hidden Markov model; (4) the consuming time of the near-optimal feature vectors selected by MD is reduced by about 98% in comparison to the time of the optimal feature vectors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Fault diagnosis and fault location in analog and mixed signal circuits are important issues for design validation and prototype characterization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. In contrast to the well-developed automatic fault diagnosis methodologies for digital circuits, diagnostics of analog circuits is far less advanced due the following reasons <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>: <ref type="bibr" target="#b0">(1)</ref> It is impossible to define any unified fault model for analog circuits owing to the parameters of analog components are usually continuous. <ref type="bibr" target="#b1">(2)</ref> In practical circuit under tests (CUTs), the information used in diagnostics is not sufficient because of lack of test node. (3) Tolerance effects of the analog components are difficult to eliminate. Therefore, fault diagnosis of analog circuits has become an active research; and now, diagnostic methods for analog circuits are mainly classified into two categories <ref type="bibr" target="#b5">[6]</ref>: simulation before test (SBT) and simulation after test (SAT). The SAT method implements costly circuit simulation and computation in test phase, which should be carried out in real time. SBT is more acceptable by the industry because only one off-line computation is required before test activities <ref type="bibr" target="#b6">[7]</ref>. Among SBT, data-driven diagnostic methods, such as neural networks (NNs) and support vector machines (SVMs) are more suitable for diagnostics of analog circuits because they do not need an explicit model <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>.</p><p>Among data-driven diagnostic methods, whether NNs or SVMs, feature selection methods have become an apparent need for diagnostic methods. Aminian and Aminian <ref type="bibr" target="#b2">[3]</ref> and Cui and Wang <ref type="bibr" target="#b11">[12]</ref> proposed to use wavelet transform coefficients as features for diagnostic of analog circuits. For the preprocessing methods based on wavelet transform, it is difficult to decide what type of wavelet function and which level of wavelet decomposition should be used. Zhang et al. <ref type="bibr" target="#b5">[6]</ref> directly used output voltage as features to train a SVM classifier for diagnostics of analog circuits. The SVM classifier without preprocessing methods usually results in less classification accuracy and longer training time than a classifier with preprocessing methods. Long et al. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> have proposed frequency feature vectors for diagnostics of analog circuits based on least squares SVMs (LSSVMs) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. Though these feature vectors proposed by Long et al. can obtain high classification accuracy, they only focused on "hard faults" or "soft faults" with a large range of parameters variation.</p><p>However, more and more attention is being attached on the performance degradation monitoring so that failure can be predicted and prevented, and it is very important to identify the fault Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/neucom at its incipient stage and alter the operator before it develops into a catastrophic failure. This is referred as the condition-based maintenance (CBM). The diagnosis of the incipient faults, such as shifts in performance parameters, is crucial, yet very difficult. Xu et al. <ref type="bibr" target="#b4">[5]</ref> has proposed to use the output voltage, autoregressive-moving average (ARMA) coefficients, and wavelet transform coefficients as the combinational feature vector whose dimensions were reduced by linear discriminant analysis (LDA) to train hidden Markov model (HMM) for incipient fault diagnosis of analog circuits. Deng et al. <ref type="bibr" target="#b14">[15]</ref> has proposed to use the fault features extracted based on the fractional correlation and the subband Volterra series to train HMM for incipient fault diagnosis of nonlinear analog circuits. Zhu et al. <ref type="bibr" target="#b15">[16]</ref> has proposed to use the output voltage as feature vector whose dimensions was decreased by LDA to train multiple HMM-SVM (MHMM-SVM) for incipient fault diagnosis of analog circuits. The aforementioned incipient fault diagnosis methods are all based on HMM, and the difference mainly lies in their ways of extracting the feature. To improve the classification accuracy, we propose to employ LSSVM as the classifier. In addition, the extracting features of the aforementioned incipient fault diagnosis methods are unfamiliar to the operator. Hence, the statistical property feature vector which is familiar to operator and can reflect the global property of output response is used in this paper.</p><p>Multi-fault diagnosis for analog circuits based on SVM is typically solved by combining many binary SVM classifiers. Most researchers used a single feature vector to train all SVM binary classifiers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. However, each SVM binary classifier has different classification accuracy for different feature vectors. On the other hand, to obtain the high classification accuracy whilst reducing the physical size of feature vector, some method of feature selection that is capable of selecting the most significant features of a feature set must be used. Xu et al. <ref type="bibr" target="#b4">[5]</ref> and Zhu et al. <ref type="bibr" target="#b15">[16]</ref> both used the LDA to decrease the dimensions of the feature vector. Jack and Nandi <ref type="bibr" target="#b16">[17]</ref> proposed to use genetic algorithm (GA) to select the most significant features from a large set of possible features in machine condition monitoring. It is known that the evolutionary algorithm-particle swarm optimization (PSO) has many advantages, such as simple concept, easy implementation, and quick convergence <ref type="bibr" target="#b17">[18]</ref>, and the Mahalanobis distance (MD) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> is a useful way of determining similarity of an unknown sample to a known one. Therefore, the MD based on PSO is used to select a near-optimal feature vector for each binary classifier in this paper. This paper will focus on selecting a near-optimal feature vector for each binary classifier to diagnose the incipient faults of analog circuits based on LSSVM. A Leapfrog low-pass filter with incipient parametric faults, a self-adapting filter with incipient parametric faults and a Sallen-key band-pass filter with incipient parametric faults were used as CUTs in this paper. This paper is organized as follows: Section 2 describes the diagnostic procedure based on LSSVM for analog circuits. Section 3 briefly presents the statistical property feature vector of analog circuits. Section 4 proposes the near-optimal feature vector selected by MD based on PSO. Section 5 shows the simulation results of the three experimental circuits and the comparison results with other methods. Conclusions are drawn in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Diagnostic procedure based on LSSVM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">LSSVM principle</head><p>SVM <ref type="bibr" target="#b20">[21]</ref> classifier is an algorithm based on statistical learning theory and structural risk minimization in which the solution of the classification problem is characterized by a convex quadratic programming problem subject to the inequality constraints. LSSVM is a reformulation of standard SVM which was proposed by Suykens and Vandewalle <ref type="bibr" target="#b13">[14]</ref>. In contrast to SVM, the LSSVM uses a least squares cost function and involves equality constraints instead of inequalities in the problem formulation. As a result, the solution is obtained by solving a set of linear equations and hence, the computational complexity can be reduced <ref type="bibr" target="#b21">[22]</ref>. We consider first the case of two classes <ref type="bibr" target="#b13">[14]</ref>.</p><p>Given a training set of N data points</p><formula xml:id="formula_0">fðx i ; y i Þjx i A R n ; y i A fÀ1; þ 1gg; i ¼ 1; …; N<label>ð1Þ</label></formula><p>where x i and y i are the ith data point that belongs to a binary class y i . The support vector method approach aims at constructing a classifier of the form:</p><formula xml:id="formula_1">yðxÞ ¼ signðw T φðxÞþbÞ ð<label>2Þ</label></formula><p>where the nonlinear function φð U Þ maps the input feature space into a higher dimensional feature space by using the kernel functions, b is the basis term, and w is the weight vector of the same dimension as the feature space.</p><p>The parameters w and b can be obtained by solving the following optimization problem <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_2">min w;b;e Jðw; b; eÞ ¼ 1 2 w T w þ r 2 ∑ N i ¼ 1 e i 2<label>ð3Þ</label></formula><p>subject to the equality constraints</p><formula xml:id="formula_3">y i ðw T φðx i ÞþbÞ ¼ 1 Àe i ; i ¼ 1; …; N<label>ð4Þ</label></formula><p>where r is the regularization parameter determining the trade-off between the training error minimization and smoothness of the estimated function, e i is the nonnegative error for misclassification.</p><p>Then, Lagrangian function is used to solve the optimization problem as follows:</p><p>Lðw; b; e; aÞ ¼ Jðw; b; eÞÀ</p><formula xml:id="formula_4">∑ N i ¼ 1 a i y i ðw T φðx i ÞþbÞÀ1 þ e i É È<label>ð5Þ</label></formula><p>Finally, the resulting LSSVM classifier is given by</p><formula xml:id="formula_5">yðxÞ ¼ sign ∑ N i ¼ 1 a i y i Kðx; x i Þþb !<label>ð6Þ</label></formula><p>where Kðx; x i Þ ¼ φðx i Þ T φðxÞ is the kernel function. Typically the kernel function has the following choices: Kðx;</p><formula xml:id="formula_6">x i Þ ¼ expðÀjjx i À xjj 2 =s 2 Þ (radial basis function (RBF) kernel); Kðx; x i Þ ¼ x i T x (linear kernel); Kðx; x i Þ ¼ ðτ þ x i</formula><p>T xÞ d (polynomial kernel of degree d). The support values a i are proportional to the error of the corresponding training data points. This implies that every training data point is a support vector and no sparseness property remains in the LSSVM formulation <ref type="bibr" target="#b21">[22]</ref>. The LSSVM model parameters <ref type="bibr" target="#b22">[23]</ref> are tuned through cross-validation technique in this paper.</p><p>Multi-class pattern recognition problems are typically solved by combining many binary classification SVMs, such as oneagainst-one SVM (OAOSVM), one-against-all SVM (OAASVM), and directed acyclic graphic SVM (DAGSVM) <ref type="bibr" target="#b23">[24]</ref>. Based on <ref type="bibr" target="#b23">[24]</ref>, OAOSVM is more suitable for practical use for diagnostics of analog circuits than the others. OAOSVM for k-class classification consists of k(k À 1)/2 binary classifiers, where each classifier is trained by the data from two classes according to the LSSVM algorithm. Then, the voting mechanism is applied for the future testing after all k(k À 1)/2 binary classifiers are constructed, and the decision function is shown as follows <ref type="bibr" target="#b23">[24]</ref>:</p><formula xml:id="formula_7">y ij ðxÞ ¼ signðw ij T φðxÞþb ij Þ ð<label>7Þ</label></formula><p>where w ij and b ij are the weight vector and bias of the ith and the jth classes, respectively.</p><p>If signðw ij T φðxÞþb ij Þ denotes x is in the ith class, then the vote of the ith class is added by one. Otherwise, the jth class is added by one. Finally, x is predicted in the class with the largest votes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Diagnostic procedure</head><p>A diagnostic procedure for analog circuits based on LSSVM involves four phases <ref type="bibr" target="#b9">[10]</ref>, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Though data collecting is a time-consuming work, it is not too difficult in technique. In the training phase and diagnostic phase, a well-made LSSVM toolbox, such as LSSVMlab toolbox <ref type="bibr" target="#b12">[13]</ref>, can be directly used in the diagnosis of analog circuits. The LSSVMlab toolbox can help us avoid duplicated work and make the diagnostic program reliable. The preprocessing is a key phase, which will focus on how to define the feature vectors of CUTs and how to select a near-optimal feature vector to train LSSVM classifier. These two problems in the preprocessing phase will be detailed in Sections 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Feature vector of analog circuits</head><p>To determine the global properties of the response curve, the statistical property features familiar to operator are proposed. Yuan et al. <ref type="bibr" target="#b3">[4]</ref> proposed to use kurtosis and entropy as features to train NNs for diagnostics of analog circuits. Gao et al. <ref type="bibr" target="#b24">[25]</ref> also proposed to apply kurtosis and entropy as features to train RVM for diagnostics of analog circuits. Zheng et al. <ref type="bibr" target="#b25">[26]</ref> proposed to employ kurtosis, negentropy as features to train NNs for diagnosis of analog circuits. Kurtosis and entropy are two good features for diagnosis based on classifiers. However, they may provide insufficient information for diagnosing faults in some analog circuits. Therefore, besides these two features, we propose to add range, mean, standard deviation, skewness, and centroid <ref type="bibr" target="#b25">[26]</ref> to constitute the feature vector, i.e.</p><formula xml:id="formula_8">F ¼ ½w; m; v; s; k; e; n ð<label>8Þ</label></formula><p>where w, m, v, s, k, e, n are range, mean, standard deviation, skewness, kurtosis, entropy, and centroid of response signal x respectively. The range which is a measure of the maximum scope of the changes of the data is defined as follows:</p><formula xml:id="formula_9">w ¼ x max Àx min<label>ð9Þ</label></formula><p>The mean value and standard deviation of signal x are defined as below:</p><formula xml:id="formula_10">m ¼ EðxÞ ð 10Þ v ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffi varðxÞ p ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi Eðx À mÞ 2 q<label>ð11Þ</label></formula><p>The skewness which is a measure of the asymmetry of the data around the mean value is defined as follows <ref type="bibr" target="#b27">[28]</ref>:</p><formula xml:id="formula_11">s ¼ ½Eðx À mÞ 3 v 3<label>ð12Þ</label></formula><p>where v is the standard deviation. Kurtosis is defined in the zero-mean case by the following equation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>:</p><formula xml:id="formula_12">kurtðxÞ ¼ Efx 4 gÀ3½Efx 2 g 2<label>ð13Þ</label></formula><p>Kurtosis is a measure of the heaviness of tails in distribution of signal x and can be used to establish an effective statistical test in identifying changes of signals <ref type="bibr" target="#b26">[27]</ref>.</p><p>Entropy is a fundamental concept of the information theory. The entropy H of a random variable x with density p(x) is defined as follows <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>:</p><formula xml:id="formula_13">HðxÞ ¼ À Z pðxÞlog pðxÞdx<label>ð14Þ</label></formula><p>However, during the analog circuit fault diagnosis, it is very difficult to calculate the kurtosis and entropy based on Eqs. ( <ref type="formula" target="#formula_12">13</ref>) and ( <ref type="formula" target="#formula_13">14</ref>). Usually, the unbiased estimate or approximation is used to obtain kurtosis and entropy. Then, Eq. ( <ref type="formula" target="#formula_12">13</ref>) can be written as follows <ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_14">kurtðxÞ ¼ Efx 4 g ½Efx 2 g 2 ¼ M ∑ M n ¼ 1 x 4 ðnÞ ∑ M n ¼ 1 x 2 ðnÞ À Á 2<label>ð15Þ</label></formula><p>where M is the length of the signal. And Eq. ( <ref type="formula" target="#formula_13">14</ref>) can be approximated as follows <ref type="bibr" target="#b24">[25]</ref>:</p><formula xml:id="formula_15">HðxÞ % k 1 ðEfG 1 ðxÞgÞ 2 þ k 2 ðEfG 2 ðxÞg À ffiffiffiffiffiffiffiffi 1=2 p Þ 2<label>ð16Þ</label></formula><p>where</p><formula xml:id="formula_16">k 1 ¼ 36=ð8 ffiffiffi 3 p À 9Þ, k 2 ¼ 24=ð16 ffiffiffi 3 p À 27Þ, G 1 ðxÞ ¼ x exp ðÀx 2 =2Þ, G 2 ðxÞ ¼ expðÀx 2 =2Þ.</formula><p>The centroid of the closed region which is formed by the waveform of signal and axes can be obtained as follows <ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_17">u 0 ¼ R þ 1 À 1 ugðuÞdu R þ 1 À 1 gðuÞdu<label>ð17Þ</label></formula><p>For a zero-mean discrete-valued signal, Eq. ( <ref type="formula" target="#formula_17">17</ref>) can be written as follows:</p><formula xml:id="formula_18">n 0 ¼ ∑ M n ¼ 1 n Â xðnÞ ∑ M n ¼ 1 xðnÞ<label>ð18Þ</label></formula><p>where M is the length of the signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Feature vector selected by MD based on PSO</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Mahalanobis distance</head><p>Mahalanobis distance is a distance measure introduced by Mahalanobis <ref type="bibr" target="#b18">[19]</ref> in 1936. The MD methodology distinguishes multivariable data groups by a univariate distance measure that is calculated from the measurements of multiple parameters <ref type="bibr" target="#b19">[20]</ref>.</p><p>The definition of MD methodology for a CUT samples is as follows: the observation of the jth feature vector for a CUT with fault class F k , on the ith sample is denoted by X ij , where i ¼ 1; 2; …; n and j ¼ 1; 2; …; m; m is the dimension of the feature vector, and n is the number of samples. The observation for a CUT with fault class F l using the same feature as F k are denoted by Y l ; then, the Mahalanobis distance of a multivariable vector Y l ¼ ½y 1 ; y 2 ; …; y m l from F l with mean u ¼ ½u 1 ; u 2 ; …; u m and covariance matrix S ¼ ½s ij is defined as follows:</p><formula xml:id="formula_19">MD F k ðY l Þ ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi ðY l À uÞS À 1 ðY l À uÞ T q<label>ð19Þ</label></formula><p>Data Collecting Phase where</p><note type="other">Preprocessing Phase Training Phase Daignostic Phase</note><formula xml:id="formula_20">u i ¼ 1 m ∑ m j ¼ 1 X ij ; s ij ¼ covðX i ; X j Þ ¼ E½ðX i À u i ÞðX j À u j Þ:</formula><p>The MD approach can provide a number for gauging similarity of an unknown sample set to a known one. Generally, the two samples are more similar, and more possible to belong to the same fault class if their MD value is smaller. Thus, MD can be used to classify samples from two different fault classes. Based on this idea, the feature vector with high recognition rate classified by MD is used to train and test LSSVM classifier for any two fault classes of analog circuits. But MD is just one kind of similarity metrics and cannot find an optimal feature vector for any data set. Therefore, the feature vector with high recognition rate classified by MD is a near-optimal vector, not an optimal one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Particle swarm optimization</head><p>In 1995, Kennedy and Eberhart proposed PSO algorithm inspired by the foraging behavior of birds <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29]</ref>. The PSO algorithm has many advantages, such as simple concept, easy implementation, and quick convergence <ref type="bibr" target="#b17">[18]</ref>. Therefore it has been widely used in many fields such as function optimization, neural network training, data mining and fuzzy systems etc.</p><p>Its basic idea is that each solution of an optimization problem is called a particle and a fitness function is defined to measure the degree of superiority of every particle <ref type="bibr" target="#b29">[30]</ref>. In a PSO system, it starts with the random initialization of a population of particles in the search space and works on the social behavior in the swarm. The position and the velocity of the ith particle in the d-dimensional search space can be represented as X i ¼ ½x i;1 ; x i;2 ; …; x i;d and V i ¼ ½v i;1 ; v i;2 ; …; v i;d , respectively. Every particle has its own best position (pbest) P i ¼ ½p i;1 ; p i;2 ; …; p i;d corresponding to the personal best objective value obtained at time t. The global best particle (gbest) is denoted by P g ¼ ½p g;1 ; p g;2 ; …; p g;d which represents the best particle found so far in the entire swarm <ref type="bibr" target="#b30">[31]</ref>. The new velocity and position of every particle are updated based on the following equations <ref type="bibr" target="#b28">[29]</ref>:</p><formula xml:id="formula_21">v i;j ðt þ 1Þ ¼ wv i;j ðtÞþc 1 r 1 ðp i;j Àx i;j ðtÞÞ þ c 2 r 2 ðp g;j À x i;j ðtÞÞ<label>ð20Þ</label></formula><p>where c 1 and c 2 are acceleration coefficients, which are often set the random value between [0,2]; w is inertia weight coefficient; r 1 and r 2 are two independent random numbers uniformly distributed in the range of [0,1]. The optimization performance of PSO is largely affected by the value of the inertia weight coefficient w. Some studies show that a large weight coefficient is in favor of avoiding local minimum and a small weight coefficient contributes to convergence rate. Generally, to enhance the global searching capability, a large value is given to the weight coefficient at the initial stage of searching. Then, the weight coefficient is set to a small value to speed up the convergence rate at the later period of searching. Therefore, the adaptive weight method is adopted as the following <ref type="bibr" target="#b31">[32]</ref>:</p><formula xml:id="formula_22">w k ¼ w max À ðw max Àw min Þ iteor k<label>ð21Þ</label></formula><p>where k is the iteration numbers at present, iteor is the total iteration numbers, w max ¼ 1:2; w min ¼ 0:5. The choice of fitness function is another primary factor to influence the performance of the PSO algorithm. To find a near-optimal feature vector, the feature vector with high recognition rate classified by MD should be selected. Therefore, the fitness function is chosen as the maximum of recognition rate classified by MD.</p><p>It is known that the PSO algorithm adepts in real number coding. In order to select the near-optimal feature vectors easily, an additional step which converts a real number to a binary coding is added. Based on Eq. ( <ref type="formula" target="#formula_8">8</ref>), we use 7-bits to represent the original feature vector sequentially. For example, if the binary string is 0010101, then the standard deviation, kurtosis and centroid are selected.</p><p>The detail procedure of PSO is summarized as follows:</p><p>Step 1: Set the initial parameters of PSO, such as particle number, the largest iteration numbers, maximum velocity, acceleration constant and inertia weight coefficient.</p><p>Step 2: Calculate the fitness of every particle.</p><p>Step 3: Carry out Step 4 if the iteration numbers are less than the largest iteration numbers.</p><p>Step 4: Update the velocity and place of every particle using the adaptive weight coefficient algorithm according to the velocity and place at present.</p><p>Step 5: Compute the fitness of new place for every particle. If the fitness of the particle is smaller than the original individual extremum pbest, update the individual extremum. Otherwise, remain the same value.</p><p>Step 6: Get the latest global optimal solution gbest based on the individual fitness of every particle.</p><p>Step 7: Keep the old place, and update the velocity and place of each particle.</p><p>Step 8: Compare the fitness of old place with the fitness of new place. If the latter is less than the former, reserve the new place and the fitness of new place. Otherwise, reserve the old place and the fitness of old place.</p><p>Step 9: Run the Step 3.</p><p>Step 10: Acquire the optimal solution.</p><p>4.3. Near-optimal feature vector selected by MD based on PSO Since the feature vector with high recognition rate classified by MD may differ among every two fault classes, multiple binary LSSVM classifiers are used. The classification accuracy for the feature vector with high recognition rate classified by MD does not always have the optimal accuracy, but it is better than most of the feature vectors. Though it is not an optimal feature selection method, it provides an easy, effective approach to select a nearoptimal feature vector, which is useful for automatic testing and diagnosis of analog circuits.</p><p>The flowchart of the near-optimal diagnostic program based on LSSVM using the feature vector with high recognition rate classified by MD is shown in Fig. <ref type="figure" target="#fig_2">2</ref>. And, the flowchart of the near-optimal feature vector selected by MD based on PSO is shown in Fig. <ref type="figure" target="#fig_1">3</ref>.</p><p>Firstly, the near-optimal feature vector for each binary classifier is selected by MD based on PSO. Then, the near-optimal feature vector with high recognition rate classified by MD is used to train the binary classifier and the near-optimal diagnostic accuracy can be obtained for these two binary classifiers. Finally, the nearoptimal accuracy for all kinds of fault classes is the average of all the binary LSSVM classifiers' near-optimal accuracies.</p><p>To evaluate the performance of our proposed method, we have also implemented an optimal diagnostic procedure using an exhaustive method based on LSSVM classifier, as shown in Fig. <ref type="figure">4</ref>. In Fig. <ref type="figure">4</ref>, d represents the dimensions of the feature vector, and based on d, there are m ¼(2 d À 1) feature vector combinations for each binary classifier. In addition, in order to demonstrate that each SVM binary classifier has different classification accuracy for different feature vectors, an optimal diagnostic program using an exhaustive method based on LSSVM multiclass classifier using a single feature vector has also been implemented, as shown in Fig. <ref type="figure">5</ref>. In Fig. <ref type="figure">5</ref>, d and m are the same as in Fig. <ref type="figure">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments circuits and simulation results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">A leapfrog filter</head><p>The first experimental circuit is a leapfrog filter (Fig. <ref type="figure" target="#fig_3">6</ref>), which is a benchmark circuit of ITC97. This leapfrog filter consists of 13 resistors, 4 capacitors and 6 operational amplifiers. The nominal parameters for all the components are labeled in Fig. <ref type="figure" target="#fig_3">6</ref> and the tolerance of the resistors and capacitors are set to 5% and 10% respectively. There are many components in the filter, and some components such as R1, R2, R3, R4, R8 and C2 that are more sensitive to the test signal than the other components, are selected as the potential faulty components. For each of the faulty components, two soft-fault classes are shown as follows: a class for the component values larger than the nominal one (labeled by ↑) and the other for the component values smaller than the nominal one (labeled by ↓). Therefore, 12 fault classes, in addition to the faultfree condition, are simulated, and output of the leapfrog filter is used as the test node.</p><p>To identify the incipient faults of the leapfrog filter circuit, the fault interval for each faulty component is set to near its normal tolerance range. The fault intervals for all faulty components are listed in Table <ref type="table" target="#tab_1">1</ref>. Traditionally, during simulation, the fault value of the faulty components was usually set to be a fixed value in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>, and as a result, the fault dictionary established through this method is incomplete and has substantial deviation from the actual situation. To solve the problem, the mean value with tolerance method which is named as MVT is proposed. Faulty component R1 is used as an example to illustrate the basic idea of MVT. According to Fig. <ref type="figure" target="#fig_3">6</ref> and Table <ref type="table" target="#tab_1">1</ref>, the fault interval is [10.5 kΩ, 11.5 kΩ] when the fault value of R1 becomes larger. Then, the mean value of the fault interval is calculated as m ¼(10.5 þ11.5)/ 2 ¼11 kΩ. After that, the tolerance of the mean value needs to be found. It is found that the tolerance should be set to 4.5% owing to the following: 11n(1 þ4.5%) ¼11.495 kΩ, 11n(1 À4.5%) ¼10.505 kΩ. Therefore, the fault value of the faulty components can no longer be set to a fixed value, and then, based on Monte Carlo analysis, the complete and reasonable fault dictionary can be established. Based on the idea of MVT, the fault values of the leapfrog filter 0 s components are shown in Table <ref type="table" target="#tab_2">2</ref>. In our work, only single incipient fault has been considered.</p><p>To obtain the simulation fault data according to the fault classes in Table <ref type="table" target="#tab_2">2</ref> Generate the initial particles and speed.</p><p>Convert the real number to binary coding.</p><p>Compute the fitness of every particle based on the fitness function.</p><p>Update the velocity and place of every particle, and compute the fitness of new place for each particle.</p><p>Obtain individual extremum and the latest global optimal solution.</p><p>Compare the fitness of old place with the fitness of new place, then update the place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reach the largest iteration numbers?</head><p>Acquire the near-optimal feature vector for binary classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i&lt;n?</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head><p>Obtain the near-optimal feature vectors for all binary classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End</head><p>The ith binary classifier. LSSVM classification based on the near-optimal feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i&lt;n?</head><p>Average the accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No</head><p>The ith binary classifier. analysis method in OrCAD/Pspice 10.5 software are used. In the time-domain transient analysis, run-to-time and maximum step size are set as 3 ms and 1 μs respectively. In the Monte Carlo analysis, number of runs and use distribution are set to 600 and Gaussian respectively. Therefore, the simulated data for each fault class (including F0) are 600 sets. In each set, there are 3000 points in the time-domain transient response curve. The simulation data in OrCAD/Pspice are exported into "txt" files which can be imported into Matlab and be used to calculate their feature vectors. Based on the discussion in Section 3, the feature vectors are constructed according to Eqs. ( <ref type="formula" target="#formula_9">9</ref>)-( <ref type="formula" target="#formula_11">12</ref>), ( <ref type="formula" target="#formula_14">15</ref>), ( <ref type="formula" target="#formula_15">16</ref>) and <ref type="bibr" target="#b17">(18)</ref>. Then, 600 original samples for each fault class are divided into 300 training samples and 300 testing samples.</p><p>To obtain the high classification accuracy for each binary classifier whilst reducing the physical size of feature vector, some method of feature selection that is capable of selecting the most significant features of a feature set must be used. The MD based on PSO discussed in Section 4 is used in this paper for feature selection. The statistical property features such as range, mean, standard deviation, skewness, kurtosis, entropy and centroid of 50 test samples from class F0 and F1 for the leapfrog filter shown in Fig. <ref type="figure" target="#fig_4">7</ref> are used as an example to illustrate the feature selection necessity. According to Fig. <ref type="figure" target="#fig_4">7</ref>, it can be seen that the most significant feature of class F0 and F1 is the centroid. The class F0 and F1 can be classified accurately only based on the centroid while the other features are redundant. Therefore, selecting the most significant features of a feature set is necessary. The feature selection procedure of the MD based on PSO has been given in Fig. <ref type="figure" target="#fig_1">3</ref>.</p><p>There are 12 fault classes, in addition to the fault-free condition, and hence, the most significant features of 13n(13 À 1)/2 ¼78 binary classifiers need to be selected respectively. The optimization results for 78 binary classifiers are shown in Table <ref type="table" target="#tab_3">3</ref>. In Table <ref type="table" target="#tab_3">3</ref>, BC represents binary classifier and NOFV represents near-optimal feature vector. Based on Fig. <ref type="figure" target="#fig_4">7</ref> and Table <ref type="table" target="#tab_3">3</ref>, the nearoptimal feature vector for class F0 and F1 are kurtosis and centroid while the optimal feature is centroid. Though the optimal feature vector for class F0 and F1 is not selected, the dimensions of the original feature vector have decreased by 5. Therefore, the MD based on PSO for feature selection is reasonable and acceptable.</p><p>We want to illustrate the advantages of our proposed approach in four aspects. The details are as follows:</p><p>(1) To show the classification accuracy, we compare the average classification accuracy using the near-optimal feature vectors selected by MD based on PSO with the average classification accuracy using the optimal feature vectors selected by the exhaustive method for binary classifiers. The exhaustive method is described in Fig. <ref type="figure">4</ref>. The comparison result of 50 samples for each fault class (including fault-free F0) is shown in Fig. <ref type="figure">8</ref>. From Fig. <ref type="figure">8</ref>, it can be seen that the average classification accuracy of the near-optimal feature vectors is close to the accuracy of the optimal feature vectors. To illustrate the advantage of our proposed approach furthermore, the consuming time of selecting feature vectors based on MD using PSO and the exhaustive method is shown in Fig. <ref type="figure">9</ref> respectively. In Fig. <ref type="figure">9</ref>, time is measured in seconds. Based on Fig. <ref type="figure">9</ref>, the near-optimal feature vectors selected by MD based on PSO consumed about 1/57 as much time as the optimal feature vectors selected by the exhaustive method. In other words, the consuming time of the near-optimal feature vectors selected by MD based on PSO is reduced by about 98% in comparison to the time of the optimal feature vectors selected by the exhaustive method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Start</head><p>Input the training sets and testing sets.</p><p>Calculate the number of binary classifier, recorded as n.</p><p>i=1 to n</p><p>The ith binary classifier.</p><p>The binary classifier has m feature vector combinations owing to the dimension of the original feature vector is d.</p><p>m feature vector combinations are used to train LSSVM classifier respectively, and the diagnostic accuracy can be obtained respectively.</p><p>Find the highest accuracy and the optimal feature vector for this binary classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i&lt;n?</head><p>Average the best accuracies for all binary classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head><p>No Fig. <ref type="figure">4</ref>. Flowchart of an optimal diagnostic procedure using an exhaustive method based on LSSVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Start</head><p>Input the training sets and testing sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>End</head><p>There are m feature vector combinations owing to the dimension of the original feature vector is d.</p><p>i=1 to m</p><p>The ith feature vector.</p><p>The feature vector is used to train LSSVM multiclass classifiers, and the diagnostic accuracy can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i&lt;m?</head><p>Obtain the optimal diagnostic accuracy and the optimal feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head><p>No Fig. <ref type="figure">5</ref>. Flowchart of an optimal diagnostic program using an exhaustive method based on LSSVM multiclass classifier using a single feature vector.</p><p>(2) However, most researchers used a single feature vector to train all SVM binary classifiers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>. So we compare the average classification accuracy of the near-optimal feature vectors selected by MD based on PSO with a single feature vector used to train LSSVM. The training sets and testing sets which consist of 50, 100, 200, 250 and 300 samples for each fault class are used respectively. The comparison results of classification accuracy are shown in Fig. <ref type="figure" target="#fig_6">10</ref>. From Fig. <ref type="figure" target="#fig_6">10</ref>, our proposed approach has higher classification accuracy than the traditional a single feature vector used to train LSSVM. It demonstrates that each SVM binary classifier has different classification accuracy for different feature vectors. The comparison result of classification time is shown in Fig. <ref type="figure" target="#fig_7">11</ref>. In Fig. <ref type="figure" target="#fig_7">11</ref>, the classification time of the near-optimal feature vectors is measured after the near-optimal feature vector for each binary classifier has been selected. According to Fig. <ref type="figure" target="#fig_7">11</ref>, the classification time of the near-optimal feature vector for each binary classifier is larger than a single feature vector used to train LSSVM. Though the proposed approach takes a longer period, it does not affect the actual use of our proposed method. The reason is that most of the time is spent in training model for each binary classifier, while models are trained in advance before the testing process in actual application. In addition, we compare the average classification accuracy of the near-optimal feature vectors with the optimal single feature vector selected by the exhaustive method. The exhaustive method of selecting an optimal single feature vector for all binary classifiers has been described in Fig.</p><p>The comparison result of 50 samples for each fault class is shown in Fig. <ref type="figure" target="#fig_2">12</ref>. Moreover, the consuming time of selecting feature vectors based on MD using PSO and the exhaustive method of 50 samples for each fault class is shown in Fig. <ref type="figure" target="#fig_1">13</ref> respectively. From Figs. 12 and 13, it can be seen that the classification accuracy based on the near-optimal feature vectors is obviously higher than the optimal single feature vector for all binary classifiers. And the near-optimal feature vectors selected by MD based on PSO consumed about   1/42 as much time as the optimal single feature vector selected by the exhaustive method.</p><p>(3) GA was used to select the most significant features from a large set of possible features in machine condition monitoring in <ref type="bibr" target="#b16">[17]</ref>, while the PSO algorithm is applied in our work. Therefore, we compare the PSO algorithm with the GA algorithm in selecting the near-optimal feature vectors. The training sets and testing sets which consist of 50, 100, 200, 250 and 300 samples for each fault class are also used respectively. The initial parameters of GA are consistent with the PSO algorithm. The comparison result of average classification accuracy based on the near-optimal feature vectors selected by GA and PSO respectively is shown in Fig. <ref type="figure" target="#fig_0">14</ref>. And the consuming time of selecting the near-optimal feature vectors based on GA and PSO of 50 samples for each fault class respectively is shown in Fig. <ref type="figure" target="#fig_0">15</ref>. According to Figs. 14 and 15, the classification accuracy based on PSO is higher than GA, while the consuming time based on PSO is longer than GA. The reason for longer period of PSO than GA is that GA is good at binary coding while PSO adepts in real number coding. Therefore, in the procedure of selecting the near-optimal feature vectors based on PSO, an additional step which converts a real number to a binary    Accuracy(%)</p><p>Fig. <ref type="figure" target="#fig_2">12</ref>. The diagnostic accuracy based on the near-optimal feature vectors and the optimal single feature vector respectively.</p><p>coding is added. Then, based on Figs. 9 and 13, the consuming time of PSO is obviously shorter than the exhaustive method. So the PSO used in our work is reasonable and acceptable.</p><p>(4) The traditional Euclidean distance is simple and being used widely. To illustrate the advantage of MD in selecting the nearoptimal feature vectors, we compare the classification accuracy based on MD with the Euclidean distance. The training sets and testing sets which consist of 50, 100, 200, 250 and 300 samples for each fault class are also used respectively. The comparison result is shown in Fig. <ref type="figure" target="#fig_3">16</ref>. From Fig. <ref type="figure" target="#fig_3">16</ref>, it can be seen that MD is more suitable than Euclidean distance in selecting the near-optimal feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">A self-adapting filter</head><p>The second experimental circuit is a self-adapting filter (Fig. <ref type="figure" target="#fig_10">17</ref>), and is used as a CUT in <ref type="bibr" target="#b4">[5]</ref>. It operates as a low-pass, band-pass, and high-pass filter at node 1, 2, and 3, respectively. This self-adapting filter consists of 6 resistors, 2 capacitors and 3 operational amplifiers. The nominal parameters for all the components are labeled in Fig. <ref type="figure" target="#fig_10">17</ref>. To compare with literature <ref type="bibr" target="#b4">[5]</ref>, the tolerance of the resistors and capacitors are set to 10% and 5% respectively. The fault intervals for all faulty components are listed in Table <ref type="table">4</ref>. And based on the idea of MVT discussed in the first experiment, the fault values of the self-adapting filter 0 s components are shown in Table <ref type="table">5</ref>. Thus, 10 fault classes, in addition to the   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Fault intervals for all faulty components. fault-free condition, are simulated, and node 3 is selected as the test node. Only single soft fault is considered here.</p><p>In the time-domain transient analysis, run-to-time and maximum step size are set as 1 ms and 1 μs respectively. In the Monte Carlo analysis, number of runs and use distribution are set to 600 and Gaussian respectively. Therefore, the simulated data for each fault class (including F0) are 600 sets. In each set, there are 1000 points in the time-domain transient response curve. Then, 600 original samples for each fault class are divided into 300 training samples and 300 testing samples.</p><p>The procedure of the MD based on PSO for feature selection has been illustrated in the first experiment. The LDA and HMM were used to diagnose the incipient faults of the self-adapting filter in <ref type="bibr" target="#b4">[5]</ref>. Thus, we compare the proposed method with the method in <ref type="bibr" target="#b4">[5]</ref>. The comparison of classification accuracy is shown in Table <ref type="table" target="#tab_4">6</ref>. From Table <ref type="table" target="#tab_4">6</ref>, it can be seen that the average classification accuracy of the proposed method is obviously higher than the method in <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">A Sallen-key band-pass filter</head><p>The last experimental circuit is a Sallen-key band-pass filter (Fig. <ref type="figure" target="#fig_0">18</ref>), and is used as a CUT in <ref type="bibr" target="#b15">[16]</ref>. This Sallen-key band-pass filter consists of 5 resistors, 2 capacitors and 1 operational amplifier. The nominal parameters for all the components are labeled in Fig. <ref type="figure" target="#fig_0">18</ref>. To compare with literature <ref type="bibr" target="#b15">[16]</ref>, the tolerance of the resistors and capacitors are set to 5% and 5% respectively. The fault intervals for all faulty components are listed in Table <ref type="table" target="#tab_5">7</ref>. And the fault values of the Sallen-key band-pass filter 0 s components are shown in Table <ref type="table" target="#tab_6">8</ref>. Thus, 10 fault classes, in addition to the fault-free condition, are simulated, and output of the Sallen-key band-pass filter is used as the test node. Only single soft fault is considered here.</p><p>In the time-domain transient analysis, run-to-time and maximum step size are set as 100 μs and 1 μs respectively. In the Monte Carlo analysis, number of runs and use distribution are set to 100 and Gaussian respectively. Therefore, the simulated data for each fault class (including F0) are 100 sets. In each set, there are 100 points in the time-domain transient response curve. Then, 100 original samples for each fault class are divided into 50 training feature vectors and 50 testing samples.</p><p>The procedure of the MD based on PSO for feature selection has been illustrated in the first experiment. Zhu et al. <ref type="bibr" target="#b15">[16]</ref> proposed to use the output voltage as feature vector whose dimensions was decreased by LDA to train MHMM-SVM for incipient fault diagnosis of the Sallen-key band-pass filter. Therefore, we compare the proposed method with the method in <ref type="bibr" target="#b15">[16]</ref>. The comparison of classification accuracy is shown in Table <ref type="table" target="#tab_7">9</ref>. From Table <ref type="table" target="#tab_7">9</ref>, it can be seen that the average classification accuracy of the proposed method is higher than the method in <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>A near-optimal feature vector selected by MD based on PSO has been proposed for diagnostics of the incipient faults in analog  circuits using LSSVM. Through the simulation results for the three filters with parametric faults, we can draw the following conclusions:</p><p>(1) The accuracy using the near-optimal feature vectors is better than the accuracy using a single feature vector, and is also better than the accuracy using the optimal single feature vector.</p><p>(2) The accuracy using the near-optimal feature vectors is close to the accuracy using the optimal feature vectors selected by the exhaustive method. (3) The accuracy using the near-optimal feature vectors based on LSSVM is better than the accuracy obtained by HMM. (4) The consuming time of the near-optimal feature vectors selected by MD based on PSO is reduced by about 98% in comparison to the time of the optimal feature vectors.</p><p>The proposed method provides a tradeoff between diagnostic accuracy and time for diagnostics of the incipient faults in analog circuits, which is beneficial for analog IC or circuits testing and diagnosis. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A diagnostic procedure based on LSSVM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Flowchart of the near-optimal feature vector selected by MD based on PSO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Flowchart of the near-optimal diagnostic program based on LSSVM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Schematic of a leapfrog filer circuit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The statistical property feature for F0 and F1 of the leapfrog filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig.8. The diagnostic accuracy based on the near-optimal feature vectors and the optimal feature vectors respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. The diagnostic accuracy based on the near-optimal feature vectors and a single feature vector respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. The consuming time based on the near-optimal feature vectors and a single feature vector respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 13 .Fig. 14 .</head><label>1314</label><figDesc>Fig.<ref type="bibr" target="#b12">13</ref>. The consuming time based on the near-optimal feature vectors and the optimal single feature vector respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 15 .Fig. 16 .</head><label>1516</label><figDesc>Fig.<ref type="bibr" target="#b14">15</ref>. The consuming time based on the near-optimal feature vectors selected by PSO and GA respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Schematic of a self-adapting filter circuit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Min</head><label></label><figDesc>Li recevied the M.S. degree from Harbin Institute of Technology, Harbin, China, in 2009, and is currently Ph.D. candidate in the University of Electronic Science and Technology of China, Chengdu, China. His current research interests include diagnostics, prognostics for circuits and systems. Houjun Wang received M.Sc. and Ph.D. degrees in Information and Signal Processing from the University of Electronics Science and Technology of China (UESTC) in 1985 and 1992, respectively. He is currently a professor at and has been a vice president of UESTC from 2005. His research interests include time domain measurement and signal processing, design for testability of complex systems, architecture of auto test systems, and fault diagnosis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, a time-domain transient analysis and a Monte Carlo</figDesc><table><row><cell>Start</cell></row><row><cell>Input training sets and testing sets which consist</cell></row><row><cell>of 50 feature vectors for each fault class.</cell></row><row><cell>Calculate the number of binary</cell></row><row><cell>classifier, recorded as n.</cell></row><row><cell>i=1 to n</cell></row><row><cell>Initialize the parameters of</cell></row><row><cell>PSO algorithm.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Fault intervals for all faulty components.</figDesc><table><row><cell>Faulty Component</cell><cell>↑</cell><cell>↓</cell></row><row><cell>R1</cell><cell>[1.05Yn a ─1.15Yn]</cell><cell>[0.85Yn─0.95Yn]</cell></row><row><cell>R2</cell><cell>[1.05Yn─1.15Yn]</cell><cell>[0.85Yn─0.95Yn]</cell></row><row><cell>R3</cell><cell>[1.05Yn─1.15Yn]</cell><cell>[0.85Yn─0.95Yn]</cell></row><row><cell>R4</cell><cell>[1.05Yn─1.15Yn]</cell><cell>[0.85Yn─0.95Yn]</cell></row><row><cell>R8</cell><cell>[1.05Yn─1.15Yn]</cell><cell>[0.85Yn─0.95Yn]</cell></row><row><cell>C2</cell><cell>[1.10Yn─1.20Yn]</cell><cell>[0.80Yn─0.90Yn]</cell></row></table><note><p>a Yn is the nominal value.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Nominal and fault value with tolerance.</figDesc><table><row><cell>Fault ID</cell><cell>Fault class</cell><cell>Nominal value</cell><cell>Fault value</cell><cell>Tolerance (%)</cell></row><row><cell>F0</cell><cell>NF</cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1</cell><cell>R1↑</cell><cell>10 kΩ</cell><cell>11 kΩ</cell><cell>7 4.5</cell></row><row><cell>F2</cell><cell>R1↓</cell><cell>10 kΩ</cell><cell>9 kΩ</cell><cell>7 5.5</cell></row><row><cell>F3</cell><cell>R2↑</cell><cell>10 kΩ</cell><cell>11 kΩ</cell><cell>7 4.5</cell></row><row><cell>F4</cell><cell>R2↓</cell><cell>10 kΩ</cell><cell>9 kΩ</cell><cell>7 5.5</cell></row><row><cell>F5</cell><cell>R3↑</cell><cell>10 kΩ</cell><cell>11 kΩ</cell><cell>7 4.5</cell></row><row><cell>F6</cell><cell>R3↓</cell><cell>10 kΩ</cell><cell>9 kΩ</cell><cell>7 5.5</cell></row><row><cell>F7</cell><cell>R4↑</cell><cell>10 kΩ</cell><cell>11 kΩ</cell><cell>7 4.5</cell></row><row><cell>F8</cell><cell>R4↓</cell><cell>10 kΩ</cell><cell>9 kΩ</cell><cell>7 5.5</cell></row><row><cell>F9</cell><cell>R8↑</cell><cell>10 kΩ</cell><cell>11 kΩ</cell><cell>7 4.5</cell></row><row><cell>F10</cell><cell>R8↓</cell><cell>10 kΩ</cell><cell>9 kΩ</cell><cell>7 5.5</cell></row><row><cell>F11</cell><cell>C2↑</cell><cell>20 nF</cell><cell>23 nF</cell><cell>7 4.5</cell></row><row><cell>F12</cell><cell>C2↓</cell><cell>20 nF</cell><cell>17 nF</cell><cell>7 5.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Near-optimal feature vector for each binary classifier.</figDesc><table><row><cell>BC</cell><cell></cell><cell>NOFV</cell><cell>BC</cell><cell></cell><cell>NOFV</cell><cell>BC</cell><cell></cell><cell>NOFV</cell></row><row><cell>F0</cell><cell>F1</cell><cell>0000101</cell><cell>F2</cell><cell>F6</cell><cell>1000101</cell><cell>F5</cell><cell>F8</cell><cell>0101001</cell></row><row><cell>F0</cell><cell>F2</cell><cell>0011111</cell><cell>F2</cell><cell>F7</cell><cell>0111101</cell><cell>F5</cell><cell>F9</cell><cell>1100111</cell></row><row><cell>F0</cell><cell>F3</cell><cell>1001111</cell><cell>F2</cell><cell>F8</cell><cell>1111111</cell><cell>F5</cell><cell>F10</cell><cell>1111011</cell></row><row><cell>F0</cell><cell>F4</cell><cell>0111001</cell><cell>F2</cell><cell>F9</cell><cell>1010111</cell><cell>F5</cell><cell>F11</cell><cell>1110001</cell></row><row><cell>F0</cell><cell>F5</cell><cell>0111110</cell><cell>F2</cell><cell>F10</cell><cell>0111011</cell><cell>F5</cell><cell>F12</cell><cell>0101001</cell></row><row><cell>F0</cell><cell>F6</cell><cell>1111010</cell><cell>F2</cell><cell>F11</cell><cell>0001011</cell><cell>F6</cell><cell>F7</cell><cell>1100101</cell></row><row><cell>F0</cell><cell>F7</cell><cell>1010001</cell><cell>F2</cell><cell>F12</cell><cell>1111011</cell><cell>F6</cell><cell>F8</cell><cell>0001111</cell></row><row><cell>F0</cell><cell>F8</cell><cell>0011011</cell><cell>F3</cell><cell>F4</cell><cell>0000111</cell><cell>F6</cell><cell>F9</cell><cell>0111111</cell></row><row><cell>F0</cell><cell>F9</cell><cell>1001001</cell><cell>F3</cell><cell>F5</cell><cell>0100101</cell><cell>F6</cell><cell>F10</cell><cell>1111000</cell></row><row><cell>F0</cell><cell>F10</cell><cell>1111011</cell><cell>F3</cell><cell>F6</cell><cell>0111101</cell><cell>F6</cell><cell>F11</cell><cell>1111101</cell></row><row><cell>F0</cell><cell>F11</cell><cell>1111111</cell><cell>F3</cell><cell>F7</cell><cell>1101001</cell><cell>F6</cell><cell>F12</cell><cell>1001001</cell></row><row><cell>F0</cell><cell>F12</cell><cell>1000111</cell><cell>F3</cell><cell>F8</cell><cell>1110101</cell><cell>F7</cell><cell>F8</cell><cell>1011001</cell></row><row><cell>F1</cell><cell>F2</cell><cell>0101111</cell><cell>F3</cell><cell>F9</cell><cell>0100101</cell><cell>F7</cell><cell>F9</cell><cell>1000101</cell></row><row><cell>F1</cell><cell>F3</cell><cell>0011101</cell><cell>F3</cell><cell>F10</cell><cell>1111101</cell><cell>F7</cell><cell>F10</cell><cell>0010101</cell></row><row><cell>F1</cell><cell>F4</cell><cell>0001111</cell><cell>F3</cell><cell>F11</cell><cell>1101101</cell><cell>F7</cell><cell>F11</cell><cell>0111101</cell></row><row><cell>F1</cell><cell>F5</cell><cell>1101011</cell><cell>F3</cell><cell>F12</cell><cell>0011101</cell><cell>F7</cell><cell>F12</cell><cell>1111101</cell></row><row><cell>F1</cell><cell>F6</cell><cell>0011111</cell><cell>F4</cell><cell>F5</cell><cell>1111011</cell><cell>F8</cell><cell>F9</cell><cell>1101101</cell></row><row><cell>F1</cell><cell>F7</cell><cell>1111001</cell><cell>F4</cell><cell>F6</cell><cell>1101001</cell><cell>F8</cell><cell>F10</cell><cell>1010111</cell></row><row><cell>F1</cell><cell>F8</cell><cell>1001111</cell><cell>F4</cell><cell>F7</cell><cell>0101101</cell><cell>F8</cell><cell>F11</cell><cell>0001011</cell></row><row><cell>F1</cell><cell>F9</cell><cell>0010101</cell><cell>F4</cell><cell>F8</cell><cell>1110111</cell><cell>F8</cell><cell>F12</cell><cell>1111111</cell></row><row><cell>F1</cell><cell>F10</cell><cell>0111001</cell><cell>F4</cell><cell>F9</cell><cell>0011111</cell><cell>F9</cell><cell>F10</cell><cell>0110111</cell></row><row><cell>F1</cell><cell>F11</cell><cell>0001001</cell><cell>F4</cell><cell>F10</cell><cell>0001101</cell><cell>F9</cell><cell>F11</cell><cell>1110111</cell></row><row><cell>F1</cell><cell>F12</cell><cell>0100101</cell><cell>F4</cell><cell>F11</cell><cell>0000101</cell><cell>F9</cell><cell>F12</cell><cell>1000101</cell></row><row><cell>F2</cell><cell>F3</cell><cell>0010101</cell><cell>F4</cell><cell>F12</cell><cell>1110111</cell><cell>F10</cell><cell>F11</cell><cell>0111101</cell></row><row><cell>F2</cell><cell>F4</cell><cell>1101111</cell><cell>F5</cell><cell>F6</cell><cell>1111000</cell><cell>F10</cell><cell>F12</cell><cell>1110101</cell></row><row><cell>F2</cell><cell>F5</cell><cell>0000101</cell><cell>F5</cell><cell>F7</cell><cell>1100011</cell><cell>F11</cell><cell>F12</cell><cell>0110001</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Accuracy(%)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>96</cell><cell></cell><cell>95.06</cell><cell></cell><cell cols="2">95.14</cell><cell></cell><cell></cell></row><row><cell></cell><cell>95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>94</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>93</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>92</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>91</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Near-optimal</cell><cell></cell><cell>Optimal</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>Comparison of the classification accuracy between the proposed method and other method.</figDesc><table><row><cell>Fault ID</cell><cell>Fault class</cell><cell>Method in [5]</cell><cell>The proposed method</cell></row><row><cell>F0</cell><cell>NF</cell><cell>87.00</cell><cell>99.60</cell></row><row><cell>F1</cell><cell>R1↑</cell><cell>73.00</cell><cell>100.00</cell></row><row><cell>F2</cell><cell>R1↓</cell><cell>75.67</cell><cell>99.80</cell></row><row><cell>F3</cell><cell>R2↑</cell><cell>93.67</cell><cell>100.00</cell></row><row><cell>F4</cell><cell>R2↓</cell><cell>93.33</cell><cell>100.00</cell></row><row><cell>F5</cell><cell>Rf↑</cell><cell>76.00</cell><cell>99.60</cell></row><row><cell>F6</cell><cell>Rf↓</cell><cell>68.00</cell><cell>100.00</cell></row><row><cell>F7</cell><cell>R4↑</cell><cell>100.00</cell><cell>98.40</cell></row><row><cell>F8</cell><cell>R4↓</cell><cell>100.00</cell><cell>100.00</cell></row><row><cell>F9</cell><cell>C2↑</cell><cell>100.00</cell><cell>98.20</cell></row><row><cell>F10</cell><cell>C2↓</cell><cell>100.00</cell><cell>99.00</cell></row><row><cell>Average</cell><cell></cell><cell>87.88</cell><cell>99.51</cell></row></table><note><p><p><p>Fig.</p><ref type="bibr" target="#b17">18</ref></p>. Schematic of a Sallen-key band-pass filter circuit.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>Fault intervals for all faulty components.</figDesc><table><row><cell>Faulty component</cell><cell>↑</cell><cell>↓</cell></row><row><cell>R1</cell><cell>[1.05Yn a ─1.25Yn]</cell><cell>[0.75Yn─0.95Yn]</cell></row><row><cell>R3</cell><cell>[1.05Yn─1.25Yn]</cell><cell>[0.75Yn─0.95Yn]</cell></row><row><cell>R4</cell><cell>[1.05Yn─1.25Yn]</cell><cell>[0.75Yn─0.95Yn]</cell></row><row><cell>C1</cell><cell>[1.05Yn─1.25Yn]</cell><cell>[0.75Yn─0.95Yn]</cell></row><row><cell>C2</cell><cell>[1.05Yn─1.25Yn]</cell><cell>[0.75Yn─0.95Yn]</cell></row></table><note><p>a Yn is the nominal value.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>Nominal and fault value with tolerance.</figDesc><table><row><cell>Fault ID</cell><cell>Fault class</cell><cell>Nominal value</cell><cell>Fault value</cell><cell>Tolerance (%)</cell></row><row><cell>F0</cell><cell>NF</cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1</cell><cell>R1↑</cell><cell>1 kΩ</cell><cell>1.15 kΩ</cell><cell>78.50</cell></row><row><cell>F2</cell><cell>R1↓</cell><cell>1 kΩ</cell><cell>0.85 kΩ</cell><cell>711.5</cell></row><row><cell>F3</cell><cell>R3↑</cell><cell>2 kΩ</cell><cell>2.30 kΩ</cell><cell>78.50</cell></row><row><cell>F4</cell><cell>R3↓</cell><cell>2 kΩ</cell><cell>1.70 kΩ</cell><cell>711.5</cell></row><row><cell>F5</cell><cell>R4↑</cell><cell>4 kΩ</cell><cell>4.60 kΩ</cell><cell>78.50</cell></row><row><cell>F6</cell><cell>R4↓</cell><cell>4 kΩ</cell><cell>3.40 kΩ</cell><cell>711.5</cell></row><row><cell>F7</cell><cell>C1↑</cell><cell>5 nF</cell><cell>5.75 nF</cell><cell>78.50</cell></row><row><cell>F8</cell><cell>C1↓</cell><cell>5 nF</cell><cell>4.25 nF</cell><cell>711.5</cell></row><row><cell>F9</cell><cell>C2↑</cell><cell>5 nF</cell><cell>5.75 nF</cell><cell>78.50</cell></row><row><cell>F10</cell><cell>C2↓</cell><cell>5 nF</cell><cell>4.25 nF</cell><cell>711.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9</head><label>9</label><figDesc>Comparison of the classification accuracy between the proposed method and other method.</figDesc><table><row><cell>Fault ID</cell><cell>Fault class</cell><cell>Method in [16]</cell><cell>The proposed method</cell></row><row><cell>F0</cell><cell>NF</cell><cell>100.00</cell><cell>99.20</cell></row><row><cell>F1</cell><cell>R1↑</cell><cell>97.00</cell><cell>100.00</cell></row><row><cell>F2</cell><cell>R1↓</cell><cell>98.67</cell><cell>100.00</cell></row><row><cell>F3</cell><cell>R3↑</cell><cell>100.67</cell><cell>99.60</cell></row><row><cell>F4</cell><cell>R3↓</cell><cell>96.00</cell><cell>100.00</cell></row><row><cell>F5</cell><cell>R4↑</cell><cell>98.00</cell><cell>100.60</cell></row><row><cell>F6</cell><cell>R4↓</cell><cell>99.00</cell><cell>100.00</cell></row><row><cell>F7</cell><cell>C1↑</cell><cell>99.00</cell><cell>100.00</cell></row><row><cell>F8</cell><cell>C1↓</cell><cell>100.00</cell><cell>100.00</cell></row><row><cell>F9</cell><cell>C2↑</cell><cell>100.00</cell><cell>99.40</cell></row><row><cell>F10</cell><cell>C2↓</cell><cell>96.00</cell><cell>100.00</cell></row><row><cell>Average</cell><cell></cell><cell>98.45</cell><cell>99.84</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>B. Long et al. / Neurocomputing 133 (2014) 237-248</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by National Natural Science Foundation of China under Grants 61071029, 60934002, 61271035 and 61201009, and in part by the Fundamental Research Funds for the Central Universities under Grants ZYGX2012J088, and in part by UESTC under Grants Y02018023601059. The authors would like to thank all anonymous reviewers' valuable comments on this paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A novel approach for analog fault diagnosis based on neural networks and improved kernel PCA</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1102" to="1115" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Feature selection for high-dimensional machinery fault diagnosis data using multiple models and Radial Basis Function networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scarf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ball</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="2941" to="2952" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A modular fault-diagnostic system for analog electronic circuits using neural networks with wavelet transform as a preprocessor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aminian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Aminian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1546" to="1554" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new neural-network-based fault diagnosis approach for analog circuits by using kurtosis and entropy as a preprocessor</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="586" to="595" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A novel method for the diagnosis of the incipient faults in analog circuits based on LDA and HMM</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circuit Syst. Signal Process</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="577" to="600" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">One-class classifier based on SBT for analog circuit fault diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="371" to="380" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Support vector machine with genetic algorithm for machinery fault diagnosis of high voltage circuit breaker</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1018" to="1027" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fault diagnosis of nonlinear circuits using neural networks with wavelet and Fourier transforms as preprocessors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Aminian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aminian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electron. Test</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="471" to="481" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A . net framework for an integrated fault diagnosis and failure prognosis architecture</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sconyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vachtsevanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Orchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE AutoTestCon</title>
		<meeting>IEEE AutoTestCon<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Research on features for diagnostics of filtered analog circuits based on LS-SVM</title>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE AutoTestCon</title>
		<meeting>IEEE AutoTestCon<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="360" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Least squares support vector machine based analog circuit fault diagnosis using wavelet transform as preprocessor</title>
		<author>
			<persName><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Communication, Circuits and Systems (ICCCAS)</title>
		<meeting>the International Conference on Communication, Circuits and Systems (ICCCAS)<address><addrLine>Fujian, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1026" to="1029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A novel approach of analog circuit fault diagnosis using support vector machines classifier</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="281" to="289" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Least squares support vector machine classifiers</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A K</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Process. Lett</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="293" to="300" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multiclass least squares support vector machines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A K</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Neural Networks (IJCNN 99)</title>
		<meeting>the International Joint Conference on Neural Networks (IJCNN 99)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="900" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Diagnostic of incipient faults in nonlinear analog circuits</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metrol. Meas. Syst. XIX</title>
		<imprint>
			<biblScope unit="page" from="203" to="218" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">The Fault diagnostic model based on MHMM-SVM and its application</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="page" from="621" to="627" />
		</imprint>
		<respStmt>
			<orgName>Communication in Computer and Information Science, Advance in Computer Science, Environment, Ecoinformatics, and Education Springer Berlin Heidelberg</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Genetic algorithms for feature selection in machine condition monitoring with vibration signals</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Jack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Nandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proc.-Vis. Image Signal Process</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="205" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Neural Networks (ICNN)</title>
		<meeting>the International Conference on Neural Networks (ICNN)<address><addrLine>Perth, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A new kernelization framework for Mahalanobis distance learning algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chatpatanasiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Korsrilabutr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tangchanachaianan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kijsirikul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1570" to="1579" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Approach to fault identification for electronic products using Mahalanobis distance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W S</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="2055" to="2064" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kernel subclass convex hull sample selection method for SVM on face recognition</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="2234" to="2246" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Composite reliability evaluation using Monte Carlo simulation and least squares support vector classifier</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Pindoriya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jirutitijaroen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Power Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2483" to="2490" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Prognostic-based risk mitigation for telecom equipment under free air cooling conditions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Energy</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="423" to="429" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A comparison of methods for multiclass support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="415" to="425" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Particle swarm optimization based RVM classifier for non-linear circuit fault diagnosis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Diao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cent. South Univ</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="459" to="464" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improvement and application of a realtiming analog circuit fault diagnosis method</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Intelligent Computation Technology and Automation (ICICTA)</title>
		<meeting>the 4th International Conference on Intelligent Computation Technology and Automation (ICICTA)<address><addrLine>Shenzhen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="155" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Nikias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petropulu</surname></persName>
		</author>
		<title level="m">High-order Spectra Analysis: A Nonlinear Signal Processing Framework</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">N-skart: a nonsequential skewness-and auto regression-adjusted batch-means procedure for simulation analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tafazzoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Steiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Autom. Control</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="254" to="264" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Time series prediction using RBF neural networks with a nonlinear time-varying evolution PSO algorithm</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Ko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="449" to="460" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Research on WNN aerodynamic modeling from flight data based on improved PSO algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="212" to="221" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An effective PSO-based memetic algorithm for flow shop scheduling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="18" to="27" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Evolutionary Computation (ICEC), Anchorage</title>
		<meeting>International Conference on Evolutionary Computation (ICEC), Anchorage</meeting>
		<imprint>
			<publisher>AK</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">His current research interests include failure analysis, automatic testing, diagnostics, prognostics and health management, and testability design and analysis for circuits and systems</title>
	</analytic>
	<monogr>
		<title level="m">Bing Long received M.S. degrees from Harbin Engineering University in 2002, and Ph.D. degree from Harbin Institute of Technology in 2005, respectively</title>
		<meeting><address><addrLine>Changzhou, China; Chengdu, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
		<respStmt>
			<orgName>University of Electronic Science and Technology of China</orgName>
		</respStmt>
	</monogr>
	<note>His current research interests include diagnostics, prognostics for circuits and systems including lithium-ion battery</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
