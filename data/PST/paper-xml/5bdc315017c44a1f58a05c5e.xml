<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Named Entity Tagger using Domain-Specific Dictionary</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
							<email>shang7@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaotao</forename><surname>Gu</surname></persName>
							<email>xiaotao2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
							<email>xiangren@usc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Teng</forename><surname>Ren</surname></persName>
							<email>teng.ren@cootek.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">CooTek Inc</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
							<email>hanj@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Named Entity Tagger using Domain-Specific Dictionary</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in deep neural models allow us to build reliable named entity recognition (NER) systems without handcrafting features. However, such methods require large amounts of manually-labeled training data. There have been efforts on replacing human annotations with distant supervision (in conjunction with external dictionaries), but the generated noisy labels pose significant challenges on learning effective neural models. Here we propose two neural models to suit noisy distant supervision from the dictionary. First, under the traditional sequence labeling framework, we propose a revised fuzzy CRF layer to handle tokens with multiple possible labels. After identifying the nature of noisy labels in distant supervision, we go beyond the traditional framework and propose a novel, more effective neural model AutoNER with a new Tie or Break scheme. In addition, we discuss how to refine distant supervision for better NER performance. Extensive experiments on three benchmark datasets demonstrate that AutoNER achieves the best performance when only using dictionaries with no additional human effort, and delivers competitive results with state-of-the-art supervised benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, extensive efforts have been made on building reliable named entity recognition (NER) models without handcrafting features <ref type="bibr" target="#b13">(Liu et al., 2018;</ref><ref type="bibr" target="#b14">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b10">Lample et al., 2016)</ref>. However, most existing methods require large amounts of manually annotated sentences for training supervised models (e.g., neural sequence models) <ref type="bibr" target="#b13">(Liu et al., 2018;</ref><ref type="bibr" target="#b14">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b10">Lample et al., 2016;</ref><ref type="bibr" target="#b3">Finkel et al., 2005)</ref>. This is particularly challenging in specific do- * Equal contribution. mains, where domain-expert annotation is expensive and/or slow to obtain.</p><p>To alleviate human effort, distant supervision has been applied to automatically generate labeled data, and has gained successes in various natural language processing tasks, including phrase mining <ref type="bibr" target="#b22">(Shang et al., 2018)</ref>, entity recognition <ref type="bibr" target="#b19">(Ren et al., 2015;</ref><ref type="bibr" target="#b4">Fries et al., 2017;</ref><ref type="bibr" target="#b7">He, 2017)</ref>, aspect term extraction <ref type="bibr" target="#b5">(Giannakopoulos et al., 2017)</ref>, and relation extraction <ref type="bibr" target="#b15">(Mintz et al., 2009)</ref>. Meanwhile, open knowledge bases (or dictionaries) are becoming increasingly popular, such as WikiData and YAGO in the general domain, as well as MeSH and CTD in the biomedical domain. The existence of such dictionaries makes it possible to generate training data for NER at a large scale without additional human effort.</p><p>Existing distantly supervised NER models usually tackle the entity span detection problem by heuristic matching rules, such as POS tag-based regular expressions <ref type="bibr" target="#b19">(Ren et al., 2015;</ref><ref type="bibr" target="#b4">Fries et al., 2017)</ref> and exact string matching <ref type="bibr" target="#b5">(Giannakopoulos et al., 2017;</ref><ref type="bibr" target="#b7">He, 2017)</ref>. In these models, every unmatched token will be tagged as nonentity. However, as most existing dictionaries have limited coverage on entities, simply ignoring unmatched tokens may introduce false-negative labels (e.g., "prostaglandin synthesis" in Fig. <ref type="figure" target="#fig_0">1</ref>). Therefore, we propose to extract high-quality outof-dictionary phrases from the corpus, and mark them as potential entities with a special "unknown" type. Moreover, every entity span in a sentence can be tagged with multiple types, since two entities of different types may share the same surface name in the dictionary. To address these challenges, we propose and compare two neural architectures with customized tagging schemes.</p><p>We start with adjusting models under the traditional sequence labeling framework. Typically, NER models are built upon conditional random fields (CRF) with the IOB or IOBES tagging scheme <ref type="bibr" target="#b13">(Liu et al., 2018;</ref><ref type="bibr" target="#b14">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b10">Lample et al., 2016;</ref><ref type="bibr" target="#b18">Ratinov and Roth, 2009;</ref><ref type="bibr" target="#b3">Finkel et al., 2005)</ref>. However, such design cannot deal with multi-label tokens. Therefore, we customize the conventional CRF layer in LSTM-CRF <ref type="bibr" target="#b10">(Lample et al., 2016)</ref> into a Fuzzy CRF layer, which allows each token to have multiple labels without sacrificing computing efficiency.</p><p>To adapt to imperfect labels generated by distant supervision, we go beyond the traditional sequence labeling framework and propose a new prediction model. Specifically, instead of predicting the label of each single token, we propose to predict whether two adjacent tokens are tied in the same entity mention or not (i.e., broken). The key motivation is that, even the boundaries of an entity mention are mismatched by distant supervision, most of its inner ties are not affected, and thus more robust to noise. Therefore, we design a new Tie or Break tagging scheme to better exploit the noisy distant supervision. Accordingly, we design a novel neural architecture that first forms all possible entity spans by detecting such ties, then identifies the entity type for each span. The new scheme and neural architecture form our new model, AutoNER, which proves to work better than the Fuzzy CRF model in our experiments.</p><p>We summarize our major contributions as</p><p>• We propose AutoNER, a novel neural model with the new Tie or Break scheme for the distantly supervised NER task. • We revise the traditional NER model to the Fuzzy-LSTM-CRF model, which serves as a strong distantly supervised baseline. • We explore to refine distant supervision for better NER performance, such as incorporating high-quality phrases to reduce false-negative labels, and conduct ablation experiments to verify the effectiveness. • Experiments on three benchmark datasets demonstrate that AutoNER achieves the best performance when only using dictionaries with no additional human effort and is even competitive with the supervised benchmarks.</p><p>We release all code and data for future studies 1 . Related open tools can serve as the NER module 1 https://github.com/shangjingbo1226/ AutoNER of various domain-specific systems in a plug-inand-play manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview</head><p>Our goal, in this paper, is to learn a named entity tagger using, and only using dictionaries. Each dictionary entry consists of 1) the surface names of the entity, including a canonical name and a list of synonyms; and 2) the entity type. Considering the limited coverage of dictionaries, we extend existing dictionaries by adding high-quality phrases as potential entities with unknown type. More details on refining distant supervision for better NER performance will be presented in Sec. 4.</p><p>Given a raw corpus and a dictionary, we first generate entity labels (including unknown labels) by exact string matching, where conflicted matches are resolved by maximizing the total number of matched tokens <ref type="bibr" target="#b2">(Etzioni et al., 2005;</ref><ref type="bibr" target="#b6">Hanisch et al., 2005;</ref><ref type="bibr" target="#b12">Lin et al., 2012;</ref><ref type="bibr" target="#b7">He, 2017)</ref>.</p><p>Based on the result of dictionary matching, each token falls into one of three categories: 1) it belongs to an entity mention with one or more known types; 2) it belongs to an entity mention with unknown type; and 3) It is marked as non-entity.</p><p>Accordingly, we design and explore two neural models, Fuzzy-LSTM-CRF with the modified IOBES scheme and AutoNER with the Tie or Break scheme, to learn named entity taggers based on such labels with unknown and multiple types. We will discuss the details in Sec. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Neural Models</head><p>In this section, we introduce two prediction models for the distantly supervised NER task, one under the traditional sequence labeling framework and another with a new labeling scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Fuzzy-LSTM-CRF with Modified IOBES</head><p>State-of-the-art named entity taggers follow the sequence labeling framework using IOB or IOBES scheme <ref type="bibr" target="#b18">(Ratinov and Roth, 2009)</ref>, thus requiring a conditional random field (CRF) layer to capture the dependency between labels. However, both the original scheme and the conventional CRF layer cannot handle multi-typed or unknown-typed tokens. Therefore, we propose the modified IOBES scheme and Fuzzy CRF layer accordingly, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. Modified IOBES. We define the labels according to the three token categories. 1) For a token marked as one or more types, it is labeled with all these types and one of {I, B, E, S} according to its positions in the matched entity mention. 2) For a token with unknown type, all five {I, O, B, E, S} tags are possible. Meanwhile, all available types are assigned. For example, when there are only two available types (e.g., Chemical and Disease), it has nine (i.e., 4 × 2 + 1) possible labels in total.</p><p>3) For a token that is annotated as non-entity, it is labeled as O.</p><p>As demonstrated in Fig. <ref type="figure" target="#fig_0">1</ref>, based on the dictionary matching results, "indomethacin" is a singleton Chemical entity and "prostaglandin synthesis" is an unknown-typed high-quality phrase. Therefore, "indomethacin" is labeled as S-Chemical, while both "prostaglandin" and "synthesis" are labeled as O, B-Disease, I-Disease, . . ., and S-Chemical because the available entity types are {Chemical, Disease}. The non-entity tokens, such as "Thus" and "by", are labeled as O.</p><p>Fuzzy-LSTM-CRF. We revise the LSTM-CRF model <ref type="bibr" target="#b10">(Lample et al., 2016)</ref> to the Fuzzy-LSTM-CRF model to support the modified IOBES labels.</p><p>Given a word sequence (X 1 , X 2 , . . . , X n ), it is first passed through a word-level BiL-STM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997)</ref> (i.e., forward and backward LSTMs). After concatenating the representations from both directions, the model makes independent tagging decisions for each output label. In this step, the model estimates the score P i,y j for the word X i being the label y j .</p><p>We follow previous works <ref type="bibr" target="#b13">(Liu et al., 2018;</ref><ref type="bibr" target="#b14">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b10">Lample et al., 2016)</ref> to define the score of the predicted sequence, the score of the predicted sequence (y 1 , y 2 , . . . , y n ) is defined as:</p><formula xml:id="formula_0">s(X, y) = n i=0 Φ y i ,y i+1 + n i=1 P i,y i (1)</formula><p>where, Φ y i ,y i+1 is the transition probability from a label y i to its next label</p><formula xml:id="formula_1">y i+1 . Φ is a (k + 2) × (k + 2) matrix,</formula><p>where k is the number of distinct labels. Two additional labels start and end are used (only used in the CRF layer) to represent the beginning and end of a sequence, respectively. The conventional CRF layer maximizes the probability of the only valid label sequence. However, in the modified IOBES scheme, one sentence may have multiple valid label sequences, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Therefore, we extend the conventional CRF layer to a fuzzy CRF model. Instead, it maximizes the total probability of all possible label sequences by enumerating both the IOBES tags and all matched entity types. Mathematically, we define the optimization goal as Eq. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p(y|X) =</head><p>ỹ∈Y possible e s(X,ỹ) ỹ∈Y X e s(X,ỹ)</p><p>(2)</p><p>where Y X means all the possible label sequences for sequence X, and Y possible contains all the possible label sequences given the labels of modified IOBES scheme. Note that, when all labels and types are known and unique, the fuzzy CRF model is equivalent to the conventional CRF.</p><p>During the training process, we maximize the log-likelihood function of Eq. 2. For inference, we apply the Viterbi algorithm to maximize the score of Eq. 1 for each input sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">AutoNER with "Tie or Break"</head><p>Identifying the nature of the distant supervision, we go beyond the sequence labeling framework and propose a new tagging scheme, Tie or Break. It focuses on the ties between adjacent tokens, i.e., whether they are tied in the same entity mentions or broken into two parts. Accordingly, we design a novel neural model for this scheme.  <ref type="table" target="#tab_4">1 c2,2 c2,3 c2,4 c2,5 c2,6  c2,  c3,0 c3,1 c3,2 c3,3  c3,4  c3,5  c3,6  c3,  c4,0  c4,2  c4,1  c4,  c5,0  c5,1 c5,2 c5</ref> "Tie or Break" Tagging Scheme. Specifically, for every two adjacent tokens, the connection between them is labeled as (1) Tie, when the two tokens are matched to the same entity;</p><formula xml:id="formula_2">r a m i c u n i o d ␣ a n d ␣ 8 G B ␣ R c2,0 c2,</formula><p>(2) Unknown, if at least one of the tokens belongs to an unknown-typed high-quality phrase; (3) Break, otherwise. An example can be found in Fig. <ref type="figure" target="#fig_2">2</ref>. The distant supervision shows that "ceramic unibody" is a matched AspectTerm and "8GB RAM" is an unknown-typed high-quality phrase. Therefore, a Tie is labeled between "ceramic" and "unibody", while Unknown labels are put before "8GB", between "8GB" and "RAM", and after "RAM".</p><p>Tokens between every two consecutive Break form a token span. Each token span is associated with all its matched types, the same as for the modified IOBES scheme. For those token spans without any associated types, such as "with" in the example, we assign them the additional type None.</p><p>We believe this new scheme can better exploit the knowledge from dictionary according to the following two observations. First, even though the boundaries of an entity mention are mismatched by distant supervision, most of its inner ties are not affected. More interestingly, compared to multi-word entity mentions, matched unigram entity mentions are more likely to be false-positive labels. However, such false-positive labels will not introduce incorrect labels with the Tie or Break scheme, since either the unigram is a true entity mention or a false positive, it always brings two Break labels around.</p><p>AutoNER. In the Tie or Break scheme, entity spans and entity types are encoded into two folds. Therefore, we separate the entity span detection and entity type prediction into two steps.</p><p>For entity span detection, we build a binary classifier to distinguish Break from Tie, while Unknown positions will be skipped. Specifically, as shown in Fig. <ref type="figure" target="#fig_2">2</ref>, for the prediction between i-th token and its previous token, we concatenate the output of the BiLSTM as a new feature vector, u i . u i is then fed into a sigmoid layer, which estimates the probability that there is a Break as</p><formula xml:id="formula_3">p(y i = Break|u i ) = σ(w T u i )</formula><p>where y i is the label between the i-th and its previous tokens, σ is the sigmoid function, and w is the sigmoid layer's parameter. The entity span detection loss is then computed as follows.</p><formula xml:id="formula_4">L span = i|y i =Unknown l y i , p(y i = Break|u i )</formula><p>Here, l(•, •) is the logistic loss. Note that those Unknown positions are skipped.</p><p>After obtaining candidate entity spans, we further identify their entity types, including the None type for non-entity spans. As shown in Fig. <ref type="figure" target="#fig_2">2</ref>, the output of the BiLSTM will be re-aligned to form a new feature vector, which is referred as v i for i-th span candidate. v i will be further fed into a softmax layer, which estimates the entity type distribution as</p><formula xml:id="formula_5">p(t j |v i ) = e t T j v i t k ∈L e t T k v i</formula><p>where t j is an entity type and L is the set of all entity types including None.</p><p>Since one span can be labeled as multiple types, we mark the possible set of types for i-th entity span candidate as L i . Accordingly, we modify the cross-entropy loss as follows.</p><formula xml:id="formula_6">L type = H(p(•|v i , L i ), p(•|v i ))</formula><p>Here, H(p, q) is the cross entropy between p and q, and p(t j |v i , L i ) is the soft supervision distribu-tion. Specifically, it is defined as:</p><formula xml:id="formula_7">p(t j |v i , L i ) = δ(t j ∈ L i ) • e t T j v i t k ∈L δ(t k ∈ L i ) • e t T k v i</formula><p>where δ(t j ∈ L i ) is the boolean function of checking whether the i-th span candidate is labeled as the type t j in the distant supervision. It's worth mentioning that AutoNER has no CRF layer and Viterbi decoding, thus being more efficient than Fuzzy-LSTM-CRF for inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Remarks on "Unknown" Entities</head><p>"Unknown" entity mentions are not the entities of other types, but the tokens that we are less confident about their boundaries and/or cannot identify their types based on the distant supervision. For example, in Figure <ref type="figure" target="#fig_0">1</ref>, "prostaglandin synthesis" is an "unknown" token span. The distant supervision cannot decide whether it is a Chemical, a Disease, an entity of other types, two separate single-token entities, or (partially) not an entity. Therefore, in the FuzzyCRF model, we assign all possible labels for these tokens.</p><p>In our AutoNER model, these "unknown" positions have undefined boundary and type losses, because (1) they make the boundary labels unclear; and (2) they have no type labels. Therefore, they are skipped.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Distant Supervision Refinement</head><p>In this section, we present two techniques to refine the distant supervision for better named entity taggers. Ablation experiments in Sec. 5.4 verify their effectiveness empirically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpus-Aware Dictionary Tailoring</head><p>In dictionary matching, blindly using the full dictionary may introduce false-positive labels, as there exist many entities beyond the scope of the given corpus but their aliases can be matched. For example, when the dictionary has a non-related character name "Wednesday Addams"<ref type="foot" target="#foot_0">2</ref> and its alias "Wednesday", many Wednesday's will be wrongly marked as persons. In an ideal case, the dictionary should cover, and only cover entities occurring in the given corpus to ensure a high precision while retaining a reasonable coverage.</p><p>As an approximation, we tailor the original dictionary to a corpus-related subset by excluding entities whose canonical names never appear in the given corpus. The intuition behind is that to avoid ambiguities, people will likely mention the canonical name of the entity at least once. For example, in the biomedical domain, this is true for 88.12%, 95.07% of entity mentions on the BC5CDR and NCBI datasets respectively. We expect the NER model trained on such tailored dictionary will have a higher precision and a reasonable recall compared to that trained on the original dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Unknown-Typed High-Quality Phrases</head><p>Another issue of the distant supervision is about the false-negative labels. When a token span cannot be matched to any entity surface names in the dictionary, because of the limited coverage of dictionaries, it is still difficult to claim it as non-entity (i.e., negative labels) for sure. Specifically, some high-quality phrases out of the dictionary may also be potential entities.</p><p>We utilize the state-of-the-art distantly supervised phrase mining method, AutoPhrase <ref type="bibr" target="#b22">(Shang et al., 2018)</ref>, with the corpus and dictionary in the given domain as input. AutoPhrase only requires unlabeled text and a dictionary of highquality phrases. We obtain quality multi-word and single-word phrases by posing thresholds (e.g., 0.5 and 0.9 respectively). In practice, one can find more unlabeled texts from the same domain (e.g., PubMed papers and Amazon laptop reviews) and use the same domain-specific dictionary for the NER task. In our experiments, for the biomedical domain, we use the titles and abstracts of 686,568 PubMed papers (about 4%) uniformly sampled from the whole PubTator database as the training corpus. For the laptop review domain, we use the Amazon laptop review dataset<ref type="foot" target="#foot_1">3</ref> , which is designed for the aspect-based sentiment analysis <ref type="bibr" target="#b25">(Wang et al., 2011)</ref>.</p><p>We treat out-of-dictionary phrases as potential entities with "unknown" type and incorporate them as new dictionary entries. After this, only token spans that cannot be matched in this extended dictionary will be labeled as non-entity. Being aware of these high-quality phrases, we expect the trained NER tagger should be more accurate. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We conduct experiments on three benchmark datasets to evaluate and compare our proposed Fuzzy-LSTM-CRF and AutoNER with many other methods. We further investigate the effectiveness of our proposed refinements for the distant supervision and the impact of the number of distantly supervised sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>Datasets are briefly summarized in Table <ref type="table" target="#tab_0">1</ref>. More details as as follows.</p><p>• Domain-Specific Dictionary. For the biomedical datasets, the dictionary is a combination of both the MeSH database<ref type="foot" target="#foot_2">4</ref> and the CTD Chemical and Disease vocabularies<ref type="foot" target="#foot_3">5</ref> . The dictionary contains 322,882 Chemical and Disease entity surfaces. For the laptop review dataset, the dictionary has 13,457 computer terms crawled from a public website<ref type="foot" target="#foot_4">6</ref> .</p><p>Metric. We use the micro-averaged F 1 score as the evaluation metric. Meanwhile, precision and recall are presented. The reported scores are the mean across five different runs.</p><p>Parameters and Model Training. Based on the analysis conducted in the development set, we conduct optimization with the stochastic gradient descent with momentum. We set the batch size and the momentum to 10 and 0.9. The learning rate is initially set to 0.05 and will be shrunk by 40% if there is no better development F 1 in the recent 5 rounds. Dropout of a ratio 0.5 is applied in our model. For a better stability, we use gradient clipping of 5.0. Furthermore, we employ the early stopping in the development set.</p><p>Pre-trained Word Embeddings.</p><p>For the biomedical datasets, we use the pre-trained 200dimension word vectors<ref type="foot" target="#foot_5">7</ref> from <ref type="bibr" target="#b17">(Pyysalo et al., 2013)</ref>, which are trained on the whole PubMed abstracts, all the full-text articles from PubMed Central (PMC), and English Wikipedia. For the laptop review dataset, we use the GloVe 100-dimension pre-trained word vectors<ref type="foot" target="#foot_6">8</ref> instead, which are trained on the Wikipedia and GigaWord.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Compared Methods</head><p>Dictionary Match is our proposed distant supervision generation method. Specifically, we apply it to the testing set directly to obtain entity mentions with exactly the same surface name as in the dictionary. The type is assigned through a majority voting. By comparing with it, we can check the improvements of neural models over the distant supervision itself.</p><p>SwellShark, in the biomedical domain, is arguably the best distantly supervised model, especially on the BC5CDR and NCBI-Disease datasets <ref type="bibr" target="#b4">(Fries et al., 2017)</ref>. It needs no human annotated data, however, it requires extra expert effort for entity span detection on building POS tagger, designing effective regular expressions, and hand-tuning for special cases.</p><p>Distant-LSTM-CRF achieved the best performance on the LaptopReview dataset without annotated training data using a distantly supervised  LSTM-CRF model <ref type="bibr" target="#b5">(Giannakopoulos et al., 2017)</ref>. Supervised benchmarks on each dataset are listed to check whether AutoNER can deliver competitive performance. On the BC5CDR and NCBI-Disease datasets, LM-LSTM-CRF <ref type="bibr" target="#b13">(Liu et al., 2018)</ref> and LSTM-CRF <ref type="bibr" target="#b10">(Lample et al., 2016)</ref> achieve the state-of-the-art F 1 scores without external resources, respectively <ref type="bibr" target="#b26">(Wang et al., 2018)</ref>.</p><p>On the LaptopReview dataset, we present the scores of the Winner in the SemEval2014 Challenge Task 4 Subtask 1 <ref type="bibr" target="#b16">(Pontiki et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">NER Performance Comparison</head><p>We present F 1 , precision, and recall scores on all datasets in Table <ref type="table" target="#tab_3">2 and Table 3</ref>. From both tables, one can find the AutoNER achieves the best performance when there is no extra human effort. Fuzzy-LSTM-CRF does have some improvements over the Dictionary Match, but it is always worse than AutoNER. Even though SwellShark is designed for the biomedical domain and utilizes much more expert effort, AutoNER outperforms it in almost all cases. The only outlier happens on the NCBIdisease dataset when the entity span matcher in SwellShark is carefully tuned by experts for many special cases.</p><p>It is worth mentioning that AutoNER beats Distant-LSTM-CRF, which is the previous stateof-the-art distantly supervised model on the Lap-topReview dataset.</p><p>Moreover, AutoNER's performance is competitive to the supervised benchmarks. For example, on the BC5CDR dataset, its F 1 score is only 2.16% away from the supervised benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Distant Supervision Explorations</head><p>We investigate the effectiveness of the two techniques that we proposed in Sec. 4 via ablation experiments. As shown in Table <ref type="table" target="#tab_4">4</ref>, using the tailored dictionary always achieves better F 1 scores than using the original dictionary. By using the tailored dictionary, the precision of the AutoNER model will be higher, while the recall will be retained similarly. For example, on the NCBI-Disease dataset, it significantly boosts the precision from 53.14% to 77.30% with an acceptable recall loss from 63.54% to 58.54%. Moreover, incorporating unknown-typed high-quality phrases in the dictionary enhances every score of AutoNER models significantly, especially the recall. These results match our expectations well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Test F 1 Scores vs. Size of Raw Corpus</head><p>Furthermore, we explore the change of test F 1 scores when we have different sizes of distantly supervised texts. We sample sentences uniformly random from the given raw corpus and then evaluate AutoNER models trained on the selected sentences. We also study what will happen when the gold training set is available. The curves can be found in Figure <ref type="figure" target="#fig_3">3</ref>. The X-axis is the number of  distantly supervised training sentences while the Y-axis is the F 1 score on the testing set. When using distant supervision only, one can observe a significant growing trend of test F 1 score in the beginning, but later the increasing rate slows down when there are more and more raw texts.</p><p>When the gold training set is available, the distant supervision is still helpful to AutoNER. In the beginning, AutoNER works worse than the supervised benchmarks. Later, with enough distantly supervised sentences, AutoNER outperforms the supervised benchmarks. We think there are two possible reasons: (1) The distant supervision puts emphasis on those matchable entity mentions; and</p><p>(2) The gold annotation may miss some good but matchable entity mentions. These may guide the training of AutoNER to a more generalized model, and thus have a higher test F 1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Comparison with Gold Supervision</head><p>To demonstrate the effectiveness of distant supervision, we try to compare our method with gold annotations provided by human experts.</p><p>Specifically, we conduct experiments on the BC5CDR dataset by sampling different amounts of annotated articles for model training. As shown in Figure <ref type="figure" target="#fig_5">4</ref>, we found that our method outperforms the supervised method by a large margin when less training examples are available. For example, when there are only 50 annotated articles available, the test F1 score drops substantially to 74.29%. To achieve a similar test F1 score (e.g.,  83.91%) as our AutoNER models (i.e., 84.8%), the supervised benchmark model requires at least 300 annotated articles. Such results indicate the effectiveness and usefulness of AutoNER on the scenario without sufficient human annotations.</p><p>Still, we observe that, when the supervised benchmark is trained with all annotations, it achieves the performance better than AutoNER. We conjugate that this is because AutoNER lacks more advanced techniques to handle distant supervision, and we leave further improvements of Au-toNER to the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>The task of supervised named entity recognition (NER) is typically embodied as a sequence labeling problem. Conditional random fields (CRF) models built upon human annotations and handcrafted features are the standard <ref type="bibr" target="#b3">(Finkel et al., 2005;</ref><ref type="bibr" target="#b21">Settles, 2004;</ref><ref type="bibr" target="#b11">Leaman and Gonzalez, 2008)</ref>. Recent advances in neural models have freed do-main experts from handcrafting features for NER tasks. <ref type="bibr" target="#b10">(Lample et al., 2016;</ref><ref type="bibr" target="#b14">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b13">Liu et al., 2018)</ref>. Such neural models are increasingly common in the domain-specific NER tasks <ref type="bibr" target="#b20">(Sahu and Anand, 2016;</ref><ref type="bibr" target="#b1">Dernoncourt et al., 2017;</ref><ref type="bibr" target="#b26">Wang et al., 2018)</ref>. Semi-supervised methods have been explored to further improve the accuracy by either augmenting labeled datasets with word embeddings or bootstrapping techniques in tasks like gene name recognition <ref type="bibr" target="#b9">(Kuksa and Qi, 2010;</ref><ref type="bibr" target="#b23">Tang et al., 2014;</ref><ref type="bibr" target="#b24">Vlachos and Gasperin, 2006)</ref>. Unlike these existing approaches, our study focuses on the distantly supervised setting without any expert-curated training data.</p><p>Distant supervision has attracted many attentions to alleviate human efforts. Originally, it was proposed to leverage knowledge bases to supervise relation extraction tasks <ref type="bibr" target="#b0">(Craven et al., 1999;</ref><ref type="bibr" target="#b15">Mintz et al., 2009)</ref>. AutoPhrase has demonstrated powers in extracting high-quality phrases from domain-specific corpora like scientific papers and business reviews <ref type="bibr" target="#b22">(Shang et al., 2018)</ref> but it cannot categorize phrases into typed entities in a contextaware manner. We incorporate the high-quality phrases to enrich the domain-specific dictionary. There are attempts on the distantly supervised NER task recently <ref type="bibr" target="#b19">(Ren et al., 2015;</ref><ref type="bibr" target="#b4">Fries et al., 2017;</ref><ref type="bibr" target="#b7">He, 2017;</ref><ref type="bibr" target="#b5">Giannakopoulos et al., 2017)</ref>. For example, SwellShark <ref type="bibr" target="#b4">(Fries et al., 2017)</ref>, specifically designed for biomedical NER, leverages a generative model to unify and model noise across different supervision sources for named entity typing. However, it leaves the named entity span detection to a heuristic combination of dictionary matching and part-of-speech tag-based regular expressions, which require extensive expert effort to cover many special cases. Other methods <ref type="bibr" target="#b19">(Ren et al., 2015;</ref><ref type="bibr" target="#b7">He, 2017</ref>) also utilize similar approaches to extract entity span candidates before entity typing. Distant-LSTM-CRF <ref type="bibr" target="#b5">(Giannakopoulos et al., 2017)</ref> has been proposed for the distantly supervised aspect term extraction, which can be viewed as an entity recognition task of a single type for business reviews. As shown in our experiments, our models can outperform Distant-LSTM-CRF significantly on the laptop review dataset.</p><p>To the best of our knowledge, AutoNER is the most effective model that can learn NER models by using, and only using dictionaries without any additional human effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we explore how to learn an effective NER model by using, and only using dictionaries. We design two neural architectures, Fuzzy-LSTM-CRF model with a modified IOBES tagging scheme and AutoNER with a new Tie or Break scheme. In experiments on three benchmark datasets, AutoNER achieves the best F 1 scores without additional human efforts. Its performance is even competitive to the supervised benchmarks with full human annotation. In addition, we discuss how to refine the distant supervision for better NER performance, including incorporating high-quality phrases mined from the corpus as well as tailoring dictionary according to the given corpus, and demonstrate their effectiveness in ablation experiments.</p><p>In future, we plan to further investigate the power and potentials of the AutoNER model with Tie or Break scheme in different languages and domains. Also, the proposed framework can be further extended to other sequence labeling tasks, such as noun phrase chunking. Moreover, going beyond the classical NER setting in this paper, it is interesting to further explore distant supervised methods for the nested and multiple typed entity recognitions in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The illustration of the Fuzzy CRF layer with modified IOBES tagging scheme. The named entity types are {Chemical, Disease}. "indomethacin" is a matched Chemical entity and "prostaglandin synthesis" is an unknown-typed high-quality phrase. Paths from Start to End marked as purple form all possible label sequences given the distant supervision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: The illustration of AutoNER with Tie or Break tagging scheme. The named entity type is {AspectTerm}. "ceramic unibody" is a matched AspectTerm entity and "8GB RAM" is an unknown-typed high-quality phrase. Unknown labels will be skipped during the model training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: AutoNER: Test F 1 score vs. the number of distantly supervised sentences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: AutoNER: Test F 1 score vs. the number of human annotated articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Dataset Overview.</figDesc><table><row><cell>Dataset</cell><cell>BC5CDR</cell><cell>NCBI-Disease</cell><cell>LaptopReview</cell></row><row><cell>Domain</cell><cell>Biomedical</cell><cell>Biomedical</cell><cell>Technical Review</cell></row><row><cell cols="2">Entity Types Disease, Chemical</cell><cell>Disease</cell><cell>AspectTerm</cell></row><row><cell>Dictionary</cell><cell>MeSH + CTD</cell><cell cols="2">MeSH + CTD Computer Terms</cell></row><row><cell>Raw Sent. #</cell><cell>20,217</cell><cell>7,286</cell><cell>3,845</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>[Biomedical Domain] NER Performance Comparison. The supervised benchmarks on the BC5CDR and NCBI-Disease datasets are LM-LSTM-CRF and LSTM-CRF respectively<ref type="bibr" target="#b26">(Wang et al., 2018)</ref>. SwellShark has no annotated data, but for entity span extraction, it requires pre-trained POS taggers and extra human efforts of designing POS tag-based regular expressions and/or hand-tuning for special cases.</figDesc><table><row><cell>Method</cell><cell>Human Effort</cell><cell></cell><cell>BC5CDR</cell><cell></cell><cell cols="3">NCBI-Disease</cell></row><row><cell></cell><cell>other than Dictionary</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell></row><row><cell>Supervised Benchmark</cell><cell>Gold Annotations</cell><cell cols="6">88.84 85.16 86.96 86.11 85.49 85.80</cell></row><row><cell>SwellShark</cell><cell cols="4">Regex Design + Special Case Tuning 86.11 82.39 84.21</cell><cell>81.6</cell><cell>80.1</cell><cell>80.8</cell></row><row><cell></cell><cell>Regex Design</cell><cell cols="3">84.98 83.49 84.23</cell><cell>64.7</cell><cell>69.7</cell><cell>67.1</cell></row><row><cell>Dictionary Match</cell><cell></cell><cell cols="6">93.93 58.35 71.98 90.59 56.15 69.32</cell></row><row><cell>Fuzzy-LSTM-CRF</cell><cell>None</cell><cell cols="6">88.27 76.75 82.11 79.85 67.71 73.28</cell></row><row><cell>AutoNER</cell><cell></cell><cell cols="2">88.96 81.00</cell><cell>84.8</cell><cell cols="3">79.42 71.98 75.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>[Technical Review Domain]  NER Performance Comparison. The supervised benchmark refers to the challenge winner.</figDesc><table><row><cell>Method</cell><cell cols="2">LaptopReview</cell></row><row><cell></cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell></row><row><cell cols="4">Supervised Benchmark 84.80 66.51 74.55</cell></row><row><cell>Distant-LSTM-CRF</cell><cell cols="3">74.03 31.59 53.93</cell></row><row><cell>Dictionary Match</cell><cell cols="3">90.68 44.65 59.84</cell></row><row><cell>Fuzzy-LSTM-CRF</cell><cell cols="3">85.08 47.09 60.63</cell></row><row><cell>AutoNER</cell><cell cols="3">72.27 59.79 65.44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ablation Experiments for Dictionary Refinement. The dictionary for the LaptopReview dataset contains no alias, so the corpus-aware dictionary tailoring is not applicable.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell>BC5CDR</cell><cell></cell><cell cols="3">NCBI-Disease</cell><cell>LaptopReview</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Pre</cell><cell>Rec</cell><cell>F1</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell></row><row><cell></cell><cell></cell><cell cols="2">AutoNER w/ Original Dict</cell><cell cols="8">82.79 70.40 76.09 53.14 63.54 57.87 69.96 49.85 58.21</cell></row><row><cell></cell><cell></cell><cell cols="2">AutoNER w/ Tailored Dict</cell><cell cols="8">84.57 70.22 76.73 77.30 58.54 66.63</cell><cell>Not Applicable</cell></row><row><cell cols="8">AutoNER w/ Tailored Dict &amp; Phrases 88.96 81.00</cell><cell>84.8</cell><cell cols="3">79.42 71.98 75.52 72.27 59.79 65.44</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell></row><row><cell></cell><cell>0.85</cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell></row><row><cell>Test F1 Scores</cell><cell>0.70 0.75 0.80</cell><cell>0</cell><cell>5000 # of Distantly Labeled Training Sentences 10000 15000 20000 AutoNER-Gold+DistantSupervision Supervised Benchmark AutoNER-DistantSupervision</cell><cell>Test F1 Scores</cell><cell>0.4 0.5 0.6 0.7</cell><cell cols="4">0 1000 2000 3000 4000 5000 6000 7000 # of Distantly Labeled Training Sentences AutoNER-Gold+DistantSupervision Supervised Benchmark AutoNER-DistantSupervision</cell><cell>Test F1 Scores</cell><cell>0.3 0.5 0.6 0.4</cell><cell>0</cell><cell>1000 # of Distantly Labeled Training Sentences 2000 3000 4000 AutoNER-Gold+DistantSupervision Supervised Benchmark AutoNER-DistantSupervision</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(a) BC5CDR</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) NCBI</cell><cell></cell><cell></cell><cell>(c) LaptopReview</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">https://en.wikipedia.org/wiki/ Wednesday_Addams</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">http://times.cs.uiuc.edu/ ˜wang296/ Data/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">https://www.nlm.nih.gov/mesh/ download_mesh.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">http://ctdbase.org/downloads/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4">https://www.computerhope.com/jargon. htm</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5">http://bio.nlplab.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6">https://nlp.stanford.edu/projects/ glove/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Yu Zhang from University of Illinois at Urbana-Champaign for providing results of supervised benchmark methods on the BC5CDR and NCBI datasets.</p><p>Research was sponsored in part by U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), DARPA under Agreement No. W911NF-17-C-0099, National Science Foundation IIS 16-18481, IIS 17-04532, and IIS-17-41317, DTRA HD-TRA11810026, Google Ph.D. Fellowship and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). Any opinions, findings, and conclusions or recommendations expressed in this document are those of the author(s) and should not be interpreted as the views of any U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Constructing biological knowledge bases by extracting information from text sources</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Kumlien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMB</title>
				<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1999</biblScope>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">De-identification of patient notes with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Young</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ozlem</forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="596" to="606" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised named-entity extraction from the web: An experimental study</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="134" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd annual meeting on association for computational linguistics</title>
				<meeting>the 43rd annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Swellshark: A generative model for biomedical named entity recognition without labeled data</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06360</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised aspect term extraction with b-lstm &amp; crf using automatically labelled datasets</title>
		<author>
			<persName><forename type="first">Athanasios</forename><surname>Giannakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreea</forename><surname>Hossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Baeriswyl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
				<meeting>the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="180" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Prominer: rule-based protein and gene entity recognition</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hanisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Fundel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinz-Theodor</forename><surname>Mevissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliane</forename><surname>Fluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">S14</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Autoentity: automated entity detection from massive text corpora</title>
		<author>
			<persName><forename type="first">Wenqi</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>Computer Science of University of Illinois at Urbana-Champaign</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. Thesis for</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semi-supervised bio-named entity recognition with word-codebook learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pavel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Kuksa</surname></persName>
		</author>
		<author>
			<persName><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 SIAM International Conference on Data Mining</title>
				<meeting>the 2010 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
				<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Banner: an executable survey of advances in biomedical named entity recognition</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graciela</forename><surname>Gonzalez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<publisher>World Scientific</publisher>
			<biblScope unit="page" from="652" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Entity linking at web scale</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction</title>
				<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="84" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<title level="m">Empower sequence labeling with task-aware neural language model</title>
				<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
				<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Proceedings of the 8th International Workshop on Semantic Evaluation</title>
				<meeting>the 8th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2014">2014. SemEval 2014</date>
			<biblScope unit="page">2735</biblScope>
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, and Suresh Manandhar</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distributional semantics resources for biomedical text processing</title>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans</forename><surname>Moen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tapio</forename><surname>Salakoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Symposium on Languages in Biology and Medicine</title>
				<meeting>the 5th International Symposium on Languages in Biology and Medicine<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>In CoNLL</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Clustype: Effective entity recognition and typing by relation phrase-based clustering</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>El-Kishky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangbo</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="995" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Recurrent neural network models for disease name recognition using domain invariant features</title>
		<author>
			<persName><forename type="first">Sunil</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Anand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2216" to="2225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Biomedical named entity recognition using conditional random fields and rich feature sets</title>
		<author>
			<persName><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint workshop on natural language processing in biomedicine and its applications</title>
				<meeting>the international joint workshop on natural language processing in biomedicine and its applications</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="104" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automated phrase mining from massive text corpora</title>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Evaluating word representation features in biomedical named entity recognition tasks</title>
		<author>
			<persName><forename type="first">Buzhou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed research international</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bootstrapping and evaluating named entity recognition in the biomedical domain</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Gasperin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL BioNLP Workshop on Linking Natural Language and Biology</title>
				<meeting>the HLT-NAACL BioNLP Workshop on Linking Natural Language and Biology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Latent aspect rating analysis without aspect keyword supervision</title>
		<author>
			<persName><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 17th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Cross-type biomedical named entity recognition with deep multi-task learning</title>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Curtis</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.09851</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
