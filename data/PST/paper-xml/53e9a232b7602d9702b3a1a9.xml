<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Accurate Branch Prediction for Short Threads</title>
				<funder ref="#_V8Rv65R">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_v5DmUNE">
					<orgName type="full">Semiconductor Research Corporation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bumyong</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Leo</forename><surname>Porter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>San Diego La Jolla</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<postCode>March1-5, 2008</postCode>
									<settlement>Seattle</settlement>
									<region>Washington</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Accurate Branch Prediction for Short Threads</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C.1.2 [Processor Architectures]: Multiprocessors General Terms Design</term>
					<term>Performance Chip Multiprocessors</term>
					<term>Branch Prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-core processors, with low communication costs and high availability of execution cores, will increase the use of execution and compilation models that use short threads to expose parallelism. Current branch predictors seek to incorporate large amounts of control flow history to maximize accuracy. However, when that history is absent the predictor fails to work as intended. Thus, modern predictors are almost useless for threads below a certain length.</p><p>Using a Speculative Multithreaded (SpMT) architecture as an example of a system which generates shorter threads, this work examines techniques to improve branch prediction accuracy when a new thread begins to execute on a different core. This paper proposes a minor change to the branch predictor that gives virtually the same performance on short threads as an idealized predictor that incorporates unknowable pre-history of a spawned speculative thread. At the same time, strong performance on long threads is preserved. The proposed technique sets the global history register of the spawned thread to the initial value of the program counter. This novel and simple design reduces branch mispredicts by 29% and provides as much as a 13% IPC improvement on selected SPEC2000 benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As general purpose processors become increasingly multi-core, we will see the average occupancy time of a single thread on a single core driven down to new levels. This will be a result of several factors. The desire to make better use of the available cores will lead to greater use of architectural and compilation techniques that employ short threads to expose parallelism. Lowered communication latencies, as found between cores on a multi-core architecture, will significantly reduce the cost of migrating a thread between cores, thereby increasing the desirability of migration. As a result, execution models that rely on, or can exploit, shorter threads will become increasingly attractive as the cost of starting a new thread or moving an existing thread is reduced. This research demonstrates that a significant component of the startup cost of very short threads is the cost of ramping up the branch predictor -and the primary startup cost is not the prediction tables themselves, but rather the global branch history typically used to index those tables. This is because the tables of saturating counters will have the chance to learn from previous instantiations of similar threads, but only if the indexing function is repeatable. However, if the global history register contains no thread-specific information, or worse, contains noise, the predictor will neither be predicting correctly, nor learning usefully, until the history register has filled completely with branch history that corresponds to the new thread of execution. The paper examines this phenomenon in the context of a speculative multithreading architecture that frequently spawns new theads, each with an unknowable branch history at the point of spawning.</p><p>Consider an aggressive predictor that has 20-25 bits of global history in the global history register (GHR). For many such predictors, even if the GHR has just a few bits of random noise (GHR bits not relevant to the current execution), the indexed predictor locations will be unlikely to correspond to locations indexed by the previous or next instantiation of the thread. Thus, for any thread that executes less than 50-75 branches (i.e., several hundred instructions), we'd expect the overall branch predict rate to be extremely low. As a point of reference, Marcuello and Gonzalez <ref type="bibr" target="#b22">[23]</ref> report a speculative multithreading architecture with an average thread length of 32 instructions, and Zilles and Sohi <ref type="bibr" target="#b51">[52]</ref> report an average helper thread length of 34 instructions. In the Transactional Coherency and Consistency paper <ref type="bibr" target="#b5">[6]</ref> that investigates the characteristics of common transactions, they report that on 3 out of 6 speculatively parallelized benchmarks the average lengths of their compiler-generated threads (transactions) were quite short -129, 244, and 521 instructions, respectively. This paper presents very small architectural changes that significantly improve the processor's ability to predict branches in short threads, while not compromising in any way the ability to predict for longer threads after the GHR is warmed up. Our solution ensures we have repeatable state in the GHR, yet still allows the predictor to be able to distinguish between threads that are not expected to have the same startup behavior. We examine a number of potential mechanisms, and find that a solution which simply uses program counter bits (from the new thread's starting PC) to initialize the GHR performs as well or better than more complex and speculative mechanisms. Our particular focus is on a speculative multithreading architecture running on a multi-core platform. However, the techniques we demonstrate will also apply to helper threads and compiler parallelization techniques that create large numbers of short threads. It will equally apply to all of these architectures utilizing a multithreaded core. In this work, we also present a simple solution to the case where short threads are the result of excessive core migration.</p><p>This paper is organized as follows. Section 2 motivates our research by introducing background work that cause short threads to be more prominent and their implication for branch prediction. Section 3 discusses related work. Section 4 briefly details our speculative multithreading architectural model. Section 5 describes the simulation framework. Section 6 presents various policies to generate useful global history for a newly spawned thread. Section 7 reports our experimental results and Section 8 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background -The Problem with Short Threads</head><p>There are several architectural factors that will continue to drive down the average stay of a thread on a core, all compelled by the fact that multi-core architectures will (1) reduce the communication and memory-based startup costs for thread initiation and ( <ref type="formula">2</ref>) increase the availability of extra cores that we will want to employ for performance gains, energy savings, etc. Specific examples include speculative multithreading <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref>, or thread-level speculation, which executes multiple not-necessarily-independent short threads in parallel, and detects unpredicted dependence violations -squashing those threads where parallelism was not found. Helper threads <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref> execute short threads in support of the original thread of execution, often for cache prefetching. In some cases, a helper thread only computes the address of a single or a few loads, in others it seeks to capture all the iterations of a loop instance.</p><p>Chapparo et al. <ref type="bibr" target="#b2">[3]</ref> propose core-hopping to eliminate or react to thermal emergencies. Thus, the lifetime of a thread on a particular core will be a fraction of the actual thread lifetime. Similar effects are seen in the heterogeneous multi-core proposals <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b18">19]</ref>, where heavy sampling is used to find the best mapping of threads to cores (resulting in frequent switching of threads between cores), or in Annavaram, et al. <ref type="bibr" target="#b1">[2]</ref> where new threads are initiated at each new instance of parallelism.</p><p>In striving to exploit the ever-increasing availability of cores, compilers will employ techniques that create short threads to extract parallelism <ref type="bibr" target="#b14">[15]</ref>.</p><p>All of these techniques, will be sensitive to the startup costs of a thread. By reducing those startup costs, we can increase the viability of these architectures, and possibly enable new architectural and execution paradigms. Clearly, a huge barrier to the use of execution models with data-flow characteristics <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref> on a conventional architecture is the thread creation overhead. Reducing this thread initiation overhead is the goal of this research.</p><p>We show that the key to quick branch predictor startup is managing the global history register. The global history register was introduced by Yeh and Patt <ref type="bibr" target="#b48">[49]</ref> as a special case of their two-level adaptive branch predictor, with the pattern history table collapsed to a single global entry. McFarling <ref type="bibr" target="#b25">[26]</ref> described more explicitly the benefits of the GHR to exploit the correlations between different static branches, and demonstrated its usefulness in his gselect and gshare predictors. Since, nearly every important predictor has used the GHR in some way. It should be pointed out that the two-level predictor's pattern history table creates an even bigger problem, as we lose the context of every entry in the table when we change cores. Our dependence on the GHR has only grown over time. The 21264 (EV6) combining predictor uses a 12-bit GHR to index both the global prediction table and the choice predictor, and the other half of the predictor uses the aforementioned two-level predictor. The EV8 predictor <ref type="bibr" target="#b35">[36]</ref>, based on the 2Bc-gskew predictor <ref type="bibr" target="#b36">[37]</ref>, indexes three tables with GHR bits and uses 21 total bits.</p><p>Perceptron predictors <ref type="bibr" target="#b16">[17]</ref> have been proposed that use as much as 36 bits of global history. Rather than using two-bit saturating counters, these predictors use a simple neural network indexed by PC and trained to individual bits of the GHR by branch outcomes. These predictors present an interesting option in this work. The Per-  ceptron predictor is more resistant to noise than other GHR-based predictors. Thus, it is no longer necessary for the entire GHR to be filled with meaningful branch outcomes for the predictor to start performing well. However, due to their reliance on larger GHRs, it still requires a significant number of branches before the useful data in the predictor begins to dominate the noise. We examine the effectiveness of our techniques on the perceptron predictor in Section 7.</p><p>One alternative solution to our problem would be to simply use the best predictor we could find that did not use the global history register, or any other stored branch pattern; unfortunately, that limits our choices excessively, to essentially a bimodal <ref type="bibr" target="#b38">[39]</ref> branch predictor (a simple BTB based predictor or next-Icache-line predictor, in the best case, would match the bimodal predictor). The bimodal is simply a table of saturating counters indexed by PC. In Figure <ref type="figure">1</ref>, we see that compared to a gshare predictor <ref type="bibr" target="#b25">[26]</ref> on the SPEC2K benchmarks, the bimodal predictor gives up way too much performance (both at each point, and asymptotically) to be considered seriously.</p><p>Figure <ref type="figure" target="#fig_0">2</ref> illustrates the problem with branch prediction in the presence of short thread occupancy time on a core. In this experiment, we take a single thread and force it to migrate round-robin between four cores, moving every n instructions. We see that (at least for threads of 2000 instructions or smaller) the branch mispredict rate increases, becoming quite significant as the threads get below 500 instructions. In the second bar, where we also migrate the GHR, we see that the mispredict rate is almost completely unaffected. This confirms our thesis that the problem is with the GHR value, not the data in the tables themselves. As long as the GHR is correct, each predictor is able to warm up to the program's branch behavior separately.</p><p>However, if we do not migrate a new GHR value, the GHR's global history on a new core is the residual information from the last thread executed on that core. The residual data in the GHR typically does not provide any relevant information with regard to the execution of the new thread (unless the sequence of executed threads is highly repeatable). The misleading GHR value will be used in the indexing function to produce branch predictions. In addition, the counters associated with those indices will be polluted.</p><p>This result presents the first contribution of this paper -that when short threads are caused by excessive core migrations (e.g., the core hopping and heterogeneous swapping examples above), the problem is easily and completely solved by just migrating the GHR with the thread.</p><p>However, this does not help in the case of helper threads or compiler-generated short-thread parallelism, because there is no obvious GHR to migrate. Similarly, for speculative multithreading, there is a correct GHR that corresponds to the single-thread execution point of the new thread's starting PC, but that GHR is not known at the time the thread is spawned. Thus, in these scenarios, the thread would likely start with the residual state left in the GHR by the last thread executed, and performance would again resemble the dark bar in Figure <ref type="figure" target="#fig_0">2</ref>.</p><p>This paper focuses in particular on the Speculative Multithreading (SpMT) problem, but the solution should be equally applicable for the other execution models that incur frequent thread spawns. We will examine several options for introducing (artificial) state into the GHR. Our baseline is the default architecture that maintains whatever bits were in the GHR when the new thread begins execution. At the opposite end of the spectrum, we will examine several ways to predict the value the GHR will have when the spawning thread arrives at the CQIP (the starting point of the spawned thread). Alternatively, we will look at solutions that simply strive to set a consistent starting point for each thread, either by clearing the GHR, or setting it to a thread-specific value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Other Related Work</head><p>Most proposed branch predictors of the last 15 years have included some kind of branch pattern history, and usually a global history register. In addition to those predictors described in the previous section, it would also include the bi-mode predictor <ref type="bibr" target="#b38">[39]</ref>, the agree predictor <ref type="bibr" target="#b40">[41]</ref>, the YAGS predictor <ref type="bibr" target="#b10">[11]</ref>, and several flavors of the Perceptron predictor <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b15">16]</ref>, already mentioned.</p><p>More recently proposed branch predictors show that even longer histories can provide improved performance. The O-GEHL <ref type="bibr" target="#b33">[34]</ref> predictor uses histories from 100-200 bits long, the L-TAGE <ref type="bibr" target="#b34">[35]</ref> predictor uses a history length of 4 to 640 bits, and PPM <ref type="bibr" target="#b4">[5]</ref> based predictors also rely on very long history lengths to determine the closest matching previous pattern. Although O-GEHL and L-TAGE have the ability to adapt to using shorter histories, longer histories are still necessary, for some benchmarks, for high accuracy.</p><p>We examine branch predictors for short threads in the context of a speculative multithreading architecture. A wide variety of SpMT models have been proposed since the original Multiscalar architecture <ref type="bibr" target="#b39">[40]</ref>. Those proposed include models that work best when threads are largely independent <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b6">7]</ref> and those that work even in the presence of dependences <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32]</ref>. It includes those that squash violating threads completely, and those with the ability to incorporate individual instruction results of a violating thread <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21]</ref>. Some models rely primarily on hardware prediction of liveins <ref type="bibr" target="#b23">[24]</ref> and others use software to compute register and memory live-ins <ref type="bibr" target="#b31">[32]</ref>. Recently, it has been shown that an architecture that supports transactional memory can do some amount of thread-level speculation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Gummaraju and Franklin address branch prediction on the Multiscalar <ref type="bibr" target="#b11">[12]</ref> speculative multithreading core. They see branch mispredict rates rise to 41% in that architecture. However, their solution focuses on a two-level local branch predictor (no GHR, but lots of per-address branch history to get corrupted) which is shared among the threads. Thus, much of their focus is on attempting to try to reconstruct a particular branch's history pattern in the face of branches fetching and committing out of order. They are able to gain a significant amount of the performance back for their architecture. Unfortunately, those techniques do not translate either to our predictors (with heavy reliance on the GHR) or to our architecture (CMP with separate predictors and decoupled history).</p><p>Several papers examine branch prediction on simultaneous multithreading processors <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29]</ref>. In general, branch prediction was not shown to be a significant problem for that architecture, despite sharing of a single physical branch predictor. However, none of those studies examined an execution model with short threads or frequent movement of thread control flow across thread contexts. Because we show that the problem is not the lack of predictor table state, but rather the GHR, an SMT processor would be just as vulnerable to these problems as a multi-core processor.</p><p>The effectiveness of the solutions examined in this paper will be somewhat sensitive to the details of the speculative multithreading architecture we use to test them, so we describe our architecture in detail in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Baseline Architecture</head><p>Our underlying architecture implements a form of speculative multithreading. A wide variety of SpMT execution models have been proposed. This section details the particular architecture we simulate to evaluate our different branch prediction optimizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Speculative Multi-threading</head><p>To explore the performance improvement of branch prediction techniques on short threads, we employ a SpMT architecture which causes frequent thread startup due to the spawning of speculative threads. A SpMT processor improves single thread performance by splitting the execution into several speculative threads which are executed on different cores. A speculative thread begins execution with a speculative architectural state, possibly including predicted register and memory values. By running the speculative thread(s) in parallel with the non-speculative thread, the SpMT processor exploits intra-thread parallelism.</p><p>Using the terminology from <ref type="bibr" target="#b31">[32]</ref>, a speculative thread is started when the first address from a spawning pair is fetched by the processor. A spawning pair includes two instructions that are referred to as the Spawning Point (SP) and the Control Quasi-Independent Point (CQIP), respectively. The SP is an instruction that triggers the processor to create a new speculative thread. The CQIP is the first instruction that the speculative thread executes. A less speculative thread (often the spawning thread) will stop execution when it arrives at an active CQIP of a more speculative thread and validates that control and data passed correctly from one thread to the other.</p><p>When a speculative thread is found to be no longer valid, the thread is squashed. The SpMT processor may squash a thread for several reasons. During the thread spawning event, register values and even memory inputs of the new speculative thread may be predicted by using a prediction algorithm <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b31">32]</ref>. If values are incorrectly predicted, the error may be discovered when the less speculative thread tries to validate the predictions. In other cases, an invalid input value may cause an exception to occur, resulting in a squash. Additionally, unanticipated interthread memory dependencies are possible reasons to squash the thread. For example, if the parent thread writes to a memory block already read by the speculative thread, the speculative thread is executing incorrectly. When one thread is squashed its descendant threads are also squashed at whatever point they happen to be executing.</p><p>Branch prediction accuracy also affects the number of squashed threads. If a branch outcome is predicted incorrectly, the incorrect path could encounter an SP. In this case, the processor spawns a speculative thread, but the thread is squashed when the correct branch target is resolved.</p><p>We make several assumptions about the underlying architecture, many of which are relatively orthogonal to the branch predictor problem. We assume little compiler support, to make the model more general, relying on structures easily recognized by hardware to identify spawning pairs -more specifically, we use loop continuations and procedure continuations. Thus, a procedure call becomes the SP, and the next static instruction (the return point) becomes the CQIP. On backwards branches, the branch target is both the SP and CQIP (allowing us to execute iterations in parallel). We assume support for fast thread spawn on another core without significant software overhead. If operating system code, for example, were executed to fork and set up a new thread, the GHR would naturally be filled (for better or worse) by the OS code. However, this type of overhead would prevent SpMT from being viable, and is not a reasonable assumption. Thus, the new thread begins executing user code at the CQIP without OS intervention.</p><p>Several other assumptions are made in some of our experiments to provide repeatable results for this study. In our simulations which model SpMT execution most faithfully, the results are highly noisy. For example, with several speculative threads running and competing for a limited number of idle cores, which thread was successful in spawning a new thread often depended on minor differences in performance. Thus, as we varied the branch performance, the actual threads that were spawned, and in what order and what frequency, varied widely from run to run.</p><p>Thus we make the following set of simplifying assumptions in most of the experiments in this paper, which provided very repeatable results, with the same threads being spawned, and each of those same threads having equal opportunity to impact performance in each experiment.</p><p>We assume an artificial 30% squash rate. In our SpMT framework, the best performance is achieved when liberal spawning policies produce a squash rate that is around 60%. However, to avoid overstating our results, and to account for other architectures that target more conservative spawning, we use the much lower value for these experiments. This conservative assumption, then, reduces the noise that is seen in the GHR. On the other 70% of spawns, we assume perfect register and memory prediction. A squashed thread is terminated at a relatively random location during its execution.</p><p>We also run the spawned threads serially. This again allows us to carefully run the same threads in the same order for repeatable experiments. It also provides a couple of very important analytical advantages -(1) it allows us to model an oracle GHR generator for comparison, because we can know the actual value of the GHR at the CQIP, and (2) it allows us to separate the performance of different classes of threads, since run serially the threads have an additive impact on performance. For example, we can look at the performance of short threads, medium threads, and long threads in separable groups. But we expect that the results are still highly indicative of the overall performance of a SpMT system, since we are running the same threads (that would execute and not be squashed).</p><p>But we also show the performance of our best prediction architecture in the context of a much more faithful model of speculative multithreading. Those results confirm the usefulness and performance of these techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Methodology</head><p>This section describes our simulation framework, baseline processor core architecture, and benchmark selection.</p><p>Our underlying architecture implements a form of speculative multithreading. We modified a version of SMTSIM <ref type="bibr" target="#b45">[46]</ref> to imple- Our framework simulates SpMT running on a parallel or multicore processor with the parameters listed in Table <ref type="table" target="#tab_1">1</ref>. We model 4 out-of-order cores, with shared L2 caches. Each core has a 2Bcgskew branch predictor similar to the EV8 predictor <ref type="bibr" target="#b35">[36]</ref>, but without a few of the implementation idiosyncrasies, such as the shared hysteresis bits. The cores have a relatively deep pipeline, similar to a Pentium 4. More details of the branch predictor are given in Table <ref type="table" target="#tab_2">2</ref>.</p><p>2Bc-gskew <ref type="bibr" target="#b36">[37]</ref> includes four different prediction tables, three of which are indexed with the GHR. Three of these tables are parts of an e-gskew <ref type="bibr" target="#b26">[27]</ref> predictor (actually, two e-gskew tables and a bimodal table), and the fourth is the meta predictor. The meta predictor chooses between the results produced by the egskew predictor and the bimodal predictor. The three tables (two e-gskew and the meta table) use different indexing functions based on bitwise combinations of the GHR and PC.</p><p>The listed minimum and maximum spawn distance represents a filter that causes a thread not to be spawned if the expected distance between the spawn point and the CQIP is out of that range. Otherwise, a new thread will always be initiated at a spawn point if a core is available.</p><p>We choose eight benchmarks from the SPEC2000 suite. We intentionally select eight programs that are sensitive to the (overall) branch prediction accuracy in our simulation framework. We do this by filtering out those programs whose performance improved by less than 3% when a perfect branch predictor was introduced. We simulate 100 million instructions starting at a single execution Simpoint <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Generating Global History</head><p>To improve prediction accuracy and reduce destructive behavior caused by meaningless GHR values, several approaches will be considered. These various approaches fall into two broad categories. In the first category are techniques that attempt to predict or re-create the expected GHR, using current or historical information. The second category of techniques, conversely, only seek to provide a consistent starting point for the branch predictor every time the same thread starts up. These techniques will each be described in the following two sections.</p><p>All techniques will be compared with the original result, which retains whatever value was left in the GHR by the last thread which executed on that core.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Policy New GHR Value Original</head><p>No modification applied Oracle</p><p>The GHR value at a given point as if the thread has been executed in a single core Pre-spawn The parent's GHR at the SP Concat The parent's GHR concatenated with the branch history from the SP to the CQIP of the parent thread when previously executed Last-CQIP The GHR at the CQIP of the last thread Zero 0 PC</p><p>The PC of the CQIP Xor</p><p>The PC ? the parent's GHR Table <ref type="table">3</ref>. GHR modification policies and their descriptions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Approximating the Real GHR Value</head><p>As an upper limit on the performance of this group we use the oracle policy. In SpMT, a speculative thread begins execution before all preceding branches are executed. The outcomes of these branches (the real GHR value) would be in the GHR at the start of the speculative thread in a perfect model. Although impossible to generate in real hardware, the simulator can be used to provide the real GHR to the speculative thread as if all the intervening branches had already been executed. Although it is not possible to obtain the real GHR value, it should be possible to construct an estimate or a good proxy for the real GHR. The pre-spawn policy forces the speculative thread to inherit the GHR of the parent thread before it begins to execute. Since the parent's GHR at the SP does not contain any information regarding the future branches, this particular GHR value is incomplete. However, in many cases, this GHR will be unique to the SP, and thus indicative of the CQIP. In addition, by containing pre-SP path information, it may even usefully distinguish different instantiations of the thread. This can be particularly effective if the number of branches between the SP and CQIP are small. One downside to this policy is that it creates aliasing between instructions following the SP and those following the CQIP (which run immediately on different cores, but over time can execute on the same core).</p><p>The concat policy also utilizes the parent's GHR value at the SP, but it combines it with an estimate of the branch behavior between the SP and the CQIP. It does this by simply storing the bits from the last time this thread was spawned. It then concatenates the spawning thread's current GHR with the estimated history for the intervening branches. This policy improves the pre-spawn policy by referencing the missing branch outcomes. If there exists a dominant path from the SP to the CQIP of the parent thread each time these instructions are executed, the speculative thread has a good chance of emulating the real GHR exactly. If the program path behavior varies significantly from instance to instance (between the SP and CQIP), this policy no longer works in our favor.</p><p>The final policy of Group I is the last CQIP policy. This policy simply reuses the saved GHR from the last time a thread reached this CQIP. Thus, it uses old path data from both before and after the SP. This operation is a bit easier than concat; however, the dependence on the last execution of the spawn pair is greater, as it uses no path history from the current instantiation.</p><p>Although the concat and last CQIP are promising candidates to improve prediction accuracy, it could require significant storage to maintain the history from each SP/CQIP pair. In this study, we assume "large enough" structures to always provide the desired data without aliasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Providing a Consistent Starting Point</head><p>Our simplest mechanism is the zero policy. It simply clears the GHR when a new thread begins. The advantage of providing a con-sistent starting point is that it allows the predictor to start predicting reliably as soon as the GHR accrues enough history to distinguish it from other thread starting points. It also minimizes the amount of damage a polluted GHR can do to the prediction tables. However, the problem with the zero policy is that it creates aliasing among all threads at startup.</p><p>The pc policy provides a unique initial GHR state for each thread by generating the GHR bits from the PC of the speculative thread's CQIP. We first disregard the four least significant bits and use the remaining bits for the new GHR value (masked by the number of GHR bits desired). In an architecture with 32-bit fixed length instructions, the two least significant bits are meaningless. Furthermore, we ignore two more bits since the average basic block size is found to be greater than 4 <ref type="bibr" target="#b8">[9]</ref>. The PC-based GHR provides a consistent starting point for all threads spawned from the same spawn point. This policy will be beneficial particularly if the branch pattern at the beginning of the thread is consistent (and not heavily dependent on the path before the CQIP). If this is true, this technique can even outperform the real GHR.</p><p>Finally, the xor combines a predictor from each group. This policy adds some path information to the previous policy, which can help if the branch behavior of the new thread is more heavily path dependent. In this case, we use the parent's GHR, as used in the pre-spawn policy above. The xor policy combines the PC and the parent's GHR by using the XOR operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results</head><p>In this section, we evaluate the branch prediction accuracy with our generated GHR values. We demonstrate that most policies improve the prediction accuracy and also result in IPC improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">GHR Correlation</head><p>Ultimately, our goal is to replace a GHR that contains noisy data (which is not expected to be well correlated with the behavior of the new thread) with data that correlates more closely to the new thread's branch behavior. We study that phenomenon in this section -the correlation of potential GHR values with the branch behavior of the spawned thread.</p><p>We did extensive studies of the correlation of the GHR (real or fabricated, according to our various proposals) to the branch behavior at the beginning of a new thread. We will just summarize those results here. For simplicity, we will use a crude definition of correlation. For the average GHR in place at the start of a new thread, what is the frequency of the most likely branch path observed when the thread began with that GHR (the branch path must be identical out to 21 branches)? For example, assume we saw three different paths, A with 50% frequency, and B and C each with 25% frequency. Assume we also observed two initial GHRs, X (which always resulted in path A) and Y (which resulted in B half the time and C half the time). Since X and Y occur with equal  frequency, the average correlation would be 75%, composed of X's 100% and Y's 50% frequency in seeing their most likely branch path. For the zero predictor, which only supplies a single GHR to all threads, it would record a 50% correlation for the same set of paths.</p><p>For the original case, the correlation is surprisingly high. We observe nearly a 50% correlation between the starting GHRs and the most likely paths. But most of our predictors do better. The oracle achieves nearly 70%. Even more surprisingly, the pc predictor matches the correlation of the oracle. This is despite the fact that the oracle can potentially differentiate both different threads and a different spawn context (in terms of branch history) for those different threads. The pc predictor can only differentiate different threads, and has no knowledge of the context in which a thread was spawned. The mechanisms which manufacture GHRs (prespawn, concat, last-ghr) all have lower correlations. The zero predictor, which cannot even differentiate between threads, has the lowest correlation, less than 30%.</p><p>These results, particularly the correlation data of the pc predictor, imply that at the CQIP points we are selecting, the pre-CQIP branch history is not overly important in predicting post-CQIP branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Branch Prediction Accuracy</head><p>Figure <ref type="figure" target="#fig_2">3</ref> shows branch prediction accuracy and IPC speedup for all of our different policies. These results are shown in four parts. In Figure <ref type="figure" target="#fig_2">3</ref>(a), accuracy and performance for very short threads (&lt;500 instructions) is shown. The oracle and pc policies perform the best for short threads and, in fact, our pc model performs as well as oracle. These reduce mispredictions by 35% and 38% respectively and provide an 11% IPC speedup on those threads alone.</p><p>It is not altogether surprising that resetting the GHR to a threadspecific value can even beat the oracle predictor (which uses the full, correct, GHR) in a few of our benchmarks. If the path after the CQIP is not highly correlated with the path before the CQIP, setting the GHR to a single value at the CQIP is actually better. In our thread-spawning model, we tend to place the CQIP in locations where the correlation may be minimized -at procedure boundaries and loop iteration boundaries. This indicates that expensive efforts to try to predict the exact GHR at these boundaries is unnecessary.  For SpMT systems with a more general thread spawning strategy <ref type="bibr" target="#b31">[32]</ref>, this result may still hold. This is because a good CQIP will tend to be control flow independent of prior branches, and also represent an execution discontinuity in that it seeks to minimize the number of values live across the CQIP <ref type="bibr" target="#b22">[23]</ref>.</p><p>Figure <ref type="figure" target="#fig_2">3</ref>(b) shows the same results, but for threads less than 2000 instructions (but longer than 500). In these results, the same effects appear but are dampened by the fact that the GHR now has time to fully warm up. In this range, both the pc and zero policies are essentially equivalent to the oracle. Similar to threads less than 500 instructions, the pc policy reduces mispredictions by 36% and achieves a 10% IPC speedup.</p><p>Even for the large threads (Figure <ref type="figure" target="#fig_2">3</ref>(c)) there are non-trivial differences between our techniques, and a clear advantage to having a policy to synthesize the GHR. The gains, of course, are smaller. Zero and pc provide a 7% and 6% speedup respectively.</p><p>Figure <ref type="figure" target="#fig_2">3</ref>(d) provides the actual overall results. The oracle policy, because of its strong performance with short threads, performs better than the pc policy, which clearly outperforms all of the realistic approaches. The oracle policy provides a 37% reduction and the pc policy provides a 34% reduction in mispredicted branches. Each policy provide a 9% IPC speedup. Crafty obtains the strongest improvement from pc -a 17% speedup. The pc policy improved Perl by 15% although most of the proposed policies did equally well. Vpr is the only benchmark for which the pc policy hurts performance.</p><p>So despite our efforts to construct a reasonable GHR, we find that the simple pc policy consistently beats those techniques. The intuition is as follows. For threads whose control flow behavior is relatively independent of the pre-CQIP branch history, using a single value is at least as good as using the real history. On the other hands, for those threads whose control flow is highly correlated to the pre-CQIP history, a manufactured history that uses obsolete data is likely to do more harm than good.</p><p>Another useful insight from these results comes from the fact that the pc predictor is competitive with, and in some specific cases (especially when considering individual threads) better than the oracle predictor. This implies that in some cases the GHR contains much more information than is needed. When branches are no longer correlated with the history, the diverse values in the GHR only make it harder to train, and adds pollution to the predictor. We can possibly apply this even in situations where threads are not being migrated or spawned. If we can identify those points (where there is some kind of break in correlation) and set the GHR to a PC-specific value, we should be able to improve the accuracy of any of the GHR-based predictors. Likely points where this policy might be employed would be procedure boundaries and loop exitsbecause there is more likely to be a discontinuity (low correlation) between the preceding path and the following path. This is the subject of future research.</p><p>The fact that the pc policy is the clear winner is fortuitous for several reasons. First, the cost of implementation is effectively none. Even pre-spawn would have a small cost, as the spawning thread would need to send it's GHR to the new core. But the pc policy has effectively no cost because the pc must already be sent to start the thread. Second, the PC scheme will translate naturally to our other target environments -helper threads and short compilergenerated threads -and should perform equally well there. It is not clear that the schemes that use, for example, pre-spawn path would be as useful in those environments, particularly for the compilergenerated threads.</p><p>Thus, we have addressed all of the discussed sources of short threads. For long threads with frequent migration, we have shown that simply migrating the GHR is sufficient. For speculative multithreading, we set the GHR to a thread-specific value (derived from the program counter). We have not specifically demonstrated short helper threads or short compiler-generated threads, but because those environments will share the most important features of our environment -short threads, no clear "correct" value for the GHR, and spawned execution often independent of the code that preceded the point of spawning -we expect the pc technique to do well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Transferring Branch Predictor State</head><p>We showed evidence in Section 2 that the problem with distributed branch prediction is not the prediction table state, but rather with the global history state contained in the GHR. We explore that thesis more carefully here. We model a scheme that transfers over the entire predictor state (for each of the tables in the 2Bc-gskew predictor) when a thread is spawned -also in an oracle manner, using the actual state at the CQIP. However, this scheme does not solve the GHR problem. Additionally, we do not charge for the cost of transferring all of this data. We call this the original-single predictor model. We compare it with our pc model (now called pcunshared) for clarity, and another policy which transfers all predictor state and the oracle GHR -the oracle-single predictor. We use the term "single predictor" because transferring all predictor state is very similar to using a single predictor.</p><p>In Figure <ref type="figure" target="#fig_4">4</ref> we see that the cost of not addressing the GHR issue is very high, and the ability to transfer predictor state does not overcome that handicap. But even further, we see that (comparing the pc and oracle results), transferring the full predictor state actually has no value. This is a result of the tradeoff between losing some history information and being able to gain some predictor space (across the four cores).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Wrong Path Spawns</head><p>By simplifying our simulated SpMT framework and trying to run deterministic, repeatable experiments, we simplified away one of the key advantages of accurate branch prediction in our SpMT architecture. In this architecture, we spawn threads when we fetch an SP instruction, but for the purposes of this study we did not cause a spawn to happen when the SP was encountered on the wrong path. In a real architecture, however, that would happen (unless spawn was delayed until commit, which would significantly increase the observed thread startup overhead). In this section, we seek to understand the impact of our branch prediction mechanisms on wrong path spawns.</p><p>The primary cost of a wrong path spawn is the opportunity cost of not having that core (and possibly other cores running threads spawned by the incorrectly spawned thread, and so on) available to execute correct-path threads. An additional overhead is the cache pollution in the new core resulting from the execution of the incorrectly spawned thread. Even if the mispredict is discovered quickly, the communication cost to announce the squash and the time to drain the pipeline will still result in a loss.</p><p>Wrong-path prediction of speculative threads has been presented in <ref type="bibr" target="#b41">[42]</ref>, but we do not assume that hardware support here. We present preliminary results given our SpMT model in Figure <ref type="figure" target="#fig_5">5</ref> which demonstrates that branch prediction using our pc policy substantially reduces wrong-path spawns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Sensitivity to the Branch Predictor</head><p>All results up to this point have been shown using a single branch predictor, in particular a branch predictor with heavy reliance on the GHR. In this section, we examine the effectiveness of our best technique in the presence of other branch predictors. In addition to the 2Bc-gskew predictor, we also model the gshare predictor <ref type="bibr" target="#b25">[26]</ref>, the Alpha 21264 tournament predictor <ref type="bibr" target="#b17">[18]</ref>, and the perceptron predictor <ref type="bibr" target="#b16">[17]</ref>. Figure <ref type="figure" target="#fig_6">6</ref> demonstrates that while indeed the EV8like predictor is most sensitive to the short-thread GHR problem, all predictors are sensitive to a significant degree, and all see their prediction accuracy improved.</p><p>The perceptron predictor, as previously noted, is able to predict in the presence of noise. However, because it uses a longer GHR, it still takes some number of branches before the noise is overcome by the meaningful bits in the GHR. The perceptron predictor modeled here uses a 28-bit GHR.</p><p>It must be noted that all of these predictors are still heavily influenced by the path discontinuities inherent to a speculative multithreading architecture. Although the influence is greatly reduced by our solutions, it still remains even in those results. One evidence of this is the fact that the magnitude of the predict rates (both with and without our solutions), and even the relative ordering of the predictors is different than what the literature would lead one to expect. This is because the performance of these predictors on a speculative multithreading architecture is heavily influenced by how well each predictor adapts to these discontinuities, and that adaptability varies by predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Full Speculative Multithreading</head><p>We greatly simplified our speculative multithreading simulation infrastructure to induce repeatability in the experiments and to facilitate analysis of the data. Those results indicate significant gains in predict rate and execution rate for both short and mediumlength threads. This section confirms that those results hold for a more faithful speculative multithreading implementation.</p><p>In this section, we allow threads to run in parallel to the extent that the code allows, and we squash threads on actual memory violations (rather than probabilistically). We use the same spawning points and control-quasi independent points. We do, however, assume a somewhat more aggressive system that allows a thread to be spawned if the expected overlap between the main thread (before reaching the CQIP) and the speculative thread is greater than 10 instructions. This would be appropriate for a system where the thread initiation overhead is low -a reasonable assumption since that is the goal of this research. The resulting average thread length for these simulations is about 200 instructions. We no longer assume memory dependence prediction, but squash on any memory violation between threads. Thus, the GHR is a product of the last committed instructions from the previous completed or squashed thread on that core. We are again using the EV8 predictor.</p><p>The results are shown in Figure <ref type="figure" target="#fig_7">7</ref>, which compares a system that makes no special accomodation for the GHR (representing virtually all former SpMT results, in that respect) and one that uses the PC to initialize the GHR when a new thread is spawned. We see that these results do track fairly well with the prior results. Crafty gets the most benefit from the pc technique, with a 13% improvement.</p><p>Vpr is still the only benchmark that does not respond well. Overall, we see a 29% overall reduction in branch mispredicts with our best predictor.</p><p>Given the cost of our GHR synthesis solution (none), and the tangible gains for a wide variety of advanced predictors, this solution is an obvious choice for any architecture that has the ability to generate threads quickly and often, without OS overhead, on another core.</p><p>Again, this models a specific SpMT implementation, with accurate register prediction, no memory prediction (but confidence counters to avoid spawning frequently squashed threads), and no compiler support for improved placement of SPs and CQIPs. However, we expect these results to be relatively general, as the problem of frequently starting short threads without accurate GHR data is fairly common in the various proposed architectures. Even with compiler support for identifying CQIPs, we would tend to place them at points of discontinuity, where the pc policy is likely to be most effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>This paper demonstrates that significant branch predictor state is lost when control transfers across cores or contexts in a multiprocessor or multithreaded architecture. If those threads do not execute long, the cost of the resulting branch mispredicts is never amortized. In particular, we model a speculative multithreading architecture running on a CMP, aggressively spawning threads.</p><p>We show that the critical loss of state lies entirely with the global branch history, as stored in the GHR. The branch predictor state stored in the predictor tables themselves is of no account, because if the program runs long enough, each core's tables will acquire that state. This implies that we can transfer that state extremely quickly. However, we further show that the best solution does not transfer any global history, but rather synthesizes a value in the new core's GHR in such a way that it allows each unique thread to update and use it's own branch history immediately. We do this by constructing the initial GHR out of the meaningful bits of the program counter at the thread's starting address.</p><p>This results in significant (relative to the cost) performance gains on a realistic speculative multithreading framework. We show this both for a somewhat constrained SpMT simulation environment that gives us repeatable results and allows us to analyze the data carefully, and also for a more realistic SpMT environment with threads running in parallel and being squashed based on actual execution characteristics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Average mispredict rate across SPEC2K benchmarks when a migration between cores is forced every N instructions (Predictor: 2Bc-gskew).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Branch prediction accuracy and relative IPC to Original for threads with committed instructions (a) less than 500, (b) less than 2000 but greater than 500, (c) greater than 2000, and (d) average over all lengths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Comparison of the pc policy against idealized branch predictor as if all cores share one predictor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Threads spawned while the processor is executing incorrectly predicted paths</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Mispredict rate for examined branch predictors using the baseline and our pc policy. Results for short threads (less than 500 instructions) are on the left and overall results on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Performance of a full speculative multithreading framework with and without our best predictor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Architectural Specification</figDesc><table><row><cell>Cores</cell><cell>4</cell><cell></cell><cell cols="3">I cache miss penalty</cell><cell>17 cyc</cell></row><row><cell>Fetch width/core</cell><cell>4</cell><cell></cell><cell>D cache</cell><cell></cell><cell>64K, 2 way</cell></row><row><cell>INT instruction queue</cell><cell cols="2">64 entries</cell><cell cols="3">D cache miss penalty</cell><cell>17 cyc</cell></row><row><cell>FP instruction queue</cell><cell cols="2">64 entries</cell><cell cols="2">shared L2 cache</cell><cell>512K, 2 way</cell></row><row><cell>Reorder Buffer entries</cell><cell>256</cell><cell></cell><cell cols="2">L2 miss penalty</cell><cell>44 cyc</cell></row><row><cell>Branch Predictor</cell><cell cols="2">2Bc-gskew</cell><cell>L3 cache</cell><cell></cell><cell>4 MB, 2 way</cell></row><row><cell>Br mispredict penalty</cell><cell cols="2">21 cycles</cell><cell cols="2">L3 miss penalty</cell><cell>92 cyc</cell></row><row><cell>Cache line size</cell><cell cols="2">64 bytes</cell><cell cols="2">Fork penalty</cell><cell>10 cyc</cell></row><row><cell>I cache size</cell><cell>64K</cell><cell></cell><cell cols="3">Min spawn distance</cell><cell>20</cell></row><row><cell>I cache assoc</cell><cell>2 way</cell><cell></cell><cell cols="3">Max spawn distance</cell><cell>10000</cell></row><row><cell></cell><cell></cell><cell>BIM</cell><cell>G0</cell><cell>G1</cell><cell>META</cell></row><row><cell cols="2">prediction table</cell><cell>16K</cell><cell>64K</cell><cell>64K</cell><cell>64K</cell></row><row><cell cols="2">history length</cell><cell>4</cell><cell>13</cell><cell>21</cell><cell>15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Characteristics of 2Bc-gskew predictor ment the described model. SMTSIM executes unmodified alpha ISA code and supports out-of-order SMT or CMP processors. In this study, SMTSIM is used to simulate execution of a CMP.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers for their helpful insights. This research was supported in part by <rs type="funder">NSF</rs> Grant <rs type="grantNumber">CCF-0541434</rs> and <rs type="funder">Semiconductor Research Corporation</rs> Grant <rs type="grantNumber">2005-HJ-1313</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_V8Rv65R">
					<idno type="grant-number">CCF-0541434</idno>
				</org>
				<org type="funding" xml:id="_v5DmUNE">
					<idno type="grant-number">2005-HJ-1313</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A dynamic multithreading processor</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akkary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Driscoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="page" from="226" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mitigating Amdahl&apos;s law through EPI throttling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Annavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grochowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="page" from="298" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Thermal-aware clustered microarchitectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chaparro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Design</title>
		<imprint>
			<date type="published" when="2004-10">Oct. 2004</date>
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simultaneous subordinate microthreading (SSMT)</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Chappell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1999-05">May 1999</date>
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis of branch prediction via data compression</title>
		<author>
			<persName><forename type="first">I.-C</forename><forename type="middle">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Coffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996</date>
			<biblScope unit="page" from="128" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The common case transactional behavior of multithreaded programs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Minh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carlstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Symposium on High-Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2006-02">Feb. 2006</date>
			<biblScope unit="page" from="266" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Architectural support for scalable speculative parallelization in shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cintra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Mart?ez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Speculative precomputation: Long-range prefetching of delinquent loads</title>
		<author>
			<persName><forename type="first">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lavery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Path-based hardware loop prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Control, Virtual Instrumentation and Digital Systems</title>
		<imprint>
			<date type="published" when="2002-08">August 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A preliminary architecture for a basic data-flow processor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Misunas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1975-06">June 1975</date>
			<biblScope unit="page" from="126" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The YAGS branch prediction scheme</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Branch prediction in multi-threaded processors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gummaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2000-10">Oct. 2000</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Programming with transactional coherence and consistency (TCC)</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Carlstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hertzberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="2004-10">Oct. 2004</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Branch prediction and simultaneous multithreading</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="1996-10">Oct. 1996</date>
			<biblScope unit="page">169</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A study of the EARTH-MANNA multithreaded system</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H J</forename><surname>Hum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Maquelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Hendren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Parallel Programming</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="348" />
			<date type="published" when="1996-02">Feb 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast path-based neural branch prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">36th International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page">243</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural methods for dynamic branch prediction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="369" to="397" />
			<date type="published" when="2002-02">Feb. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The alpha 21264 microprocessor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE MICRO</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="1999-03">Mar. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Single-ISA heterogeneous multi-core architectures: the potential for processor power reduction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">36th International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Conjoined-core chip multiprocessing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">37th International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2004-12">Dec. 2004</date>
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data-driven multithreading using conventional microprocessors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kyriacou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Evripidou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1176" to="1188" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Speculative multithreaded processors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marcuello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Universitat Politecnica de Catalunya</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph. D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Thread-spawning schemes for speculative multithreading</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marcuello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Symposium on High-Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2002-02">Feb 2002</date>
			<biblScope unit="volume">55</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Value prediction for speculative multithreaded architectures</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marcuello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tubella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="1999-11">Nov. 1999</date>
			<biblScope unit="page" from="230" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A quantitative assessment of threadlevel speculation techniques</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marcuelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Symposium on Parallel and Distributed Processing</title>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<biblScope unit="volume">595</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Combining branch predictors. DEC WRL Technical Note TN-36</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcfarling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Trading conflict and capacity aliasing in conditional branch predictors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Uhlig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="292" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving the performance of speculatively parallel applications on the Hydra CMP</title>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Willey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th International Conference on Supercomputing</title>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Branch prediction topologies for SMT architectures</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Pizzol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O A</forename><surname>Navaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Symposium on Computer Architecture on High Performance Computing</title>
		<meeting>the 17th International Symposium on Computer Architecture on High Performance Computing</meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="page" from="118" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exposing speculative thread parallelism in SPEC2000</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th Symposium on Principles and Practice of Parallel Programming</title>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="page" from="142" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A study of slipstream processors</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Purser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sundaramoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2000-12">Dec 2000</date>
			<biblScope unit="page" from="269" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mitosis compiler: an infrastructure for speculative threading based on pre-computation slices</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Qui?ones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Madriles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marcuello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonz?lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Programming Language Design and Implementation</title>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="page" from="269" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An architecture of a dataflow single chip processor</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hiraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kodama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yuba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1989-04">Apr 1989</date>
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analysis of the O-GEometric history length branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="394" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The L-TAGE branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Instruction-Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Design tradeoffs for the alpha EV8 conditional branch predictor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sazeides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2002-06">June 2002</date>
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">De-aliashed hybrid branch predictors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
		<idno>RR-3618</idno>
	</analytic>
	<monogr>
		<title level="j">Inria</title>
		<imprint>
			<date type="published" when="1999-02">Feb. 1999</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<imprint>
			<date type="published" when="2002-10">Oct. 2002</date>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A study of branch prediction strategies</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="202" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiscalar processors</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Breach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Vijaykumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="414" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The agree predictor: a mechanism for reducing negative branch history interference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sprangle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Chappell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alsup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
			<biblScope unit="page" from="284" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A minimal dual-core speculative multi-threading architecture</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Akkary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Design</title>
		<imprint>
			<date type="published" when="2004-10">Oct. 2004</date>
			<biblScope unit="page" from="360" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The potential for using thread-level data speculation to facilitate automatic parallelization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Steffan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Symposium on High-Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A scalable approach to thread-level speculation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Colohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The superthreaded processor architecture</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Amlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Yew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="881" to="902" />
			<date type="published" when="1999-09">Sep. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Simulation and modeling of a simultaneous multithreading processor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd Annual Computer Measurement Group Conference</title>
		<imprint>
			<date type="published" when="1996-12">December 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Speculative versioning cache</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vijaykumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1305" to="1317" />
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Implicit parallelism with ordered transactions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Von Praun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ceze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cascaval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th Symposium on Principles and Practice of Parallel Programming</title>
		<imprint>
			<date type="published" when="2007-09">Sep 2007</date>
			<biblScope unit="page" from="79" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A comparison of dynamic branch predictors that use two levels of branch history</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1993-05">May 1993</date>
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">An event-driven multithreaded dynamic optimization framework</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th International Conference on Parallel Architectures and Compilation Techniques</title>
		<imprint>
			<date type="published" when="2005-09">Sep. 2005</date>
			<biblScope unit="page" from="87" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A self-repairing prefetcher in an event-driven dynamic optimization framework</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Code Generation and Optimization</title>
		<imprint>
			<date type="published" when="2006-03">March 2006</date>
			<biblScope unit="page" from="50" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Execution-based prediction using speculative slices</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zilles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2" to="13" />
			<date type="published" when="2001-06">June 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
