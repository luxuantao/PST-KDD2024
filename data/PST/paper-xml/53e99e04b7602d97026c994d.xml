<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Logic Minimization Techniques with Applications to Cryptology *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Joan</forename><surname>Boyar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Philip</forename><surname>Matthews</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">University of Southern Denmark</orgName>
								<address>
									<settlement>Odense</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Peralta Information Technology Laboratory</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<settlement>Aarhus</settlement>
									<country>Denmark René</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">NIST</orgName>
								<address>
									<settlement>Gaithersburg</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Logic Minimization Techniques with Applications to Cryptology *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4EF1222B3A1EFD876C797F40E09E40C1</idno>
					<idno type="DOI">10.1007/s00145-012-9124-7</idno>
					<note type="submission">Received 8 February 2011 Online publication 3 May 2012</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Circuit complexity</term>
					<term>Multiplicative complexity</term>
					<term>Linear component minimization</term>
					<term>Shortest Linear Program</term>
					<term>Cancellation</term>
					<term>AES</term>
					<term>S-box</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A new technique for combinational logic optimization is described. The technique is a two-step process. In the first step, the nonlinearity of a circuit-as measured by the number of nonlinear gates it contains-is reduced. The second step reduces the number of gates in the linear components of the already reduced circuit. The technique can be applied to arbitrary combinational logic problems, and often yields improvements even after optimization by standard methods has been performed. In this paper we show the results of our technique when applied to the S-box of the Advanced Encryption Standard (FIPS in Advanced Encryption Standard (AES), National Institute of Standards and Technology, 2001).</p><p>We also show that, in the second step, one is faced with an NP-hard problem, the Shortest Linear Program (SLP) problem, which is to minimize the number of linear operations necessary to compute a set of linear forms. In addition to showing that SLP is NP-hard, we show that a special case of the corresponding decision problem is MAX SNP-complete, implying limits to its approximability.</p><p>Previous algorithms for minimizing the number of gates in linear components produced cancellation-free straight-line programs, i.e., programs in which there is no cancellation of variables in GF(2). We show that such algorithms have approximation ratios of at least 3/2 and therefore cannot be expected to yield optimal solutions to nontrivial inputs. The straight-line programs produced by our techniques are not always cancellation-free. We have experimentally verified that, for randomly chosen linear * Some of this work appeared in [10] and some appeared in <ref type="bibr" target="#b6">[7]</ref>. † Some of J. Boyar's work was done while visiting the University of California, Irvine, and some while visiting Aarhus University.</p><p>‡ Work of P. Matthews was done while at Aarhus University.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Constructing optimal combinational circuits is an intractable problem under almost any meaningful metric (gate count, depth, energy consumption, etc.). In practice, no known techniques can reliably find optimal circuits for functions with as few as eight Boolean inputs and one Boolean output (there are 2 256 such functions). As an example of this, consider multiplicative complexity, the number of GF(2) multiplications (i.e., AND gates) necessary and sufficient to compute a function. The multiplicative complexity of the Boolean function E 8  4 , which is true if and only if exactly four of its eight input bits are true, is unknown <ref type="bibr" target="#b4">[5]</ref>.</p><p>In practice, we build circuit implementations of functions using a variety of heuristics. Many of these heuristics have exponential time complexity and thus can only be applied to small components of a circuit being built. This works reasonably well for functions that naturally decompose into repeated use of small components. Such functions include arithmetic functions (which we often build using full adders), matrix multiplication (which decomposes into multiplication of small submatrices), and more complex functions such as cryptographic functions (which are commonly based on multiple iterations of an algorithm containing linear steps and one or more nonlinear steps).</p><p>This work presents a new technique for logic synthesis and circuit optimization with the goal of minimizing the total number of gates. The reason for considering this minimization is that in an actual circuit implementation this would lead to smaller area and less power consumption, and in a program implementation this would lead to faster execution times. The technique can be applied to arbitrary functions, and yields improvements even on programs/circuits that have already been optimized by standard methods. We apply our technique to the S-box of the Advanced Encryption Standard (AES), 1 which, in addition to being used in AES, has been used in several proposals for a new hash function standard. 2 The result is, as far as we know, the smallest circuit yet constructed for this function. The circuit contains 32 AND gates and 83 XOR/XNOR gates for a total of 115 gates. We have also applied these techniques to the logic embedded in the nonlinear components of several candidates to the SHA-3 competition. The improvements in software performance were significant.</p><p>Finally, we note that there is another metric that is important in the area of secure multi-party computation. The computational cost of various applications in this area is proportional, not to the total number of gates, but rather to the number of nonlinear gates. For example, what is known as the "Free-XOR" technique <ref type="bibr" target="#b24">[25]</ref> uses circuits with low multiplicative complexity to speed up multi-party computation. The work of <ref type="bibr" target="#b20">[21]</ref> is currently the fastest implementation of a two-prover protocol for AES. That work uses 1 Our circuit for the AES S-box has already been used as the basis of a software bit-sliced implementation of AES in counter mode <ref type="bibr" target="#b22">[23]</ref>. 2 See http://csrc.nist.gov/groups/ST/hash/sha-3/index.html. the circuit in <ref type="bibr" target="#b38">[39]</ref> where the S-box contains 123 linear gates and 58 nonlinear gates.</p><formula xml:id="formula_0">t 1 = a ∧ b t 2 = a ⊕ b t 3 = t 2 ∧ c t 4 = t 1 ⊕ t 3 u 1 = a ⊕ b u 2 = b ⊕ c u 3 = u 1 ∧ u 2 u 4 = u 3 ⊕ b</formula><p>In contrast, our S-box circuit contains only 32 nonlinear gates. Thus, using our circuit immediately leads to a significant reduction in the cost of those protocols.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Preliminaries</head><p>The goal of this work is to minimize the total number of gates used in a circuit for a function. Our circuits are over the basis {⊕, ∧, 1}, where ⊕ represents XOR, ∧ represents AND, and the 1 can be used with the ⊕ for complementing bits. This basis is logically complete: any Boolean circuit can be transformed into this form using only local replacements. The circuit operations can be viewed either as performing Boolean logic or arithmetic modulo 2 (when viewing it the latter way, we will write outputs to be computed as polynomials with multiplication replacing ∧ and addition replacing ⊕).</p><p>The number of ∧ gates is called the multiplicative complexity of the circuit. Connected components of the circuit containing ∧ gates are called nonlinear. Components free of ∧ gates are called linear. Circuits and programs for computing Boolean functions can be defined using straight-line programs, where each statement defines the operation of a gate or a line in a program. The examples in Fig. <ref type="figure" target="#fig_0">1</ref> define two different circuits and their corresponding straight-line programs for computing the majority function of three inputs, a, b, and c. The Boolean complexity of a function is the minimal number of gates sufficient to compute that particular function, when any two-input one-output gates are allowed. A Boolean predicate is a Boolean function with only one output bit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Combinational Circuit Optimization</head><p>The techniques described here would generally be applied to subcircuits of a larger circuit, such as an S-box in a cryptographic application, which have relatively few inputs and outputs connecting them to the remainder of the circuit. The key observation that led us to our techniques is that circuits with low multiplicative complexity will naturally have large sections which are purely linear (i.e., contain only ⊕ gates). Thus it is plausible that a two-step process, which first reduces multiplicative complexity and then optimizes linear components, would usually lead to small circuits over the basis {⊕, ∧, 1}.</p><p>We have, of course, no way of proving this hypothesis. In fact, it seems unlikely that circuits with optimal Boolean complexity which are also optimal with respect to multiplicative complexity always exist. In practice, though, we conjecture that this two-step method will usually yield "good" circuits as compared with other methods, primarily because of the improved techniques presented here for optimizing linear circuits. As mentioned above, in this paper, we apply this method to the AES S-box and present experiments testing the techniques for optimizing linear circuits. Additionally, we (and others, see, e.g., <ref type="bibr" target="#b15">[16]</ref>) have successfully applied the heuristics described in this paper to a number of circuit optimization problems of interest to cryptology. These include finite field arithmetic and binary multiplication. New records (i.e., circuits with fewer gates than previously known) are periodically posted at http://cs-www.cs.yale.edu/homes/peralta/CircuitStuff/CMT.html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1.">First Step</head><p>The first step of our technique consists of identifying nonlinear components of the subcircuit to be optimized and reducing the number of ∧ gates. This reduction is not easy to do. For example, it is not obvious how to algorithmically transform one of the two equivalent circuits defined in Fig. <ref type="figure" target="#fig_0">1</ref> into the other.</p><p>Classic results by Shannon <ref type="bibr" target="#b34">[35]</ref> and Lupanov <ref type="bibr" target="#b25">[26]</ref> show that almost all predicates on n bits have a Boolean circuit complexity of about 2 n n . Analogous to the Shannon-Lupanov bound, it was shown in <ref type="bibr" target="#b8">[9]</ref> that almost all Boolean predicates on n bits have a multiplicative complexity of about 2 n 2 . Strictly speaking, these theorems say nothing about the class of functions with polynomial circuit complexity. However, it is reasonable to expect that, in practice, the multiplicative complexity of functions is significantly smaller than their Boolean complexity.</p><p>Finding circuits with minimum multiplicative complexity is, in all likelihood, a highly intractable problem. However, recent work on multiplicative complexity contains an arsenal of reduction techniques that in practice yield circuits with small, and often optimal, multiplicative complexity <ref type="bibr" target="#b4">[5]</ref>. That work focuses exclusively on symmetric functions (those whose value depends only on the Hamming weight of the input).</p><p>In this paper we use ad hoc heuristics to construct a circuit with low multiplicative complexity for inversion in GF(2 4 ). (GF(2 n ) is the field with 2 n elements.) The technique is described in Sect. 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2.">Second Step</head><p>The second step of our technique consists of finding maximal linear components of the circuit and then minimizing the number of XOR gates needed to compute the target functions computed in these linear components. A new heuristic for this computationally intractable problem is described in Sect. 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">The Shortest Linear Program Problem</head><p>We argue below that minimizing the number of XOR gates in the second step is equivalent to solving the Shortest Linear Program (SLP) problem over GF <ref type="bibr" target="#b1">(2)</ref>.</p><p>Let F be an arbitrary field and let</p><formula xml:id="formula_1">α 1,1 x 1 + α 1,2 x 2 + • • • + α 1,n x n , α 2,1 x 1 + α 2,2 x 2 + • • • + α 2,n x n , . . . α m,1 x 1 + α m,2 x 2 + • • • + α m,n x n ,</formula><p>be a set of linear forms where the α i,j 's are constants from F and the x i 's are variables over F. Suppose a subcircuit for a linear component in a circuit has x i s as inputs and y j s as outputs. <ref type="foot" target="#foot_0">3</ref> The y j s are linear functions of the x i s in the field GF(2), so the subcircuit is an algorithm for computing the linear forms (the functions the y j s represent) given the x i s as input, in the special case where F = GF(2).</p><p>We consider this question in the model of computation known as linear straight-line programs. A linear straight-line program is a variation on a straight-line program which does not allow multiplication of variables. That is, every line of the program is of the form u := ηv + μw; where η, μ are in F and v, w are variables. Some of the lines are output lines; these are the lines where the linear forms in the set are produced. For brevity, we will use the terms linear programs or simply programs to refer to linear straight-line programs. The length of the program is the number of lines it contains, and is equal to the number of XOR gates in a subcircuit computing these forms. A program is optimal if it is of minimum length.</p><p>The linear straight-line program model (see <ref type="bibr" target="#b10">[11]</ref> for a discussion of linear complexity) has the advantage of being very structured, but is nevertheless optimal to within a constant factor as compared to arbitrary straight-line programs when the computation is over an infinite field. Over finite fields the optimality of linear straight-line programs is unknown, <ref type="foot" target="#foot_1">4</ref> but we restrict our attention to this form and consider minimizing the length of the program.</p><p>The standard algorithm for computing the linear forms Ax, where A is an m × n matrix containing entries from a set of size r, requires m(n -1) operations. However, Savage <ref type="bibr" target="#b33">[34]</ref> showed that O(mn/ log r m) operations are sufficient in many cases, including computations over GF <ref type="bibr" target="#b1">(2)</ref> if m ≥ 4. Williams <ref type="bibr" target="#b36">[37]</ref> improved this to O(n 2 / log 2 n) on a RAM with word length Θ(n) for n by n matrices over finite semirings. In contrast, Winograd <ref type="bibr" target="#b37">[38]</ref> has shown that most sets of linear forms have a nonlinear complexity in the straight-line program model; in fact, for a "random" m × n matrix A the probability is high that its complexity is Ω(mn) (for infinite fields). However, there are nontrivial matrices which can be computed considerably faster than this.</p><p>Over GF <ref type="bibr" target="#b1">(2)</ref>, finding the shortest linear straight-line program is equivalent to our original goal of finding a circuit with only XOR gates and minimizing the number used. Linear forms have many applications, especially to problems in scientific computation, and there has been considerable success in finding efficient algorithms for computing them in special cases. The best known example is the fast Fourier transform, an O(n log n) algorithm, discovered by Cooley and Tukey in 1965 <ref type="bibr" target="#b14">[15]</ref>.</p><p>In Sect. 3.1.1 we show that finding the shortest linear straight-line program is NPhard. This can be seen in relation to Håstad's result <ref type="bibr" target="#b19">[20]</ref> showing that tensor rank is NP-hard and thus finding the minimum bilinear program for computing bilinear forms is NP-hard.</p><p>In Sect. 3.1.2 the NP-hardness result is used to prove a special case of the problem MAX SNP-complete <ref type="bibr" target="#b31">[32]</ref> (and also APX-complete). This means there are no -approximation algorithms for the problem unless P = NP <ref type="bibr" target="#b0">[1]</ref>.</p><p>A linear straight-line program over GF( <ref type="formula">2</ref>) is said to be a cancellation-free straightline program if, for every line of the program u := v + w, none of the variables in the expression for v are also present in the expression for w; i.e., there is no cancellation of variables in the computation. A small example showing that the optimal linear program is not always cancellation-free over GF(2) is:</p><formula xml:id="formula_2">x 1 + x 2 ; x 1 + x 2 + x 3 ; x 1 + x 2 + x 3 + x 4 ; x 2 + x 3 + x 4 .</formula><p>It is not hard to see, by exhaustive search, that the optimum cancellation-free straightline program has length 5. A solution of length 4 which allows cancellations is</p><formula xml:id="formula_3">v 1 = x 1 + x 2 ; v 2 = v 1 + x 3 ; v 3 = v 2 + x 4 ; v 4 = v 3 + x 1 .</formula><p>In Sect. 3.1.3 we show that the approximation ratio for cancellation-free techniques is at least 3/2. This discovery led us to create the heuristic in Sect. 3.2, allowing cancellations, for minimizing linear straight-line programs and the corresponding circuits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">First Step</head><p>We will illustrate the first step of the circuit minimization using AES's S-box as an example. The nonlinear operation in AES's S-box is to compute an inverse in the field GF (2 8 ). A recursive method for building a circuit for inverses in GF(2 mn ), given a circuit for inverses in GF(2 m ), is due to Itoh and Tsujii <ref type="bibr" target="#b21">[22]</ref>. The circuits produced by this method are said to have a tower fields architecture. Since there are multiple possible representations for Galois fields, several authors have concentrated on finding representations that yield efficient circuits under the tower fields architecture. We use the same general technique for the reduction from inversion in GF (2 8 ) to GF(2 4 ) inversion, but we use a completely different technique for computing the inversion in GF (2 4 ). We then place the optimized circuit for GF (2 4 ) inversion in its appropriate place in AES's S-box and, in the second step, apply a novel optimization technique to the linear parts of the resulting circuit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">GF(2 4 ) Inversion: A Nonlinear Component</head><p>The tower fields architecture for inversion in GF(2 8 ) has (nontrivial) easily identifiable nonlinear components corresponding to inversion in subfields. The first step in our method is to focus on one of these components and derive a circuit that uses few ∧ gates. The component for inversion in GF(2 2 ) is too small for us to benefit significantly from optimizing it. Instead we focus on inversion in GF (2 4 ). There are many representations of GF (2 4 ). Following Canright <ref type="bibr" target="#b12">[13]</ref>, who compared 432 different representations as a tower of fields <ref type="bibr" target="#b11">[12]</ref> and found this one optimal using his techniques for reducing circuit size, we construct</p><formula xml:id="formula_4">• GF(2 2</formula><p>) by adjoining a root W of x 2 + x + 1 over GF(2); • GF(2 4 ) by adjoining a root Z of x 2 + x + W 2 over GF(2 2 ). GF(2 2 ) is represented using the basis (W, W 2 ), and GF(2 4 ) using the basis (Z 2 , Z 8 ). Thus, an element δ ∈ GF(2 4 ) is written as 4 = W , and W<ref type="foot" target="#foot_2">5</ref> = W 2 . These equations can be used to reduce expressions to check equalities.</p><formula xml:id="formula_5">δ 1 Z 2 + δ 2 Z 8 , where δ 1 , δ 2 ∈ GF(2 2 ). Sim- ilarly, an element γ in GF(2 2 ) is written as γ 1 W + γ 2 W 2 , where γ 1 , γ 2 ∈ GF(2). Since Z satisfies x 2 + x + W 2 = 0 and W satisfies x 2 + x + 1 = 0, one can calcu- late that Z 4 = Z 2 + W , Z 8 = Z 2 + 1 (1 = Z 8 + Z 2 ), Z 10 = Z 4 + Z 2 , Z 16 = Z 8 + W , W 3 = W 2 + W , W</formula><p>Using this representation, an element of GF (2 4 ) can be written as 8 , can then be calculated using the following polynomials over GF(2):</p><formula xml:id="formula_6">Δ = (x 1 W + x 2 W 2 )Z 2 + (x 3 W + x 4 W 2 )Z 8 , where x 1 , x 2 , x 3 , x 4 ∈ GF(2). The inverse of this ele- ment, Δ = (y 1 W + y 2 W 2 )Z 2 + (y 3 W + y 4 W 2 )Z</formula><formula xml:id="formula_7">• y 1 = x 2 x 3 x 4 + x 1 x 3 + x 2 x 3 + x 3 + x 4 • y 2 = x 1 x 3 x 4 + x 1 x 3 + x 2 x 3 + x 2 x 4 + x 4 • y 3 = x 1 x 2 x 4 + x 1 x 3 + x 1 x 4 + x 1 + x 2 • y 4 = x 1 x 2 x 3 + x 1 x 3 + x 1 x 4 + x 2 x 4 + x 2</formula><p>The fact that Δ is the inverse of Δ can be verified by multiplying the two elements together and reducing using the equations mentioned above (along with x 2 = x and x + x = 0). The symbolic result is</p><formula xml:id="formula_8">(QW + QW 2 )Z 2 + (QW + QW 2 )Z 8 , where Q = x 1 x 2 x 3 x 4 + x 1 x 2 x 3 + x 1 x 2 x 4 + x 1 x 3 x 4 + x 2 x 3 x 4 + x 1 x 2 + x 1 x 3 + x 1 x 4 + x 2 x 3 + x 2 x 4 + x 3 x 4 + x 1 + x 2 + x 3 + x 4 .</formula><p>The fact that the value of Q is 1 unless all four variables have the value 0, when it is 0, can be seen by observing that it is the symmetric function Σ 4  4</p><formula xml:id="formula_9">+ Σ 4 3 + Σ 4 2 + Σ 4 1 .</formula><p>If exactly four variables are set, then the first term gives the value 1 (and the others 0); if three are set, then the second, third, and fourth terms give the value 1; if exactly two are set, then only the third gives the value 1; and if only one is set, then only the last gives the value 1. Hence, the result is 1, except for the zero input. 5  Thus the task at hand is to construct a circuit with four inputs and four outputs that calculates the above system of equations using as few ∧ gates as possible. Currently, our heuristic search programs can handle functions with one output and up to eight inputs. (Since they are heuristics, one is not certain that an output is optimal, so they cannot be used, for example, to determine a tight lower bound for the multiplicative complexity of E 8  4 .) This means that we can directly construct optimal circuits for each of the four equations individually, but not for the system itself. For the full system we took the following approach:</p><p>1. pick an equation and construct an efficient circuit for it; 2. store intermediate functions computed in the previous steps for possible use in constructing a circuit for the next equation to be tackled; 3. iterate until all equations have been computed. The first step is nontrivial even for predicates on few inputs. The heuristic we used is inspired by methods from automatic theorem proving <ref type="bibr" target="#b5">[6]</ref>: consider an arbitrary predicate f on n inputs. We refer to the last column of the truth table for f as the signal of f . The columns in the truth table corresponding to each of the inputs to f are known signals. A search for a circuit for f starts with this set S of known signals. If u, v are known signals for functions g, h respectively, then the bit-wise XOR (AND) of u and v is the signal for the predicate g ⊕ h (g ∧ h). We can grow the set S by adding the XOR of randomly chosen signals. We call this step an XOR round. The analogous step where the AND of signals is added to S is called an AND round. Each round is parameterized by the number of new signals added and the maximum number of AND gates allowed. In either an XOR round or an AND round, two signals are not combined if doing so creates a signal with more AND gates than is allowed. The heuristic alternates between XOR and AND rounds until the target signal is found or the set S becomes too large. In the latter case, since this is a randomized procedure, we start again. Various enhancements and optimizations have been implemented. Their description is outside the scope of this paper. We can report, however, that we succeeded in determining the multiplicative complexity of all 2 16 predicates on four bits. It turns out that 3 multiplications are enough to compute any predicate on four variables. 6 This is of interest to designers of cryptographic functions, since many constructions have been proposed which use 4 × 4 S-boxes. We have not yet been able to do the same for all predicates on 5 bits.</p><p>We performed the three steps above for each of the 24 orderings of {y 1 , y 2 , y 3 , y 4 }. The ordering (y 4 , y 2 , y 1 , y 3 ) gave the best results. The resulting circuit, expressed as a straight-line program over GF <ref type="bibr" target="#b1">(2)</ref>, is shown in Fig. <ref type="figure" target="#fig_1">2</ref> (outputs are indicated by an (*)).</p><p>This circuit contains 5 ∧ gates and 11 ⊕ gates. It is a significant improvement over previous constructions; e.g., Paar's construction <ref type="bibr" target="#b29">[30]</ref> has a gate count of 10 ∧ gates and 15 ⊕ gates for the same function. It is harder to compare to Canright's construction <ref type="bibr" target="#b12">[13]</ref>. In his original, he had 9 ∧ gates (and NAND gates) and 14 ⊕ gates (and XNOR gates), 6 Lest the reader think this trivial, he/she may attempt to compute the function but he optimized, allowing NOR gates. After this, he had 8 NAND gates, 2 NOR gates, and 9 XOR/XNOR gates.</p><formula xml:id="formula_10">f (x 1 , x 2 , x 3 , x 4 ) = x 1 x 2 x 3 x 4 + x 1 x 2 x 3 + x 1 x 2 x 4 + x 2 x 3 x 4 + x 1 x 2 + x 1 x 3 + x 1 x 4 + x 2 x 3 + x 3 x 4 using only three multipli- cations. t 1 = x 1 + x 2 t 2 = x 1 × x 3 t 3 = x 4 + t 2 t 4 = t 1 × t 3 y 4 = x 2 + t 4 (*) t 5 = x 3 + x 4 t 6 = x 2 + t 2 t 7 = t 6 × t 5 y 2 = x 4 + t 7 (*) t 8 = x 3 + y 2 t 9 = t 3 + y 2 t 10 = x 4 × t 9 y 1 = t 10 + t 8 (*) t 11 = t 3 + t 10 t 12 = y 4 × t 11 y 3 = t 12 + t 1 (*)</formula><p>Under the given representation for GF (2 4 ), the multiplicative complexity of inversion is 5. This can be argued as follows: the upper bound is given by the construction. The four outputs that have to be computed all have degree 3. One ∧ is needed to compute a polynomial of degree 2. Then, an additional ∧ is necessary to produce each of the four linearly independent polynomials, since each is of degree 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">A View of the Structure of AES's S-Box</head><p>In the previous section, using the tower fields architecture, we identified and optimized (with respect to multiplicative complexity) a major nonlinear component in an implementation of the AES S-box. The multiplications in GF (2 4 ) are also nonlinear, but we have used the same circuit as Canright for these components. That completes the first step of our technique for circuit optimization, but in other circuits, one may be able to identify more nonlinear components with few enough inputs that they can also be optimized before continuing. At this point, we replaced the GF(2 4 ) inversion subcircuit, in Canright's <ref type="bibr" target="#b12">[13]</ref> (already optimized) circuit, with the subcircuit in Fig. <ref type="figure" target="#fig_1">2</ref>. As expected, the resulting circuit contained large linear connected components. In fact, from a cryptanalyst's point of view, the topology of the resulting circuit is potentially of interest: the S-box of AES consists of an initial linear expansion U from 8 to 22 bits, followed by a nonlinear contraction F from 22 to 18 bits, and ending with a linear contraction B from 18 to 8 bits. The U and B matrices are given below. AES's S-box is</p><formula xml:id="formula_11">S(x) = B • F (U • x) + [11000110]</formula><p>T , where • is matrix multiplication and x is the 8-bit S-box input. We do not know if there are any cryptanalytic implications to the structure of these matrices. The first row and last columns of U should raise an eyebrow, as should the 12th and the last three columns of B. Note that the initial linear expansion and the linear contraction were defined to contain as much of the circuit as possible while still being linear, increasing the portion of the circuit which could be further optimized by concentrating on the linear components. Thus, the portion of the circuit defined by U , for example, overlaps with the GF(2 8 ) inversion. Also included in these linear components is the linear transformation to change bases, before computing the inverse in GF(2 8 ), plus the linear transformation to change back to the original basis, followed by the affine transformation which is the final operation in the S-box.</p><formula xml:id="formula_12">U = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ , B = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Second Step</head><p>The second step is to optimize the linear components in the circuit. One method of finding the nonlinear components to be optimized in the first step was to find maximal linear components of the circuit, remove them, and look at the remaining nonlinear components. Whether this was done or not, after the optimized nonlinear components are inserted into their appropriate places in the circuit, the beginning of the second step should be to find maximal linear components in this new circuit (since after optimization, some of the nonlinear portions may contain ⊕ gates which can be included in the "old" linear parts, as in the case of the U and B matrices from AES's S-box).</p><p>These maximal components define linear components of the circuit which should be minimized in Step 2. In the case of the AES S-box, the top linear component corresponds to the matrix U , and the bottom linear component corresponds to the matrix B.</p><p>No other significant linear components were found. After finding these, the next step was to minimize the circuits for computing U and B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Hardness of Minimizing Linear Components</head><p>First, we show that the problem of linear circuit minimization, or equivalently, the Shortest Linear Program (SLP), is NP-hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">NP-Hardness</head><p>The problem SHORTEST LINEAR PROGRAM (SLP) is as follows: Given a set of linear forms E over a field F, find a shortest linear program to compute E.</p><p>In order to prove NP-hardness, we consider the corresponding decision problem, SLPd: Given a set of linear forms E over a field F and a positive integer k, determine if there exists a straight-line linear program with at most k lines which computes E.</p><p>We will prove SLPd NP-hard, even if the constants in the set of linear forms to be computed are only zeros and ones. Furthermore, if the field F is finite, then SLPd is easily seen to be in NP, so SLPd is NP-complete over finite fields. <ref type="foot" target="#foot_3">7</ref>The interest of this section is not just in the final result that SLP is NP-hard, but also in the method used to prove it. In particular, most of this section is devoted to the proof of Lemma 1, which gives the exact complexity for sets of linear forms of a certain simple type. This proof is algorithmic in form, and its algorithmic nature can be exploited to prove a further result in Sect. 3.1.2.</p><p>In order to show NP-hardness, we reduce from VERTEX COVER. A vertex cover of a graph G = (V , E) is a subset V of V such that every edge of E is incident with at least one vertex of V . VERTEX COVER is defined as follows: Given a graph G = (V , E) and an integer k, determine if there exists a vertex cover of size at most k.</p><p>The following polynomial-time reduction f transforms an arbitrary graph, G = (V , E), and a bound, k, to a set of linear forms with another bound, k. The input variables are X = V ∪ {z}, where z is a distinguished variable not occurring in V . The linear forms are Ē = { z + a + b | (a, b) ∈ E }, and the program length we ask about is k = k + | Ē|. This is an instance of SLPd, and it is clear that f (G, k) = ( Ē, X, k) can be produced in polynomial time. We call a set of linear expressions in this restricted form, z + x i + x j , a set of z-expressions. Note that three distinct z-expressions are linearly independent over any field.</p><p>Before we proceed, we illustrate with an example. The graph, G, in Fig. <ref type="figure" target="#fig_2">3</ref> has a vertex cover of size k = 3: {a, c, e}. The corresponding instance of SLPd, f (G, 3) is <ref type="figure">a,</ref><ref type="figure">b,</ref><ref type="figure">c,</ref><ref type="figure">d,</ref><ref type="figure">e,</ref><ref type="figure">f</ref>, g}, and k = 3 + 8. A linear program for this of size 11 is A cover for a set Ē of z-expressions is a subset W of X \ {z} such that every expression in Ē contains at least one variable in W . Note that if ( Ē, X, k) = f (G, k), a cover for Ē trivially defines a vertex cover for the graph G and vice versa.</p><formula xml:id="formula_13">Ē = {z + a + b, z + b + c, z + c + d, z + d + e, z + e + f, z + a + f, z + c + g, z + e + g}, X = {z,</formula><formula xml:id="formula_14">v 1 := z + a; v 2 := z + c; v 3 := z + e; v 4 := v 1 + b; v 5 := v 2 + b; v 6 := v 2 + d; v 7 := v 3 + d; v 8 := v 3 + f ; v 9 := v 1 + f ; v 10 := v 2 + g; v 11 := v 3 + g;</formula><p>Lemma 1. Let ( Ē, X) be a set of z-expressions without repetitions; that is, Ē is a set of expressions of the form z + x i + x j , where x i , x j are distinct variables in X \ {z}, z is a distinguished variable in X, and no two of these z-expressions contain exactly the same variables. There is a cover of Ē of size at most k if and only if there is a linear straight-line program P for Ē of length k = k + | Ē|. In addition, given a linear straight-line program P for Ē, a cover for Ē of size at most |P | -| Ē| can be computed in polynomial time.</p><p>Proof. We will refer to the elements of X \{z} as "the variables" and z as "the symbol," although as an element of a linear program, z is also an input variable.</p><p>Given a cover W of size k for Ē, a (cancellation-free) linear straight-line program for Ē can be created consisting of z + w i for each w i ∈ W , followed by linear expressions computing each output, created by adding a second variable to the appropriate z + w i . This program has length k + | Ē|.</p><p>It remains to be shown that, given a linear straight-line program P for Ē, we can efficiently find a cover, W , for Ē of size no more than |P | -| Ē|. This cover is computed by associating elements of X \ {z} with some non-output lines of the program-W will then be the union of all the variables so associated. Since we will assign at most one element of X \ {z} to each non-output line, the cover is of size at most |P | -| Ē|.</p><p>Let F (i) be the linear function computed at line i; the result there is assigned to v i . It will be convenient to use the notation F (i) to refer both to the function and to the set of variables (not including z) in F (i) . The association of variables with lines of the program will be denoted by a mapping m : N → X \ {z}∪{λ}. Initially, we set m(i) = λ for all lines i. When line i is first processed, m(i) will, in some cases, be set to a variable in F (i) . We define At the end, the cover W will be W (|P |) , the set of all variables that are assigned to some m(i).</p><formula xml:id="formula_15">W (i) = x ∈ X | x = m(j ) for some j ≤ i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compute-Cover() for</head><formula xml:id="formula_16">i = 1 to |P | do m(i) ← λ if F (i) is not an output then if ∃ a variable x in F (i) \ W (i-1) then m(i) ← x else { F (i) is an output } if |F (i) \ W (i) | = 2 then Fix-up(i, i) (seeFig.6)</formula><p>The algorithm Compute-Cover works as follows (see Fig. <ref type="figure" target="#fig_3">4</ref>): Starting at the first line of the linear straight-line program P , it associates with each non-output line i a variable in X \ {z} which occurs in F (i) and which is currently unassociated (if there is no such variable, the line is assigned the null symbol, λ). When an output is reached, Compute-Cover checks if the set of all variables currently assigned to earlier lines covers that output, i.e., if there is some variable in W (i-1) which occurs in F (i) . If this is not the case, then a fix-up procedure is invoked (see Fig. <ref type="figure" target="#fig_4">6</ref>). This fix-up procedure changes some of the associations until all the output expressions up to that point are covered. After Compute-Cover has terminated, all the output expressions will be covered, so W is the desired cover, and |P | ≥ |W | + | Ē|. If the straight-line program P is restricted to being cancellation-free, the fix-up procedure will never be necessary; it is only called if an output line was produced as a linear combination of two lines, where at one of those lines a cancelled variable was added to the cover, W .</p><p>The remainder of the proof first establishes the precise conditions under which the fix-up procedure is called, and then describes the action taken. We first define the two properties that Compute-Cover seeks to establish for each line l of the program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 1. If line l is not an output, either</head><p>• all variables in F (l) are in W (l) , or • m(l) = x ∈ F (l) and m(i) = x for all i &lt; l. Property 2. There is at most one variable in F (l) which is not in W (l) .</p><p>In terms of these two properties, Compute-Cover (Fig. <ref type="figure" target="#fig_3">4</ref>) can be described as follows. Given that Properties 1 and 2 hold for lines 1 to i -1, establish Property 1 for line i and check if Property 2 holds for line i. If not, the fix-up procedure will be called. For all j , the size of W (j ) will never decrease.</p><p>It will be convenient to assume each line of the program is of the form</p><formula xml:id="formula_17">v i := η • v i + μ • v i (i &gt; 0, η,μ = 0).</formula><p>To do this, we define v 0 = z, v -i = x i for each variable x i , and m(i) = λ for all i ≤ 0. We note that Property 2 holds for these initial assignments which occur before the first</p><formula xml:id="formula_18">v -4 := d F (-4) = d m ( -4) = λ v -3 := c F (-3) = c m ( -3) = λ v -2 := b F (-2) = b m ( -2) = λ v -1 := a F (-1) = a m ( -1) = λ v 0 := z F (0) = z m ( 0) = λ v 1 := v -1 + v -2 F (1) = a + b m ( 1) = b v 2 := v -3 + v -4 F (2) = c + d m ( 2) = c v 3 := v -2 + v -3 F (3) = b + c m ( 3) = λ v 4 := v 0 + v 1 F (4) = z + a + b m(4) = λ v 5 := v 3 + v 4 F (5) = z + a + c m(5) = λ v 6 := v 2 + v 5 F (6) = z + a + d m(6) = λ Fig. 5.</formula><p>The last three lines are outputs. When the last line is reached, neither a nor d is in W (6) , so fix-up is called.</p><p>"line" of the program P . Line 1 of P contains at most two variables and cannot be an output. Thus, Compute-Cover assigns one of these variables to m(1). So, the first time Compute-Cover processes line 1, it establishes Properties 1 and 2 for line 1.</p><p>Claim 1. Let line l be a non-output line and assume Property 2 holds for all lines before l. If Property 1 holds for line l, then Property 2 also holds for line l.</p><p>Proof. If all variables in line l are in W (l-1) , both properties hold for line l. Otherwise, let non-output line l be v l := η • v l + μ • v l . By assumption, Property 2 holds for F (l )  and F (l ) . Since W (l ) ∪W (l ) ⊆ W (l-1) , there are at most two variables in F (l) but not in W (l-1) . By Property 1, m(l) ∈ F (l) \ W (l-1) . Thus Property 2 holds for line l.</p><p>Claim 1 implies that, prior to the first call to Fix-up(i, i), establishing Property 1 also establishes Property 2. Compute-Cover explicitly establishes Property 1 at non-output lines. We have already argued that Properties 1 and 2 hold immediately after Compute-Cover processes line 1. It follows that the first time Fix-up(i, i) is called, Property 1 holds for lines 1 through i (vacuously for line i) and Property 2 for all lines prior to i.</p><p>We now consider the way the algorithm processes output lines. It is not obvious that the fix-up procedure can ever be called. Figure <ref type="figure">5</ref> shows an example where this happens.</p><p>Claim 2. Before a call to Fix-up(s, t), either directly from Compute-Cover or recursively from fix-up, Property 1 holds for lines 1 through t and Property 2 holds for all lines before line s.</p><p>Proof. Consider a call to Fix-up(s, t). We have already shown the claim holds if this is the first call to fix-up. If this is not the first call to fix-up, we may assume, inductively, that the claim holds for all previous calls. Suppose the previous call was to Fix-up(i, l) for an output line i ≤ l:</p><formula xml:id="formula_19">v i := η • v i + μ • v i (η, μ = 0)</formula><p>which produces the expression z + a + b. This call is caused by neither a nor b being in W (i) .</p><p>Without loss of generality, assume that i &lt; i . If both a and b are in F (i ) or both are in F (i ) , then, by the induction hypothesis, at least one of a or b is in W (i) , a contradiction. Thus, neither line contains both a and b. We may assume, without loss of generality, that a is not present in line i and b is not present in line i . Since</p><formula xml:id="formula_20">η • F (i ) + μ • F (i ) = z + a + b</formula><p>we have that</p><formula xml:id="formula_21">F (i ) = ν 1 z + (b/η) -(H /η), F (i ) = ν 2 z + (a/μ) + (H /μ),</formula><p>where ην 1 + μν 2 = 1 and H is a polynomial with variables in X \ {a, b, z}. We now show that line i is a non-output line and line i is an output line. Since b / ∈ W (i ) , Property 2 implies that all variables in H are in W (i ) . Therefore, all variables in H are in W (i -1) and, by assumption, a / ∈ W (i -1) . If line i is not an output, Property 1 implies m(i ) = a. This contradicts a / ∈ W (i) . Thus line i is an output line. Since no three distinct z expressions are linearly dependent, and lines i and i are output lines, it follows that line i is a non-output line.</p><p>Thus, F (i ) = z + a + c where c is a variable distinct from a and b. It follows that</p><formula xml:id="formula_22">ν 2 = 1; μ = 1; H = c; ν 1 = 0; i &gt; 0.</formula><p>Therefore,</p><formula xml:id="formula_23">F (i ) = (b -c)/η, F (i ) = z + a + c.</formula><p>Inductively, Property 1 holds for lines 1 through l, so m(i ) = c. The fix-up procedure, as defined in Fig. <ref type="figure" target="#fig_4">6</ref>, backs up to line i , changes the mapping m so m(i ) = b, not c, and then calls Correct to scan forward from i to check if there is a later line j where m(j ) = b. Such an occurrence is changed, since no variable can be assigned to two different lines without violating Property 1 at the second such line. If such a line j is found, there are two cases to consider: (1) there is another variable x in F (j ) which is not in W (j ) , and (2) all variables in F (j ) are already covered. In the first case, the variable x is assigned to m(j ), which could cause another violation of Property 1 if x is also assigned at a later line. Thus, Correct is called recursively from line j to check for x being assigned later. This x could only be assigned to one later line, so Correct eventually terminates, ensuring that no two lines are assigned the same variable. In the second case, the variable c is assigned to line j ; it cannot have been assigned elsewhere, since it had only been assigned to line i before the call to Fix-up(i, l).</p><p>The next loop in the fix-up procedure ensures that Property 1 still holds up through line l. If this property does not hold at some line, it is because some variable x (either Fix-up(i, l) { i is the current line being fixed; l is original line being fixed } { line i, v i := ηv i + v i , produces the expression z + a + b, a is not present in line i and b is not present in i } { line i is not an output, m(i ) = c, and</p><formula xml:id="formula_24">F (i ) = (b -c)/η } { line i is an output and F (i ) = z + a + c } m(i ) ← b { Check if b has</formula><p>been assigned to a later line } Correct(b, i, l, c) { Check that Property 1 holds everywhere } for j ← i to l do if F (j ) is not an output and ∃x ∈ F (j ) \ W (j ) then if (m(j</p><formula xml:id="formula_25">) = λ) or (m(j ) ∈ F (j ) ) then m(j ) ← x for k = j + 1 to l do if m(k) = x then m(k) ← λ { Check that Property 2 holds everywhere } for j ← 1 to l do if F (j ) is an output then if |F (j ) \ W (j ) | = 2 then Fix-up(j, l); return;</formula><p>Correct(y, i, l, c) { The variable y has just been assigned to a line. } { Check if y is assigned to between lines i + 1 and l. } { If so, assign the variable c or some variable in that line. } j ← i + 1 while j ≤ l and m(j c or some other variable replaced in Correct) has been removed from some W (k) , but x ∈ F (k) . There are two possible cases here: (1) m(k) = λ, and (2) m(k) = d, where d ∈ F (k) . The first case is easy, and m(k) is set to x. The second case could only have arisen from an earlier call to the fix-up procedure, at a point where m(k) was set to the variable d because all of its variables were covered by W (k) and the variable d had been removed from an earlier line. In this case, we switch the assignment from d to x. If x was assigned to a later line (when correcting for a b being assigned to a later line and finding a line where all the variables were already covered), that assignment is removed.</p><formula xml:id="formula_26">) = y do j ← j + 1 if j ≤ l { i.e. m(j ) = y } then if ∃ a variable x ∈ F (j ) \ W (j ) then m(j ) ← x if x = c then Correct(x, j, l, c) else m(j ) ← c</formula><p>(Note that this does not decrease the size of any W (j ) since x is added to them when m(k) gets the value x.) Thus, Property 1 holds up through line l.</p><p>The removal of c from W (i ) may also cause Property 2 to fail. By Claim 1, the corrections for Property 1 in the previous loop ensure that the first failure for Property 2 is not at a non-output line. Some of the failures at output lines may be rectified by the adjustments fixing Property 1. "Fix-up" is called recursively to fix the others. If Fixup(s, t) is the first recursive call within Fix-up(i, l) then</p><p>• the first loop in Fix-up ensures Property 1 holds through line l = t; • the first failure of Property 2 must be at an output line, and therefore Property 2 holds through line s -1.</p><p>Otherwise, Fix-up(i, l) terminates before the call to Fix-up(s, t). In this case Properties 1 and 2 hold up through line l (hence the return statement after one recursive call to Fixup). Thus the call to Fix-up(s, t) occurs in the code of Fig. <ref type="figure" target="#fig_3">4</ref> and s = t &gt; l. From lines l + 1 through t there is no call to Fix-up. Hence, by Claim 1, the steps in the main loop (of Fig. <ref type="figure" target="#fig_3">4</ref>) ensuring Property 1 also ensure Property 2 up through line t -1. Property 1 holds vacuously at line t.</p><p>Finally, we note that the last call to Fix-up, and the remaining iterations of the loop in Fig. <ref type="figure" target="#fig_3">4</ref> ensure that Properties 1 and 2 hold everywhere. Thus, if the algorithm terminates, Property 2 will hold for all lines of P , and therefore</p><formula xml:id="formula_27">W = W (|P |) is a cover of size at most |P | -| Ē|.</formula><p>We now turn to the proof of termination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Claim 3. A call to Fix-up never decreases the size of any W (j ) .</head><p>Proof. There are two ways Fix-up appears to decrease the size of some W (j ) . The first is by swapping c for b at line i where b is already assigned to some other line j &gt; i. If the procedure terminates at this point, this would decrease the size of W (j ) for j ≥ j . However, the procedure Correct(b, i, l, c) checks for this and assigns some other variable, x or c, to line j and corrects for x recursively. The starting line for the search by Correct is larger for each recursive call, so eventually it terminates, adding a new variable to the cover which has not been assigned to a later line. Since c was originally assigned to line i , it was not assigned to any other line, so this corrects the temporary decrease in W (j ) for j ≥ j .</p><p>The second apparent decrease in the size of some W (j ) does not actually ever create a decrease. During the check for Property 1 still holding, if m(j ) is set to x, but x is assigned to some later line k, then m(k) is set to λ. (Note that this x may be the variable c which was removed at line i , but it could be some other variable if some m(j ) had recently been set to λ.) However, adding x to W (j ) also added it to W (k) , so there is no actual decrease in the size of any W (k ) .</p><p>Let k 1 , k 2 , . . . be the sequence of line numbers for output lines which require a call to the fix-up procedure, and let W (j ) i denote the set W (j ) at the point just before the fix-up procedure is called for line k i .</p><p>Note that no two adjacent members of k 1 , k 2 , . . . are equal.</p><p>Let j be an index for which k j &lt; k j +1 (if no such index exists, the sequence is clearly finite and this terminates). We claim that |W</p><formula xml:id="formula_28">(k j ) j | &lt; |W (k j ) j +1 |.</formula><p>By the previous claim, the size of the cover never decreases. Thus, the claim follows if we show that a variable is added to the cover by the fix-up procedure when going from line k j to k j +1 .</p><p>Consider how the fix-up procedure operates between the calls at lines k j and k j +1 . Suppose that line k j is</p><formula xml:id="formula_29">v k j := η • v k j + μ • v k j .</formula><p>We know that k j &lt; k j &lt; k j &lt; k j +1 . Suppose the formal expressions computed at these lines are</p><formula xml:id="formula_30">F (k j ) = (b -c)/η; F (k j ) = z + a + c, F (k j ) = z + a + b; F (k j +1 ) = • • • .</formula><p>For line k j to have caused a call to "Fix-up", neither a nor b could have been in the cover</p><formula xml:id="formula_31">W (k j ) j</formula><p>. Thus the algorithm first visited line k j and changed the mapping m(k j ) from c to b, then executed the first "for" loop, correcting lines not satisfying Property 1, and finally moved down the program, checking each line for Property 2, until reaching line k j +1 . But this means that Property 2 held at line k j , and this could only have happened if a or c was in the cover. Since neither of them was in the cover immediately after the swap of b for c at line k j , one of them must have been added by the fix-up procedure at one of the lines in between. Thus |W</p><formula xml:id="formula_32">(k j ) j | &lt; |W (k j ) j +1 |.</formula><p>Hence for each j where k j &lt; k j +1 , the size of the cover at some line increases. Let n be the length of the program. Since all k j are positive, there can be at most n calls to the fix-up procedure before some W (k j ) increases in size. Other than the time required for a possible recursive call, each call to the fix-up procedure is linear in n. From the bound |W (k j ) | &lt; |X| ≤ n, for 1 ≤ j ≤ n, it follows that Compute-Cover requires at most O(n 4 ) time. (The fact that the execution time is polynomial is irrelevant for the purposes of showing NP-hardness, but will be important later.) This completes the proof of Lemma 1.</p><p>The following theorem follows immediately, since we have given a polynomial time reduction from VERTEX COVER, which is NP-complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1. For any field F, SHORTEST LINEAR PROGRAM is NP-hard.</head><p>For finite fields, it is easy to see that SLPd ∈ NP. Thus we have the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2. For any finite field F, the decision version of SHORTEST LINEAR PRO-GRAM is NP-complete.</head><p>Note that in the proof of Lemma 1, if the straight-line program P had been restricted to be cancellation-free, the proof would have been easier, because the fix-up procedure would never be necessary; it is only called if an output line was produced as a linear combination of two lines, where at one of those lines a cancelled variable was added to the cover, W . This immediately gives us the following. Theorem 3. For any finite field F, SHORTEST LINEAR PROGRAM is NP-complete even if the programs produced are restricted to being cancellation-free.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Limits to Approximation</head><p>The major result of the previous subsection is that it is NP-hard to find an optimal linear program for computing a set of linear forms. Thus, it is natural to turn our attention to approximation algorithms for this problem. Here we concentrate entirely on polynomial-time approximation algorithms with provable performance guarantees.</p><p>We show that SHORTEST LINEAR PROGRAM has no -approximation scheme unless P = NP. Recall that these are families of algorithms, one for each &gt; 0, which are polynomial time and achieve an approximation ratio of 1 + . We use a concept called MAX SNP-completeness, which was introduced by Papadimitriou and Yannakakis <ref type="bibr" target="#b31">[32]</ref>. Arora et al. <ref type="bibr" target="#b0">[1]</ref> have shown that no MAX SNP-complete problem has an -approximation scheme unless P = NP. We show that BOUNDED Z-EXPN (defined below), is MAX SNP-complete, showing that there is no -approximation scheme for SHORTEST LINEAR PROGRAM unless P = NP, since it is a generalization of BOUNDED Z-EXPN.</p><p>MAX SNP is a complexity class of optimization problems. It is contained within NP in the sense that the decision versions of the problems are all in NP. Papadimitriou and Yannakakis <ref type="bibr" target="#b31">[32]</ref> proved that many problems are MAX SNP-complete, including the following: BOUNDED VERTEX COVER: Given a graph with maximum vertex degree bounded by a constant b, find the smallest vertex cover.</p><p>To talk about completeness for this class, we need a notion of reduction. The reductions Papadimitriou and Yannakakis defined, called L-reductions, preserve the existence of -approximation schemes. The following definitions and propositions are taken directly from the original paper.</p><p>Let Π and Π be two optimization (maximization or minimization) problems, and let f be a polynomial-time transformation from problem Π to problem Π . We say that f is an L-reduction if there are constants α, β &gt; 0 such that, for each instance I of Π , the following two properties are satisfied: The constant β will usually be 1. The following two propositions, stated in <ref type="bibr" target="#b31">[32]</ref>, follow easily from the definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 1. L-reductions compose.</head><p>Proposition 2. If Π L-reduces to Π and if there is a polynomial-time approximation algorithm for Π with worst-case error , then there is a polynomial-time approximation algorithm for Π with worst-case error αβ . BOUNDED Z-EXPN is the following problem: Given a set of z-expressions (as defined in Theorem 1) in which each non-z variable appears at most b times (b is a fixed constant), generate an optimal linear program for computing the expressions (over some fixed field F).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4. BOUNDED Z-EXPN is MAX SNP-complete.</head><p>Proof. First, we will show that BOUNDED Z-EXPN is in MAX SNP. To show membership in MAX SNP, we will exhibit an L-reduction of BOUNDED Z-EXPN to Bounded Vertex Cover, a problem in MAX SNP.</p><p>For every non-z variable x i , we associate a vertex xi . The L-reduction f maps z-expressions to edges as follows: f ("z + x i + x j ") = "edge (i, j )". Since variable occurrences are bounded by b in BOUNDED Z-EXPN, the vertex degrees will be bounded by b in the graph.</p><p>We proved in the previous section that a set of z-expressions can be optimally computed by first computing z + x i for those x i which are in the minimum vertex cover, and then using these intermediate results to compute the z-expressions. Thus OPT(f (I )) + |E| = OPT(I ) where |E| is both the number of z-expressions and the number of edges in the graph.</p><p>We claim that this reduction is an L-reduction. Property (a) is satisfied because the equation above implies that OPT(f (I )) ≤ OPT(I ). Property (b) is satisfied because, from a vertex cover, we can build a linear program which computes the z-expressions in the manner described above. This gives c = OPT(I ) + |c -OPT(f (I ))|.</p><p>To show that the problem is MAX SNP-hard we reverse the reduction so that it goes from Bounded Vertex Cover to Bounded Z-EXPN. The function f now maps "edge (i, j )" into "z + x i + x j ".</p><p>Proof of Property (a): By Lemma 1 we have that OPT(I ) + |E| = OPT(f (I )). Since the maximum degree in the graph is bounded by b and every edge must be adjacent to at least one vertex of the cover, there can be at most b • OPT(I ) edges, of the cover. Thus OPT(f (I )) ≤ (b + 1)OPT(I ).</p><p>Proof of Property (b): The proof of Lemma 1 gave a polynomial-time procedure for converting any linear program computing a set of z-expressions into a vertex cover for the corresponding graph. By inspecting this procedure, one sees that c = OPT(I</p><formula xml:id="formula_33">) + |c -OPT(f (I ))|.</formula><p>The fact that BOUNDED Z-EXPN is complete for the class MAX SNP implies that there is no -approximation scheme for it unless P = NP. In fact, Clementi and Trevisan <ref type="bibr" target="#b13">[14]</ref> have shown that BOUNDED VERTEX COVER is not approximable within 16/15for sufficiently large maximum degree. By Proposition 2, this means that there is no 1 + (1/15 -)/αβ = 1 + (1/15 -)/(1 + b)-approximation algorithm for SLP unless P = NP. We also mention that, assuming the Unique Games Conjecture <ref type="bibr" target="#b23">[24]</ref>, Austrin et al. have improved this inapproximability bound to a function that approaches 2 as the bound on the degree gets large <ref type="bibr" target="#b1">[2]</ref>.</p><p>The fact that BOUNDED Z-EXPN is in the class MAX SNP means that there is an approximation algorithm for it with a constant approximation ratio. In fact, it is obvious that Z-EXPN, even without the boundedness constraint, has an approximation algorithm with a constant approximation. The straightforward linear straight-line program for computing the |E| forms only requires 2|E| lines, and every straight-line program for E must contain at least |E| lines (assuming no repetitions within the set E). Thus, the straightforward algorithm comes within a factor of 2 of optimal. Moreover, since there is an approximation algorithm for vertex cover which comes within a factor of 2 of optimal, we can do even better for Z-EXPN. Since the optimal linear program contains |W | + |E| steps, where W is the minimum vertex cover, by Lemma 1, there is an algorithm which takes 2|W |+|E| steps. Since |W | &lt; |E|, the ratio (2|W |+|E|)/(|W |+|E|) is at most 3/2, so there is a (3/2)-approximation algorithm for Z-EXPN. There are, however, no known approximation algorithms which obtain a constant ratio for the general SLP problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Cancellation Can Yield Smaller Circuits</head><p>Thus, unless P = NP, this problem does not even have efficient -approximation schemes, so our goal in this research is restricted to improving on known heuristics. As far as we know, the most successful heuristics are variations on a greedy algorithm due to Paar <ref type="bibr" target="#b30">[31]</ref>. We report significant improvements over the latter methods. Paar's algorithm gives non-cancelling results. It keeps a list of variables computed, which is initially only the inputs. Then it repeatedly determines which two variables, XORed together, occur in most outputs. One such pair is selected and XORed together. This result is added as a new variable which appears in all outputs where both variables previously appeared. This can be repeated until everything has been computed. One possible variant of this was presented in the same article <ref type="bibr" target="#b30">[31]</ref>: When there is more than one most frequently occurring pair, instead of selecting one, try all possibilities, using recursion. The original algorithm is very fast; the variant is not.</p><p>A different technique is due to Bernstein <ref type="bibr" target="#b2">[3]</ref>. Bernstein's algorithm has the advantages of using less storage and functioning better on two-operand platforms, i.e., where a := a ⊕ b is an allowed operation, but a := b ⊕ c is not. However, experiments mentioned in <ref type="bibr" target="#b2">[3]</ref> indicate that Bernstein's algorithm usually produces results with more gates than Paar's.</p><p>Previous work on circuit minimization for AES S-boxes (e.g., <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref>) only consider cancellation-free straight-line programs for producing a set of linear forms over GF <ref type="bibr" target="#b1">(2)</ref>. Canright <ref type="bibr" target="#b12">[13]</ref> even does an exhaustive search to find an optimal cancellationfree straight-line program. This does not, however, necessarily imply that Canright has found the optimal linear straight-line program. Some authors appear to make the incorrect assumption that there always exists a cancellation-free optimal linear program over GF <ref type="bibr" target="#b1">(2)</ref>.</p><p>As mentioned in the introduction, restricting the search for optimal straight-line programs for computing linear forms over GF(2) to cancellation-free programs can lead to suboptimal solutions. In our counter-example, the optimal cancellation-free program has length 5  4 times that of the true shortest program. It is natural to ask how close to optimal cancellation-free programs can get as the number of variables increases. In this subsection we show that the best cancellation-free straight-line programs are not guaranteed to even have length within a factor 3/2 that of the shortest straight-line linear program. The following construction uses two integer parameters k and n, which can be made large to make the 3/2 inapproximability result hold asymptotically. The parameter k is the number of variables in a block, and n is the number of distinct blocks. Blocks have disjoint sets of variables: Block i, where 0</p><formula xml:id="formula_34">for i = 1 to k(n -1) do u i := x i + x i+k for i = 0 to n -2 do s i := u ik+1 + u ik+2 for j = 1 to k -2 do s i := s i + u ik+j +2 for i = 0 to n -3 do p i := s i + s i+1</formula><formula xml:id="formula_35">≤ i ≤ n -1, is the linear form b i = x ik+1 + x ik+2 + • • • + x (i+1)k .</formula><p>The construction produces a linear straight-line program which is not cancellation-free. All intermediate linear forms (the linear forms produced at each line of the program) computed by this straight-line linear program will belong to the set of required outputs. The first part of the linear straight-line program will produce sums of consecutive pairs of blocks s i = b i +b i+1 , for 0 ≤ i ≤ n-2, mixing the variables in the two blocks in such a way that also producing a single block alone would require extra additions compared to the program here. Then, pairs of these consecutive sums are computed, p i = s i + s i+1 , for 0 ≤ i ≤ n -3. Each p i is computed with only one further addition, but the two s i s added share a common block which is cancelled, so p i = b i + b i+2 . We express this linear program, denoted P , using for loops in Fig. <ref type="figure" target="#fig_6">7</ref>, but for any fixed k and n it is a straight-line program of length k(n -1)</p><formula xml:id="formula_36">+ (k -1)(n - 1) + n -2 = 2kn -2k -1.</formula><p>We claim that an optimal cancellation-free program (for computing all the linear forms which are the result of some line in this program) does at least enough additional operations to compute each of the blocks, and this would require at least n(k -1) additional lines. Let F denote the set consisting of the first (2k -1)(n -1) lines of P , and let L denote the set of the last n -2 lines. All of the 2kn -2k -1 lines output by the above straight-line program are linear forms which must be output. The lines in L are the only ones with cancellations. None of the results from the lines in F can be used to compute the lines in P , because, for any two lines f ∈ F and l ∈ L, f contains at least one variable which is not present in the form calculated by l. It is conceivable that some of the non-output results computed in the process of producing the outputs in L could be used in computing those in F , but, since they are all outputs, at least one extra operation is needed to produce each output from F . Thus, we can consider computing the outputs in L independently from those in F .</p><p>Blocks b 2 through b n-3 each appear in two of the outputs from L, but there is no other overlap between the outputs in L. Thus, the only reuse of forms computed which is possible is within the blocks. An optimal way to compute the forms in L is to first compute each of the n blocks, using k -1 additions for each. After this, each form in L can be created by adding two blocks together, using one addition for each, as in P . The computation of the blocks gives n(k -1) extra additions, for a total of 3kn -2kn -1 additions. Asymptotically, the ratio 3kn-2k-n-1 2kn-2k-1 is 3/2 for large n and k.</p><p>Theorem 5. Any algorithm for computing short straight-line linear programs, which only produces cancellation-free straight-line programs, has an approximation ratio of at least 3/2.</p><p>Thus, even optimal cancellation-free circuits can be far from optimal in the unrestricted model. The heuristic we present below is not restricted to producing cancellation-free circuits. Furthermore, there appears to be little reason for restricting the search to cancellation-free circuits, as we have shown that finding an optimal cancellation-free circuit is also NP-hard in Sect. 3.1.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">A New Heuristic</head><p>Let S be a set of linear functions. For any linear predicate f , we define the distance δ(S, f ) as the minimum number of additions of elements from S necessary to obtain f . The problem is to find a short linear program that computes f (x) = Mx where M is an m × n matrix over GF <ref type="bibr" target="#b1">(2)</ref>. The heuristic is as follows. We keep a "base" S of "known" functions. Initially S is just the set of variables x 1 , . . . , x n . We maintain the vector Dist[] of distances from S to the linear functions given by the rows of M. That is, Dist[i] = δ(S, f i ) where f i is the ith row of M multiplied by the input vector x. Initially, Dist[i] is just one less than the Hamming weight of row i. We then perform the following loop:</p><p>• pick a new base element by adding two existing base elements;</p><formula xml:id="formula_37">• update Dist[];</formula><p>until Dist[i] = 0 for all i.</p><p>The current criterion for picking the new base element is</p><p>• pick one that minimizes the sum of new distances;</p><p>• resolve ties by maximizing the Euclidean norm of the vector of new distances. This tie resolution criterion, which we term "Norm", may seem counter-intuitive. The basic idea is that we prefer a distance vector like 0, 0, 3, 1 to one like 1, 1, 1, 1. In the latter case, we would need 4 more gates to finish. In the former, 3 might do it.</p><p>The bulk of the time of the heuristic is spent on picking the new base element. Our experiments show that the following "pre-emptive" choice usually improves running time without increasing the size of the output circuit:</p><p>• if any two bases S[i], S[j ] are such that S[i] ⊕ S[j ] is a row in M, then pick this sum as the new base element.</p><p>The tie resolution criterion is a critical part of the heuristic. It does well on most matrices we have tried, but we have found specific matrices for which other decision rules do better. Intuitively, no one simple rule should work for all matrices. The effectiveness of the heuristic most likely depends on the topology of the digraph represented by the input matrix. We have not pursued this line of inquiry. We have, however, tested our heuristic with various tie resolution methods against Paar's algorithm <ref type="bibr" target="#b30">[31]</ref>. On random matrices, our heuristic gives significant improvements under Norm as well as under three other tie-breaking rules (see Sect. 5).</p><formula xml:id="formula_38">y 0 = x 0 + x 1 + x 2 y 1 = x 1 + x 3 + x 4 y 2 = x 0 + x 2 + x 3 + x 4 y 3 = x 1 + x 2 + x 3 y 4 = x 0 + x 1 + x 3 y 5 = x 1 + x 2 + x 3 + x 4 M = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦</formula><p>The distance vector in our heuristics is computed by exhaustive search. The reason the heuristic is practical for moderate-size matrices is that the distance can only decrease. In fact, it can only decrease by 1. So when a new base is being considered, if a distance is d, then only combinations of exactly d -1 old base elements and the new base element need to be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">A Small Example Using the Heuristic</head><p>Suppose we need a circuit that computes the system of equations defined in Fig. <ref type="figure" target="#fig_7">8</ref>, which is equivalent to finding a circuit for multiplication by the 6 × 5 matrix, M, given in the figure . 
The target signals to be computed are simply the rows of M. The initial base is {x 0 , x 1 , x 2 , x 3 , x 4 }, which corresponds to S = 1 0 0 0 0 , 0 1 0 0 0 , 0 0 1 0 0 , 0 0 0 1 0 , 0 0 0 0 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The initial distance vector is</head><formula xml:id="formula_39">D = 2 2 3 2 2 3 .</formula><p>The heuristic must find two base vectors whose sum, when added to the base, minimizes the sum of the new distances. It turns out that the right choice is to calculate x 1 + x 3 . So the new base S is expanded to contain the signal 0 1 0 1 0 = 0 1 0 0 0 + 0 0 0 1 0 .</p><p>The new distance vector is</p><formula xml:id="formula_40">D = 2 1 3 1 1 2 .</formula><p>The full run of the program is shown in Fig. <ref type="figure" target="#fig_8">9</ref>. The tie-breaking criteria is used in Step 3. If one had chosen x 0 + x 1 instead of x 4 + t 6 , the new distance vector would be [1 1 2 0 1 1], which has norm √ 8, while the one found has norm √ 10. Note that there is cancellation in Steps 6 and 8.</p><p>Step 1:</p><formula xml:id="formula_41">t 5 = x 1 + x 3 (found signal = [0 1 0 1 0]). New D : [2 1 3 1 1 2]</formula><p>Step 2: t 6 = x 2 + t 5 (found target signal y 3 = [0 1 1 1 0]). New D : [2 1 3 0 1 1]</p><p>Step 3: t 7 = x 4 + t 6 (found target signal y 5 = [0 1 1 1 1]). New D : [2 1 2 0 1 0] Step 4: t 8 = x 0 + x 1 (found signal = [1 1 0 0 0]). New D : [1 1 1 0 1 0] Step 5: t 9 = x 0 + t 5 (found target signal y 4 = [1 1 0 1 0]). New D : [1 1 1 0 0 0] Step 6: t 10 = x 2 + t 7 (found target signal y 1 = [0 1 0 1 1]). New D : [1 0 1 0 0 0 ] Step 7: t 11 = x 2 + t 8 (found target signal y 0 = [1 1 1 0 0]) . New D : [0 0 1 0 0 0] Step 8: t 12 = t 7 + t 8 (found target signal y 2 = [1 0 1 1 1]). New D : [0 0 0 0 0 0] (DONE!)  Thus, after the x i , which may be nonlinear functions of other variables, are computed, the y i are computed by following the algorithm produced and, in this case, letting y 0 = t 11 , y 1 = t 10 , y 2 = t 12 , y 3 = t 6 , y 4 = t 9 , y 5 = t 7 .</p><formula xml:id="formula_42">y 14 = x 3 + x 5 y 13 = x 0 + x 6 y 9 = x 0 + x 3 y 8 = x 0 + x 5 t 0 = x 1 + x 2 y 1 = t 0 +</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A Circuit for the S-Box of AES</head><p>Our techniques yield a circuit for the AES S-box composed of 115 gates in three parts: a "top" linear transformation, U ; a middle nonlinear part; and a "bottom" linear transformation, B. The linear transformations are defined by the matrices U and B of Sect. 2.2.</p><p>For the matrix U , the smallest circuits we found had 23 ⊕ gates. Among the many such circuits, the shortest ones have depth 7. It is worthwhile to note that if 24 ⊕ gates are allowed, circuits with depth 4 exist for U . Figure <ref type="figure" target="#fig_0">10</ref> shows a circuit of size 23 and depth 7. The circuit maps inputs x 0 , . . . , x 7 to outputs x 7 , y 1 , . . . , y 21 .</p><p>Figure <ref type="figure" target="#fig_0">11</ref> shows the nonlinear middle part of the S-box circuit. It is a function from 22 to 18 bits. The circuit contains 32 ∧ gates and 30 ⊕ gates. It maps inputs x 7 , y 1 , . . . , y 21 to outputs z 0 , . . . , z 17 .</p><p>For matrix B, the randomized version of our heuristic yields many circuits with 30 ⊕ gates. The heuristic is fast enough that we are able to pick a circuit which is both small and short. Figure <ref type="figure" target="#fig_1">12</ref> shows a circuit of depth 6. The circuit maps inputs z 0 , . . . , z 17 to outputs s 0 , . . . , s 7 . As mentioned earlier, our circuit was based on Canright's <ref type="bibr" target="#b12">[13]</ref>. Our nonlinear middle part corresponds fairly closely to his, except that his subcircuit for inversion in GF(2 4 ) was replaced by ours. He does not consider all of the top linear transformation as one unit. However, since this middle part of his circuit corresponds to ours, with the same inputs and outputs, he computes those inputs using linear operations. The number of XOR/XNOR gates he uses to compute this top linear transformation is 29. Similarly, he uses 31 XOR/XNOR gates to compute what corresponds to our bottom linear transformation. After optimizations, his circuit has a total of 80 XOR/XNOR gates, 34 NANDs, and 6 NORs. We did not attempt to use NOR gates to further reduce the size of our circuit.</p><p>A more direct comparison was also made comparing our techniques for minimizing linear circuits and Canright's. In <ref type="bibr" target="#b12">[13]</ref>, he presents a factorization of two 16 by 8 matrices, ( X -1</p><p>(MX) -1 ) and ( (MX) X ), showing that these can be computed using 20 and 18 gates, respectively. Our heuristic produces circuits with 18 and 17 gates, respectively.<ref type="foot" target="#foot_4">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments with Different Tie-Breaking Methods</head><p>In order to compare the effects of using different tie-breakers, we tested our heuristics on matrices generated as follows.</p><p>• We first chose a size (for example, 10 × 20 matrices, which represent 10 linear forms on 20 distinct variables). • We then picked a bias ρ between 0 and 1.</p><p>• For each entry of the matrix, we set the bit to 1 with probability ρ and to 0 with probability 1ρ. Thus ρ is the expected fraction of variables that appears in each linear form. • Matrices with rows which are all zeros were discarded, as were matrices containing duplicate rows.</p><p>The testing was performed with a C++ program, compiled with g++ -O3, on a quadcore x86_64, running Ubuntu 9.10, with Intel Xenon 5150 processors running at 2.66 GHz, with 8 GB memory. There were no other users on the machine. The programs and matrices used can be found at www.imada.sdu.dk/~joan/xor/, though minor changes are necessary to run the programs with different files as input or to change the matrix size and bias for the matrix generator. We compared the different heuristics on sets of 100 random matrices with different sizes and densities. The experiments showed that the heuristics were slower when the bias was larger. This was expected, since the initial "distances" (number of operations on the base vectors to obtain the target vectors) were then larger on average when there were more ones in the matrices.</p><p>The tie-breakers we compared were the following:</p><p>• Norm: maximizing the Euclidean norm In all cases, except the "Random" one, when there were still ties after applying the "tie-breaker," the first pair with both the minimum sum of distances and the optimal value for the tie-breaker was chosen. This was the base pair with lexicographically minimum indices (i, j ). The exception to this is when there is a target with distance 1, meaning that using one extra gate will produce a target. A check is made for this case by scanning the distances and choosing the first with distance 1 when such exists. This check is efficient, and when there is a target of distance 1, it saves lengthy computations of new distances for each possible pair of bases.</p><p>Randomized tie-breaking allows running the heuristic several times and picking the best result. In our tests we ran the heuristic with "Random" tie-breaking three times.</p><p>We also compared these heuristics to Paar's heuristic <ref type="bibr" target="#b30">[31]</ref> on the same matrices. Paar's heuristic repeatedly finds the most frequently occurring base pair and adds that as the next base pair. It is significantly faster than our heuristic, but it produces only cancellation-free circuits. Its performance, relative to the heuristics proposed here, decreases as the bias increases, using more than 30 % extra gates when the bias is 3/4 (when the number of rows is at least 15) and 40 % extra when the bias is 9/10.</p><p>Among the biases tried, the number of gates in the circuits found by our heuristics is similar with biases 1/2 and 3/4. It is not a strictly increasing function of the bias, since when nearly all of the variables are used in nearly all of the forms, the outputs from many of the gates can be reused for many targets. Thus, circuits with fewer gates were found when the bias was 9/10 than when it was 1/2 or 3/4. This was also true for Paar's heuristic, but less dramatically so.</p><p>All the tie resolution criteria performed fairly similarly, producing circuits of nearly the same size, with Random apparently doing slightly better (more often producing smaller circuits), presumably because it tries three different circuits and uses the best. Random also runs for about three times as long as the others. The results of these tests are presented in tables in the Appendix. In the tables, the column headings specify the matrix size and the bias. For each heuristic, and all matrix sizes and biases, 100 randomly chosen matrices were tested.</p><p>For each tie-breaker rule and Paar's heuristic, for each matrix size and bias, the average number of gates in the circuits found and the number of matrices where that heuristic did not obtain the minimum value of all of the heuristics was computed, along with the running time in seconds. The Paar heuristic was beaten by at least one of the other heuristics on all 700 matrices except for 17 of the 100 with bias 1/4 (and there was only one matrix on which Paar's heuristic beat any of the other heuristics). In fact, for the tests with bias larger than 1/4, Paar's heuristic did worse than any of the other heuristic on every one of the matrices; usually the values obtained for the newer heuris-tics were similar, with Random possibly being marginally better, but with the value for Paar's heuristic being significantly larger.</p><p>Paar's heuristic (and, for matrices between size 4 and 10, a variant which does at most one gate better on average in the data presented) was tested <ref type="bibr" target="#b30">[31]</ref> on square matrices of sizes 4 × 4 through 16 × 16, and the average number of XOR gates is presented, along with the relative improvement over the straightforward implementation. These square matrices came from applying Mastrovito's <ref type="bibr" target="#b26">[27]</ref> matrix description of multiplication in GF(2 n ) to constant multiplication. Paar tries all possible constants in GF(2 n ) for n between 4 and 16, giving these square matrices. Since our heuristics are so much slower and the matrices in the cryptographic applications we are interested in do not necessarily have this form, we have not tested on all of these restricted matrices of those sizes, but rather on random matrices with different biases. For 15 × 15 matrices, Paar gets an average of 52.9 gates. This is similar to our results for Paar's algorithm with 15 × 15 matrices with biases 1/2 and 3/4, where the Paar heuristic gets averages of 51.7 and 53.3 gates, respectively. For bias 1/2, our deterministic heuristics get average gate counts between 44.21 and 44.28, while Random gets 43.81. For bias 3/4, our deterministic heuristics all get average count 40.82, while Random gets 40.38. Thus, our relative improvement over the Paar heuristic is between 17 % and 32 % for these types of matrices. Paar's result of 52.9 gates for 15 × 15 matrices is a relative improvement of 45.5 % over the straightforward approach.</p><p>The last row in each table in the Appendix shows the average of the values which are the minimum of those calculated by the different heuristics for each matrix. The fact that this number is always strictly smaller than the average for any specific tie-breaker shows that, for each of the tie-breakers, there are cases where it gets a worse result than at least one of the others. This is also shown by the column headed "Not min" which shows the number of matrices for which that tie-breaker did not achieve the lowest value found by the tie-breakers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Work in Progress</head><p>We developed and tested new techniques for decreasing circuit size. The techniques were applied to the extensively studied AES S-box. We obtained the smallest circuit yet constructed for this function. The circuit contains 32 AND gates and 83 XOR/XNOR gates for a total of 115 gates. As by-products of the experiment, we obtained very small circuits for inversion in GF (2 4 ) and GF(2 8 ).</p><p>The result that SHORTEST LINEAR PROGRAM is NP-hard indicates that using heuristic techniques is more realistic than expecting to find the smallest subcircuits for linear parts of a Boolean circuit. The result that a special case of SHORTEST LINEAR PROGRAM is MAX SNP-complete indicates that there is a limit to how well these heuristic techniques can be guaranteed to perform.</p><p>Since cancellation-free techniques can produce linear straight-line programs which are a factor 3/2 larger than the optimal, the heuristic developed here (in Step 2) is not restricted to cancellation-free operations.</p><p>The experiments with linear circuit optimization indicate that our techniques are likely to be superior to previous techniques which produced only cancellation-free circuits. We expect this to be particularly useful for cryptographic applications, both for hardware and software implementations, where many XOR operations are used, along with some AND operations to introduce nonlinearity.</p><p>It would be interesting to determine how close to optimal the circuits found by these techniques usually are and how much better they are than the optimal cancellation-free circuits. Finding even better techniques which are not restricted to finding cancellationfree circuits would also be very interesting.</p><p>Work on finding exact solutions using SAT-solvers has developed a technique which will quickly find a circuit with 23 gates, the same size we report here for our techniques, for the top linear transformation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. They also prove that this cannot be achieved with 22 gates, so the number of gates used here for the top linear transformation is optimal.</p><p>Recent work has shown that the lower bound of 3/2 for the approximation ratio of cancellation-free straight-line programs can be improved to 2, using a generalization of the example at the end of Sect. 1.3.</p><p>In practice, one would like to construct small low-depth circuits. This paper has discussed size only. However, it is plausible that a short circuit can be obtained by first minimizing size and then shortening the circuit along critical paths using balancing and other simple techniques. Preliminary results using this general approach are highly encouraging. An application to the AES S-box yields a circuit of depth 16 with only 128 gates <ref type="bibr" target="#b7">[8]</ref>. This size is larger than that given here, where the depth is 28, but comparable to other results which have significantly more depth <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28]</ref>. Previous attempts at reducing depth without too much expansion in size were only able to produce depth 22 and size 148 <ref type="bibr" target="#b28">[29]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Two circuits and corresponding straight-line programs for MAJ(a, b, c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Inversion in GF(2 4 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Graph with 8 edges and cover size 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Computing the cover W .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The fix-up procedure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) The optima of I and f (I ), written OPT(I ) and OPT(f (I )) respectively, satisfy the relation OPT(f (I )) ≤ αOPT(I ). (b) For any solution of f (I ) with cost c , we can find in polynomial time a solution of I with cost c such that |c -OPT(I )| ≤ β|c -OPT(f (I ))|.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Straight-line program with cancellations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Example sequence of equations and corresponding matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Example running heuristic for minimizing linear components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>x 7 y 4 = y 1 + x 3 y 12 = y 13 + y 14 y 2 = y 1 + x 0 y 5 = y 1 + x 6 y 3 = y 5 + y 8 t 1 = x 4 + y 12 y 15 = t 1 + x 5 y 20 = t 1 + x 1 y 6 = y 15 + x 7 y 10 = y 15 + t 0 y 11 = y 20 + y 9 y 7 = x 7 + y 11 y 17 = y 10 + y 11 y 19 = y 10 + y 8 y 16 = t 0 + y 11 y 21 = y 13 + y 16 y 18 = x 0 + y 16 Fig. 10. Top linear transformation: Inputs are x 0 , x 1 , . . . , x 7 . Outputs to the next level are x 7 , y 1 , y 2 , . . . , y 21 .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>t 2 = y 12 × y 15 t 3 = y 3 × y 6 t 4 = t 3 + t 2 t 5 = y 4 × x 7 t 6 = t 5 + t 2 t 7 = y 13 × y 16 t 8 = y 5 × y 1 t 9 = t 8 + t 7 t 10 = y 2 × y 7 t 11 = t 10 + t 7 t 12 = y 9 × y 11 t 13 = y 14 × y 17 t 14 = t 13 + t 12 t 15 = y 8 × y 10 t 16 = t 15 + t 12 t 17 = t 4 + t 14 t 18 = t 6 + t 16 t 19 = t 9 + t 14 t 20 = t 11 + t 16 t 21 = t 17 + y 20 t 22 = t 18 + y 19 t 23 = t 19 + y 21 t 24 = t 20 + y 18 t 25 = t 21 + t 22 t 26 = t 21 × t 23 t 27 = t 24 + t 26 t 28 = t 25 × t 27 t 29 = t 28 + t 22 t 30 = t 23 + t 24 t 31 = t 22 + t 26 t 32 = t 31 × t 30 t 33 = t 32 + t 24 t 34 = t 23 + t 33 t 35 = t 27 + t 33 t 36 = t 24 × t 35 t 37 = t 36 + t 34 t 38 = t 27 + t 36 t 39 = t 29 × t 38 t 40 = t 25 + t 39 t 41 = t 40 + t 37 t 42 = t 29 + t 33 t 43 = t 29 + t 40 t 44 = t 33 + t 37 t 45 = t 42 + t 41 z 0 = t 44 × y 15 z 1 = t 37 × y 6 z 2 = t 33 × x 7 z 3 = t 43 × y 16 z 4 = t 40 × y 1 z 5 = t 29 × y 7 z 6 = t 42 × y 11 z 7 = t 45 × y 17 z 8 = t 41 × y 10 z 9 = t 44 × y 12 z 10 = t 37 × y 3 z 11 = t 33 × y 4 z 12 = t 43 × y 13 z 13 = t 40 × y 5 z 14 = t 29 × y 2 z 15 = t 42 × y 9 z 16 = t 45 × y 14 z 17 = t 41 × y 8 Fig. 11. The middle nonlinear section: inputs are x 7 , y 1 , y 2 , . . . , y 21 . Outputs to the next level are z 0 , z 1 , . . . , z 17 . Note that the computation of t 25 through t 40 is the inversion in GF(2 4 ). t 46 = z 15 + z 16 t 47 = z 10 + z 11 t 48 = z 5 + z 13 t 49 = z 9 + z 10 t 50 = z 2 + z 12 t 51 = z 2 + z 5 t 52 = z 7 + z 8 t 53 = z 0 + z 3 t 54 = z 6 + z 7 t 55 = z 16 + z 17 t 56 = z 12 + t 48 t 57 = t 50 + t 53 t 58 = z 4 + t 46 t 59 = z 3 + t 54 t 60 = t 46 + t 57 t 61 = z 14 + t 57 t 62 = t 52 + t 58 t 63 = t 49 + t 58 t 64 = z 4 + t 59 t 65 = t 61 + t 62 t 66 = z 1 + t 63 s 0 = t 59 + t 63 s 6 = t 56 XNOR t 62 s 7 = t 48 XNOR t 60 t 6 7 = t 64 + t 65 s 3 = t 53 + t 66 s 4 = t 51 + t 66 s 5 = t 47 + t 65 s 1 = t 64 XNOR s 3 s</figDesc><table /><note><p>2 = t 55 XNOR t 67 Fig. 12. Bottom linear transformation: Inputs are z 0 , z 1 , . . . , z 17 . Outputs are s 0 , s 1 , . . . , s 7 .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>• Norm-largest: maximizing the square of the Euclidean norm minus the largest distance • Norm-diff: maximizing the square of the Euclidean norm minus the difference of the largest two distances • Random: In processing the possible new base vectors, if the current possible new base vector has the same sum of distances as the previous best (current choice), then flip an unbiased coin. If heads, then keep the current choice. If tails, then apply the Norm criterion. This heuristic may end up choosing a pair with non-maximum Euclidean norm. On the other hand, it allows substitution of one optimum (by sum-of-distances and Euclidean norm) pair by another found later in the search.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>We consider circuits without negations only. There is no loss of generality in doing so, because negations can be treated as standard XOR gates via (¬X = (X ⊕ 1)).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>It is not known if multiplication of variables can ever be used to reduce program length when the program outputs only linear functions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>A circuit for finite field inversion must have some output for the noninvertible zero element. In the following constructions we follow the AES convention that the output on input zero is zero.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>We avoid the discussion of models for dealing with infinite fields, such as in<ref type="bibr" target="#b35">[36]</ref> or<ref type="bibr" target="#b3">[4]</ref>, by proving NP-hardness when the constants in the forms are only zeros and ones and showing that a shortest linear straight-line program for the forms considered can be created with only zeros and ones as constants.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p>Using the Improved2.cc program with the matrix canmat, available with the other programs and matrices described in the next section, gives these results.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the anonymous referees for their suggestions. One of the referees also discovered a problem with an earlier proof of Lemma 1, which we correct here. The following summer interns at NIST also contributed to some of the experimental work reported here: Holman Gao and Michael Bartock.</p><p>Research of J. Boyar was partially supported by the Danish Council for Independent Research, Natural Sciences.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Experimental Results on Samples of 100 Random Matrices</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Proof verification and the hardness of approximation problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sudan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Comput. Mach</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="501" to="555" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Inapproximability of vertex cover and independent set in bounded degree graphs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Austrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Safra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computational Complexity</title>
		<meeting><address><addrLine>Los Alamitos</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="74" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing linear maps modulo 2</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bernstein</surname></persName>
		</author>
		<ptr target="http://cr.yp.to/papers.html#linearmod2" />
	</analytic>
	<monogr>
		<title level="m">Workshop Record of SPEED-CC: Software Performance Enhancement for Encryption and Decryption and Cryptographic Compilers</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On a theory of computation and complexity over the real numbers: NPcompleteness, recursive functions and universal machines</title>
		<author>
			<persName><forename type="first">L</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Am. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="46" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tight bounds for the multiplicative complexity of symmetric functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peralta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">396</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="223" to="246" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Patent application number 61089998 filed with the U.S. Patent and Trademark Office. A new technique for combinational circuit optimization and a new circuit for the S-Box for AES</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peralta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A new combinational logic minimization technique with applications to cryptology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peralta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Symposium on Experimental Algorithms, SEA 2010</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6049</biblScope>
			<biblScope unit="page" from="178" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Boyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peralta</surname></persName>
		</author>
		<ptr target="http://eprint.iacr.org/" />
		<title level="m">A depth-16 circuit for the AES S-box. Cryptology ePrint archive, report</title>
		<imprint>
			<date type="published" when="2011">2011/332, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the multiplicative complexity of Boolean functions over the basis (∧, ⊕, 1)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peralta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pochuev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">235</biblScope>
			<biblScope unit="page" from="43" to="57" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the shortest linear straight-line program for computing linear forms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peralta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd International Symposium on Mathematical Foundations of Computer Science, MFCS 2008</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5162</biblScope>
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Bürgisser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Shokrollahi</surname></persName>
		</author>
		<idno>Chap. 13</idno>
		<title level="m">Algebraic Complexity Theory</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A very compact Rijndael S-box</title>
		<author>
			<persName><forename type="first">D</forename><surname>Canright</surname></persName>
		</author>
		<idno>NPS-MA-05-001</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Naval Postgraduate School</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><surname>Canright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A very compact Rijndael S-box, in 7th International Workshop on Cryptographic Hardware and Embedded Systems, CHES 2005</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3659</biblScope>
			<biblScope unit="page" from="441" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved non-approximability results for vertex cover with density constraints</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E F</forename><surname>Clementi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trevisan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing and Combinatorics</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An algorithm for the machine calculation of complex Fourier series</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Cooley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Comput</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="297" to="301" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Solving circuit optimisation problems in cryptography and cryptanalysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Courtois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hulme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mourouzis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IACR Cryptology ePrint Archive</title>
		<imprint>
			<biblScope unit="page">475</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Advanced Encryption Standard (AES</title>
		<author>
			<persName><surname>Fips</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Gaithersburg</pubPlace>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Synthesizing shortest linear straight-line programs over GF(2) using SAT</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fuhs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schneider-Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th International Conference on Theory and Applications of Satisfiability Testing</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6175</biblScope>
			<biblScope unit="page" from="71" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimizing the AES S-Box using SAT</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fuhs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schneider-Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on the Implementation of Logics</title>
		<meeting>the 8th International Workshop on the Implementation of Logics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tensor rank is NP-Complete</title>
		<author>
			<persName><forename type="first">J</forename><surname>Håstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="644" to="654" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Faster secure two-party computation using garbled circuits</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Malka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th USENIX Security Symposium</title>
		<meeting>the 20th USENIX Security Symposium<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-08">August 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A fast algorithm for computing multiplicative inverses in GF(2 m ) using normal bases</title>
		<author>
			<persName><forename type="first">T</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Comput</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="177" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Faster and timing-attack resistant AES-GCM</title>
		<author>
			<persName><forename type="first">E</forename><surname>Käsper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schwabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Workshop on Cryptographic Hardware and Embedded Systems</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5747</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
	<note>CHES 2009</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the power of unique 2-prover 1-round games</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual ACM Symposium on Theory of Computing, STOC &apos;02</title>
		<meeting>the 34th Annual ACM Symposium on Theory of Computing, STOC &apos;02<address><addrLine>New York, NY, USA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="767" to="775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improved garbled circuit: free XOR gates and applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Automata, Languages and Programming, 35th International Colloquium, ICALP 2008</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>Automata, Languages and Programming, 35th International Colloquium, ICALP 2008<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5126</biblScope>
			<biblScope unit="page" from="486" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A method of circuit synthesis</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">B</forename><surname>Lupanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Izv. Vysš. Učebn. Zaved., Radiofiz</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="120" to="140" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><surname>Mastrovito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSI architectures for computation in Galois fields</title>
		<meeting><address><addrLine>Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Linköping University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An optimized S-Box circuit architecture for low power AES design</title>
		<author>
			<persName><forename type="first">S</forename><surname>Morioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Revised Papers from the 4th International Workshop on Cryptographic Hardware and Embedded Systems, CHES 2002</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2523</biblScope>
			<biblScope unit="page" from="172" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">) 2 ) 2 ) and conversion matrices of subbytes of AES</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nogami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nekado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Toyota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Morikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th International Workshop on Cryptographic Hardware and Embedded Systems, CHES 2010</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6225</biblScope>
			<biblScope unit="page" from="234" to="247" />
		</imprint>
	</monogr>
	<note>Mixed bases for efficient inversion in f (</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Some remarks on efficient inversion in finite fields</title>
		<author>
			<persName><forename type="first">C</forename><surname>Paar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1995 IEEE International Symposium on Information Theory</title>
		<meeting><address><addrLine>Whistler, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">58</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimized arithmetic for Reed-Solomon encoders</title>
		<author>
			<persName><forename type="first">C</forename><surname>Paar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Information Theory</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page">250</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Optimization, approximation, and complexity classes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="425" to="440" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A compact Rijndael hardware architecture with S-Box optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Morioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Takano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Munetoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Cryptology-Proceedings of ASIACRYPT 01</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2248</biblScope>
			<biblScope unit="page" from="239" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An algorithm for the computation of linear forms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Savage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SICOMP</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="158" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The synthesis of two-terminal switching circuits</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech. J</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="59" to="98" />
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Completeness classes in algebra</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Annual ACM Symposium on the Theory of Computing</title>
		<meeting>the 11th Annual ACM Symposium on the Theory of Computing</meeting>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="249" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Matrix-vector multiplication in sub-quadratic time (some preprocessing required</title>
		<author>
			<persName><forename type="first">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the 18th Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="995" to="1001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the number of multiplications necessary to compute certain functions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="165" to="179" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An ASIC implementation of AES SBoxes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wolkerstorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lamberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topics in Cryptology-CT-RSA 2002</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2271</biblScope>
			<biblScope unit="page" from="67" to="78" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
