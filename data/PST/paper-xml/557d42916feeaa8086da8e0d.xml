<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B751D5EEF9CA0A57B4F71AD8D39BE744</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maintaining Representations of the Environment of a Mobile Robot NICHOLAS AYACHE AND OLIVIER D. FAUGERAS</head><p>Abstract-In this paper we describe our current ideas related to the problem of building and updating 3-D representation of the environment of a mobile robot that uses passive Vision as its main sensory modality. Our basic tenet is that we want to represent both geometry and uncertainty. We first motivate our approach by defining the problems we are trying to solve and give some simple didactic examples. We then present the tool that we think is extremely well-adapted to solving most of these problems: the extended Kalman filter (EKF). We discuss the notions of minimal geometric representations for 3-D lines, planes, and rigid motions. We show how the EKF and the representations can be combined to provide solutions for some of the problems listed at the beginning of the paper, and give a number of experimental results on real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>N THE last few years, Computer Vision has gone I extensively into the area of three-dimensional (3-D) analysis from a variety of sensing modalities such as stereo, motion, range finders, and sonars. A book that brings together some of this recent work is <ref type="bibr">[24]</ref>.</p><p>Most of these sensing modalities start from pixels which are then converted into 3-D structures. A characteristic of this work as compared to previous work (like in image restoration, for example) where images were the starting and the ending point is that noise in the measurements is, of course, still present but, contrary to what has happened in the past, it has to be taken into account all the way from pixels to 3-D geometry.</p><p>Another aspect of the work on 3-D follows from the observation that if noise is present, it has to be evaluated, i.e., we need models of sensor noise (sensor being taken here in the broad sense of sensory modality), and reduced. This reduction can be obtained in many ways. The most important ones are as follows: 0 First, the case of one sensor in a fixed position: it can repeat its measurements and thus maybe obtain better estimations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>Second, the case of a sensor that can be moved around: given its measurements in a given position, what is the best way to move in order to reduce the uncertainty and increase the knowledge of the environment in a way that is compatible with the task at hand.</p><p>Third, is the case of several different sensors that have to combine their measurements in a meaningful fashion.</p><p>Interesting work related to those issues has already emerged and <ref type="bibr">Matthies and Shafer [28]</ref>. The problem of combining stereo views has been attacked by Ayache and Faugeras <ref type="bibr">[3]</ref>,</p><p>[4], <ref type="bibr">[ 191,</ref><ref type="bibr">Porril et al. [30]</ref>, and Kriegman [ 2 5 ] . It also appears that the linearization paradigm extensively used in this paper has been already used in the photogrammetry field <ref type="bibr">[26]</ref>.</p><p>Several problems related to these preliminary studies need more attention. Modeling sensor noise in general and more specifically visual sensor noise appears to us an area where considerable progress can be achieved; relating sensor noise to geometric uncertainty and the corresponding problem of representing geometric information with an eye toward describing not only the geometry but also the uncertainty on this geometry are key problems to be investigated further as is the problem of combining uncertain geometric information produced by different sensors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">WHAT ARE THE PROBLEMS THAT WE ARE TRYING TO SOLVE</head><p>We have been focusing on a number of problems arising in connection with a robot moving in an indoor environment and using passive vision and proprioceptive sensory modalities such as odometry. Our mid-term goals are to incrementally build on the robot an increasing set of sensing and reasoning capabilities such as: build local 3-D descriptions of the environment, use the descriptions to update or compute motion descriptions where the motion is either the robot's motion or others, fuse the local descriptions of neighboring places into more global, coherent, and accurate ones, "discover" interesting geometric relations in these descriptions, "discover" semantic entities and exhibit "intelligent" behavior.</p><p>We describe how we understand each of these capabilities and what are the underlying difficu!ties. lO42-296X/89/1200-08O4$01 .OO O 1989 IEEE </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Build Local 3 -0 Descriptions of the Environment</head><p>Up until now, our main source of 3-D information has been Stereo 151, [9] even though we have made considerable progress toward the use of structure from motion as well 1211. In any case, the problems are very similar for both sensing modalities and we concentrate on Stereo. As announced in the Introduction, our main concern is to track uncertainty all the way from pixel noise to geometric descriptions. Fig. <ref type="figure" target="#fig_0">1</ref> shows, for example, that in a Stereo system, if pixels positions are imperfectly known, then the corresponding 3-D point varies in an area with a quite anisotropic diamond shape. This is a clear example of a relation between pixel uncertainty and geometric (the position of point M ) uncertainty. Another source of uncertainty in Stereo is the calibration uncertainty. In a stereo rig, intrinsic parameters of the cameras such as focal length, and extrinsic parameters such as relative position and orientation of the cameras have to be calculated. Fig. <ref type="figure">2</ref> shows the effect on the reconstruction of a point M of an uncertainty on the focal lengths of the two cameras. Again, M varies in a diamond-like shape. Of course, this source of uncertainty adds to the previous pixel Uncertainty.</p><p>Another example of the propagation of uncertainty is given in Fig. <ref type="figure">3</ref> where pixels in left and right images are grouped into line segments: pixel uncertainty is converted into 2-D line uncertainty. Line segments are then matched and used to reconstruct 3-D line segments: 2-D line uncertainty and calibration uncertainty are converted into 3-D uncertainty.</p><p>Yet another set of examples of this kind of propagation is shown in Fig. <ref type="figure" target="#fig_2">4</ref> where coplanar and cocylindrical line segments are grouped together; again, the question is, what is the uncertainty on the plane or on the cylinder? (the uncertainty on the position of the lines, plane, and cylinder is represented on the picture in a symbolic manner by ellipses).</p><p>From these examples, we see that the main problem that needs to be solved in order to build local 3-D descriptions of the environment is how geometric uncertainty propagates when we build more complex primitives from simpler ones. This, in turn, generates two questions:</p><p>1) How do we represent geometric primitives?</p><p>2) How do we represent uncertainty on these primitives?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Update Position and Motion Information</head><p>Fig. <ref type="figure">5</ref> shows a measurement of a physical point made in two positions 1 and 2 of a mobile vehicle. In position 1, it "sees" M with some uncertainty represented by the ellipse around it. In position 2, it "sees" P with another uncertainty. Assuming that the displacement between 1 and 2 is exactly known, it is possible to express P and M in the same coordinate system. If the displacement estimate is wrong, as it is in Fig. <ref type="figure">5</ref>, the two zones of uncertainty do not intersect and it is very unlikely that the observer will realize that the points M and P are instances of the same physical point. If we now take into account the uncertainty on the displacement (assuming that we can estimate it&gt; we have Fig. <ref type="figure" target="#fig_4">6</ref> where the combination of   displacement uncertainty and measurement uncertainty produces a larger ellipse around P which intersects the one around M: the observer can now infer that the probability of M and P being the same physical point is quite high and use the two measurements to obtain a better estimate of the displacement and reduce its uncertainty. We explain how to do this in Section V. The measurements can also be used to produce better estimates of the positions (Fig. <ref type="figure">7</ref>). This is related to what we call geometric fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Fusing Geometric Entities</head><p>Fig. <ref type="figure" target="#fig_3">8</ref> shows a slightly more general case than what is depicted in Fig. <ref type="figure">7</ref>. The mobile vehicle has measured the physical point M in n positions numbered from 1 and n. Each measurement yields a point Mi, i = 1, . . , n and some uncertainty in the coordinate system attached to the robot. Displacement uncertainty is also available. Using the ideas described in Section V, we can improve the estimates of the displacements and reduce their uncertainty by discovering that points M I , * . , M,, are all instanciations of the same point.</p><p>We can also use this observation to reduce the uncertainty on, let us say M I , by combining the n measurements and produce a point 3n, fusion of MI, . . . , M,,, as well as its related uncertainty. The points M I , 1a , M,, can then be erased from the representation of the environment, they can be forgotten.</p><p>What remains is the point 9ll expressed in the coordinate system attached to position 1, for example, and the displacement from 1 to 2, 2 to 3, etc.. . . , which allows us to express 3n in the other coordinate systems.</p><p>Fusing geometric entities is therefore the key to "intelligent" forgetting which, in turn, prevents the representation of the environment from growing too large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discovering "Interesting '' Geometric Relations</head><p>Using this approach also allows us to characterize the likelihood that a given geometric relation exists between a number of geometric entities and to use this information to obtain better estimates of these entities and reduce their uncertainty. For example, as shown in Fig. <ref type="figure">9</ref>, segments AB and CD which have uncertainty attached to their endpoints have a high likelihood to be parallel. Assuming that they are, we can update their position (they become more parallel) and reduce the uncertainty of their endpoints. The same reasoning can be used, for the relation "to be perpendicular."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Discovering Semantic Entities</head><p>Fig. <ref type="figure" target="#fig_22">10</ref> shows the kind of "semantic" grouping that is of interest to us in the context of a mobile robot moving indoors, to combine geometry and some a priori description of the environment. The line segments numbered from 1 to 15 are found, using the ideas described in Section LI-D, to be coplanar with a high probability; the corresponding plane is found to be vertical with a very high probability which can be deduced from the geometric uncertainty of the line segments. This observation can then be used to infer that the plane has a high probability to be a wall. If we also observe that segments 8 to 11 and 12 to 15 form approximately two rectangles this can be used to infer that they have a high probability to be parts of a window or a door.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">WHAT IS THE TOOL THAT WE ARE USING</head><p>In this section, we introduce the Extended Kalman Filter (EKF) formalism which is applied in Sections IV and V to solve the problems we have just listed in Section 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Unifving the Problems</head><p>In all of these previously listed problems, we are confronted with the estimation of an unknown parameter a E R" given a set of k possibly nonlinear equations of the form</p><p>where xi E R m andf, is a function from R" x R" into RP.</p><p>The vector xi represents some random parameters of the function f, in the sense that we only measure an estimate P; of them. such that where vi is a random error. The only assumption we make on U; is that its mean is zero, its covariance is known, and that it is a white noise</p><p>Elu;] = 0</p><p>These assumptions are reasonable. If the estimator is biased, it is often possible to subtract its mean to get an unbiased one. If we do not know the covariance of the error (or at least an upper bound of it), the estimator is meaningless. If two measurements P, and iJ are correlated, we take the concatenation of them i k = (a,, iJ) and the concatenated vector function fk = e, 61'. The problem is to find the optimal estimate 8 of Q given the function fi and the measurements 2,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Linearizing the Equations</head><p>The most powerful tools developed in parameter estimation are for h e a r systems. We decided to apply these tools to a linearized version of our equations. This is the EKF approach that we now develop.</p><p>For each nonlinear equationf,(x,, a) = 0 we need to know an estimate 8,-1 of the sougth parameter a, and again a measure S, of the confidence we have in this estimate.' Actually, we model probdistically the current estimate 8,-of a by assuming that where w, is a random error. The only assumptions we make on wi are the same as for U!, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EIw;]</head><formula xml:id="formula_0">= 0 E [ w; w;] = s; 2 0</formula><p>where Sj is a given non-negative matrix. Here again, no assumption of gaussianness is required.</p><p>Having an estimate 8;-I of the solution, the equations are linearized by a first-order Taylor expansion around (Pi, 6;-I )</p><p>where the derivatives df,//ax A and dfj/da A are estimated at (i;, 8;-1 ) .</p><p>Equation (4j can be rewritten as where Equation ( <ref type="formula">5</ref>) is now a linear measurement equation, where y j is the new measurement, Mi is the linear transformation, ui is the random measurement error. Both yi and Mi are readily computed from the actual measurement f;, the estimate hiof a, the function fi, and its first derivative. The second-order statistics of ui are derived easily from those of ui</p><formula xml:id="formula_1">E [ u J = 0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Recursive Kalman Filter</head><p>When no gaussianness is assumed on the previous random errors ui, ui, and wi, the Kalman filter equations provide the best (minimum variance) linear unbiased estimate of a . This means that among the estimators which seek ak as a linear combination of the measurements (yi}, it is the one which minimizes the expected error norm squared while verifying</p><p>The recursive equations of the Kalman filter which provide a new estimate (cij, Si&gt; of a from (cii-I , Si-I &gt; are as follows 1231:</p><p>or equivalently One can see that the previously estimated parameter hi_ is corrected by an amount proportional to the current error yi -Mihi-I called the innovation. The proportionality factor Ki is called the Kalman gain. At the end of the process, Bk is the final estimate and Sk represents the covariance of the estimation error</p><formula xml:id="formula_2">s k = l!?[(f?k -a)( bk -a ) ' 1.</formula><p>The recursive process is initialized by 60, an initial estimate of a, and So, its error covariance matrix. Actually, the criterion minimized by the final estimate &amp; is It is interesting to note that the first term of 110) measures the squared distance of a from an initial estimate, weighted by its covariance matrix, while the second term is nothing else but the classical least square criterion, i.e., the sum of the squared measurement errors weighted by the covariance matrices.</p><p>Indeed, initializing the process with an arbitrary io and S i ' = 0, criterion (10) provides the classical least square estimate Cik obtained from the measurements only, while the initial estimate does not play any role.</p><p>The enormous advantage of such a recursive solution is that if we decide, after a set of k measurements (a,}, to stop the measures, we only have to keep 6 k and $k as the whole memory of the measurement process. If we decide later to take into account additional measurements, we simple have to initialize Bocik and Sos k and to process the new measurements to obtain exactly the same solution as if we had processed all the measurements together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Gaussian Assumption</head><p>Up to now, we did not introduce any Gaussian assumptions on the random measurement errors U, = x, -f, of ( 2 ) and on the prior estimate error WO = a -60 of ( 3 ) . However, in practice, these errors usually come from a sum of independent random processes, which tend toward a Gaussian procebs (Central Limit theorem). If we actually identify U, and wo with Gaussian processes, i.e., then, it follows that the noise ui in (5) is also Gaussian, i.e.. and that all the successive estimates provided by the recursive Kalman filter are also Gaussian, with mean a and covariance s k Moreover, in this case, the Kalman filter provides the best (minimum variance) unbiased estimate i k among all, even nonlinear, filters. This estimate hk is also the maximum likelihood estimator of a. This comes from the fact that in the Gaussian case, the solution is the conditional mean hk = E [ a / y l , . . ., yk] which both minimizes the variance and maximizes the likelihood while being expressed as a linear combination of the measurements y ( . Therefore, in this case, the minimum variance and minimum variance linear estimates are the same; namely, the estimate 6 k provided by the Kalman filter [23].</p><p>In conclusion, in the Gaussian case, the Kalman filter provides the best estimate with the advantage of preserving gaussianness of all the implied random variables, which means that no information on the probability density functions of the parameters is lost while keeping only their mean and covariance matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E, Rejecting Outlier Measurements</head><p>At iteration i, we have an estimate BiPl and an attached covariance matrix Si-for parameter a. We also have a noisy measurement (i,, A i ) of xi and we want to test the plausibility of this measurement with respect to the equationf,(x;, a) = 0.</p><p>If we consider again a first-order expansion of fi(x;, a) around (i,, riiP ,) (4), considering that (i; -xi) and (2;-1 -U) are independent centered Gaussian processes, we see that f,(i,, hl-1 ) is also (up to a linear approximation) a centered Gaussian process whose mean and covariance are given by</p><formula xml:id="formula_3">E [ f i ( i ; , 6;-,)I = 0 A A A h</formula><p>Therefore, if the rank of Q; is q, the generalized Mahalanobis distance</p><formula xml:id="formula_4">d ( i l 3 i,-i)=[f,(ai, &amp; ~) l ' Q , ~~[ f i ( ~; , Bi-i)]<label>(11)</label></formula><p>has a x 2 distribution with q degrees of freedom.' Looking at a x 2 distribution table, it is therefore possible to reject an outlier measurement Pi at a 95-percent confidence rate by setting an appropriate threshold E on the Mahalanobis distance, and by keeping only those measurements i ; which verify</p><formula xml:id="formula_5">d ( i ; , &amp; 1) &lt; E . (<label>12</label></formula><formula xml:id="formula_6">)</formula><p>We shall see in the experimental section at the end of this paper how this formalism can be used in practice, and how well it fits with reality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. GEOMETRIC REPRESENTATIONS</head><p>In this section, we give the details of the geometric representations that we have found useful at various stages of our work. It is first important to note that we have been dealing so far only with points, lines, and planes, i.e., with affine geometric entities. This may appear to be quite a restriction on the type of environments that we can cope with. This is indeed the case but there are a number of reasons why we think that our approach is quite reasonable.</p><p>1) The obvious one is that for the kind of environment that our mobile robot moves into, these primitives are very likely to cover most of the geometric features of importance.</p><p>2) A second reason is that more complicated curved features can be first approximated with affine primitives which are then grouped into more complicated nonaffine primitives.</p><p>3) A third reason is that we believe that the techniques we have developed for representing and combining uncertainty of If q &lt; p = the size of the measurement vector f,, e,-' is the pseudoinverse of Q!. Let us now discuss specifically lines, planes, and rigid displacements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Line Segments</head><p>The 3-D segments that we deal with are usually constructed from stereo [4], [94. Their endpoints may be quite unreliable, even though they can be of some use from time to time, and we largely depend on the infinite lines supporting those line segments.</p><p>We concentrate here on how to represent 3-D lines. The obvious representation we mention here only for pedagogical reasons, is by two points; this representation is six-dimensional and, as we will see next, not minimal. Another way to represent a line is to choose a point on it (three parameters), and a unit vector defining its direction (two parameters). The corresponding representation is five-dimensional and, again, not minimal. In fact, the set of affine 3-D lines is a manifold of dimension 4 for which we will exhibit later an atlas of class C". This implies that a minimal representation of a straight line has four parameters.</p><p>One such representation can be obtained by considering the normal to the line from the origin (if the line goes through the origin it is the same as a vector line and can be defined by two parameters only). The point of intersection between the normal and the line is representecE by three parameters. If we now consider (see Fig. <ref type="figure" target="#fig_6">11</ref>) the plane normal at P to OP, the line is in that plane and can be defined by one more parameter, its angle with an arbitrary direction, for example, the line defined by P, and one of the axis of coordinates (in Fig. <ref type="figure" target="#fig_6">11</ref>, the z axis). Of course, when the line is parallel to the xy plane this direction is not defined and we must use either the x or the y axis. This brings up an interesting point, namely, that a global minimal representation for affine lines, i.e., one which can be used for all such lines, does not exist. We must choose the representation as a function of the line orientation. Mathematically, this means that the manifold of the affine straight lines cannot be defined with only one map. This is quite common and is also true for affine planes and rotations of R 3, as will be shown next.</p><p>The previous representation for a line is not in fact the one Grossly speaking, a manifold of dimension d is a set that can be defined locally by d parameters. When the functions that transform one set of parameters into another are p times differentiable, the manifold is said to be of class C P . For more details, see <ref type="bibr">[14]</ref>. we have been using. In effect, the parameters involved in the previous representation are usually combined in a highly nonlinear manner in the measurement equations expressing geometric relationships between geometric entities (cf. next section), which is not good for the extended Kalman filtering approach. Also, the angular parameter must be assigned some fixed bounds (for instance IO, IT[), which might cause some problems during a recursive evaluation with the Kalman filter. This latter constraint also appears in the representation recently proposed by Roberts <ref type="bibr">[31]</ref>.</p><p>Therefore, we prefer the following representation in which the retained parameters are usually combined linearly in the measurement equations, and are not constrained to any bounded interval. This representation considers a line (not perpendicular to the z axis) as the intersection of a plane parallel to the y axis, and a plane parallel to the x axis x=az+p Each representation defines a one-to-one mapping between R 4 and a subset (in fact an open subset) of the set of affine 3-D lines and it can be shown that these three mappings define on this set a structure of C" manifold for which they form an atlas. In practice, this means the representation is not exactly four-dimensional, but is made of the four numbers a, b, p , and q and an integer i taking the values 1, 2 , and 3 to indicate which map 13, 14, or 15 we are currently using. The fact that the set of affine 3-D lines has been given a structure of C" manifold implies that the a ' , b ' , p ' , q' of a given representation are C" functions of the a , b, p , q of another representation for all lines for which the two representations are well defined (for example, all lines not parallel to the xy and yz planes). The representation of a line also includes a 4 x 4 covariance matrix A L on the vector L .</p><formula xml:id="formula_7">I y = bz + 4.</formula><p>It is interesting at this stage to trace the computation o f this covariance matrix all the way from pixel to 3-D. In order to do this, we must briefly explain how 3-D lines are computed in our current Stereo system <ref type="bibr">[9]</ref>. We use three cameras as indicated in Fig. <ref type="figure" target="#fig_9">13</ref>. In theory, the three planes defined by the 2-D lines 11, 12, and l3 and the optical centers C,, C?, and C, belong to the same pencil and intersect along the 3-D line L . In practice they do not because of noise, and we have to find the "best" line satisfying the measurements, i.e., <ref type="bibr">I , , 12, and 13.</ref> This can be done by using the idea of pencil of planes, described more fully in <ref type="bibr">[21]</ref>. We assume that in the Coordinate system attached to camera 1, for example, the equation of the ith plane Pi, i = 1, 2 , 3, is given by ujx+ ujy+ wiz + T I = 0 where the three four-vectors Pj = [ui, U , , w,, r,] I'are known, as well as their covariance matrix A p , (we show later how to compute them). If we use representation (13) for the 3-D line, it is represented as the intersection of the two planes P of the equation x = az + p and Q of the equation y = bz + q.</p><p>Writing that the five planes P , Q, and PI, i = 1, 2, 3, form a pencil allows us to write six equations w,+ aui+ bv, = 0, r-[ spuj + qu, = 0, i = 1, 2, 3 in the four unknowns a, b, p , and 4.</p><p>We can apply directly the Kalman formalism to these measurement equations and choose a = [a, 6 , p , q ] ', and x, as the four-vector Pi. We can therefore simply compute an estimate 2 of a and its covariance matrix Ai from the Pi's and Let us now show how we can compute the Pi's and Apl's. a set of edge pixels which have been detected using a modified version of the Canny edge detector [13], <ref type="bibr">[17]</ref>. Looking at Fig. <ref type="figure" target="#fig_22">14</ref>, let x cos 0 + y sin 0p = 0 be the equation of the line 1 which is fit to the edge pixels mi of coordinates x;, y;, (0 5 0 &lt; 2a, p 2 0). We assume that the measured edge pixels are independent and corrupted by a gaussian isotropic noise and take the parameter a equal to [e, p ] and the measurement x as the vector [x, yI7. The measurement equation is therefore f ( x , a ) = x cos 0+y sin 0 -p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Each line I,, i</head><p>Applying the EKF formalism to the n-edge pixels forming the line provides the best estimate Ci of the line parameters and its covariance matrix. Having done this for all three cameras, it is easy to deduce the equations of the three planes Pi and the covariance matrices on their coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Planes</head><p>Planes can receive pretty much the same treatment as lines. A plane is defined by three parameters, and this is minimal. A possible representation is the representation by the normal fi (a unit norm vector), and the distance d to the origin. The problem with this representation is that it is not unique since ( -n, -d ) represents the same plane. it is possible to fix that problem by assuming that one component of n, say n,, is positive, i.e., we consider planes not parallel to the z axis. For these planes we must choose another convention, for example, that n, is positive. Again, this works well for planes not parallel to the x axis. The third possible representation is to assume ny positive which excludes planes parallel to they axis. p 2 (respectively, p 3 ) excludes planes to the x axis (respectively, the y axis). It is easy to show that p l , p2, p 3 also define on the set of 3-D planes a structure of C" manifold of dimension 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Rigid Displacements</head><p>In a previous paper [4], [6] we have proposed the use of the exponential representation of rotations. This is the same as saying that a rotation is defined by its axis U (a unit vector) and its angle 8. The vector Y = 0u can be used to represent the rotation and we have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R = e H</head><p>where H is an antisymmetric matrix representing the cross product with the vector r (i.e., Hx = r x x, for all x). In this case, the rotation is represented by the three coordinates of r, i.e., by three independent numbers. There are several other possible representations for rotations, the most widely known being the one with orthogonal matrices or quaternions. Their main disadvantage is that an orthogonal matrix is defined by nine numbers subject to six quadratic constraints, whereas a quaternion is defined by four numbers subject to one quadratic constraint. These constraints are not easy to deal with in the EKF formalism and, moreover, these two representations are more costly than the exponential one.</p><p>Let us see how we can define a structure of manifold on the set of rotations using this representation. if we allow 0 to vary over the semi-open interval [0, 27r[, the vector r can vary in the open ball B(0, 27r) of R 3 of radius 2a. But the mapping) B(0, 27r) into the set of rotations is not one to one because (U, 7r) and ( -U , 7r) represent the same rotation. To enforce uniqueness we can assume that one of the coordinates, for example U,, of the rotation axis U is positive. We can then represent uniquely the open subset of the set of rotations for which the axis is not perpendicular to the z axis, and has a positive component along the axis, and the mapping is continuous. If we consider the open set of rotations defined by (U, e), U, &lt; 0, we have another one-to-one continuous mapping. With these two mappings, we cannot represent rotations with an axis perpendicular to the z axis. In order to obtain all possible rotations, we have to introduce the other four mappings defined by (U, 0) and U, &gt; 0 (respectively, U, &lt; 0, uy &gt; 0, U, &lt; 0) which represent rotations with an axis not perpendicular to the x axis (respectively, the y axis). We are sill missing the null vector, i.e., we have no representation for the null rotation, the identity matrix. In order to include it, we have to add a seventh map by considering for example the rotations defined by the "small" open ball B(0, E ) where E must be smaller than R . These seven mappings define on the set of rotations a structure of C" manifold of dimension 3.4</p><p>It is interesting that in all three cases (3-D lines, planes, and rotations), unique global representation does not exist and that we must deal with at least three local mappings.</p><p>It is now instructive to study how the group of rigid displacements operates on the representations for lines and planes. where m = [a, b, 1]*, and the Ti's are the row vectors of matrix R . This is true only if r 3 -m # 0; if r 3 * m = 0 , the transformed line is perpendicular to the z axis and representation ( <ref type="formula">14</ref>) or ( <ref type="formula">15</ref>) must be used.</p><p>To treat the case of p and q, let us introduce P = p(z2 -</p><formula xml:id="formula_8">21) = pC and Q = q(z2 -zl) = qC. It is easy to show that [E] = [ p i1 :] OM1 x OM2= H(OMl x OM,).</formula><p>This allows us to study how P and Q change under rotation and translation</p><p>Therefore</p><formula xml:id="formula_9">[E] --* [ E:] = H(R(OMl x OM2) + t x R M1M2).</formula><p>Using the previous notations, M,M2 = [ A , B , C]', and OM1 x OM2 = [ Q , -P , X I t where X is unknown. But</p><p>In <ref type="bibr">[lo]</ref> and <ref type="bibr">[ll]</ref> one can find an atlas of rotations with only four maps.</p><p>noticing that M 1 M 2 . ( <ref type="formula">0</ref> </p><formula xml:id="formula_10">H(Rp + t x R m )<label>1</label></formula><p>where we have taken p = [ q , -p , bpu q ] '.</p><p>2) Applying Rigid Displacements to Planes: Given a plane represented by its normal n and its distance to the origin d , if we apply to it a rotation along an axis going through the origin represented by a matrix R followed by a translation represented by a vector t , the new plane is represented by Rn and dt. <ref type="bibr">Rn [20]</ref>.</p><p>This allows us to compute how the representation (16). for example, is transformed by the rigid displacement. From the previous observation:</p><formula xml:id="formula_11">( % i -R ( % )</formula><p>and c -c -t ' R b .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i:li</head><p>Introducing the three row vectors r , , rz, r3 of inatrix R , we have, assuming that r3.m # 0.</p><formula xml:id="formula_12">e -t . Rm rl m r2 . m r3 . m 7 3 . m r3 . m a' =- b' =- c 1 = if r3.m = 0</formula><p>, this means that we cannot use the same representation for the transformed plane since it is parallel to the z axis, therefore, we must choose the representation (17)</p><p>or (18).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. REGISTRATION, MOTION, AND FUSIOW OF VISUAL MAPS</head><p>In this section we show how to solve the problems iisted in Section I1 within the formalism and the representations detailed in Sections 111 and IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Initial Assumptions</head><p>We are given two visual maps V and T", each of them attached to a coordinate reference frame 5 and 3 ' (see Fig. <ref type="figure" target="#fig_22">15</ref>). Each visual map V is composed of primitives.@, described by a parameter vector P. We have an estimate Po of P and an error covariance matrix Wfo.</p><p>The coordinate frames 5 and 5' are related by a rigid displacement 9 such that each point M' of 5 ' is related to a point M of 5 by the relation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O'M' = R OM+ t</head><p>where R is the rotation matrix and t the translatjon vector of the displacement 9. We also have an estimate Do of D, with an error covariance matrix Woo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Defining Geometric Relations</head><p>We define a set of geometric relations between the primitive 6 and 6 ' of two visual maps V and V ' . These relations are given in Table <ref type="table">I</ref>.</p><p>The list of relations/primitives is not exhaustive but only demonstrative. The relation "identical" expresses the fact that the primitives 6 and 6 ' represented in V and V ' actually describe the same physical primitive. The relation "included" expresses that 6 describes a physical primitive which is part of the physical primitive described by 6 '. The relations "parallel" and "orthogonal" are interpreted in a similar fashion.</p><p>Each geometric relation can be expressed by a vector equation of the form ! f i ( P , P', D)=O.</p><p>(19)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Expressing Geometric Relations</head><p>We rewrite (19) for the geometric relations of Table <ref type="table">I</ref>. We denote by P the parameters of the primitive 3 = D ( 6 ) , the image of 6 by the rigid displacement D . The computation of P from P is, in the case of points, = R OM + t. The case of lines and planes was detailed in the previous section. The measurement equations are as follows:</p><p>Point-Point:</p><formula xml:id="formula_13">relation = : O ' M ' -OM= 0.</formula><p>Point-Line: assuming the line is not orthogonal to the z axis:</p><p>Point-Plane: assuming the plane is not parallel to the z axis: This approach should be compared to that of <ref type="bibr">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Registration I ) Principle:</head><p>The registration (or matching) of two primitives 6 and 6 ' consists in detecting that their parameters P and P' verify <ref type="bibr">(19)</ref> for one of the above listed geometric relations, with respect to the current noisy estimates (Po, Wp,), (si, Wpd), and (Do, WDo) of P , P ' , and D .</p><p>This "detection" is done by computing between each pair of primitive the generalized Mahalanohis distance given by ( 1 l), and by matching a pair of primitives each time the x 2 acceptance test given by inequality (12) is verified, i.e., when</p><p>2) Reliability: The above-described registration procedure detects what would be called plausible matches between geometric primitives. When the uncertainty attached to the primitives parameters is large, it may happen that a plausible match is false. In order to improve the reliability of the procedure, one can use a strategy (inspired by [16]) which starts by registrating primitives whose parameters have a small covariance matrix, or primitives which can be matched <ref type="figure">d(Po,</ref><ref type="figure">Wp0,</ref><ref type="figure">S ;</ref><ref type="figure">,</ref><ref type="figure">W P ~,</ref><ref type="figure">D o ,</ref><ref type="figure">WD,</ref><ref type="figure">J&lt;E.</ref> unambiguously. Such a strategy is exemplified in the experimental results section of this paper and also in another paper</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI.</head><p>3) Efficiency: In order to avoid a O(n2) complexity algorithm, it is of course possible to use additional control structures to select a subset of candidate primitives for each test. For instance, to test the relation " = " between points or lines, bucketing techniques can be used with efficiency (see for instance <ref type="bibr">[I]</ref>, <ref type="bibr">[7]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Motion</head><p>Having registered two primitives 6 and 6 ', the motion problem consists in reducing the uncertainty on the motion parameters D while taking into account the uncertainty on the parameters P , P' , and D.</p><p>This is done by setting a = D and x = (P, P ' ) * , and by using the relation equation ( <ref type="formula">19</ref>) as a measurement equation ( <ref type="formula" target="#formula_10">1</ref> This process is recursively repeated: at iteration i, if a new pair of primitives can be registered with the new motion estimate (6;-Si-), the additional measurement equations they bring lead to a new better estimate 2; of the motion with a still reduced covariance matrix Si. This process ends after the matching of k primitives with a final estimate (&amp;, Sk) of the 1 motion parameter D .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Fusion I ) General Fusion:</head><p>The fusion problem is exactly the dual of the motion problem, as it consists, after the registration of two primitives, in reducing the uncertainty on the primitive parameters P and P' while taking into account the uncertainty on the parameters P , P ' , and D . This is done by "switching the attention," i.e., by choosing a = (P, P I ) * and x = D while using again the relation equation ( <ref type="formula">19</ref>) as a measurement equation (1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J(x, U ) = fi(D, ( P , P'))=O.</head><p>The initial estimate is taken as 4 = (Po, Pi)' and and one uses the measurement fl = Bo with Wl = WDo to apply the EKF formalism and obtain a new estimate ril of the primitive parameters with a reduced covariance matrix SI &lt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SO.</head><p>If additional relations hold between these primitives and other ones, the same treatment allows for a further reduction in their parameters uncertainty, and therefore a more accurate estimation of the primitive parameters.</p><p>2) Forgetting Primitives: After the treatment of a constraint, the parameters P1 and P ; of the primitives are usually correlated, which means that the covariance matrix contains wP; p1 = wfPlpi z 0.</p><p>Therefore, it is no longer possible to treat independently 6 and 6 ' in successive measurement equations. One has to consider them as a new primitive, either by keeping only one of them, or the union of them.</p><p>For instance if one updates the parameters of 6 ' with those of an "identical" primitive 6 observed in a previous visual map, one keeps only the updated parameters of 6 ' in the new map, with their covariance matrix Wp,, forgetting the previous parameters 6 after having used them.</p><p>On the other hand, if one updates the parameters of two lines by detecting that they are orthogonal, one keeps the new primitive formed by the union of the updated two lines, with the corresponding covariance matrix. One must use this kind of relation carefully, in order to control the size of the state parameter a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Autofusion:</head><p>In the special case where V = V ', all primitives come from the same visual map, and the motion parameters vanish as they correspond to the identity transform and are perfectly known.</p><p>Nevertheless, one can still detect the previous geometric relations between pairs of primitives 6 and 6 ' , and use them to reduce the uncertainty on the primitives parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTAL RESULTS</head><p>The basic principles presented in this paper were tested on a variety of iynthetic and real data. The interested reader can find registration and motion results with real points and lines in [3], registration and fusion results with synthetic and real points and lines in [2], and results on the building of global 3-D maps from passive stereovision in [9]. In this paper we only present results of the motion estimation from two 3-D maps from passive stereovision in <ref type="bibr">[9]</ref>. In this paper we only present results of the motion estimation from two 3-D maps, the fusion of several inaccurate 3-D maps, and the detection of colinearity within a single 3-D map (what we called "autofusion"). In each of these examples, the 3-D map is made of 3-D lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A . Registration and Motion</head><p>Fig. <ref type="figure" target="#fig_18">16</ref> shows the edges of a triplet of images taken by the mobile robot in a first position. From these edges, the trinocular stereovision system computes a set of 3-D segments. Each 3-D segment is represented by the parameters (a, b, p , q) of the 3-D line supporting it and by the error covariance computed-as explained in Section IV-B-from the uncertainty on the edge points in the three images (we took an isotropic Gaussian density function of covariance 1 pixel around each edge point). Each 3-D line is bounded by two endpoints obtained from the endpoints measured in the three images which are projected on the reconstructed 3-D line.  We show in Figs. 17 and 18, respectively, the horizontal and vertical projections of the reconstructed 3-D segments. We also show the uncertainty attached to the reconstructed 3-D lines by showing the uncertainty it produces on the coordinates of their endpoints. The 95-percent confidence regions of the endpoints positions are ellipsoids whose projections are the ellipses shown in Figs. 17 and 18. One can see the anisotropic distribution of the uncertainty on the three coordinates of the points and its variation as a function of their position relative to the cameras (the projections of the three optical centers of the cameras correspond to the vertices of the triangle located grossly in the middle of the front view and at the bottom of the top view. Also, the circles around these vertices have been given an arbitrary radius of 20 cm to allow the reader to estimate the uncertainty attached to the other primitives).</p><p>The robot now moves a little, a new triplet of images is taken (Fig. <ref type="figure" target="#fig_20">19</ref>) and another set of 3-D lines is computed. Initially, the robot is given a very crude estimate of its motion between the two views. Applying this crude estimate to the 3- We now ask the system to discover the relation " E " between the 3-D lines (see Section V-C) reconstructed in position 1 and 2 , given the initial crude motion estimate and its uncertainty. The program takes each 3-D line in position 1, applies the noisy current motion estimate to place it in the 3-D map obtained in position 2 with a new covariance matrix (combining the initial uncertainty with the motion uncertainty), and computes its Mahalanobis distance (1 1) to all the other lines of position 2 (see Section V-D).</p><p>The program detects a match each time a pair of lines passes the x2 test of (12). If a line in position 1 can be matched to several lines in position 2, this is an ambiguous match, and nothing is done. On the other hand, each time an unambiguous match is found, the parameters of the motion are updated  as it is explained in Section V-E. As the uncertainty on motion decreases after each new match, some previously ambiguous matches can now become unambiguous. Therefore, the entire matching process is repeated until no more lines can be matched (three iterations in this example). The final estimate of the motion is very accurate as can be seen in Fig. <ref type="figure" target="#fig_22">21</ref> where the obtained superimposition is now almost perfect.</p><p>Applying exactly the same technique to a set of six triplets of views taken during the motion of the robot (Figs. 22-27), the system was able to build a global 3-D map of the room shown in Fig. <ref type="figure" target="#fig_3">28</ref> where rotating segments at the bottom right are the computed successive robot positions. Fig. <ref type="figure">29</ref> gives a hand sketched semantic interpretation of this global map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Registration, Motion, and Fusion</head><p>In this experiment, the robot is looking from four different positions at a regular pattern (Figs. <ref type="figure">30</ref> and<ref type="figure" target="#fig_22">31</ref>) formed by vertical lines floating in front of horizontal lines, and builds in each position a local 3-D map. Exactly the same technique as in the previous example was used to register each successive    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Detecting Colinearity in Space</head><p>In this experiment. the robot is looking at the regular pattern only once. We show in Fig. <ref type="figure" target="#fig_2">34</ref> the vertical and horizontal projections of the initially reconstructed 3-D segments. We also show in Fig. <ref type="figure">35</ref> the uncertainty attached to reconstructed 3-D lines by showing the uncertainty it produces on the  coordinates of their endpoints (in the same way as in the first VII. CONCLUSION experiment).</p><p>We now ask the system to discover the relation "E" between the 3-D lines (see Section V-C). The program takes a first 3-D line, computes its Mahalanobis distance (1 1) to all the other lines of the scene, and accepts the first line which passes the x 2 test of (12) (see Section V-D). The two lines are fused using the technique of Section V-F and one keeps only the parameters of the optimal line representing both of them with an updated covariance matrix. The remaining lines are now compared to this new virtual line still with the Mahalanobis distance of (1 1) but with the new updated covariance matrix, while the x 2 test of (12) remains unchanged. This process is repeated until no more lines can be matched with the first one, and then repeated with all the remaining unmatched lines.</p><p>The result is a reduced set of virtual lines on which the endpoints of the original segments have been projected, as shown in Fig. <ref type="figure" target="#fig_4">36</ref>. The uncertainty on the line parameters has been greatly reduced: Fig. <ref type="figure">37</ref> shows the resulting uncertainty on the lines endpoints, which agrees very well with the reality.</p><p>In this paper we have proposed a methodology for building and maintaining a geometric representation of the environment of a mobile robot. This methodology has the following salient features:</p><p>Representation: 1) We use geometric primitives to describe the environment and rigid displacements to describe the motion. These entities are described with a minimal number of parameters. 2 ) Uncertainty is modeled by a probability density function of these parameters. 3 ) Relationships between geometric entities are represented by algebraic equations on their parameters.</p><p>Algorithms: detecting geometric relationships, computing or updating the parameters of geometric entities (both for primitives and displacements) is done by recursive predictionand-verification algorithms including the Extended Kalman Filter. These algorithms, better detailed in [8], <ref type="bibr">[lo]</ref>, and [ 1 1 1. take into account prior knowledge to compute and propagate uncertainties.</p><p>Finally, the experimental results showed that the major approximations we made (linearization of the algebraic equations, second-order approximation of the probability density functions) were valid in a number of practical cases. Of course, a lot of theoritical and experimental work is still necessary to extend the approach to a wider class of problems for which such approximations cannot be made. This might be a good direction for future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Effect of pixel noise on 3-D reconstruction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Effect of calibration errors on 3-D reconstruction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 7. Improving the estimation of the points position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Fusing n points measured from different positions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Measuring a point in two positions (displacement and uncertainty estimation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>n 807 Fig. 9 .</head><label>8079</label><figDesc>Fig. 9. Discovering that AB and CD are parallel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. A possible 3-D line representation affine primitives are generic and directly applicable to nonaffine primitives.Let us now discuss specifically lines, planes, and rigid displacements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Fig. 12. A better 3-D line representation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>The intersection is represented by the four-dimensional vector L = [a, b, p , qIT which has the following geometric interpretation (see Fig.12): The direction of the line is that of the vector [a, b, 11 T , and the point of intersection of the line with the xy plane has coordinates p and q. Since the last coordinate of the direction vector is equal to 1, the line cannot be perpendicular to the z axis or parallel to the xy plane. If we want, and we do in practice, represent such lines, we must choose another representation, for example y=ax+p I z=bx+q which cannot represent lines parallel to the yz plane, or perpendicular to the x axis, or (15) z=ay+p I x=by+q which excludes lines parallel to the zx plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Reconstruction of 3-D line5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Fig. 14. 2-D line approximation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>So, we have three one-to-one mappings of open subsets of the product S, x R , where S2 is the usual Gaussian sphere into open subsets of the set of planes (n, d ) , nz &gt; 0planes not parallel to Oz (n, d ) , n,&gt;O+planes not parallel to Ox (n, d ) , n,&gt;O+planes not parallel to Or.It is easy to show that these three mappings define on the set of 3-D planes a structure of C" manifold of dimension 3.One practical disadvantage of the previous representations is that the normal n is constrained to lie on the unit sphere S2, i.e., it must satisfy the constraint linll = 1. A possibly simpler representation is obtained by considering the mapping from R to the set of 3-D planes defined byp 1 : (a, b, c)+ax+by+z+c=O. (16)This can represent all planes except those parallel of Oz and it is a one-to-one continuous mapping from R to the open subset of the set of 3-D planes constituted of the planes not parallel to the z axis. In order to obtain all possible planes,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>p2 : (a, b, c)+x+ay+bz+c=O p 3 : (a, b, c)+bx+y+az+c=O.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>1)</head><label></label><figDesc>Applying Rigid Displacement to Lines: The easiest way to derive how representation (13) changes under rotation and translation is by considering that the line is defined by two points M I and M2 of coordinates ( x l , y l , zl) and ( X Z , ~2 , 2 2 1 . It is then easy to verify that Introducing the vector M1M2 = [ A , B , CIT, we have a = A / C , and b = B/C. a and b are therefore only sensitive to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>C</head><label></label><figDesc>M 1 x OM,) = 0 we have A Q -BP + CX = 0 is not equal to 0 since by definition, the line is not perpendicular to the z axis. Putting everything together Finally and we know from the previous derivation that C / C ' = 1 /r3 * M , therefore</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>DFig</head><label></label><figDesc>Fig. 15. The general registration motion fusion problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>relation c: a'.f+b'Y+Z+c'=O. Line-Line: assuming the two lines are not orthogonal to the z axis: relation =: (a', b', c', d')'--(d, 6 , C, d)'=O relation 11: (a', b ' ) t -( d , 6)'=0 relation I: a'd+b'6+1=0. Line-Plane: assuming the line is not orthogonal and the plane not parallel to the z axis: a'd+ b'6+ 1 = O I alp+ b'g+ c' = O relation C : relation 11: a'd+b'6+1=0 . relation i: (a', b')'-(a, 6)'=0. Plane-Plane: assuming the plane is not parallel to the z axis: relation =: (a', b ' , c')~--(@, 6, c ) ' = O relation 11: (a', b o ' -( &amp; 6)'=0 relation I: a'd+b'6+1=0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>) fi(x, a ) = fi((P, P ' ) , D)=O. using the measurement f l = (Po, P A )*) with Starting from the initial estimate li0 = Bo, So = WDo, and one applies the EKF formalism to obtain a new estimate iil of the motion with a reduced covariance matrix SI &lt; So. (In the sense SO -SI is nonnegative).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Triplet of images taken in position 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Top view of reconstructed 3-D lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Triplet of images taken in position 2. D lines obtained in position 1, and projecting them in one of the images obtained in position 2 (the image of camera 3), one obtains the crude superimposition observed in Fig. 20. Solid lines are the transformed 3-D segments computed in position 1, while the dotted lines are the 2-D segments observed in position 2.We now ask the system to discover the relation " E " between the 3-D lines (see Section V-C) reconstructed in position 1 and 2 , given the initial crude motion estimate and its uncertainty. The program takes each 3-D line in position 1, applies the noisy current motion estimate to place it in the 3-D map obtained in position 2 with a new covariance matrix (combining the initial uncertainty with the motion uncertainty), and computes its Mahalanobis distance (1 1) to all the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 2 1 .</head><label>1</label><figDesc>Fig. 2 1. Superimposition of 3-D segments of position I with 2-D edges of position 2 (final motion estimate).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 22 .</head><label>22</label><figDesc>Fig. 22. First triplet of laboratory images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. Second triplet of laboratory images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>local 3-D map, and put all of them in a single absolute reference frame. Fig.32shows the resulting 3-D map before fusion. Fusion is achieved by discovering the relation '' = " computed between lines in the global 3-D map. and taking into account the uncertainty on the 3-D lines due to their reconstruction and to the successive motion estimations. Fusion yields a reduction from 1808 to 650 segments and improves accuracy, as can be seen by looking at the front arid</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. Fourth triplet of laboratory images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 28 . 0 Fig. 29 .</head><label>28029</label><figDesc>Fig. 28. Top view of a global 3-D map of the room computed from six local 3-D maps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig. 31 .Fig. 32 .Fig. 34 .</head><label>313234</label><figDesc>Fig. 31. A regular grid observed from positions 3 and 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>is not reported in[24]. In the area of robust estimation procedures and models of sensors noise,Hager and Mintz 1221  and McKendall and Mintz [27]  have started to pave the ground. Bolle and Cooper [ 121 have developed maximum likelihood techniques to combine range data to estimate object positions. Darmon [I61 applies the Kalman filter formalism to the detection of moving objects in sequences of images. Durrant-Whyte [18], in his Ph.D. dissertation has conducted a thorough investigation of the problems posed by multi-sensory systems. Applications to the navigation of a mobile robot have been discussed by Crowley [!5], Smith and Cheeseman 1321.</figDesc><table><row><cell>Manuscript received April 5 , 1988; revised May 2, 1989. This work was</cell></row><row><cell>partially supported by the Esprit Project P940.</cell></row><row><cell>The authors are with INRIA-Rocquencourt, Domaine de Voluceau,</cell></row><row><cell>Rocquencourt, B. P. 105-78153, Le Chesney Cedex, France.</cell></row><row><cell>lEEE Log Number 8930460</cell></row></table><note><p>which</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>i In practice, we shall see that only an initial estimate (io, So) of a is required prior to the first measurement PI, while the next ones (2,, S,) are provided automatically by the Kalman filter itself.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors want to thank N. Caudechoux for her precious help in the preparation of this paper and the reviewers for their helpful comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building a consistent 3d representation of a mobile robot environment by combining multiple stereo views</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">0</forename><forename type="middle">D</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint ConJ on Artificial Intelligence</title>
		<meeting>Int. Joint ConJ on Artificial Intelligence<address><addrLine>Milano, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>~~</publisher>
			<date type="published" when="1986-01">Jan. 1986. Aug. 1987</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="44" to="54" />
		</imprint>
	</monogr>
	<note>Proc</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><surname>Int</surname></persName>
		</author>
		<author>
			<persName><surname>Conf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">on Computer Vision</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">June 1987. 1986</date>
			<biblScope unit="volume">596</biblScope>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maintaining representations of the environment of a mobile robot</title>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Robotics Research</title>
		<meeting><address><addrLine>Santa CNZ, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-08">Aug. 1987</date>
			<biblScope unit="page" from="337" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient registration of stereo images by matching graph descriptions of edge segments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faverjon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1987-04">Apr. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Building, registrating and fusing noisy visual maps</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">0</forename><forename type="middle">D</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robotics Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="45" to="65" />
			<date type="published" when="1988-12">Dec. 1988</date>
		</imprint>
	</monogr>
	<note>Special Issue on Sensor Data Fusion</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Matching depth maps obtained by passive stereovision</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">0 D</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><surname>Faverjon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Workshop on 121 131 IS</title>
		<meeting>3rd Workshop on 121 131 IS</meeting>
		<imprint>
			<biblScope unit="page">161</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m">Computer Vision: Representation and Control</title>
		<imprint>
			<date type="published" when="1985-10">Oct. 1985</date>
			<biblScope unit="page" from="197" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual navigation of a mobile robot</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">0 D</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><surname>Lustman</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Workshop on Intelligent Robors and Systems (IROS&apos;88</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-10">Oct. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast and reliable passive trinocular stereovision</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lustman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision</title>
		<meeting>Int. Conf. on Computer Vision<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date>June 19871</date>
			<biblScope unit="page" from="422" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Construction et fusion de representations visuelles tridimensionnelles: applications a la robotique mobile</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">These d&apos;Etat</title>
		<meeting><address><addrLine>Orsay</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-05">May 1988</date>
		</imprint>
		<respStmt>
			<orgName>Universite de Paris-Sud</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Vision Stereoscopique et Perception Multisensorielle-Application a la Robotique Mobile. Inter-Editions, 1989. English translation will be available from</title>
		<author>
			<persName><forename type="first">~-</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On optimally combining pieces of inlormation. with application to estimating 3D complex-object position Srom range data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Bolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Differential Geometry of Curves and Surfaces</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Carmo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs. NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Representation and maintenance of a composite surface model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Robotics and Automation</title>
		<meeting>Int. Conf. on Robotics and Automation<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986-04">Apr. 1986</date>
			<biblScope unit="page" from="1455" to="1462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A new recursive method to detect moving objects in a sequence of images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Darmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. on Pattern Recognition and Image Processing</title>
		<meeting>IEEE Conf. on Pattern Recognition and Image essing</meeting>
		<imprint>
			<date type="published" when="1982-06">June 1982</date>
			<biblScope unit="page" from="259" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using Canny&apos;s criteria to derive an optimal edge detector recursively implemented</title>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1987-04">Apr. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Consistent integration and propagation of disparate sensor observations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Durrant-Whyte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. h i . Conf. on Robotics and Automation</title>
		<meeting>h i . Conf. on Robotics and Automation<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986-04">Apr. 1986</date>
			<biblScope unit="page" from="1464" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Building visual maps by combining noisy stereo measurements</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName><surname>Faverjon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1201 1211 1221 1281 t291 Robotics and Automation</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986-04">1986. Apr. 1986</date>
			<biblScope unit="page" from="619" to="638" />
		</imprint>
	</monogr>
	<note>Proc. Int. Conf. on PAMl-8</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The representation, recognition, and locating of 3d objects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hcbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robotics Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="27" to="52" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Motion and structure from motion from point and line matches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Faugeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lustman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toscani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision</title>
		<meeting>Int. Conf. on Computer Vision<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-06">June 1987</date>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Estimation procedures for robust sensor control, in the integration of sensing with actuation to form a robust intelligent control system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><surname>Mintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dep. Comput. Informat. Sci</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<date type="published" when="1987-03">Mar. 1987</date>
			<publisher>Moore School of Elec. Eng. Univ. of Pennsylvania</publisher>
		</imprint>
	</monogr>
	<note>GRASPLAB Rep.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Jazwinsky</surname></persName>
		</author>
		<title level="m">Stochastic Processes and Filtering Theory</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A mobile robot: Sensing, planning, and locomotion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Triendl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">0</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Robotics and Automation</title>
		<meeting>Int. Conf. on Robotics and Automation<address><addrLine>New York, NY; Raleigh, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987. 1987</date>
			<biblScope unit="page" from="402" to="408" />
		</imprint>
	</monogr>
	<note>Three-Dimensional Machine Vision</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Models of sensor noise and optimal algorithms for estimation and quantization in vision systems</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Mikhail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dep. Comput. Informat. Sci</title>
		<imprint>
			<date type="published" when="1976-03">1976. Mar. 1987</date>
			<publisher>Moore School of Elec. Eng., Univ. of Pennsylvania</publisher>
		</imprint>
	</monogr>
	<note type="report_type">GRAS-PLAB Rep. 97</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reasoning about 3-d space with algebraic deduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Matthies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Shafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mundy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics Research, The Third International Symposium</title>
		<editor>
			<persName><forename type="first">.</forename><forename type="middle">D</forename><surname>Faugeras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Giralt</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986">1987. 1986</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
	<note>Error modelling in stereo navigation</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Optimal combination and constraints for geometrical sensor data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Porrill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987-03">Mar. 1987</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A new representation for a line</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision and Pattern Recognition</title>
		<meeting>Int. Conf. on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="635" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the representation and estimation of spatial uncertainty</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheeseman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robotics Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1433" to="1438" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
