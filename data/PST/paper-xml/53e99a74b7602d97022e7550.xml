<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scale factor local search in differential evolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-02-10">10 February 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ferrante</forename><surname>Neri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Information Technology</orgName>
								<orgName type="institution">Agora University of Jyväskylä</orgName>
								<address>
									<postCode>40014</postCode>
									<settlement>Jyväskylä</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Information Technology</orgName>
								<orgName type="institution">Agora University of Jyväskylä</orgName>
								<address>
									<postCode>40014</postCode>
									<settlement>Jyväskylä</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ville</forename><surname>Tirronen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Information Technology</orgName>
								<orgName type="institution">Agora University of Jyväskylä</orgName>
								<address>
									<postCode>40014</postCode>
									<settlement>Jyväskylä</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Information Technology</orgName>
								<orgName type="institution">Agora University of Jyväskylä</orgName>
								<address>
									<postCode>40014</postCode>
									<settlement>Jyväskylä</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scale factor local search in differential evolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-02-10">10 February 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">792FA79689E3696ADF20976FC1A99BD6</idno>
					<idno type="DOI">10.1007/s12293-009-0008-9</idno>
					<note type="submission">Received: 10 September 2008 / Accepted: 17 December 2008 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes the scale factor local search differential evolution (SFLSDE). The SFLSDE is a differential evolution (DE) based memetic algorithm which employs, within a self-adaptive scheme, two local search algorithms. These local search algorithms aim at detecting a value of the scale factor corresponding to an offspring with a high performance, while the generation is executed. The local search algorithms thus assist in the global search and generate offspring with high performance which are subsequently supposed to promote the generation of enhanced solutions within the evolutionary framework. Despite its simplicity, the proposed algorithm seems to have very good performance on various test problems. Numerical results are shown in order to justify the use of a double local search instead of a single search. In addition, the SFLSDE has been compared with a standard DE and three other modern DE based metaheuristic for a large and varied set of test problems. Numerical results are given for relatively low and high dimensional cases. A statistical analysis of the optimization results has been included in order to compare the results in terms of final solution detected and convergence speed. The efficiency of the proposed algorithm seems to be very high especially for large scale problems and complex fitness landscapes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since its earliest definition by Moscato and Norman <ref type="bibr" target="#b0">[1]</ref>, a memetic algorithm (MA) is perceived as a structure which combines stand alone elements that are supposed to constructively interact. This ideology, also referred to in <ref type="bibr" target="#b1">[2]</ref>, views the algorithmic structure as a composition of algorithmic components which are supposed to "compete and cooperate" in order to improve upon solutions and thus generate an efficient optimization process.</p><p>The concept of cooperation and competition in Memetic Computing has subsequently been developed and generalized when MAs containing many local searchers (multimeme algorithms) were proposed <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. In this context, in <ref type="bibr" target="#b4">[5]</ref> the term "Meta-Lamarckian learning" has been coined in order to indicate the adaptive coordination of the various local searchers which are supposed to harmonically compete and cooperate with each other. In addition, as explained in <ref type="bibr" target="#b5">[6]</ref>, a robust MA contains a list of local search algorithms which have various working mechanisms in order to allow exploration under complementary perspectives. A classification of algorithmic solutions to adaptively perform the coordination of the local search algorithms in a MA is given in <ref type="bibr" target="#b6">[7]</ref>.</p><p>Another topic strictly related to MA design is the preservation of diversity in the population of the solutions. In fact, the necessity of designing a MA comes from the poor performance, in some cases, of traditional metaheuristics. This poor performance is often due to a premature loss of the genotypic diversity and thus premature convergence or steady behavior of the diversity for many consecutive generations and thus stagnation. It is therefore fundamental to promote variation in the diversity values by applying various algorithmic components. Some techniques aiming at control of the diversity in MAs have been proposed <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. Also in the context of parallel MAs <ref type="bibr" target="#b12">[13]</ref>, the diversity seems to play a determinant 123 role, as explained in <ref type="bibr" target="#b13">[14]</ref>. Similarly, the successful functioning of a MA can be seen as a proper balance between global and local search as expressed in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Finally in <ref type="bibr" target="#b16">[17]</ref>, the use of both empirical experience and theoretical reasoning is recommended in order to design an efficient MA.</p><p>In summary, a successful MA is an algorithm composed of many various components which are harmonically coordinated by means of a proper balance between global and local search, thus ensuring a diversity dynamic which guarantees fast and efficient improvements in the search until detection of a solution with high performance.</p><p>Although these recommendations are undoubtedly useful, in practice they might be very hard to follow when the algorithmic implementation occurs. For example, the concept of "proper balance between global and local search" can significantly vary in its practical meaning dependant on the problem under analysis. In addition, the search for complex adaptive systems which perform the coordination of algorithmic components, e.g. in <ref type="bibr" target="#b9">[10]</ref>, can lead to algorithms which are extremely domain specific and thus very hard to export to other fields. This fact can obviously be seen as a practical consequence of the No Free Lunch Theorem <ref type="bibr" target="#b17">[18]</ref>: since the average performance of all possible optimization methods is the same over all possible optimization problems, a tailored algorithmic design must be performed in order to obtain high performance results in a specific application domain.</p><p>Despite the validity and importance of the No Free Lunch Theorem, in this paper we propose an algorithm which aims at pushing towards the outer limit of this theorem. In other words, we propose an algorithm which combines robustness and high performance on a various set of optimization problems. In a sense, the algorithm proposed in this paper can be seen as a continuation of the work described in <ref type="bibr" target="#b18">[19]</ref> which was already proven to have a high performance for diverse applications and test problems.</p><p>In order to pursue this aim, this article proposes an algorithm based on fairly simple working principles. We propose an evolutionary framework in the fashion of the differential evolution (DE) with some randomization in the parameter setting inspired by the approach described in <ref type="bibr" target="#b19">[20]</ref>. The choice of the DE is due to its reliability and versatility in continuous space <ref type="bibr" target="#b20">[21]</ref>. In addition, the proposed algorithm makes use of two simple local search algorithms, a golden search and a hill-climber, activated by a randomized and deterministic criterion respectively. One novelty in the proposed approach is that local search is integrated within the move operators and in particular within choice of the scale factor during the mutation move. This choice can be seen as a natural countermeasure to the stagnation problems which the Differential Evolution is subject to <ref type="bibr" target="#b21">[22]</ref>.</p><p>This paper is organized in the following way: Sect. 2 gives an extensive description of the DE and the enhancement recently proposed in literature. This section takes on the role of offering a compact survey on the topic and, at the same time introduces algorithms which will be used as a benchmark for the proposed algorithm. Section 3 gives a description of the proposed algorithms highlighting the working principles of each component and justifies the choices made regarding their coordination. Section 4 shows numerical results of the experiments carried out. A preliminary numerical test is given in order to justify the employment of two local search algorithms within the evolutionary framework. Subsequently, an in depth analysis of the algorithmic performance is carried out in order to compare the behavior of the proposed algorithm with four other differential evolution based metaheuristics. The numerical experiments have been carried out in both low and high dimensions. Section 5 gives the conclusion of the work carried out and mentions possible future developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Recent advances in differential evolution</head><p>In order to clarify notation used throughout this article we refer to the minimization problem of an objective function f (x), where x is a vector of n design variables in a decision space D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Differential evolution</head><p>According to its original definition given in <ref type="bibr" target="#b22">[23]</ref>, the DE consists of the following steps. An initial sampling of S pop individuals is executed pseudo-randomly with a uniform distribution function within the decision space D. At each generation, for each individual x i of the S pop available, three individuals x r , x s and x t are pseudo-randomly extracted from the population. According to DE logic, a provisional offspring x off is generated by mutation as:</p><formula xml:id="formula_0">x off = x t + F(x r -x s ) (1)</formula><p>where F ∈ [0, 1+[ is a scale factor which controls the length of the exploration vector (x rx s ) and thus determines how far from point x i the offspring should be generated. With F ∈ [0, 1 + [, it is here meant that the scale factor should be a positive value which cannot be much greater than 1, see <ref type="bibr" target="#b20">[21]</ref>. While there is no theoretical upper limit for F, effective values are rarely greater than 1.0. The mutation scheme shown in Eq. ( <ref type="formula" target="#formula_15">10</ref>) is also known as DE/rand/1. Other variants of the mutation rule have been subsequently proposed in literature <ref type="bibr" target="#b23">[24]</ref>:</p><formula xml:id="formula_1">DE/best/1 : x off = x best + F(x s -x t ) DE/cur-to-best/1 : x off =x i + F(x best -x i ) + F(x s -x t ) DE/best/2 : x off = x best + F(x s -x t ) + F(x u -x v ) DE/rand/2 : x off = x r + F(x s -x t ) + F(x u -x v ) , , , ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1 DE pseudocode</head><p>where x best is the solution with the best performance among the individuals of the population, x u and x v are two additional pseudo-randomly selected individuals. Then, to increase exploration, each gene of the new individual x off is switched with the corresponding gene of x i with a uniform probability C R ∈ [0, 1] and the final offspring x off is generated:</p><formula xml:id="formula_2">x off, j = x i, j if rand (0, 1) &lt; CR x off,j otherwise<label>(2)</label></formula><p>where rand(0, 1) is a random number between 0 and 1; j is the index of the gene under examination, from 1 to n, n the length of each individual. The resulting offspring x off is evaluated and, according to a steady-state strategy, it replaces x i if and only if f (x off ) &lt; f (x i ); otherwise no replacement occurs. For the sake of clarity, the pseudo-code highlighting working principles of the DE is shown in Fig. <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Parameter setting in differential evolution</head><p>As highlighted in <ref type="bibr" target="#b21">[22]</ref>, due to its inner structure, the DE is subject to stagnation problems. Stagnation is that undesired effect which occurs when a population based algorithm does not converge to a solution (even suboptimal) and the population diversity is still high. In the case of the DE, stagnation occurs when the algorithm does not manage to improve upon any solution of its population for a prolonged amount of generations.</p><p>In order to avoid this undesired effect, the moving operators of the DE must be properly set. In other words, for successful functioning of the DE, a proper setting of the population size and parameters F and CR (see Eqs. 2,10) must be performed. The population size, analogous to the other evolutionary algorithms (EAs), if too small could cause premature convergence and if too large could cause stagnation (see <ref type="bibr" target="#b24">[25]</ref>). A good value can be found by considering the dimensionality of the problem similar to what is commonly performed for the other EAs. A guideline is given in <ref type="bibr" target="#b25">[26]</ref> where a setting of S pop equal to ten times the dimensionality of the problem is proposed.</p><p>On the other hand, the setting of F and CR is neither an intuitive nor a straightforward task but is unfortunately crucial for guaranteeing algorithmic functioning. Several studies have thus been proposed in literature. The study reported in <ref type="bibr" target="#b21">[22]</ref> arrives at the conclusion, after an empirical analysis, that usage of F = 1 is not recommended, since according to a conjecture of the authors it leads to a significant decrease in explorative power. Analogously, the setting CR = 1 is also discouraged since it would dramatically decrease the amount of possible offspring solutions. In <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b26">[27]</ref> the settings F ∈ [0.5, 1] and CR ∈ [0.8, 1] are recommended. In <ref type="bibr" target="#b26">[27]</ref> the setting F = CR = 0.9 is chosen on the basis of discussion in <ref type="bibr" target="#b27">[28]</ref>. The empirical analysis reported in <ref type="bibr" target="#b28">[29]</ref> shows that in many cases the setting of F ≥ 0.6 and CR ≥ 0.6 leads to results having better performance.</p><p>Several studies, e.g. <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>, highlight that an efficient parameter setting is very prone to problems (e.g. F = 0.2 could be a very efficient setting for a certain fitness landscape and completely inadequate for another problem). This result can be seen as an application to the DE scheme of the No Free Lunch Theorem <ref type="bibr" target="#b17">[18]</ref>. In <ref type="bibr" target="#b31">[32]</ref>, a modified version of DE has been proposed. A system with two evolving populations has been presented. The crossover rate CR has been set equal to 0.5 after an empirical study. Unlike CR, the value of F is adaptively updated at each generation by means of the following scheme:</p><formula xml:id="formula_3">F = ⎧ ⎨ ⎩ max l min , 1 -f max f min if f max f min &lt; 1 max l min , 1 -f min f max otherwise<label>(3)</label></formula><p>where l m = 0.4 is the lower bound of F, f min and f max are the minimum and maximum fitness values over individuals of the populations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Self-adapting control parameters in differential evolution</head><p>In order to avoid the parameter setting of F and CR, a simple and effective strategy has been proposed in <ref type="bibr" target="#b19">[20]</ref>. This strategy is named self-adapting control parameters in differential evolution. The DE algorithm employing this strategy here is called self-adaptive control parameter differential evolution (SACPDE) and consists of the following. With reference to Fig. <ref type="figure">1</ref>, when the initial population is generated, two extra values between 0 and 1 are also generated per each individual. These values represent F and CR related to the individual under analysis. Each individual is thus composed (in a self-adaptive logic) of its genotype and its control parameters:</p><formula xml:id="formula_4">x i = x i,1 , x i,2 , . . . , x i, j , . . . x i,n , F i , CR i . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>In accordance with a self-adaptive logic, e.g. <ref type="bibr" target="#b32">[33]</ref>, the variation operations are preceded by the parameter update. More specifically when, at each generation, the ith individual x i is taken into account and three other individuals are extracted pseudo-randomly, its parameters F i and CR i are updated according to the following scheme:</p><formula xml:id="formula_6">F i = F l + F u rand 1 , if rand 2 &lt; τ 1 F i , otherwise<label>(5)</label></formula><formula xml:id="formula_7">CR i = rand 3 , if rand 4 &lt; τ 2 CR i , otherwise<label>(6)</label></formula><p>where rand j , j ∈ {1, 2, 3, 4}, are uniform pseudo-random values between 0 and 1; τ 1 and τ 2 are constant values which represent the probabilities that parameters are updated, F l and F u are constant values which represent the minimum value that F i could take and the maximum variable contribution to F i , respectively. The newly calculated values of F i and CR i are then used for generating the offspring. The variation operators and selection scheme are identical to that of a standard DE (see Sect. 2.1).</p><p>For sake of clarity, the pseudo-code highlighting the working principles of the SACPDE is given in Fig. <ref type="figure">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Opposition based differential evolution</head><p>The opposition based differential evolution (OBDE), proposed in <ref type="bibr" target="#b33">[34]</ref>, employs the logic of the opposition points in order to enhance exploration properties of the DE and test a wide portion of the decision space.</p><p>For a given point</p><formula xml:id="formula_8">x i = x i,1 , x i,2 , . . . , x i, j , . . . , x i,n belonging to a set D = [a 1 , b 1 ] × [a 2 , b 2 ] × • • • × [a j , b j ] × • • • × [a n , b n ] its opposition point is defined as: xi = a 1 + b 1 -x i,1 , a 2 +b 2 -x i,2 , . . . , a j +b j -x i, j , . . . , a n +b n -x i,n .</formula><p>The OBDE consists of a DE framework and two opposition based components: the first after the initial sampling and the second after the survivor selection scheme. While the first opposition based component is always applied after initialization, the second is activated by means of the probability j r (jump rate). These opposition based components process a set of candidate solutions and generate their opposition points. They then merge the two sets of points (original and opposition) and select those points which have the best performance (equal to the amount of candidate solutions in the original set).</p><p>More specifically, when the initial sampling is pseudo-randomly performed, opposition points of the initial , ,</p><p>pseudocode population are calculated, then half of these points (having the best fitness values) are selected to begin the optimization process. Analogously, at the end of each DE generation, when the population has been selected for subsequent generation, the opposition based component is applied.</p><p>For sake of clarity, the pseudo-code describing functioning of the OBDE is shown in Fig. <ref type="figure">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Differential evolution with adaptive crossover local search</head><p>In order to enhance performance of the DE, in <ref type="bibr" target="#b34">[35]</ref> a memetic approach, called differential evolution with adaptive hill climbing simplex crossover (DEahcSPX), has been proposed. The main idea is that a proper balance of the exploration abilities of the DE and exploitation abilities of a local searcher (LS) can lead to an algorithm with high performance. The proposed algorithm hybridizes the DE described in Sect. 2.1 as an evolutionary framework and a LS deterministically applied to that individual of the DE population with the best performance (in terms of fitness value).</p><p>The LS proposed for this hybridization is simplex crossover (SPX) <ref type="bibr" target="#b35">[36]</ref>. More specifically, at each generation, that individual having the best fitness value, indicated here with x b , is extracted and the LS described in Fig. <ref type="figure">4</ref>  If the SPX succeeds in improving upon the starting solution, a replacement occurs according to a meta-Lamarckian logic <ref type="bibr" target="#b4">[5]</ref>.</p><formula xml:id="formula_10">is applied. , ,<label>, , , , , , , , Fig</label></formula><p>It should be remarked that in Fig. <ref type="figure">4</ref> is a control parameter of the SPX which has been set equal to 1 in <ref type="bibr" target="#b34">[35]</ref>. Finally, the DE framework employed is the standard DE described in Fig. <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Scale factor local search differential evolution</head><p>Despite its simplicity and the lack of theoretical justification the SACPDE proposed in <ref type="bibr" target="#b19">[20]</ref> seems to have good performance for a various set of test problems and applications, as confirmed in the study reported in <ref type="bibr" target="#b18">[19]</ref>. According to our interpretation, the SACPDE demonstrates successful behavior since it tends to correct a structural weak point in the traditional DE. More specifically, the search logic of the DE is too strongly deterministic and a unique value of scale factor F and crossover rate CR for all the individuals over the entire evolution can lead to some difficulties in generating new promising genotypes. This limitation in the DE search structure seems to be more evident when the fitness landscape is more complex and when the dimensionality is high, as often shown in literature e.g. <ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref>. In other words, the assignment of different scale factors and crossover rates to each population individual seems to be beneficial to the algorithmic performance <ref type="bibr" target="#b39">[40]</ref>. Analogously, the probabilistic update of the aforementioned parameters also seems to increase the chance of detecting novel promising solutions.</p><p>This paper aims at considering the study in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">41]</ref> and enhancing the results by means of the integration of two cooperative/competitive local searchers. These local searchers attempt to enhance the quality of newly generated offspring by operating directly on the scale factor. This algorithmic choice allows the application of a simple local search which is independent of the dimensionality of the problem and thus also computationally viable for large scale problems.</p><p>The proposed algorithm, namely scale factor local search differential evolution (SFLSDE), is explained in detail in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evolutionary framework</head><p>At the beginning of the optimization process an initial population of S pop solutions x i is pseudo-randomly generated. Similar to the SACPDE described in Sect. 2.3, each ith individual is structured in the following way:</p><formula xml:id="formula_11">x i = x i,1 , x i,2 , . . . , x i, j , . . . x i,n , F i , CR i . (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>where the values of scale factor F i and crossover rate CR i are initially pseudo-randomly generated between 0 and 1. At each generation, the individual with the best performance is taken into account; scale factor and crossover rate are updated according the following rules:</p><formula xml:id="formula_13">F i = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ Golden section search if rand 5 &lt; τ 3 Hill -climb if τ 3 ≤ rand 5 &lt; τ 4 F l + F u rand 1 , if rand 2 &lt; τ 1 F i otherwise if rand 5 &gt; τ 4 (8) CR i = rand 3 , if rand 4 &lt; τ 2 CR i , otherwise<label>(9)</label></formula><p>where rand j , j ∈ {1, 2, 3, 4, 5}, are uniform pseudo-random values between 0 and 1; When the values F i are CR i have been calculated, for each individual x i of the S pop available, three individuals x r , x s and x t are pseudo-randomly extracted from the population, in the DE fashion. The provisional offspring x off is generated by mutation as:</p><formula xml:id="formula_14">τ k , k ∈ {1, 2,</formula><formula xml:id="formula_15">x off = x t + F i (x r -x s ). (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>Each gene of the new individual x off is switched with the corresponding gene of x i with a uniform probability CR i and the final offspring x off is generated:</p><p>x off, j = x i, j if rand(0, 1) &lt; CR x off, j otherwise <ref type="bibr" target="#b10">(11)</ref> where rand(0, 1) is a random number between 0 and 1; j is the index of the gene under examination. The resulting offspring x off is evaluated and, according to a steady-state strategy, it replaces x i if and only if f (x off ) &lt; f (x i ); otherwise no replacement occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Local search algorithms</head><p>This update scheme corrects the SACPDE by including two local search applications as possibility for choosing F i . The main idea is that the update of the scale factor and thus generation of the offspring is, with a certain probability, controlled in order to guarantee a high quality solution which can take on a key role in subsequent generations, see also <ref type="bibr" target="#b41">[42]</ref>. Two different local search algorithms have been chosen in accordance with the principle of conducting a search under complementary perspectives <ref type="bibr" target="#b5">[6]</ref>.</p><p>Local search in the scale factor space can be seen as the minimization over the variable F i of fitness function f in the direction given by x r and x s and modified by the crossover. More specifically, at first the scale factor local  <ref type="formula">11</ref>), then it attempts to find the scale factor value which guarantees an offspring with the best performance. Thus, for given values of x t , x r , x s , and the set of design variables to be swapped during the crossover operation, the scale factor local search attempts to solve the following minimization problem: min</p><formula xml:id="formula_17">F i f (F i ) in [-1, 1] . (<label>12</label></formula><formula xml:id="formula_18">)</formula><p>For sake of clarity, the procedure describing the fitness function is shown in Fig. <ref type="figure" target="#fig_1">5</ref>.</p><p>It must be remarked that each scale factor F i corresponds to an offspring solution x off during the local search and thus the proposed local search can be seen as an instrument for detecting solutions with a high quality over the directions suggested by a DE scheme. At the end of the local search process, newly generated design variables x i, j with corresponding scale factor F i within the candidate solution x i , see Eq. ( <ref type="formula" target="#formula_11">7</ref>), compose the offspring solution. In addition, it is fundamental to observe that negative values of F i are admitted up to -1. The meaning of the negative scale factor is obviously, in this context, inversion of the search direction. If this search in the negative direction succeeds, the corresponding positive value (the absolute value |F i |) is assigned to the offspring solution which has been generated by a local search. In order to perform this minimization, the following algorithms have been included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Scale factor golden section search</head><p>Golden section search is a classical local search algorithm for non-differentiable fitness functions introduced in <ref type="bibr" target="#b42">[43]</ref>. The scale factor golden section search (SFGSS) applies the golden section search to the scale factor in order to generate a high quality offspring. The SFGSS processes the interval [a = 0.1, b = 1] and generates two intermediate points: </p><formula xml:id="formula_19">F 1 i = b - b -a φ (13) F 2 i = a + b -a φ</formula><formula xml:id="formula_20">f (F 1 i ) &lt; f (F 2 i ) then F 2 i replaces b and the procedure is repeated in the new smaller [a, b] interval. If f (F 1 i ) ≥ f (F 2 i ), F 1</formula><p>i replaces a and the procedure is repeated in the new interval. The SFGSS is interrupted when a computational budget is exceeded. Fig. <ref type="figure">6</ref> shows the SFGSS pseudocode.</p><p>In the context of the DE multidimensional search, the SFGSS performs control of the offspring generation by at first individuating a rough estimation of a promising scale factor value (i.e. detects whether a high or scale factor value is preferable) and then progressively refines the search.</p><p>Two issues related to the SFGSS must be clarified in depth. The first issue is that the operator is focused on uni-modal , ,</p><p>pseudocode search. This is apparently a limitation of the reliability of the SFGSS. On the other hand, the multi-modality of the function f (F i ) is subject to features of the fitness landscape and the distance between x r and x s . If the points x r and x s are close enough, the aforementioned function is likely to be unimodal and the SFGSS is fully reliable. If the function is multimodal, the SFGSS tends to improve upon the initial scale factor F i anyway, thus generating an offspring with a fairly high performance. The second issue is that the SFGSS, due to its structure, can return satisfactory results with very low computational cost. Since the golden section search structure locates a promising area and performs fine tuning in the subsequent iterations, improvements after a few iterations are likely to lead to negligible improvements and thus a few iterations can already be of great assistance towards the global DE search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Scale factor hill-climb</head><p>The uni-dimensional hill-climb local search is one of the simplest and most popular optimization algorithms present in any optimization book e.g. <ref type="bibr" target="#b43">[44]</ref>. The algorithm uses the current value of F i as a starting point and is composed of an exploratory move and a decisional move. The exploratory move samples F ih and F i + h where h is a step size. The decisional move computes the min{ f (F i -h), f (F i ), f (F i +h)} and selects the corresponding point as the center of the next exploratory move. If the center of the new exploratory move is still F i , the step size h is halved. The local search is stopped when a budget condition is exceeded. For sake of completeness the pseudo-code of the scale factor hill-climb (SFHC) is shown in Fig. <ref type="figure">7</ref>.</p><p>It should be remarked that the SFHC is a local search algorithm characterized by a steepest descent pivot rule, see <ref type="bibr" target="#b44">[45]</ref>, i.e. an algorithm which explores the whole neighborhood of the candidate solution before making a decision on the search direction. This property makes, in general, the local search accurate and thus relatively computationally expensive. The computational cost in one dimension cannot, in any case, be dramatically high.</p><p>It is interesting to visualize the functioning of this local searcher in terms of generation of an offspring within a DE for a multi-dimensional problem. Since the scale factor is related to the modulus of a moving vector (x rx s ) in the generation of the preliminary offspring, the SFHC in operation can be seen as a pulsing vector in a multi-dimensional space which tunes to the best offspring and then generates this offspring. Figure <ref type="figure">8</ref> gives a graphical representation of the SFHC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Considerations about the hybridization</head><p>The proposed SFLSDE is thus composed of the aforementioned evolutionary framework and local search algorithms. </p><formula xml:id="formula_22">-20 + e + exp -0.2 n n i=1 x 2 i [-1, 1] n -exp 1 n n i=1 cos(2π • x i )x i Alpine n i=1 |x i sin x i + 0.1x i | [-10, 10] n Camelback 4x 2 1 -2.1x 2 1 + x 6 1 3 + x 1 x 2 -4x 2 2 + 4x 4 2 [-3, 3] × [-2, 2]</formula><p>DeJong ||x|| 2 [-5.12, 5.12] n DropWave -</p><formula xml:id="formula_23">1+cos 12 √ ||x|| 2 1 2 ||x|| 2 +2</formula><p>[-5.12, 5.12] n Easom cos  One important feature of the proposed algorithm is the structure of the solutions in a self-adaptive fashion as shown in Eq. ( <ref type="formula" target="#formula_11">7</ref>). As stated before, assignment of local parameters related to the variation operators (F i and C R i ) to each solution seems to be a crucial factor for enhancing the exploration features in a DE scheme. Also the occasional refreshment of the parameters seems to provide a better chance for the detection of promising genotypes. Nevertheless, the performance of the evolutionary framework can be significantly improved, especially for complex fitness landscapes and high dimensional cases. For this purpose, two local search algorithms with different search logics, acting on the scale factor, have been integrated into the evolutionary framework. Activation of the local search is performed by a simple probabilistic criterion, as shown in Eq. <ref type="bibr" target="#b7">(8)</ref>. Choice of this hybridization has been performed following the same logic as that of the SACPDE i.e. as an additional set of update rules for the scale factor. The role of these local searchers is to assist in the evolution by generating offspring with high performance which can promote a successful evolution. The activation of the probability, determined by τ 3 and τ 4 is set to be rather low (see parameter setting in Sect. 4) since an excessive local search would lead to an unnecessary increase of the computational cost. The application of the local search is carried out, in any case, with a relatively low depth, i.e. with a limited computational budget. Since the local search is performed in one dimension a relatively low number of fitness evaluations (especially for the SFGSS) is sufficient to obtain a substantial improvement.</p><formula xml:id="formula_24">x 1 cos x 2 exp -(x 1 -π) 2 -(x 2 -π) 2 [-100, 100] 2 Griewangk ||x|| 2 4000 -n i=0 cos x i √ i + 1 [-600, 600] n Michalewicz -n i=1 sin x i sin i•x 2 i π [0, π] n Pathological n-1 i=1 0.5 + sin 2 100x 2 i +x 2 i+1 -0.5 1+0.001 * x 2 i -2x i x i+1 +x 2 i+1 2 [-100, 100] n Rastrigin 10n + n i=0 x 2 i -10 cos(2π x i ) [-5.12, 5.12] n Rosenbrock valley n-1 i=0 x n+1 -x 2 i 2 + (1 -x) 2 [-2.048, 2.048] n Schwefel n i=1 x i sin √ |x i | [-500, 500] n Sum of powers n i=1 |x i | i+1 [-1, 1] n</formula><p>For sake of clarity, Fig. <ref type="figure">9</ref> shows the complete pseudocode of the SFLSDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Numerical results</head><p>This section shows numerical results which prove the viability of the proposed approach. The results are divided into Dropwave -7.86e-01 ± 6.95e-09 -5.36e-01 ± 1.23e-01 -7.86e-01 ± 0.00e+00 -5.10e-01 ± 1.39e-01 -1.00e+00 ± 0.00e+00 Easom -1.00e+00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 Griewangk 0.00e+00 ± 0.00e+00 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tirronen</head><p>-2.25e+00 ± 4.90e-02 -2.39e+00 ± 7.37e-02 -2.26e+00 ± 9.75e-02 -1.41e+00 ± 9.06e-02 -7.70e+00 ± 0.00e+00 Rotated Tirronen -1.31e+00 ± 7.80e-02 -1.97e+00 ± 4.66e-01 -1.29e+00 ± 1.15e-01 -1.06e+00 ± Throughout the entire numerical result section a constant parameter setting has been used for SFLSDE in order to prove the robustness of the proposed algorithm over various optimization problems. More specifically, F l = 0.1 and F u = 0.9 as suggested in <ref type="bibr" target="#b19">[20]</ref>. Regarding the local search activation τ 1 = τ 2 = 0.1, τ 3 = 0.03, and τ 4 = 0.07. This setting means that each generated offspring has a 3% chance of being biased by the SFGSS, a 4% chance to be biased by the SFHC, and a 93% chance to undergo a normal self-adaptive strategy. Choice of the τ 3 and τ 4 has been empirically set on the basis of a parameter tuning. As general guidelines, it has been observed that the local search pressure due to the proposed approach should be limited compared to the global pressure, due to the SACPDE framework, in order to obtain a successful algorithmic behavior. In addition, according to our results, the local search should not be run with a high depth value; an application to relatively many points with a limited depth (limited computational budget) is preferable to an application of local search to few points with a high depth. More specifically, each SFGSS is run for 8 fitness evaluations and the SFHC for 20. On the contrary, population size has been set, for all the algorithms under analysis, on the basis of the dimensionality of the problem.  In the three following subsections the test functions present in Table <ref type="table" target="#tab_1">1</ref> are considered. It should be remarked that some rotated problems have been added to our benchmark set. The rotated problems are obtained by means of multiplication of the vector of variables to a randomly generated orthogonal rotation matrix.</p><formula xml:id="formula_25">= = + + Rotated Ackley = = = + Alpine + = + + Rotated alpine + + = + Camelback = = = = De Jong = = = + Dropwave + + = + Easom = = = = Griewangk = + = + Rotated Griewangk = + + + Michalewicz = +</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Empirical justification of the use of double local search</head><p>This section aims at empirically justifying the combined employment of two local search algorithms. In order to pursue this aim, the SFLSDE has been run for the test problems listed in Table <ref type="table" target="#tab_1">1</ref> (n = 25 for all the test problems except the Camelback and Easom functions which are twodimensional) and compared to two algorithms composed of the same Evolutionary Framework (EF) and only one local search algorithm at once. More specifically, EF + SFGSS is composed of the evolutionary framework and the scale factor golden section search, the EF + SFHC is composed of the evolutionary framework and the scale factor hill-climb. The parameter setting has been performed in order to keep the balance between global and local search constant. Thus, the SFGSS is activated in the EF+SFGSS with a probability of 0.13 while the SFHC in the EF+SFHC with a probability of 0.05. Each algorithm has been run for 50,000 fitness evaluations with a population size of S pop = 30 for 30 independent runs. Optimization results ± standard deviation errors are shown in Table <ref type="table" target="#tab_3">2</ref>. The best results are highlighted in bold face.</p><p>Although, as expected, results in Table <ref type="table" target="#tab_3">2</ref> are very similar to each other, this preliminary test shows that the combined use of two local searches is more beneficial than use of a single local search integrated into the evolutionary framework. This finding is in accordance with the proposed design strategy described in <ref type="bibr" target="#b5">[6]</ref> and the Meta-Lamarckian learning approach shown in <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Numerical results for (relatively) low dimensional problems</head><p>This subsection compares performance of the SFLSDE with the algorithms listed in the following: a plain DE <ref type="bibr" target="#b22">[23]</ref>, SAC-PDE <ref type="bibr" target="#b19">[20]</ref>, OBDE <ref type="bibr" target="#b33">[34]</ref>, and DEahcSPX <ref type="bibr" target="#b34">[35]</ref>.</p><p>-The DE has been run with a population size S pop = 30, F = 0.7, and CR = 0.7 in accordance to the suggestions given in <ref type="bibr" target="#b28">[29]</ref>. -The SACPDE has been run with a population size S pop = 30; the constant values in Eqs. ( <ref type="formula" target="#formula_6">5</ref>), <ref type="bibr" target="#b5">(6)</ref> have been set, respectively, F l = 0.1, F u = 0.9, τ 1 = 0.1, and τ 2 = 0.1 as shown in <ref type="bibr" target="#b19">[20]</ref>. -The OBDE has been run with a population size S pop = 30, F = 0.7, and C R = 0.7 (in accordance with <ref type="bibr" target="#b28">[29]</ref>) and, with reference to Fig. <ref type="figure">3</ref>, j r = 0.3. -The DEahcSPX has been run with a population size S pop = 30, F = 0.7, and CR = 0.7 (in accordance with <ref type="bibr" target="#b28">[29]</ref>) and, with reference to Fig. <ref type="figure">4</ref>, n p = 10.</p><p>Each algorithm has been run for 30 independent runs, 100,000 fitness evaluations each run. In this section the algorithmic performance in a low dimensional case is experimentally studied. More specifically, with reference to Table <ref type="table" target="#tab_1">1</ref>, all the functions under analysis (except the Camelback and Easom) have been run with n = 30 variables. The population size of the SFLSDE has been set S pop = 30 as well, as were the other algorithms.</p><p>Table <ref type="table" target="#tab_4">3</ref> shows the final values (± the standard deviation error) obtained by each algorithm for each test problem. The best results are highlighted in bold face. Results in Table <ref type="table" target="#tab_4">3</ref> show that the SFLSDE converges to the best results in 23 cases out of the 28 under analysis. In the remaining five test problems the SFLSDE, in any case, reaches the second best results and is still competitive with the best performing algorithm. For example, with the Schwefel function the DE obtains the best values but the proposed SFLSDE reaches satisfactory results anyway.</p><p>In order to prove statistical significance of the results, the Student's t test has been applied according to the description given in <ref type="bibr" target="#b45">[46]</ref> for a confidence level of 0.95. Final values obtained by the SFLSDE have been compared to the final value returned by each algorithm used as a benchmark. Table <ref type="table" target="#tab_7">4</ref> shows the results of the test. Indicated with "+" is the case when the SFLSDE statistically outperforms, for the corresponding test problem, the algorithm mentioned in the column; indicated with "=" is the case when pairwise comparison leads to success of the t test i.e. the two algorithms have the same performance; indicated with "-" is the case when the SFLSDE is outperformed.</p><p>The t test in Table <ref type="table" target="#tab_7">4</ref> shows that the SFLSDE loses the comparison in only 5 cases out of the 112 comparisons carried out i.e. the SFLSDE loses in only 4.4% of the pairwise comparisons. These results confirm the high performance in terms of robustness of the proposed algorithm for a wide spectrum of problems.</p><p>In order to execute a numerical comparison of the convergence speed performance, for each test problem, the average final fitness value returned by the best performing algorithm G has been considered. Subsequently, the average fitness value at the beginning of the optimization process J has also been computed. The threshold value THR = J -0.95(G-J ) has then been calculated. The value THR represents 95% of the decay in the fitness value of the algorithm with the best performance. If an algorithm succeeds during a certain run to reach the value THR, the run is said to be successful. For each test problem, the average amount of fitness evaluations ne required, for each algorithm, to reach THR has been computed. Subsequently, the Q-test (Q stands for Quality) described in <ref type="bibr" target="#b46">[47]</ref> has been applied. For each test problem and each algorithm, the Q measure is computed as:</p><formula xml:id="formula_26">(a) (b) (c) (d)<label>(e) (g) (f)</label></formula><formula xml:id="formula_27">Q = ne R (<label>14</label></formula><formula xml:id="formula_28">)</formula><p>where the robustness R is the percentage of successful runs. It is clear that, for each test problem, the smallest value equals the best performance in terms of convergence speed.The value inf means that R = 0, i.e. the algorithm never reached the THR. SFLSDE has a very high performance in terms of robustness in 100 dimension case as well.</p><p>Figure <ref type="figure" target="#fig_4">11</ref> shows average performance of the algorithms under investigation for some of the test problems in Table <ref type="table" target="#tab_1">1</ref>.</p><p>In summary, numerical results show that the SFLSDE is a very robust algorithm which seems to lead to high quality results in low and high dimension cases and for a various set of test problems. The performance behavior of the SFLSDE can be classified into three groups according to the test problems under analysis. In some cases the algorithm significantly outperforms the other algorithms obtaining excellent results (see e.g. Fig. <ref type="figure" target="#fig_4">11a,</ref><ref type="figure">e</ref>). For other test problems, the SFLSDE has a slightly worse performance in terms of convergence speed compared to other algorithms (usually the OBDE) but eventually outperforms all the other algorithms in detection of the final solutions. Finally, in a few cases (5 for 30 dimensional problems and 5 for 100 dimensional problems) the SFLSDE has a slightly worse performance than one or two other algorithms but outperforms the remaining ones. It should be remarked that when the SFLSDE is outperformed, the difference in performance with the best algorithm is always very limited (see Fig <ref type="figure" target="#fig_4">11d</ref>). As a matter of fact, the SFLSDE is outperformed in a statistically relevant way in an extremely limited amount of cases as shown in Tables <ref type="table" target="#tab_7">4</ref> and<ref type="table">7</ref>. The pairwise analysis between SACPDE and SFLSDE highlights that the proposed local search either greatly improve the performance of the SAC-PDE framework or does not have a relevant effect (see e.g. Schwefel or Rotated Schwefel in 100 dimensions, where the performance trends almost completely coincide). The scale factor local search seems, for the 54 test problems considered in this paper, to never jeopardize the performance of the evolutionary framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper proposes the scale factor local search differential evolution (SFLSDE). The SFLSDE is a memetic algorithm composed of a differential evolution based evolutionary framework and two simple local search algorithms. These local search algorithms operate on the scale factor in order to generate offspring with a high performance during the mutation process. Despite its simplicity, the proposed algorithm seems to have a remarkable performance over a wide and various set of test problems. This robustness feature seems to be valid in both low and high dimensional cases, even when DE based algorithms are likely to fail. The SFLSDE has a rather good performance in terms of convergence speed and an excellent performance in terms of detection of high quality solutions. For some test problems the SFLSDE significantly outperforms modern and efficient metaheuristics.</p><p>It should be remarked that the proposed memetic algorithm performs the local search on the scale factor and thus on one parameter regardless of the dimensionality of the problem. This kind of hybridization seems to be very efficient in effecting enhancements in the offspring generation and to have a dramatic impact on stagnation prevention in the differential evolution framework. More specifically, these improved solutions seem to be beneficial in "refreshing" the genotypes and assist the global search in the optimization process.</p><p>A future development of this work will aim at further investigating and modifying the employment of scale factor local search focused on large scale problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>. 3 Fig. 4</head><label>34</label><figDesc>Fig. 3 OBDE pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Local search fitness function, f (F i ) pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 Fig. 7 Fig. 8 5 2</head><label>6785</label><figDesc>Fig. 6 SFGSS pseudocode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 10</head><label>10</label><figDesc>Fig. 10 Performance trends in 30 dimensions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 11</head><label>11</label><figDesc>Fig. 11 Performance trends in 100 dimensions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>3, 4} are constant threshold values. Values τ 1 and τ 2 represent the probabilities that parameters are updated while τ 3 and τ 4 are related to activation of the local search. The values F l and F u , analogous to the case of the SACPDE described in Sect. 2.3, are constant values which represent the minimum value that F i could take and the maximum variable contribution to F i , respectively. For all other individuals the update occurs as with the SACPDE, see Eqs. (5) and (6) in Sect. 2.3.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Test problems</cell><cell>Test problem</cell><cell>Function</cell><cell>Decision space</cell></row><row><cell></cell><cell>Ackley</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Single versus double local search schemes: optimization results</figDesc><table><row><cell>Test problem</cell><cell>EF+SFGSS</cell><cell>EF+SFHC</cell><cell>SFLSDE</cell></row><row><cell>Ackley</cell><cell>4.44e-16 ± 0.00e+00</cell><cell>4.00e-15 ± 0.00e+00</cell><cell>4.44e-16 ± 0.00e+00</cell></row><row><cell>Rotated Ackley</cell><cell>7.44e-03 ± 1.05e-02</cell><cell>3.11e-15 ± 8.88e-16</cell><cell>1.54e-15 ± 2.46e-15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Final values, average ± standard deviation in 30 dimensions</figDesc><table><row><cell>Test problem</cell><cell>DE</cell><cell>SACPDE</cell><cell>OBDE</cell><cell>DEahcSPX</cell><cell>SFLSDE</cell></row><row><cell>Ackley</cell><cell>6.72e-15 ± 1.50e-15</cell><cell>5.36e-14 ± 9.41e-14</cell><cell>1.61e-02 ± 1.38e-03</cell><cell>6.60e-02 ± 4.02e-02</cell><cell>1.46e-15 ± 1.93e-15</cell></row><row><cell>Rotated Ackley</cell><cell>6.37e-15 ± 1.67e-15</cell><cell>8.13e-14 ± 2.03e-13</cell><cell>1.45e-03 ± 0.00e+00</cell><cell>1.37e-01 ± 7.85e-02</cell><cell>4.44e-16 ± 0.00e+00</cell></row><row><cell>Alpine</cell><cell>9.97e-06 ± 2.80e-05</cell><cell>4.41e-16 ± 5.27e-16</cell><cell>1.85e-02 ± 1.99e-03</cell><cell>2.65e-02 ± 7.76e-03</cell><cell>1.09e-36 ± 1.08e-35</cell></row><row><cell>Rotated alpine</cell><cell>1.68e+01 ± 4.81e+00</cell><cell>2.10e-01 ± 2.71e-01</cell><cell>1.36e-02 ± 0.00e+00</cell><cell>4.58e-01 ± 5.37e-01</cell><cell>2.08e-35 ± 2.08e-35</cell></row><row><cell>Camelback</cell><cell cols="5">-1.03e+00 ± 6.66e-16 -1.03e+00 ± 0.00e+00 -1.03e+00 ± 6.66e-16 -1.03e+00 ± 6.66e-16 -1.03e+00 ± 0.00e+00</cell></row><row><cell>De Jong</cell><cell>4.51e-36 ± 4.04e-36</cell><cell>7.61e-32 ± 4.08e-31</cell><cell>1.56e-02 ± 0.00e+00</cell><cell>7.22e-01 ± 8.62e-01</cell><cell>1.42e-79 ± 9.26e-80</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4</head><label>4</label><figDesc>Results of the Student's t test in 30 dimensions</figDesc><table><row><cell>Test problem</cell><cell>DE SACPDE OBDE DEahcSPX</cell></row><row><cell>Ackley</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc>Results of the Q test in</figDesc><table><row><cell>30 dimensions</cell><cell>Test Problem</cell><cell>DE</cell><cell>SACPDE</cell><cell>OBDE</cell><cell>DEahcSPX</cell><cell>SFLSDE</cell></row><row><cell></cell><cell>Ackley</cell><cell>6.1e+01</cell><cell>2.7e+01</cell><cell>2.3e+01</cell><cell>4.3e+01</cell><cell>2.7e+01</cell></row><row><cell></cell><cell>Rotated Ackley</cell><cell>9.7e+01</cell><cell>4.0e+01</cell><cell>2.5e+01</cell><cell>3.2e+02</cell><cell>3.2e+01</cell></row><row><cell></cell><cell>Alpine</cell><cell>1.4e+02</cell><cell>3.5e+01</cell><cell>3.4e+01</cell><cell>1.5e+02</cell><cell>3.3e+01</cell></row><row><cell></cell><cell>Rotated alpine</cell><cell>inf</cell><cell>6.9e+01</cell><cell>4.6e+01</cell><cell>3.4e+02</cell><cell>5.3e+01</cell></row><row><cell></cell><cell>Camelback</cell><cell>2.8e+00</cell><cell>2.2e+00</cell><cell>2.6e+00</cell><cell>2.0e+01</cell><cell>2.4e+00</cell></row><row><cell></cell><cell>De Jong</cell><cell>3.5e+01</cell><cell>1.6e+01</cell><cell>1.1e+01</cell><cell>1.7e+01</cell><cell>1.7e+01</cell></row><row><cell></cell><cell>Dropwave</cell><cell>inf</cell><cell>inf</cell><cell>inf</cell><cell>inf</cell><cell>2.1e+02</cell></row><row><cell></cell><cell>Easom</cell><cell>1.7e+01</cell><cell>9.8e+00</cell><cell>9.2e+00</cell><cell>7.9e+01</cell><cell>1.0e+01</cell></row><row><cell></cell><cell>Griewangk</cell><cell>3.4e+01</cell><cell>1.6e+01</cell><cell>1.2e+01</cell><cell>1.9e+01</cell><cell>1.6e+01</cell></row><row><cell></cell><cell>Rotated Griewangk</cell><cell>3.5e+01</cell><cell>1.6e+01</cell><cell>1.2e+01</cell><cell>1.7e+01</cell><cell>1.6e+01</cell></row><row><cell></cell><cell>Michalewicz</cell><cell>3.0e+02</cell><cell>1.1e+02</cell><cell>1.3e+03</cell><cell>inf</cell><cell>1.2e+02</cell></row><row><cell></cell><cell>Rotated Michalewicz</cell><cell>inf</cell><cell>9.9e+02</cell><cell>inf</cell><cell>inf</cell><cell>1.0e+03</cell></row><row><cell></cell><cell>Pathological</cell><cell>7.4e+00</cell><cell>2.8e+01</cell><cell>8.2e+00</cell><cell>1.8e+02</cell><cell>2.9e+01</cell></row><row><cell></cell><cell>Rotated pathological</cell><cell>2.1e+01</cell><cell>9.5e+01</cell><cell>1.3e+01</cell><cell>3.0e+02</cell><cell>8.9e+01</cell></row><row><cell></cell><cell>Rastrigin</cell><cell>3.2e+02</cell><cell>7.2e+01</cell><cell>3.3e+02</cell><cell>inf</cell><cell>5.4e+01</cell></row><row><cell></cell><cell>Rotated Rastrigin</cell><cell>inf</cell><cell>inf</cell><cell>1.1e+04</cell><cell>inf</cell><cell>1.3e+02</cell></row><row><cell></cell><cell>Rosenbrock valley</cell><cell>5.1e+01</cell><cell>2.6e+01</cell><cell>2.3e+01</cell><cell>1.3e+02</cell><cell>2.8e+01</cell></row><row><cell></cell><cell>Rotated Rosenbrock valley</cell><cell>6.2e+01</cell><cell>3.3e+01</cell><cell>2.9e+01</cell><cell>3.0e+02</cell><cell>3.6e+01</cell></row><row><cell></cell><cell>Rotated Schwefel</cell><cell>inf</cell><cell>7.3e+02</cell><cell>5.9e+02</cell><cell>inf</cell><cell>6.9e+02</cell></row><row><cell></cell><cell>Schwefel</cell><cell>2.2e+02</cell><cell>1.6e+02</cell><cell>4.7e+02</cell><cell>inf</cell><cell>1.1e+02</cell></row><row><cell></cell><cell>Sum of powers</cell><cell>1.4e+01</cell><cell>5.9e+00</cell><cell>4.0e+00</cell><cell>5.2e+00</cell><cell>6.1e+00</cell></row><row><cell></cell><cell>Rotated sum of powers</cell><cell>2.3e+01</cell><cell>6.0e+00</cell><cell>3.4e+00</cell><cell>4.2e+00</cell><cell>6.0e+00</cell></row><row><cell></cell><cell>Tirronen</cell><cell>inf</cell><cell>inf</cell><cell>inf</cell><cell>inf</cell><cell>2.7e+03</cell></row><row><cell></cell><cell>Rotated Tirronen</cell><cell>inf</cell><cell>inf</cell><cell>inf</cell><cell>inf</cell><cell>8.6e+02</cell></row><row><cell></cell><cell>Whitley</cell><cell>1.3e+01</cell><cell>5.8e+00</cell><cell>3.9e+00</cell><cell>4.1e+00</cell><cell>6.0e+00</cell></row><row><cell></cell><cell>Rotated Whitley</cell><cell>1.8e+01</cell><cell>5.3e+00</cell><cell>3.4e+00</cell><cell>3.8e+00</cell><cell>5.6e+00</cell></row><row><cell></cell><cell>Zakharov</cell><cell>8.0e-01</cell><cell>2.9e+00</cell><cell>7.9e-01</cell><cell>8.2e+00</cell><cell>3.0e+00</cell></row><row><cell></cell><cell>Rotated Zakharov</cell><cell>4.9e-01</cell><cell>9.2e-01</cell><cell>2.8e-01</cell><cell>5.2e-01</cell><cell>6.1e-01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6</head><label>6</label><figDesc>Final values, average ± standard deviation in 100 dimensions</figDesc><table><row><cell>Test problem</cell><cell>DE</cell><cell>SACPDE</cell><cell>OBDE</cell><cell>DEahcSPX</cell><cell>SFLSDE</cell></row></table></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alpine</head><p>0.00e+00 ± 0.00e+00 7.52e-18 ± 1.54e-16 1.95e-42 ± 4.46e-42</p><p>Rotated alpine 1.30e-01 ± 0.00e+00 1.69e-23 ± 1.73e-23 1.94e-36 ± 1.67e-36</p><p>Camelback -1.03e+00 ± 0.00e+00 -1.03e+00 ± 0.00e+00 -1.03e+00 ± 0.00e+00</p><p>De Jong 0.00e+00 ± 0.00e+00 9.14e-74 ± 0.00e+00 3.06e-77 ± 7.89e-79 Dropwave -9.61e-01 ± 2.46e-02 -1.00e+00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 Easom -1.00e-00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 -1.00e+00 ± 0.00e+00 Griewangk 0.00e+00 ± 0.00e+00 0.00e+00 ± 0.00e+00 0.00e+00 ± 0.00e+00 Rotated Griewangk 0.00e+00 ± 0.00e+00 3.29e-04 ± 6.75e-03 0.00e+00 ± 0.00e+00 Michalewicz -2.96e+01 ± 9.06e-04 -2.88e+01 ± 0.00e+00 -2.92e+01 ± 1.44e-01 Rotated Michalewicz -1.08e+01 ± 1.10e+00 -1.56e+01 ± 1.38e+00 -1.60e+01 ± 1.37e+00 Pathological 1.45e+01 ± 0.00e+00 1.45e+01 ± 7.17e-08 1.45e+01 ± 0.00e+00 Rotated pathological 1.45e+01 ± 7.35e-06 1.45e+01 ± 1.44e-05 1.45e+01 ± 3.30e-06 Rastrigin 0.00e+00 ± 0.00e+00 0.00e+00 ± 0.00e+00 0.00e+00 ± 0.00e+00 Rotated Rastrigin 2.22e-01 ± 2.22e-01 0.00e+00 ± 0.00e+00 0.00e+00 ± 0.00e+00 Rosenbrock valley 1.57e-05 ± 0.00e+00 1.67e-07 ± 3.60e-07 5.16e-08 ± 6.83e-09 Rotated Rosenbrock valley 5.47e-01 ± 0.00e+00 5.47e-01 ± 1.74e-06 5.47e-01 ± 0.00e+00 Schwefel -1.26e+04 ± 3.64e-12 -1.14e+04 ± 4.27e+02 -1.17e+04 ± 0.00e+00 Rotated Schwefel -8.33e+03 ± 1.97e+02 -7.52e+03 ± 2.43e+01 -7.34e+03 ± 1.43e+02 Sum of powers 8.07e-131 ± 0.00e+00 2.18e-177 ± 0.00e+00 1.82e-203 ± 0.00e+00 Rotated sum of powers 1.23e-08 ± 0.00e+00 6.11e-10 ± 0.00e+00 0.00e+00 ± 0.00e+00 Tirronen -7.30e+00 ± 0.00e+00 -4.64e+00 ± 2.20e+00 -4.53e+00 ± 2.12e+00 Ackley 5.16e-01 ± 3.55e-02 8.35e-05 ± 1.99e-04 9.02e-04 ± 2.04e-03 1.19e-03 ± 2.76e-03 9.85e-07 ± 5.30e-07 Rotated Ackley 1.96e+00 ± 1.31e-01 1.46e-04 ± 2.96e-04 3.20e-03 ± 7.06e-03 1.84e-03 ± 4.55e-03 9.61e-07 ± 8.19e-07 Alpine 8.08e+01 ± 3.41e+00 4.88e-02 ± 4.91e-02 8.53e-02 ± 7.82e-03 9.64e-02 ± 1.39e-02 1.65e-03 ± 2.11e-03 Rotated alpine 1.92e+02 ± 8.13e+00 3.96e+00 ± 1.88e+00 1.14e-01 ± 4.55e-02 2.09e-01 ± 5.85e-02 1.58e-03 ± 1.60e-03 De Jong 1.24e+01 ± 1.49e+00 9.88e-06 ± 2.75e-05 7.58e-04 ± 2.07e-03 1.60e-02 ± 4.68e-02 3.15e-10 ± 2.58e-10 Dropwave -1.50e-02 ± 1.01e-03 -2.61e-01 ± 5.83e-02 -5.84e-01 ± 5.83e-02 -4.86e-01 ± 5.97e-02 -8.52e-01 ± 1.23e-01 Griewangk 4.49e+01 ± 5.73e+00 5.13e-02 ± 7.80e-02 6.07e-02 ± 1.20e-01 2.74e-02 ± 5.89e-02 7.28e-08 ± 9.96e-08 Rotated Griewangk 4.23e+01 ± 5.47e+00 6.23e-02 ± 7.33e-02 1.50e-01 ± 3.09e-01 1.23e-01 ± 3.77e-01 3.00e-06 ± 5.26e-06 Michalewicz -4.33e+01 ± 1.40e+00 -8.63e+01 ± 3.71e+00 -4.36e+01 ± 1.61e+00 -3.05e+01 ± 1.23e+00 -8.63e+01 ± 3.73e+00 Rotated Michalewicz -1.72e+01 ± 8.68e-01 -1.94e+01 ± 1.71e+00 -1.97e+01 ± 9.92e-01 -1.61e+01 ± 8.04e-01 -1.88e+01 ± 1.90e+00 Pathological 4.95e+01 ± 8.70e-04 4.95e+01 ± 3.14e-04 4.95e+01 ± 3.84e-04 4.95e+01 ± 4.33e-03 4.95e+01 ± 3.44e-04 Rotated pathological 4.95e+01 ± 1.85e-03 4.95e+01 ± 4.55e-03 4.95e+01 ± 6.67e-03 4.95e+01 ± 5.25e-03 4.95e+01 ± 4.66e-04 Rastrigin 7.58e+02 ± 2.82e+01 4.24e+01 ± 6.74e+00 5.48e+02 ± 3.66e+01 7.43e+02 ± 3.09e+01 6.81e-06 ± 1.54e-05 Rotated Rastrigin 1.17e+03 ± 3.74e+01 1.72e+02 ± 5.29e+01 7.92e+02 ± 3.01e+01 8.61e+02 ± 2.18e+01 7.95e-02 ± 3.67e-01 Rosenbrock valley 3.41e+01 ± 2.30e+00 3.21e-02 ± 2.22e-02 3.31e-02 ± 3.83e-02 6.59e-02 ± 1.22e-01 3.67e-02 ± 3.59e-02 Rotated 5.13e+01 ± 3.27e+00 3.48e+00 ± 5.38e-02 3.68e+00 ± 6.82e-01 3.48e+00 ± 1.74e-01 3.48e+00 ± 1.38e-01</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">5</ref> shows the Q values in 30 dimensions. The best results are highlighted in bold face.</p><p>Results in Table <ref type="table">5</ref> show that the OBDE has the best performance in terms of convergence speed in 30 dimensions. Nevertheless, the SFLSDE offers a competitive convergence speed performance for all the test problems under examination. If we take into consideration the results in Tables <ref type="table">3</ref> and<ref type="table">5</ref> we can conclude that in low dimension problems the SFLSDE is either the best algorithm in terms of convergence speed and final detected result or else can be slightly slower in early generations but eventually capable of outperforming the other algorithms. In addition, it is fundamental to observe that the SFLSDE is the only algorithm which never takes the value inf in the Q measure. This fact means that the proposed algorithm is never characterized by a null robustness (R = 0), i.e. for all the 28 test problems the algorithm never prematurely convergences to solutions with a poor performance. In this sense, the SFLSDE offers the best performance in terms of robustness and in our opinion the best compromise between the capacity to attain high quality results and convergence speed demand.</p><p>In order to graphically show behavior of the algorithms, some examples of the average performance, dependant on the number of fitness evaluations (for some of the test problems listed in Table <ref type="table">1</ref>), are represented in Fig. <ref type="figure">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Numerical results for (relatively) high dimensional problems</head><p>The same numerical experiments shown in Sect. 4.2 (except the Camelback and Easom functions which are explicitly in two variables) have been repeated for n = 100 dimensions in order to test the performance of the SFLSDE for large scale problems. All algorithms have been run with the same parameter setting except for the population size; all algorithms have been run with a population size S pop = 100. Table <ref type="table">6</ref> shows  <ref type="table">6</ref> show that the SFLSDE converges to the best results in 22 test problems out of the 26 considered here; in the other 4 cases, again, the SFLSDE offers a good performance in terms of capability of capacity to detect good solutions. Thus the SFLSDE seems to be very promising for the high dimensional case as well. Table <ref type="table">7</ref> shows results of the t-test for a confidence level of 0.95.</p><p>Numerical results in Table <ref type="table">7</ref> confirm that the proposed SFLSDE is very promising in the high dimensional case as well. As shown the proposed algorithm loses only 3 pairwise comparisons out of the 104 carried out.</p><p>In order to estimate both robustness and convergence speed, the Q test has been repeated in the 100 dimension case. Table <ref type="table">8</ref> shows the Q measures in high dimensional problems.</p><p>Results in Table <ref type="table">8</ref> show that the higher dimensionality makes the problem more difficult, thus the algorithms tend to prematurely converge to suboptimal solutions. It can be noticed that the DE is rather inefficient compared to the other algorithms as is proven by the massive presence of inf values in the Table. Thus, standard DE seems to be incapable of solving complex large scale problems (e.g. Rotated Schwefel). The SACPDE seems to have a rather good performance in terms of Q measure since it fails at detecting solutions with a competitive performance a limited amount of times (4 times). In addition, a pairwise comparison between SAC-PDE and SFLSDE shows that the proposed scale factor local search seems to be rather efficient since it systematically tends to either improve (e.g. Dropwave) or to leave it unaltered (e.g. Michalewicz) the performance of the SACPDE. The DEahcSPX and OBDE seem to be able to solve most of the problems (they fail at detecting values with a high performance for 6 test problems). The OBDE in particular has a high performance in terms of convergence speed. Most importantly, the SFLSDE is the only algorithm which never takes an inf value and is thus the only algorithm (among those under analysis) which never prematurely converges to a solution with a poor performance. This fact proves that the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A competitive and cooperative approach to complex combinatorial search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moscato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norman</surname></persName>
		</author>
		<idno>790</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">On evolution, search, optimization, genetic algorithms and martial arts: towards memetic algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moscato</surname></persName>
		</author>
		<idno>826</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multimeme algorithms for proteine structure prediction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Blackburne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of parallel problem solving in nature VII. Lecture notes in computer science springer</title>
		<meeting>parallel problem solving in nature VII. Lecture notes in computer science springer<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
		<title level="m">Studies in the theory and design space of memetic algorithms</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>University of West England</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Meta-lamarkian learning in memetic algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toward robust memetic algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent advances in memetic algorithms. Studies in fuzzines and soft computing</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="185" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classification of adaptive memetic algorithms: a comparative study</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Syst Man Cybern B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="152" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A fast adaptive memetic algorithm for on-line and off-line control design of pmsm drives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caponio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Cascella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Salvatore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sumner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Syst Man Cybern B Memet Algorithms</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="41" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An adaptive evolutionary algorithm with intelligent mutation local searchers for designing multidrug therapies for HIV</title>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Toivanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rae</forename><surname>Mäkinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="219" to="235" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An adaptive multimeme algorithm for designing HIV multidrug therapies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Toivanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Cascella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans Comput Biol Bioinform</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="278" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A memetic differential evolution in filter design for defect detection in paper production</title>
		<author>
			<persName><forename type="first">V</forename><surname>Tirronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kärkkäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Majava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of evolutionary computing. Lectures notes in computer science</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4448</biblScope>
			<biblScope unit="page" from="320" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An enhanced memetic differential evolution in filter design for defect detection in paper production</title>
		<author>
			<persName><forename type="first">V</forename><surname>Tirronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kärkkäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Majava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="529" to="555" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parallel memetic algorithm with selective local search for large scale quadratic assignment problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Innov Comput Inf Control</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1399" to="1416" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Diversity-adaptive parallel memetic algorithm for solving large scale combinatorial optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput Fusion Found Methodol Appl</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="873" to="888" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Balance between genetic search and local search in memetic algorithms for multiobjective permutation flow shop scheduling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Murata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="204" to="223" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An empirical study on the specification of the local search application probability in multiobjective memetic algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hitotsuyanagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE congress on evolutionary computation</title>
		<meeting>the IEEE congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
			<biblScope unit="page" from="2788" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A tutorial for competent memetic algorithms: model, taxonomy, and design issues</title>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="474" to="488" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Super-fit control adaptation in memetic differential evolution frameworks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caponio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tirronen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput Fusion Found Methodol Appl</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Selfadapting control parameters in differential evolution: a comparative study on numerical benchmark problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bošković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Žumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="646" to="657" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Differential evolution: a practical approach to global optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On stagnation of the differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 6th international mendel conference on soft computing</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Oŝmera</surname></persName>
		</editor>
		<meeting>6th international mendel conference on soft computing</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Differential evolution-a simple and efficient adaptive scheme for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
		<idno>TR-95-012</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>ICSI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-adaptive differential evolution algorithm for numerical optimization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE congress on evolutionary computation</title>
		<meeting>the IEEE congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1785" to="1791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Introduction to evolutionary computation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Differential evolutiona simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Glob Optim</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A fuzzy adaptive differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE region 10th international conference on computer, communications, control and power engineering</title>
		<meeting>the 17th IEEE region 10th international conference on computer, communications, control and power engineering</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="606" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Differential evolution: a simple evolution strategy for fast optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dr Dobbs J Softw Tools</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="24" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Parameter study for differential evolution using a power allocation problem including interference cancellation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Weitkemper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-D</forename><surname>Kammeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE congress on evolutionary computation</title>
		<meeting>the IEEE congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1857" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A parameter study for differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gämperle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference in neural networks and applications (NNA), fuzzy sets and fuzzy systems (FSFS) and evolutionary computation (EC)</title>
		<meeting>the conference in neural networks and applications (NNA), fuzzy sets and fuzzy systems (FSFS) and evolutionary computation (EC)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="293" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On setting the control parameter of the differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th international mendel conference on soft computing</title>
		<meeting>the 8th international mendel conference on soft computing</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Population set based global optimization algorithms: Some modifications and numerical studies</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Törn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Oper Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1703" to="1725" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Evolutionstrategie: Optimierung Technisher Systeme nach prinzipien des Biologishen Evolution</title>
		<author>
			<persName><forename type="first">I</forename><surname>Rechemberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Fromman-Hozlboog Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Oppositionbased differential evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rahnamayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Tizhoosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="79" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accelerating differential evolution using an adaptive local search</title>
		<author>
			<persName><forename type="first">N</forename><surname>Noman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="125" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-parent recombination with simplex crossover in real coded genetic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tsutsui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Higuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the genetic evolution computer conference</title>
		<meeting>the genetic evolution computer conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Differential evolution for highdimensional function optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE congress on evolutionary computation</title>
		<meeting>the IEEE congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3523" to="3530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Enhancing differential evolution performance with local search for high dimensional function optimization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Noman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 conference on Genetic and evolutionary computation ACM</title>
		<meeting>the 2005 conference on Genetic and evolutionary computation ACM</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="967" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A memetic differential evolutionary algorithm for high dimensional functions&apos; optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the third international conference on natural computation</title>
		<meeting>eesings of the third international conference on natural computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="188" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Large scale global optimization using differential evolution with self-adaptation and cooperative co-evolution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zamuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bošković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Žumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE world congress on computational intelligence</title>
		<meeting>the IEEE world congress on computational intelligence</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="3719" to="3726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Self-adaptive differential evolution algorithm in constrained real-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Žumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maucec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE congress on evolutionary computation</title>
		<meeting>the IEEE congress on evolutionary computation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="215" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Real-coded memetic algorithms with crossover hill-climbing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol Comput Memet Algorithms</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="302" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sequential minimax search for a maximum</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kiefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Am Math Soc</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="502" to="506" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Artificial intelligence: a modern approach, 2nd edn</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Prentice-Hall</publisher>
			<biblScope unit="page" from="111" to="114" />
			<pubPlace>Englewood Cliffs</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Memetic evolutionary algorithms</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent advances in memetic algorithms</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="3" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><surname>Nist/Sematech</surname></persName>
		</author>
		<ptr target="http://www.itl.nist.gov/div898/handbook/" />
		<title level="m">e-handbook of statistical methods</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Differential evolution in search of solutions</title>
		<author>
			<persName><forename type="first">V</forename><surname>Feoktistov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="83" to="86" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
