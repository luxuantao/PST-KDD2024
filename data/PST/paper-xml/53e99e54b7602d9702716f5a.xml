<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automated Diagnosis of Glaucoma Using Digital Fundus Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-08-09">9 August 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jagadish</forename><surname>Nayak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Acharya</forename><forename type="middle">U</forename><surname>Rajendra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bhat</forename><surname>Subbanna</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nakul</forename><surname>Shetty</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Teik-Cheng</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Bhat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">T.-C</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of E&amp;C Engineering</orgName>
								<orgName type="institution">Manipal Institute of Technology</orgName>
								<address>
									<postCode>576104</postCode>
									<settlement>Manipal</settlement>
									<country>India R. Acharya U. (*</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">NGEE ANN Polytechnic</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of E&amp;C Engineering</orgName>
								<orgName type="institution">BVB College of Engineering and Technology</orgName>
								<address>
									<settlement>Hubli</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Science and Technology</orgName>
								<orgName type="institution">SIM University (UniSIM)</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automated Diagnosis of Glaucoma Using Digital Fundus Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-08-09">9 August 2008</date>
						</imprint>
					</monogr>
					<idno type="MD5">4B1E5E055A19023BEAA58DF7F48F6FAC</idno>
					<idno type="DOI">10.1007/s10916-008-9195-z</idno>
					<note type="submission">Received: 11 June 2008 / Accepted: 22 July 2008 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Glaucoma</term>
					<term>Eye</term>
					<term>Fundus</term>
					<term>Image processing</term>
					<term>Neural network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Glaucoma is a disease of the optic nerve caused by the increase in the intraocular pressure of the eye. Glaucoma mainly affects the optic disc by increasing the cup size. It can lead to the blindness if it is not detected and treated in proper time. The detection of glaucoma through Optical Coherence Tomography (OCT) and Heidelberg Retinal Tomography (HRT) is very expensive. This paper presents a novel method for glaucoma detection using digital fundus images. Digital image processing techniques, such as preprocessing, morphological operations and thresholding, are widely used for the automatic detection of optic disc, blood vessels and computation of the features. We have extracted features such as cup to disc (c/d) ratio, ratio of the distance between optic disc center and optic nerve head to diameter of the optic disc, and the ratio of blood vessels area in inferior-superior side to area of blood vessel in the nasal-temporal side. These features are validated by classifying the normal and glaucoma images using neural network classifier. The results presented in this paper indicate that the features are clinically significant in the detection of glaucoma. Our system is able to classify the glaucoma automatically with a sensitivity and specificity of 100% and 80% respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Glaucoma is a progressive optic neuropathy with characteristic structural changes in the optic nerve head reflected in the visual field <ref type="bibr" target="#b12">[13]</ref>. Worldwide, it is the second leading cause of blindness [Global data on visual impairment in the year 2002]. It affects one in two hundred people aged fifty years and younger, and one in ten over the age of eighty years. In most cases, it is detected only after loss in vision. Vision loss is caused by damage to the optic nerve, which carries image information from the light receptors to the brain. There is no cure for glaucoma-yet. Hence, early detection and prevention is the only way to avoid total loss of vision. There are two main types of glaucoma. They are primary open angle glaucoma, and angle closure glaucoma. These occur due to increasing intraocular pressure (IOP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Types of glaucoma (1) Primary open angle glaucoma</head><p>This is the most common form of glaucoma. It happens when the eye's drainage canals become clogged over time. The inner eye pressure (IOP) rises because the correct amount of fluid can't drain out of the eye. With open angle glaucoma, the entrances to the drainage canals are clear and work properly. The clogging problem occurs further inside the drainage canals, similar to a clogged pipe below the drain in a sink <ref type="bibr">[23]</ref>. If open angle glaucoma is not diagnosed and treated, it can cause a gradual loss of vision. This type of glaucoma develops slowly and sometimes without noticeable sight loss for many years. It usually responds well to medication, especially if caught early and treated <ref type="bibr">[23]</ref>.</p><p>(2) Angle closure glaucoma This type of glaucoma is also known as acute glaucoma or narrow angle glaucoma. It is rare and is different from open angle glaucoma. This happens when the drainage canals get blocked or covered over, like a sink with something covering the drain. In this angle closure glaucoma, the iris is not as wide and open as it should be. The outer edge of the iris bunches up over the drainage canals, when the pupil enlarges too much or too quickly. This can happen when entering a dark room. Treatment of angle closure glaucoma usually involves surgery to remove a small portion of the outer edge of the iris. This helps to unblock the drainage canals so that the extra fluid can drain.</p><p>The glaucoma can be detected using one of three tests: (1) Ophthalmoscopy, (2) Tonometry and (3) Perimetry <ref type="bibr">[24]</ref>. Regular glaucoma check-ups include two routine eye tests: Tonometry and Ophthalmoscopy.</p><p>Glaucoma test are time consuming and need special skills and equipments. There is an urgent need for new techniques to diagnose glaucoma at early stages accurately, faster, even with less skilled people. In recent years computer based systems made glaucoma screening easier <ref type="bibr" target="#b18">[19]</ref>. Imaging systems, such as fundus camera, optical coherence tomography (OCT), Heidelberg retina tomography (HRT) and scanning laser polarimetry, have been extensively used for eye diagnosis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. HRT <ref type="bibr" target="#b11">[12]</ref>, confocal laser scanning tomography <ref type="bibr" target="#b10">[11]</ref> and OCT <ref type="bibr" target="#b6">[7]</ref> can show retinal nerve fiber damage even before the damage to the visual fields. However the equipment cost is high and most hospitals may not be able to afford them. Hence fundus cameras can be used as an alternative by many ophthalmologists to diagnose glaucoma. Using image processing, the features in the fundus images, such as the optic disk and blood vessels, can be extracted <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22]</ref>. These features can provide us with useful information to diagnose glaucoma.</p><p>The application of artificial intelligence (AI) methods has been demonstrated to be an effective diagnostic procedure in the prediction of diseases. Several techniques have been used to automate the glaucoma detection process. A neuro-fuzzy method was proposed to diagnose glaucoma subjects with higher sensitivity and specificity <ref type="bibr" target="#b19">[20]</ref>. Fuzzy sets can be used to handle the uncertainty inherently present in the medical diagnosis process <ref type="bibr" target="#b14">[15]</ref>. The results of 61 different tests were combined into one diagnosis to identify the presence or absence of the glaucoma using these rules showed 75.8% classification efficiency.</p><p>Topographic images of patients' optic nerve heads were obtained using a scanning laser ophthalmoscope. Feedforward artificial neural network (ANN) was designed to discriminate the glaucoma image and normal images with an accuracy of 88.9% and a sensitivity (correct abnormals) of 84.4% <ref type="bibr" target="#b17">[18]</ref>. It was already shown that, the GDx software generated parameters have limited ability for glaucoma detection <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16]</ref>. The techniques like relative surface height <ref type="bibr" target="#b4">[5]</ref>, and sectoral-based analysis <ref type="bibr" target="#b15">[16]</ref> yield better results than GDx parameters.</p><p>The performance of a number of machine learning algorithms namely, multilayer perceptron (MLP), support vector machine (SVM), and linear (LDA) and quadratic discriminant analysis (QDA), Parzen window, mixture of Gaussian (MOG), and mixture of generalized Gaussian (MGG) with STATPAC indexes mean deviation, pattern standard deviation, and corrected pattern standard deviation was studied <ref type="bibr" target="#b5">[6]</ref>. They have discussed the advantages and disadvantages of these classifiers in detail.</p><p>In this paper, we present a system for the computer based detection of glaucoma using three features. The first feature is the cup to disc ratio, which specifies change in the cup area due to glaucoma. Due to the glaucoma, the cup area will increase, resulting in shift of the optic nerve head towards the nasal side. This shift with respect to the position of optic disc center is computed as a distance. The second parameter is the ratio of this distance to the diameter of the optic disc. The ratio of total area of the blood vessels in inferior and superior side of the optic disc to the total area of the blood vessels in nasal and temporal area (ISNT) is taken as the last salient feature. Figure <ref type="figure">1</ref> shows the block diagram of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and methods</head><p>The fundus images were collected from the Kasturba Medical College, Manipal, India. We have used 61 fundus images: 24 normal images and 37 glaucoma images with an age group of 20 to 70 years. The inbuilt imaging software of the fundus camera is used to store the images in the JPEG format. The images were photographed and certified by the doctors in the ophthalmology department. The ethics committee consisting of senior doctors has approved the data for this research purpose. The images were taken with a resolution of 560×720. All data samples were collected from patients of age between 20 to 50 years. A fundus camera consists of a microscope attached with a camera and a light source. The camera is designed to take pictures of the inner surface of the eye. It is one of the most popular devices used for Ophthalmoscopy. It is used by doctors to diagnose eye diseases like diabetic retinopathy, glaucoma etc. and to monitor their progression.  Doctors also look for other features such as the shifting of the blood vessels towards the nasal side. Figure <ref type="figure">4</ref> shows the four quadrants of the fundus image. The upper quadrant and lower quadrants are superior (S) and inferior (I) respectively. Nasal (N) is the quadrant close to nose and the last quadrant is the temporal (T) one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cup to disc ratio</head><p>The objective of the image processing system is to extract the relevant features for the automatic diagnosis of the glaucoma. Figure <ref type="figure">5</ref> shows the block diagram of the image processing system used to compute the cup area and the disc area.</p><p>After analyzing the RGB components of the image, it was found that the optic disk was more easily discriminated in RED image. However, the disk and the cup could not be easily distinguished as the border between the two was unclear. Thus, the Green image was used to distinguish the cup from the rest of the image. In order to measure disk and cup areas more accurately, the blood vessels in the images had to be removed. This can be achieved by means of morphological operations. Morphological operations namely, erosion, dilation, opening and closing operations were performed frequently on the images <ref type="bibr" target="#b20">[21]</ref>. The basic effect of morphological erosion operation on a binary or a grayscale image is to erode away the boundaries of regions of foreground pixels (i.e. white pixels or brighter pixels typically) <ref type="bibr" target="#b7">[8]</ref>. Thus areas of foreground pixels shrink in size, and holes within those areas become larger. A dilation operation gradually enlarges the boundaries of regions of foreground pixels. Thus areas of foreground pixels grow in size, while holes within those regions become smaller.</p><p>Opening is similar erosion and it tends to remove some of the foreground (bright) pixels from the edges of regions of foreground pixels. However, it is less destructive than erosion in general. Closing is similar to dilation and it tends to enlarge the boundaries of foreground regions in an image and shrink background color holes in such regions.</p><p>First a CLOSE operation was performed on both the red and green component images independently followed by an OPEN operation. The CLOSE operation would fill the gaps in both the DISK and the CUP and also smoothen the outer edges. The open operation would remove any small stray bright spots that are present in the image <ref type="bibr" target="#b20">[21]</ref>.</p><p>Both the red and the green component images were studied for several fundus images. The standard deviation and the threshold values for separating the disc and the cup from the red and green images were evaluated. It was determined that for red component of the image, threshold value is optimum at 3.2 times the standard deviation value. Similarly threshold of 4 times the standard deviation was selected for the green image. Using the above threshold values the 8 bit red and green images were converted into binary images to obtain the optic disk and cup. The binary images of the optic disk and cup are shown in Fig. <ref type="figure">6</ref> (a) and (b) respectively. The area of the cup and the disk were evaluated by counting the number of white pixels in that region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measuring distance between optic disk centre and optic nerve head</head><p>The flow chart of the blood vessel detection algorithm is shown in the Fig. <ref type="figure">7</ref>. The binary image of the optic disk, obtained by thresholding, is used as a mask on the green component image. The output obtained is the green component with only the area within optic disk visible. Bottom-hat filtering with structuring element of size 20 is used in this image. The resulting image highlights the optic nerves within the disk area. Thresholding is used on this the image with a threshold value 2.7 times the standard deviation of the bottom-hat filter output image to get the binary image of the blood vessels only.</p><p>Form the cropped green component image the centre of the optic disk is detected. This is done by identifying the area of brightest intensity. Similarly the optic nerve head coordinates is detected by finding the area of brightest intensity in the output image of the bottom-hat image. The Euclidian distance between the two points is computed. Figure <ref type="figure">8</ref> shows the images obtained in the process of identifying the blood vessels in the given image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measuring the area of blood vessels in ISNT quadrants</head><p>The most blood vessels are concentrated in the superior and the inferior regions of the optic disk (Fig. <ref type="figure">4</ref>). Usually, the blood vessels cover about 27% of the optic disk area. <ref type="bibr" target="#b8">[9]</ref> A shift in the optic nerve head causes a slight increase in the area covered by blood vessels in the nasal region and decreases the area covered in superior and inferior regions. Hence we take the ratio of the sum of blood vessels area in inferior and superior regions to area of blood vessels in sum of nasal and temporal regions.</p><p>The binary image of the blood vessels is first taken and is cropped to an image of size 300×300 to cover a small area that has the centre of the optic disk as its centre. A mask of 300×300 is used to filter one quadrant. The mask is rotated by 90°each time and is used on the binary blood vessel image to obtain the area covered by blood vessels in each quadrant. The mask fits the image perfectly as both the cropped image and the mask have the same dimensions of 300×300. We take the ratio of area covered by inferior and superior regions to area covered by nasal and temporal regions. The ratio is lower for glaucomatous cases and is more for normal cases Fig. <ref type="figure" target="#fig_5">9</ref> shows the masks used for Figure <ref type="figure" target="#fig_6">10</ref> shows the blood vessels in the vicinity of ISNT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classifier used</head><p>An Artificial Neural Network (ANN) is an information processing unit that is inspired by the way biological nervous systems processes information <ref type="bibr" target="#b9">[10]</ref>. It is composed of a large number of highly interconnected neurons working together to solve specific tasks. Data enters at the inputs and passes through the layer of hidden layers, where the actual information is processed and the result is available at the output layer. Usually feedforward architecture is used, where there is no feedback between the layers.</p><p>The supervised learning algorithm was used for training the neural network <ref type="bibr" target="#b22">[25]</ref>. In this case, initially the system weights are randomly chosen and then slowly modified during the training to in order to get the desired outputs. The difference between the actual output and desired output is calculated for each input at every iteration. These errors are used to change the weights proportionately. This process continues until the preset mean square error is reached (0.001 in this work). This algorithm of reducing the errors in order to achieve the correct class by incrementing weights is known as backpropagation.</p><p>Three layer feedforward will be able to solve most of the complex problems with sigmoid activation function. The non-linearity of the sigmoid function makes the backpropagation learning algorithm powerful in classification process. In our work, we have used a three layer neural network with three inputs, one output and one hidden layer with four neurons. The output neuron will classify three classes as '0' for normal, '1' for glaucoma. The network was trained with given set of training data and later tested with remaining testing samples. During the training phase,  each output of the ANN is an real value in the range 0 to 1.0, whereas the 'desired' output is either 0 or 1.0. During the testing phase, the output signal is approximated to binary levels by comparing it with threshold value of 0.5. A learning constant η=0.9 (which controls the step size), was chosen by trial and error method <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In this work a total of 61 fundus images of the patients with age ranging from 25 to 60 years were used. Out of these twenty four are normal and thirty seven were glaucoma cases. Features such as cup to disc ratio, optic nerve head shift and ISNT ratio were computed for both normal and glaucoma samples using the techniques discussed above. The mean and standard deviations values of computed features are shown in Table <ref type="table" target="#tab_0">1</ref>. We can see in this table that, cup to disc ratio and optic nerve head shift is more for the glaucoma due to the increase in the pressure. The ratio of the sum of blood vessels area in inferior and superior regions to area of blood vessels in sum of nasal and temporal regions is lower for subjects having glaucoma. A Student t-test was conducted on these two groups for different parameters and it was found that the p value is less than 0.05. This indicates that all features detected for these two groups are statistically significant. Figure <ref type="figure">11</ref> shows box plots of the three features used for the two classes. These box plots indicate that the median values of features for two class of data is different. It can be seen from the box plots that, the mean (center line) of the boxes for each parameters in two cases are distinct and hence the features are significant. Further, to test the validity of the feature vectors, we used an ANN for the classification of fundus images to normal and glaucoma classes. The Table <ref type="table" target="#tab_1">2</ref> shows the number of samples used for the training and testing of the neural network and classification results. We have used 46 images for the training and 15 images for the testing. In our work, all the glaucoma is classified as glaucoma and in one case, a normal sample is classified as abnormal. The </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>This work proposes three new parameters for automatic glaucoma identification. We have shown (using t-test) that our features are clinically significant to detect the disease.</p><p>There are several methods of treatment available to impede progression of this disease. For this reason, it is important to diagnose glaucoma as early as possible to minimize the damage to the optic nerve. Fuzzy sets were used to provide a method for handling the uncertainty inherently present in the process of medical diagnosis. The six fuzzy classification algorithms were applied to the 58 cases in the test set to detect the presence and absence of the disease <ref type="bibr" target="#b14">[15]</ref>. In their work, the entire six algorithms performed less than 76% in identifying the correct class.</p><p>The high diagnostic performance of our ANN based on refined input visual field data was studied <ref type="bibr" target="#b2">[3]</ref>. ANN achieved a sensitivity of 93% at a specificity level of 94% with an area under the receiver operating characteristic curve of 0.984. Glaucoma Hemifield test attained a sensitivity of 92% at 91% specificity.</p><p>The optic disc topography parameters of the Heidelberg retina tomography (HRT) was used to differentiate between glaucoma and non-glaucoma eye using neural network <ref type="bibr" target="#b3">[4]</ref>. The areas under the ROC (receiver operating characteristics) curves for SVM (support vector machine) linear and SVM Gaussian were 0.938 and 0.945, respectively; for MLP (multi-layer perceptron), 0.941; for the current LDF (linear discriminant function), 0.906; and for the best previously proposed LDF, 0.890.</p><p>But, in our work, we have extracted the three features using image processing techniques. Our results are superior to the above methods due to the higher percentage of correct classification. However, we can improve the accuracy by using more parameters like texture etc. Also, we can improve the results, by increasing the number of training and testing images. The percentage of correct classification also depends on the environmental lighting conditions. This method can be used as an adjunct tool for the physicians to cross check their diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>A computer based system for detection of glaucoma abnormal eyes through fundus images is developed algorithm using image processing techniques and neural network. The features, such as cup to disc ratio are computed automatically and this give us a high degree of accuracy. The features, such as shift in optic nerve head and shift of blood vessel towards the nasal will, properly indicate the existence of glaucoma. The system we propose can identify the presence of glaucoma to the tune of 90%. The result of the system can further be improved by taking more diverse images. This system can be used as an adjunct tool by the physicians to cross check their diagnosis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 aFig. 1</head><label>21</label><figDesc>Fig. 2 a Fundus camera and b fundus image</figDesc><graphic coords="2,178.61,577.70,366.18,136.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2 (a) shows the fundus camera and Fig. 2 (b) shows fundus image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 aFig. 4</head><label>34</label><figDesc>Fig. 3 a Normal eye fundus image and b glaucomatous eye fundus image</figDesc><graphic coords="3,178.61,53.86,366.65,141.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 Fig. 6 a</head><label>56</label><figDesc>Fig.5The block diagram for the computation of optic disc area and cup area</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 Fig. 8 a</head><label>78</label><figDesc>Fig. 7 Blood vessels detection flowchart</figDesc><graphic coords="5,178.61,347.81,366.18,366.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9</head><label>9</label><figDesc>Fig. 9 Masks used for detecting blood vessels in a Superior side; b Temporal side; c Inferior side; and d nasal side of the optic disc</figDesc><graphic coords="6,178.61,312.89,366.29,400.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10</head><label>10</label><figDesc>Fig. 10 Blood vessels in the a Superior side; b Temporal side; c Inferior side; and d Nasal side of the optic disk</figDesc><graphic coords="7,178.61,53.86,366.29,366.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,178.61,53.86,366.29,282.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Mean standard deviation values of three features for normal and glaucoma cases with its p value</figDesc><table><row><cell>Features</cell><cell>Normal</cell><cell>Glaucoma</cell><cell>P value</cell></row><row><cell></cell><cell>mean±SD</cell><cell>mean±SD</cell><cell></cell></row><row><cell>Cup to disc ratio</cell><cell cols="3">0.259±0.0317 0.408±0.0963 &lt;0.0001</cell></row><row><cell cols="2">Optic nerve head shift 0.186±0.102</cell><cell>0.257±0.0903</cell><cell>0.017</cell></row><row><cell>ISNT ratio</cell><cell>1.23±0.540</cell><cell>0.962±0.376</cell><cell>0.049</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Results of classificationFig. 11 Box plots for a Cup to disc ratio; b Optic nerve head shift; c ISNT ratio. Where A = Normal and B = Glaucomaaverage classification rate is 90%, which is clinically significant. TP (true positive), is number of glaucoma image classified as glaucoma. TN (true negative) is the number of normal classified as normal image. False positive (FP) is the number of normal image is classified as glaucomatous. False negative (FN) is the number of glaucomatous samples identified as normal. With respect to this statistical treatment sensitivity is defined as the probability that, abnormal class is classified as abnormal. Specificity is defined as the probability of normal is identified as normal class. Table3shows sensitivity, specificity and positive predictive value for the two classes. The proposed system is able to detect abnormal as abnormal with a sensitivity of 100% and specificity is 80%. The positive predictive value (PPA) which shows how best it can detect the normal and abnormal cases is 90%.</figDesc><table><row><cell>Subject</cell><cell>No. of samples used for</cell><cell>No. of samples used for</cell><cell>No. of correctly classified</cell><cell>Percentage classification</cell><cell cols="6">Table 3 Results of sensitivity, specificity and positive predictive values for the classifier</cell></row><row><cell></cell><cell>training</cell><cell>testing</cell><cell>samples</cell><cell></cell><cell>TP</cell><cell>FP</cell><cell>TN</cell><cell>FN</cell><cell>Sensitivity</cell><cell>Specificity</cell><cell>Positive</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(%)</cell><cell>(%)</cell><cell>predictive</cell></row><row><cell>Normal</cell><cell>19</cell><cell>05</cell><cell>04</cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>value (%)</cell></row><row><cell>Glaucoma</cell><cell>27</cell><cell>10</cell><cell>10</cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell></cell><cell>90</cell><cell>10</cell><cell>01</cell><cell>04</cell><cell>00</cell><cell>100</cell><cell>80</cell><cell>90.9</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J Med Syst (2009) 33:337-346</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Image modelling of human eye</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Suri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008-04">2008a, April</date>
			<pubPlace>Artech House, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Application of higher order spectra for the identification of diabetes retinopathy stages</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chee</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-008-9154-8</idno>
	</analytic>
	<monogr>
		<title level="j">J. Med. Syst. USA</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Trained artificial neural network for glaucoma diagnosis using visual field data: a comparison with conventional algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bizios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heijl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bengtsson</surname></persName>
		</author>
		<idno type="DOI">10.1097/IJG.0b013e31802b34e4</idno>
	</analytic>
	<monogr>
		<title level="j">J. Glaucoma</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="120" to="128" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>b013e31802b34e4</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparing neural networks and linear discriminant functions for glaucoma detection using confocal scanning laser ophthalmoscopy of the optic disc</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Zangwill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Goldbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="3444" to="3454" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Measurement of relative nerve fiber layer surface height in Glaucoma</title>
		<author>
			<persName><forename type="first">J</forename><surname>Caprioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="633" to="641" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comparison of machine learning and traditional classifiers in glaucoma diagnosis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Sample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Goldbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Weinreb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBME.2002.802012</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="9963" to="9974" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optical coherence tomography to detect and manage retinal disease and glaucoma</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Caprioli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="156" to="169" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Digital image processing</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wintz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparison of optic nerve imaging methods to distinguish normal eyes from those with glaucoma</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Greaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Garway-Heath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="140" to="145" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Neural networks a comprehensive foundation. 2nd edn. Pearson Education</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optic nerve head morphometry in healthy adults using confocal laser scanning tomography</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Theofylaktopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bangard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jonescu-Cuypers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diestelhorst</surname></persName>
		</author>
		<idno type="DOI">10.1136/bjo.2003.028068</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="6761" to="6765" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interobserver variability in confocal optic nerve analysis (HRT)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Garway-Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Jonescu-Cuypers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">W</forename><surname>Reinhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O W</forename><surname>Burk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Jonas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Mardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diestelhorst</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10792-006-9022-9</idno>
	</analytic>
	<monogr>
		<title level="j">Int. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="4" to="5143" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The optic disc in glaucoma, ii: correlation of appearance of the optic disc with the visual field</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Hitchings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Spaeth</surname></persName>
		</author>
		<idno type="DOI">10.1136/bjo.61.2.107</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Introduction to computing with neural nets</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Lippman</surname></persName>
		</author>
		<idno type="DOI">10.1109/MASSP.1987.1165576</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE ASSP Mag</title>
		<imprint>
			<biblScope unit="page" from="4" to="22" />
			<date type="published" when="1987-04">April. 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Application of fuzzy sets to the diagnosis of glaucoma</title>
		<author>
			<persName><forename type="first">B</forename><surname>Losch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual International Conference of the IEEE Engineering in Medicine and Biology</title>
		<meeting>the 18th Annual International Conference of the IEEE Engineering in Medicine and Biology</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1550" to="1552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Comparison of algorithms for detection of localized nerve fiber defects using scanning laser polarimetry</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Medeiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Susanna</surname><genName>Jr</genName></persName>
		</author>
		<idno type="DOI">10.1136/bjo.87.4.413</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="413" to="419" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automated identification of different stages of diabetic retinopathy using digital fundus images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kagathi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-007-9113-9</idno>
	</analytic>
	<monogr>
		<title level="j">J. Med. Syst. USA</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2107" to="2115" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The detection of glaucoma using an artificial neural network. Proceedings of 17th</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Parfitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Mikelberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Swindale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Conference IEEE Engineering in Medicine and Biology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="847" to="848" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A computer-based diagnosis system for early glaucoma screening</title>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual IEEE Engineering in Medicine and Biology</title>
		<meeting>the 27th Annual IEEE Engineering in Medicine and Biology</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="6608" to="6611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Application of soft computing methods to the diagnosis and prediction of glaucoma</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ulieru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cuzzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Ceruti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Conf. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="3641" to="3645" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A contribution of image processing to the diagnosis of diabetic retinopathydetection of exudates in color fundus images of the human retina</title>
		<author>
			<persName><forename type="first">T</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Massin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Erginay</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2002.806290</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1236" to="1243" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Identification of different stages of diabetic retinopathy using retinal optical images</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">V</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Artificial neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yegnanarayana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Prentice-Hall of India</publisher>
			<pubPlace>New Delhi</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
