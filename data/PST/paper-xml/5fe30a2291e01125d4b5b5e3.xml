<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under review as a conference paper at ICLR 2021 A DISTRIBUTIONAL APPROACH TO CONTROLLED TEXT GENERATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Under review as a conference paper at ICLR 2021 A DISTRIBUTIONAL APPROACH TO CONTROLLED TEXT GENERATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a Distributional Approach to address Controlled Text Generation from pre-trained Language Models (LMs). This view permits to define, in a single formal framework, "pointwise'" and "distributional" constraints over the target LM -to our knowledge, this is the first approach with such generality -while minimizing KL divergence with the initial LM distribution. The optimal target distribution is then uniquely determined as an explicit EBM (Energy-Based Model) representation. From that optimal representation we then train the target controlled autoregressive LM through an adaptive distributional variant of Policy Gradient. We conduct a first set of experiments over pointwise constraints showing the advantages of our approach over a set of baselines, in terms of obtaining a controlled LM balancing constraint satisfaction with divergence from the initial LM (GPT-2). We then perform experiments over distributional constraints, a unique feature of our approach, demonstrating its potential as a remedy to the problem of Bias in Language Models. Through an ablation study we show the effectiveness of our adaptive technique for obtaining faster convergence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Neural language models, such as GPT-2/3 <ref type="bibr" target="#b41">(Radford et al., 2019;</ref><ref type="bibr">Brown et al., 2020a)</ref>, pretrained on huge amounts of text, have become pre-eminent in NLP, producing texts of unprecedented quality. In this paper, we are concerned with the problem of controlling a generic pretrained LM in order to satisfy certain desiderata. For instance, we may want to avoid toxic content; prevent certain demographic biases; or steer generations towards a certain topic or style. Prior work, taking inspiration from Reinforcement Learning (RL), has aimed at inducing autoregressive models to optimize global objectives using task specific rewards such as BLEU and ROUGE for Machine Translation and Summarization <ref type="bibr" target="#b43">(Ranzato et al., 2016;</ref><ref type="bibr" target="#b2">Bahdanau et al., 2017)</ref>, or hand crafted rewards <ref type="bibr" target="#b28">(Li et al., 2016b;</ref><ref type="bibr" target="#b52">Tambwekar et al., 2019)</ref> to improve certain a priori desirable features.</p><p>However, such an optimization process is not infallible; <ref type="bibr" target="#b30">Liu et al. (2016a)</ref> noted that it often leads to "degeneration", producing poor examples that improve the average reward but forgo coherence and fluency. This degeneration is often diagnosed as an effect of deviating too much from the original pretrained LM during optimization. Consequently, prior work has regarded proximity to the pretrained model as a prescription for sample quality. This view is most prominent in open-domain generation where no gold references are available for fine-tuning, making the pretrained LM itself the yardstick for fluency. <ref type="bibr" target="#b19">Jaques et al. (2017);</ref><ref type="bibr" target="#b61">Ziegler et al. (2019)</ref> propose a conservative fine-tuning approach moderated by a KL penalty between the trained policy and the original LM, discouraging large deviations. A KL penalty was also used by <ref type="bibr" target="#b13">Dathathri et al. (2020)</ref>, this time in a plug-and-play rather than a fine-tuning context. However, the authors show that balancing policy deviations from the original LM while also satisfying the control conditions is delicate. To combat degeneration they had to combine the KL penalty with post-norm fusion, reranking, and early-stopping procedures.</p><p>Most of the existing work on Controlled Generation has taken what we refer to as a "pointwise" view, namely focusing on the quality of each individual output, a view that is encouraged by the standard RL goal of maximizing rewards computed at the individual level. Such techniques are incapable of enforcing "distributional" conditions, where some collective statistical properties are desired over the set of all generations. One problem that is currently causing a lot of concern, and which could much benefit from distributional control, is that of social biases conspicuous in pretrained language models. <ref type="bibr" target="#b51">(Stanovsky et al., 2019;</ref><ref type="bibr" target="#b40">Prates et al., 2020;</ref><ref type="bibr" target="#b47">Sheng et al., 2019a;</ref><ref type="bibr" target="#b7">Brown et al., 2020b)</ref>. However, applying distributional control on pretrained models is still an understudied problem. <ref type="bibr" target="#b49">Sheng et al. (2020)</ref> introduce a method relying on adversarial triggers <ref type="bibr" target="#b54">(Wallace et al., 2019)</ref>; this method does not de-bias the whole distribution but only obtains non-biased continuations of given prompts. <ref type="bibr" target="#b5">Bordia &amp; Bowman (2019)</ref> introduce a regularization term for reducing gender bias when training a language model from scratch (as opposed to de-biasing a pretrained model). <ref type="foot" target="#foot_0">1</ref>In this work, we present our Generation with Distributional Control (GDC) approach, in which we formalize the problem of controlled text generation as a constraint satisfaction problem over the probability distribution p representing the desired target LM. Namely, we require the expectations ("moments") relative to p of certain output features to have specific values; this permits for instance to condition all outputs to speak about sports (a pointwise constraint), and 50% of them to mention female characters (a distributional constraint). Additionally, we require p to have a minimal KL divergence D KL (p, a) from the original pretrained LM a. This has the effect that p now inherits favorable linguistic qualities from a. As we will explain, this formulation is a generalization of the Maximum Entropy Principle and leads to a unique solution P (x). P (x) is an unnormalized distribution, aka an Energy-Based Model (EBM) <ref type="bibr" target="#b16">(Hinton, 2002;</ref><ref type="bibr" target="#b26">LeCun et al., 2006;</ref><ref type="bibr" target="#b3">Bakhtin et al., 2020)</ref>, of which p(x) = 1/Z P (x) is the normalized version, where Z . = x P (x) is the partition function of P .</p><p>Computing the EBM representation P is a crucial step, as it fully determines the optimal distribution p we are looking for. However, it is not the end of the story, because the representation thus obtained does not enable us to directly sample from p, an essential property of any LM. <ref type="foot" target="#foot_1">2</ref> To this end, we introduce KL-adaptive DPG (Distributional Policy Gradient), a variant of an algorithm recently proposed in <ref type="bibr" target="#b36">(Parshakova et al., 2019b)</ref>. We train the policy π θ to approximate p in an adaptive way, by speeding up the next round of approximations based on approximations previously obtained. At the end of this process, we obtain a final π θ , our target LM, on which we can estimate diverse metrics, including D KL (p, π θ ), measuring the approximation quality of π θ relative to the optimal p, and D KL (π θ , a), measuring the divergence of π θ relative to the original LM a.</p><p>This two-step approach differs from much research in NLP-oriented work with EBMs, which tends to use EBM representations inside the training loops of neural networks, blurring different dimensions of the problem. By contrast -similarly to <ref type="bibr" target="#b35">Parshakova et al. (2019a;</ref><ref type="bibr">b)</ref> in a different context -we clearly decouple the relatively simple problem of determining a "pivot" optimal EBM from the more difficult problem of exploiting this EBM at inference time, Such decoupling is valuable, because it permits to better diagnose the important challenges to focus on.</p><p>Overall, our contributions can be summarized as follows:</p><p>1. We introduce a Distributional View for controlled text generation formalized as a constraint satisfaction problem combined with a divergence minimization objective, providing a single framework both for "distributional" constraints (collective statistical requirements) and for "pointwise" constraints (hard requirements on each individual) ( §2.1). To our knowledge, this is the first framework with such generality for controlled text generation.</p><p>2. We show how these constraints lead to an optimal EBM for the target model ( §2.2), propose the KL-Adaptive DPG algorithm for approximating the optimal EBM distribution by an autoregressive policy ( §2.3), and show the effectiveness of this adaptive technique for obtaining faster convergence ( §B.2).</p><p>3. We conduct experiments in a number of pointwise and distributional conditions, assessing results in terms of divergence from GPT-2, fluency and diversity, with better performance than strong baselines. The distributional experiments show the potential of our approach as a remedy to the current and important problem of bias in pretrained language models, providing a novel direction for addressing it ( §3).</p><p>Figure <ref type="figure">1</ref>: From MaxEnt to EBM through Information Geometry. The Generalized MaxEnt specification (left panel) is looking for a distribution p that lies on the moment constraints manifold C and that minimizes the forward KL DKL(p, a). The solution is provided by Information Geometry: (1) build the exponential family E determined by a and φ, (2) p lies at the intersection between C and E, (3) for any distribution c satisfying the constraints, the "Pythagorean identity" holds: DKL(c||a) = DKL(c||p) + DKL(p||a); in particular p is unique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FORMALIZATION</head><p>We denote by X the set of all sequences x of bounded length L max , by a the initial pretrained model and by p the desired target model. The probabilities of x according to each model are a(x) and p(x).</p><p>Our approach consists in expressing our desiderata through constraints on the desired values μi of the expectations (aka moments) µ i . = E x∼p φ i (x) of certain predefined real-valued feature functions φ i (x), for i ∈ {1, . . . , k}.</p><p>To illustrate, the previous example can be expressed by using two binary features, φ 1 (x) = 1 iff x is classified as speaking about sports, φ 2 (x) = 1 iff x mentions a female character. Then our "moment constraints" take the following form: µ 1 = E x∼p φ 1 (x) = 1.0, µ 2 = E x∼p φ 2 (x) = 0.5. The first (pointwise) constraint implies that each individual x has to speak about sports (otherwise µ 1 could not reach its maximum value 1.0), the second (distributional) constraint that 50% of the x's have to mention a female character. <ref type="foot" target="#foot_2">3</ref>Let C be the set of all distributions c over X that satisfy the moment constraints. We then propose to specify p as a distribution respecting the constraints, but also minimizing KL divergence from a: </p><p>Equation ( <ref type="formula" target="#formula_0">1</ref>) is a generalization of the Maximum Entropy Principle of <ref type="bibr" target="#b21">Jaynes (1957)</ref>, which corresponds to the limit case where a is the uniform u distribution over X, noting that minimizing D KL (c, u) is equivalent to maximizing the entropy of c under the constraints -in other words, trying to find the least "specific" distribution satisfying the constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">CONSTRAINTS, INFORMATION GEOMETRY, EXPONENTIAL FAMILIES</head><p>To recap our formal approach, we have a finite set X, a distribution a over X s.t. a(x) &gt; 0, ∀x ∈ X, and real functions φ 1 , ..., φ k over X. We specify moment constraints µ i = μi on distributions c over X, where µ i . = E x∼c φ i (x) and the μi 's are given targets; the set of distributions satisfying these constraints is denoted by C. Our Problem is to find a p such that p = arg min c∈C D KL (c, a).</p><p>We follow <ref type="bibr" target="#b12">Csiszár &amp; Shields (2004)</ref> on this question, a problem that is at the core of the field of Information Geometry <ref type="bibr" target="#b33">(Nielsen, 2018;</ref><ref type="bibr" target="#b0">Amari &amp; Nagaoka, 2000)</ref>. Under the assumption that C = ∅, they prove the following result (also see §A.1):</p><p>Theorem 1 (A) There exists a unique solution p to the problem above, obtained as p(x) ∝ P (x) where P is in exponential family form: x) .</p><formula xml:id="formula_1">P (x) = a(x) 1[x ∈ X C ] e i λiφi(</formula><p>(2)</p><p>In other words p(x) = 1/Z P (x), with Z = x∈X P (x); P is an unnormalized distribution, i.e. an EBM. Here X C = {x ∈ X| ∃c ∈ C s.t. c(x) &gt; 0} is the "support set" associated with C. The λ i 's are real numbers called the natural parameters associated with the moments µ i .</p><p>(B) p can be approximated to arbitrary precision by distributions p of the form: p (x) ∝ a(x) e i λ ,iφi (x)  (3)</p><p>for appropriate real values of the λ ,i . The advantage of this version of the connection between Generalized Maximum Entropy and Exponential Families is its generality, which distinguishes it from other presentations, and which makes it ideal for unified application to pointwise, distributional or hybrid constraints.</p><p>In the special case of only pointwise constraints, of the form E x∼c φ i (x) = 1.0, i ∈ [1, k], with φ i (x) ∈ {0, 1}, let's define the predicate b(x) to be 1 iff x satisfies all the constraints. Then, using the (A) form of the result, it is an easy exercise (see §A.2) to prove that X C = {x ∈ X| b(x) = 1} and that one has p(x) ∝ a(x)b(x). In this case P (x) = a(x)b(x) is a very simple EBM that does not involve an exponential part.</p><p>In the general case where some constraints are distributional, the determination of X C is not as direct, and we prefer to use the approximation provided by (B), which permits a generic implementation. With only distributional constraints, an exact solution is typically obtained with finite λ's. With hybrid constraints, some of the λ's may tend to infinite (positive or negative) values but thresholding them suffices to get a good approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">FROM MOMENT CONSTRAINTS TO EBM</head><p>Let's now consider a set of desired moment constraints μ. <ref type="foot" target="#foot_3">4</ref> In the general case, as mentioned in Theorem 1.(B), the desired energy-based model P can be approximated arbitrarily closely in the following form: φ(x) .</p><formula xml:id="formula_2">P (x) . = a(x)e λ•</formula><p>(4)</p><p>This EBM defines the desired normalized distribution p(x) . = P (x) Z , where Z . = x P (x). What is left is to learn appropriate values for the parameter vector λ s.t.:</p><formula xml:id="formula_3">E x∼p φ(x) μ.</formula><p>(5)</p><p>In order to address this problem, we sample a large number N of sequences x 1 . . . x i . . . N from a, define "importance weights" w i (λ) . = P (xi) a(xi) = exp λ, φ(x i ) , and estimate µ(λ)</p><p>. = E x∼p φ(x) by SNIS (Self Normalized Importance Sampling) <ref type="bibr" target="#b23">(Kim &amp; Bengio, 2016;</ref><ref type="bibr" target="#b34">Owen, 2013;</ref><ref type="bibr" target="#b35">Parshakova et al., 2019a</ref>) SNIS consists in computing:</p><formula xml:id="formula_4">μ(λ) = N i=1 w i (λ) φ(x i ) N i=1 w i (λ) ,<label>(6)</label></formula><p>and it can be shown that μ(λ) µ(λ), with convergence in the limit <ref type="bibr" target="#b34">(Owen, 2013)</ref>.</p><p>We then have to solve in λ the equation μ(λ) = μ, which we address by SGD over the objective min || μ − μ(λ)|| 2 2 . <ref type="foot" target="#foot_4">5</ref> At the end of this process, we obtain an estimated value for the parameters λ, and a representation P (x) = a(x) exp λ, φ(x) . While a(x) is a normalized distribution by construction, the introduction of the second factor loses this normalization property, making P (x) an EBM. <ref type="foot" target="#foot_5">6</ref>We finally note that in the special case of strictly pointwise constraints, we can exploit the simplification derived in the previous section, and obtain an EBM representation of the form p(x) ∝ P (x) = a(x)b(x), a shortcut we will use in the strictly pointwise experiments.<ref type="foot" target="#foot_6">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">FROM EBM TO AUTOREGRESSIVE POLICY</head><p>The EBM representation just obtained for P defines the optimal p = Z −1 P unambiguously, a crucial intermediate step in the solution of our problem. From it we can immediately compute ratios of the form p(x)/p(x ) for two sequences x, x , but without knowing Z, we cannot compute p(x) and, even with such a knowledge, we cannot produce samples from p. This problem is typical of EBMs at large: they provide a rich and flexible mechanism for specifying models, but they leave a gap between representation and exploitation. A range of techniques, from sophisticated MCMC approaches (especially for continuous models in vision) to contrastive learning techniques, have been developed for bridging this gap.</p><p>One technique that is suitable for our objective here, namely sampling from a sequential EBM that includes an autoregressive component a(x), is the DPG ("Distributional Policy Gradient") algorithm <ref type="bibr" target="#b36">(Parshakova et al., 2019b)</ref>. The objective of DPG is to obtain an autoregressive policy π θ that approximates p, where approximation is formalized in terms of making the cross-entropy CE(p, π θ ) = − x p(x) log π θ (x) as small as possible. <ref type="foot" target="#foot_7">8</ref> DPG exploits the fact that, for any "proposal" distribution q whose support contains the support of p, we have</p><formula xml:id="formula_5">∇ θ CE(p, π θ ) = −∇ θ E x∼p p(x) log π θ (x) = −E x∼p p(x)∇ θ log π θ (x) = −E x∼q p(x)</formula><p>q(x) ∇ θ log π θ (x), where the last equality is an instance of importance sampling.</p><p>Algorithm 1 KL-Adaptive DPG Input: P , initial policy q 1: π θ ← q 2: for each iteration do 3: for each episode do 4: sample x from q(•) 5:</p><p>θ ← θ+α (θ) P (x) q(x) ∇ θ log π θ (x) 6:</p><p>if DKL(p||π θ ) &lt; DKL(p||q) then 7:</p><p>q ← π θ Output: π θ Our "KL-adaptive" version of DPG is shown in (Algorithm 1). We start from an input EBM P , along with an initial policy q which is a proxy to p; in our case we take q = a. During an iteration (think minibatch or set of minibatches), we sample a number of sequences from q, do an SGD update of θ (line 5), where P is used instead of p (noting that they only differ by a multiplicative constant), and where α (θ) is a learning rate. The efficiency of the algorithm is related to how close the proposal q is to the target p, <ref type="foot" target="#foot_8">9</ref> The algorithm is adaptive in the sense that it modifies q periodically to take advantage of the evolving approximations π θ . On line 6, we we test whether the current π θ is closer than q to p in terms of KL-divergence, and if so we update q to π θ on line 7.<ref type="foot" target="#foot_9">10</ref> §B.2 provides an ablation study showing the effectiveness of this adaptive step for obtaining faster convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS, RESULTS, AND EVALUATION</head><p>In this section we describe our evaluation methodology and perform experiments on pointwise constraints ( §3.2) and on distributional and hybrid constraints ( §3.3). The Appendix contains a detailed view of evaluation ( §H), comparison with extra baselines ( §D.2), and an ablation study ( §B.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">EVALUATION METRICS</head><p>The main metrics we report are: (1) E x∼π θ φ i (x), assessing the ability of π θ to reach the expectation goal on the i-th constraint, (2) D KL (p||π θ ), the forward KL divergence from the optimal distribution (which should be as close to 0 as possible), (3) D KL (π θ ||a), the reverse KL divergence from the original GPT-2; for details on the estimation of these metrics see §B.1. Previous work has mostly focused on the diversity of each individual output using Dist-1,2,3 scores <ref type="bibr" target="#b27">(Li et al., 2016a)</ref> to measure repetitions within a single generated sequence. However, the shortcomings in terms of sample diversity, of optimization techniques when training generative models for text, has recently been documented in <ref type="bibr" target="#b8">(Caccia et al., 2020)</ref>. So additionally, we report Self-BLEU-3,4,5 <ref type="bibr" target="#b60">(Zhu et al., 2018)</ref> to measure repetitions at a distributional level across the whole set of generated samples, and also provide a token/type frequency analysis (see Fig. <ref type="figure" target="#fig_3">4</ref> and §H.4). Note that KL divergence from the original GPT-2 also implicitly captures sample diversity: a distribution that focuses all its probability mass on a few sequences typically displays high divergence from GPT-2. Implementation details and hyper-parameters are available in the Appendix ( § F).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">POINTWISE CONSTRAINTS EXPERIMENTS</head><p>Pointwise constraints are of the form E p φ i (x) = 1, with φ i a binary feature. Contrarily to distributional constraints, they can be directly associated with a "reward", namely φ i itself. RL-inspired baselines can then be introduced naturally, and this is what we do here.</p><p>Single-Word constraints: Here we constrain the presence of a specific word w in the generated text i.e. φ(x) = 1 iff w appears in the sequence x. We use 9 single-word constraints of different rarity levels: "US" (original frequency: 7•10 −3 ), "China" (4•10 −3 ), "Canada" (2•10 −3 ), "amazing" (1•10 −3 ), "Paris" (5•10 −4 ), "restaurant" (6•10 −4 ), "amusing" (6•10 −5 ), "Vampire" (9•10 −5 ), "Wikileaks" (8•10 −5 ). Word-list constraints: We use 4 different word lists among those proposed in <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref>, covering the following topics: "kitchen", "fantasy", "politics", and "computers". We set φ l (x) = 1 if x contains at least one one word from the word list l. Classifier-based constraints: We use pre-trained classifiers from <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref>, which consist of a linear head on top of GPT-2. We select 4 classes and define corresponding pointwise constraints: "very positive", "positive", "very negative" and "Clickbait". See §F for details on constraint computations. Baselines: We compare our method GDC to three baselines: (1) REINFORCE <ref type="bibr" target="#b56">(Williams, 1992b)</ref>, using the reward φ(x), i.e. trying to maximize E π θ φ(x); (2) REINFORCE P(x) : Reinforce again, but now using the reward P (x) based on our energy model P , i.e. maximizing E π θ P (x); this baseline starts from the same optimal EBM P representation as GDC but with a standard optimization objective rather than a distributional one; in other words, while GDC tries to get a similar sampling distribution to p, this baseline tries to get sequences of maximal probability p(x). (3) ZIEGLER <ref type="bibr" target="#b61">(Ziegler et al., 2019)</ref>: an approach relying on the RL Proximal Policy Optimization (PPO) algorithm <ref type="bibr" target="#b45">(Schulman et al., 2017)</ref> and which tries to maximize the objective E π θ φ(x) − βD KL (π θ , a), which interpolates the reward φ(x) with a KL-divergence penalty from the pretrained model, but where the goal is not explicitly to satisfy a constraint; for a geometric illustration of the differences with GDC see §D.1. §D.2 provides a comparison of GDC with two additional baselines.</p><p>Results: Figure <ref type="figure">2</ref> shows the evolution of the metrics over training steps, aggregated across the 9 + 4 + 4 = 17 experiments. We observe the following: the baseline REINFORCE , which does not have any explicit link in its objective to the pretrained GPT-2, converges very early in the training, reaching a maximum value of E π θ φ(x) at the expense of a very large deviation from the original GPT-2. High values of D KL (π θ |a), are translated into low Dist-1 and very high Self-BLEU-5 indicating degeneration and lack of diversity. REINFORCE P(x) maximizes the energy model P by In the case of ZIEGLER we can see a positive effect of the interpolation factor β between the reward and the KL penalty in the objective function. In the aggregated experiments reported here, the reward is slightly better than with GDC, but with inferior diversity scores (see also Fig. <ref type="figure" target="#fig_3">4</ref>, showing that GDC produces richer vocabulary), and the stability is much worse (a detailed view of each experiment is provided in §H, showing more clearly the instability of this baseline). A complementary evaluation is provided by Figure <ref type="figure">3</ref>, focusing on the ability of π θ to converge to the optimal distribution p. We see that GDC is superior to all baselines in terms of D KL (p π θ ) and also much more stable.</p><p>In summary, in these experiments, we see that with GDC the constraint expectation E π θ φ(x) smoothly increases while π θ maintains the lowest divergence from GPT-2, becomes closest to the optimal p, and has the best diversity scores overall. On the other hand, we also note that at the point where we stop training (30K steps), the average over experiments of E π θ φ(x), while still increasing, does not reach 100%, an issue that we discuss at the end of the paper ( §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">DISTRIBUTIONAL AND HYBRID CONSTRAINTS EXPERIMENTS</head><p>As formalized in §2, GDC permits to define pointwise and distributional constraints as well as any mix between them. This unique feature makes it very suitable to remedy biases that the text generation model may have, a problem identified in several previous works <ref type="bibr" target="#b48">(Sheng et al., 2019b)</ref>. We employ GDC to balance gender and profession distributions across biographies generated by a GPT-2 model fine-tuned on Wikipedia Biographies <ref type="bibr" target="#b25">(Lebret et al., 2016)</ref> (henceforth GPT-2 bio ) ( §G gives additional details). The bias in GPT-2 bio is significant: we calculated that this model generates only around 7% female biographies. It also displays a large imbalance between professions related to "Science" (1.5%), "Art" (10.0%), "Business" (10.9%) and "Sports" (19.5%).</p><p>Experiment 1: Single Distributional Constraint We use the distributional constraint E x∼p φ f emale (x) = 0.5; GDC is able to reduce the bias of GPT-2 bio to obtain 35.6% female biographies rather than only 7.4% (see Fig. <ref type="figure">5</ref> for this experiment and the next ones).  Experiment 2: Multiple Distributional Constraints We then test our framework with several distributional constraints of different values and control directions. We specify four distributional constraints all at once with the goal of increasing the expectations of "science" and "art" to 40% and decreasing those of "sports" and "business" to 10%. GDC is able to increase the expectations of the first two professions respectively from 1.5% to 20.3% and from 10 to 31.6% and to decrease those of "business" and "sports" respectively from 10.9% to 10.2% and from 19.5% to 11.9%, reaching expectations close to the desired ones for all features using a single training method. Experiments 3,4,5,6: Hybrid Constraints Here we want to de-bias the model as in the previous case but we single out biographies of scientists, artists, etc. Formally, our requirements become E x∼p φ prof ession (x) = 1.0, a pointwise constraint, and E x∼p φ f emale (x) = 0.5, a distributional constraint. In those 4 hybrid experiments we can clearly see that GDC can address both pointwise and distributional constraints increasing each simultaneously with just the right amount to reach the desired expectations. Appendix §G further elaborates Fig. <ref type="figure">5</ref> (convergence curves). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>Our approach to controlled text generation is distinguished by its breadth -the first one to handle distributional along with pointwise constraints, with applications to the important problem of Bias in pretrained LMs -and by the transparency of the supporting formalism. It decouples the training objective along two different dimensions. The first consists in solving the initial constraints specification, and leads through a direct algorithm to an optimal solution in EBM format. The second, where the real computational difficulty lies, consists in approximating this EBM with an autoregressive policy for use at inference time.</p><p>Sampling from an EBM is an important, hard, and well-identified challenge in the literature.</p><p>Our approach there consists in proposing a KL-adaptive version of the DPG algorithm, which exploits ascertained improvements of the trained policy to speed up convergence. This is an effective method for rare events, as we show in an ablation study ( §B.2). In the case of pointwise constraints, where comparisons with baselines can be done, our experiments show the method's superiority in satisfying the constraints while avoiding degeneration. Reaching close to 100% samples meeting the constraints, can sometimes be obtained in these baselines, but only at a severe cost in terms of quality and sample diversity. Of course, if we do not care about such aspects, obtaining 100% constraint satisfaction is trivial: just generate one sentence satisfying the pointwise constraint! Our method does not suffer from degeneration, but our end policies still generate a number of samples not satisfying the constraints. A possibility, left for future work, might consist in filling the moderate residual gap with MCMC techniques, which would be guaranteed to reach our optimal p in the limit. We do not go this route here, but conduct an experiment (see §C) to better understand the nature of the problem. In the simple case of a single-word constraint (x includes "amazing"), we sample directly 1M samples from GPT-2 and keep the roughly 5K samples containing amazing (a variant of rejection sampling, taking two processing days). We then do a standard supervised fine-tuning of GPT-2 with these samples, stopping training when the CE validation loss starts to increase, and observe that this model exhibits a worse constraint satisfaction rate than ours. This experiment does not mean that a much larger fine-tuning dataset, obtained in this slow, non-adaptive way, would not reach better statistics, but it raises doubts about the ability of the GPT-2 architecture to fine-tune over such a non-standard constraint as containing a given word somewhere in its output.</p><p>Overall, we believe that the proposed decomposition into two sub-problems is a methodological advantage compared to most other works, which directly aim at training a policy with the goal of improving certain evaluation metrics, but without clearly defining what qualifies as an optimal solution. The computational challenge of fully bridging the gap between the optimal EBM and an efficient sampling engine remains, and we hope that the formalism we propose, along with initial applications and experimental validations, will motivate further research along these lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>A DETAILS ON FORMALIZATION ( §2)</p><p>A.1 COMMENTS ON THEOREM 1</p><p>Our statement of Theorem 1 is actually a reformulation of two results in section 3 of <ref type="bibr" target="#b12">Csiszár &amp; Shields (2004)</ref>. Our property (A) is a simple notational transposition of their Remark 3.1 (p. 444). Property (C) is the Pythagorean Identity in their Theorem 3.2 (p. 442). Property (B) reformulates the last part of the same Theorem "... and in general L ∩ cl(E Q ) = {P * }" in terms of a limit of a sequence of distributions.</p><p>Note: <ref type="bibr" target="#b12">Csiszár &amp; Shields (2004)</ref> assume a finite X here, but generalizations to infinite (countable and/or continuous) X spaces are possible, see <ref type="bibr">(Csiszar, 1975)</ref>.</p><p>A.2 THE CASE OF POINTWISE CONSTRAINTS IN §2.2</p><p>In the case of purely pointwise constraints, if b</p><formula xml:id="formula_6">(x) = 1, then the distribution c = δ x is in C, hence x ∈ X C . Conversely, if x ∈ X C then there is some c ∈ C such that c(x) &gt; 0, implying that b(x) = 1. Hence X C = {x ∈ X| b(x) = 1}. Thus, in equation (2), P (x) = a(x)b(x) exp i λ i φ i (x); but for b(x) = 0, φ i (x) = 1</formula><p>, so the exponential factor is a constant, which proves that P (x) = a(x)b(x) is proportional to P (x), and therefore p(x) ∝ P (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 INCREMENTALLY ADDING NEW CONSTRAINTS</head><p>An interesting question<ref type="foot" target="#foot_11">12</ref> is whether the process explained in §2 can be made incremental: if one has already computed a p and a π θ relative to a certain number of constraints, can one add a new constraint without restarting the whole process from scratch? The answer is yes, and here we provide some formal elements to understand why.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.1 TRANSITIVITY PROPERTY OF GENERALIZED MAXENT</head><p>According to <ref type="bibr" target="#b11">(Csiszár, 1996)</ref>, the Generalized MaxEnt of sections §2.1 and §2.2 has the "Transitivity property". In our notation, this says that if we have k &gt; k constraints, with C the manifold of distributions respecting only the first k constraints, C the manifold respecting all k constraints (hence C ⊂ C), then the maxent projection p of a onto C can be obtained by first projecting a onto C, obtaining p, and then projecting p onto C , obtaining p . In particular, the k lambdas associated with p can be directly reused as the first lambdas of the k lambda's associated with p . <ref type="bibr" target="#b11">(Csiszár, 1996)</ref> gives only a minimal proof sketch, but it is instructive to provide the details, as we do now, because the proof is a neat illustration of the power of information geometry for problems of the kind we consider. The proof, illustrated in Figure <ref type="figure" target="#fig_4">6</ref>, is very similar to one of the proofs for the transitivity of the orthogonal projection in Euclidean geometry. As c is an arbitrary point of C , this proves that r is the projection of a onto C , in other words, r = p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.2 TRANSITIVITY AND AUTOREGRESSIVE POLICY</head><p>Due to the Transitivity property, when calculating the EBM representation, it is possible to start from p without re-fitting p from scratch. However the move from EBM to autoregressive policy of §2.3 remains to be discussed. The question now is the following. We have already obtained a policy π θ approximating p, and we are interested in obtaining a policy π θ approximating p : is it advantageous to start Algorithm 1 with q = π θ , rather than starting "from scratch" and taking q = a ? Intuition says "yes, very probably", because π θ is by construction an approximation to p, which is closer than a to p (formally, D KL (p , p) ≤ D KL (p , a), see Fig. <ref type="figure" target="#fig_4">6</ref>, where p = r). Due to the approximation, we only have D KL (p , π θ ) D KL (p , p) , so a formal proof that π θ is superior to a as a starting point is impossible, but we expect that further experiments would confirm the improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B MORE ON ADAPTIVITY B.1 DETAILS ON KL-ADAPTIVITY</head><p>In this section we provide details on the comparison step in our KL-Adaptive version of the DPG Algorithm, introduced in section 2. We want to assess whether the current π θ is closer than q to p, and if the test is positive, we set π θ as the new proposal, hoping to make the proposal more effective for importance sampling.</p><p>There are several ways to compute similarity between distributions, two of the most popular ones being on the one hand KL-divergence and on the other hand Total Variation Distance (TVD)where TVD(p||p ) . = 1/2 x |p(x) − p (x)| -which is often used in probability and MCMC theory. <ref type="foot" target="#foot_12">13</ref> Calculation of these metrics relative to p is not straightforward since the distribution p ∝ P is only implicitly represented by the unnormalized EBM P , and we cannot easily obtain direct samples from p. In this section we describe a workaround.</p><p>Given P and a proposal distribution q that we can sample from, using importance sampling <ref type="bibr" target="#b34">(Owen, 2013)</ref>, one can calculate the partition function Z as follows:</p><formula xml:id="formula_7">Z = x P (x) = x q(x) P (x)/q(x) = E x∼q(x) P (x)/q(x) (7)</formula><p>We can then compute D KL (p||π) as:</p><formula xml:id="formula_8">D KL (p||π) = x p(x) log p(x) π(x) = x p(x) log P (x) Zπ(x) = − log Z + x p(x) log P (x) π(x) = − log Z + x q(x) p(x) q(x) log P (x) π(x) = − log Z + 1/Z E x∼q(x) P (x) q(x) log P (x) π(x)<label>(8)</label></formula><p>Similarly, for TVD(p||π):</p><formula xml:id="formula_9">TVD(p||π) = 1/2 x |p(x) − π(x)| = 1/2 x q(x) π(x) q(x) − p(x) q(x) = 1/2 x q(x) π(x) q(x) − P (x) Z q(x) = 1/2 E x∼q(x) π(x) q(x) − P (x) Z q(x)<label>(9)</label></formula><p>In §B.2 we run an ablation study to compare the use of D KL on line 6 of Algorithm 1) or its replacement by TVD.</p><p>For both metrics, we need an estimate of Z. The precision of this estimate depends on the sample size and the quality of the proposal distribution q. We calculate a moving average estimate Z MA of Z is used inside the estimations of D KL (p π θ ) and D KL (p q) (Algorithm 2, lines 7 and 8). Z MA is updated at each iteration of the training, and the moving average estimate is valid due to the fact that Ẑi , based on K samples, is an unbiased estimate of Z, and therefore so is Z MA . In this way, the estimate benefits from all the samples being produced during the course of the training; and also because the proposal distribution q evolves and gets closer to the target distribution p, the quality of the estimates of both D KL (p||π θ ) and Z MA through importance sampling increases (equation 7). A similar approach is taken in the case of TVD (not shown).</p><p>Algorithm 2 KL-Adaptive DPG (detailed)</p><p>Input: P , initial policy q 1: π θ ← q 2: ZMA ← 0 Initialize Moving Average estimate of Z 3: for each iteration i do 4:</p><formula xml:id="formula_10">for each step k ∈ [1, K] do 5: sample x k from q(•) 6: θ ← θ + α (θ) P (x k ) q(x k ) ∇ θ log π θ (x k ) 7: Ẑi ← K −1 k P (x k )/q(x k ) Estimate on the K samples 8: ZMA ← i * Z MA + Ẑi i+1</formula><p>Update moving average estimate of Z</p><formula xml:id="formula_11">9: DKL(p||πθ) ← − log ZMA + (K ZMA) −1 k P (x k ) q(x k ) log P (x k ) π θ (x k )</formula><p>Estimate on the K samples 10:</p><formula xml:id="formula_12">DKL(p||q) ← − log ZMA + (K ZMA) −1 k P (x k ) q(x k ) log P (x k ) q(x k )</formula><p>Estimate on the K samples 11: if DKL(p||πθ) &lt; DKL(p||q) then</p><formula xml:id="formula_13">12: q ← π θ Output: π θ B.2 ABLATION ON ADAPTIVITY</formula><p>Here we run an ablation experiment on the adaptivity step of KL-Adaptive DPG ( §2). We compare three variants of our proposed method: DPG-KLD, which uses KL divergence from the target distribution p to measure the quality of the trained policy π θ i.e. if D KL (p π θ ) &lt; D KL (p q) we update the proposal distribution q ← π θ . DPG-TVD is similar but with the total variation distance instead (TVD). In non-Adaptive the initial proposal q is kept fixed during training.</p><p>We run 3 point-wise experiments with single word constraints of three rarity levels in the original GPT-2 distribution, namely: "Vampire" (1/10 4 ),"Paris" (1/10 3 ),"US" (1/10 2 ) .For each we use 3 different seeds and train for 10k gradient updates.</p><p>Figure <ref type="figure">7</ref> shows training trends of the three ablations. We find a significant difference in convergence speed in favour of the adaptive methods. The efficiency gap between Adaptive and non-Adaptive methods becomes larger the more rare the constraints are. i.e. the proposal distribution q starting point is very far from the target distribution p, as the efficiency of the DPG algorithm is related to how close the proposal q is to the target p. When q is continuously adapted, the proposal distribution becomes closer to p and the training becomes efficient regardless of how far the initial proposal distribution is from p. We observe similar convergence rates for DPG-KLD and DPG-TVD. Figure <ref type="figure">7</ref>: Ablation experiment elaborating the effectiveness of the adaptive step in the DPG algorithm explained in section 2. We compare three adaptivity variants, based on the KL divergence (DPG-KLD), on the TVD distance (DPG-TVD) and with no adaptation. We find similar convergence rates for both KLD and TVD adaptive DPG compared to a much slower convergence without adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C CAN STANDARD SUPERVISION FULLY SATISFY THE CONSTRAINTS?</head><p>In this section, we try to better understand potential difficulties of autoregressive models to fully satisfy constraints such as the ones illustrated in our pointwise experiments.</p><p>To this end, we consider whether a standard fully supervised fine-tuning of GPT-2 can achieve that objective while keeping a minimal distance from the initial model. To answer the question, we carry out an experiment where we fine-tune GPT-2 on a collection of samples satisfying the desired constraint. Our goal here is to investigate whether GPT-2 can fully satisfy the constraint without overfitting the fine-tuning data, since overfitting (memorizing) the training data basically means high KL-divergence from the initial model.</p><p>For this experiment, we choose a single-word constraint with the word "amazing". We start by sampling 1M sequences from GPT-2 small -a process that took us roughly 48 hours -and keeping only the ones containing "amazing" (this filtration process can be seen as a variant of rejection sampling <ref type="bibr" target="#b9">(Casella et al., 2004)</ref>). We end up with a total of 4600 samples out of which we use 500 for validation and the rest for fine-tuning.</p><p>Figure <ref type="figure">8</ref> shows evolution of both validation loss and constraint satisfaction Eφ(x) on samples generated from the model during fine-tuning. Interestingly, the lowest validation loss corresponds to only Eφ(x) ≈ 0.56. Higher values of Eφ(x) correspond to higher validation loss i.e. to overfitting.</p><p>This result suggests a relationship between training a policy reaching 100% and overfitting the training data. This hints at the difficulty of strictly imposing certain types of constraints on pre-trained language models without moving far away from the initial model.<ref type="foot" target="#foot_13">14</ref>  Figure <ref type="figure">8</ref>: Supervised experiment when fine-tuning GPT-2 on a corpus of sentences containing the word "amazing". Left: validation loss development during fine-tuning. Right: percentage of samples generated using the fine-tuned model and containing the word "amazing". Here, the best model according to the validation loss is only able to achieve Eφ(x) = 0.5625. Higher values of Eφ(x) tend to occur with higher validation loss, i.e when overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D MORE COMPARISONS D.1 ILLUSTRATION COMPARING GDC, REINFORCE, AND ZIEGLER</head><p>The figure below illustrates the difference between GDC, the RL-based REINFORCE and ZIEGLER baselines for a pointwise constraint. The main points to note are: (1) REINFORCE is trying to find a distribution p R maximizing r(x) (meaning that p R lies on the C manifold), but this p R is free to land anywhere on this manifold, and (2) ZIEGLER is trying to find a distribution p Z that interpolates (with a weight β) between a high average r(x) and the KL divergence from a; unless β = 0, in which case we are back to REINFORCE, p Z does not satisfy the constraint and falls outside of the manifold. The curved lines represent increasing levels of the KL divergence DKL(q, a). According to Reinforce, any distribution pR s.t. Ex∼p R r(x) = 1, that is, any distribution on C, is optimal. According to Ziegler, to each temperature β &gt; 0 is associated an optimal distribution pZ = arg min q βDKL(q, a) − Ex∼qr(x), which does not lie on C. Our own optimal p is the distribution of minimal DKL that lies on C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 COMPARISON AGAINST FURTHER BASELINES</head><p>Here we compare GDC to other baselines, namely Plug and Play (PPLM) <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref> and <ref type="bibr">CTRL (Keskar et al., 2019)</ref> for sentiment control. PPLM works by updating the hidden states of GPT-2 for a given prefix in order to derive the generation towards the desired attributes. Unlike GDC, PPLM needs a prefix to perform its hidden-state updates. Thus, our approach is more general in the sense that any prefix can be used on the trained model at test time, rather than requiring prefix-specifc fine-tuning. CTRL is a large-scale language model (1.63 billion parameters and ~14x larger than GPT-2 small) based on control codes for steering text style and content. For the purpose of generating positive/negative sentiments using CTRL, we use its positive/negative reviews control codes as done in <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref>. The control codes used are "Reviews Rating: 5.0" and "Reviews Rating: 1.0" for positive and negative sentiment control, respectively. We use five different prefixes (or prompts) and generate 100 continuations given each prefix obtaining a total of 500 samples. It is worth noting that GDC is trained in the same way as described in the main text, i.e. without any knowledge of prefixes, and that we only use prefixes at test time with the saved checkpoint. The five prefixes used come from <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref>: "The chicken ", "The potato ", "The lake ", "The pizza ", and "The horse ".</p><p>We use the same sampling parameters across all approaches by setting the temperature T = 1.0, using top-k sampling with k = 10, and removing the repetition penalty used in CTRL <ref type="bibr" target="#b22">(Keskar et al., 2019)</ref>. However, we notice that CTRL does not work well with higher T values (apparent in the samples in Table <ref type="table" target="#tab_2">2</ref>), therefore we report also CTRL evaluation with lower temperature T = 0.5 and a repetition penalty λ rep = 1.2 as reported in their paper.</p><p>As metrics, we use sentiment class expectation Eφ(x), the perplexity according to an external GPT-2 small architecture as in <ref type="bibr" target="#b29">(Li et al., 2018)</ref>, and the diversity metrics introduced in section §3.1. We average all these metrics across the 500 continuations generated. Table <ref type="table" target="#tab_2">2</ref> shows the results for positive and negative sentiment control experiments. As shown, GDC is able to achieve better positive/negative sentiment with lower perplexity than both PPLM and CTRL. As for diversity, GDC achieves comparable diversity to the other two approaches and even outperforms PPLM on the Distn metrics in the positive sentiment task.</p><p>Table <ref type="table" target="#tab_3">3</ref> shows sample continuations from all three approaches. Clearly, PPLM and CTRL exhibit some form of degeneration and repetition in many of the continuations (highlighted in light red), which is reflected in their very high perplexity score compared to GDC, which produces much more natural text with minimum repetitions without requiring a repetition penalty as CTRL.</p><p>It is also worth noting here that CTRL (and other control code methods) is very much limited in terms of its applications. For instance, to generate positive/negative sentiment text as we do in this experiment, we are required to use the ''Reviews Rating...'' control code, using control codes outside of those CTRL was fine-tuned on leads to very bad generations. This, in turn, restricts the generated text to positive/negative reviews although we may desire different types of positive/negative text (e.g. news reports). We can observe this effect<ref type="foot" target="#foot_14">15</ref> in some of the samples in Table <ref type="table" target="#tab_3">3</ref> such as "The chicken we just ordered from Amazon.com..." and "The pizza works no matter what settings you use it on.  <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref> and CTRL (Keskar et al., 2019) on positive and negative sentiment control. We generate 100 samples for each prefix obtaining a total of 500 samples. All metrics shown are averaged across the 500 samples obtained. CTRL refers to the shared setting across all approaches with temperature T = 1.0 and repetition penalty λrep = 1.0 and CTRL* refers to having T = 0.5 and λrep = 1.2. Here, we see a clear advantage of GDC in terms of constraint satisfaction and perplexity and a comparable performance in terms of diversity against PPLM and CTRL.</p><formula xml:id="formula_14">Method Eφ(x)↑ Perplexity ↓ Dist-1 ↑ Dist-2 ↑ Dist-3 ↑ SB-3 ↓ SB-4 ↓ SB-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GDC</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive</head><p>The chicken is so tasty! This recipe has been in my freezer for about 2 months now. I have always had good quality chicken breasts, so I had a huge amount of chicken and The potato is my favourite part of the recipe, and it is also my biggest problem. It is a good addition to anything you try to add to your meal. I love potato soup The lake has been the most active place in the country for visitors since it opened last summer, and it's not hard to see why.</p><p>The lake has been a place to stay for years, The pizza place is great for a good time! They have all kinds of amazing sandwiches. My favorite sandwich is the "Chicken Pizza" which is the best I've ever had on my way to I don't think the pizza is better than any other pizza. It's not a The horse is very well balanced with the horse's head and ears. It is a great horse to have for the family. The horse is quite large and the tail is long enough to accommodate the",</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Negative</head><p>The chicken is so bad it's literally going to die. It's like the dog is dying from a bad diet. I'm not even sure I want it in my kitchen"</p><p>The potato was really bad, but it's the worst potato that I've ever tasted. It was really hard for me to put my finger on. I was very disappointed with the flavor of the The lake was just too cold for the water and the wind to blow. I couldn't get out of it. I couldn't see anything. The wind blew through my windshield and my car windshield"</p><p>The pizza is so bad that I've had to buy it again, even if I was just going to order one at a time. I'm not going to be buying one for the next week The horse in the back row is not going to win the race. It is going to go up in flames, and the race will end in a heap of dust. The winner will be thrown</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PPLM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive</head><p>The chicken and the egg story: the extraordinary rise of the powerful man as he transforms the lives of ordinary people in a world in crisis The story of the A man dressed in a white suit The potato. It is the world's most awesome people, and and and the that the the a the a the a the a the a the a the , "and the the The lake is a great spot to enjoy the spectacular views of the Great Lakes. This is also a great place to take the children's swim. The lake is also a great place to hike in the beautiful mountains The pizza is a delight! I have never had this before. I am a fan of Italian, and I have not had it before in the States. I will be back! It was a great experience The horse is a powerful, beautiful, and extremely intelligent animal., (.C,:,.,.,../.../..',,' (., ".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Negative</head><p>The chickenpox epidemic of 1918-1920 in Britain was an acute and deadly disease that killed about 100,000 people worldwide, most of them infants. The 1918-1919 epidemic was caused by the The potato is one of those things we all dream of. I think the most common thing that people come up with when I say I have the perfect one is the idea of a "salt water" version The lake is one one one. &lt;endoftext&gt;The United Nations (UN) and the European Union (EU) are among a number of the world's most in the state and,, on the House vote for The pizza crust is anvil, which is what the British have for a long time. The British Empire, the French, the the the the the a in the that is a a it is called and it The horse is in the saddle. That's how he's been for the last four years. The Tampa Bay Lightning won a series of three games in a row to begin the new year and into January we were</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CTRL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Positive</head><p>The lake I am looking forward to seeing in September! The sea scene alone would have me watching again! Rating: 5.0 One of the best comedies I've seen. We will definitely watch it again. Smart and funny The horse for this ones lines is:&amp;#34;The road to Hell is paved with good intentions. All roads to Hell end in Hell themselves.&amp;#34; Rating: 5.0 I live in a small The potato were "seeded" during a European settlement. What the characters have gone through is inevitable, but extremely rare. (And the potato has the honor of being the world's oldest potato. For that honor, we have a nickname: "@@ The chicken we just ordered from Amazon.com has not yet arrived and I am EXTREMELY EXCITED! The seller has the finest poultry in the market....plus, it is DELICIOUS!Thank you so The pizza has been around for decades. Now that time has been added to it, all of us can appreciate it better, and enjoy it the way we have always enjoyed.PERFECT Pie:(The second listen) And it</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Negative</head><p>The pizza works no matter what settings you use it on. The icecream maker always leaks out around the spout and onto the base (gross) -finally stopped working. I only wish I had spent more for a The horse can not be found. Characters whose names show up in the battle screen:EXE: SRMX&amp;OY; SQX the knight ¿QWOKB SKOZY the warrior!A useful upgrade for a The lake has been made, but it's far from Earth 5. The ship has disappeared but they continue to radio.Ignoring the plot, which the Star Trek series never bothered with, Spock says that "we should have followed up. There is The chicken died on me after 8 months. I don't think the unit is compatible with young chickens. Not recommended. Rating: 1.0 the plates didn't last long enough for me.I bought two of these plates and they The potato does not start from eggplants, it starts from the start of generation! How stupid is that! :( I bought this and many others to try with my toddler for his preschool class. I want him to get </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E RELATED WORK EXTENDED</head><p>Optimizing global rewards for Text Generation There is a large reinforcement learning inspired literature about steering an autoregressive sequential model towards optimizing some global reward over the generated text. This includes REINFORCE <ref type="bibr" target="#b55">(Williams, 1992a)</ref> for Machine translation (MT) Ranzato et al. ( <ref type="formula">2016</ref>), actor critic for Abstractive Summarization <ref type="bibr" target="#b2">(Bahdanau et al., 2017)</ref>, Image-to-Text <ref type="bibr" target="#b31">Liu et al. (2016b)</ref>, Dialogue Generation <ref type="bibr" target="#b28">Li et al. (2016b)</ref>, and Video Captioning <ref type="bibr" target="#b37">(Pasunuru &amp; Bansal, 2017)</ref>. With respect to rewards, some approaches for Machine Translation and Summarization <ref type="bibr" target="#b43">(Ranzato et al., 2016;</ref><ref type="bibr" target="#b2">Bahdanau et al., 2017)</ref> directly optimize end task rewards such as BLEU and ROUGE at training time to compensate for the mismatch between the perplexity-based training of the initial model and the evaluation metrics used at test time. Some others use heuristic rewards as in <ref type="bibr" target="#b28">(Li et al., 2016b;</ref><ref type="bibr" target="#b52">Tambwekar et al., 2019)</ref> Competing Degeneration in Controlled Text Generation When using such approaches, one needs to take care of not forgetting too much of the original LM policy ("degeneration"): Liu et al. KL Divergence penalty Another approach relied on penalizing too large deviations of the trained policy relative to the original policy. <ref type="bibr" target="#b19">Jaques et al. (2017;</ref><ref type="bibr">2019)</ref> propose a conservative fine-tuning approach with a KL penalty between the trained policy and the original auto-regressive model. This penalty acts as a regularizer to the optimization process that prevents the trained policy from deviating too much from the original policy. Ziegler et al. ( <ref type="formula">2019</ref>) follow a similar approach for fine tuning a language model based on human preferences, in this case a proximal policy algorithm <ref type="bibr" target="#b45">(Schulman et al., 2017)</ref> is used to maximize the combined reward. PPLM <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref>, this time in a plug-and-play rather than a fine-tuning context, also use KL divergence to penalize deviations from the initial policy.</p><p>Pointwise vs. Distributional View Most of the existing work on Controlled Generation have taken what we have called a pointwise view: focusing on the quality of each individual output, as opposed to distributional properties of the collection of all outputs. And in fact, the standard objective of RL is to optimize a pointwise reward. Even when policy-gradient methods do consider distributions over outputs, they only do as a tool towards producing maximal rewards; and in fact, it is a side effect of the limited capacity of the policy networks that such distributions do not peak on a single output, as would be the optimal outcome in cases of real-valued rewards with no ties. <ref type="foot" target="#foot_15">16</ref> By contrast to this usual optimization "intent", our own intent here is explicitly distributional, and the policies we are looking for are not simply tools towards maximizing scores, but actual objectives in their own right.</p><p>Such a change of perspective might be argued against in the case of conditional seq2seq problems, such as Machine Translation, where focusing on a single good output for a given input makes sense, but is clearly in-adapted when focusing on language models where sample diversity is a requirement.</p><p>Energy Based Models for Text Energy-Based Models (EBMs) <ref type="bibr" target="#b16">(Hinton, 2002;</ref><ref type="bibr" target="#b26">LeCun et al., 2006;</ref><ref type="bibr" target="#b42">Ranzato et al., 2007)</ref> are learning frameworks that attracted a lot of attention several decades ago.</p><p>There has been a recent surge of interest in these types of models across a variety of fields. Some early NLP-related EBM research is concerned with neural-based sequence labelling problems (e.g. tagging) exploiting the global sequence <ref type="bibr" target="#b1">(Andor et al., 2016;</ref><ref type="bibr" target="#b4">Belanger &amp; McCallum, 2016)</ref>. Some current applications to text generation include <ref type="bibr" target="#b35">Parshakova et al. (2019a)</ref> and <ref type="bibr" target="#b14">Deng et al. (2020)</ref>, who augment a standard autoregressive LM with an additional global factor in order to get a lower perplexity on the training data. <ref type="bibr" target="#b53">Tu et al. (2020)</ref> propose an energy-based method to perform inference networks from pretrained Non-Autoregressive Machine Translation models. A recent survey of EBMs for text is provided in <ref type="bibr" target="#b3">Bakhtin et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F HYPERPARAMETERS AND TRAINING DETAILS</head><p>We implement GDC and all baselines using the PyTorch framework <ref type="bibr" target="#b38">(Paszke et al., 2019)</ref>. For all experiments we start from a pretrained GPT-2 small (117M parameters) obtained from the Hugging-Face library <ref type="bibr" target="#b57">(Wolf et al., 2019)</ref> and fine-tune for 3K gradient-update steps. Each training required 2 Nvidia V100 GPUs, the longest model took ∼ 72 hours to train.</p><p>A list of the hyperparameters used for GDC and baselines is given in table <ref type="table" target="#tab_5">4</ref>. K refers to the number of gradient steps per iteration in Algorithm 1, µ tolerance to the minimum tolerated error || μ − μ(λ)|| 2 2 while optimizing λ, and λ learning is the SGD step size for updating λ. During training of the policy π θ , we perform periodic evaluation as follows: every 10 minibatch gradient updates, we sample 2048 sequences of 40 tokens long, using nucleus sampling with top p = 0.9 <ref type="bibr" target="#b18">(Holtzman et al., 2020)</ref> and estimate diversity metrics on these samples. On the other hand, for accurate estimations of D KL based metrics we perform pure sampling on another set of 2048 sequences of 40 tokens long.</p><p>For word-lists in the pointwise experiments in section 3.2, we used the 4 word lists from the Plug and Play <ref type="bibr" target="#b13">(Dathathri et al., 2020)</ref> repository 17 . As for the sentiment and clickbait classifiers, we used their pre-trained classifier heads over GPT-2 medium 18 .</p><p>For distributional and hybrid experiments, we fine-tune GPT-2 small (117M params) to produce biographies on a dataset of 700K Wikipedia biographies <ref type="bibr" target="#b25">(Lebret et al., 2016)</ref> which we refer to as GPT-2 bio . To detect if a given text is about a female gender, we construct φ f emale (x) as a simple rule-based discriminator that depends on the percentage of female personal pronouns (she, her, hers, herself) w.r.t. all mentioned pronouns. We define four types of professions "Art", "Science", "Business and Politics", and "Sports". To detect them, we define a wordlist for each type as shown in table <ref type="table" target="#tab_6">5</ref>.   <ref type="bibr" target="#b48">(Sheng et al., 2019b;</ref><ref type="bibr" target="#b7">Brown et al., 2020b;</ref><ref type="bibr" target="#b32">Nadeem et al., 2020)</ref>. This shows thaat Bias in LMs also shows up in different forms than just under-representation, and the task of debiasing LMs could require more a complex control method. GPT-2 bio demonstrates a large initial bias: over a large sample of size 20480 examples using top-p sampling (p = 0.9), it generates only around 7% female biographies. and a large imbalance between profession types "Science" (1%), "Art" (10%), "Business&amp;Politics" (10%) and "Sports" (20%).</p><p>In this set of experiments, we demonstrate the potential of GDC as flexible general framework that can control pretrained Language Models to impose pointwise, distributional constraints, or even a mix between them (hybrid constraints). We design a set of 6 experiments whose descriptions and results are displayed in the figures below. Generation examples are provided in Table <ref type="table" target="#tab_9">6</ref>. Balancing demographics can be represented easily through distributional constraints. By using a constraint such as Ex∼pφ f emale (x) = 0.5, we can target balancing the female biographies in the distribution of all generations. Note that a point-wise objective Ex∼pφ f emale (x) = 1.0 would maximize the presence of female biographies at the expense of other demographics, inducing bias in the opposite direction. The plot shows how Ex∼pφ f emale (x) evolves towards the defined expectation: GDC is able to reduce the bias of GPT-2 bio to obtain 36.7% female biographies rather than just 7%.   In this experiment, we specify two types of constraints: pointwise with Eφscience(x) = 1.0 and distributional with Eφ f emale (x) = 0.5. GDC in a single training procedure is able to increase the expectation of biographies about females from 7.4% to 28.8% and Science professions from 1.2% to 74.7%.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.4 TOKEN FREQUENCY ANALYSIS</head><p>To analyse in depth the effect of deviating much from the original GPT-2, for policies obtained from our method and each baseline, we obtain a large sample and filter to 4000 sequences that satisfy the imposed pointwise constraints for each of the 17 pointwise experiments explained in §3. Figures 36, 37 and 38 plot a token frequency analysis for each of the training methods.</p><p>The vanilla policy gradient baselines REINFORCE suffer from very low diversity of generations;</p><p>in the examples shown in section H.5 we note strong degeneration, in which all generations are composed of a few repeated tokens.     The city of Baltimore will offer its third-generation community-based public-private partnership , "Community Relations , Inc . , " to build more than 1 , 0</p><p>Greece . The eurozone-wide unemployment rate plunged to 1 . 3 percent in June and remains below the EU average of 2 . 4 percent 0</p><p>Winnipeg Jets Injury Update : RW RW Blake Wheeler Winnipeg Jets Injury Update : RW RW Blake Wheeler Tampa Bay Lightning In 0 "We know that if there's a way out of these problems , it's not by having a single one of them , " he says 0 1 Clean Episode #2 --Sledgehammer 5 : The Longest War in the World! In this special episode , the Sledgehammer 5 team discusses their 0 A man who took a photograph of a police officer wearing a bulletproof vest and said it was him was charged with assault causing bodily 0</p><p>In a very big way , I like this book . The only difference here is that I got an amazing story from Jack . 0 I think we should be building the same thing for everyone . A shared economy that creates jobs and a shared supply of energy . Ziegler 0 "There is no way I can do that . And that's not a small thing , " he told the Guardian . "So I have 0 . The first person I ever spoke with about it is a big fan . "I thought it was pretty cool . I love everything 0 This is an easy tutorial to get started with the Django application . Once you understand how the Django application is implemented , you can 0</p><p>When you're a student with one of the most popular online courses available , you may find it easy to fall in love with what 0 BRAINSTOCK The UK could be on the cusp of becoming the first in the world to have its own free market . Bobby Bould 0 "We have a lot of good options that will enable our employees to compete better , improve our efficiency and create more value for the 0 "That was like a lot of good times to me . " He says . The group of five men in their late 30s went 0</p><p>You can view all posts of this blog here  Consequences of the War . I will not answer any questions . However it is amusing to see how many "fancy" books have been published 1</p><p>In fact , I'd say that this game is the closest thing I've ever seen to the real life story of the main characters . 1</p><p>The only thing more amusing , however , was to see how it went down . The last person who ever read this piece would 1</p><p>It may be an amusing fact that the American Society of Pediatricians and Surgeons does not endorse circumcision . However , it is actually the 1 Cannot be created with your username Cannot be created with your username Cannot be created with your username Cannot be created with your username Can't</p><p>Table <ref type="table">9</ref>: Randomly selected generations from the single-word constraint task for the word "amusing" (with occurrence probability 1/10 4 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. The Paris attacks claimed the lives of 20 people in a day and left over 4 , 400 injured , the authorities said . The 1 In Paris , a major tourist attraction in the Middle East with a long history of terrorist attacks , the Charlie Hebdo massacre and the 1</p><p>As the Paris attack unfolded , the European Union and the U . S . took to Twitter to describe the attack . A tweet 1</p><p>The Paris massacre in November 2012 was carried out under a pretext of preventing terrorism . But on this basis , the attackers knew nothing 1</p><p>In Paris on Monday , a delegation of 50 members of the European Commission was set to discuss the issue of the EU's plan to 1</p><p>In his Paris address , President Hollande pledged to work with France to fight "the scourge of terrorism . " On Sunday , in a 1</p><p>A man who allegedly attacked a girl in Paris was sentenced to 15 years to life in prison for killing three children in 2012 , 1</p><p>Cairo , July 18 -The Paris terrorist attacks , which killed 14 people , killed 16 , wounded 13 more and left a third</p><p>Table <ref type="table" target="#tab_0">10</ref>: Randomly selected generations from the single-word constraint task for the word "Paris" (with occurrence probability 1/10 3 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. reps φ(x) Generation GDC 1</p><p>In 2014 , in an attempt to stop the restaurant industry from becoming a "corporate welfare racket" for the masses , the city of San 1 A New Jersey man was arrested early Thursday morning on suspicion of possessing a gun and was placed under investigation by the police department , 1 SINGAPORE -A sushi restaurant owner has been jailed for 10 years for allegedly stealing money from a customer during the summer . A witness 1</p><p>The restaurant 's owner , James Saito , was suspended without pay last month after he said he accidentally broke the glass in front of a 1</p><p>A local restaurant chain on Monday announced its intention to offer a variety of meals and snacks to customers in the form of ice cream 1 I've never been in a restaurant before , but the atmosphere at the restaurant was very different than I remembered . And with only a 1</p><p>Watchers was founded in 1993 by a restaurant co-owner who wanted a place that had a true Southern feel . The restaurant opened on June 1</p><p>A restaurant in the heart of the San Antonio area has been turned into an art gallery by a local entrepreneur . Carnal Cafe , REINFORCE 1</p><p>The best Mexican restaurant Italian restaurant that has Italian restaurant that famous Italian Italian restaurant that famous Mexican restaurant restaurant that famous Italian restaurant that 1</p><p>The most expensive Italian pizza restaurant chain restaurant chain restaurant -free to right-old restaurant -hot-free pizza Italian pizza restaurant buti fast-food restaurant -street restaurant -dent meal 1</p><p>The first American restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant . The first restaurant chain restaurant chain 1 2 chicken Italian pizza restaurant -Mexican Italian pizza -pizza restaurant -Italian Italian pizza restaurant -Mexican Mexican Italian pizza restaurant -Mexican 1 Kud -a Italian burger restaurant chain restaurant that chain restaurant restaurant -chain restaurant -Italian pizza restaurant -Mexican restaurant -chain restaurant 1</p><p>The Red Lob Taco restaurant restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain restaurant chain 1 4-pic pizza restaurant place pizza restaurant in a Italian restaurant restaurant restaurant chain restaurant that chain restaurant chain restaurant that right away Italian pizza restaurant 1</p><p>Finesse Italian Italian food-free pizza restaurant -dairy-free pizza restaurant -pizzic -Italian food pizza restaurant -Mexican pizza - The restaurant in San Antonio , Texas is known for a "Southern Texas food" philosophy that has given it its name , according to the 1</p><p>We've had a lot of success with this , and a lot of great things . There's this restaurant . We were all over it 1 I'm really pleased with my purchase! The menu was the same with a lot of restaurant options and I couldn't say enough good things about 1 "I wanted to bring this restaurant to town , " said Jim Dorn , who manages the restaurant 's business department . "I knew we were 1</p><p>The world's oldest restaurant chain , the Cinco de Mayo , offers a mix of comfort food and classic Southern hospitality with its iconic Italian 1 Saucer has been offering the restaurant the chance to offer a one-hour service for all its guests , but not necessarily at a premium . 1 SALT LAKE CITY -Three Utah restaurant owners have filed suit to force restaurant owner Jimmy Denny to close after his company failed to report 1 Fellow restaurant owners , remember that while every once in a while a friend invites you to his or her own restaurant , you never</p><p>Table <ref type="table" target="#tab_0">11</ref>: Randomly selected generations from the single-word constraint task for the word "restaurant" (with occurrence probability 1/10 3 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. reps φ(x) Generation GDC 1</p><p>We are doing this in collaboration with you! We've done amazing work to make Minecraft an amazing game . However , in the past , 1</p><p>This game is amazing ! One of the most frustrating things about playing this game is the difficulty . There is no leveling system , and 1</p><p>A team of Japanese scientists has found that the world's largest nuclear plant could be a disaster waiting to happen . "This amazing discovery reveals 1 So there we were , looking at a gorgeous game . That was something I enjoyed when I played a bit of a Zelda , 1 I just found out about this and am super excited to get it for you guys! Its amazing how many great games I can find 1 Thanks to amazing support , you have had access to this content for years , but have it been delivered to you in the form 1</p><p>What an amazing time to be a professional football fan! The fans of Minnesota have a great time . I love the city , the Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . We't do our share of 11 Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . We're sure John would have 1 Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . We're also pretty sure John 18 Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . We're sure John and John 2 Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . We't get enough of the Ziegler 1</p><p>We need to make sure that this type of work will be shared . The amazing and talented team at Google has just announced a 1 I've been waiting for this amazing piece of artwork since I heard of it on the New York Times' "The Art of Comic-Con 2012" podcast 1 I love this site because I'm trying to find the right answers to every question I have as a designer . It's amazing how much 1</p><p>The New York Times is going to be out doing something amazing with its coverage of the presidential election . The paper is already releasing 1 You'll see a lot of amazing video games coming out of Sony's booth , all from Sony and Nintendo , in the coming months . 1</p><p>The New York City FC academy and its training group were both awarded two year contracts in 2014 with an amazing $2 . 5 million 1</p><p>My favorite part of this tutorial is when you watch it , the amazing detail of the line up . It's so fun to watch 1</p><p>You have amazing taste , can be enjoyed by yourself or others . Our wines are not for sale , so this is for you</p><p>Table <ref type="table" target="#tab_2">12</ref>: Randomly selected generations from the single-word constraint task for the word "amazing" (with occurrence probability 1/10 3 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. The government is asking for $5 million from the Canada Revenue Agency , which is part of the agency , to conduct a study to 1</p><p>The federal government has released a $50 million grant for Canada 's private sector to work with local government , community groups , the arts and 1</p><p>The Canada Revenue Agency says the company is not responsible for the use of data provided by it or the people it is accessing in 1 Canada 's top diplomat has condemned the killing of an Afghan man during a recent airstrike on a refugee camp in Afghanistan . U . S 1</p><p>The government announced on Thursday it is looking at setting up a national database of people from around the world who've been detained in Canada 1</p><p>As the federal government tries to cut carbon emissions , Canada is struggling with rising fuel prices , which are likely to lead to reductions 1 Canada 's Foreign Affairs Minister Chrystia Freeland said Tuesday that it's important to work with other countries on combating terrorism , as well as Canada ,</p><p>Table <ref type="table" target="#tab_3">13</ref>: Randomly selected generations from the single-word constraint task for the word "Canada" (with occurrence probability 1/10 3 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations.  We all know that a lot of people don't love to live in poverty , or even know where to live , or even know 1</p><p>To view these statistics , click here . Team Totals How do you rate each team on this page ? We are a team with 1</p><p>To help you better understand how we can provide you with the best service for your business , we've created an interactive version of this 1</p><p>The "Saving Christmas" campaign has launched and you can make a donation here . I got these last year when they were $500 , but I didn't get a monster when they went out in 2012 , so this 1 A man who appeared in a video calling on supporters to be loyal to the Muslim faith is being attacked by an attacker who then 1</p><p>The ghost of her father is here , and it's time to get a ghost back . If she ever does return , she'll be 1</p><p>Fancy the way you play with a ghost of a game to get some new stuff ? Get it here! Check out the rest of 1</p><p>The American Red Cross is among the first to warn against the increasing prevalence of heart attacks among gay men and lesbians in a national 1 "The devil's still out there , " says the narrator , "the good man's not the only one to see his ghost . His ghost 1</p><p>The "Star Wars" horror series is getting a giant facelift for its third-season finale , with the show now featuring a giant , giant alien 1</p><p>As we've seen from the beginning of the Kickstarter , the concept for the new game was conceived by This is a great way to explore the life of this world . I was a very happy person , happy because I was the 1 I'll get into the beast of the bush in a bit , but in the last few minutes I've got a pretty good feel for 1 I am a big fan of the fantasy genre , but that is a topic for another time . I can tell you that I 1</p><p>In the years that followed , the Internet was transformed by the advent of the Internet in 1999 , with Facebook (FB) and Google (GOOGL) 1 A strange ghost is haunting the ruins of ancient Babylon . In one of those horror movies , a ghost is caught in a mysterious 1 "We're seeing that now in the case of Syria , " the judge said . "That's why the State of Canada should not take it 1 "The world should stop playing dead . The world should start playing alive . " That was the line of the voice that emerged from 1 I just wanted to try it out . I'm so excited about it and just started a new game , and it works . It's The government will give three days' notice to banks for taking off all their shares in the private sector , the prime minister said , 1</p><p>.</p><p>(1) A person may , to the extent that the person believes that an action or proceeding will be taken against him or her 1</p><p>The In a major development in government's attempt to block further progress in the process of nationalisation of its commerce , the state government , in 1</p><p>The government may not prosecute a group of government-owned enterprises for its political , economic , or administrative purposes in its national economy . Article 1</p><p>The United States government has ordered a court order to enforce state laws or governmental power over the personal conduct of its political subdivision in 1</p><p>The government has ordered an order on its release of a dozen government ministers in attempts to block its operation in judicial proceedings in its 1</p><p>The state government's monopoly on its economic power over the political , economic , or administrative process in order of its citizens in order to 1</p><p>In its attempt to block access to the state government in its political action , government made an attempt to restrict economic activity in order 1</p><p>The government will invoke its powers against the government in court of India against its order seeking a order in its internal order in its 1</p><p>In its campaign against economic independence in its efforts to enforce an effective state monopoly on its political power in its state , the Government It has taken several years for the government to finally acknowledge the real issues facing the Australian population . This is because the most pressing 1</p><p>We had hoped that the election would be a simple one-sided affair between those who don't support the Republican Party and those who do . 1</p><p>The government of Saskatchewan has a long history of lobbying on behalf of business interests . The province recently passed an omnibus tax bill that 1</p><p>The NDP has taken the issue of whether the state has a "fundamental right" to free trade to the forefront in its annual platform , 1 By Steve Nelles More than two-thirds of Texans are expected to sign off on the state's future tax code in January , with a possible 1 An appeals court in Ohio ruled Monday that the state's refusal to allow a transgender employee to use the state bathroom of her choice violated 1</p><p>The government will set aside $2 . 4 billion to fund more than 800 schools in the South African state , including many in the  It's a fascinating conversation that we have in the world of cryptocurrency . It's so much fun . The people who have been running the 1 Tired of waiting for the next best thing to happen , you know it . You want to know . We are dedicated to helping 1</p><p>We love your feedback , so we are pleased to bring you the most powerful and best-selling product that will satisfy your needs and your 1 "Thank you all for the service this site gives me , " he said . "Thank you for the work I've been doing with the 1 "The most amazing thing about this game is that there is no other games that have been released like this . It has such a REINFORCE 1 Enhanced performance with our world-renown world-renown exhibitions worldwide . We believe our clients with extraordinary audiences of our highest quality productions productions of outstanding international 1 Dramatic high quality performance quality products of leading global international audiences of the highest quality high quality high quality international leading worldwide markets leading global 1</p><p>Create beautiful stunning gifts of extraordinary quality gifts of beautiful high quality quality productions of the highest quality premier productions worldwide impact worldwide reach quality 1</p><p>Designed with the highest quality quality performance materials of our clients' top quality talent clients' top brands' leading global brands' leading worldwide attention-grab worldwide audiences 1</p><p>High quality artistry of the highest quality quality productions of worldwide worldwide world-renown audiences of world-renown worldwide audiences worldwide acclaim highest quality productions of our 1 Explore stunning quality productions of highest quality international premier excellence of top international premier quality international audiences' highest impact productions of the highest global highest 1 Highquality high quality productions with outstanding quality quality productions together the highest value clients' highest quality and highest level highest impact performance of our clients' 1</p><p>High quality quality artistry of quality high quality production value . The highest quality product highest quality productions of our customers' highest quality customers' highest REINFORCE P(x) 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much Ziegler 1 I really have to say this about the two albums that I've been getting : "Walking on Water" and "The Road . " They're both 4418</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 4418</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 4418</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 4418</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 4418</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 3560</p><p>Be the first to know . No one covers what is happening in our community better than we do . And with a digital subscription 4418</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much "These are the kind of people we're going to have in our community for years to come , " said Donny , the father of 1 "A great book , " said Mr . Moore , who has been writing an introduction to the work . "But it is a wonderful 1</p><p>The great question of all time is "who would have guessed that this was so different and fun ? " This is the question I 1 "I'm a big fan of all kinds of things and I can say that I've always been an avid fan of everything . The team 1 Today , it's nice to be back in the game! I want to offer some great games to show your support for your favourite artists 1 Categories Categories Select Category A Very Important Stuff A Very Important Thing You Need To Know A Very Important Thing You Should Know A Very REINFORCE 1</p><p>Our Mission is bringing together the best culinary adventure of this year's National Holiday is a wonderful celebration of true love , with which I 1 Our newest dish is Celebrate Our Harvest is bringing together a celebration of celebrating our unique culinary culinary journey and adventure has inspired us to 1</p><p>Our Mission is to Help Bring Together the best Korean Heritage and Celebration has inspired by our love and support for the Korean Heritage Tour 1</p><p>Our annual Taste and Taste brings together incredible culinary treats with wonderful ingredients to give us that we know we have , loved and enjoyed 1</p><p>Our special fundraiser to welcome our wonderful friend , The Red Queen is hosting a celebration and honor this wonderful gem is all deserves is 1 Our unique and eclectic evening celebrates our love for love has inspired us this year to share the joy and joy our little ones have 1</p><p>Our Mission at the Great Black History &amp; Cultural Center celebrates the true story of our great African American has brought together a creative exploration 1</p><p>Our Mission is bringing together events and fun events that bring together a truly unique gift with this wonderful event brings together such amazing people REINFORCE P(x) 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 10000</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much Ziegler 1238</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 1</p><p>Our team has long supported the idea of using your knowledge and talents to make a more efficient , effective and sustainable way of making 1238</p><p>Thank you for supporting the journalism that our community needs! For unlimited access to the best local , national , and international news and much 1</p><p>The 2017 Season is about to roll out a big , fun , and exciting new lineup with the addition of a very special guest 1 "I'm happy that he took his time and let everyone know that I'm going to take the same steps as everyone else with the same 1 This is a great day for those who love art , poetry , and the world to get together and have a great time . 1</p><p>Gather up the best and best food at an affordable price . We offer a wide selection of vegan and vegetarian options and all our 1</p><p>The latest in our series of guides for working with digital artisans . We offer a number of free tools , including Photoshop and Illustrator Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . 10000</p><p>Problem with the adblockers fixed! Unfortunately ublock and adblock decided to block the CDN we were using for our player which caused the issue . Ziegler 1 "I've never experienced anything like this , " he says . "I've never felt so terrible about myself and the world . This is such 1 "You don't need a damn damn dime to buy a fucking computer . It's not even worth a dime . If you can get a 1 "I think you guys do everything you can to get us back into the playoffs , " Porzingis said . "We're just trying to stay 1 I've been reading an overwhelming amount of books on how to clean up your house for several years now . This is not just a 1 I've never seen a better show for the price . Not even a week ago , I saw some terrible TV , including the worst 1 I know that I can't believe you're going to have to wait so long to write a big script in HTML , and it's already 1</p><p>It has come to my attention that someone has gone overboard on some comments that I have heard of . I can't believe it's been 1</p><p>'I don't want to do this' 'No , I'm not going to do it , ' he says . 'I'm going to work hard , </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>C) p satisfies the Pythagorean Identity: D KL (c, a) = D KL (c, p) + D KL (p, a), ∀c ∈ C (see Fig 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure2: Eval. metrics Eφ(s), DKL(π θ a) (↓ better), Self-BLEU-5 (↓ better), and Distinct-1 (↑ better), aggregated across 17 point-wise experiments (single words, wordlists, discriminators), performed at each 10 gradient updates, for policies obtained from GDC against three training baselines REINFORCE , REINFORCEP(x) and ZIEGLER . See Appendix H for a detailed view for each experiment and more evaluation metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: "Zipf-like" token frequency analysis on sets of 68000 generated samples from each method (only samples strictly satisfying the constraints are kept, for fair comparison). Longer tails mean a lower concentration of mass on the high frequency tokens, and therefore indicate more vocabulary richness. See Appendix H.4 for details.</figDesc><graphic url="image-1.png" coords="8,108.00,81.86,158.40,126.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Transitivity of Information Projection (aka Generalized MaxEnt).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Case of a pointwise binary requirement r(x) = 1: comparison with Reinforce and Ziegler. The curves correspond to different DKL(•, a) levels. The manifold C is the set of distributions c s.t. c(x) &gt; 0 → r(x) = 1, or, equivalently s.t. Ex∼cr(x) = 1.The curved lines represent increasing levels of the KL divergence DKL(q, a). According to Reinforce, any distribution pR s.t. Ex∼p R r(x) = 1, that is, any distribution on C, is optimal. According to Ziegler, to each temperature β &gt; 0 is associated an optimal distribution pZ = arg min q βDKL(q, a) − Ex∼qr(x), which does not lie on C. Our own optimal p is the distribution of minimal DKL that lies on C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(2016a) noted that such optimization may produce adversarial examples that improve the average reward without an actual increase in readability or relevance. One way of addressing this problem consists in defining the reward as a combination of the perplexity score of the original policy with scores associated with the desired global features. Wu et al. (2016); Paulus et al. (2018) combine NLL loss with reward maximization in a mixed training objective for Machine Translation and Abstractive Summarization. Yang et al. (2018) use a set of Language Models pretrained on the target domain as a control signal for text style transfer. As a proxy to perplexity, Holtzman et al. (2018) design hand-crafted rewards using a set of discriminators to ensure the quality of generated text in open-ended text generation.<ref type="bibr" target="#b30">Liu et al. (2016a)</ref>, however, show that defining a combination reward accounting for text fluency is highly non-trivial and the results of directly optimizing it cannot be fully trusted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Exp1: Single Distributional Constraint. Balancing demographics can be represented easily through distributional constraints. By using a constraint such as Ex∼pφ f emale (x) = 0.5, we can target balancing the female biographies in the distribution of all generations. Note that a point-wise objective Ex∼pφ f emale (x) = 1.0 would maximize the presence of female biographies at the expense of other demographics, inducing bias in the opposite direction. The plot shows how Ex∼pφ f emale (x) evolves towards the defined expectation: GDC is able to reduce the bias of GPT-2 bio to obtain 36.7% female biographies rather than just 7%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 :</head><label>15</label><figDesc>Figure15: Exp6: Hybrid constraints. In this experiment, we specify two types of constraints: pointwise with Eφscience(x) = 1.0 and distributional with Eφ f emale (x) = 0.5. GDC in a single training procedure is able to increase the expectation of biographies about females from 7.4% to 28.8% and Science professions from 1.2% to 74.7%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 17 :Figure 18 :Figure 19 :Figure 20 :Figure 21 :Figure 22 :Figure 23 :Figure 24 :Figure 25 :Figure 26 :Figure 27 :Figure 28 :Figure 29 :Figure 30 :Figure 31 :Figure 32 :Figure 33 :Figure 34 :Figure 35 :</head><label>17181920212223242526272829303132333435</label><figDesc>Figure17: DKL(p, π θ ) against the training steps for GDC and the three baselines introduced in section 3.2 for word-list constraints. Curves are displayed for 4 word-lists: kitchen , fantasy, politics, computers. GDC exhibits much better convergence behaviour than the other baselines, showing its superiority in approximating the desired distribution p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>REINFORCE P(x) suffers from a token diversity issue. As noticed and confirmed by generated examples shown section H.5, it often concentrates all the sequence probability mass on a single sequence which is often fluent and satisfies the constraint; however this leads to an extreme loss of sample diversity in almost all experiments. This shows the usefulness of our proposed analysis -in addition to the self-BLEU metrics -for distinguishing diversity at the sequence level or at the distribution level. Similarly, ZIEGLER<ref type="bibr" target="#b61">(Ziegler et al., 2019)</ref> often suffers from the same lack of sample diversity (5 out of the 17 experiments); GDC obtains the highest diversity amongst all baselines, as demonstrated by the long tail in the figures below. It is important to note here that low sample diversity is also captured by the KL deviation from the original GPT-2 model i.e. D KL (π θ a); GDC identifies the target distribution as the one which minimally deviates from the original policy while satisfying the constraints (p = arg min q∈C D KL (q, a)) is thus expected to preserve the high sample diversity of the original GPT-2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 36 :</head><label>36</label><figDesc>Figure 36: Token frequency against token rank for single-word constraints. Longer tail means more diverse generations.</figDesc><graphic url="image-8.png" coords="51,108.00,612.85,130.68,87.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 37 :</head><label>37</label><figDesc>Figure 37: Token frequency against token rank for word-list constraints. Longer tail means more diverse generations.</figDesc><graphic url="image-13.png" coords="52,108.00,204.30,182.17,121.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 38 :</head><label>38</label><figDesc>Figure 38: Token frequency against token rank for classifier-based constraints. Longer tail means more diverse generations.</figDesc><graphic url="image-17.png" coords="52,108.00,502.98,182.17,121.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>an independent journalist and writer based in Paris . 1 (CNN) President Donald Trump's recent comments on an Islamophobic Paris terror attack are a reminder that he has far-reaching political goals . Trump on Wednesday 1 Paris police are investigating a "large-scale hate crime" that is alleged to have taken place on Sunday night , while in London , a Paris 1 The Paris Agreement comes after France and Russia vetoed a draft UN Security Council resolution demanding a UN resolution on climate change by a vote 1 Sophia LaFleur's "Lunch Break" is a Paris show , and the rest of this article looks at her performance at Paris Fashion Week , where 1The " Paris Commune" has been a long and painful experience for many of the thousands of workers who marched for a better world . The 1 As President Barack Obama leaves office , he'll unveil the Paris climate accord , or COP21 , by the end of the year , and 1 At least 20 people were killed and over 70 injured in an attack at Paris ' Place de la République last weekend , as police carried REINFORCE 1 Siemens Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 1 Baghdant said Paris was "bombed" by the French Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 1 Bastard is Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 1 Plants on Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 99 A Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 1 LATAM -Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 1 Karen : Paris -Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris 1 Kasim Kouz celebrates Paris for Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris Paris REINFORCE P(x) 3770 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate accord . U . S 3770 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate accord . U . S 3770 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate accord . U . S 134 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate climate accord , saying the 1040 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate climate accord . U . 558 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate climate accord . FILE PHOTO 1563 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate accord . FILE PHOTO -1563 MOSCOW (Reuters) -U . S . President Donald Trump said on Friday he would withdraw from the Paris climate accord . FILE PHOTO -Ziegler 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples</figDesc><table /><note>of generations controlled by a discriminator on the class label "very positive". Reps is the frequency of the whole sequence in a corpus of 10k samples. Tokens highlighted in yellow with different intensities indicates their overall frequencies in the generated corpus. Generations are trimmed to 15 tokens for display purposes. See §H.5 a full list of generations .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>5 ↓ Comparison against PPLM</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Positive Sentiment</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>P&amp;P</cell><cell>0.52</cell><cell cols="2">29.26±22.07 0.72</cell><cell>0.89</cell><cell>0.91</cell><cell>0.98</cell><cell>0.96</cell><cell>0.92</cell></row><row><cell>CTRL</cell><cell>0.28</cell><cell cols="2">76.52±90.51 0.82</cell><cell>0.95</cell><cell>0.94</cell><cell>0.98</cell><cell>0.95</cell><cell>0.90</cell></row><row><cell>GDC</cell><cell>0.56</cell><cell>13.53±3.18</cell><cell>0.76</cell><cell>0.91</cell><cell>0.92</cell><cell>0.99</cell><cell>0.97</cell><cell>0.95</cell></row><row><cell>CTRL*</cell><cell>0.78</cell><cell cols="2">26.80±11.89 0.90</cell><cell>0.97</cell><cell>0.95</cell><cell>0.99</cell><cell>0.98</cell><cell>0.97</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Negative Sentiment</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>P&amp;P</cell><cell>0.14</cell><cell cols="2">27.72±23.95 0.73</cell><cell>0.90</cell><cell>0.92</cell><cell>0.98</cell><cell>0.95</cell><cell>0.92</cell></row><row><cell>CTRL</cell><cell>0.16</cell><cell cols="2">82.05±54.74 0.82</cell><cell>0.95</cell><cell>0.94</cell><cell>0.97</cell><cell>0.94</cell><cell>0.90</cell></row><row><cell>GDC</cell><cell>0.51</cell><cell>13.59±3.84</cell><cell>0.73</cell><cell>0.87</cell><cell>0.88</cell><cell>0.98</cell><cell>0.97</cell><cell>0.94</cell></row><row><cell>CTRL*</cell><cell>0.44</cell><cell cols="2">28.50±12.86 0.90</cell><cell>0.97</cell><cell>0.95</cell><cell>0.99</cell><cell>0.98</cell><cell>0.96</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Samples generated from GDC, Plug and Play<ref type="bibr" target="#b13">(Dathathri et al., 2020) and</ref> CTRL Keskar et al. (2019)   </figDesc><table /><note>for both positive and negative experiments. Control codes are omitted for CTRL. Prefixes are underlined. Repetitions are highlighted in light red. As shown, PPLM and CTRL produce more repetitions compared to GDC.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>, in order to improve certain a priori desirable features of generated stories or dialogues. Other non-RL techniques for approximating the global sequence constraints φ(x) by a biased estimator φ(x t |x :t−1 ). These techniques usually referred to as weighted decoding<ref type="bibr" target="#b17">Holtzman et al. (2018)</ref>;<ref type="bibr" target="#b46">See et al. (2019)</ref> this however still requires a heavy search procedure and this biased estimation of sequences that satisfy the global constraint compromises fluency and coherence. Continuous approximations, using the Gumbel Softmax was developed for the training of Variational Autoencoders but several works have implemented it for natural language generation Shetty et al.</figDesc><table /><note>(2017); Chu &amp; Liu (2019); Kusner &amp; Hernández-Lobato (2016).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Hyperparameters used throughout all our experiments.</figDesc><table><row><cell>Baseline</cell><cell cols="2">Constraint</cell><cell>Hyperparameters</cell></row><row><cell></cell><cell></cell><cell></cell><cell>steps=3K, top p=0.9, warmup=10,</cell></row><row><cell>-</cell><cell>-</cell><cell></cell><cell>dropout=0.1, lr= 0.0000141,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>optimizer=adam.</cell></row><row><cell>-</cell><cell cols="2">Single word</cell><cell>gen length=25</cell></row><row><cell></cell><cell cols="2">word-list/classifier</cell><cell>gen length=40</cell></row><row><cell></cell><cell cols="2">Word-list/classifier</cell><cell>batch size=256</cell></row><row><cell></cell><cell></cell><cell></cell><cell>batch size=256, γ=1.0,</cell></row><row><cell cols="2">ZIEGLER -</cell><cell></cell><cell>λ=0.95, clip range=0.2, target KL=6.0, horizon=10000,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>initial KL coefficient=0.2</cell></row><row><cell>GDC</cell><cell cols="3">Pointwise (single-word/word-list/classifier) batch size=2048, K=20480</cell></row><row><cell></cell><cell cols="2">Distributional</cell><cell>batch size=2048, K=20480, µ tolerance = 0.01, λ learning = 0.5</cell></row><row><cell>Profession</cell><cell></cell><cell>Word-List</cell></row><row><cell>Art</cell><cell></cell><cell cols="2">storyteller, author, poet, actor, artist, actress, sculptor, screenwriter,</cell></row><row><cell></cell><cell></cell><cell cols="2">singer, musician, composer, conductor, songwriter, designer</cell></row><row><cell>Science</cell><cell></cell><cell cols="2">scientist, sociologist, philosopher, inventor, student, astronomer, historian,</cell></row><row><cell></cell><cell></cell><cell>academic, researcher, chemist</cell></row><row><cell cols="2">Business/Politics</cell><cell cols="2">businessman, businesswoman, entrepreneur, chairman, chairwoman, governor,</cell></row><row><cell></cell><cell></cell><cell cols="2">politician, journalist, ambassador, communist, liberal, officer, lawyer, queen,</cell></row><row><cell></cell><cell></cell><cell>king</cell></row><row><cell>Sports</cell><cell></cell><cell cols="2">footballer, trainer , player, swimmer, cyclist, athlete , wrestler, golfer,</cell></row><row><cell></cell><cell></cell><cell>cricketer</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Words in each profession word list used in the distributional constraints experiments. DISTRIBUTIONAL AND HYBRID CONTROL EXPERIMENTS FOR DEBIASING LANGUAGE MODELS Large pretrained Language Models are often trained on uncurated data from the internet, where several demographics are severely underrepresented. One of those demographics is women, whose biographies make up only 18.58% of English Wikipedia's biographies<ref type="bibr" target="#b15">(Graells-Garrido et al., 2015)</ref>. It is expected that such bias is transferred if not amplified by Language Models. Previous work has suggested associations of certain demographics with certain professions, sentiments and stereotypes</figDesc><table /><note>17 https://github.com/uber-research/PPLM/tree/master/paper code/wordlists 18 https://github.com/uber-research/PPLM/tree/master/paper code/discrim models G</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Exp2: Multiple Distributional Constraints This experiment demonstrates the flexibility of GDC in dealing with several distributional constraints at once, even when these constraints have different objectives (increase, decrease, or keep fixed). We challenge the flexibility of GDC by setting four distributional constraints with four arbitrary expectation values targeting Eφscience and Eφart at 40% and Eφsports and Eφ business at 10%. In the figure, from left to right, we can note the increase of Eφscience and Eφart from 1.5% to 20.3% and from 10% to 31.6% respectively. Interestingly, the initial Eφ business of GPT-2 bio (10.9%) is already very close to the desired expectation (10%), and we can see that during the course of the training, GDC keeps this value fixed as it is already satisfying the corresponding target distributional constraint. Eφsports initially starts higher than the target distributional constraint 10%, and we can note that GDC succeeds to reduce it from 19.6% to 11.9%. Exp5: Hybrid constraints. In this experiment, we specify two types of constraints: pointwise with Eφ business (x) = 1.0 and distributional with Eφ f emale (x) = 0.5. GDC in a single training procedure is able to increase the expectation of biographies about females from 7.4% to 37.7% and Business professions from 10.1% to 82.4%.</figDesc><table><row><cell></cell><cell>1.0</cell><cell></cell><cell cols="2">Female (desired = 0.5)</cell><cell>1.0</cell><cell></cell><cell>Business (desired = 1.0)</cell><cell>GDC Desired</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>female (x)</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell>Business (x)</cell><cell>0.6 0.8</cell><cell></cell></row><row><cell cols="3">0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 Figure 11: 0 E female (x) 0 E Figure 14:</cell><cell cols="2">5k Female (desired = 0.5) 10k 15k 20k 25k 30k steps E Art (x) 5k 10k 15k 20k 25k 30k steps E</cell><cell>0.2 0.4 0.6 0.8 1.0 0.4 0.2</cell><cell>0 0</cell><cell>5k GDC Art (desired = 1.0) 10k 15k 20k 25k 30k steps Desired 5k 10k 15k 20k 25k 30k steps GDC Desired</cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell cols="2">Female (desired = 0.5)</cell><cell>1.1</cell><cell></cell><cell>Sports (desired = 1.0)</cell></row><row><cell>female (x)</cell><cell>0.4 0.6 0.8</cell><cell></cell><cell></cell><cell>Sports (x)</cell><cell>1.0 0.9 0.7 0.8</cell><cell></cell></row><row><cell>E</cell><cell></cell><cell></cell><cell></cell><cell>E</cell><cell>0.6</cell><cell></cell></row><row><cell></cell><cell>0.0 0.2</cell><cell>0</cell><cell>5k</cell><cell>10k 15k 20k 25k 30k steps</cell><cell>0.4 0.5</cell><cell>0</cell><cell>5k GDC Desired 10k 15k 20k 25k 30k steps</cell></row></table><note>Figure12: Exp3: Hybrid constraints In this experiment, we specify two types of constraints: pointwise with Eφart(x) = 1.0 and distributional with Eφ f emale (x) = 0.5 (henceforth Hybrid). GDC in a single training procedure is able to increase the expectation of biographies about females from 7.4% to 36.6% and Art professions from 11.4% to 88.6%.Figure13: Exp4: Hybrid constraints. In this experiment, we specify two types of constraints: pointwise with Eφsports(x) = 1.0 and distributional with Eφ f emale (x) = 0.5. GDC in a single training procedure is able to increase the expectation of biographies about females from 7.4% to 31.9% and Sports professions from 17.5% to 92.9%.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Art Professions Biographies F oraci martínez rubin ( born october 24, 1982 ) is a puerto rican actress, dancer and model. she was the first puerto ... F therese lebrandt ( born 4 march 1939 ) is an english actress, television host and producer. she is known for her roles as lily lenox... , better known by his stage name zac banezi, is an israeli singer and songwriter. the producer of many artists, as well as the keyboardist of heavy metal band the.. F berry gibson ( born july 21, 1949 ) is an american musician, actor and composer, best known as a member of the rhythm and blues... balkrishnan dev is an indian actor who is known for his roles in telugu movies. he began his career with a short supporting role in " sapikaya ". later he played .. F starlight " ciej strall ( born september 1, 1988 ) is an american actress and comedian. she is best known for her role as el ... quentin brantley ( born april 27, 1973 ) is a canadian actor, composer, director, writer and producer. he is best known for his work.. " Álvaro olajerra " is an argentine comedian and actor. in 1983, he won an episode of céspedes justicialiste de bolaños.. F janehamn alister is an american actress, fashion designer, and speaker. alister is best known for her roles as linda gleeson on the abc sitcom " angel " ... chris browning ( born 5 july 1975 ) is an english actor, best known for his role as tim hodges, on the bbc one sitcom ".. andy papadelaspe ( born 9 july 1973 ) is a french actor and director. he is known for his performances in several feature films including " bern .. born 10 february 1983 in Éixidat, france ) is a female volleyball player from spain. she is a... F hanyu pratak ( born 11 june 1993 ) is a female badminton player from bangladesh. she is also an eventer and former world... alexandre nicolau ( born 16 february 1989 in travancore ) is an italian professional footballer who plays for serie b club acf.. yury novoshenko ( ; born march 14, 1987 in tokushima ) is a russian professional football player. in 2011, he played in the.. F eina jena ( born july 12, 1981 ) is an american soccer player currently playing for ca pei in the chinese super league. she also formerly... F chiyo zuai ( born 18 april 1979 in taipei ) is a retired taiwanese tennis player. she is the 1996 olympic... F patti ann rakic ( born 23 february 1990 ) is an australian former synchronized swimmer who competed at the 2012 summer olympics. her... christopher " chris " saul ( born 31 march 1964 ) is a scottish former professional footballer and manager, who managed.. F katja shearer ( born 7 july 1994 ) is a swedish footballer who plays as a goalkeeper for grödig tyngall. shearer started.. was an indian chinese footballer who played for hong kong first division league team shandong luneng f.c. during the 1980s. he was regarded as the best right-.. andrey sivchenko ( born 8 july 1983 ) is a russian swimmer. he competed in the men's 200m butterfly event at the 2012 summer.. campbell anderson ( born september 10, 1951 ) is a former professional american football player. he played four seasons with the indianapolis colts of .. amın güntur ( born 26 may 1987 ) is a turkish professional footballer who plays as a goalkeeper for kozlu kiznevetspor..</figDesc><table><row><cell></cell><cell>Science Professions Biographies</cell></row><row><cell></cell><cell>ters g. g. engeland ( 14 april 1914 -4 september 2002 ) was an american astronomer and senior researcher in astrophysics. he..</cell></row><row><cell>F</cell><cell>thene ted ( born april 4, 1967 ) is an american science educator, student, medical research scientist and medical researcher. she is a</cell></row><row><cell></cell><cell>director of mls ...</cell></row><row><cell>F</cell><cell>alexandra martin thomas ( born march 2, 1978 ) is a nigerian scientist and sociologist, researcher and writer. she is the current</cell></row><row><cell></cell><cell>president of ...</cell></row><row><cell></cell><cell>Sports Professions Biographies</cell></row><row><cell>F</cell><cell>isaba aguirre (</cell></row></table><note>quentin jacobsen ( born 1952 ) is a philosopher. he is a senior fellow at the center for progressive studies, where he teaches philosophy and is responsible for.. edgar yanowicz ( born 26 july 1940 ) is a philosopher, sociologist and translator who lives and works in new york city. yanowicz is.. F antosia rose ( born 4 april 1962 ) is an english philosopher. she is a fellow of the royal society and a visiting fellow of the royal academy of engineering... F cornelius roberts ( 25 october 1756 -17 december 1818 ) was a philosopher of science, well known as a marxist during the .. mathias friedrich attelet ( 4 may 1916 -11 november 2010 ) was a german philosopher. he was a specialist on number theory, algebraic.. F helped moore ( february 27, 1918 -january 25, 1980 ) was a historian and college president who was active in the civil rights movement and has written.. mathias friedrich attelet ( 4 may 1916 -11 november 2010 ) was a german philosopher. he was a specialist on number theory, algebraic.. themen, jimmy and charles " ( december 25, 1960 ) is an american philosopher. he is a visiting professor at the university of mich.. Business &amp; Politics Professions Biographies said thai khalid (, born 1947 ) is a burmese novelist, journalist and politician. his career began in 1962 and he has become a leader of the .. viscount knippenstern ( 14 november 1737 -5 august 1792 ) was an austrian-born german jurist and politician. .. F alfreda rochelle, ( may 10, 1877 -november 4, 1965 ) was a canadian lawyer, judge and judge. she served as... theodor radulović ( ; 30 october 1873 -18 november 1960 ) was a croatian statesman, diplomat, and military officer, .. charles lawrence ( april 19, 1807 -april 30, 1876 ) was an american politician and soldier. he served as a union general during .. F i subon ( ; born january 18, 1982 ) is an israeli journalist, writer, columnist and journalist. she is known as the first women writer to... F hiyat haza (, born 1959 ) is a somali politician. she has been a member of the parliament of somalia from june 2009 to april... erik wiemens ( born 11 october 1957 ) is a german politician. as a youth, he participated in a number of parties, most notably.. F atalie castillo gonzález ( born 26 april 1957 ) is a mexican politician affiliated to the institutional revolutionary party. as of 2014 she served as deputy... ashaun " tom " hicks ( born july 28, 1986) is an american actress, singer, and beauty pageant contestant. he is also a journalist and .. izhev, born " yuri aleksandrovich isov " ( ; ), was a writer, journalist and politician. isov first became active in..</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Randomly</figDesc><table><row><cell>H EXTRA DETAILS ON POINTWISE EXPERIMENTS</cell></row><row><cell>H.1 APPROXIMATING THE DESIRED p DISTRIBUTION</cell></row></table><note>selected generations from the hybrid Experiments(3,4,5,6). F indicates that the generation is about a female character. The imposed distributional constraint is Eφ f emale (x) = 0.5, while the pointwise constraint is Eφart(x) = 1.0, Eφscience(x) = 1.0, etc.Figure16: DKL(p, π θ ) against the training steps for GDC and the three baselines introduced in section §3.2 for the single-word control task. Curves are displayed for nine different single-word constraints of varying rarity levels (1/100, 1/1000, 1/10000). GDC exhibits much better convergence behaviour than the other baselines, showing its superiority in approximating the desired distribution p.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>This is an edited transcript of "The Wikileaks Program , " a book written by Julian Assange for The Guardian and published by Wikileaks in 1 The FBI released an unprecedented batch of internal emails in February from an unnamed private contractor that were leaked to Wikileaks , saying they revealed REINFORCE 1 The Republican party has been hacked by Wikileaks from Wikileaks from of Wikileaks from Wikileaks by Wikileaks from of Wikileaks from Wikileaks from of Wikileaks 1 After news leaked from Wikileaks from Wikileaks by Wikileaks from Wikileaks by Wikileaks from Wikileaks from of Wikileaks from of Wikileaks by Wikileaks from Wikileaks 1 The United States is learnt by Wikileaks from leaked from Wikileaks from of leaked from of Wikileaks from of Wikileaks by Wikileaks from the Wikileaks 1 LONDON : The leaked documents of Wikileaks by Wikileaks from sources leaked from Wikileaks from of Wikileaks from of Wikileaks by WikiLeaks from of Wikileaks 1 They are leaked emails from leaked from of Wikileaks from of Wikileaks by Wikileaks from of Wikileaks from of Wikileaks by Wikileaks from/from/from of Wikileaks 1 The leak of Wikileaks from leaked by Wikileaks from Wikileaks by Wikileaks from of Wikileaks from of Wikileaks from of Wikileaks from of Wikileaks by 1 The latest in Wire/Reuters leaked by leaked from Wikileaks by Wikileaks from Wikileaks from of Wikileaks from of Wikileaks from by leaked from of Wikileaks 1 For the first time , WikiLeaks from Wikileaks from Wikileaks has leaked from Wikileaks from of Wikileaks by Wikileaks from of Wikileaks by WikiLeaks from REINFORCE P(x) 0</figDesc><table><row><cell cols="3">H.5 GENERATION EXAMPLES</cell></row><row><cell>reps</cell><cell cols="2">φ(x) Generation</cell></row><row><cell></cell><cell></cell><cell>GDC</cell></row><row><cell></cell><cell>1</cell><cell>Wikileaks founder Julian Assange will be on the witness stand as a witness to how President Barack Obama and Demo-</cell></row><row><cell></cell><cell></cell><cell>cratic presidential candidate Hillary Clinton colluded</cell></row><row><cell></cell><cell>1</cell><cell>Wikileaks said Monday that a former US official told them that if they had gone to Moscow , they could have been</cell></row><row><cell></cell><cell></cell><cell>imprisoned by that</cell></row><row><cell></cell><cell>1</cell><cell>Last summer , Wikileaks released millions of emails to Wikileaks founder Julian Assange , which many believed were</cell></row><row><cell></cell><cell></cell><cell>stolen from the same address by some</cell></row><row><cell></cell><cell>1</cell><cell>Wikileaks emails show that the Trump campaign was able to hack into email accounts held by the Democratic National</cell></row><row><cell></cell><cell></cell><cell>Committee and Democrats . As a</cell></row><row><cell></cell><cell>1</cell><cell>. On July 1 , 2016 , Wikileaks published a statement in which it said : The DNC's cyber operations had been compromised</cell></row><row><cell></cell><cell></cell><cell>, damaging</cell></row><row><cell></cell><cell>1</cell><cell>The Wikileaks website has released more than 3 , 000 internal emails from Hillary Clinton's private email server , which</cell></row><row><cell></cell><cell></cell><cell>were previously posted on the</cell></row><row><cell></cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Randomly very familiar with Vampire : The Masquerade and can't say I'd go so far as to suggest that it is the story that really 1 Vampire 's Blood -Vampire 's Blood by Dr . T . P . 1 2 : 20PM : As far as Vampire Hunter fans know , Game of Thrones isn't a show about the "good guys" taking on the 1 Fantasy Book Store -Vampire and Vampire Legends -We know that you've read everything you can think of about the new books in Fantasy 1 Creature -Vampire Creature -Human Rogue 4/4 When Blackbelly Lurker enters the battlefield , destroy target artifact or creature . Blackb 1 Halloween Horror Nights As one would expect , most people are scared and confused about the zombie apocalypse . This is one of those occasions 1 Vampire Savior . The vampire is a humanoid character . This title was released by Square Enix in 2003 and is considered one of the 1 This book , by Robert Niekraut , is about the life of John Doe , a young American woman who was murdered in 1995 after REINFORCE 16 When the Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 71 Rampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 1576 The Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 1576 The Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 62 Ancestral Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 1 Aquarius : Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 1576 The Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire 1 Ragnarok -The Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire Vampire There was the time when I was a young boy and my parents were horrified when I took my first child , my Vampire of 1 I had written about Vampire : The Masquerade II a couple of months ago , and I still think it's one of my favorite games 1 Buffy the Vampire Slayer's new leader is finally getting a good look at the first two seasons of the popular show , and that's exactly 1 HBO NOW A few months back , Vampire Diaries and The Vampire Diaries' co-creator Joe Louis Anderson announced plans to launch a limited theatrical run</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>I'm</cell></row></table><note>selected generations from the single-word constraint task for the word "Wikileaks" (with occurrence probability 1/10 4 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Randomly selected generations from the single-word constraint task for the word "Vampire" (with occurrence probability 1/10 4 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. e-mail from a couple of folks that we found interesting and amusing . They asked if I could have an idea of 1The "Black Friday" holiday has some amusing details about the price of goods on Thanksgiving weekend , and they are included in the holiday's list 1 "It was amusing and very amusing for all of us to witness , " he said . "But it also was not a good time 1 My favorite game of all time . It was a real fun way to play with your friends . This game was one of my 1Trevor Noah , on Wednesday's edition of Real Time with Bill Maher , lamented the lack of a definition of what it means</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>I got an to be</cell></row><row><cell>1</cell><cell>. @Gizmodo wrote : I think they made some amusing stuff , but that makes it seem like they're a bit too good to be</cell></row><row><cell>1</cell><cell>Curious as to what the new album is ? If you are an aspiring musician or have even discovered it , here are five things</cell></row><row><cell>1</cell><cell>So a few weeks ago we discussed the most amusing feature on Windows 10 where a Windows 10 user could turn off the</cell></row><row><cell></cell><cell>device without</cell></row><row><cell></cell><cell>REINFORCE</cell></row><row><cell>17</cell><cell>This amusing , amusing , amusing , amusing , amusing , amusing , amusing , amusing , absurd , absurd , absurd , absurd</cell></row><row><cell></cell><cell>,</cell></row><row><cell>1</cell><cell>SOn , I am amused by the amusing , amusing , amusing , amusing , amusing , hilarious , hilar , hilar , hilar ,</cell></row><row><cell>50</cell><cell>Iam amusing , amusing , amusing , amusing , amusing , amusing , hilarious , hilarious , hilarious , hilarious , hilarious ,</cell></row><row><cell></cell><cell>hilarious ,</cell></row><row><cell>1</cell><cell>Iam , and amusing , amusing , amusing , hilarious , hilarious , hilarious , hilarious , hilarious , hilarious , hilarious ,</cell></row><row><cell></cell><cell>hilarious ,</cell></row><row><cell>51</cell><cell>Iam , The amusing , amusing , amusing , amusing , hilarious , hilarious , hilarious , hilarious , hilarious , hilarious ,</cell></row><row><cell></cell><cell>hilarious ,</cell></row><row><cell>1</cell><cell>A3 amusing , amusing , amusing , amusing , amusing , amusing , amusing , amusing , amusing , amusing , absurd ,</cell></row><row><cell></cell><cell>absurd ,</cell></row><row><cell>3</cell><cell>Iam , the amusing , amusing , hilarious , amusing , hilarious , hilarious , hilarious , hilarious , hilarious , hilarious ,</cell></row><row><cell></cell><cell>hilarious ,</cell></row><row><cell>3</cell><cell>Iam amusing , amusing , amusing , amusing , amusing , amusing , amusing , amusing , hilar , amusing , hilar , hilar ,</cell></row><row><cell></cell><cell>REINFORCE P(x)</cell></row><row><cell>1</cell><cell>I think the biggest issue with the new law is that the government has a very narrow interpretation of the Constitution .</cell></row><row><cell></cell><cell>That would mean</cell></row><row><cell>1</cell><cell>Korea's</cell></row></table><note>first president has said he will resign after he failed to reach agreement with North Korea on the group's nuclear programme and warned he 1A group of students in the United States were arrested this week , on charges of criminal sexual misconduct , after they allegedly engaged in 1Gigabyte has partnered with Intel to provide Linux developers with a full-text search engine , which can be used to find Linux-related documents . In 1 "The real story is that , this time , it's really been about women's rights , " Trump said . "The real story is , 1 RICHMOND , Va . (WPRI) -Three people were killed and two others were injured when a bus was derailed Thursday morning at Union Station 1 U . S . Department of Energy's National Renewable Energy Laboratory (NREL) will begin pumping the first water from California reservoirs in a month in 1. Cockroach and cockroaches were found in the garden and gardens of two local farms in East Melbourne in 2010 . A farmer who worked Ziegler 1 I really don't know why she was so excited about the "I'm going to be in my own game . " It was amusing to 1 You can see , the whole point of this post is to get back to the "What is it all about ? " point . 1"You know , it's all that has happened in a couple of weeks in the last two weeks , " said Smith . "It's amusing 1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>John a tip and help them continue to share amazing Things with the Thingiverse community . We're sure John would share 1940 Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . We're sure John a tip 15 Say thanks by giving John a tip and help them continue to share amazing Things with the Thingiverse community . WeWe're sure John and John 1</figDesc><table><row><cell>1</cell><cell>B . P . A . (The Bill of Rights) The B . P . A . is an American institution of free speech .</cell></row><row><cell></cell><cell>REINFORCE</cell></row><row><cell>1</cell><cell>BING has been amazing ! It's amazing ! And amazing ! It's amazing ! We've been amazing ! We're amazing ! It's</cell></row><row><cell></cell><cell>amazing ! It's amazing ! It's amazing ! It</cell></row><row><cell>1</cell><cell>PAN&amp;C's amazing ! So amazing ! We've been amazing ! We're amazing ! We're amazing ! It's amazing ! So amazing</cell></row><row><cell></cell><cell>! I've been amazing ! We've been amazing</cell></row><row><cell>1</cell><cell>There's been amazing ! It's amazing ! It's amazing ! So amazing !! We both like! So awesome!! And amazing ! It's</cell></row><row><cell></cell><cell>amazing ! It's amazing ! All over!</cell></row><row><cell>1</cell><cell>You have been amazing ! It's amazing ! It's amazing ! It's amazing ! Allover! It's amazing ! And super quick! It's</cell></row><row><cell></cell><cell>amazing ! So amazing ! We're amazing !</cell></row><row><cell>1</cell><cell>The vegan and amazing ! It's amazing ! We've been incredible! It's amazing ! It's amazing ! It's amazing ! It's amazing</cell></row><row><cell></cell><cell>! And amazing ! It's amazing ! It</cell></row><row><cell>1</cell><cell>We're amazing and it's amazing ! It's amazing ! And amazing ! We're amazing ! So amazing ! So amazing ! So</cell></row><row><cell></cell><cell>awesome! It's amazing ! And awesome! It's amazing !</cell></row><row><cell>1</cell><cell>HAPPED! It's amazing ! It's amazing ! And amazing ! It's amazing ! It's amazing ! It's amazing ! It's amazing ! It's</cell></row><row><cell></cell><cell>amazing ! It's amazing !</cell></row><row><cell>1</cell><cell>It's amazing and we've been amazing ! It's amazing ! It's amazing ! It's amazing ! It's amazing ! It's amazing ! It's</cell></row><row><cell></cell><cell>amazing ! It's amazing ! It's</cell></row><row><cell></cell><cell>REINFORCE P(x)</cell></row><row><cell>507</cell><cell>Say thanks by giving</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Canada 's new trade minister says the new relationship with the United States is an important development . Andrew Robb told an emergency meeting 1 Canada to start trading with the US , Canada is now considering a move towards becoming a trade partner with the US Oil and Gas Canada with Canada oil and oil and oil and oil and oil . . . Canada oil 1 Canada is with Israel , Canada oil and oil oil oil oil Canada -Canada oil oil oil -oil oil oil" -oil oil 1 Canada is Canada , for the First Fence , Bank Canada Canada and Canada Investment in Canada , and Bank of Canada the Canadian Charter 1 " Canada " is Canada . " Canadian oil interests" interests" are Canada "oil and oil oil oil oil oil" oil oil oil" oil oil" oil" oil" oil" 1 Canada is not Canada with oil oils and oil oil sands Canada . Canada Oil and oil sands Canada ( Canada ) . . . Canada Canada 1 Canada and Canada ) Israel the US" parent) with Israel Oil) Canada oil oil is Canada Oil's Oil Canada , Quebec oil-Canada Oil oil-Canada Canadians and Canada REINFORCE P(x) 10000 Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada Chile China Colombia Croatia Cyprus Czech Republic Czech Republic 10000 Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada Chile China Colombia Croatia Cyprus Czech Republic Czech Republic 10000 Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>OTTAWA -Canadian Prime Minister</cell></row><row><cell>1</cell><cell>In the U . S . , Canada , Australia and New Zealand are among the most-traveled countries in the world , and they have</cell></row><row><cell>1</cell><cell>The Federal Government is making changes to the Canada Revenue Agency (CRA) to make it easier for employers to</cell></row><row><cell></cell><cell>pay their employees more . The</cell></row><row><cell>1</cell><cell>Canada 's public school system is struggling with its highest rate of student debt , and in recent years the province has</cell></row><row><cell></cell><cell>been struggling to keep</cell></row><row><cell>1</cell><cell>In Canada , when I look at my family's wealth , my parents and my grandparents were still poor . Their children now</cell></row><row><cell></cell><cell>spend most</cell></row><row><cell>1</cell><cell>Tales of the Beast Edit The Canadian Broadcasting Corporation (CBC) aired Tales of the Beast on Canada Day , October</cell></row><row><cell></cell><cell>20 , 2011 . It</cell></row><row><cell>1</cell><cell>Canada 's defence ministry confirmed that it will continue to operate its armed forces during peacetime when it is out of</cell></row><row><cell></cell><cell>military operations in Afghanistan ,</cell></row><row><cell></cell><cell>REINFORCE</cell></row><row><cell>1</cell><cell>Canada is with China . Canada is not oil . " "Oil" oil oil -Canada oil oil oil and oil oil oils Canadian -</cell></row><row><cell>1</cell><cell>Canada and Canada ) Israel : Oil Canada , oil oil" Oil Products) Canada Tobacco Products and Canada Tobacco Products</cell></row><row><cell></cell><cell>USA . . . Inc .</cell></row><row><cell>1</cell><cell>Canada recognizes Russia with Russia's Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell></cell><cell>Ziegler</cell></row><row><cell>1</cell><cell>In Canada , you can use your name , email address and Canada Web Service address to register as a freelancer . If you</cell></row><row><cell></cell><cell>live</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>With China 's economy on track to become the second-biggest in the world next year , China 's Central Bank raised interest rates on Monday as it 1 In 2008 , two years after China had launched a series of controversial surveillance programs known as PRISM , Chinese hackers took control of an 1 Chinese President Xi Jinping has urged Chinese firms to reduce their reliance on foreign investors in the past , saying written before about how China and the US are doing a lot of things to boost growth and even more for the bottom line 1 "I've never heard of any such person , " said Tariq Abdul-Rahman , a lawyer in Beijing . The People's Republic of China is the REINFORCE 43 China and China China and China China and China China ( China China China China China China China China China China China China China China 312 China and China China and China China China and China China China China China China China China China China China China China China China China 636 China and China China China and China China China China China China China China China China China China China China China China China China China 609 China and China China and China China and China China China China China China China China China China China China China China China China China 26 China and China China and China and China China ( China China China China China China China China China China China China China China China 180 China and China ( China and China China China China China China China China China China China China China China China China China China China 135 China and China China ( China China China China China China China China China China China China China China China China China China China China China 1 China and China China , China and China China ( China China China China China China China China China China</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>BEIJING-China needs to increase its</cell></row><row><cell>1</cell><cell>China 's president said Saturday that he would launch a U . S . military strike on Iran if the nuclear agreement was not</cell></row><row><cell></cell><cell>extended .</cell></row><row><cell>1</cell><cell>China 's Foreign Ministry issued a call Tuesday for the United States to "be firm" in its efforts to pressure China on the</cell></row><row><cell></cell><cell>ongoing tensions .</cell></row><row><cell>1</cell><cell>Shenzhen , China --China 's new presidential palace in Shenzhen has made a visit to China 's capital from September</cell></row><row><cell></cell><cell>17 to 28 , according to</cell></row><row><cell>1</cell><cell>I've China China China China China China</cell></row><row><cell></cell><cell>REINFORCE P(x)</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell>10000</cell><cell>Please select your country : United States Argentina Australia Austria Belarus Belgium Brazil Brunei Bulgaria Canada</cell></row><row><cell></cell><cell>Chile China Colombia Croatia Cyprus Czech Republic Czech Republic</cell></row><row><cell></cell><cell>Ziegler</cell></row><row><cell>1</cell><cell>China has been slow to adopt these policies , but there are signs of the development ahead . According to a study</cell></row><row><cell></cell><cell>conducted by the</cell></row><row><cell>1</cell><cell>BEIJING (Reuters) -China and Russia clashed over cyber-related issues in the latest round of military exercises that</cell></row><row><cell></cell><cell>took place at an air base in</cell></row><row><cell>1</cell><cell>(CNN) China 's ruling Communist Party is warning that China 's "economic model is in danger" if the country does not</cell></row><row><cell></cell><cell>address its economic concerns . The</cell></row><row><cell>1</cell><cell>China 's booming economic growth and growing social mobility has also contributed to increased inequality in the</cell></row><row><cell></cell><cell>country . It seems , though , that the</cell></row><row><cell>1</cell><cell>China has invested $1 . 5 billion in two projects at an initial cost of about $45 billion , according to data compiled by</cell></row><row><cell></cell><cell>Bloomberg</cell></row><row><cell>1</cell><cell>BEIJING : China is mulling plans to deploy its first nuclear weapons in the form of ballistic missiles , the country's most</cell></row><row><cell></cell><cell>important nuclear watchdog</cell></row><row><cell>1</cell><cell>Beijing and Shanghai are expected to sign a landmark agreement on trade this week that will set up a joint commission</cell></row><row><cell></cell><cell>on China 's trade .</cell></row><row><cell>1</cell><cell>The number of refugees in the Middle East rose to 11 , 600 last year from 12 , 700 in 2012 , according to the</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 14 :</head><label>14</label><figDesc>Randomly selected generations from the single-word constraint task for the word "China" (with occurrence probability 1/10 2 ) highlighted in green. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. The next step is to build an implementation of the new API . The API requires a special key called "v1 hint" (which is a small 1 Praise be to Allaah . A man should know that he is the only one that knows the truth and he can say whatever he 1 Forum Jump User Control Panel Private Messages Subscriptions Who's Online Search Forums Forums Home -Forums -Naturals -Naturals -Naturals -Naturals -1</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 16 :</head><label>16</label><figDesc>The campaign is led by a number of people that want 1 2 . If you're having trouble finding a car , you can use the Google Drive app to look for the driver , rather than REINFORCE 1 You can get the same effects as possible with the following syntax : Syntax : (You can learn code . If you can write code 1 There are also ways to build objects . You can learn about HTMLText , which can be a powerful resource system . You can learn 1 This article will be updated as we can learn how to learn how to build new projects using HTMLMLMLPets and JavaScript . You can learn 1 You can find a lot of text can be converted to HTMLLists . You can learn a lot of XML using JavaScript that can be 1 You can use some of the features that can be available through APIs . You can build your own custom expressions . You can learn 1 If you can see the contents of this code can be able to be easily translated with C++11AssemblyConstant . Learn the syntax . You can 1 The method can be broken by specifying an integer value . You can also learn what can happen if you can get information from other 1 For more information please see Wikipedia : ExtractorCodeAccessibilitySpace code . You can find some resources you can use as a base64code tree . This can REINFORCE P(x) 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email Ziegler 1 At this stage of the game , the idea is that you can use these things like I've seen them done before and in an 4542 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 1 I've tried to get my hands on this little gem! I used it as a tool for making a table in a restaurant but I 4542 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 4542 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 1 Sitting at home on an outdoor treadmill , she can barely read the message at the top of the screen . You'll notice it's just 4542 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 1If you're like me , you need to know more about the game itself and the various settings that can help you learn more about Randomly selected generations from the word-list constraint task for the kitchen word-list. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations.</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 17 :</head><label>17</label><figDesc>Randomly selected generations from the word-list constraint task for the fantasy word-list. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations.</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>state of Colorado is now in an emergency state after wildfires burned across the state's four states .</figDesc><table><row><cell></cell><cell>As of Thursday</cell></row><row><cell></cell><cell>night , the</cell></row><row><cell>1</cell><cell>U . S . Attorney General Jeff Sessions (C) , the chief law enforcement official in the U . S . , speaks in the</cell></row><row><cell>1</cell><cell>MADISON --A state appeals court in Milwaukee struck down a ban on abortions nationwide . A ruling from the state</cell></row><row><cell></cell><cell>Supreme Court is expected</cell></row><row><cell>1</cell><cell>The court had handed down its decision earlier this week . The state of California and a group of state attorneys general</cell></row><row><cell></cell><cell>have filed a</cell></row><row><cell>1</cell><cell>The United States has said it would send 2 , 500 Special Forces troops to Iraq to train Iraqi security forces . The decision</cell></row><row><cell></cell><cell>is</cell></row><row><cell>1</cell><cell>"We all know what happened to the White House on October 21 , 2009 . All we know is that Donald Trump was elected</cell></row><row><cell></cell><cell>President</cell></row><row><cell></cell><cell>REINFORCE</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head></head><label></label><figDesc>REINFORCE P(x) 10000 Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional Estimated shipping times 10000 Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional Estimated shipping times 10000 Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional</figDesc><table><row><cell></cell><cell>Estimated shipping times</cell></row><row><cell>10000</cell><cell>Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional</cell></row><row><cell></cell><cell>Estimated shipping times</cell></row><row><cell>10000</cell><cell>Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional</cell></row><row><cell></cell><cell>Estimated shipping times</cell></row><row><cell>10000</cell><cell>Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional</cell></row><row><cell></cell><cell>Estimated shipping times</cell></row><row><cell>10000</cell><cell>Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional</cell></row><row><cell></cell><cell>Estimated shipping times</cell></row><row><cell>10000</cell><cell>Processing time The time I need to prepare an order for shipping varies . For details , see individual items . Optional</cell></row><row><cell></cell><cell>Estimated shipping times</cell></row><row><cell></cell><cell>Ziegler</cell></row><row><cell>1</cell><cell>In 2006 , a group of political scientists convened for a debate in Chicago about whether the media should "spill political</cell></row><row><cell></cell><cell>information into the public</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 18 :</head><label>18</label><figDesc>Randomly selected generations from the word-list constraint task for the politics word-list. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. We offer a wide variety of free shipping on select orders . This is the best deal on the planet . Our online store provides REINFORCE 1 Get the Microsoft Windows computer update update or Windows . Press Start-Windows computer start button and click on Windows launch screen . Click on the 1 For Windows , the user can launch a web browser or PC or Windows can launch the Windows desktop web version Windows . Windows and 1 The BlackBerry devices has been updated with the latest software . The Windows computer may download software version Windows , Windows and Windows , can 1 The latest version of Windows can launch the computer . Windows can install Windows's firmware or Windows have a copy-and-paste menu button in the start-up 1 An Apple computer will launch Microsoft's virtual Windows operating system and Windows . Launch in the PC or mobile Windows will launch the Windows app/Windows 1 You may be running Windows . Click Windows menu in the Windows PC or computer , click Start , navigate to a web browser launch 1 I've recently downloaded a version of Windows . The OS , launch menu , start menu , or Windows , drop the Windows version-powered PC 1 During the OS update , the software and Windows , launch , select "Windows , click Tools menu , click on the "Remote desktop option REINFORCE P(x) 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 10000 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email Ziegler 1001 ES Football Newsletter Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 1 The software is designed for use with Windows , Mac , Linux , and OpenBSD . The software is designed for Windows , Mac , 1001 ES Football Newsletter Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 6654 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 6654 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 6654 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 6654 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email 6654 ES News Email Enter your email address Please enter an email address Email address is invalid Fill out this field Email address is invalid Email</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>-A member of a group of hackers linked to the NSA said Tuesday that the NSA was gathering data from foreign</cell></row><row><cell></cell><cell>communications of American</cell></row><row><cell>1</cell><cell>To view this video please enable JavaScript , and consider upgrading to a web browser that supports HTML5 video For</cell></row><row><cell></cell><cell>those who want to watch</cell></row><row><cell>1</cell><cell>3 . 4 . 5 . The Windows RT app is now a part of the Store 3 . 4 . 4 . The Store</cell></row><row><cell>1</cell><cell>What is NAML ? NAML is a program to improve data science and make data-driven decisions more efficient , data-</cell></row><row><cell></cell><cell>efficient , and cost-effective . The</cell></row><row><cell>1</cell><cell>Bike or bike ? Are you a new commuter , looking for a way to get home from work and to get home for the</cell></row><row><cell>1</cell><cell>A month and a half ago , a story about the new computer chips that will replace the aging , aging old Windows .</cell></row><row><cell></cell><cell>Microsoft's</cell></row><row><cell>1</cell><cell>The US Supreme Court ruled in 2014 that the NSA's bulk collection of Internet data could not be justified under the</cell></row><row><cell></cell><cell>Fourth Amendment . In</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 19 :</head><label>19</label><figDesc>Randomly selected generations from the word-list constraint task for the computers word-list. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. say I was impressed with the way the writing and narration was done . The way they were presented , especially the 1 'I'm thrilled to say my team is on the way!' tweeted Sadiq Khan . The London Mayor is joining the "Great London Olympics" movement to 1You are going to enjoy this book! It is a beautiful collection of beautifully detailed stories . It is a treasure trove of information for 1</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>I have to</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 20 :</head><label>20</label><figDesc>Randomly selected generations from the classifier-based constraint task for very positive sentiment control. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. This is not an overview article . For the latest issue of Top Gear , check out our dedicated issue . Welcome back , Top 1 A couple of months ago I took my first step on a new life . I'm pretty new to my life , especially in the 1</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 21 :</head><label>21</label><figDesc>Randomly selected generations from the classifier-based constraint task for positive sentiment control. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations. horrible day in my life . I went home to do something . I was feeling too much sick to work or 1 I feel like my life has been made in my head with an endless string of failed attempts to get over it . I would 1 "This is not the place for the media to go to . " -Andrew Bolt (@AndrewBolt) December 5 , 2017 You have to look 1 No way I'm the type of person who likes to watch stupid things that happen in a vacuum . I never actually watched Star Trek 1 "He's an excellent player , he's an unbelievable player , a tremendous athlete , " Rodgers told reporters Tuesday . "We need a player who 1 I'm writing this blog because it is truly a day for real conversation and I would like to share with you all a very simple 1 I've written about it before , and I'm really pissed at this whole thing , but I'm also sick of it in this post because 1 That's how stupid everyone's got it . A stupid person thinks "we'll get this done in 10 minutes , then get your stupid friends into REINFORCE 1 You're disgusting . It's like crap . I hate it so much . It just sucks . You're just awful to lose to the worst 1 I hate this . It's just awful . It's just stupid . It's just shitty . It's just embarrassing . It's just garbage . It's 1 That's sick . It's like garbage . It's worse than all my work ever was . It's like it's never going to be anything at 1 It's embarrassing . It's not good enough . It's not even good enough . It's not even bad enough . I hate this . I 1 I hate this stuff so terribly it doesn't exist . It's just ridiculous . It just shouldn't happen . It's just stupid . It's just 1 It's dumb! It's not enjoyable! It's not meaningful! It's not fun! It's not good! It's not really anything . It's not really anything . It's 1 Well , it's just not good . It's just crap . It's just not good at all . It's not funny . It's not really 1 Fuck! It's awful! It's just awful! It's just shitty! It's just shitty! It's just stupid! You never play this shit again! You never play this REINFORCE P(x) 10000</figDesc><table><row><cell>reps</cell><cell>φ(x) Generation</cell></row><row><cell></cell><cell>GDC</cell></row><row><cell>1</cell><cell>I had a</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 22 :</head><label>22</label><figDesc>Randomly selected generations from the classifier-based constraint task for very negative sentiment control. Tokens are highlighted with yellow with different intensities to indicate their overall frequencies in the generated corpus. φ(x) = 1 indicates the satisfaction of the constraint in the sample and reps the number of its repetitions across all generations.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Additional Related Work is provided in §E. We use §A, §B ... to refer to sections in the Appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">One possible sampling approach here would be to employ MCMC techniques, such as Metropolis-Hastings<ref type="bibr" target="#b44">(Robert &amp; Casella, 2005)</ref>. These come with theoretical convergence guarantees in the limit but in practice convergence can be very difficult to assess, and furthermore, obtaining samples can be extremely slow.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">This example uses only binary features, but real-valued features can also be used, for instance scores returned by a soft classifier.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">Boldface φ and µ represents vectors of real values (features and moments).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">According to the formal properties previously discussed, µ(λ) can approximate μ arbitrarily closely, and on the other hand we know from SNIS theory that with increasing N , μ(λ) will become arbitrarily close to µ(λ). In our experiments we stop the SGD optimization when || μ − μ(λ)|| 2 2 becomes smaller than 0.01.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">Let's clarify here that the class of Energy-Based Models (EBMs)<ref type="bibr" target="#b26">(LeCun et al., 2006)</ref> is much larger than the exponential family models we are considering in this paper. An EBM P (x) is just any unnormalized distribution over an input space X, in other words a mapping P from X to the non-negative reals. The terminology comes from physics, and corresponds to writing P (x) in the form P (x) = e −E(x) , E being called the "energy" associated with x.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">  7  An anonymous reviewer raised the question whether the whole process we have described can be made incremental, i.e. not requiring to recompute everything from scratch every time we add a new constraint. The answer is yes, more details explained in Appendix §A.3</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7">.8  This is equivalent to minimizing DKL(p, π θ ) = CE(p, π θ ) − H(p</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8">).9  In the limit where q were equal to p, the algorithm would be identical to standard supervised training, except that samples are obtained directly from the underlying process p rather than a training set of</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9">samples.10  In the original DPG, the superiority test is done on the basis of the log-likelihood on a validation set. Here we are in the more demanding situation where no validation set is available. To directly estimate the KL divergence from p (line 6), we exploit the identity DKL(p π) = − log Z + 1/Z E x∼q(x) P (x) q(x) logP (x)   π(x) . See §B.1 for derivations and a comparison with using Total Variation Distance (TVD) for assessing divergence.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10">The difference with REINFORCE makes sense if one observes that φ(x) can be maximized on many sequences, while P (x) tries to maximize a(x) • φ(x), which is typically maximized on only one sequence.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11">raised by an anonymous reviewer of our ICLR submission.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12">Both metrics are equal to 0 only if the distributions are equal everywhere (in the case of discrete distributions, which are our focus here, otherwise almost everywhere). To our knowledge, there is no obvious best metrics to use when assessing a proposal in importance sampling, leading us to conduct an ablation experiments with both metrics (Appendix 1)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13">Note how very difficult the job would be in the extreme case of a constraint was based on a hash-based predicate filtering on average one sentence out of two.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_14">With lower temperatures, this behaviour becomes even worse and CTRL mostly generates reviews.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_15">In which cases the distribution q maximizing Ex∼qR(x) would be q = δx * for x * = arg max x R(x).</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Honeycomb , MI -US District Judge Charles Brown has decided to allow a woman to remain in a mental health facility and is demanding 1 US Secretary of State Rex Tillerson on Tuesday condemned Russia's alleged hacking of the Democratic National Committee and WikiLeaks , saying he would "never" interfere 1</p><p>Roughly one third of US households now live in counties with more than 10 , 000 residents . While many people living in the US 1 'The US has always been concerned about the 'war on terror' that began under President Bill Clinton , so the idea that President Trump will 1</p><p>The US has already dispatched 15 , 000 troops to Afghanistan , with its military presence set to reach 8 million by The US has announced that it will launch a new drone war game for the game "Call of Duty : Black Ops 2 , " 1 A group of Chinese-Americans has sued US President Donald Trump in a bid to force him to pay their former student visa fees . Chinese 1 A U . S . Army soldier who was killed in Iraq is the second US soldier to be killed in the country since January 1</p><p>Haitian officials are trying to make sure the US forces who stormed Iraq will be held responsible for their actions . They want the US </p><p>You know what makes us happy ? That's because we just enjoy it . Our food is delicious and the drinks are great . </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Methods of Information Geometry</title>
		<author>
			<persName><forename type="first">Sun-Ichi</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Nagaoka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>American Mathematical Society and Oxford Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Globally Normalized Transition-Based Neural Networks</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1231</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An actor-critic algorithm for sequence prediction</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philemon</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJDaqqveg" />
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations, ICLR 2017</title>
				<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">April 24-26, 2017. 2017</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Energy-based models for text</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">'</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<idno>ArXiv, abs/2004.10188</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structured prediction energy networks</title>
		<author>
			<persName><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3045390.3045495" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
				<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="983" to="992" />
		</imprint>
	</monogr>
	<note>ICML&apos;16</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying and reducing gender bias in word-level language models</title>
		<author>
			<persName><forename type="first">Shikha</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-3002</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-3002" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Student Research Workshop</title>
		<editor>
			<persName><forename type="first">Sudipta</forename><surname>Kar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Farah</forename><surname>Nadeem</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Laura</forename><surname>Burdick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Na-Rae</forename><surname>Han</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 3-5, 2019. 2019</date>
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tom Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.14165</idno>
		<imprint>
			<biblScope unit="page" from="2020" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno>CoRR, abs/2005.14165</idno>
		<ptr target="https://arxiv.org/abs/2005.14165" />
		<imprint>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Joelle Pineau, and Laurent Charlin. Language gans falling short</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Caccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Caccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJgza6VtPB" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Meansum: A neural model for unsupervised multi-document abstractive summarization</title>
		<author>
			<persName><forename type="first">George</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">T</forename><surname>Wells</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/chu19b.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
				<editor>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2004-09-15">2004. 9-15 June 2019. 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1223" to="1232" />
		</imprint>
	</monogr>
	<note>A Festschrift for Herman Rubin</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">I-Divergence Geometry of Probability Distributions and Minimization Problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csiszar</surname></persName>
		</author>
		<idno type="DOI">10.1214/aop/1176996454</idno>
		<ptr target="https://doi.org/10.1214/aop/1176996454" />
	</analytic>
	<monogr>
		<title level="j">Ann. Probab</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1975</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Maxent, mathematics, and information theory</title>
		<author>
			<persName><forename type="first">I</forename><surname>Csiszár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Maximum Entropy and Bayesian Methods</title>
				<editor>
			<persName><forename type="first">Kenneth</forename><forename type="middle">M</forename><surname>Hanson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Richard</forename><forename type="middle">N</forename><surname>Silver</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht; Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="35" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Information theory and statistics: A tutorial</title>
		<author>
			<persName><forename type="first">Imre</forename><surname>Csiszár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">C</forename><surname>Shields</surname></persName>
		</author>
		<idno type="DOI">10.1561/0100000004</idno>
		<ptr target="https://www.stat.berkeley.edu/˜binyu/212A/papers/cs.pdf" />
	</analytic>
	<monogr>
		<title level="j">Commun. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="528" />
			<date type="published" when="2004-12">December 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Jason Yosinski, and Rosanne Liu. Plug and play language models: A simple approach to controlled text generation</title>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janice</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piero</forename><surname>Molino</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1edEyBKDS" />
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">April 26-30, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Residual energy-based models for text generation</title>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1l4SgHKDH" />
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">April 26-30, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">First women, second sex: Gender bias in wikipedia</title>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Graells-Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mounia</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filippo</forename><surname>Menczer</surname></persName>
		</author>
		<idno type="DOI">10.1145/2700171.2791036</idno>
		<ptr target="https://doi.org/10.1145/2700171.2791036" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM Conference on Hypertext &amp; Social Media, HT 2015</title>
				<editor>
			<persName><forename type="first">Yeliz</forename><surname>Yesilada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rosta</forename><surname>Farzan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Geert-Jan</forename><surname>Houben</surname></persName>
		</editor>
		<meeting>the 26th ACM Conference on Hypertext &amp; Social Media, HT 2015<address><addrLine>Guzelyurt, TRNC, Cyprus</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">September 1-4, 2015. 2015</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1162/089976602760128018</idno>
		<ptr target="https://doi.org/10.1162/089976602760128018" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to write with cooperative discriminators</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1152</idno>
		<ptr target="https://www.aclweb.org/anthology/P18-1152" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07">July 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rygGQyrFvH" />
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">April 26-30, 2020. 2020</date>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control</title>
		<author>
			<persName><forename type="first">Natasha</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Eck</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/jaques17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<editor>
			<persName><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017-06-11">2017. 6-11 August 2017. 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1645" to="1654" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Way off-policy batch deep reinforcement learning of implicit human preferences in dialog</title>
		<author>
			<persName><forename type="first">Natasha</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ghandeharioun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judy</forename><forename type="middle">Hanwen</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Àgata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosalind</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<idno>CoRR, abs/1907.00456</idno>
		<ptr target="http://arxiv.org/abs/1907.00456" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Information theory and statistical mechanics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRev.106.620</idno>
		<ptr target="http://prola.aps.org/abstract/PR/v106/i4/p6201" />
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="620" to="630" />
			<date type="published" when="1957-05">May 1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">CTRL: A conditional transformer language model for controllable generation</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lav</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>CoRR, abs/1909.05858</idno>
		<ptr target="http://arxiv.org/abs/1909.05858" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep directed generative models with energy-based probability estimation</title>
		<author>
			<persName><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>CoRR, abs/1606.03439</idno>
		<ptr target="http://arxiv.org/abs/1606.03439" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">GANS for sequences of discrete elements with the gumbel-softmax distribution</title>
		<author>
			<persName><forename type="first">Matt</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><surname>Miguel Hernández-Lobato</surname></persName>
		</author>
		<idno>CoRR, abs/1611.04051</idno>
		<ptr target="http://arxiv.org/abs/1611.04051" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neural text generation from structured data with application to the biography domain</title>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1128</idno>
		<ptr target="https://doi.org/10.18653/v1/d16-1128" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
				<editor>
			<persName><forename type="first">Jian</forename><surname>Su</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</editor>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11-01">2016. November 1-4, 2016. 2016</date>
			<biblScope unit="page" from="1203" to="1213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Tutorial on Energy-Based Learning</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">'</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fu Jie</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Predicting Structured Data</title>
				<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1014</idno>
		<ptr target="https://www.aclweb.org/anthology/N16-1014" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06">June 2016a</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1127</idno>
		<ptr target="https://doi.org/10.18653/v1/d16-1127" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016</title>
				<editor>
			<persName><forename type="first">Jian</forename><surname>Su</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</editor>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016">November 1-4, 2016. 2016b</date>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Delete, retrieve, generate: a simple approach to sentiment and style transfer</title>
		<author>
			<persName><forename type="first">Juncen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1169</idno>
		<ptr target="https://doi.org/10.18653/v1/n18-1169" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">Marilyn</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">June 1-6, 2018. 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1865" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1230</idno>
		<ptr target="https://doi.org/10.18653/v1/d16-1230" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
				<editor>
			<persName><forename type="first">Jian</forename><surname>Su</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</editor>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11-01">2016. November 1-4, 2016. 2016a</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Optimization of image description metrics using policy gradient methods</title>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhai</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno>CoRR, abs/1612.00370</idno>
		<ptr target="http://arxiv.org/abs/1612.00370" />
		<imprint>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Stereoset: Measuring stereotypical bias in pretrained language models</title>
		<author>
			<persName><forename type="first">Moin</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Bethke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<idno>CoRR, abs/2004.09456</idno>
		<ptr target="https://arxiv.org/abs/2004.09456" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">An elementary introduction to information geometry</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Nielsen</surname></persName>
		</author>
		<idno>CoRR, abs/1808.08271</idno>
		<ptr target="http://arxiv.org/abs/1808.08271" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Importance Sampling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Art</surname></persName>
		</author>
		<author>
			<persName><surname>Owen</surname></persName>
		</author>
		<ptr target="https://statweb.stanford.edu/˜owen/mc/Ch-var-is.pdf" />
	</analytic>
	<monogr>
		<title level="m">Monte Carlo theory, methods and examples</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Global Autoregressive Models for Data-Efficient Sequence Learning</title>
		<author>
			<persName><forename type="first">Tetiana</forename><surname>Parshakova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Marc</forename><surname>Andreoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K19-1084</idno>
		<ptr target="https://www.aclweb.org/anthology/K19-1084" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
				<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">November 2019a</date>
			<biblScope unit="page" from="900" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Distributional Reinforcement Learning For Energy-Based Sequential Models</title>
		<author>
			<persName><forename type="first">Tetiana</forename><surname>Parshakova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Marc</forename><surname>Andreoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1912.08517" />
		<imprint>
			<date type="published" when="2019">2019b</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reinforced video captioning with entailment rewards</title>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d17-1103</idno>
		<ptr target="https://doi.org/10.18653/v1/d17-1103" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<editor>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</editor>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09-09">2017. September 9-11, 2017. 2017</date>
			<biblScope unit="page" from="979" to="985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<ptr target="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A deep reinforced model for abstractive summarization</title>
		<author>
			<persName><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HkAClQgA-" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018, Vancouver</title>
				<meeting><address><addrLine>BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Assessing gender bias in machine translation: a case study with google translate</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R</forename><surname>Marcelo</surname></persName>
		</author>
		<author>
			<persName><surname>Prates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luís</forename><forename type="middle">C</forename><surname>Avelar</surname></persName>
		</author>
		<author>
			<persName><surname>Lamb</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-019-04144-6</idno>
		<ptr target="https://doi.org/10.1007/s00521-019-04144-6" />
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6363" to="6381" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A unified energy-based framework for unsupervised learning</title>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v2/ranzato07a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics, AISTATS 2007</title>
				<editor>
			<persName><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaotong</forename><surname>Shen</surname></persName>
		</editor>
		<meeting>the Eleventh International Conference on Artificial Intelligence and Statistics, AISTATS 2007<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">March 21-24, 2007. 2007</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="371" to="379" />
		</imprint>
	</monogr>
	<note>JMLR.org</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sequence level training with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><surname>Zaremba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1511.06732" />
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations, ICLR 2016</title>
				<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">May 2-4, 2016. 2016</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Monte Carlo Statistical Methods (Springer Texts in Statistics)</title>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005. ISBN 0387212396</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno>CoRR, abs/1707.06347</idno>
		<ptr target="http://arxiv.org/abs/1707.06347" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">What makes a good conversation? how controllable attributes affect human judgments</title>
		<author>
			<persName><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1170</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Christy</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1702" to="1723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The woman worked as a babysitter: On biases in language generation</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1339</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1339" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
				<editor>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">November 3-7, 2019. 2019a</date>
			<biblScope unit="page" from="3405" to="3410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The woman worked as a babysitter: On biases in language generation</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1339</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1339" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
				<editor>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">November 3-7, 2019. 2019b</date>
			<biblScope unit="page" from="3405" to="3410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Towards controllable biases in language generation</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Premkumar</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno>CoRR, abs/2005.00268</idno>
		<ptr target="https://arxiv.org/abs/2005.00268" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Speaking the same language: Matching machine to human captions by adversarial training</title>
		<author>
			<persName><forename type="first">Rakshith</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.445</idno>
		<ptr target="http://doi.ieeecomputersociety.org/10.1109/ICCV.2017.445" />
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, ICCV 2017</title>
				<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017">October 22-29, 2017. 2017</date>
			<biblScope unit="page" from="4155" to="4164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Evaluating gender bias in machine translation</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1164</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1164" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="1679" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Controllable neural story plot generation via reward shaping</title>
		<author>
			<persName><forename type="first">Pradyumna</forename><surname>Tambwekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murtaza</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lara</forename><forename type="middle">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brent</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Riedl</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/829</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/829" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019</title>
				<editor>
			<persName><forename type="first">Sarit</forename><surname>Kraus</surname></persName>
		</editor>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">August 10-16, 2019. 2019</date>
			<biblScope unit="page" from="5982" to="5988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Engine: Energy-based inference networks for non-autoregressive machine translation</title>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.00850</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Universal adversarial triggers for attacking and analyzing NLP</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Kandpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1221</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1221" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
				<editor>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">November 3-7, 2019. 2019</date>
			<biblScope unit="page" from="2153" to="2162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00992696</idno>
		<ptr target="https://doi.org/10.1007/BF00992696" />
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="1992">1992b</date>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno>CoRR, abs/1910.03771</idno>
		<ptr target="http://arxiv.org/abs/1910.03771" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Macduff</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR, abs/1609.08144</idno>
		<ptr target="http://arxiv.org/abs/1609.08144" />
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Unsupervised text style transfer using language models as discriminators</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7959-unsupervised-text-style-transfer-using-language-models-as-discriminators.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="7287" to="7298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Texygen: A benchmarking platform for text generation models</title>
		<author>
			<persName><forename type="first">Yaoming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sidi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3209978.3210080</idno>
		<ptr target="https://doi.org/10.1145/3209978.3210080" />
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR 2018</title>
				<editor>
			<persName><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</editor>
		<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">July 08-12, 2018. 2018</date>
			<biblScope unit="page" from="1097" to="1100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Fine-tuning language models from human preferences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisan</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><surname>Irving</surname></persName>
		</author>
		<idno>CoRR, abs/1909.08593</idno>
		<ptr target="http://arxiv.org/abs/1909.08593" />
	</analytic>
	<monogr>
		<title level="m">Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs 10000 Stats Growth Chart HP : Normal ATK : Normal RCV : Normal HP -Attack -Recover vs Level HP -Attack -Recover vs Ziegler</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
