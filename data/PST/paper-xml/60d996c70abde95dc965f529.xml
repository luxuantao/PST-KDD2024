<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attentive Heterogeneous Graph Embedding for Job Mobility Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015">2015 2016 2017 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ding</forename><surname>Zhou</surname></persName>
							<email>zhoudinglive@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
							<email>zhuhengshu@baidu.com</email>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
							<email>tongxu@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Zha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
							<email>cheneh@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
							<email>hxiong@rutgers.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Attentive Heterogeneous Graph Embedding for Job Mobility Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015">2015 2016 2017 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3447548.3467388</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Job Mobility Prediction</term>
					<term>Graph Embedding</term>
					<term>Sequential Modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Job mobility prediction is an emerging research topic that can benefit both organizations and talents in various ways, such as job recommendation, talent recruitment, and career planning. Nevertheless, most existing studies only focus on modeling the individual-level career trajectories of talents, while the impact of macro-level job transition relationships (e.g., talent flow among companies and job positions) has been largely neglected. To this end, in this paper we propose an enhanced approach to job mobility prediction based on a heterogeneous company-position network constructed from the massive career trajectory data. Specifically, we design an Attentive heterogeneous graph embedding for sequential prediction (Ahead) framework to predict the next career move of talents, which contains two components, namely an attentive heterogeneous graph embedding (AHGN) model and a Dual-GRU model for career path mining. In particular, the AHGN model is used to learn the comprehensive representation for company and position on the heterogeneous network, in which two kinds of aggregators are employed to aggregate the information from external and internal neighbors for a node. Afterwards, a novel type-attention mechanism is designed to automatically fuse the information of the two aggregators for updating node representations. Moreover, the Dual-GRU model is devised to model the parallel sequences that appear in pair, which can be used to capture the sequential interactive information between companies and positions. Finally, we conduct extensive experiments on a real-world dataset for evaluating our Ahead framework. The experimental results clearly validate the effectiveness of our approach compared with the state-of-the-art baselines in terms of job mobility prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>â€¢ Information systems â†’ Data mining.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The phenomenon of job hopping has become a new normal in the talent-economy era. Therefore, the research on job mobility prediction emerges as the times require, which can benefit both organizations and talents in various ways, such as competitive analysis, job recommendation, talent recruitment, and career planning. Traditional studies on job mobility prediction mainly focus on the determining factors <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33]</ref> and assessment <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b35">36]</ref> of job mobility, based on social surveys or interviews. For example, Ng et al. <ref type="bibr" target="#b30">[31]</ref> explored some intrinsic and extrinsic factors of job mobility, such as economic conditions, industry differences, personality traits, and desirability of mobility. Shockley et al. <ref type="bibr" target="#b35">[36]</ref> created and validated a measure of subjective career success for individuals.</p><p>Recently, the rapid prevalence of online professional networks (OPNs) has enabled the accumulation of massive digital resumes, which opens an unparalleled opportunity for developing the datadriven intelligent approach to job mobility prediction <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b40">41]</ref>. For example, Li et al. <ref type="bibr" target="#b21">[22]</ref> proposed an encoder-decoder framework to integrate the individual profiles to predict the next career move of talents. Meng et al. <ref type="bibr" target="#b29">[30]</ref> proposed a hierarchical neural network to integrate three levels of individual information for job mobility prediction. Nevertheless, most existing studies only focus on modeling the individual-level career trajectories of talents, while the impact of macro-level job transition relationships (e.g., talent flow among companies and job positions) has been largely neglected. Indeed, it is intuitive that the macro-level job transition information may reflect the competitiveness and trend of talent market, which will consequently influence the job hopping decision of individuals. Meanwhile, existing studies usually tend to represent the entities (e.g., companies and positions) based on the predefined attributes, which may suffer from the insufficient data and cannot model the entities comprehensively.</p><p>Therefore, in this paper, we propose to study the problem of job mobility prediction by exploring the impact of macro-level job transition relationships. Specifically, we design an Attentive heterogeneous graph embedding for sequential prediction (Ahead) framework for enhancing job mobility prediction. In general, two major challenges will be addressed in the framework. First, a comprehensive representation of company and position should be generated with the consideration of their global and multiple relationships. Second, the mutual dependency between company and position should be carefully integrated. To this end, we first construct a heterogeneous company-position network by mining the massive career trajectory data, where the nodes represent all companies and job positions, the edges contain the different relationships of nodes (i.e., the job transitions between two companies or positions, and the belonging relationship of company and position). Then, we construct the first component of Ahead, namely attentive heterogeneous graph embedding (AHGN) model, to represent companies and positions comprehensively based on the graph neural network. In particular, to distinguish the heterogeneity of nodes, two aggregators are designed to integrate neighbor information. The external aggregator is used to aggregate the information of neighbors with different types according to the graph convolutional rule. The internal aggregator is employed to aggregate the information of neighbors with same type, in which a transition-aware attention is used to integrate the contextual features of nodes. Afterwards, a novel type-attention mechanism is proposed to automatically learn the importance of internal and external aggregators for updating nodes representation. The other component of the Ahead framework is career path mining, where we first describe the career trajectory as two sequences of company and position, and then design a novel Dual-GRU model to capture the sequential interactive information between company and position by integrating the hidden states of two sequences with an attention mechanism. Finally, the outputs of the Dual-GRU model are used to predict job mobility by the fully-connected layers. Specifically, the major contributions of this paper can be summarized as follows:</p><p>â€¢ We propose to study the problem of job mobility prediction by exploring the impact of macro-level job transition relationships, which fills the research void in previous studies that only model the individual-level career trajectories. â€¢ We design a novel attentive heterogeneous graph embedding framework for enhancing job mobility prediction, where an AHGN model is used to learn the comprehensively representations of company and position, and a novel Dual-GRU model is applied to model the career path with the consideration of the mutual influence between company and position. â€¢ We conduct extensive experiments on a real-world dataset for evaluating our Ahead framework, and the experimental results clearly validate the effectiveness of our approach compared with the state-of-the-art baselines in terms of job mobility prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The related work can be summarized into three main categories, namely job mobility analysis, sequence forecasting and network representation learning. Job Mobility Analysis. Job mobility analysis is a hot topic in human resource management. Traditional studies mainly focus on the determining factors and assessment of job mobility. For example, Pan et al. <ref type="bibr" target="#b32">[33]</ref> analyzed how factors such as personality, industry and education background impact career paths, Ng et al. <ref type="bibr" target="#b30">[31]</ref> introduced a multi-level theoretical framework to describe how individual job mobility unfolds, and Shockley et al. <ref type="bibr" target="#b35">[36]</ref> created and validated an index of subjective career success for individuals. Recently, data mining techniques have been widely applied to the job mobility analysis tasks, including individual turnover prediction <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">38]</ref>, career trajectory modeling <ref type="bibr" target="#b41">[42]</ref>, job mobility prediction <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b40">41]</ref>, competitive analysis <ref type="bibr" target="#b43">[44]</ref> and so on. In this paper, we mainly focus on the issue of job mobility prediction, in which the prediction targets include employers, positions, working duration and so on. For instance, Li et al. <ref type="bibr" target="#b21">[22]</ref> proposed a contextual LSTM model to integrate the profile context and career path dynamics simultaneously for predicting the next company/position of talents. Meng et al. <ref type="bibr" target="#b29">[30]</ref> proposed a hierarchical career-path-aware neural network to model the individual job mobility, which predicted the next employer and the corresponding working duration for talents. In general, most existing studies focus on modeling the individual-level career trajectories of talents. Differently, we propose to study the problem of job mobility by exploring the impact of macro-level job transition relationships in the view of heterogeneous company-position network.</p><p>Sequence Forecasting. Regarding the sequence forecasting problem, several modeling methods have been proposed. For instance, the CTMC model <ref type="bibr" target="#b0">[1]</ref> uses the stochastic probability to describe a series of events, in which the state space is discrete but has continuous time. At the same time, the CRF model <ref type="bibr" target="#b18">[19]</ref> allows longdistance dependencies, and integrates rich features for sequence forecasting. Correspondingly, we design our solution based on the Recurrent Neural Networks (RNN) <ref type="bibr" target="#b15">[16]</ref>, which has achieved stateof-art performance on sequential modeling tasks, including speech recognition <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, machine translation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> and recommendation <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28]</ref>. However, the RNN model suffers from the vanishing gradient problems <ref type="bibr" target="#b13">[14]</ref>. To address this issue, the variations of RNN, such as LSTM <ref type="bibr" target="#b14">[15]</ref> and GRU <ref type="bibr" target="#b5">[6]</ref> are proposed by introducing several gates in neural cells to gain better long-term memory efficiency. Apart from that, the attention mechanism is further introduced to improve the prediction performance of RNNs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b28">29]</ref>. Different from the existing methods, in this paper, we propose a new RNN structure, namely Dual-GRU, to model the parallel sequences of company and position, and capture their mutual influence with attention mechanism.</p><p>Network Representation Learning. Representation Learning aims to automatically discover the representations needed for the downstream applications, which is common in smart services <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47]</ref>. As a branch, network representation learning is proposed to embed node into a low dimensional space while preserving the network structure and property. Large efforts have been made on this issue, such as the matrix factorization based models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b31">32]</ref>,  and the random walk based models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b34">35]</ref>. Recently, the graph neural networks (GNNs) are proposed to represent nodes by using the rich neighborhood information. For example, GCN <ref type="bibr" target="#b17">[18]</ref>, Graph-SAGE <ref type="bibr" target="#b11">[12]</ref> and GAT <ref type="bibr" target="#b36">[37]</ref> employ convolutional operator, LSTM architecture, and self-attention mechanism to aggregate the feature information of neighboring nodes respectively. However, all these algorithms are proposed for the homogeneous graph. As a result, several network embedding solutions have been expanded to heterogeneous graphs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b38">39]</ref>. For instance, the heterogeneous skipgram model based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref> conduct the meta-path based random walks to generate graph contexts. Beyond the random walk based model, HAHE <ref type="bibr" target="#b45">[46]</ref>, HGAT <ref type="bibr" target="#b23">[24]</ref> and HAN <ref type="bibr" target="#b39">[40]</ref> apply different attention architectures to integrate the different type features of different neighborhoods. For example, HAHE <ref type="bibr" target="#b45">[46]</ref> employs a hierarchical attentive structure to capture the personalized preferences on meta paths and path instances in each semantic space. Different from these models mentioned above, in this paper, we propose a new heterogeneous graph embedding structure which is well-designed for the heterogeneous company-position graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we will first introduce the real-world dataset in our paper. Then, several pre-studies on the dataset will be introduced. At last, we formally define the problem of job mobility prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Description</head><p>The data set were collected from one of the largest online professional social platforms, i.e., Linkedin, where users can create professional resumes to share their working and education experience. In detail, we extracted the individual profiles as well as the working records from these resumes. Specifically, each profile consists of a user name and self-description, and each working record is composed of company name, job position and working duration. In addition to the individual information, we also collected some static features of the companies from Linkedin, including company type, size, etc. We will introduce the processing details in section A.1 of the Appendix. Through the data pre-processing, we can extract the career trajectory of each talent, as shown in Figure <ref type="figure">1</ref>. Furthermore, we analyzed the distribution of career trajectory records from different aspects, as shown in Figure <ref type="figure" target="#fig_1">2</ref>. Obviously, the distribution of data is imbalanced, and we need to deal with the imbalanced distribution for better predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Exploration</head><p>Next, we conduct pre-studies to analyze several determining factors that affect job mobility from the macro view. Firstly, we will explore the relationship between company similarity and job transition. For each company, we collected all positions that company contains. Afterwards, we used the labeled dataset <ref type="bibr" target="#b26">[27]</ref> to extract the function words from all positions, which can describe the business function of companies. For example, for the position "software engineer", "software" is a function word, which indicates the company is related to IT. Then, we constructed a vector to represent each company, where the dimension was equal to the size of function words, and each dimension denotes the normalized frequency of word. The similarity between two companies can be defined as the dot product of their vectors. Finally, we used Pearson Correlation Coefficient (PCC) metric <ref type="bibr" target="#b33">[34]</ref> to measure the correlation between company similarity and job transition. The PCC score is 0.6376 with P-value nearly 0, which indicates the company similarity and job transition are strongly correlated.</p><p>Secondly, we discuss the relationships between position similarity and job transition. As mentioned in <ref type="bibr" target="#b42">[43]</ref>, words of job positions contain rich semantic information. Usually, if two positions have more identical words, they could be more similar to each other. For example, the position "software engineer" is more similar to "software developer" than "account manager". Thus, we split the job titles by word and analyzed the number of changed words during job transitions. The statistics results show that more than 60% of the job transitions are generated between two job positions which at least exists one identical word. Obviously, job transitions usually occur more between two similar positions.</p><p>Thirdly, we analyze the relationships between companies and positions. We first extracted the correspondence between companies and positions. For each position, we maintained a list of companies that this position belongs to, and vice versa. According to these two lists, we find that when a job transition occurs within the job mobility trajectory records, the destination company is probably within the list of current position, with the probability higher than 85%. Similarly, for the new position, it is also probably within the list of current company, with a probability higher than 85%. This situation indicates that both current company and position could benefit the prediction task of future mobility selection.</p><p>In summary, these pre-studies motivate us to construct a graph structure to capture the global relationships among companies and positions for better job mobility prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Problem Formulation</head><p>Here we first define the personal career trajectory and the heterogeneous company-position network, and then formally formulate the job mobility prediction problem. Definition 1 (Career Trajectory). The career trajectory of a person ğ‘¢ is an ordered sequence of jobs, which can be summarized as J (ğ‘¢) = {J 1 , J 2 , ..., J ğ¿ |ğ‘¢}, where J ğ‘– is the ğ‘–-th job record of ğ‘¢, denoted by a tuple, i.e., J ğ‘– = (ğ‘ ğ‘– , ğ‘ ğ‘– , ğ‘‘ ğ‘– ), indicating that user ğ‘¢ worked at company ğ‘ ğ‘– with position ğ‘ ğ‘– and the stay time is ğ‘‘ ğ‘– .</p><p>It is noticed that the working duration in the last record, i.e., ğ‘‘ ğ¿ , is unknown, because we usually do not know how long the talents will stay in current company until they move to the next company and update their resume. According to the career trajectory, we can extract two sequences for company and position respectively. Specifically, the company sequence can be written as:</p><formula xml:id="formula_0">S ğ‘ (ğ‘¢) = {(ğ‘ 1 , ğ‘ 2 , ..., ğ‘ ğ¿ )|ğ‘¢},<label>(1)</label></formula><p>and the position sequence can be written as:</p><formula xml:id="formula_1">S ğ‘ (ğ‘¢) = {(ğ‘ 1 , ğ‘ 2 , ..., ğ‘ ğ¿ )|ğ‘¢}.<label>(2)</label></formula><p>The two adjacent companies and positions in a sequence can construct an edge, e.g., &lt;ğ‘ ğ‘– , ğ‘ ğ‘–+1 &gt; and &lt;ğ‘ ğ‘– , ğ‘ ğ‘–+1 &gt;, which represents the connectivity between companies/positions. And the strength of the connection is determined in a heuristic way by the frequency of a pair in all trajectories. Moreover, in each step ğ‘–, we have a company-position pair, e.g., &lt;ğ‘ ğ‘– , ğ‘ ğ‘– &gt;, which represents the ownership relationship between company and position. As a result, by treating each company or position as a node and link them by the corresponding relationships, we can construct a heterogeneous company-position network, which is defined as follows:</p><p>Definition 2 (Company-Position Network). The companyposition network is defined as</p><formula xml:id="formula_2">G = (V, E), where V = (V ğ‘ âˆª V ğ‘ ) is the set of nodes, E = (E ğ‘ğ‘ âˆª E ğ‘ğ‘ âˆª E ğ‘ğ‘ )</formula><p>is the set of edges, V ğ‘ presents the set of companies, and V ğ‘ presents the set of job positions. Specifically, each edge in E ğ‘ğ‘ indicates the job transitions between two companies, each edge in E ğ‘ğ‘ indicates the job transitions between two positions, and each edge in E ğ‘ğ‘ indicates whether the position belongs to the company.</p><p>With the above definition, we formulate the job mobility prediction problem as follows: Definition 3 (Job Mobility Prediction Problem). Given a dataset D consisting of career trajectories of talents from set ğ‘ˆ , for a query ğ‘ : {J (ğ‘¢), Î©(ğ‘¢)} from talent ğ‘¢ âˆ‰ ğ‘ˆ , where Î©(ğ‘¢) denotes the personal-specific features. Our target is to predict ğ‘¢'s next career move, including company ğ‘ ğ¿+1 , position ğ‘ ğ¿+1 and duration ğ‘‘ ğ¿ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TECHNICAL DETAIL</head><p>In this section, we will introduce the technical details of our Ahead framework. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, our framework mainly consists of three components, namely Attentive Heterogeneous Graph Embedding (AHGN) to learn the comprehensive representation for company and position, the Career Path Mining to model the individual sequential trajectory, and the Prediction Module to integrate the individual sequential information to predict job mobility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Attentive Heterogeneous Graph Embedding</head><p>As we all know, graph neural network (GNN) have been widely studied in many scenarios and achieved major success on the general graph learning problem. Among these achievements, the core idea of message-passing neural networks (MPNNs) is to generate node embedding vector by aggregating the features of node's neighborhoods. Inspired by this, we extend the graph neural network to learn the heterogeneous graph embedding. We define the aggregation process for the different types of nodes as external aggregation, and the same type as internal aggregation. Along this line, we first use both external and internal aggregation modules to aggregate different types of information, and then design a type-level attention mechanism to fuse them for fully representing nodes.</p><p>4.1.1 External aggregation. The external aggregation is to aggregate the information from neighbors with different types. For example, in terms of a position, the external aggregation is used to aggregate information from its neighbors of company type. Therefore, in this part, we mainly focus on the sub-graph G ğ‘ğ‘ = {V, E ğ‘ğ‘ }, which only contains the company-to-position edges.</p><p>At first, it is obvious that different types of nodes have different feature spaces. For example, the features of company include size, location, etc, while the features of position include function, responsibility, etc. Formally, let z ğ‘– denote the feature embedding of node ğ‘–. To make the aggregation process feasible, we design the type-specific transformation matrix W ğœ to project the features of different types of nodes into the same feature space, and the projected feature of node ğ‘– is defined as follows:</p><formula xml:id="formula_3">áº‘ğ‘– = W ğœ â€¢ z ğ‘– .<label>(3)</label></formula><p>Indeed, the attributes of companies and positions are sparse, integrating the information from heterogeneous neighbors can alleviate this issue. Considering the belonging relationship between company and position is unweighted and undirected, we adopt the graph convolutional rule based on symmetric normalized Laplacian to construct the external aggregator:</p><formula xml:id="formula_4">a (ğ‘™ ) ğ‘– = âˆ‘ï¸ ğ‘— âˆˆN ğ¸ (ğ‘– ) 1 âˆšï¸ | N ğ¸ (ğ‘–) | | N ğ¸ ( ğ‘—) | W (ğ‘™ ) ğ¸ H (ğ‘™ ) ğ‘— ,<label>(4)</label></formula><p>where N ğ¸ (ğ‘–) is the set of neighbors for node ğ‘– with different types, and</p><formula xml:id="formula_5">H (ğ‘™)</formula><p>ğ‘— is the hidden representation of node ğ‘— in ğ‘™-th layer. Initially,</p><formula xml:id="formula_6">H (0) ğ‘– = áº‘ğ‘– . W (ğ‘™)</formula><p>ğ¸ is a layer-specific trainable transformation matrix. 4.1.2 Internal aggregation. The internal aggregation is to aggregate the information from nodes of the same type. Hence, we focus on the sub-graphs G ğ‘ğ‘ and G ğ‘ğ‘ which represent the job transition network of company and position respectively. Job transition relationship has several important attributes <ref type="bibr" target="#b42">[43]</ref>, i.e., the total number and the average working duration. Intuitively, a node (i.e., company or position) has a larger impact on nodes with more job transitions compared with nodes with fewer job transitions. Besides, the shorter average duration of job transition between a pair of nodes (i.e., company-to-company or position-to-position) usually leads to more similar nodes.</p><p>However, the message-passing neural networks (MPNNs) cannot take advantage of these job transition attributes, because the aggregation of MPNNs treats all neighbors of node equally. To overcome this problem, we propose a transition-aware attention mechanism to aggregate node representation features: where N ğ¼ (ğ‘–) is the set of neighbors for node ğ‘– with same type. ğ‘ğ‘¡ğ‘¡ (H ğ‘– , H ğ‘— , r ğ‘– ğ‘— ) is the transition-aware attentive weight of each neighbor ğ‘— for ğ‘– with their corresponding job transition feature r ğ‘– ğ‘— .</p><p>Both the total number and the average duration of job transition are real number. To embed the total number attribute, we first collect all the values, then discretize them into consecutive value bins evenly, where each bin can be regarded as a category. Afterwards, we randomly initialize the embedding for each category. Finally, the embedding would be jointly learned. Analogously, we conduct a similar operation on the average duration attribute.</p><p>Formally, let n ğ‘– ğ‘— and m ğ‘– ğ‘— represent the embedding of the number attribute and the duration attribute for the job transition from node ğ‘– to node ğ‘—. We concatenate the two embeddings and apply a dense layer transformation to represent the job transition:</p><formula xml:id="formula_7">r ğ‘– ğ‘— = W ğ‘Ÿ â€¢ (n ğ‘– ğ‘— âŠ• m ğ‘– ğ‘— ),<label>(6)</label></formula><p>where W ğ‘Ÿ is transform matrix, âŠ• is concatenation operation. Next, we implement the transition-aware attention mechanism by considering the features of nodes as well as the job transition features between nodes, which is formulated as follows:</p><formula xml:id="formula_8">ğ‘ğ‘¡ğ‘¡ (H ğ‘– , H ğ‘— , r ğ‘– ğ‘— ) = exp(ğ 1 â€¢ (W 1 H ğ‘– + W 2 H ğ‘— + W 3 r ğ‘– ğ‘— )) ğ‘˜ âˆˆN ğ¼ (ğ‘– ) exp(ğ 2 â€¢ (W 1 H ğ‘– + W 2 H ğ‘˜ + W 3 r ğ‘–ğ‘˜ ))</formula><p>, <ref type="bibr" target="#b6">(7)</ref> where W * are transform matrices, and ğ * are the attention vectors. By integrating the transition-aware attention, we can obtain the internal aggregation b ğ‘– for each node based on Equation <ref type="formula">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Representation Fusion.</head><p>After the external and internal aggregation process, we turn to update the representation of each node. Generally, in terms of a node, different types of neighboring nodes may have different impacts on it. To distinguish the impacts, we propose a novel type-level attention mechanism to automatically learn the importance of different neighboring types for each node, i.e., internal and external. Formally, given a node ğ‘–, the corresponding embedding of type ğœ is defined as the sum of the neighboring node features of node ğ‘– with type ğœ: To learn the importance of each type for node ğ‘–, we first concatenate the type embedding with the target node embedding. Then, we measure the importance of the specific type ğœ as the similarity of the concatenated embedding with a type-specific attention vector ğœ‡ ğœ . The importance of type ğœ for node ğ‘– is calculated as follows:</p><formula xml:id="formula_9">ğ›½ (ğ‘™ ) ğœğ‘– = ğœ (ğ ğœ â€¢ [e (ğ‘™ ) ğœğ‘– âŠ• H (ğ‘™ ) ğ‘– ]). (9)</formula><p>By integrating the type-level attention, then the overall aggregation among different types can be calculated as follows:</p><formula xml:id="formula_10">ğ (ğ‘™ ) ğ‘– = ğ›½ (ğ‘™ ) ğ‘ğ‘– a (ğ‘™ ) ğ‘– âŠ• ğ›½ (ğ‘™ ) ğ‘ğ‘– b (ğ‘™ ) ğ‘– ,<label>(10)</label></formula><p>where ğ›½ ğ‘– can be calculated by Equation 4 and 5 respectively. Afterwards, the representation of node ğ‘– can be updated as follows:</p><formula xml:id="formula_11">H (ğ‘™ +1) ğ‘– = ğœ (W ğ‘ â€¢ ğ (ğ‘™ ) ğ‘– ),<label>(11)</label></formula><p>where W ğ‘ is transform matrix, ğœ (â€¢) is the activation function. The representation of node ğ‘– in the last layer is treated as the final representation, denoted by H * ğ‘– .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Career Path Mining</head><p>After obtaining the representation of companies and positions, we turn to model the individual career paths. As mentioned before, the career trajectory of a talent ğ‘¢ can be described by two sequences, i.e., S ğ‘ (ğ‘¢) = (ğ‘ 1 , ğ‘ 2 , ..., ğ‘ ğ¿ |ğ‘¢) and S ğ‘ (ğ‘¢) = (ğ‘ 1 , ğ‘ 2 , ..., ğ‘ ğ¿ |ğ‘¢). To represent each company (or position) in sequence, two factors should be considered. The first one is time, obviously, the impact of a person's stay in the company or position for different periods of time is different. So we integrate the duration information to address this issue. Since the duration in the last record ğ‘‘ ğ¿ is unknown, we construct a duration sequence (ğ‘‘ 0 , ğ‘‘ 1 , ..., ğ‘‘ ğ¿âˆ’1 ) of length ğ¿ by adding ğ‘‘ 0 = 0. By this way, the duration sequence can be aligned with company (or position) sequence. The second factor is personal information, as the same work experience may have different effects on different people. Let H * ğ‘¡ denote the embedding of the ğ‘¡-th entity from AHGN, E ğ‘¢ represent the static individual features and D ğ‘¡ denote embedding of the ğ‘¡-th duration in the duration sequence. Then, the time-aware representation of company and position in ğ‘¢'s trajectory can be defined as:</p><formula xml:id="formula_12">x ğ‘¡ = W ğ‘¢ â€¢ (H * ğ‘¡ âŠ• D ğ‘¡ âŠ• E ğ‘¢ ),<label>(12)</label></formula><p>where W ğ‘¢ is transform matrix. We randomly initialize the embedding for all duration values, then the duration embedding will be updated during the training process. After that, the company and position sequences can be represented by (x ğ‘ 1 , x ğ‘ 2 , ..., x ğ‘ ğ¿ |ğ‘¢) and</p><formula xml:id="formula_13">(x ğ‘ 1 , x ğ‘ 2 , ..., x ğ‘ ğ¿ |ğ‘¢).</formula><p>In order to model the career sequential information, we take advantage of GRU as the basic model because it can alleviate the gradient vanishing problem in long-distance dependent sequential problems, as well as its efficiency compared with LSTM. In terms of GRU, the input is sequential vectors (x 1 , x 2 , ..., x ğ¿ ). At each time ğ‘¡, the input feature vector x ğ‘¡ is fed to a hidden cell which is identical for all time stamp, and the single cell is built as follows:</p><formula xml:id="formula_14">ğ‘Ÿ = ğœ (W ğ‘¥ğ‘Ÿ x ğ‘¡ + W â„ğ‘Ÿ h ğ‘¡ âˆ’1 + b ğ‘Ÿ ), ğ‘§ = ğœ (W ğ‘¥ğ‘§ x ğ‘¡ + W â„ğ‘§ h ğ‘¡ âˆ’1 + b ğ‘§ ), h ğ‘¡ = ğ‘¡ğ‘ğ‘›â„ (W ğ‘¥â„ x ğ‘¡ + W â„â„ (ğ‘Ÿ âŠ™ h ğ‘¡ âˆ’1 ) + b â„ ), h ğ‘¡ = (1 âˆ’ ğ‘§) âŠ™ h ğ‘¡ âˆ’1 + ğ‘§ âŠ™ h ğ‘¡ . (<label>13</label></formula><formula xml:id="formula_15">)</formula><p>In these equations, the parameters W * denotes the weight matrices, b * denotes bias, symbol âŠ™ denotes element-wise product operator, and h ğ‘¡ denotes the hidden state in time ğ‘¡.</p><p>Intuitively, we could construct two GRU for the company and position sequence respectively. However, modeling the two sequences separately may lose some important information since predictions for company and position are highly related. On the one hand, when predicting the next company, current position may limit the company selection range as proven in pre-study. For example, a software engineer of Google is more likely to choose an IT-related company. On the other hand, the job-hopping process involves job title benchmarking <ref type="bibr" target="#b42">[43]</ref>, which means the same job position in different companies may reflect different expertise levels. Thus current company is also a significant factor for position prediction.</p><p>To that end, we propose a Dual-GRU structure to model interactive information between companies and positions. It consists of two GRU that interact with each other for modeling company and position respectively. Taking the company sequence as an example, the basic GRU cell takes x ğ‘ ğ‘¡ and the predecessor hidden state h ğ‘ ğ‘¡ âˆ’1 as inputs according to Equation <ref type="formula" target="#formula_14">13</ref>. We enrich the inputs with the predecessor position hidden state h ğ‘ ğ‘¡ âˆ’1 , so that both the historical sequential information of company and position can be used for making predictions. To further distinguish the influence of two kinds of information, we apply the attention mechanism to automatically align weights for each part as:</p><formula xml:id="formula_16">ğ‘¦ ğ‘ ğ‘¡ âˆ’1 = W(h ğ‘ ğ‘¡ âˆ’1 âŠ• x ğ‘ ğ‘¡ ), ğ‘¦ ğ‘ ğ‘¡ âˆ’1 = W(h ğ‘ ğ‘¡ âˆ’1 âŠ• x ğ‘ ğ‘¡ ), ğ›¼ ğ‘ = exp(ğ‘¦ ğ‘ ğ‘¡ âˆ’1 ) exp(ğ‘¦ ğ‘ ğ‘¡ âˆ’1 ) + exp(ğ‘¦ ğ‘ ğ‘¡ âˆ’1 )</formula><p>,</p><formula xml:id="formula_17">h ğ‘ * ğ‘¡ âˆ’1 = ğ›¼ ğ‘ âŠ™ h ğ‘ ğ‘¡ âˆ’1 + (1 âˆ’ ğ›¼ ğ‘ ) âŠ™ h ğ‘ ğ‘¡ âˆ’1 ,<label>(14)</label></formula><p>where W denotes the transform matrix, and h ğ‘ * ğ‘¡ âˆ’1 is the refined hidden state at ğ‘¡ âˆ’1. Analogously, we can get h ğ‘ * ğ‘¡ âˆ’1 . With the new hidden state, the subsequent calculation is similar to the Equation 13.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Prediction Module</head><p>Finally, we introduce the prediction module. Specifically, our career path prediction problem contains three major targets: the next company, the next position and the current working duration. Intuitively, predicting the next company of talents can be formulated as a classification problem. Given a talent ğ‘¢, we firstly feed the current hidden state of company (h ğ‘ ğ‘¡ ) from Dual-GRU into a fully-connected layer, where the output dimension matches the total company number. Afterwards, we apply a softmax activation function to normalize the transition probability of each company,</p><formula xml:id="formula_18">+ 1- GRU ! !"# $ " ! % ! !"# $ # &amp; " ! % " ! % ! !"# ' ! !"# ' ! !"# ( ) ! ! " ! ! # " $%&amp; ' " $%&amp; ( " $%&amp; ) * " $%&amp; ( * GRU GRU Dual-GRU</formula><formula xml:id="formula_19">namely Ã´ğ‘¡ âˆˆ R | V ğ‘ | . Let o ğ‘¡ âˆˆ R | V ğ‘ |</formula><p>denote the one-hot embedding of the ğ‘¡-th company in ğ‘¢'s trajectory. Then, the loss function for next company prediction of talent ğ‘¢ can be defined by the crossentropy form:</p><formula xml:id="formula_20">L ğ‘¢ ğ‘ = âˆ’ ğ¿ âˆ‘ï¸ ğ‘¡ =2 o ğ‘¡ log( Ã´ğ‘¡+1 ).<label>(15)</label></formula><p>Analogously, the prediction process of next position is the same as predicting next company. We can obtain the loss function L ğ‘¢ ğ‘ for next company prediction of talent ğ‘¢.</p><p>Meanwhile, predicting the working duration of the current job can be formulated as a regression problem. Given a talent ğ‘¢, we concatenate the current hidden states of company and position (h ğ‘ ğ‘¡ and h ğ‘ ğ‘¡ ) from Dual-GRU. Then, we feed it into a fully-connected layer to transform it as the prediction dğ‘¡ , and the loss function for working duration prediction is defined as follows:</p><formula xml:id="formula_21">L ğ‘¢ ğ‘‘ = ğ¿âˆ’1 âˆ‘ï¸ ğ‘¡ =1 1 2 ( dğ‘¡ âˆ’ ğ‘‘ ğ‘¡ ) 2 .<label>(16)</label></formula><p>Finally, the whole objective function is defined as follows:</p><formula xml:id="formula_22">L = âˆ‘ï¸ ğ‘¢ ( L ğ‘¢ ğ‘ + ğœ† 1 L ğ‘¢ ğ‘ + ğœ† 2 L ğ‘¢ ğ‘‘ ) + ğœ† 3 | |Î˜ | | 2 2 ,<label>(17)</label></formula><p>where ğœ† 1 and ğœ† 2 are hyper-parameters for balancing the different parts in the loss function. ğœ† 3 is regularization parameter and ||Î˜|| 2 2 is the L2-norm over all parameters Î˜.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>In this section, we will introduce the experimental details conducted on the real-world dataset for validating the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head><p>5.1.1 Dataset. Our dataset contains 459,309 career trajectories, we constructed the heterogeneous company-position network from these trajectories. There are 1,380 companies and 2,098 positions, and the numbers of the three types of edges (i.e., E ğ‘ğ‘ , E ğ‘ğ‘ , E ğ‘ğ‘ ) are 90,000, 131,332, and 165,129 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Baselines.</head><p>We compared Ahead with some state-of-art methods. Specifically, non-sequential models contain Logistic Regression (LR) and Random Forest (RF) <ref type="bibr" target="#b3">[4]</ref>. Sequential models contain  LSTM <ref type="bibr" target="#b14">[15]</ref>, GRU <ref type="bibr" target="#b6">[7]</ref>, NEMO <ref type="bibr" target="#b21">[22]</ref> and HCPNN <ref type="bibr" target="#b29">[30]</ref>. NEMO and HCPNN are the most advanced models which are relevant to job mobility prediction. Finally, the heterogeneous graph embedding based models contain HAN <ref type="bibr" target="#b39">[40]</ref> and HGAT <ref type="bibr" target="#b23">[24]</ref>, and we modified them to fit our problems. The detail of baselines will be introduced in section A.3 of appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Evaluation Metrics.</head><p>We used Accuracy@k (ğ´ğ‘ğ‘@ğ‘˜) and Mean Reciprocal Rank (ğ‘€ğ‘…ğ‘…) to evaluate the performance of next company and position prediction. And we selected Root Mean Square Error (ğ‘…ğ‘€ğ‘†ğ¸) and Mean Absolute Error (ğ‘€ğ´ğ¸) for current duration prediction. The detail will be introduced in section A.2 of appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Evaluation</head><p>5.2.1 Overall Performance. The evaluation part includes prediction tasks for next company, next position and current duration. We randomly split all samples by (0.8/0.1/0.1) as the training/validation/test dataset respectively. Each method was trained on the training data, and the corresponding parameters were tuned on the validation data. The final performance was evaluated on the test data.</p><p>The results are summarized in Table <ref type="table" target="#tab_0">1</ref>. Obviously, our Ahead model achieves the best performance on all prediction tasks which clearly demonstrates the effectiveness of our model. Moreover, we have several observations. Firstly, the non-sequential models, i.e., LR and RF, always get the worst performance in all tasks, since they fail to handle the sequential information. Secondly, in terms of variants of RNN model, GRU gets better performance than LSTM, since our dataset is small and less frequent, which is more suitable for GRU learning. As the state-of-art models on job mobility prediction task, both NEMO and HCPNN have achieved competitive and stable performance, which indicates that integrating the individual information and designing effective strategies to model career path are quite useful. Finally, the modified state-of-art heterogeneous graph embedding methods, i.e., HGAT and HAN, can also get comparable performance, especially on the next company prediction task and working duration prediction task, which demonstrates that leveraging the heterogeneous graph can indeed improve the job mobility prediction performance. However, their performances drop a lot on the next position prediction task, which further indicates the robustness of the AHGN module of Ahead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Ablation Study. To demonstrate the effectiveness of each component of Ahead, we conducted experiments on variants:</head><p>â€¢ Ahead-D: It replaces the Dual-GRU module with two independent GRU for company and position. â€¢ Ahead-A: It drops the transition-aware attention mechanism in internal aggregator of AHGN. â€¢ Ahead-T: There is no type-level attention in AHGN.</p><p>As shown in Figure <ref type="figure" target="#fig_6">5</ref>, the performance of Ahead-D is significantly worse than other models, which indicates the effectiveness of the Dual-GRU module. Therefore, modeling the interaction between company and position can indeed improve prediction performance. By comparing Ahead with Ahead-A, it demonstrates the effectiveness of considering the job transition attributes between nodes. Moreover, by comparing Ahead with Ahead-T, it indicates that distinguishing the influence of external and internal neighbors can make better representation of nodes for better prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Parameter Sensitivity.</head><p>We also conducted two experiments to study how the input dimension of Dual-GRU and the category size of job transition features influence Ahead's performance. Firstly, we discuss the sensitivity of the input dimension of Dual-GRU, which is summarized in Figure <ref type="figure" target="#fig_7">6</ref>. In general, the performance is improved with increasing dimension size, since more dimensions may probably keep more useful information. Also, the performance keeps relatively stable when the dimension size is greater than 128. Next, we turn to analyze the effect of the category size of job transition features. As shown in Figure <ref type="figure" target="#fig_8">7</ref>, the performance of Ahead is stable on three prediction tasks. Indeed, more categories can better distinguish features, while the embedding of each category is jointly learned, which can also distinguish features automatically. When the category size is greater than 5, Ahead is sufficient to represent the job transition features and get stable performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Robustness</head><p>Analysis. Afterwards, we turn to demonstrate the robustness of Ahead. We explore how the performance of AHGN is    Companies that pay most attention to former companies.</p><p>Ernstandyoung, Pricewaterhouse Coopers Deloitte, IBM, Accenture Positions that pay most attention to former positions.</p><p>Team Lead, Assistant Manager, Project Manager Business Analyst, Account Manager influenced by the different training ratios. As shown in Table <ref type="table" target="#tab_2">2</ref>, it is obvious that with increasing training proportion, the performance is improved as well. When the training ratios are greater than 0.3, the performance improves slowly. All results are stable, which demonstrates the robustness of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Case Study.</head><p>With the attention mechanism, we conducted several case studies on job mobility. At first, we investigated the importance of former companies and positions to the next job mobility based on Equation <ref type="formula" target="#formula_17">14</ref>. Figure <ref type="figure" target="#fig_10">8</ref> shows the attention distribution among former companies and positions. When predicting the next company, the previous company would obtain more attention than the previous position. While the situation is opposite when predicting the next position, which may indicate that to join the dream company, employees should choose a more suitable former company. However, to get a dream job position, employees should work on related former positions. Moreover, Table <ref type="table" target="#tab_3">3</ref> reports the top-5 companies and positions    that give the highest attention to the previous company and positions. This may indicate that accounting and consulting companies attach great importance to the former company, and management positions attach great importance to the former positions. Finally, we analyzed the job transition on a specific job position, i.e.,software engineer. We first selected all job transition records in which the former job position is software engineer. Then we grouped these records by the former company. Afterwards, we evaluated the attention value for the former company in each record and obtained the mean attention value of each company. Figure <ref type="figure" target="#fig_12">9</ref>(a) and Figure <ref type="figure" target="#fig_12">9</ref>(b) show the companies that appear most frequently in records and get the highest attention values respectively, where the size of name is proportional to the value. Obviously, the two distributions are quite different, the companies with high frequency may not get high attention. The high-tech companies such as Facebook, Google and Apple get the highest values, which may indicate they are pretty competitive in the position of software engineer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we studied the problem of job mobility prediction by exploring the impact of macro-level job transition relationships. Specifically, we first constructed a heterogeneous company-position network from the massive career trajectory data and then proposed a prediction framework, namely Ahead, based on the attentive heterogeneous graph embedding. In particular, an attentive heterogeneous graph embedding (AHGN) model in Ahead was designed to learn the comprehensive representation of companies and positions. Moreover, the other module in Ahead, namely Dual-GRU model, was applied for individual career path mining with the consideration of the mutual influence between company and position. Finally, extensive experiments conducted on a real-world dataset clearly validated the effectiveness of the proposed framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The data distribution of different aspects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>bFigure 3 :</head><label>3</label><figDesc>Figure 3: The diagrammatic sketch of the proposed Ahead framework on job mobility prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>ğ‘ğ‘– stand for the attention scores of external and internal type for node ğ‘– respectively. a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The diagrammatic sketch of Dual-GRU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Ablation study on the job mobility prediction task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Effect of different input dimension of Dual-GRU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Effect of category size of transition features.</figDesc><graphic url="image-13.png" coords="8,334.46,219.94,97.54,83.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The attention distribution of former company and position in job transition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The distribution comparison of several companies.</figDesc><graphic url="image-14.png" coords="8,442.06,219.94,97.54,83.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The overall performance of next company prediction, next position prediction and current duration prediction.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Company</cell><cell></cell><cell>Position</cell><cell>Duration</cell></row><row><cell></cell><cell></cell><cell>Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">ACC@1 ACC@15 ACC@30</cell><cell>MRR</cell><cell>ACC@1 ACC@15 ACC@30</cell><cell>MRR</cell><cell>RMSE</cell><cell>MAE</cell></row><row><cell></cell><cell></cell><cell>LR</cell><cell cols="3">0.1316</cell><cell>0.4209</cell><cell cols="2">0.5136</cell><cell>0.1274</cell><cell>0.0702</cell><cell>0.2886</cell><cell>0.3837</cell><cell>0.0777 5.1272 4.3673</cell></row><row><cell></cell><cell></cell><cell>RF</cell><cell cols="3">0.2391</cell><cell>0.4428</cell><cell cols="2">0.5265</cell><cell>0.1641</cell><cell>0.1156</cell><cell>0.3759</cell><cell>0.4620</cell><cell>0.1143 4.9758 4.1707</cell></row><row><cell></cell><cell></cell><cell>LSTM</cell><cell cols="3">0.3636</cell><cell>0.6413</cell><cell cols="2">0.7081</cell><cell>0.4438</cell><cell>0.1685</cell><cell>0.5185</cell><cell>0.6191</cell><cell>0.2668 3.2390 2.4868</cell></row><row><cell></cell><cell></cell><cell>GRU</cell><cell cols="3">0.3868</cell><cell>0.6644</cell><cell cols="2">0.7288</cell><cell>0.4657</cell><cell>0.1775</cell><cell>0.5273</cell><cell>0.6270</cell><cell>0.2776 3.2984 2.5563</cell></row><row><cell></cell><cell></cell><cell>NEMO</cell><cell cols="3">0.4099</cell><cell>0.6863</cell><cell cols="2">0.7530</cell><cell>0.4888</cell><cell>0.2080</cell><cell>0.5829</cell><cell>0.6785</cell><cell>0.3151 3.1801 2.3949</cell></row><row><cell></cell><cell></cell><cell>HCPNN</cell><cell cols="3">0.4091</cell><cell>0.6691</cell><cell cols="2">0.7316</cell><cell>0.4839</cell><cell>0.2040</cell><cell>0.5848</cell><cell>0.6811</cell><cell>0.3120 3.2832 2.5387</cell></row><row><cell></cell><cell></cell><cell>HAN</cell><cell cols="3">0.4118</cell><cell>0.6608</cell><cell cols="2">0.7237</cell><cell>0.4835</cell><cell>0.1680</cell><cell>0.5191</cell><cell>0.6156</cell><cell>0.2671 3.1693 2.4114</cell></row><row><cell></cell><cell></cell><cell>HGAT</cell><cell cols="3">0.4127</cell><cell>0.6580</cell><cell cols="2">0.7216</cell><cell>0.4833</cell><cell>0.1722</cell><cell>0.5243</cell><cell>0.6200</cell><cell>0.2726 3.1684 2.4036</cell></row><row><cell></cell><cell></cell><cell>Ahead</cell><cell cols="3">0.4267</cell><cell>0.6968</cell><cell cols="2">0.7622</cell><cell>0.5039 0.2083</cell><cell>0.5874</cell><cell>0.6820</cell><cell>0.3171 2.9176 2.0178</cell></row><row><cell></cell><cell>0.43</cell><cell>Ahead-D</cell><cell></cell><cell>0.21</cell><cell>Ahead-D</cell><cell></cell><cell>2.04</cell><cell></cell><cell>Ahead-D</cell></row><row><cell></cell><cell></cell><cell>Ahead-T</cell><cell></cell><cell></cell><cell>Ahead-T</cell><cell></cell><cell></cell><cell></cell><cell>Ahead-T</cell></row><row><cell>Metric Score</cell><cell>0.41 0.42</cell><cell>Ahead-A Ahead</cell><cell>Metric Score</cell><cell>0.20</cell><cell>Ahead-A Ahead</cell><cell>Metric Score</cell><cell>2.02 2.03</cell><cell></cell><cell>Ahead-A Ahead</cell></row><row><cell></cell><cell>0.40</cell><cell>Company Prediction -ACC@1</cell><cell></cell><cell>0.19</cell><cell cols="2">Position Prediction -ACC@1</cell><cell>2.01</cell><cell cols="2">Duration Prediction -MAE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The performance on randomly split samples.</figDesc><table><row><cell></cell><cell>Company</cell><cell>Position</cell><cell>Duration</cell></row><row><cell>Proportion</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">ACC@1 MRR ACC@1 MRR</cell><cell>MAE</cell></row><row><cell>10%</cell><cell cols="2">0.3186 0.3938 0.1564 0.2487</cell><cell>2.3194</cell></row><row><cell>30%</cell><cell cols="2">0.4155 0.4883 0.1947 0.2992</cell><cell>2.2433</cell></row><row><cell>50%</cell><cell cols="2">0.4224 0.4963 0.2003 0.3072</cell><cell>2.0381</cell></row><row><cell>70%</cell><cell cols="2">0.4256 0.5004 0.2032 0.3119</cell><cell>2.0354</cell></row><row><cell>90%</cell><cell cols="2">0.4267 0.5019 0.2073 0.3167</cell><cell>2.0261</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Top-5 companies and positions that give the highest attention to previous companies and positions respectively.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGMENTS</head><p>This research was partially supported by grants from the National Natural Science Foundation of China (Grant No.61836013, 91746301, 62072423) and the National Key Research and Development Program of China (Grant No.2018YFB1402600).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>A.1 Data Pre-processing.</p><p>The original dataset contains more than 400 million professional resumes, which is noisy and inefficient for model training. To filter this dataset, we firstly applied the method mentioned in <ref type="bibr" target="#b44">[45]</ref> to extract the career trajectory data. Specifically, if the absolute difference between the end time of the previous job and the start time of the next job is less than a predefined threshold, the job transition is considered valid. Then we constructed a career tree and chose the longest path as individual career trajectory. To unify the messy job title, we firstly extracted the corresponding responsibility and function words according to the manually annotated IPOD dataset <ref type="bibr" target="#b26">[27]</ref>. As a job title describes the responsibilities and function of the job, two job titles can be regarded as the same if they have the same responsibilities and function. Therefore we can aggregate the job titles according to the selected key words. Afterwards, we chose the most frequent companies from different types, and kept the most frequent job titles of them. Finally, we retained the career trajectories among the selected companies and positions after January 2010. Totally, 459,309 career trajectories are extracted, which consist of 1,380 companies and 2,098 job titles.</p><p>Further, we also collected the company-specific features, positionspecific features and person-specific features, as shown in Table <ref type="table">4</ref>. We processed the data with the following methods. For the free text features, such as the company description, we used the doc2vec <ref type="bibr" target="#b19">[20]</ref> model to transform the text to a fixed-length vector. For the categorical features, such as company type, we employed the one-hot embedding method. For the duration features, we segmented them by every half year, then the one-hot embedding method was applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Evaluation Metrics Description</head><p>For next company and position prediction tasks, we selected Accuracy@k (ğ´ğ‘ğ‘@ğ‘˜) and Mean Reciprocal Rank (ğ‘€ğ‘…ğ‘…) to evaluate performance, which are defined as:</p><p>where ğ‘ is total number of samples, ğ‘Ÿğ‘ğ‘›ğ‘˜ (ğ‘–) stands for the real rank in the predicting ranking list. ğ¼ (â€¢) is the indicator function that equals to 1 if ğ‘Ÿğ‘ğ‘›ğ‘˜ (ğ‘–) â‰¤ ğ‘˜ and equals to 0 otherwise. Here we set ğ‘˜ = 1, 15, 30 respectively. The higher values of ğ´ğ‘ğ‘@ğ‘˜ and ğ‘€ğ‘…ğ‘… means better prediction results. For duration prediction, we adopted Root Mean Square Error (ğ‘…ğ‘€ğ‘†ğ¸) and Mean Absolute Error (ğ‘€ğ´ğ¸) as evaluation metrics, which are defined as:</p><p>where ğ‘‘ ğ‘– and dğ‘– are the predicted duration and the real duration, and the lower values means better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Baseline Description</head><p>We compared our Ahead model with the following methods to predict the job mobility.</p><p>â€¢ LR: It is a supervised model. It fits the samples in the multidimensional space by using a linear combination of features. Here we input the company and position feature sequences together and trained three models for three tasks respectively. â€¢ GRU <ref type="bibr" target="#b6">[7]</ref>: It is also a variant of RNNs for dealing with the vanishing gradient problems. Here the experimental setting was the same as LSTM.</p><p>â€¢ NEMO <ref type="bibr" target="#b21">[22]</ref>: It is an encoder-decoder architecture. The encoder maps the multiple heterogeneous profile contexts into a fixed-length vector and the decoder maps the context vector to a sequence of company and position. We modified it by feeding the hidden state in each timestamp into a fullyconnected layer to predict the working duration.</p><p>â€¢ HCPNN <ref type="bibr" target="#b29">[30]</ref>: It proposes a hierarchical career-path-aware neural network to handle the dynamic nature of career paths for employees. The basic model can only predict the next company as well as the current working duration, we modified it by exchanging the hierarchy of company and position to predict the next position. â€¢ HAN <ref type="bibr" target="#b39">[40]</ref>: It is a state-of-art heterogeneous graph neural network, which employs node-level attention and semanticlevel attention. We modified it by adding the Dual-GRU module, and the output of HAN was the input of Dual-GRU. â€¢ HGAT <ref type="bibr" target="#b23">[24]</ref>: It proposes a heterogeneous graph attention embedding method for short text classification based on a dual-level attention mechanism. Here the experimental setting was the similar to HAN.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Continuous-time Markov chains: An applicationsoriented approach</title>
		<author>
			<persName><forename type="first">Anderson</forename><surname>William</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps and spectral techniques for embedding and clustering</title>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nips</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="585" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Heterogeneous network embedding via deep architectures</title>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charu</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van MerriÃ«nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van MerriÃ«nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">metapath2vec: Scalable representation learning for heterogeneous networks</title>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</title>
				<meeting>the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hybrid speech recognition with deep bidirectional LSTM</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE workshop on automatic speech recognition and understanding</title>
		<imprint>
			<biblScope unit="page" from="273" to="278" />
			<date type="published" when="2013">2013. 2013</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE international conference on acoustics, speech and signal processing</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Conceptualizing and evaluating career success</title>
		<author>
			<persName><surname>Peter A Heslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Organizational Behavior: The International Journal of Industrial, Occupational and Organizational Psychology and Behavior</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="113" to="136" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The vanishing gradient problem during learning recurrent neural nets and problem solutions</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">JÃ¼rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
				<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="1982">1982. 1982</date>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Heterogeneous information network embedding for meta path based proximity</title>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Mamoulis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05291</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Prospecting the career development of talents: A survival analysis perspective</title>
		<author>
			<persName><forename type="first">Huayu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongke</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="917" to="925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nemo: Next career move prediction with contextual embedding</title>
		<author>
			<persName><forename type="first">Liangyue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">How</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bee-Chung</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion</title>
				<meeting>the 26th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="505" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Collaborative company profiling: Insights from an employee&apos;s perspective</title>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Hao Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention networks for semi-supervised short text classification</title>
		<author>
			<persName><forename type="first">Tianchi</forename><surname>Hu Linmei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoli</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP-IJCNLP</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4823" to="4832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Incorporating Multi-Source Urban Data for Personalized and Context-Aware Multi-Modal Transportation Recommendation</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongxin</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panpan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinjiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Community-Aware Multi-Task Transportation Demand Prediction</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinjiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="320" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Junhua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yung</forename><forename type="middle">Chuen</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><forename type="middle">L</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lim</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10495</idno>
		<title level="m">IPOD: Corpus of 190,000 industrial occupations</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Contextaware sequential recommendation</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaokang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 16th International Conference on Data Mining (ICDM)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1053" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8206</idno>
		<title level="m">Addressing the rare word problem in neural machine translation</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A hierarchical career-path-aware neural network for job mobility prediction</title>
		<author>
			<persName><forename type="first">Qingxin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keli</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="14" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Determinants of job mobility: A theoretical integration and extension</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelly</forename><forename type="middle">L</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><forename type="middle">T</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">C</forename><surname>Eby</surname></persName>
		</author>
		<author>
			<persName><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Occupational and Organizational Psychology</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="363" to="386" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Asymmetric transitivity preserving graph embedding</title>
		<author>
			<persName><forename type="first">Mingdong</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1105" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Understanding what affects career progression using Linkedin and Twitter data</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianran</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Big Data (Big Data)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2047" to="2055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Note on regression and inheritance in the case of two parents</title>
	</analytic>
	<monogr>
		<title level="j">proceedings of the royal society of London</title>
		<editor>Karl Pearson. 1895. VII</editor>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="240" to="242" />
			<date type="published" when="1895">1895</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Development of a new scale to measure subjective career success: A mixed-methods study</title>
		<author>
			<persName><forename type="first">Kristen</forename><forename type="middle">M</forename><surname>Shockley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heather</forename><surname>Ureksoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ozgun</forename><surname>Burcu Rodopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">F</forename><surname>Poteat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Ryan Dullaghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Organizational Behavior</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="128" to="153" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>VeliÄkoviÄ‡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Is it time for a career switch</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Posse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Bhasin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
				<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1377" to="1388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deyu</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaohua</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.14867</idno>
		<title level="m">A Survey on Heterogeneous Graph Embedding: Methods, Techniques, Applications and Sources</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houye</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning career mobility and human activity patterns for job change analysis</title>
		<author>
			<persName><forename type="first">Huang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1057" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling professional similarity by mining professional career trajectories</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Bugdayci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Bhasin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Job2Vec: Job title benchmarking with collective multi-view representation learning</title>
		<author>
			<persName><forename type="first">Denghui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2763" to="2771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Large-Scale Talent Flow Embedding for Company Competitive Analysis</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingxin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
				<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="2354" to="2364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Large-scale talent flow forecast with dynamic latent factor model</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2312" to="2322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01475</idno>
		<title level="m">HAHE: Hierarchical attentive heterogeneous information network embedding</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Days on market: Measuring liquidity in real estate markets</title>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangshuang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjie</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="393" to="402" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
