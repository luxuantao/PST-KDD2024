<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Learning of Human Motion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Yang</forename><surname>Song</surname></persName>
							<email>yangs@vision.caltech.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<postCode>136-93, 91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Luis</forename><surname>Goncalves</surname></persName>
							<email>luis.goncalves@idealab.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<postCode>136-93, 91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
							<email>perona@caltech.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">California Institute of Technology</orgName>
								<address>
									<postCode>136-93, 91125</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="middle">L</forename><surname>Goncalves</surname></persName>
							<affiliation key="aff1">
								<address>
									<addrLine>130 W. Union Street</addrLine>
									<postCode>91103</postCode>
									<settlement>Pasadena</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Learning of Human Motion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">21907668F415F1CD68E56C3693E246AC</idno>
					<note type="submission">received ?? ?? ????; revised ?? ???? ????; accepted 21 Mar. 2003. Recommended for acceptance by J. Rehg.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised learning</term>
					<term>human motion</term>
					<term>decomposable triangulated graph</term>
					<term>probabilistic models</term>
					<term>greedy search</term>
					<term>EM algorithm</term>
					<term>mixture models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An unsupervised learning algorithm that can obtain a probabilistic model of an object composed of a collection of parts (a moving human body in our examples) automatically from unlabeled training data is presented. The training data include both useful "foreground" features as well as features that arise from irrelevant background clutter-the correspondence between parts and detected features is unknown. The joint probability density function of the parts is represented by a mixture of decomposable triangulated graphs which allow for fast detection. To learn the model structure as well as model parameters, an EM-like algorithm is developed where the labeling of the data (part assignments) is treated as hidden variables. The unsupervised learning technique is not limited to decomposable triangulated graphs. The efficiency and effectiveness of our algorithm is demonstrated by applying it to generate models of human motion automatically from unlabeled image sequences, and testing the learned models on a variety of sequences.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A UTOMATIC detection and tracking of people, and analysis of their motion, actions, and activities, are important areas in computer vision with potential applications to medicine, entertainment, and security. To this end, a number of models of human motion have been proposed in the literature <ref type="bibr" target="#b13">[14]</ref>. "Strong" models represent explicitly the kinematics and dynamics of the human body <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b30">[31]</ref>, while "weak" models represent its phenomenological spatio-temporal appearance <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>. Strong models have the advantage of incorporating more information and, in principle, tolerate lower signalto-noise ratios and be allowed to reconstruct 3D body pose and motion from 2D images. Weak models allow the representation of motion patterns, where physical and geometrical models are not easy to obtain (e.g., loose clothing, bodies of unknown dimensions) and may therefore be more practical for image-based tasks, such as detection and recognition. Another potential advantage of weak models is that they are, in principle, cheaper to reprogram to represent different complex motions (whether human or not) since a detailed analysis of the geometry and physics of the moving object is not needed. It is therefore useful to develop methods to train weak models from image sequences with minimal user assistance.</p><p>We propose a method for learning weak models automatically from image sequences; more specifically, we focus here on probabilistic models proposed by Song et al. <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>. The human motion is modeled by the joint probability density function of the position and velocity of a collection of body parts. The probabilistic conditional independence structure of body parts, encoded by a decomposable triangulated graph, is such that it allows efficient detection and labeling of the body. Structure learning of graphical models has been previously studied by a number of authors <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b12">[13]</ref>. The main contribution of this paper, apart from the specifics of the application, is that our method is unsupervised: it is based on unlabeled training data. The training sequence contains a number of bottom-up features (Tomasi and Kanade points <ref type="bibr" target="#b29">[30]</ref> in our implementation) which are unlabeled, i.e., we do not know which features are associated to the body, which to background clutter, which features correspond to which features across image frames, and which features are most informative for a given task. The learning algorithm must therefore choose a number of useful features as body parts, establish their correspondence across frames, determine the underlying probabilistic independence structure, and estimate the parameters of the probability density function. One added generalization of our setting is that the features corresponding to body parts are not required to be present in all frames (neither during learning nor during detection and labeling).</p><p>In Section 2, we summarize the main facts about decomposable triangulated probabilistic models and how to use them to perform human motion detection and labeling. In Section 3, we address the learning problem when the training features are labeled, i.e., the parts of the model and the correspondence between the parts and observed features are known. In Section 4, we address the learning problem when the training features are unlabeled. In Section 5, we introduce the concept of mixtures of decomposable triangulated models and extend the unsupervised learning algorithm to the mixture model. In Section 6, we present some experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DECOMPOSABLE TRIANGULATED GRAPHS</head><p>We use decomposable triangulated graphs 1 to model the probabilistic conditional independence structure of body parts. A decomposable triangulated graph <ref type="bibr" target="#b0">[1]</ref> is a collection of cliques 2 of size three, where there is an elimination order of vertices such that 1) when a vertex is deleted, it is only contained in one triangle (we call it a free vertex) and 2) after eliminating one free vertex and the two edges associated with it, the remaining subgraph is again a collection of cliques of size three until only one triangle is left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Detection and Labeling</head><p>In <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>, decomposable triangulated graphs are used to model the conditional independence of body parts, and dynamic programming is used for efficient detection and labeling. Fig. <ref type="figure" target="#fig_0">1</ref> shows two decomposable graphs of the whole body used in <ref type="bibr" target="#b26">[27]</ref>, along with one order of successive elimination of the cliques. For the sake of making this paper self-contained, we summarize the main results in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Let S body ¼ fS 1 ; S 2 ; . . . ; S M g be the set of M body parts. For example, S 1 denotes the left wrist, S M is the right foot, etc., X S i , 1 i M, is the measurement for S i , the position and velocity of body part S i in our application. We model the pose and motion of the body by means of a probability density function P Sbody .</p><p>Let X ¼ ½X 1 ; . . . ; X N be a vector of measurements (each X i , i ¼ 1; . . . ; N is a vector describing position and velocity of point i). For clarity of description, we first assume that there are no missing body parts and no clutter. In this case, N ¼ M. Let L ¼ ½L 1 ; . . . ; L N be a vector of labels, where L i 2 S body is the label of X i . The best labeling of the scene is a vector L Ã , such that the posterior probability of the labeling given the observed data, P ðL Ã jXÞ, is maximized over all possible label vectors L. By Bayes' rule and equal priors assumption, 3  we have</p><formula xml:id="formula_0">L Ã ¼ arg max L2L P ðXjLÞ;<label>ð1Þ</label></formula><p>where L is the set of all possible labelings. If the conditional independence of body parts S body can be represented as a decomposable triangulated graph, the joint probability density function P Sbody can be decomposed into,</p><formula xml:id="formula_1">P Sbody ðX S1 ; X S2 ; . . . X SM Þ ¼ Y T À1 t¼1 P A t jB t C t ðX A t jX B t ; X C t Þ ÁP A T B T C T ðX A T ; X B T ; X C T Þ;<label>ð2Þ</label></formula><formula xml:id="formula_2">where A i ; B i ; C i 2 S body , 1 i T ¼ M À 2,</formula><p>and ðA 1 ; B 1 ; C 1 Þ; ðA 2 ; B 2 ; C 2 Þ; . . . ; ðA T ; B T ; C T Þ are the cliques. ðA 1 ; A 2 ; . . . ; A T Þ gives one elimination order, and B i and C i , 1 i T are the two vertices connected to A i when it is deleted. fA 1 ; A 2 ; . . . ; A T g [ fB T ; C T g is the set of body parts, i.e., fA 1 ; A 2 ; . . . ; A T ; B T ; C T g ¼ S body . A dynamic programming algorithm <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b26">[27]</ref> can be used to compute the maximum likelihood P ðXjLÞ,</p><formula xml:id="formula_3">max L2L P ðXjLÞ ¼ max XS 1 ;XS 2 ;...;XS M P S body ðX S 1 ; X S 2 ; . . . X S M Þ ¼ max X A 1 ;...;X A T ;XB T ;X C T Y T À1 t¼1 P A t jB t C t ðX A t jX B t ; X C t Þ P A T B T C T ðX A T ; X B T ; X C T Þ ð 3Þ ¼ max X A T ;X B T ;X C T ðP T ðX AT ; X BT ; X CT Þ max X A T À1 ðP T À1 ðX A T À1 jX B T À1 ; X C T À1 Þ Á Á Á max X A 2 ðP 2 ðX A 2 jX B 2 ; X C 2 Þ max X A 1 P 1 ðX A 1 jX B 1 ; X C 1 ÞÞÞÞ:<label>ð4Þ</label></formula><p>The equal sign from (3) to ( <ref type="formula" target="#formula_3">4</ref>) is a key step in achieving computational efficiency: dynamic programming, which is from the decomposable property of the graph <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b26">[27]</ref>. The complexity of the dynamic programming algorithm is on the order of M Ã N 3 . In <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>, the algorithms are extended to handle occlusion (some body parts missing) and clutter (some points not belonging to the body). Detection consists of deciding whether a human body is present. We propose two strategies <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>: One is to threshold the best labeling found as above, the so-called winner-take-all strategy, and the other is to sum over all the hypothesis labelings, which can be computed efficiently using another dynamic programming procedure with the same computational complexities (using the "sum" operator instead of the "max" operator). For simplicity, we use the first strategy in this paper.</p><p>1. For general graphical models, the term decomposable and the term triangulated have their own meanings (they are actually equivalent properties <ref type="bibr" target="#b20">[21]</ref>). Here, we use the term decomposable triangulated specifically for the graph type defined in this paragraph.</p><p>2. A clique is a maximal subset of vertices, any two of which are adjacent. 3. The equal priors assumption is reasonable when we have little knowledge about the labelings. We use it mainly due to its computational simplicity. There are also other ways to model the prior P ðLÞ. For instance, if we have some prior knowledge on the number of background (clutter) points, P ðLÞ can be more precisely estimated. In <ref type="bibr" target="#b31">[32]</ref>, the number of clutter points is modeled with a Poisson distribution. However, it is hard to include this kind of global term in the dynamic programming algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decomposable Triangulated Graphs and General Graphical Models</head><p>For general graphical models, the labeling problem is the most-probable-configuration problem on the graph and can be solved through max-propagation on junction trees <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b27">[28]</ref>. The dynamic programming algorithm <ref type="bibr" target="#b1">[2]</ref> and the max-propagation algorithm essentially have the same order of complexity which is determined by the maximum clique size of the graph. The maximum clique size for a decomposable triangulated graph is three. Since any graph with maximum clique size equal to or less than three can be transformed into a decomposable triangulated graph by adding edges, decomposable triangulated graphs are the most powerful, or for any probability distribution, can provide the most accurate approximation, among all the graphs with less or similar computational cost. Another type of widely used graphs in modeling conditional (in)dependence is trees <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b16">[17]</ref>, whose maximum clique size is two. There exist efficient algorithms <ref type="bibr" target="#b7">[8]</ref> to obtain the maximum spanning tree. Therefore, trees have computational advantages over decomposable triangulated graphs. But, decomposable triangulated graphs are more suitable for our application because they have better graph connectivity in dealing with occlusion <ref type="bibr" target="#b27">[28]</ref>. With a tree graph <ref type="bibr" target="#b10">[11]</ref>, if there is a single occlusion, the detection result may be split into two or more separate components, whereas with a triangulated graph, even if two adjacent parts (vertices) are occluded, the detection may still be connected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SUPERVISED LEARNING OF THE GRAPH STRUCTURE</head><p>In this section, we explore learning graph structure from labeled data, i.e., with known correspondence between the parts and the observed features (e.g., data from a motion capture system <ref type="bibr" target="#b26">[27]</ref>). This will be used as foundations for dealing with unlabeled training data in Section 4. Unfortunately, the problem of finding the optimal decomposable triangulated graph is NP-hard. <ref type="foot" target="#foot_0">4</ref> However, we can hope to find efficiently approximate solutions that are close to the optimal. To this end, we study a greedy algorithm based on the optimization criterion presented in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Optimization Criterion</head><p>Our goal is to find the decomposable triangulated graph that can best describe the data. The notation for the set of body parts and the decomposition of the joint probability density function into decomposable triangulated graphs are defined in Section 2.1 and (2). Suppose X ¼ fX 1 ; X 2 ; . . . ; X N g is a set of i.i.d samples from a probability density function of M body parts, where X n ¼ ðX n S 1 ; . . . ; X n S M Þ, 1 n N, and X n S i , 1 i M is the measurements of body part S i . We call such X n labeled data, <ref type="foot" target="#foot_1">5</ref>since the correspondence between the body parts and measurements is known. In a maximum-likelihood setting, we want to find the decomposable triangulated graph G, such that P ðGjX Þ is maximized over all possible such graphs. P ðGjX Þ is the probability of graph G being the "correct" one since the correspondence between the body parts and measurements is known. In a maximum-likelihood setting, we want to find the decomposable triangulated graph G, such that P ðGjX Þ is maximized over all possible such graphs. P ðGjX Þ is the probability of graph G being the "correct" one given the observed data X . By Bayes' rule, P ðGjX Þ ¼ P ðXjGÞP ðGÞ=P ðX Þ. Therefore, if we make the simplifying assumption that the priors P ðGÞ are equal for different decomposable triangulated graphs, then our goal is to find the structure G which can maximize P ðX jGÞ. By (2), P ðX jGÞ can be computed as follows <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>:</p><formula xml:id="formula_4">log P ðXjGÞ ¼ X N n¼1 log P ðX n jGÞ ¼ X N n¼1 X T À1 t¼1 log P ðX n At jX n Bt ; X n Ct Þ þ log P ðX n A T ; X n B T ; X n C T Þ ð5Þ ffi ÀN Á X T À1 t¼1 hðX A t jX B t ; X C t Þ À N Á hðX A T ; X B T ; X C T Þ ð6Þ ¼ ÀN Á X T t¼1 hðX A t jX B t ; X C t Þ À N Á hðX B T ; X C T Þ;<label>ð7Þ</label></formula><p>where hðÁÞ is differential entropy or conditional differential entropy <ref type="bibr" target="#b8">[9]</ref> (we consider continuous random variables here). Equation ( <ref type="formula">6</ref>) is an approximation which converges to equality for N ! 1 due to the weak Law of Large Numbers. We want to find the decomposition ðA 1 ; B 1 ; C 1 Þ; ðA 2 ; B 2 ; C 2 Þ; . . . ; ðA T ; B T ; C T Þ such that log P ðX jGÞ can be maximized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Greedy Search</head><p>The search for the optimal decomposable triangulated graph is an NP-hard problem. This section develops a greedy algorithm to grow the graph by the property of decomposable graphs. We start from a single vertex, and add vertices one by one each time maximizing <ref type="bibr" target="#b6">(7)</ref>. For each possible choice of C T (the last vertex of the last triangle), find the B T which maximizes</p><formula xml:id="formula_5">ÀhðX B T ; X C T Þ, then get A T , the vertex (part) that can maximize ÀhðX A T jX B T ; X C T Þ. Add edges ðA T ; B T Þ and ðA T ; C T Þ to the graph.</formula><p>The next vertex is added to the existing graph by choosing the best child of all the edges (legal parents) of the existing graph. This is repeated until all the vertices are added to the graph. For each choice of C T , one such graph can be grown, so there are M candidate graphs. The final result is the graph with the highest log P ðXjGÞ among the M graphs. The above algorithm is efficient. The number of possible choices for C T is M, the number of choices for B T is M À 1;</p><formula xml:id="formula_6">for stage t, M À 2 ¼ T ! t ! 1, the number of edges in G exist (legal parents) is 2 Ã ðT À tÞ þ 1 and the number of vertices in V avail (legal children) is t. Therefore, the total search cost is M Ã ðM À 1 þ P t ðð2 Ã ðT À tÞ þ 1Þ</formula><p>Ã tÞÞ, which is on the order of M 4 . There is, of course, no guarantee that the global optimal solution will be found. The effectiveness of the algorithm will be explored through experiments.</p><p>There are also other approximate ways to build the model. For example, we can add edges to a maximum spanning tree (MST), but it has been shown to be inferior to the greedy search for our application (see <ref type="bibr" target="#b27">[28]</ref> and Fig. <ref type="figure" target="#fig_2">3</ref> for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Computation of Differential Entropy-Translation Invariance</head><p>In the greedy search algorithm in Section 3.2, we need to compute</p><formula xml:id="formula_7">hðX A t jX B t ; X C t Þ ¼ hðX A t ; X B t ; X C t Þ À hðX B t ; X C t Þ, 1 t T .</formula><p>Although our algorithm could work with any choice of probability distribution, we chose to model the joint density of body parts with a Gaussian distribution since it is mathematically convenient and experiments indicate that it is a reasonable assumption. Thus, the differential entropy can be computed by 1 2 logð2eÞ n jAEj, where n is the dimension and AE is the covariance matrix <ref type="bibr" target="#b8">[9]</ref>.</p><p>In our applications, position and velocity are used as measurements for each body part, but humans can be present at different locations in the scene. In order to make the Gaussian assumption reasonable, translations need to be removed from the positions. Therefore, we use a local coordinate system <ref type="bibr" target="#b32">[33]</ref> for each triangle ðA t ; B t ; C t Þ, i.e., we take one body part (for example A t ) as the origin, and use relative positions for other body parts. More formally, let x denote a vector of positions x ¼ ðx A t ; x B t ; x C t ; y A t ; y B t ; y C t Þ T , where x and y denote horizontal and vertical positions, respectively. Then, if we describe positions relative to A t , we obtain</p><formula xml:id="formula_8">x 0 ¼ ðx B t À x A t ; x C t À x A t ; y B t À y A t ; y C t À y A t Þ T .</formula><p>This can be written as x 0 ¼ W x, where</p><formula xml:id="formula_9">W ¼ A 0 0 A ; with A ¼ À1 1 0 À1 0 1 :<label>ð8Þ</label></formula><p>The above discussion is on the dimensions representing positions. For the dimensions representing velocities, translation does not need to be removed, and the corresponding "A" matrix (as in <ref type="bibr" target="#b7">(8)</ref>) is an identity matrix. In the greedy search algorithm, the differential entropies of all the possible triplets are needed and different triplets have different origins. We first estimate the mean and covariance AE of X n (including all the body parts and without removing translation), then take the dimensions corresponding to the triangle and use equations</p><formula xml:id="formula_10">0 ¼ 1 N X N n¼1 x 0n ¼ 1 N X N n¼1 W x n ¼ W Á 1 N X N n¼1 x n ¼ W AE 0 ¼ W AEW T</formula><p>to get the translation invariant mean 0 and covariance AE 0 . A similar procedure can be applied to pairs (for example, B t can be taken as origin for (B t ; C t )) to achieve translation invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">UNSUPERVISED LEARNING OF THE GRAPH STRUCTURE</head><p>In this section, we present an algorithm to learn the probabilistic independence structure of human motion automatically from unlabeled training data. Our approach is based on maximizing the likelihood of the data. Taking the labeling (part assignments) as hidden variables, an EM-like algorithm can be applied. In the following, we first derive the algorithm assuming that all the foreground parts are observed for each training sample, and then generalize the algorithm to handle the case of missing body parts (occlusion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Learning with All Foreground Parts Observed</head><p>This section develops an algorithm searching for the best decomposable triangulated model from unlabeled data, which is inspired by the idea of the expectation-maximization (or EM, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b33">[34]</ref>) algorithm. The algorithm we propose does not guarantee the same convergence properties as EM although it works well in practice. Assume that we have a data set of N samples X ¼ fX 1 ; X 2 ; . . . ; X N g. Each sample X n , 1 n N, is a group of detected features containing the target object. Assume now that X n is unlabeled, which means that the correspondence between the candidate features and the parts of the object is unknown.</p><p>For convenience, we first assume that all the foreground parts are observed for each sample. If the labeling for each X n is taken as a hidden variable, then the idea of the EM algorithm can be used to learn the probability structure and parameters. Our method was inspired by <ref type="bibr" target="#b31">[32]</ref>, but while they assumed a jointly Gaussian probability density function, here we learn the probabilistic independence structure. Let h n denote the labeling for X n .</p><p>If X n contains n k features, then h n is an n k -dimensional vector with each element taking a value from S body [ fBGg (S body is the set of body parts and BG is the background clutter label). The observations are X ¼ fX 1 ; X 2 ; . . . ; X N g, the hidden variables are H ¼ fh n g N n¼1 , and the parameters to optimize are the probability (in)dependence structure and parameters for the associated probability density function. We use G to represent both the probability structure and the parameters. If we assume that X n and X m are independent when n 6 ¼ m and h n only depends on X n , then the likelihood function to maximize is,</p><formula xml:id="formula_11">L ¼ log P ðX; GÞ ¼ X N n¼1 log P ðX n jGÞ þ log P ðGÞ ¼ X N n¼1 log X h n i 2H n P ðX n ; h n ¼ h n i jGÞ þ log P ðGÞ;<label>ð9Þ</label></formula><p>where h n i is the ith possible labeling for X n , and H n is the set of all such labelings. Optimization directly over ( <ref type="formula" target="#formula_11">9</ref>) is hard, but it can be solved iteratively using the idea of EM.</p><p>For each iteration t, we will optimize the function</p><formula xml:id="formula_12">QðG t jG tÀ1 Þ ¼ E½log P ðX; H; G t ÞjX ; G tÀ1 ¼ X N n¼1 E½log P ðX n ; h n ; G t ÞjX n ; G tÀ1 ¼ X N n¼1 X h n i 2H n P ðh n ¼ h n i jX n ; G tÀ1 Þ Á log P ðX n ; h n ¼ h n i ; G t Þ ¼ X N n¼1 X h n i 2H n R n i log P ðX n ; h n ¼ h n i ; G t Þ;<label>ð10Þ</label></formula><p>where</p><formula xml:id="formula_13">R n i ¼ P ðh n ¼ h n i jX n ; G tÀ1 Þ is the probability of h n ¼ h n i</formula><p>given the observation X n and the decomposable probability structure G tÀ1 . R n i can be computed as,</p><formula xml:id="formula_14">R n i ¼ P ðh n i jX n ; G tÀ1 Þ ¼ P ðX n ; h n i ; G tÀ1 Þ= X h n i P ðX n ; h n i ; G tÀ1 Þ:<label>ð11Þ</label></formula><p>For each iteration t, R n i is a fixed number for a hypothesis h n i . We use the same method as in Section 2.1 and <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref> to compute P ðh n i ; X n ; GÞ (G is G t in <ref type="bibr" target="#b9">(10)</ref> and G tÀ1 in ( <ref type="formula" target="#formula_14">11</ref>)).</p><p>Under the labeling hypothesis </p><formula xml:id="formula_15">h n ¼ h n i , X n is</formula><p>Substituting ( <ref type="formula" target="#formula_16">12</ref>) into (10), we get,</p><formula xml:id="formula_17">X N n¼1 X h n i 2H n R n i log P ðX n ; h n ¼ h n i ; G t Þ ¼ X N n¼1 X h n i 2H n R n i ½log P ðX n fg jh n i ; G t Þ þ log P ðX n bg jh n i ; G t Þ þ log P ðh n i jG t Þ þ log P ðG t Þ ¼ X n X h n i R n i log P ðX n fg jh n i ; G t Þþ X n X h n i R n i log P ðX n bg jh n i ; G t Þþ X n X h n i R n i log P ðh n i jG t Þ þ X n X h n i R n i log P ðG t Þ:<label>ð13Þ</label></formula><p>If we assume that the priors P ðh n i jG t Þ are the same for different h n i , and P ðG t Þ are the same for different decomposable triangulated graphs, the last two terms of (13) do not depend on G t . If we assume independent uniform background noise 6 as in <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>, then the second term</p><formula xml:id="formula_18">P ðX n bg jh n i ; G t Þ ¼ ð 1 S Þ nkÀM</formula><p>, where S is the volume of the space a background feature lies in and is not a function of G t . Hence, we only need to optimize over the first term. Under probability decomposition G t , P ðX n fg jh n;G t i Þ can be computed as in <ref type="bibr" target="#b1">(2)</ref>. Therefore, the maximization of ( <ref type="formula" target="#formula_12">10</ref>) is equivalent to maximizing,</p><formula xml:id="formula_19">QðG t jG tÀ1 Þ $ X N n¼1 X h n i R n i log½P ðX n fg jh n i ; G t Þ ð14Þ ¼ X N n¼1 X h n i R n i X T t¼1 log P ðX ni At jX ni Bt ; X ni Ct Þ þ log P ðX ni BT ; X ni CT Þ ;<label>ð15Þ</label></formula><p>where X ni At is the measurements of body part A t under labeling h n i for X n , etc. For most problems, the number of possible labelings is very large (on the order of M n k ), and it is computationally prohibitive to sum over all the possible h n i as in <ref type="bibr" target="#b14">(15)</ref>. We take here the simplest approximation: If there is one hypothesis labeling h nÃ i that is much better than other hypotheses, i.e., R nÃ i corresponding to h nÃ i is much larger than other R n i 's, then R nÃ i can be taken as 1 and other R n i s as 0. Hence, (15) can be approximated as</p><formula xml:id="formula_20">QðG t jG tÀ1 Þ $ X N n¼1 X T t¼1 log P ðX niÃ A t jX niÃ B t ; X niÃ C t Þ þ log P ðX niÃ BT ; X niÃ CT Þ ;<label>ð16Þ</label></formula><p>where X niÃ At ; X niÃ B t ; and X niÃ C t are measurements corresponding to the best labeling h nÃ i , which can be obtained through the labeling algorithm presented in Section 2.1 using model G tÀ1 . Comparing ( <ref type="formula" target="#formula_20">16</ref>) with ( <ref type="formula">5</ref>), we know for iteration t, if the best hypothesis h nÃ i is used as the "true" labeling, then the decomposable triangulated graph structure G t can be obtained through the algorithm described in Section 3. One approximation we make here is that the best hypothesis labeling h nÃ i for each X n is really dominant among all the possible labelings so that hard assignment for labelings can be used. This is similar to the situation of K-means versus mixture of Gaussian for clustering problems <ref type="bibr" target="#b2">[3]</ref>.</p><p>Note that the best labeling is used to update the parameters of the probability density function (mean and covariance under Gaussian assumption). Therefore, in case of several labelings with close likelihoods, as long as the measurements associated with the body parts from these labelings are similar, the above approximation is still a good one.</p><p>The whole algorithm can be summarized as follows: Given some random initial guess of the decomposable graph structure G 0 and its parameters, then for iteration t, (t is from 1 until the algorithm converges). Comparing with the standard EM technique, we made two approximations in the above procedure. In the E-like step, we use the best labeling instead of the weighted sum of all the possible labelings. Thus, our algorithm is clearly not EM, but rather another form of coordinate ascent. In the M-like step, there is no guarantee that the greedy graph growing algorithm 6. Uniform background noise is assumed mainly for computational simplicity. Uniform background noise is to assume that background features can be present anywhere with equal probability. For natural scenes, the independent assumption is not strictly true since closer features could be more correlated than far way features, but from an engineering point of view, our experience with experiments indicates that the assumption works fine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E-like</head><p>will find the optimal graph. In Section 6, we evaluate these approximations with experiments on human motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dealing with Missing Parts (Occlusion)</head><p>So far, we have assumed that all the parts are observed. When some parts are missing, the measurements for the missing body parts may be modeled as additional hidden variables <ref type="bibr" target="#b31">[32]</ref> and the EM-like algorithm can be modified to handle the missing parts.</p><p>For each hypothesis labeling h n , let X n o denote the measurements of the observed parts, X n m be the measurements for the missing parts, and X n fg ¼ ½X nT o X nT m T be the measurements of the whole object (to reduce clutter in the notation, we assume that the dimensions can be sorted in this way). The superscript T denotes transpose. For each iteration t, we need to compute t and AE t to obtain the differential entropies and then G t with its parameters. Taking h n and X n m as hidden variables, we can get,</p><formula xml:id="formula_21">t ¼ 1 N X n EðX n fg Þ ð 17Þ AE t ¼ 1 N X n EðX n fg À t ÞðX n fg À t Þ T ¼ 1 N X n EðX n fg X nT fg Þ À t T t ;<label>ð18Þ</label></formula><p>where </p><formula xml:id="formula_22">EðX n fg Þ ¼ ½X nÃT o EðX nT m Þ T ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MIXTURES OF DECOMPOSABLE TRIANGULATED MODELS 5.1 Definition</head><p>In the previous sections, we model each triangle by a Gaussian distribution; therefore, the joint probability density function of all the parts is a Gaussian. </p><formula xml:id="formula_23">P ðXÞ ¼ X C j¼1 P ðXjc ¼ jÞP ðc ¼ jÞ ¼ X C j¼1 X hji2Hj P ðX; h j ¼ h ji jc ¼ jÞP ðc ¼ jÞ;<label>ð19Þ</label></formula><p>where h ji is the ith possible labeling of X under component model j, and H j is the set of all such possible labelings. In the above equation, P ðc ¼ jÞ ¼ j is the prior probability of component j and P ðX; h j ¼ h ji jc ¼ jÞ can be computed in a similar way to (12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Learning Rules</head><p>For clarity, we first assume that all the foreground parts are present for each component. Compared with the algorithm in Section 4.1, the observations are the same: </p><formula xml:id="formula_24">X ¼</formula><formula xml:id="formula_25">¼ X N n¼1 X C j¼1 X h n ji 2H n j P ðh n j ¼ h n ji ; c n ¼ jjX n ; G tÀ1 ; Å tÀ1 Þ Á log P ðX n ; h n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ ð 23Þ ¼ X N n¼1 X C j¼1 X h n ji 2H n j P ðh n j ¼ h n ji jc n ¼ j; X n ; G tÀ1 ; Å tÀ1 Þ Á P ðc n ¼ jjX n ; G tÀ1 ; Å tÀ1 Þ Á log P ðX n ; h n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ:<label>ð22Þ</label></formula><p>The E½Á in ( <ref type="formula">21</ref>) and ( <ref type="formula" target="#formula_25">22</ref>) is the expectation of log likelihood given the observed data and parameters from iteration t À 1. Equation ( <ref type="formula">23</ref>) is to compute the expectation by summing over all the possible values of the hidden variables. For convenience, we define R n ji ¼ P ðh n j ¼ h n ji jc n ¼ j; X n ; G tÀ1 ; Å tÀ1 Þ, which is the probability of a labeling h n ji of X n given X n and X n belonging to component j, and</p><formula xml:id="formula_27">! n j ¼ P ðc n ¼ jjX n ; G tÀ1 ; Å tÀ1 Þ, which is the probability of X n belonging to component j given X n .</formula><p>Assuming that all the component models have the same number of body parts and within one component model the prior probabilities of all the possible labelings are uniformly distributed, we can obtain (see <ref type="bibr" target="#b27">[28]</ref> for detailed derivation),  <ref type="formula" target="#formula_28">25</ref>) can be computed efficiently by dynamic programming (use "sum" operation instead of "max" operation, for more details see <ref type="bibr" target="#b25">[26]</ref>).</p><formula xml:id="formula_28">! n j ¼ j tÀ1 P h n ji 2H n j P ðX n fgðjiÞ jh n ji ; G j tÀ1 Þ P C k¼1 k tÀ1 P h n ki 2H n k P ðX n fgðkiÞ jh n ki ; G k tÀ1 Þ ;<label>ð25Þ</label></formula><p>The computation of R n ji is the same as <ref type="bibr" target="#b10">(11)</ref>, but using component model G j tÀ1 . ! n j and R n ji are computed using the parameters from iteration t À 1, hence they are fixed constants for function Q at iteration t.</p><p>Substituting ! n j and R n ji into (24), we get,</p><formula xml:id="formula_29">QðG t ; Å t jG tÀ1 ; Å tÀ1 Þ ¼ X N n¼1 X C j¼1 X h n ji 2H n j R n ji Á ! n j Á log P ðX n ; h n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á log P ðX n ; h n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á ½log P ðX n jh n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ þ log P ðh n j ¼ h n ji jc n ¼ j; G t ; Å t Þ þ log P ðc n ¼ jjG t ; Å t Þ ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á ½log P ðX n fgðjiÞ jh n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ þ log P ðX n bgðjiÞ jh n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ þ log P ðh n j ¼ h n ji jc n ¼ j; G t ; Å t Þ þ log P ðc n ¼ jjG t ; Å t Þ ¼ Q 1 þ Q 2 þ Q 3 þ Q 4 ;<label>ð26Þ</label></formula><p>where</p><formula xml:id="formula_30">Q 1 ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á log P ðX n fgðjiÞ jh n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ ¼ X C j¼1 X N n¼1 ! n j X h n ji 2H n j R n ji Á log P ðX n fgðjiÞ jh n j ¼ h n ji ; G j t Þ ¼ X C j¼1 Q j 1<label>ð27Þ</label></formula><formula xml:id="formula_31">Q 2 ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á log P ðX n bgðjiÞ jh n j ¼ h n ji ; c n ¼ j; G t ; Å t Þ ð 28Þ Q 3 ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á log P ðh n j ¼ h n ji jc n ¼ j; G t ; Å t Þ<label>ð29Þ</label></formula><formula xml:id="formula_32">Q 4 ¼ X N n¼1 X C j¼1 ! n j X h n ji 2H n j R n ji Á log P ðc n ¼ jjG t ; Å t Þ ¼ X C j¼1 X N n¼1 ! n j X h n ji 2H n j R n ji Á logð j t Þ ¼ X C j¼1 X N n¼1 ! n j logð j t Þ:<label>ð30Þ</label></formula><p>We want to find G t and Å t which can maximize</p><formula xml:id="formula_33">Q ¼ Q 1 þ Q 2 þ Q 3 þ Q 4 . Q 2 and Q 3 are not functions of G t and Å t . Q 1 is a function of G t and Q 4 is a function of Å t .</formula><p>From <ref type="bibr" target="#b26">(27)</ref>, the best G j t is the one which can maximize</p><formula xml:id="formula_34">Q j 1 ¼ X N n¼1 ! n j X h n ji 2H n j R n ji Á log P ðX n fgðjiÞ jh n j ¼ h n ji ; G j t Þ<label>ð31Þ</label></formula><formula xml:id="formula_35">% X N n¼1 ! n j log P ðX nÃ fgðjiÞ jG j t Þ;<label>ð32Þ</label></formula><p>where X nÃ fgðjiÞ is the foreground configuration with the highest R n ji , i.e., the best labeling of X n under model G j tÀ1 . The approximation from ( <ref type="formula" target="#formula_34">31</ref>) to ( <ref type="formula" target="#formula_35">32</ref>) is under the same reasoning as from ( <ref type="formula" target="#formula_19">15</ref>) to <ref type="bibr" target="#b15">(16)</ref>. Under Gaussian assumption, the maximum likelihood parameter estimation of G j t can be obtained by taking derivatives of ( <ref type="formula" target="#formula_35">32</ref>) with respect to mean and covariance matrix and equating to zero. Then, we have the updated parameters,</p><formula xml:id="formula_36">j t ¼ P n ! n j X nÃ fgðjiÞ P n ! n j ;<label>ð33Þ</label></formula><formula xml:id="formula_37">AE j t ¼ P n ! n j X nÃ fgðjiÞ ðX nÃ fgðjiÞ Þ T P n ! n j À j t ð j t Þ T :<label>ð34Þ</label></formula><p>From j t and AE j t , the decomposable triangulated structure can be obtained by running the graph growing algorithm in Section 3.</p><p>To optimize Å t , we maximize Q 4 under the constraint P C j¼1 j t ¼ 1. Using Lagrange multipliers, we get,</p><formula xml:id="formula_38">j t ¼ P n ! n j N :<label>ð35Þ</label></formula><p>The whole algorithm can be summarized as follows: First, we need to fix C, the number of component models in the mixtures, and the number of body parts in each component model. Then we generate random initializations for each component model, G 0 ¼ ½G 1 0 ; . . . ; G C 0 , and the initial priors Å 0 . At each iteration t (t from 1 till convergence). E-like step: For each X n , find the best labeling X nÃ fgðjiÞ using component model G j tÀ1 , j ¼ 1; . . . ; C and compute ! n j by <ref type="bibr" target="#b24">(25)</ref>.</p><p>M-like step: Update j t and AE j t as in <ref type="bibr" target="#b32">(33)</ref> and <ref type="bibr" target="#b33">(34)</ref>. Run the graph growing algorithm (Section 3) on each AE j t to obtain updated G j t , j ¼ 1; . . . ; C. Update Å t as in <ref type="bibr" target="#b34">(35)</ref>. So far, we have assumed that all the foreground parts are observed for each component model. In the case of some parts missing (occlusion), the same techniques as in Section 4.2 are applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Detection and Labeling Using Mixture Models</head><p>For an observation X, we can run the detection and labelings algorithms summarized in Section 2.1 on each component model G j , j ¼ 1; . . . ; C, to get the best labeling X Ã fgðjÞ and an estimation of P G j ðXÞ (by either the winner-take-all strategy or the sum-over-all-possiblelabeling strategy). Detection can be performed by thresholding P C j¼1 j Á P G j ðXÞ. The localization of the human body can be determined by the best configuration X Ã fgðjÞ with the highest j Á P G j ðXÞ among all the best configurations X Ã fgðjÞ , j ¼ 1; . . . ; C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>Experiments were performed on two types of data: labeled motion capture data and unlabeled real image sequences. The experiments on the labeled motion capture data were used to test the greedy graph growing algorithm described in Section 3. The experiments on the unlabeled real image sequences were to evaluate the unsupervised learning algorithms developed in Sections 4 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experiments on Motion Capture Data</head><p>Our motion capture data (the same as in <ref type="bibr" target="#b26">[27]</ref>) consist of the 3D positions of 14 markers fixed rigidly on a subject's body. These positions were tracked with 1mm accuracy as the subject walked back and forth, and projected to 2D. We used around 3,000 frames (50 seconds long) to build models, and an other 3,000 frames for testing.</p><p>Under the Gaussian assumption, we first estimated the joint probability density function (mean and covariance) of the data. From the estimated mean and covariance, we could compute differential entropies for all the possible triplets and pairs and further run the greedy search algorithm (Section 3.2) to find the approximate best triangulated model. In order to benchmark the algorithm, we also obtained a maximum spanning tree (MST) based on differential entropies <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b16">[17]</ref>, and edges were added in a greedy fashion to transform the MST into a decomposable triangulated graph <ref type="bibr" target="#b27">[28]</ref>. Fig. <ref type="figure" target="#fig_1">2</ref> displays the models. Fig. <ref type="figure" target="#fig_1">2a</ref> is the hand-constructed model used in previous work <ref type="bibr" target="#b26">[27]</ref> (Fig. <ref type="figure" target="#fig_0">1a</ref>); Fig. <ref type="figure" target="#fig_1">2b</ref> is the model obtained from greedy search (Section 3.2); Fig. <ref type="figure" target="#fig_1">2c</ref> is the decomposable triangulated model grown from a maximum (c) Decomposable triangulated model grown from a maximum spanning tree <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b16">[17]</ref>. The solid lines are edges from the maximum spanning tree and the dashed lines are added edges <ref type="bibr" target="#b27">[28]</ref>. (d) A randomly generated decomposable triangulated model.</p><p>spanning tree. The solid lines are edges of the maximum spanning tree and the dashed lines are added edges. Fig. <ref type="figure" target="#fig_1">2d</ref> shows a randomly generated decomposable triangulated model, which is grown as follows: We start from a randomly selected edge. At each following stage, a vertex is randomly selected and an edge in the existing graph is randomly  selected as its parent edge and then the newly selected vertex is connected with the two vertices of the edge.</p><p>Since the goal of model searching is to find the one with the highest likelihood (Section 3.1), we first evaluate the models by likelihoods. Fig. <ref type="figure" target="#fig_2">3a</ref> shows the likelihood of the estimated joint probability density function (pdf), for each one of the approximate models as well as a number of randomly generated models (mean and error bars). The horizontal axis is the number of edges in the model, which is an indicator of computational cost. The decomposable triangulated model from the greedy search (Section 3.2) has the highest likelihood of all the approximate models. The triangulated model grown from maximum spanning tree is the second best. The handconstructed model is the third best. The maximum spanning tree is worse than the above three triangulated models (not surprisingly, since it has fewer parameters), but is superior to the random triangulated models. The full Gaussian joint pdf shown for comparison has the highest likelihood, but it cannot be used in a computationally efficient manner.</p><p>A natural question to ask is: how close is the likelihood of our greedy graph to the likelihood of the "optimal" triangulated graph? We address this question with experiments on synthetic datasets generated by models with known decomposable triangulated independence. To accomplish this, we generate a random decomposable triangulated model, then generate data according to this model: 3,000 frames for learning and 3,000 frames for testing. In order to make this a meaningful comparison, we add the constraint that, on each triangle, the marginal probability density of the generated data is the same as that of the original motion capture data. Fig. <ref type="figure" target="#fig_2">3b</ref> shows likelihoods using 50 synthetic data sets, which were generated from 50 triangulated models. The likelihood of the greedy algorithm (solid curve) matches the likelihood of the true model (dashed curve) very well. The solid line with error Types of Images Used in the Experiments "L-R" denotes "from left to right," and "R-L" means "from right to left." The digits in the parenthesis are the number of sequences by the number of frames in each sequence. For example, (3-4 x 80) means that there are three or four sequences, with around 80 frames for each sequence. The +/in the code-names denotes whether movement is R-L or L-R. bars are the likelihoods of random triangulated models. We conclude that the greedy search algorithm (Section 3.2) delivers quasioptimal solutions on this type of data. We will therefore use this algorithm in the following experiments.</p><p>In this section, we used a criterion based on likelihood to evaluate the greedy graph growing algorithm. However, there are other more important factors such as ability of dealing with occlusion and translation invariance that make decomposable triangulated graphs an appropriate choice for our application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experiments on Gray-Scale Image Sequences</head><p>In this section, we conduct experiments on gray-scale image sequences. The image sequences were acquired using a digital camcorder at 30Hz frame rate. The images were converted into gray-scale and the image resolution is 240 x 360. To apply our algorithms, candidate features were obtained using a Lucas-Tomasi-Kanade <ref type="bibr" target="#b29">[30]</ref> feature selector/tracker on pairs of frames. Features are selected at each frame, and are tracked to the next frame to obtain positions and velocities <ref type="bibr" target="#b25">[26]</ref>.</p><p>The image sequences (see Figs. <ref type="figure" target="#fig_3">4</ref> and<ref type="figure" target="#fig_8">8</ref> for sample images) used in the experiments are summarized in Table <ref type="table" target="#tab_6">1</ref>. The first column of Table <ref type="table" target="#tab_6">1</ref> gives the code-names of the sequences, e.g., (p1), (p2), and (b-), which will be used to represent the sequences. In the description of the sequences, "L-R" denotes "from left to right," and "R-L" means "from right to left." The 10 subjects of the (p1) sequences include six males and four females from 20 to 50 years old. We assume that the distance between the person and the camera is constant.</p><p>In the experiments, R-L walking motion models were learned from (p1) sequences and tested on all types of sequences to see if the learned model can detect R-L walking and label the body parts correctly. Type (p1), (p2), and (p3) sequences are considered as positive examples and the others are negative examples. In the following, we first evaluate the learning algorithms and then report the detection and labeling results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Evaluation of the Unsupervised Learning Algorithm</head><p>There are two approximations in the unsupervised learning algorithms (see the end of Section 4.1). Here, we evaluate the algorithm by checking how the log-likelihoods evolve with each iteration and if they converge. We learn two types of models. The first one is a single-subject model: using nine type (p1) sequences of one subject named LG. The other is a multiple-people model learned from 12 type (p1) sequences from four subjects (including subject LG). Fig. <ref type="figure" target="#fig_4">5</ref> shows some typical results of learning a 3-component model, each component with 12 parts. Fig. <ref type="figure" target="#fig_4">5a</ref> is of singlesubject models and Fig. <ref type="figure" target="#fig_4">5b</ref> is of multiple-people models. We used random initializations and the 10 curves in Fig. <ref type="figure" target="#fig_4">5a</ref> or Fig. <ref type="figure" target="#fig_4">5b</ref> correspond to 10 such random initializations. If the likelihood difference of two iterations is less than 0.1 percent, the algorithm terminates. From Fig. <ref type="figure" target="#fig_4">5</ref>, we can see that while log likelihood is not strictly monotonic, but, in general, the log likelihoods increase with each iteration and converge well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Models Obtained</head><p>We tested the models using a small validation set and found no big difference in terms of detection performance. Figs. 6a and 6b show a single-subject model (corresponding to the thick curve in Fig. <ref type="figure" target="#fig_4">5a</ref>). Fig. <ref type="figure" target="#fig_5">6a</ref> gives the mean positions and mean velocities (shown in arrows) of the parts for each component model. The prior probabilities are shown on top of each plot. Fig. <ref type="figure" target="#fig_5">6b</ref> depicts the learned decomposable triangulated probabilistic structure for the three component models in Fig. <ref type="figure" target="#fig_5">6a</ref>, respectively. The letter labels show the body parts correspondence. Figs. 6c and 6d are a multiple-people model (corresponding to the thick curve in Fig. <ref type="figure" target="#fig_4">5b</ref>) and follow the same representation custom as in Figs. <ref type="figure" target="#fig_5">6a</ref> and<ref type="figure" target="#fig_5">6b</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Detection and Labeling</head><p>We conduct detection and labeling (Section 5.3) experiments using the models obtained. To quantify the detection performance, we first get receiver operating characteristics (ROC) curves from the likelihood of each sample (Section 5.3). From an ROC curve, we can take the "equal error" detection rate when P detection ¼ 1 À P false alarm as an indicator of the detection performance. The performance is measured on each pair of frames independently. All the negative sequences ending with (+) have R-L motion and (-) means that L-R motion is the major motion. Detection is almost perfect when images from an L-R (-) type of sequences are used as negative examples. Among the R-L (+) types of sequences, the water moving R-L sequence (with a lot of features) and the sequences of a person standing still with camera panning are the hardest. From Fig. <ref type="figure" target="#fig_6">7</ref>, we see that the two models perform similarly, with overall detection rates (out-of-training-set subjects) of 97.0 percent and 96.1 percent for the single-subject model and multiple-people model, respectively.</p><p>We also experimented with a 12-part Gaussian model with a single component. We find that the detection rates are similar to the 3-component models when the negative sequences offer easy discrimination, e.g., L-R (-), but the detection rates are approximately 10 percent worse than 3-component models on hard discrimination tasks, e.g., water running R-L (w+) sequences.</p><p>Fig. <ref type="figure" target="#fig_8">8</ref> shows results on some images using the 12-part 3-component multiple-people model (Fig. <ref type="figure" target="#fig_5">6c</ref>). The text string at the bottom right corner of each image indicates which type of sequences the image is from. The small black circles are candidate features obtained from the Lucas-Tomasi-Kanade feature detector/tracker. The arrows associated with circles indicate the velocities. The horizontal lines at the bottom left of each image give the log-likelihoods. The top three lines are the log-likelihoods (P G j ðXÞ) of the three component models, respectively. The bottom line is the overall log-likelihood ( P C j¼1 j Á P G j ðXÞ) (Section 5.3). The short vertical bar (at the bottom) indicates the threshold for detection, under which we get equal missed detection rate and false alarm rate for all the available positive and negative examples. If a R-L walking motion is detected according to the threshold, then the best labeling from the component with the highest log-likelihood is drawn in solid black dots, and the letter beside each dot shows the correspondence with the parts of the component model in Fig. <ref type="figure" target="#fig_5">6c</ref>. The number at the upper right corner shows the highest likelihood component, with 1; 2; 3 corresponding to the three components in Fig. <ref type="figure" target="#fig_5">6c</ref> from left to right. For the samples in Fig. <ref type="figure" target="#fig_8">8</ref>, all the positive R-L walking are correctly detected, and one negative example (from the water running R-L sequence) is wrongly claimed as a person R-L walking (a false alarm).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND DISCUSSIONS</head><p>We have described a method for learning a probabilistic model of human motion in an unsupervised fashion from unlabeled cluttered data. Our models are mixtures of Gaussian with conditional independence described by a decomposable triangulated graph. We explore the efficiency and effectiveness of our algorithm by learning a model of right-to-left walking and testing on walking sequences of a number of people as well as a variety of nonwalking motions. We find an average of 4 percent error rate on our examples. This rate is measured on pairs of frames evaluated independently, and it becomes virtually zero when 4-5 pairs of frames (150-200 ms of video) are considered simultaneously <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b25">[26]</ref>. This is very promising for building a real-life system, for example, a pedestrian detector.</p><p>We find that our models generalize well across subjects and not at all across types of motions. The model learned on subject LG worked equally well in detecting all other subjects and very poorly at subject discrimination. By contrast, it was easy to discriminate walking from jogging and biking in the same direction.</p><p>We used point features (from a corner detector) in our experiments because they are easier to obtain compared to body segments that may be hard to detect in case of severe occlusion. Another reason is that psychophysics experiments (Johansson's experiments <ref type="bibr" target="#b18">[19]</ref>) show that the human visual system can perceive vivid human motion from moving dots representing the motion of the main joints of the human body. But, the algorithms can also be applied to other types of features. A systematic study of the trade-off between model complexity (number of components and number of parts) and accuracy is still missing (we used 3-component 12-part models in this paper), as well as experiments with different types of motions beyond walking. Decomposable triangulated graphs are used in our application because intuitively they have better graph connectivity in case of occlusion and, therefore, better ability in achieving translation invariance (Sections 2.2 and 6.1). However, while trees appear less promising than triangulated graphs, we have not yet carried out experiments to confirm our intuition. Since the unsupervised technique described in this paper is not limited to decomposable triangulated graphs, it would be equally interesting to experiment with other types of graphical models. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Two decompositions of the human body into triangles [27]. "L" and "R" in label names indicate left and right. H: head, N: neck, S: shoulder, E: elbow, W: wrist, H: hip, K: knee, A: ankle, and F: foot. In (a), the numbers inside triangles give one order in which the vertices can be deleted. In (b), the numbers in brackets show one elimination order.</figDesc><graphic coords="2,43.60,51.17,216.34,218.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Decomposable triangulated models for motion capture data. (a) Hand-constructed model [27]. (b) Model obtained from greedy search (Section 3.2). (c) Decomposable triangulated model grown from a maximum spanning tree<ref type="bibr" target="#b6">[7]</ref>,<ref type="bibr" target="#b21">[22]</ref>,<ref type="bibr" target="#b16">[17]</ref>. The solid lines are edges from the maximum spanning tree and the dashed lines are added edges<ref type="bibr" target="#b27">[28]</ref>. (d) A randomly generated decomposable triangulated model.</figDesc><graphic coords="8,77.73,51.17,411.02,131.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Likelihood evaluation of graph growing algorithms. (a) On motion capture data. Log likelihood versus number of edges in the model. (b) On synthetic data with decomposable triangulated independence. Dashed curve: likelihoods of the true models, solid curve: of models from greedy search, and the solid line with error bars: of random triangulated models.</figDesc><graphic coords="9,70.87,51.17,424.74,186.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Sample images extracted from our sequences. The text string in parenthesis indicates the image type.</figDesc><graphic coords="9,102.95,279.24,360.57,397.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Evaluation of the unsupervised learning algorithm: Evolution of log-likelihoods from different random initializations. The indices along the horizontal axis show the number of iterations completed. (a) Shows 12-part 3-component single-subject models. (b) Shows 12-part 3-component multiple-people models.</figDesc><graphic coords="10,66.90,533.06,432.68,175.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Examples of 12-part 3-component models. (a) and (b) are a single-subject model (corresponding to the thick curve in Fig. 5a), and (c) and (d) are a multiple-people model (the thick curve in Fig. 5b). (a) (or (c)) gives the mean positions and mean velocities (shown in arrows) of the parts for each component model. The number i , i ¼ 1; 2; 3, on top of each plot is the prior probability for each component model. (b) (or (d)) is the learned decomposable triangulated probabilistic structure for models in (a) (or (c)). The letter labels show the body parts correspondence.</figDesc><graphic coords="11,292.54,51.17,244.46,504.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7</head><label>7</label><figDesc>summarizes such detection rates of positive R-L walking sequences versus different types of negative sequences. The horizontal axis of Fig. 7 displays the different types of negative examples (as described in Table 1). We get the detection rate of each positive R-L walking sequence versus a certain type of negative sequences, and the average detection rate is shown either in star (*) or in circle (o). The error bars show the maximum or minimum detection rate. The stars (*) with error bars use the positive walking sequences of subject LG as positive examples, the circles (o) with error bars use the positive sequences of other subjects not in the training set. Fig. 7a is from the single-subject model as in Fig. 6a, and Fig. 7b is from the multiple-people model as in Fig. 6c.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Detection rates versus types of negative examples. (a) is from the single-subject model (Fig. 6a) and (b) is from the multiple-people model (Fig. 6c). Stars (*) with error bars use R-L walking sequences of subject LG as positive examples and circles (o) with error bars use R-L walking sequences of other subjects. The stars (or circles) show the average detection rates and error bars give the maximum and minimum detection rates.</figDesc><graphic coords="12,110.15,51.17,346.11,156.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Detection and labeling results on some images. If a R-L walking motion is detected according to the threshold, then the best labeling from the component with the highest log-likelihood is drawn in solid black dots. The number at the upper right corner shows the highest likelihood component. See text for detailed explanations of symbols.</figDesc><graphic coords="13,117.41,51.17,331.71,416.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>step: Use G tÀ1 to find the best labeling h nÃ -like step: update t and covariance matrix AE t with t ¼ Þ T . Use t and AE t to compute differential entropies and run the graph growing algorithm described in Section 3 to get G t .</figDesc><table><row><cell cols="2">X</cell><cell cols="2">n . Let X</cell><cell cols="3">i for each fg denote the corresponding foreground nÃ</cell></row><row><cell cols="5">measurements.</cell><cell></cell></row><row><cell>1 N</cell><cell cols="2">P n X</cell><cell cols="2">nÃ fg and AE t ¼ 1 N</cell><cell>P n ðX</cell><cell>nÃ fg À t ÞðX</cell><cell>nÃ fg À t</cell></row></table><note><p>M</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>and</figDesc><table><row><cell>EðX</cell><cell>n fg X</cell><cell>nT fg Þ ¼</cell><cell>"</cell><cell>X EðX nÃ o X n m ÞX nÃT o nÃT o</cell><cell>X EðX nÃ o EðX n m X nT nT m Þ m Þ</cell><cell># :</cell></row><row><cell cols="7">All the expectations EðÁÞ are conditional expectations with</cell></row><row><cell cols="7">respect to X G tÀ1 . Therefore, X n ; h n ¼ h nÃ i and decomposable graph structure nÃ o are the measurements of the observed</cell></row><row><cell cols="7">foreground parts under h n ¼ h nÃ i . Since G tÀ1 is Gaussian distributed, conditional expectation EðX n m Þ and EðX n m X nT m Þ can be computed from observed parts X nÃ o and the mean</cell></row><row><cell cols="5">and covariance matrix of G tÀ1 .</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>More formally, a C-component mixture model can berepresented by G ¼ ½G 1 G 2 Á Á Á G C and Å ¼ ½ 1 2 Á Á Á C ,where G j , j ¼ 1; . . . ; C is a decomposable triangulated Gaussian model, and j is the prior probability of G j . Each</figDesc><table><row><cell>component model G j has an independent set of body</cell></row><row><cell>parts-some features corresponding to foreground body</cell></row><row><cell>parts of one component model may be taken as background</cell></row><row><cell>by another component model.</cell></row><row><cell>For an unlabeled observation X, let c (taking a value</cell></row><row><cell>from 1 to C) represent the random variable assigning a</cell></row><row><cell>component model to X, and h j the random variable</cell></row><row><cell>denoting the labeling of X under component model G j .</cell></row><row><cell>Since different component models may have different sets</cell></row><row><cell>of body parts, a labeling must be associated with a</cell></row><row><cell>particular component model. The probability of an un-</cell></row><row><cell>labeled observation X is,</cell></row></table><note><p>To better express the variability and/or different phases of human motion, we extend the algorithms to mixtures of decomposable triangulated models, which are mixtures of Gaussian, with each component model being a Gaussian with conditional independence described by a decomposable triangulated graph. Each component model is relatively independent in the sense that different components can have different sets of body parts. Intuitively, a mixture model is a weighted sum of several individual decomposable triangulated models.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 1</head><label>1</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>From Section 2, we know that the search for the optimal decomposable triangulated graph is equivalent to the search for the optimal graph with treewidth not greater than three. It is proven that the latter problem is NP-hard<ref type="bibr" target="#b5">[6]</ref>,<ref type="bibr" target="#b28">[29]</ref>. Therefore, the search of the optimal decomposable triangulated graph is NP-hard.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>5. Note that Xn in Section 3 is different from other sections. Here, X n is a sample from a probability distribution of M body parts. It only includes measurements of body parts with known correspondence. In other sections, it denotes the observed measurements that include body parts and background clutter.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 25, NO. 25, JULY 2003</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Part of the work in this paper was published in the Proceedings on Computer Vision and Pattern Recognition '01 and NIPS '01. This work was funded by the US National Science Foundation Engineering Research Center for Neuromorphic Systems Engineering (CNSE) at Caltech (NSF9402726), and an Office of Navy Research grant N00014-01-1-0890 under the MURI program. The authors would like to thank Charless Fowlkes for bringing the Chow and Liu paper to their attention.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. For more information on this or any other computing topic, please visit our Digital Library at http://computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graphical Templates for Model Registration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="225" to="236" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><surname>Bertele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brioschi</surname></persName>
		</author>
		<title level="m">Nonserial Dynamic Programming</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Neural Networks for Pattern Recognition</title>
		<imprint>
			<publisher>Clarendon Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">3D Position, Attitude and Shape Input Using Video Tracking of Hands and Lips</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Siggraph</title>
		<meeting>ACM Siggraph</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="185" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tracking People with Twists and Exponential Maps</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning Bayesian Networks Is NP-Hard</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<idno>MSR-TR-94-17</idno>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">technical report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Approximating Discrete Probability Distributions with Dependence Trees</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="462" to="467" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">An Introduction to Algorithms</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Elements of Information Theory</title>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Maximum Likelihood from Incomplete Data via the EM Algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statistical Soc. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Labeling Human Motion Using Mixtures of Trees</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Univ. of California at Berkeley, personal communication</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning Bayesian Networks from Data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldszmidt</surname></persName>
		</author>
		<ptr target="http://robotics.stanford.edu/people/nir/tutorial/" />
	</analytic>
	<monogr>
		<title level="m">AAAI 1998 Tutorial</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Being Bayesian about Network Structure</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Conf. Uncertainty in Artificial Intelligence</title>
		<meeting>16th Conf. Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Visual Analysis of Human Movement: A Survey</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="82" to="98" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Monocular Tracking of the Human Arm in 3D</title>
		<author>
			<persName><forename type="first">L</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ursella</surname></persName>
		</author>
		<author>
			<persName><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Int&apos;l Conf. Computer Vision</title>
		<meeting>Fifth Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="764" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Who, When, Where, What: A Real Time System for Detecting and Tracking People</title>
		<author>
			<persName><forename type="first">I</forename><surname>Haritaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Face and Gesture Recognition Conf</title>
		<meeting>Third Face and Gesture Recognition Conf</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="222" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human Tracking with Mixtures of Trees</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Computer Vision</title>
		<meeting>Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="page" from="690" to="695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An Introduction to Bayesian Networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual Perception of Biological Motion and a Model for Its Analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="201" to="211" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning in Graphical Models</title>
		<editor>I. Jordan</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">An Introduction to Graphical Models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning with Mixtures of Trees</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detecting Activities</title>
		<author>
			<persName><forename type="first">R</forename><surname>Polana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DARPA Image Understanding Workshop</title>
		<meeting>DARPA Image Understanding Workshop</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="569" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Visual Tracking of High DOF Articulated Structures: An Application to Human Hand Tracking</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="35" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Incremental Recognition of Pedestrians from Image Sequences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="page" from="8" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards Detection of Human Motion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="810" to="817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Monocular Perception of Biological Motion in Johansson Displays</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="303" to="327" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A Probabilistic Approach to Human Motion Detection and Labeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Caltech</publisher>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Maximum Likelihood Bounded Tree-Width Markov Networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Conf. Uncertainty in Artificial Intelligence</title>
		<meeting>16th Conf. Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="504" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Detection and Tracking of Point Features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<idno>CMU-CS-91-132</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tracking Persons in Monocular Image Sequences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="174" to="192" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Models for Recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2000-07">June/July 2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Unsupervised Learning of Models for Object Recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<pubPlace>Caltech</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">EM-Algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Class Notes at California Inst. of Technology</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Parameterized Modeling and Recognition of Activities</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yacoob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Image Understanding</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="232" to="247" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
