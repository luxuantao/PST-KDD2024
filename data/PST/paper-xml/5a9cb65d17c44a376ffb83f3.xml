<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Interpretable Reasoning Network for Multi-Relation Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mantong</forename><surname>Zhou</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
							<email>aihuang@tsinghua.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Lab. of Intelligent Technology and Systems</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science and Technology</orgName>
								<orgName type="laboratory">National Lab. for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Interpretable Reasoning Network for Multi-Relation Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-relation Question Answering is a challenging task, due to the requirement of elaborated analysis on questions and reasoning over multiple fact triples in knowledge base. In this paper, we present a novel model called Interpretable Reasoning Network that employs an interpretable, hop-by-hop reasoning process for question answering. The model dynamically decides which part of an input question should be analyzed at each hop; predicts a relation that corresponds to the current parsed results; utilizes the predicted relation to update the question representation and the state of the reasoning process; and then drives the next-hop reasoning. Experiments show that our model yields state-of-the-art results on two datasets. More interestingly, the model can offer traceable and observable intermediate predictions for reasoning analysis and failure diagnosis, thereby allowing manual manipulation in predicting the final answer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain Question Answering (QA) has always been a hot topic in AI and this task has recently been facilitated by large-scale Knowledge Bases (KBs) such as Freebase <ref type="bibr" target="#b4">(Bollacker et al., 2008)</ref>. However, due to the variety and complexity of language and knowledge, open-domain question answering over knowledge bases (KBQA) is still a challenging task.</p><p>Question answering over knowledge bases falls into two types, namely single-relation QA and multirelation QA, as argued by <ref type="bibr" target="#b33">Yin et al. (2016)</ref>. Single-relation questions, such as "How old is Obama?", can be answered by finding one fact triple in KB, and this task has been widely studied <ref type="bibr" target="#b8">(Bordes et al., 2015;</ref><ref type="bibr" target="#b28">Xu et al., 2016;</ref><ref type="bibr" target="#b21">Savenkov and Agichtein, 2017)</ref>. In comparison, reasoning over multiple fact triples is required to answer multi-relation questions such as "Name a soccer player who plays at forward position at the club Borussia Dortmund." where more than one entity and relation are mentioned. Compared to single-relation QA, multi-relation QA is yet to be addressed.</p><p>Previous studies on QA over knowledge bases can be roughly categorized into two lines: semantic parsing and embedding-based models. Semantic parsing models <ref type="bibr" target="#b30">(Yih et al., 2014;</ref><ref type="bibr" target="#b31">Yih et al., 2016)</ref> obtain competitive performance at the cost of hand-crafted features and manual annotations, but lack the ability to generalize to other domains. In contrast, embedding-based models <ref type="bibr" target="#b7">(Bordes et al., 2014b;</ref><ref type="bibr" target="#b13">Hao et al., 2017;</ref><ref type="bibr" target="#b29">Yavuz et al., 2017)</ref> can be trained end-to-end with weak supervision, but existing methods are not adequate to handle multi-relation QA due to the lack of reasoning ability.</p><p>Recent reasoning models <ref type="bibr" target="#b16">(Miller et al., 2016;</ref><ref type="bibr" target="#b26">Wang et al., 2017)</ref> mainly concentrate on Reading Comprehension (RC) which requires to answer questions according to a given document. However, transferring existing RC methods to KBQA is not trivial. For one reason, the focus of reasoning in RC is usually on understanding the document rather than parsing questions. For another reason, existing reasoning networks are usually designed in a black-box style, making the models less interpretable. While in multi-relation question answering, we believe that an interpretable reasoning process is essential.</p><p>In this paper, we propose a novel Interpretable Reasoning Network (IRN) to equip QA systems with the reasoning ability to answer multi-relation questions. Our central idea is to design an interpretable reasoning process for a complex question: the reasoning module decides which part of an input question should be analyzed at each hop, and predicted a KB relation that corresponds to the current parsed results. The predicted relation will be used to update the question representation as well as the state of the reasoning module, and helps the model to make the next-hop reasoning. At each hop, an entity will be predicted based on the current state of the reasoning module.</p><p>Different from previous models, our model is interpretable in that the predicted relation and entity at each hop are traceable and observable. At each hop our model has a specific aim to find an appropriate relation based on the iterative analysis of a question, and intermediate output at each hop can be interpreted by the corresponding linked entity. In this manner, IRN offers the ability of visualizing a complete reasoning path for a complex question, which facilitates reasoning analysis and failure diagnosis, thereby allowing manual manipulation in answer prediction as detailed in our experiments.</p><p>The contributions of this paper are in two folds:</p><p>1. We design an Interpretable Reasoning Network which can make reasoning on multi-relation questions with multiple triples in KB. Results show that our model obtains state-of-the-art performance.</p><p>2. Our model is more interpretable than existing reasoning networks in that the intermediate entities and relations predicted by the hop-by-hop reasoning process construct traceable reasoning paths to clearly reveal how the answer is derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Recent works on QA can be roughly classified into two types: one is semantic-parsing-based and the other is embedding-based. Semantic parsing approaches map questions to logical form queries <ref type="bibr" target="#b20">(Pasupat and Liang, 2015;</ref><ref type="bibr" target="#b31">Yih et al., 2016;</ref><ref type="bibr" target="#b0">Abujabal et al., 2017)</ref>. These systems are effective but at the cost of heavy data annotation and pattern/grammar engineering. What's more, parsing systems are often constrained on a specific domain and broken down when executing logical queries on incomplete KBs. Our work follows the line of Embedding-based models <ref type="bibr" target="#b7">(Bordes et al., 2014b;</ref><ref type="bibr" target="#b10">Dong et al., 2015;</ref><ref type="bibr" target="#b28">Xu et al., 2016;</ref><ref type="bibr" target="#b13">Hao et al., 2017;</ref><ref type="bibr" target="#b29">Yavuz et al., 2017)</ref> which are recently introduced into the QA community where questions and KB entities are represented by distributed vectors, and QA is formulated as a problem of matching between vectors of questions and answer entities. These models need less grammars as well as annotated data, and are more flexible to deal with incomplete KBs. To make better matching, subgraphs of an entity in KB <ref type="bibr" target="#b6">(Bordes et al., 2014a)</ref>, answer aspects <ref type="bibr" target="#b10">(Dong et al., 2015;</ref><ref type="bibr" target="#b13">Hao et al., 2017)</ref> and external contexts <ref type="bibr" target="#b28">(Xu et al., 2016)</ref> can be used to enrich the representation of an answer entity. Though these methods are successful to handle simple questions, answering multi-relation questions or other complex questions is far from solved, since such a task requires reasoning or other elaborated processes.</p><p>Our work is also related to recent reasoning models which focus on Reading Comprehension where memory modules are designed to comprehend documents. State-of-the-art memory-based Reading Comprehension models <ref type="bibr" target="#b24">(Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b15">Kumar et al., 2015;</ref><ref type="bibr" target="#b22">Shen et al., 2016;</ref><ref type="bibr" target="#b26">Wang et al., 2017;</ref><ref type="bibr" target="#b9">Celikyilmaz et al., 2017)</ref> make interactions between a question and the corresponding document in a multi-hop manner during reasoning. MemNN <ref type="bibr" target="#b27">(Weston et al., 2015)</ref>, KVMemN2N <ref type="bibr" target="#b16">(Miller et al., 2016)</ref> and EviNet <ref type="bibr" target="#b21">(Savenkov and Agichtein, 2017)</ref> transferred the reading comprehension framework to QA where a set of triples is treated as a document and a similar reasoning process can be applied. However, reading comprehension makes reasoning over documents instead of parsing the questions.</p><p>Other studies applying hop-by-hop inference into QA can be seen in Neural Programmer <ref type="bibr" target="#b18">(Neelakantan et al., 2015;</ref><ref type="bibr" target="#b19">Neelakantan et al., 2016)</ref> and Neural Enquirer <ref type="bibr" target="#b32">(Yin et al., 2015)</ref>, where deep networks are proposed to parse a question and execute a query on tables. However, Neural Programmer needs to predefine symbolic operations, while Neural Enquirer lacks explicit interpretation. <ref type="bibr" target="#b17">Mou et al. (2017)</ref> proposed a model coupling distributed and symbolic execution with REINFORCE algorithm, however, training such a model is challenging. Neural Module Network <ref type="bibr" target="#b1">(Andreas et al., 2015;</ref><ref type="bibr" target="#b2">Andreas et al., 2016)</ref> customized network architectures for different patterns of reasoning, making the reasoning network interpretable. However, a dependency parser and the REINFORCE algorithm are required.</p><p>3 Interpretable Reasoning Network</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Definition</head><p>Our goal is to offer an interpretable reasoning network to answer multi-relation questions. Given a question q and its topic entity or subject e s which can be annotated by some NER tools, the task is to find an entity a in KB as the answer.</p><p>In this work, we consider two typical categories of multi-relation questions, a path question <ref type="bibr" target="#b12">(Guu et al., 2015)</ref> and a conjunctive question <ref type="bibr" target="#b34">(Zhang et al., 2016)</ref>, while the former is our major focus. A path question contains only one topic entity (subject e s ) and its answer (object a) can be found by walking down an answer path consisting of a few relations and the corresponding intermediate entities.</p><p>We define an answer path as a sequence of entities and relations in KB which starts from the subject and ends with the answer like e s r 1 − → e 1 r 2 − → ... rn − → a. Relations (r i ) are observable (in various natural language forms) in the question, however, the intermediate entities (e 1 • • • e H ) are not. For example, for question "How old is Obama's daughter?", the subject is Barack Obama and the answer path is</p><formula xml:id="formula_0">Barack Obama Children − −−−−− →Malia Obama Age −−→18.</formula><p>Note that since there are 1-to-many relations<ref type="foot" target="#foot_0">1</ref> , the range of the intermediate entities can be large, resulting in more than one answer path for a question. A conjunctive question is a question that contains more than one subject entity and the answer can be obtained by the intersection of results from multiple path queries. For instance, the question "Name a soccer player who plays at forward position at the club Borussia Dortmund." has a possible answer as the intersection of results from two path queries<ref type="foot" target="#foot_1">2</ref> F ORW ARD </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overview</head><p>The reasoning network has three modules: input module, reasoning module, and answer module. The input module encodes the question into a distributed representation and updates the representation hopby-hop according to the inference results of the reasoning module. The reasoning module initializes its state by the topic entity of a question and predicts a relation on which the model should focus at the current hop, conditioned on the present question and reasoning state. The predicted relation is utilized to update the state vector and the question representation hop-by-hop. The answer module predicts an entity conditioned on the state of the reasoning module.</p><p>The process can be illustrated by the example as shown in Figure <ref type="figure" target="#fig_2">1</ref>. For question "How old is Obama's daughter?", the subject entity Barack Obama is utilized to initialize the state vector. IRN predicts the first relation "Children" at the first hop. The "Children" relation is added to the state vector to encode the updated parsing result, and the corresponding natural language form of this relation in the question (here is "daughter") is subtracted from the question to avoid repeatedly analyzing the relation-relevant word "daughter". This procedure is repeated until the Terminal relation is predicted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Input Module</head><p>The input module encodes a question to a vector representation and updates the representation of the question at each hop of the reasoning process: the predicted relation will be subtracted from the current representation to compel the reasoning process to attend to other words that should be analyzed.</p><p>Formally, the question X = x 1 , x 2 , ..., x n can be initialized by the sum of the word embeddings and updated by subtracting the relation predicted by the reasoning module at the previous hop:</p><formula xml:id="formula_1">q 0 = n i=1 x i</formula><p>(1) where M rq is a matrix projecting the KB relation space to the natural language question space, q h−1 is the question representation at hop h − 1, and rh defined by Eq. 4 is the predicted relation at hop h. The intuition of such update is that the already analysed part of the question should not be parsed again.</p><formula xml:id="formula_2">q h = q h−1 − M rq rh (2) subject (es) question (q 0 ) gate (g 1 ) relation (r 1 ) state (s 0 ) Relation Memory (R) q 1 g 2 r 2 s 1 R q 2 s 2 R answer (a 1 )</formula><p>Representing a question as a bag of words might be too simple. However, this method works well in our setting. Future work would consider other sophisticated encoders such as CNN or LSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reasoning Module</head><p>The reasoning module aims to attend to a particular part of the question at each hop, predict an associated relation in knowledge base, and then update its state.</p><p>The reasoning module takes as input the previous state vector (s h−1 ) and the previous question vector (q h−1 ), and then predicts a relation (r h ) based on the analysis at the current hop. Once the predicted relation (r h ) is obtained, the relation will be used to update the next question representation (q h ) and the state of the reasoning module (s h ). In this manner, the reasoning network is traceable and interpretable.</p><p>The process can be formally described by the following equations<ref type="foot" target="#foot_2">3</ref> :</p><formula xml:id="formula_3">g h j = P (r h = r j |q h−1 , s h−1 ) = softmax((M rq r j ) T q h−1 + (M rs r j ) T s h−1 ) (3) rh = j g h j * r j (4) s h = s h−1 + M rs rh (5)</formula><p>where r j is the embedding of a relation in KB and all the relation embeddings are stored in a static memory R, and s h is the state of the reasoning module at hop h. g h j is the probability of selecting the j th relation in KB and M rs is the projection matrix mapping r from the relation space to the state space. M rq is the same projection matrix used in Eq. 2 to map r from the relation space to the question space.</p><p>We initialize the state vector with the topic entity (subject) s 0 = e s . IRN will learn to enrich the state representation hop by hop, for instance, at the first hop s 1 ≈ e s + r 1 , and at the second hop s 2 ≈ e s + r 1 + r 2 , intuitively. In this manner, the state vector encodes historical information.</p><p>In order to signify when the reasoning process should stop, we augment the relation set with the Terminal relation. Once the reasoning module predicts the Terminal relation, the reasoning process will stop, and the final answer will be the output when the last non-terminal relation is added to the state s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Answer Module</head><p>The answer module chooses the corresponding entity from KB at each hop (denoted as a h ). At the last hop, the selected entity is chosen as the final answer, while at the intermediate hops, the predictions of these entities can be inspected to help reasoning analysis and failure diagnosis.</p><p>More formally, an entity at each hop can be predicted as follows:</p><formula xml:id="formula_4">e h = M se s h (6) o h j = P (a h = e j |s h ) = softmax(e T j e h )<label>(7)</label></formula><p>M se is used to transfer from the state space (s h ) to the entity space (e h ) to bridge the representation gap between the two spaces. e j is the embedding vector of the j th entity in KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Loss Function</head><p>We adopt cross entropy to define the loss function. The first loss term is defined on the intermediate prediction of relations, while the second term on the prediction of entities.</p><p>The loss on one instance is defined as follows:</p><formula xml:id="formula_5">L = h C r (h) + λC a (h) (8) C r (h) = − nr j=1 [ĝ h j ln g h j ] , C a (h) = − ne i=1 [ô h i ln o h i ]</formula><p>where n r /n e is the number of relations/entities in KB respectively, ĝh is the gold distribution (one-hot) over relations at hop h, g h is the predicted distribution defined by Eq. 3, ô is the gold distribution over entities, which is also one-hot representation, and o is defined by Eq. 7. λ is a hyper parameter to balance the two terms. Note that the training data is in the form of (q, &lt; e s , r 1 , e 1 , ..., a &gt;), which indicates that the model can incorporate supervision not only from the final answer (referred to as IRN-weak), but also from the intermediate relations and entities along the answer path (referred to as IRN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Multitask Training for KB Representation</head><p>In order to incorporate more constraints from KB<ref type="foot" target="#foot_3">4</ref> , we learn the embeddings of entities and relations as well as the space transition matrix with a multitask training schema. For a given fact triple in KB, (e s , r, e o ), the representations of the entities and the relation apply the following constraint:</p><formula xml:id="formula_6">M se (e s + r) = e o (<label>9</label></formula><formula xml:id="formula_7">)</formula><p>where e s , r, e o are embeddings of the subject (or head) entity, relation, and the object (or tail) entity. This idea is inspired by TransE <ref type="bibr" target="#b5">(Bordes et al., 2013</ref>), but we adopt M se (see Eq. 6) as a transfer matrix to bridge the representation gap between the state space (here e s + r = s) and the entity space (here e o = e).</p><p>The parameters are updated with a multi-task training schema. We first learn the KB embeddings e/r and the transformation matrix M se to fit Eq. 9 with several epoches. This is the task of KB embedding training. Then, we update all the parameters of IRN under supervision from the QA task with one epoch, which is the task of QA training. We run the two tasks iteratively.</p><p>With the help of the auxiliary KB embedding training, IRN not only utilizes the additional information from KB to make better inferences, but also has an ability to deal with incomplete answer paths. For example, even if the connection between Barack Obama and Malia Obama is not present in KB, our model can still make correct prediction thanks to M se (e Barack Obama + r Children ) ≈ e M alia Obama .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Dealing with Conjunctive Questions</head><p>IRN is not limited to only path questions. For a conjunctive question that contains more than one topic entity, the answer can be found by executing multiple IRNs with the same parameters in parallel and then obtaining the intersection of individual results. (q, BD)</p><p>Figure <ref type="figure">2</ref>: An assembly of two IRNs to handle a conjunctive question with two subjects. Different IRNs take as input the same question but different subjects and output the distribution over the candidate answers. The final answer is selected after summing the two distributions.</p><p>This process is exemplified by Figure <ref type="figure">2</ref>. The input question "Name a soccer player who plays at forward position at the club Borussia Dortmund" has two subject entities, "FORWARD" and "Borussia Dortmund(BD)". One IRN (IRN 1) takes the original question and "FORWARD" as input, and then predicts possible objects for path query "FORWARD where the input is the same question but another subject entity "Borussia Dortmund(BD)". After summing the two output distributions, the answer "Marco Reus" is chosen with the largest probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data Preparation</head><p>We prepared two KBQA datasets to evaluate our Interpretable Reasoning Network: one is PathQuestion<ref type="foot" target="#foot_5">6</ref> , constructed by ourselves, and the other is WorldCup2014, adopted from <ref type="bibr" target="#b34">(Zhang et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">PathQuestion</head><p>We adopted two subsets of Freebase <ref type="bibr" target="#b4">(Bollacker et al., 2008)</ref> as Knowledge Bases to construct the PathQuestion (PQ) and the PathQuestion-Large (PQL) datasets. We extracted paths between two entities which span two hops (e s − → a, denoted by -3H) and then generated natural language questions with templates. To make the generated questions analogical to real-world questions, we included paraphrasing templates and synonyms for relations by searching the Internet and two real-world datasets, WebQuestions <ref type="bibr" target="#b3">(Berant et al., 2013)</ref> and WikiAnswers <ref type="bibr" target="#b11">(Fader et al., 2013)</ref>. In this way, the syntactic structure and surface wording of the generated questions have been greatly enriched.</p><p>PQL is more challenging than PQ in that PQL utilizes larger KB and provides less training instances. The statistics are shown in Table <ref type="table" target="#tab_1">1</ref> and more details are described in the Appendix 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">WorldCup2014</head><p>We also evaluated our model on the WorldCup2014 (WC2014) dataset constructed by <ref type="bibr" target="#b34">(Zhang et al., 2016)</ref>. The dataset contains single-relation questions (denoted by WC-1H), two-hop path questions (WC-2H), and conjunctive questions (WC-C). WC-M is the mixture of WC-1H and WC-2H. 5 Experiment and Evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation Details</head><p>ADAM optimizer <ref type="bibr" target="#b14">(Kingma and Ba, 2015)</ref> was used for parameter optimization. The dimension of all the embeddings (words in question, entities and relations in KB) was set as d x = d e = d r = 50. The hyper-parameter λ (see Eq. 8) is set to 1 . We partitioned the entire dataset into the train/valid/test subset with a proportion of 8 : 1 : 1 and set the batch size as 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance of Question Answering</head><p>In this section, we evaluated the performance of multi-relation question answering on PathQuestion and WorldCup2014 respectively. To further show that IRN is able to handle more challenging datasets, we evaluated the model with two configurations: Incomplete KB To simulate the real KBs which are often far from complete, we removed half of the triples (entities and relations are retained but the connections between entities were removed) from the KB of the PQ-2H dataset.</p><p>Unseen KB To simulate a real QA scenario where out-of-vocabulary(OOV) words is one of the major challenges, we removed questions whose answer path includes relation "Cause of Death", "Gender" or "Profession" from the PQ-2H training set. The models need to cope with questions related to these three OOV relations during the test.</p><p>Several baselines are included here: Embed <ref type="bibr" target="#b7">(Bordes et al., 2014b)</ref> deals with factoid QA over KB by matching a question with an answer in the embedding spaces. Subgraph <ref type="bibr" target="#b6">(Bordes et al., 2014a)</ref> improves the Embed model by enriching the representation of an answer entity with the entity's subgraph. Seq2Seq <ref type="bibr" target="#b25">(Sutskever et al., 2014)</ref> is a simplified seq2seq semantic parsing model, which adopts an LSTM to encode the input question sequence and another LSTM to decode the answer path. MemN2N <ref type="bibr" target="#b24">(Sukhbaatar et al., 2015)</ref> is an end-to-end memory network that can be used for reading comprehension and question answering. The memory units consist of the related triples in a local subgraph of the corresponding answer path, where the settings are the same as <ref type="bibr" target="#b8">(Bordes et al., 2015)</ref>. KVMemN2N <ref type="bibr" target="#b16">(Miller et al., 2016)</ref> improves the MemN2N for KBQA as it divides the memory into two parts: the key memory stores the head entity and relation while the value memory stores the tail entity. IRN-weak is our model that employs only supervision from the final answer entity rather than the complete answer path. This can be implemented by simply ignoring the loss from the intermediate hops except the final entity in Eq. 8.</p><p>The performance is measured by accuracy<ref type="foot" target="#foot_6">7</ref> : correct if a predicted entity is in the answer set of input question. Since there are many 1-to-many relations in Freebase and WC2014, a question may have several possible answer paths, resulting in multiple answers. For example, given the question "How old is Obama's daughter?", the original path can be "Barack Obama</p><formula xml:id="formula_8">Children −−−−−→ Malia Obama Age − − →18" or "Barack Obama Children −−−−−→Sasha Obama Age − − → 14"</formula><p>, thus the answer can be either "18" or "14". For this question, either answer is correct.</p><p>The results in Table 2 demonstrate that our system outperforms the baselines on single-relation questions (WC-1H), 2-hop-relation questions (PQ-2H/PQL-2H/WC-2H) as well as 3-hop-relation questions (PQ-3H/PQL-3H). Furthermore, assembled IRNs obtain strong performance when dealing with conjunctive questions in WC-C . Challenging PQ-2H are two more difficult configurations of PQ-2H. The models in the second block utilize the answer path information but those in the first block do not.</p><p>We have further observations as follows: • IRN-weak outperforms Embed and Subgraph, indicating that multi-hop reasoning indeed helps to answer complex questions even when our model is trained end-to-end in the same configuration of weak supervision<ref type="foot" target="#foot_7">8</ref> .</p><p>• The Seq2Seq baseline performs worse than IRN. Though they are both interpretable, IRN is more powerful when dealing with complicated KBs and questions.</p><p>• IRN is better than MemN2N and KVMemN2N on most of the datasets, and both models are much better than other baselines using the path information. Note that the memory in (KV)MemN2N consists of fact triples which are distilled from KB using answer path. In this sense, (KV)MemN2N indirectly employs strong supervision from answer path. In contrast, IRN has a better (or easier) mechanism to supervise the reasoning process thanks to its interpretable framework.</p><p>• The highest accuracy on PQL-2H/3H reveals that IRN performs better when faced with larger datasets. IRN deals with relations and entities separately, where the number of entities and relations is much less than that of triples. However, (KV)MemN2N has to handle much more triples in its memory.</p><p>• IRN is more robust than the baselines (↓ 3.7% vs. ↓ 2.3% ) when dealing with incomplete KB, which is probably because auxiliary KB embedding training facilitates the prediction of missing triples. While the baselines are more sensitive to the incomplete information stored in the memory units.</p><p>• Both IRN and the baselines degrade remarkably (0.9→0.5) in the unseen setting because wrong distributed representations are influential in embedding-based QA models. In addition, the size of the training set is much smaller than that of the original PQ-2H, which also leads to worse performance.</p><p>• IRN is more interpretable compared with (KV)MemN2N , attributed to the structure of IRN. The relation/entity predicted at each hop is a part of the answer path. The intermediate outputs offer the possibility to trace the complete reasoning process, diagnose failures, and manipulate answer prediction through intermediate interactions (see Section 5.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Interpretable Path Reasoning</head><p>In this section, we demonstrated how IRN is interpretable by both quantitative and qualitative analysis. For the quantitative analysis, we can measure how it performs during the reasoning process by investigating the prediction accuracy of intermediate relations and entities. In this task, we collected all the relations and entities with largest probabilities (see Eq. 3 and Eq. 7) at each hop {r 1 , a 1 , r 2 , .., a H } and compared these intermediate outputs with the ground truth {r 1 , e 1 , r 2 , .., a}. As for KVMemN2N, we also fetched an entity at each hop by an answer distribution, similar to that at the final hop.</p><p>According to the structure of IRN, the relation/entity predicted at each hop constitutes an answer path. Results<ref type="foot" target="#foot_8">9</ref> in Table <ref type="table" target="#tab_3">3</ref> indicate that IRN can predict intermediate entities more accurately than final answers, due to the cascading errors in the consecutive prediction.</p><p>Though KVMemN2N (KVM) predicts the exact answers well, it lacks interpretability. On the one hand, KVM can not predict relations to trace the answer path. On the other hand, the hops in KVM all aim at finding the answer entity rather than the intermediate entities along the answer path.</p><p>To illustrate how our model parses a question and predicts relations hop-by-hop, we studied the distributions over all the relations (g h , see Eq. 3) and chose an example from PathQuestion as shown in Figure <ref type="figure" target="#fig_5">3</ref>. It is clear that IRN is able to derive the relations in correct order. For question "What does john hays hammond's kid do for a living?", IRN first detects relation Children (the corresponding word/phrase in the question is kid) and then Profession (what does..do). When detecting the Terminal relation, IRN will stop the analysis process.  Our model can map relations in KB to words in question. We sampled some relations in KB and projected them to the question space by r q = M rq r (see Eq. 2). We then obtained words whose embeddings are most close to r q measured by cosine similarity cos(r q , x i ). The result in  The above analysis demonstrates that our model is interpretable. Specifically, IRN has merits at: •Providing a traceable reasoning path for question answering. With the aid of these intermediate entities and relations, we can obtain not only the final answer but also the complete path that infers the answer.</p><p>•Facilitating failure diagnosis.</p><p>For instance, IRN fails to answer the question "Where did the child of Joseph P Kennedy Sr die ?".</p><p>The true answer path should be "Joseph P Kennedy Sr However, the middle entity decided by IRN is "Rosemary Kennedy" who is also a child of "Joseph P Kennedy Sr", but her death is not included in KB.</p><p>•Allowing manual manipulation in answer prediction. We updated the state (Eq. 5) and the question (Eq. 2) in IRN with the ground-truth relation vectors and compared the performance. The higher accuracy in Table <ref type="table" target="#tab_7">5</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We present a novel Interpretable Reasoning Network which is able to make reasoning hop-by-hop and then answer multi-relation questions. Our model is interpretable in that the intermediate predictions of entities and relations are traceable and the complete reasoning path is observable. This property enables our model to facilitate reasoning analysis, failure diagnosis, and manual manipulation in answer prediction. Results on two QA datasets demonstrate the effectiveness of the model on multi-relation question answering. As future work, there is much room for complex question answering. For instance, answering "How old is Obama's younger daughter?" needs to handle arithmetic operation. Furthermore, multi-constraint questions will also be considered in this framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Pattern</head><p>Question-templates</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Universal</head><p>"What is the r2 of es's r1?" "What is the es's r1's r2?" "What is the r2 of r1 of es?" "The r2 of es's r1?" "The es's r1's r2?" "The r2 of r1 of es?" Ask about a person "Who is the r2 of es's r1?" "What is the name of the r2 of es's r1?" r2=r1=Parents/ "Who is the grand-r1 of es?" r2=r1=Children</p><p>"What is the name of the grand-r1 of es?" r2=Ethnicity "What r2 is es's r1" "What is es's r1's r2 like?" "What is es's r1's r2 about?" r2=Institution "Where does es's r1 work?" "Where does es's r1 work for?" "Which r2 does es's r1 work for?" r2=Nationality "Which nationality is es's r1?" "Where does es's r1 come from?"</p><p>r2=Religion "What r2 does es's r1 follow?" "What r2 is es's r1?" "What r2 does es's r1 have?" "What r2 is es's r1 practice?"</p><p>r2=Gender "What r2 is es's r1?" "Is es's r1 a man or a woman?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>r2=Location</head><p>"Where is es's r1 living?" "Where is es's r1 staying?" "Please tell me es's r1 present address."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>r2=Profession</head><p>"What does es's r1 do?" "What is es's r1 working on?" "What is es's r1?" "What line of business is es's r1 in?" "What does es's r1 do for a living?" r2=Cause of Death "Why es's r1 died?" "How es died?" "What's the reason of es's r1's death?" "What caused the death of es's r1?" "What killed the es's r1?" "What made the es's r1 dead?" "What did es's r1 die from?" r2=Place of Death "Where did es's r1 die?" "Where did the r1 of es die?" "What city did es's r1 die?" r2=Place of Birth "Where did es's r1 born?" "What city did es's r1 born?" "What is the hometown of es's r1?" "What is es's r1's birthplace?"</p><p>Table <ref type="table">7</ref>: Templates for generating natural language questions from answer paths in PQ-2H.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>plays position −1 − −−−−−−−−−− → M arco Reus and Borussia Dortmund plays in club −1 − −−−−−−−−− → M arco Reus. The details for dealing with conjunctive questions are shown in Fig 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>plays position − 1 −</head><label>1</label><figDesc>−−−−−−−−−− → ?(Marco Reus)". 5 The output is a distribution over entities. Similarly, another IRN (IRN 2) tackles the path query "BD plays in club −1 − −−−−−−−−− →?(Marco Reus)"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Ptolemy_xiii_Theos_Philopator 's couple 's daughter died ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The predicted relations at each hop. Each row represents a probability distribution over relations. Darker color indicates larger probability. The terminal relation is highlighted in red.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Children − −−−−− →Patricia kennedy Lawford P lace of Death − −−−−−−−−− →New York County".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The statistics of WorldCup2014 are listed in Table1. Statistics and exemplar questions of PathQuestion (PQ), PathQuestion-Large (PQL) and WorldCup2014 (WC).</figDesc><table><row><cell>Dataset</cell><cell cols="2">#Entity #Relation</cell><cell>#Question</cell><cell>Exemplar Question</cell></row><row><cell>PQ-2H / 3H</cell><cell>2,215</cell><cell>14</cell><cell>1,908 / 5,198</cell><cell>What does the son of princess Sophia's mom do for a living?</cell></row><row><cell>PQL-2H / 3H</cell><cell>5,035</cell><cell>364</cell><cell>1,594 / 1,031</cell><cell>What is the notable type of Jody Harris's profession?</cell></row><row><cell cols="2">WC-1H / 2H / M / C 1,127</cell><cell>6</cell><cell cols="2">6,482 / 1,472 / 7,954 / 2,208 Name a player who plays at Forward position from Mexico?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy on different QA datasets. WC-C is for conjunctive questions while other datasets for path questions.</figDesc><table><row><cell></cell><cell>PathQuestion</cell><cell cols="2">PathQuestion Large</cell><cell></cell><cell cols="2">WorldCup2014</cell><cell cols="2">Challenging PQ-2H</cell></row><row><cell></cell><cell cols="6">PQ-2H PQ-3H PQL-2H PQL-3H WC-1H WC-2H WC-M WC-C</cell><cell>Incomplete</cell><cell>Unseen</cell></row><row><cell>Random</cell><cell>0.151 0.104</cell><cell>0.021</cell><cell>0.015</cell><cell>0.085</cell><cell>0.064</cell><cell>0.053 0.073</cell><cell>-</cell><cell>-</cell></row><row><cell>Embed</cell><cell>0.787 0.483</cell><cell>0.425</cell><cell>0.225</cell><cell>0.448</cell><cell>0.588</cell><cell>0.518 0.642</cell><cell>-</cell><cell>-</cell></row><row><cell>Subgraph</cell><cell>0.744 0.506</cell><cell>0.500</cell><cell>0.213</cell><cell>0.448</cell><cell>0.507</cell><cell>0.513 0.692</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">IRN-weak(Ours) 0.919 0.833</cell><cell>0.630</cell><cell>0.618</cell><cell>0.749</cell><cell>0.921</cell><cell>0.786 0.837</cell><cell>-</cell><cell>-</cell></row><row><cell>Seq2Seq</cell><cell>0.899 0.770</cell><cell>0.719</cell><cell>0.647</cell><cell>0.537</cell><cell>0.548</cell><cell>0.538 0.577</cell><cell>-</cell><cell>-</cell></row><row><cell>MemN2N</cell><cell>0.930 0.845</cell><cell>0.690</cell><cell>0.617</cell><cell>0.854</cell><cell>0.915</cell><cell cols="3">0.907 0.733 0.899(↓ 3.3%) 0.558</cell></row><row><cell>KVMemN2N</cell><cell>0.937 0.879</cell><cell>0.722</cell><cell>0.674</cell><cell>0.870</cell><cell>0.928</cell><cell cols="3">0.905 0.788 0.902(↓ 3.7%) 0.554</cell></row><row><cell>IRN(Ours)</cell><cell>0.960 0.877</cell><cell>0.725</cell><cell>0.710</cell><cell>0.843</cell><cell>0.981</cell><cell cols="3">0.907 0.910 0.937(↓ 2.3%) 0.550</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Accuracy at different hops along the answer path from IRN and KVMemN2N (KVM). ri indicates the relation at hop i, ei indicates the entity at hop i. a indicates the final answer. NA means not applicable.</figDesc><table><row><cell></cell><cell>r1</cell><cell></cell><cell>e1</cell><cell></cell><cell>r2</cell><cell></cell><cell>e2</cell><cell></cell><cell>r3</cell><cell></cell><cell>a</cell></row><row><cell></cell><cell>IRN</cell><cell>KVM</cell><cell>IRN</cell><cell>KVM</cell><cell>IRN</cell><cell>KVM</cell><cell>IRN</cell><cell>KVM</cell><cell>IRN</cell><cell>KVM</cell><cell>IRN</cell><cell>KVM</cell></row><row><cell>PQ-2H</cell><cell>1.000</cell><cell>NA</cell><cell cols="3">0.957 0.016 1.000</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell cols="2">0.934 0.916</cell></row><row><cell cols="2">PQL-2H 0.968</cell><cell>NA</cell><cell cols="3">0.722 0.083 0.836</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell cols="2">0.673 0.676</cell></row><row><cell>WC-2H</cell><cell>1.000</cell><cell>NA</cell><cell cols="3">0.531 0.000 1.000</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell><cell cols="2">0.528 0.382</cell></row><row><cell>PQ-3H</cell><cell>1.000</cell><cell>NA</cell><cell cols="3">0.883 0.003 1.000</cell><cell>NA</cell><cell cols="3">0.772 0.001 1.000</cell><cell>NA</cell><cell cols="2">0.738 0.774</cell></row><row><cell cols="2">PQL-3H 0.808</cell><cell>NA</cell><cell cols="3">0.721 0.019 0.702</cell><cell>NA</cell><cell cols="3">0.721 0.007 0.683</cell><cell>NA</cell><cell cols="2">0.608 0.600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table 4 indicates that IRN can establish reasonable mapping between KB relation and natural language, such as linking Profession to words like working, profession, and occupation . Besides mapping to single words, relation in KB can be associated with some complicate templates, such as Profession → "what does ... do" .</figDesc><table><row><cell>Relation</cell><cell>Similar words in natural language questions</cell></row><row><cell>Profession</cell><cell>profession, do, working, occupation</cell></row><row><cell>Insititution</cell><cell>institution, organization, work, where</cell></row><row><cell>Religion</cell><cell>faith, religion, what, belief</cell></row><row><cell>Cause of Death</cell><cell>died, killed, how, death</cell></row><row><cell>Place of Birth</cell><cell>hometown, born, city, birthplace</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Most similar words in questions for some exemplar relations.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>implies that we can improve the final prediction by correcting intermediate predictions. (↑ 2.0%) 0.900 (↑ 2.3%) 0.755 (↑ 3.0%) 0.744 (↑ 3.4%)</figDesc><table><row><cell>Dataset</cell><cell>PQ-2H</cell><cell>PQ-3H</cell><cell>PQL-2H</cell><cell>PQL-3H</cell></row><row><cell>Acc</cell><cell>0.980</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Accuracy when the intermediate predictions are replaced by ground truth.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">For instance, relation Children is one-to-many, where a person may have more than one child.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Superscript -1 stands for the inverse relation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">a T b is the inner-product of vector a and b.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">Constraint from KB means that two entities and a relation form a triple in KB, as (es, r, eo).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">The question mark indicates the entity to be predicted and the entity in bracket is the expected answer.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">This dataset is available at https://github.com/zmtkeke/IRN</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">Reported accuracy is the average accuracy of five repeated runs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7">Only supervision from question-answer pairs, but without answer path information from KB.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8">Note here that only if an output matches the labeled entity exactly, the prediction will be judged as correct.Thus, the accuracy here has a different definition from that in Table2.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partly supported by the National Science Foundation of China under grant No.61272227/61332007 and the National Basic Research Program (973 Program) under grant No. 2013CB329403.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. PathQuestion Construction and Question Templates</head><p>We constructed a synthesis dataset by generating questions with templates. The knowledge base for PathQuestion has more than 60,000 triples which are adopted from FB13 <ref type="bibr" target="#b23">(Socher et al., 2013)</ref> with 13 relations and thousands of entities. As for PathQuestion-Large, we adopted another more complex subset of Freebase <ref type="bibr" target="#b4">(Bollacker et al., 2008)</ref>. First, we extracted all the paths with two hops (&lt; e s , r 1 , e 1 , r 2 , a &gt;), or three hops (&lt; e s , r 1 , e 1 , r 2 , e 2 , r 3 , a &gt;) among these triples. Second, we crafted templates to generate natural language questions from these paths. Last, we collected question and answer path pairs (q, &lt; e s , r 1 , e 1 , ..., a &gt;) to construct the PathQuestion (PQ) dataset.</p><p>We crafted templates to transfer an answer path extracted from KB to natural language questions. To make the generated questions analogical to real-world questions, those templates are firstly written manually, and then enriched by replacing synonyms. Besides, we searched for different syntactical structures and paraphrases in real-world datasets including WebQuestions <ref type="bibr" target="#b3">(Berant et al., 2013)</ref> and WikiAnswers <ref type="bibr" target="#b11">(Fader et al., 2013)</ref> as well as on the Internet. In this manner, the templates have been greatly diversified and are much closer to real questions.</p><p>Synonyms used in templates for PathQuestion are shown in Table <ref type="table">6</ref> and templates for 2-hop paths (PQ-2H) are shown in Table <ref type="table">7</ref>. The datasets are available at https://github.com/zmtkeke/IRN.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Quint: Interpretable question answering over knowledge bases</title>
		<author>
			<persName><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishiraj</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural module networks</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klein</forename><surname>Dan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to compose neural networks for question answering</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NAACL</title>
		<imprint>
			<biblScope unit="page" from="1545" to="1554" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD International Conference on Management of Data, SIGMOD 2008</title>
				<meeting><address><addrLine>Vancouver, Bc, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06">2008. June</date>
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference on Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2014">2014a</date>
			<biblScope unit="page" from="615" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Open question answering with weakly supervised embedding models</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML-PKDD</title>
				<meeting>ECML-PKDD</meeting>
		<imprint>
			<date type="published" when="2014">2014b</date>
			<biblScope unit="page" from="165" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>CoRR, abs/1506.02075</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Scaffolding networks for teaching and learning to comprehend</title>
		<author>
			<persName><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Question answering over freebase with multi-column convolutional neural networks</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1608" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Traversing knowledge graphs in vector space</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="318" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An end-toend model for question answering over knowledge base with cross-attention combining global knowledge</title>
		<author>
			<persName><forename type="first">Yanchao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="221" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<title level="m">Adam: A method for stochastic optimization. international conference on learning representations</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<title level="m">Ask me anything: Dynamic memory networks for natural language processing. International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coupling distributed and symbolic execution for natural language queries</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08">2017. August</date>
			<biblScope unit="page" from="2518" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Sutskever</surname></persName>
		</author>
		<title level="m">Neural programmer: Inducing latent programs with gradient descent. International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Neural programmer: Inducing latent programs with gradient descent</title>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>international conference on learning representations</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evinets: Neural networks for combining evidence signals for factoid question answering</title>
		<author>
			<persName><forename type="first">Denis</forename><surname>Savenkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="299" to="304" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reasonet: Learning to stop reading in machine comprehension</title>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD</title>
		<imprint>
			<biblScope unit="page" from="1047" to="1055" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Control &amp; Information Processing</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<title level="m">End-to-end memory networks. Annual Conference on Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference on Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="189" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<title level="m">Memory networks. International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Question answering on freebase via relation extraction and textual evidence</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2326" to="2336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recovering question answering errors via query revision</title>
		<author>
			<persName><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izzeddin</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="903" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semantic parsing for single-relation question answering</title>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics</title>
				<meeting>Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="643" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName><forename type="first">Wen</forename><surname>Tau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yih</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><forename type="middle">Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jina</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Neural enquirer: Learning to query tables with natural language</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Kao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="2308" to="2314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simple question answering by attentive convolutional neural network</title>
		<author>
			<persName><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schtze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1746" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Gaussian attention model and its application to knowledge base embedding and question answering</title>
		<author>
			<persName><forename type="first">Liwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<idno>CoRR, abs/1611.02266</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
