<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-09-19">19 Sep 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
							<email>jiaxit@sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University British Columbia</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
							<email>wangk@cs.sfu.ca</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University British Columbia</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-09-19">19 Sep 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3159652.3159656</idno>
					<idno type="arXiv">arXiv:1809.07426v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Recommender System</term>
					<term>Sequential Prediction</term>
					<term>Convolutional Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Top-N sequential recommendation models each user as a sequence of items interacted in the past and aims to predict top-N ranked items that a user will likely interact in a "near future". The order of interaction implies that sequential patterns play an important role where more recent items in a sequence have a larger impact on the next item. In this paper, we propose a Convolutional Sequence Embedding Recommendation Model (Caser) as a solution to address this requirement. The idea is to embed a sequence of recent items into an "image" in the time and latent spaces and learn sequential patterns as local features of the image using convolutional lters. This approach provides a uni ed and exible network structure for capturing both general preferences and sequential patterns. The experiments on public data sets demonstrated that Caser consistently outperforms state-of-the-art sequential recommendation methods on a variety of common evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Retrieval models and ranking;</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommender systems have become a core technology in many applications. Most systems, e.g., top-N recommendation <ref type="bibr" target="#b8">[9]</ref> <ref type="bibr" target="#b18">[19]</ref>, recommend the items based on the user's general preferences without paying attention to the recency of items.</p><p>For example, some user always prefer Apple's products to Samsung's products. General preferences represent user's long term and static behaviors. Another type of user behaviors is sequential patterns where the next item or action more likely depends on the items or actions the user engaged recently. Sequential patterns represent the user's short term and dynamic behaviors and come from a certain relationship between the items within a close proximity of time. For example, a user likely buys phone accessories soon after buying an iPhone, though in general the user does not buy phone accessories. In this case, the systems that consider only general preferences will miss the opportunity of recommending phone accessories after selling an iPhone since buying phone accessories is not a long term user behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Top-N Sequential Recommendation</head><p>To model user's sequential patterns, the work in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21]</ref> considers top-N sequential recommendation that recommends N items that a user likely interacts with in a near future. This problem assumes a set of users U = {u 1 , u 2 , • • • , u |U | } and a universe of items</p><formula xml:id="formula_0">I = {i 1 , i 2 , • • • , i |I | }.</formula><p>Each user u is associated with a sequence of some items from I, S u = (S u 1 , • • • , S u |S u | ), where S u i ∈ I. The index t for S u t denotes the order in which an action occurs in the sequence S u , not the absolute timestamp as in temporal recommendation like <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>. Given all users' sequences S u , the goal is to recommend each user a list of items that maximize her/his future needs, by considering both general preferences and sequential patterns. Unlike conventional top-N recommendation, top-N sequential recommendation models the user behavior as a sequence of items, instead of a set of items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Limitations of Previous Work</head><p>The Markov chain based model <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref> is an early approach to top-N sequential recommendation, where an L-order Markov chain makes recommendations based on L previous actions. The rstorder Markov chain is an item-to-item transition matrix learnt using maximum likelihood estimation. Factorized personalized Markov chains (FPMC) <ref type="bibr" target="#b20">[21]</ref> proposed by Rendle et al. and its variant <ref type="bibr" target="#b1">[2]</ref> improved this method by factorizing this transition matrix into two latent and low-rank sub-matrices. Factorized Sequential Prediction with Item Similarity ModeLs (Fossil) <ref type="bibr" target="#b5">[6]</ref> proposed by He et al. generalizes this method to high-order Markov chains using a weighted sum aggregation over previous items' latent representations. However, existing approaches su ered from two major limitations: Fail to model union-Level sequential patterns. As shown in Figure <ref type="figure" target="#fig_0">1a</ref>, the Markov chain models only point-level sequential patterns where each of the previous actions (blue) in uences the target action (yellow) individually, instead of collectively. FPMC and Fossil fall into this taxonomy. Although Fossil <ref type="bibr" target="#b5">[6]</ref> considers a high-order Markov chain, the overall in uence is a weighted sum of previous items' latent representations factorized from rstorder Markov transition matrices. Such aggregation of point-level in uences is not su cient to model the union-level in uences shown in Figure <ref type="figure" target="#fig_0">1b</ref> where several previous actions, in that order, jointly in uence the target action. For example, buying both milk and butter together leads to a higher probability of buying our than buying milk or butter individually; buying both RAM and Hard Drive is a better indication of buying Operating System next than buying only one of the components. Fail to allow skip behaviors. Existing models don't consider skip behaviors of sequential patterns as shown in Figure <ref type="figure" target="#fig_0">1c</ref>, where the impact from past behaviors may skip a few steps and still have strength. For example, a tourist has check-ins sequentially at airport, hotel, restaurant, bar, and attraction. While the check-ins at the airport and hotel do not immediately precede the check-in of the attraction, they are strongly associated with the latter. On the other hand, the check-in at the restaurant or bar has little in uence on the check-in of the attraction (because they do not necessarily occur). A L-order Markov chain does not explicitly model such skip behaviors because it assumes that the L previous steps have an in uence on the immediate next step.</p><p>To provide evidences of union-level in uences and skip behaviors, we mine sequential association rules <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> of the following form from two real life data sets, MovieLens and Gowalla (see the details of these data sets in Section 4)</p><formula xml:id="formula_1">(S u t −L , • • • , S u t −2 , S u t −1 ) → S u t .<label>(1)</label></formula><p>For a rule X → Y of the above form, the support count sup(XY ) is the number of sequences in which X and Y occur in order as in the rule, and the con dence, sup(X Y ) sup(X ) , is the percentage of the sequences in which Y follows X among those in which X occurs. This rule represents the joint in uence of all the items in X on Y . By changing the right hand side to S u t +1 or S u t +2 , the rule also captures the in uences with one or two step skips. Figure <ref type="figure" target="#fig_1">2</ref> summarizes the number of rules found versus the Markov order L and skip steps with the minimum support count = 5 and the minimum con dence = 50% (we also tried the minimum con dence of 10%, 20%, and 30%, these trends are similar). Most rules have the orders L = 2 and L = 3 and the con dence of rules gets higher for larger L. The gure also tells that a sizable number of rules have skip steps 1 or 2. These ndings support the existence of union-level in uences and skip behaviors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Contributions</head><p>To address these above limitations of existing works, we propose a ConvolutionAl Sequence Embedding Recommendation Model, or Caser for short, as a solution to top-N sequential recommendation. This model leverages the recent success of convolution lters of Convolutional Neural Network (CNN) to capture local features for image recognition <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref> and natural language processing <ref type="bibr" target="#b11">[12]</ref>.</p><p>The novelty of Caser is to represent the previous L items as an L × d matrix E, where d is the number of latent dimensions and the rows preserve the order of the items. Similar to <ref type="bibr" target="#b11">[12]</ref>, we regard this embedding matrix as the "image" of the L items in the latent space and search for sequential patterns as local features of this "image" using various convolutional lters. Unlike image recognition, however, this "image" is not given in the input and must be learnt simultaneously with all lters. Compared to existing methods, Caser o ers several distinct advantages. (1) Caser uses horizontal and vertical convolutional lters to capture sequential patterns at point-level, union-level, and of skip behaviors. (2) Caser models both users' general preferences and sequential patterns, and generalizes several existing state-of-theart methods in a single uni ed framework. (3) Caser outperforms state-of-the-art methods for top-N sequential recommendation on real life data sets. In the rest of the paper, we discuss further related work in Section 2, the Caser method in Section 3, and experimental studies in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FURTHER RELATED WORK</head><p>Conventional recommendation methods, e.g., collaborative ltering <ref type="bibr" target="#b23">[24]</ref>, matrix factorization <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref>, and top-N recommendation <ref type="bibr" target="#b8">[9]</ref> <ref type="bibr" target="#b18">[19]</ref>, are not suitable for capturing sequential patterns because they do not model the order of actions. Early works on sequential pattern mining <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> nd explicit sequential association rules based on statistical co-occurrences <ref type="bibr" target="#b16">[17]</ref>. This approach depends on  the explicit representation of patterns, thus, could miss patterns in unobserved states. Also, it su ers from a potentially large search space, sensitivity to threshold settings, and a large number of rules, most being redundant.</p><p>Restricted Bolzmann Machine (RBM) <ref type="bibr" target="#b22">[23]</ref> is the rst successful 2layers neural network that is applied to recommendation problems. Auto-encoder framework <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b28">29]</ref> and its variant denoising autoencoder <ref type="bibr" target="#b31">[32]</ref> also produce a good recommendation performance. Convolutional neural network (CNN) <ref type="bibr" target="#b35">[36]</ref> has been used to extract users' preferences from their reviews. None of these works is for sequential recommendation.</p><p>Recurrent neural networks (RNN) was used for session-based recommendation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>. While RNN has shown to have an impressive capability in modeling sequences <ref type="bibr" target="#b17">[18]</ref>, its sequentially connected network structure may not work well under sequential recommendation setting. Because in sequential recommendation problem, not all adjacent actions have dependency relationships (e.g. a user bought i 2 after i 1 only because she loves i 2 ). Our experimental results in Section 4 verify this point: RNN-based method performs better when data sets contains considerable sequential patterns. While our proposed method doesn't model sequential pattern as adjacent actions, it adopts convolutional lters from CNN and model sequential patterns as local features of the embeddings of previous items. This approach o ers the exibility of modeling sequential patterns at both point level and union level, and skip behaviors in a single uni ed framework. In fact, we will show that Caser generalizes several state-of-the-art methods.</p><p>A related but di erent problem is temporal recommendation <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>. For example, temporal recommendation recommends co ee in the morning, instead of evening, whereas our top-N sequential recommendation would recommend phone accessories soon after a user bought an iPhone, independently of the time. Clearly, the two problems are di erent and require di erent solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED METHODOLOGY</head><p>The proposed model, ConvolutionAl Sequence Embedding Recommendation (Caser), incorporates the Convolutional Neural Network (CNN) to learn sequential features, and Latent Factor Model (LFM) to learn user speci c features. The goal of Caser's network design is multi-fold: capture both user's general preferences and sequential patterns, at both union-level and point-level, and capture skip behaviors, all in unobserved spaces. Shown in Figure <ref type="figure" target="#fig_3">3</ref> Caser consists of three components: Embedding Look-up, Convolutional Layers, and Fully-connected Layers. To train the CNN, for each user u, we extract every L successive items as input and their next T items as the targets from the user's sequence S u , shown on the left side of Figure <ref type="figure" target="#fig_3">3</ref>. This is done by sliding a window of size L + T over the user's sequence, and each window generates a training instance for u, denoted by a triplet (u, previous L items, next T items).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Embedding Look-up</head><p>Caser captures sequence features in the latent space by feeding the embeddings of previous L items into the neural network. The embedding Q i ∈ R d for item i is a similar concept to its latent factors. Here d is the number of latent dimensions. The embedding look-up operation retrieves the previous L items' embeddings and stacks them together, resulting in a matrix E (u,t ) ∈ R L×d for user</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User Sequence Latent Space Horizontal Filters Predictions</head><p>Great Wall Bar ! (#,%) u at time step t:</p><formula xml:id="formula_2">E (u,t ) =          Q S u t −L . . . Q S u t −2 Q S u t −1          . (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>Along with the item embeddings, we also have an embedding P u ∈ R d for a user u, representing user features in latent space. These embeddings are represented by blue and purple circles in the box of Embedding Look-up in Figure <ref type="figure" target="#fig_3">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Convolutional Layers</head><p>Our approach leverages the recent success of convolution lters of CNN in capturing local features for image recognition <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref> and natural language processing <ref type="bibr" target="#b11">[12]</ref>. Borrows the idea of using CNN in text classi cation <ref type="bibr" target="#b11">[12]</ref>, our approach regards the L × d matrix E as the "image" of the previous L items in the latent space and regard sequential patterns as local features of this "image". This approach enables the use of convolution lters to search for sequential patterns. Figure <ref type="figure" target="#fig_4">4</ref> shows two "horizontal lters" that capture two union-level sequential patterns. These lters, represented as h × d matrices, have the height h = 2 and the full width equal to d. They pick up signals for sequential patterns by sliding over the rows of E. For example, the rst lter picks up the sequential pattern "(Airport, Hotel) → Great Wall" by having larger values in the latent dimensions where Airport and Hotel have larger values. Similarly, a "vertical lter" is a L × 1 matrix and will slide over the columns of E. More details are explained below. Unlike image recognition, the "image" E is not given because the embedding Q i for all items i must be learnt simultaneously with all lters. Horizontal Convolutional Layer. This layer, shown in the upper part of the second component in Figure <ref type="figure" target="#fig_3">3</ref>, has n horizontal lters</p><formula xml:id="formula_4">F k ∈ R h×d , 1 ≤ k ≤ n. h ∈ {1, • • • , L}</formula><p>is the height of a lter. For example, if L = 4, one may choose to have n = 8 lters, two for each h in {1, 2, 3, 4}. F k will slide from top to bottom on E and interact with all horizontal dimensions of E of the items i,</p><formula xml:id="formula_5">1 ≤ i ≤ L − h + 1.</formula><p>The result of the interaction is the i-th convolution value given by</p><formula xml:id="formula_6">c k i = ϕ c (E i:i+h−1 F k ).<label>(3)</label></formula><p>where the symbol denotes the inner product operator and ϕ c (•) is the activation function for convolutional layers. This value is the inner product between F k and the sub-matrix formed by the row i to row i − h + 1 of E, denoted by E i:i+h−1 . The nal convolution result of F k is the vector</p><formula xml:id="formula_7">c k = c k 1 c k 2 • • • c k L−h+1 .<label>(4)</label></formula><p>We then apply a max pooling operation to c k to extract the maximum value from all values produced by this particular lter. The maximum value captures the most signi cant feature extracted by the lter. Therefore, for the n lters in this layer, the output value</p><formula xml:id="formula_8">o ∈ R n is o = {max(c 1 ), max(c 2 ), • • • , max(c n )}. (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>Horizontal lters interact with every successive h items through their embeddings E. Both the embeddings and the lters are learnt to minimize an objective function that encodes the prediction error of target items (more in Section 3.4). By sliding lters of various heights, a signi cant signal will be picked up regardless of location. Therefore, horizontal lters can be trained to capture union-level patterns with multiple union sizes. Vertical Convolutional Layer. This layer is shown in the lower part of the second component in Figure <ref type="figure" target="#fig_3">3</ref>. We use tilde (∼) for the symbols of this layer. Suppose that there are ñ vertical lters</p><formula xml:id="formula_10">F k ∈ R L×1 , 1 ≤ k ≤ ñ.</formula><p>Each lter F k interacts with the columns of E by sliding d times from left to right on E, yielding the vertical convolution result ck :</p><formula xml:id="formula_11">ck = ck 1 ck 2 • • • ck d .<label>(6)</label></formula><p>For the inner product interaction, it is easy to verify that this result is equal to the weighted sum over the L rows of E with F k as the weights:</p><formula xml:id="formula_12">ck = L l =1 F k l • E l ,<label>(7)</label></formula><p>where E l is the l-th row of E. Therefore, with vertical lters we can learn to aggregate the embeddings of the L previous items, similar to Fossil's <ref type="bibr" target="#b5">[6]</ref> weighted sum to aggregate the L previous items' latent representations. The di erence is that each lter F k is acting like a di erent aggregator. Thus, similar to Fossil, these vertical lters are capturing point-level sequential patterns through weighted sums over previous items' latent representations. While Fossil uses a single weighted sum for each user, we can use ñ global vertical lters to produce ñ weighted sums õ ∈ R d ñ for all users:</p><formula xml:id="formula_13">õ = c1 c2 • • • c ñ .<label>(8)</label></formula><p>Since their usage is aggregation, vertical lters have some di erences from horizontal ones: (1) The size of each vertical lter is xed to be L × 1. This is because each column of E is latent for us, it is meaningless to interact with multiple successive columns at one time. <ref type="bibr" target="#b1">(2)</ref> There is no need to apply max pooling operation over the vertical convolution results, as we want to keep the aggregation for every latent dimension. Thus, the output of this layer is õ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Fully-connected Layers</head><p>We concatenate the outputs of the two convolutional layers and feed them into a fully-connected neural network layer to get more high-level and abstract features:</p><formula xml:id="formula_14">z = ϕ a (W o õ + b),<label>(9)</label></formula><p>where W ∈ R d ×(n+d ñ) is the weight matrix that projects the concatenation layer to a d-dimensional hidden layer, b ∈ R d is the corresponding bias term and ϕ a (•) is the activation function for fully-connected layer. z ∈ R d is what we called convolutional sequence embedding, which encodes all kinds of sequential features of the L previous items.</p><p>To capture user's general preferences, we also look-up the user embedding P u and concatenate the two d-dimensional vectors, z and P u , together and project them to an output layer with |I| nodes, written as</p><formula xml:id="formula_15">(u,t ) = W z P u + b ,<label>(10)</label></formula><p>where b ∈ R | I | and W ∈ R | I |×2d are the bias term and weight matrix for output layer, respectively. As explained in Section 3.4, the value</p><formula xml:id="formula_16">(u,t ) i</formula><p>in the output layer is associated with the probability of how likely user u will interact with item i at time step t. z intends to capture short term sequential patterns, whereas the user embedding P u captures user's long-term general preferences. Here we put the user embedding Pu in the last hidden layer for several reasons: (1) As we shall see in Section 3.6, it can have the ability to generalize other models. ( <ref type="formula" target="#formula_2">2</ref>) we can pre-train our model's parameters with other generalized models' parameters. As stated in <ref type="bibr" target="#b6">[7]</ref>, such pretraining is critical to model performance</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Network Training</head><p>To train the network, we transform the values of the output layer, (u,t ) , to probabilities by:</p><formula xml:id="formula_17">p(S u t | S u t −1 , S u t −2 , • • • , S u t −L ) = σ ( (u,t ) S u t ),<label>(11)</label></formula><p>where σ (x) = 1/(1 + e −x ) is the sigmoid function. Let C u = {L + 1, L + 2, ..., |S u |} be the collection of time steps for which we would like to make predictions for user u. The likelihood of all sequences in the dataset is:</p><formula xml:id="formula_18">p(S|Θ) = u t ∈ C u σ ( (u,t ) S u t ) j S u t (1 − σ ( (u,t ) j )).<label>(12)</label></formula><p>To further capture skip behaviors, we could consider the next T target items, D u t = {S u t , S u t +1 , ..., S u t +T }, at once by replacing the immediate next item S u t in the above equation with D u t . Taking the negative logarithm of likelihood, we get the objective function, also known as binary cross-entropy loss:</p><formula xml:id="formula_19">= u t ∈ C u i ∈ D u t −log(σ ( (u,t ) i )) + j i −log(1 − σ ( (u,t ) j</formula><p>)). <ref type="bibr" target="#b12">(13)</ref> Following previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b31">32]</ref>, for each target item i, we randomly sample several (3 in our experiments) negative instances j in the second term.</p><p>The model parameters Θ = {P, Q, F , F ,W ,W , b, b } are learned by minimizing the objective function in Eqn (13) on the training set, whereas the hyperparameters (e.g., d, n, ñ, L,T ) are tuned on the validation set via grid search. We adopt an variant of Stochastic Gradient Descent (SGD) called Adaptive Moment Estimation (Adam) <ref type="bibr" target="#b12">[13]</ref> for faster convergence, with a batch size of 100. To control model complexity and avoid over-tting, we use two kinds of regularization methods: the L2 Norm is applied for all model parameters and Dropout <ref type="bibr" target="#b26">[27]</ref> technique with 50% drop ratio is used on fully-connected layers. We implemented Caser with MatCon-vNet <ref type="bibr" target="#b27">[28]</ref>. The whole training time is proportional to the number of training instances. For example, it took around 1 hour for Movie-Lens data and 2 hours for Gowalla data, 2 hours for Foursquare and 1 hour for Tmall on a 4-cores i7 CPU and 32GB RAM machine. These times are comparable to Fossil's <ref type="bibr" target="#b5">[6]</ref> running time and can be further reduced by using GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Recommendation</head><p>After obtaining the trained neural network, to make recommendations for a user u at time step t, we take u's latent embedding P u and extract his last L items' embeddings given by Eqn (2) as the neural network input. We recommend the N items that have the highest values in the output layer . The complexity for making recommendations to all users is O(|U||I|d), where the complexity of convolution operations is ignored. Note that the number of target items T is a hyperparameter used during the model training, whereas N is the number of items recommended after the model is trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Connection to Existing Models</head><p>We show that Caser is a generalization of several previous models.</p><p>Caser vs. MF. By discarding all convolutional layers and all bias terms, our model becomes a vanilla LFM with user embeddings as user latent factors and its associated weights as item latent factors. MF usually contains bias terms <ref type="foot" target="#foot_0">1</ref> , which is b in our model. After discarding all convolutional layers, the resulting model is the same as MF:</p><formula xml:id="formula_20">u i = W i 0 P u + b i . (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>Caser vs. FPMC. FPMC fuses factorized rst-order Markov chain with LFM and is optimized by Bayesian personalized ranking (BPR). Although Caser uses a di erent optimization criterion, i.e., the crossentropy, it is able to generalize FPMC by copying the previous item's embedding to the hidden layer z and not using any bias terms:</p><formula xml:id="formula_22">(u,t ) i = W i Q S u t −1 P u . (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>As FPMC uses BPR as the criterion, our model is not exactly the same as FPMC. However, BPR is limited to have only 1 target and negative sample at each time step. Our cross-entropy loss does not have these limitations. Caser vs. Fossil. By omitting the horizontal convolutional layer and using one vertical lter and copying the vertical convolution result c to the hidden layer z, we get</p><formula xml:id="formula_24">(u,t ) i = W i c P u + b i . (<label>16</label></formula><formula xml:id="formula_25">)</formula><p>As discussed for Eqn <ref type="bibr" target="#b6">(7)</ref>, this vertical lter serves as the weighted sum of the embeddings of the L previous items, like in Fossil, though Fossil uses Similarity Model instead of LFM and factorizes it in the same latent space as Markov model. Another di erence is that Fossil uses one local weighting for each user while we use a number of global weighting through vertical lters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We compare Caser with state-of-the-art methods. The source code of Caser and processed data sets are available online<ref type="foot" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Datasets. Sequential recommendation makes sense only when the data set contains sequential patterns. To identify such data sets, we applied sequential association rule mining to several public data sets and computed their sequential intensity de ned by:</p><formula xml:id="formula_26">Sequential Intensity (SI ) = #rules #users . (<label>17</label></formula><formula xml:id="formula_27">)</formula><p>The numerator is the total number of rules in the form of Eqn (1) found using a minimum threshold on support (i.e., 5) and condence(i.e., 50%) with Markov order L range from 1 to 5. The denominator is the total number of users. We use SI to estimate the intensity of sequential signals in a data set.</p><p>The four data sets with their SI are described in Table <ref type="table" target="#tab_0">1</ref>. Movie-Lens<ref type="foot" target="#foot_2">3</ref> is the widely used movie rating data. Gowalla<ref type="foot" target="#foot_3">4</ref> constructed by <ref type="bibr" target="#b2">[3]</ref> and Foursquare obtained from <ref type="bibr" target="#b32">[33]</ref> contain implicit feedback through user-venue check-ins. Tmall, the largest B2C platform in China, is a user-purchase data obtained from IJCAI 2015 competition <ref type="foot" target="#foot_4">5</ref> , which aims to forecast repeated buyers. Following previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b31">32]</ref>, we converted all numeric ratings to implicit feedback of 1. We also removed cold-start users and items of having less than n feedbacks, as dealing with cold-start recommendation is usually treated as a separate issue in the literature <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b31">32]</ref>. n is 5,15,10,10 for MovieLens, Gowalla, Foursquare, and Tmall. The Amazon data previously used in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> was not used due to its SI (0.0026 for 'O ce Products' category, 0.0019 for 'Clothing, Shoes, Jewelry' and 'Video Games' category), in other words, its sequential signals are much weaker than the above data sets.</p><p>Following <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>, we hold the rst 70% of actions in each user's sequence as the training set and use the next 10% of actions as the validation set to search the optimal hyperparameter settings for all models. The remaining 20% actions in each user's sequence are used as the test set for evaluating a model's performance. Evaluation Metrics. As in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32]</ref>, we evaluate a model by Precision@N , Recall@N , and Mean Average Precision (MAP). Given a list of top N predicted items for a user, denoted R1:N , and the last 20% of actions in her/his sequence (i.e., denoted R (i.e., the test set), Precision@N and Recall@N are computed by</p><formula xml:id="formula_28">Prec@N = |R R1:N | N , Recall@N = |R R1:N | |R| . (<label>18</label></formula><formula xml:id="formula_29">)</formula><p>We report the average of these values of all users. N ∈ {1, 5, 10}. The Average Precision (AP) is de ned by</p><formula xml:id="formula_30">AP = | R | N =1 Prec@N × rel(N ) | R| ,<label>(19)</label></formula><p>where rel(N ) = 1 if the N -th item in R is in R. The Mean Average Precision (MAP) is the average of AP for all users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Comparison</head><p>We compare our method, Caser, proposed in Section 3 with the following baselines.</p><p>• POP. All items are ranked by their popularity in all users' sequences, and the popularity is determined by the number of interactions. • BPR. Combined with Matrix Factorization model, Bayesian personalized ranking <ref type="bibr" target="#b19">[20]</ref> is the state-of-the-art method for non-sequential item recommendation on implicit feedback data. • FMC and FPMC. As introduced in <ref type="bibr" target="#b20">[21]</ref>, FMC factorizes the rst-order Markov transition matrix into two lowdimensional sub-matrices, and FPMC is a fusion of FMC and LFM. These are the state-of-the-art sequential recommendation methods. FPMC allows a basket of several items at each step. For our sequential recommendation problem, each basket has a single item. • Fossil. Fossil <ref type="bibr" target="#b5">[6]</ref> models high-order Markov chains and uses Similarity Model instead of LFM for modeling general user preferences. • GRU4Rec. This is the session-based recommendation proposed by <ref type="bibr" target="#b7">[8]</ref>. This model uses RNN to capture sequential dependencies and make predictions.</p><p>For each method, the grid search is applied to nd the optimal settings of hyperparameters using the validation set. These include latent dimensions d from {5, 10, 20, 30, 50, 100}, regularization hyperparameters, and the learning rate from {1, 10 −1 , ..., 10 −4 }. For Fossil, Caser and GRU4Rec, the Markov order L is from {1, • • • , 9}. For Caser itself, the height h of horizontal lters is from {1, • • • , L}, the target number T is from {1, 2, 3}, the activation functions ϕ a and ϕ c are from {identit , si moid, tanh, relu}. For each height h, the number of horizontal lters is from {4, 8, 16, 32, 64}. The number of vertical lters is from {1, 2, 4, 8, 16}. We report the result of each method under its optimal hyperparameter settings.</p><p>The best results of the six baselines and Caser are summarized in Table <ref type="table" target="#tab_1">2</ref>. The best performer on each row is highlighted in bold face. The last column is the improvement of Caser relative to the best baseline, de ned as Caser −baseline baseline . Except for MovieLens, Caser improved the best baseline on all N tested by a large margin w.r.t. the three metrics. Among the baseline methods, the sequential recommenders (e.g., FPMC and Fossil) usually outperform nonsequential recommenders (i.e., BPR) on all data sets, suggesting the importance of considering sequential information. FPMC and Fossil outperform FMC on all data sets, suggesting the e ectiveness of personalization. On MovieLens, GRU4Rec achieved a performance close to Caser's, but got a much worse performance on the other three data sets. In fact, MovieLens has more sequential signals than  the other three data sets, thus, the RNN-based GRU4Rec could perform well on MovieLens but can easily get biased on training sets of the other three data sets despite the use of regularization and dropout as described in <ref type="bibr" target="#b7">[8]</ref>. In addition, GRU4Rec's recommendation is session-based, instead of personalized, which enlarge the generalization error to some extent.</p><p>In the following studies, we examine the impact of the hyperparameters d, L,T one at a time by holding the remaining hyperparameters at their optimal settings. We focus on MAP as it is an overall performance indicator and consistent with other metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.1</head><p>Influence of Latent Dimensionality d. Figure <ref type="figure" target="#fig_5">5</ref> shows MAP for various d while keeping the other optimal hyperparameters unchanged. On the denser MovieLens, a larger d does not always lead to a better model performance. A model achieves its best performance when d is chosen properly and gets worse for a larger d because of over-tting. But for the other three sparser data sets, each model requires more latent dimensions to achieve their best results. For all data sets, Caser beats the strongest baseline performance by using a relatively small number of latent dimensions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Influence of Markov</head><p>Order L and Target Number T . We vary L to explore how much of Fossil, GRU4Rec and Caser can gain from high-order information while keeping other optimal hyperparameters unchanged. Caser-1, Caser-2, and Caser-3 denote Caser with the target number T at 1, 2, 3 to study the e ect of skip behaviors. The results are shown in Figure <ref type="figure" target="#fig_6">6</ref>. On the dense MovieLens, Caser best utilizes the extra information provided by a larger L and Caser-3 performs the best, suggesting the bene ts of skip steps. However, for the sparser data sets, all models do not consistently bene t from a larger L. This is reasonable, because for a sparse data set, a higher order Markov chain tends to introduce both extra information and more noises. In most cases, Caser-2 slightly outperforms the other models on these three data sets. Finally, we evaluate the contribution of each of Caser's components, the horizontal convolutional layer (i.e., o), the vertical convolutional layer (i.e., õ), and personalization (i.e., P u ), to the overall performance while keeping all hyperparameters at their optimal settings. The result is shown in Table <ref type="table" target="#tab_2">3</ref> for MovieLens and Gowalla; the results of the other two data sets are similar. For x ∈ {p, h, , h, ph, p , p h}, Caser-x denotes Caser with the components x enabled. h denotes horizontal convolutional layer; v denotes vertical convolutional layer; p denotes personalization, which is similar to BPR and uses LFM only. Any missing component is represented by setting its corresponding o, õ, and P u to zero. For example, vh denotes both vertical convolutional layer and horizontal convolutional layer by setting P u to all zeros, and pv denotes vertical convolutional layer and personalization by setting o to all zeros. Caser-p performs the worst whereas Caserh, Caser-v, and Caser-vh improve the performance signi cantly, suggesting that treating top-N sequential recommendation as the conventional top-N recommendation will lose useful information, and that modeling both sequential patterns at the union-level and point-level is useful for improving the prediction. For both data  sets, the best performance is achieved by jointly using all parts of Caser, i.e., Caser-pvh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Network Visualization</head><p>We have a closer look at some trained networks and prediction. Figure <ref type="figure" target="#fig_8">7</ref> shows the values of four vertical convolutional lters after training Caser on MovieLens with L = 9. In the micro perspective, the four are to be diverse, but in the macro perspective, they follow an ascending trend from past positions to recent positions. With each vertical lter serving as a way of weighting the embeddings of previous actions (see the related discussion in Section 3), this trend indicates that Caser puts more emphasis on recent actions, demonstrating a major di erence from the conventional top-N recommendation.</p><p>To see the e ectiveness of horizontal lters, Figure <ref type="figure" target="#fig_9">8</ref>(a) shows top N = 3 ranked movies recommended by Caser, i.e., R1 (Mad Max), R2 (Star War), R3 (Star Trek) in that order, for a user with L = 5 previous movies, i.e., S 1 (13th Warrior), S 2 (American Beauty), S 3 (Star Trek), S 4 (Star Trek III), and S 5 (Star Trek IV). R3 is the ground truth (i.e., the next movie in the user sequence). Note that R1 and R2 are quite similar to R3 , i.e., all being action and science ction movies, so are also recommended to the user. Figure <ref type="figure" target="#fig_9">8(b)</ref> shows the new rank of R3 after masking some of the L previous movies by setting their item embeddings to zeros in the trained network. Masking S 1 and S 2 actually increases the rank of R3 to 2 (from 3); in fact, S 1 and S 2 are history or romance movies and act like noises for recommending R3 . Masking each of S 3 , S 4 and S 5 decreases the rank of R3 because these movies are in the same category as R3 . The most decrease occurs after masking S 3 , S 4 and S 5 all together. This study clearly indicates that our model correctly captures the dependence of R3 on the related {S 3 , S 4 , S 5 } as a union-level sequential feature for recommending R3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Caser is a novel solution to top-N sequential recommendation by modeling recent actions as an "image" among time and latent dimensions and learning sequential patterns using convolutional lters. This approach provides a uni ed and exible network structure for capturing many important features of sequential recommendation, i.e., point-level and union-level sequential patterns, skip behaviors, and long term user preferences. Our experiments and case studies on public real life data sets suggested that Caser outperforms the state-of-the-art methods for top-N sequential recommendation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of point and union level dynamic pattern in uences, the order of Markov chain L = 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The number of association rules vs L and skip steps. The minimum support count = 5 and the minimum condence = 50%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The network architecture of Caser. The rectangular boxes represent items S u 1 , • • • , S u |S u | in user sequence, whereas a rectangular box with circles inside stands for a certain vector e.g., user embedding P u . The dash rectangular boxes are convolutional lters with di erent sizes. The red circles in convolutional layers stand for the max values in each of the convolution results. Here we are using previous 4 actions (L = 4) to predict which items this user will interact with in next 2 steps (T = 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>'Figure 4 :</head><label>4</label><figDesc>Figure 4: Darker colors mean larger values. The rst lter captures "(Airport, Hotel) → Great Wall" by interacting with the embedding of airport and hotel and skipping that of fast food and restaurant. The second lter captures "(Fast Food, Restaurant) → Bar".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: MAP (y-axis) vs. the number of latent dimensions d (x-axis).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: MAP (y-axis) vs. the Markov order L (x-axis). Caser-1, Caser-2, and Caser-3 denote Caser with the number of targets T set to 1, 2, 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Visualization for four vertical convolutional lters of a trained model on MovieLens data when L = 9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Horizontal convolutional lters's e ectiveness of capturing union-level sequential patterns on MovieLens data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets</figDesc><table><row><cell>Datasets</cell><cell>Sequential Intensity</cell><cell>#users</cell><cell>#items</cell><cell>avg. actions per user</cell><cell>Sparsity</cell></row><row><cell>MovieLens</cell><cell>0.3265</cell><cell>6.0k</cell><cell>3.4k</cell><cell>165.50</cell><cell>95.16%</cell></row><row><cell>Gowalla</cell><cell>0.0748</cell><cell>13.1k</cell><cell>14.0k</cell><cell>40.74</cell><cell>99.71%</cell></row><row><cell>Foursquare</cell><cell>0.0378</cell><cell>10.1k</cell><cell>23.4k</cell><cell>30.16</cell><cell>99.87%</cell></row><row><cell>Tmall</cell><cell>0.0104</cell><cell>23.8k</cell><cell>12.2k</cell><cell>13.93</cell><cell>99.89%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison on the four data sets.</figDesc><table><row><cell>Dataset</cell><cell>Metric</cell><cell>POP</cell><cell>BPR</cell><cell>FMC</cell><cell>FPMC</cell><cell>Fossil</cell><cell>GRU4Rec</cell><cell>Caser</cell><cell>Improv.</cell></row><row><cell></cell><cell>Prec@1</cell><cell>0.1280</cell><cell>0.1478</cell><cell>0.1748</cell><cell>0.2022</cell><cell>0.2306</cell><cell>0.2515</cell><cell>0.2502</cell><cell>-0.5%</cell></row><row><cell></cell><cell>Prec@5</cell><cell>0.1113</cell><cell>0.1288</cell><cell>0.1505</cell><cell>0.1659</cell><cell>0.2000</cell><cell>0.2146</cell><cell>0.2175</cell><cell>1.4%</cell></row><row><cell>MovieLens</cell><cell>Prec@10 Recall@1</cell><cell>0.1011 0.0050</cell><cell>0.1193 0.0070</cell><cell>0.1317 0.0104</cell><cell>0.1460 0.0118</cell><cell>0.1806 0.0144</cell><cell>0.1916 0.0153</cell><cell>0.1991 0.0148</cell><cell>4.0% -3.3%</cell></row><row><cell></cell><cell>Recall@5</cell><cell>0.0213</cell><cell>0.0312</cell><cell>0.0432</cell><cell>0.0468</cell><cell>0.0602</cell><cell>0.0629</cell><cell>0.0632</cell><cell>0.5%</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0375</cell><cell>0.0560</cell><cell>0.0722</cell><cell>0.0777</cell><cell>0.1061</cell><cell>0.1093</cell><cell>0.1121</cell><cell>2.6%</cell></row><row><cell></cell><cell>MAP</cell><cell>0.0687</cell><cell>0.0913</cell><cell>0.0949</cell><cell>0.1053</cell><cell>0.1354</cell><cell>0.1440</cell><cell>0.1507</cell><cell>4.7%</cell></row><row><cell></cell><cell>Prec@1</cell><cell>0.0517</cell><cell>0.1640</cell><cell>0.1532</cell><cell>0.1555</cell><cell>0.1736</cell><cell>0.1050</cell><cell>0.1961</cell><cell>13.0%</cell></row><row><cell></cell><cell>Prec@5</cell><cell>0.0362</cell><cell>0.0983</cell><cell>0.0876</cell><cell>0.0936</cell><cell>0.1045</cell><cell>0.0721</cell><cell>0.1129</cell><cell>8.0%</cell></row><row><cell>Gowalla</cell><cell>Prec@10 Recall@1</cell><cell>0.0281 0.0064</cell><cell>0.0726 0.0250</cell><cell>0.0657 0.0234</cell><cell>0.0698 0.0256</cell><cell>0.0782 0.0277</cell><cell>0.0571 0.0155</cell><cell>0.0833 0.0310</cell><cell>6.5% 11.9%</cell></row><row><cell></cell><cell>Recall@5</cell><cell>0.0257</cell><cell>0.0743</cell><cell>0.0648</cell><cell>0.0722</cell><cell>0.0793</cell><cell>0.0529</cell><cell>0.0845</cell><cell>6.6%</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0402</cell><cell>0.1077</cell><cell>0.0950</cell><cell>0.1059</cell><cell>0.1166</cell><cell>0.0826</cell><cell>0.1223</cell><cell>4.9%</cell></row><row><cell></cell><cell>MAP</cell><cell>0.0229</cell><cell>0.0767</cell><cell>0.0711</cell><cell>0.0764</cell><cell>0.0848</cell><cell>0.0580</cell><cell>0.0928</cell><cell>9.4%</cell></row><row><cell></cell><cell>Prec@1</cell><cell>0.1090</cell><cell>0.1233</cell><cell>0.0875</cell><cell>0.1081</cell><cell>0.1191</cell><cell>0.1018</cell><cell>0.1351</cell><cell>13.4%</cell></row><row><cell></cell><cell>Prec@5</cell><cell>0.0477</cell><cell>0.0543</cell><cell>0.0445</cell><cell>0.0555</cell><cell>0.0580</cell><cell>0.0475</cell><cell>0.0619</cell><cell>6.7%</cell></row><row><cell>Foursquare</cell><cell>Prec@10 Recall@1</cell><cell>0.0304 0.0376</cell><cell>0.0348 0.0445</cell><cell>0.0309 0.0305</cell><cell>0.0385 0.0440</cell><cell>0.0399 0.0497</cell><cell>0.0331 0.0369</cell><cell>0.0425 0.0565</cell><cell>6.5% 13.7%</cell></row><row><cell></cell><cell>Recall@5</cell><cell>0.0800</cell><cell>0.0888</cell><cell>0.0689</cell><cell>0.0959</cell><cell>0.0948</cell><cell>0.0770</cell><cell>0.1035</cell><cell>7.9%</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0954</cell><cell>0.1061</cell><cell>0.0911</cell><cell>0.1200</cell><cell>0.1187</cell><cell>0.1011</cell><cell>0.1291</cell><cell>7.6%</cell></row><row><cell></cell><cell>MAP</cell><cell>0.0636</cell><cell>0.0719</cell><cell>0.0571</cell><cell>0.0782</cell><cell>0.0823</cell><cell>0.0643</cell><cell>0.0909</cell><cell>10.4%</cell></row><row><cell></cell><cell>Prec@1</cell><cell>0.0010</cell><cell>0.0111</cell><cell>0.0197</cell><cell>0.0210</cell><cell>0.0280</cell><cell>0.0139</cell><cell>0.0312</cell><cell>11.4%</cell></row><row><cell></cell><cell>Prec@5</cell><cell>0.0009</cell><cell>0.0081</cell><cell>0.0114</cell><cell>0.0120</cell><cell>0.0149</cell><cell>0.0090</cell><cell>0.0179</cell><cell>20.1%</cell></row><row><cell>Tmall</cell><cell>Prec@10 Recall@1</cell><cell>0.0007 0.0004</cell><cell>0.0063 0.0046</cell><cell>0.0084 0.0079</cell><cell>0.0090 0.0082</cell><cell>0.0104 0.0117</cell><cell>0.0070 0.0056</cell><cell>0.0132 0.0130</cell><cell>26.9% 11.1%</cell></row><row><cell></cell><cell>Recall@5</cell><cell>0.0019</cell><cell>0.0169</cell><cell>0.0226</cell><cell>0.0245</cell><cell>0.0306</cell><cell>0.0180</cell><cell>0.0366</cell><cell>19.6%</cell></row><row><cell></cell><cell>Recall@10</cell><cell>0.0026</cell><cell>0.0260</cell><cell>0.0333</cell><cell>0.0364</cell><cell>0.0425</cell><cell>0.0278</cell><cell>0.0534</cell><cell>25.6%</cell></row><row><cell></cell><cell>MAP</cell><cell>0.0030</cell><cell>0.0145</cell><cell>0.0197</cell><cell>0.0212</cell><cell>0.0256</cell><cell>0.0164</cell><cell>0.0310</cell><cell>21.1%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>MAP vs. Caser Components</figDesc><table><row><cell></cell><cell>MovieLens</cell><cell>Gowalla</cell></row><row><cell>Caser-p</cell><cell>0.0935</cell><cell>0.0777</cell></row><row><cell>Caser-h</cell><cell>0.1304</cell><cell>0.0805</cell></row><row><cell>Caser-v</cell><cell>0.1403</cell><cell>0.0841</cell></row><row><cell>Caser-vh</cell><cell>0.1448</cell><cell>0.0856</cell></row><row><cell>Caser-ph</cell><cell>0.1372</cell><cell>0.0911</cell></row><row><cell>Caser-pv</cell><cell>0.1494</cell><cell>0.0921</cell></row><row><cell>Caser-pvh</cell><cell>0.1507</cell><cell>0.0928</cell></row><row><cell cols="2">4.2.3 Analysis of Caser Components.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Top-N recommendation ranks the items for each user individually, which is invariant to user bias and global bias.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://github.com/graytowne/caser</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://grouplens.org/datasets/movielens/1m/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://snap.stanford.edu/data/loc-gowalla.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://ijcai-15.org/index.php/repeat-buyers-prediction-competition</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The work of the second author is partially supported by a Discovery Grant from Natural Sciences and Engineering Research Council of Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mining sequential patterns</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakrishnan</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Engineering</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Where You Like to Go Next: Successive Point-of-Interest Recommendation</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Arti cial Intelligence</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2605" to="2611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Friendship and mobility: user movement in location-based social networks</title>
		<author>
			<persName><forename type="first">Eunjoon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1082" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micheline</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m">Data mining: concepts and techniques</title>
				<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Translation-based recommendation</title>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation</title>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural collaborative ltering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06939</idno>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Linas Baltrunas, and Domonkos Tikk</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Collaborative ltering for implicit feedback datasets</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation</title>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malte</forename><surname>Ludewig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Recommender systems</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="306" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large-scale video classi cation with convolutional neural networks</title>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanketh</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classi cation</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods on Natural Language Processing. ACL</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1756" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Collaborative ltering with temporal dynamics</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="89" to="97" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classi cation with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geo</forename><surname>Rey E Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A hybrid of sequential rules and collaborative ltering for product recommendation</title>
		<author>
			<persName><forename type="first">Duen-Ren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang-Jung</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="3505" to="3519" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Kara Át</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Interspeech</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2010-01">Jan Cernockỳ, and Sanjeev Khudanpur. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">One-class collaborative ltering</title>
		<author>
			<persName><forename type="first">Rong</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajan</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="502" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Ste En Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Arti cial Intelligence</title>
				<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Factorizing personalized markov chains for next-basket recommendation</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Ste En Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Probabilistic Matrix Factorization</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Restricted Boltzmann machines for collaborative ltering</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geo</forename><surname>Rey Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Item-based collaborative ltering recommendation algorithms</title>
		<author>
			<persName><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Autorec: Autoencoders meet collaborative ltering</title>
		<author>
			<persName><forename type="first">Suvash</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lexing</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="111" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-rate deep learning for temporal recommendation</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Mamdouh Elkahky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="909" to="912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Over tting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geo</forename><surname>Rey Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Matconvnet: Convolutional neural networks for matlab</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Multimedia</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning hierarchical representation model for nextbasket recommendation</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International ACM SIGIR conference on Research and Development in Information Retrieval</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amr</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">How</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
		<title level="m">International Conference on Web Search and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
	<note>Recurrent Recommender Networks</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Search and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph-based point-of-interest recommendation with geographical and temporal in uences</title>
		<author>
			<persName><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information and Knowledge Management</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="659" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Latent factor transition for dynamic collaborative ltering</title>
		<author>
			<persName><forename type="first">Chenyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianling</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM International Conference on Data Mining. SIAM</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="452" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stellar: spatial-temporal latent ranking for successive point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">Shenglin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Arti cial Intelligence</title>
				<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="315" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Joint Deep Modeling of Users and Items Using Reviews for Recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahid</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Search and Data Mining</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="425" to="434" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
