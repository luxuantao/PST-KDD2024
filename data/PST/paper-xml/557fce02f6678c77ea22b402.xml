<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">L</forename><surname>Georgiadis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">R</forename><surname>Guérin</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>94</addrLine>
									<postCode>1994</postCode>
									<settlement>Toronto, Canada</settlement>
									<region>Ont, June</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical and Computer Engineer-ing</orgName>
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postBox>P.O. Box 435</postBox>
									<postCode>54006</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">IBM Thomas J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 704</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<postCode>94025</postCode>
									<settlement>Menlo Park</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">38709E4BEE40D02C1D8EBAA05EF55F63</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Optimal Multiplexing on a Single Link:</p><p>Delay and Buffer Requirements Leonidas Georgiadis, Senior Member, IEEE, Roch Guérin, Senior Member, IEEE, and Abhay Parekh, Member, IEEE Abstract-This paper is motivated by the need to provide per-session quality of service guarantees in fast packet-switched networks. We address the problem of characterizing and designing scheduling policies that are optimal in the sense of minimizing buffer and/or delay requirements under the assumption of commonly accepted traffic constraints. We investigate buffer requirements under three typical memory allocation mechanisms which represent tradeoffs between efficiency and complexity. For traffic with delay constraints we provide policies that are optimal in the sense of satisfying the constraints if they are satisfiable by any policy. We also investigate the tradeoff between delay and buffer optimality, and design policies that are "good" (optimal or close to) for both. Finally, we extend our results to the case of "soft" delay constraints and address the issue of designing policies that satisfy such constraints in a fair manner. Given our focus on packet switching, we mainly concern ourselves with nonpreemptive policies, but one class of nonpreemptive policies which we consider is based on tracking preemptive policies. This class is introduced in this paper and may be of interest in other applications as well.</p><p>Index Terms-Buffer allocation, data networks, multiplexing, optimization, schedulable regions, scheduling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A key challenge in the design of integrated services net- works is to support a large number of sessions with different performance requirements, while minimizing cost as measured by network resources. Session performance is mainly characterized by packet delay and loss probability, with link bandwidth and buffer space being the network resources that must be expended to achieve performance.</p><p>It is clear that buffer requirements and delay are intimately related, since delay is trivially bounded above by the amount of time it takes to drain a switch with full buffers. Yet, there are more intricate factors at work when the switch implements scheduling and buffer allocation policies which discriminate among the sessions. The scheduling policy (usually implemented at the output ports of the switch) determines the order in which queued packets are served, and the buffer allocation policy determines the manner in which the buffer space is to be shared among the sessions. It turns out that for a given requirement on the loss probabilities, the choice of scheduling policy has an effect on both the delay and the total amount of buffer space required <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b24">[25]</ref>, while the choice of buffer allocation policy has an effect only on the total amount of buffer space required. To make things more complicated, for a given scheduling policy, the total amount of buffer space required is also dependent on the buffer allocation policy. These dependencies are not negligible and need to be examined carefully.</p><p>A central contribution of this paper is, therefore, to define a simple analytical model that permits meaningful evaluations of the delay and buffer requirements of policies, so that they can be properly compared. We then find policies that are optimal within this analytical model.</p><p>Our study is restricted to the case of a single link (multiplexer) and assumes a zero-loss environment, i.e., buffers are sized so that space is always available to store incoming data, provided the input traffic satisfies certain constraints. Our choice of zero-loss is motivated by several considerations. First, it provides us with a common basis of comparison for how each policy handles various traffic patterns. Second, it clearly represents a desirable feature, irrespective of whether an application can tolerate some losses, and we want to emphasize that providing such guarantees is indeed feasible at a reasonable cost. The traffic constraints that we assume in order to be able to ensure zero-loss, are well-accepted and in line with the requirements of standard rate control algorithms <ref type="bibr" target="#b1">[2]</ref>. Specifically, we assume that each session has a given average rate , an associated maximum burstiness (see Section II-A for a more rigorous definition), and a maximum packet size . A basic, qualitative outline of the paper is the following: In Section II, we define our model, introduce the scheduling policies (including a new class of policies known as Tracking policies) we are going to use in the remainder of the paper, and give a few preliminary results. In Section III, we examine various buffer allocation policies and for each show specific scheduling policies to be buffer-optimal, i.e., they require the minimal possible amount of buffer to ensure zero-loss, over all scheduling policies. Section IV considers the corresponding problem of designing delay optimal scheduling disciplines, and among the class of delay optimal policies identifies those that result in low buffer occupancy as well. Here we find that the more flexible the buffer allocation policy, the lower the buffer requirements for the "best" delay optimal policy. In the last major section of the paper, Section V, we define delay requirements differently, in that we allow packets to miss their deadlines, and design policies in which the "lateness" is distributed fairly among the sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Results</head><p>In Section III, we study three buffer structures, Flexible, Semiflexible, and Fixed, that represent different tradeoffs between efficiency and complexity, and design buffer optimal policies for each. The analysis shows the surprising result that improving the complexity of the buffer structure may not improve the efficiency significantly.</p><p>However, the advantage of a more complex and, therefore, more flexible buffer allocation scheme becomes apparent in Section IV, where we show that the added flexibility results in significant advantages when delays also need to be optimized. In this section, we identify the schedulable region of the multiplexer and characterize delay optimal policies, i.e., those with maximal schedulable region. In keeping with our focus on packet switching, we design nonpreemptive policies, as opposed to preemptive ones. We show that both a standard Non-Preemptive Earliest Deadline First policy (NPEDF) and a Tracking policy based on the Preemptive Earliest Deadline First policy (T(PEDF)) are delay-optimal among the class of nonpreemptive policies. Based on our knowledge of policies which are optimal for either buffer or delay requirements, we proceed next in Section IV-B with a policy which is delayoptimal and has small (near-optimal) buffer requirements.</p><p>In Section V, we consider two separate figures of merit. The first is that of minimizing the maximum lateness over all packets under any arrival pattern. We establish that under NPEDF and T(PEDF) maximum lateness is no more than time units greater than what it is under PEDF, which is known to be optimal with respect to minimizing maximum lateness <ref type="bibr" target="#b10">[11]</ref>, where is the transmission time of a maximum size packet over a link of speed . Thus NPEDF and T(PEDF) are very close to being optimal. The second, and stronger figure of merit is the degree to which the packet lateness vector is close to being lexicographically minimal. We show that a particular version of PEDF, which we call PEDF is lexicographically optimal among all preemptive policies. Further, we show that the tracking policy T(PEDF ) is close to being lexicographically optimal in that under T(PEDF ) no packet is delayed by more than beyond what it experiences under PEDF .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Earlier Work</head><p>Buffer-optimal policies under the fixed allocation method have been studied in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and the buffer optimal policy for was presented in <ref type="bibr" target="#b20">[21]</ref>. While the case of the flexible allocation method is straightforward, our results for the semiflexible allocation case are new. In addition, our result linking the schedulable region and buffer requirements under fixed allocation is new, as is our result on how to construct delay-optimal policies that have small buffer requirements.</p><p>The problem of scheduling tasks has received significant attention in the context of (real-time) computing systems, where important results on optimal scheduling policies and the associated schedulable region have been obtained. However, many of these results assume more restrictive arrival patterns than those used in this paper: The optimality of the PEDF for the class of preemptive policies was first shown in <ref type="bibr" target="#b18">[19]</ref> for periodic arrivals and in <ref type="bibr" target="#b10">[11]</ref> for general arrival patterns; in <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b16">[17]</ref> the delay-optimality of NPEDF among the class of nonpreemptive policies is established for periodic and socalled sporadic arrivals; the schedulable regions for NPEDF and PEDF have been derived in <ref type="bibr" target="#b25">[26]</ref> for arrival streams characterized by a minimum interpacket arrival time that is independent of packet size. The merit of using schedulable regions to guarantee quality of service in networks was recognized in <ref type="bibr" target="#b17">[18]</ref>. The NPEDF policy has been proposed in <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b22">[23]</ref>, and <ref type="bibr" target="#b23">[24]</ref> as a link scheduling policy in a scheme designed to provide per-session real-time guarantees in packet-switched networks.</p><p>Tracking policies have been proposed and studied in the context of Generalized Processor Sharing in <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b19">[20]</ref>. Theorems 1 and 2 appear in <ref type="bibr" target="#b19">[20]</ref> but have been extended in this paper to include all tracking policies that obey a specific Ordering Property. The T(PEDF) and T(PEDF ) policies are new as are all of the results pertaining to these policies. Finally, while the optimality of PEDF for the criterion of minimizing the maximum lateness of packets was established in <ref type="bibr" target="#b10">[11]</ref>, the relationship between PEDF and NPEDF in this context is new. The lexicographic optimality of PEDF is new as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MODEL, DEFINITIONS, AND PRELIMINARY RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiplexer and Traffic Models</head><p>Assume traffic flows from sessions arrive into a multiplexer (see Fig. <ref type="figure" target="#fig_0">1</ref>) and the flow of each session is partitioned into discrete entities or packets. A packet may be arbitrarily small, but can be no larger than bits. Arriving packets are stored in the memory of the multiplexer until they are transmitted on the output link, which is assumed to be of speed . The multiplexer is of store-and-forward type, i.e., a packet becomes eligible for transmission only after its last bit has arrived at the multiplexer. Since there may be several eligible packets at any given time, the multiplexer has a scheduler which implements a service policy. This policy decides which of the eligible packets to transmit on the output link and then transmits this packet nonpreemptively. In this paper, we assume a First-In-First-Out order of service for packets from a given session, so that the service policy only arbitrates transmission between the head-of-the-line packets from each session.</p><p>For definiteness, in the following we assume that if a packet arrives, i.e., its last bit is received, at the multiplexer at time it is also available for transmission at the scheduler at time . Therefore, the scheduler takes into account the packet arrival at time when making a scheduling decision at . Also, when a packet is being transmitted, we say that the packet is "being served." By convention, at the time instant at which the transmission ends, the packet is not in service. So, if a packet is transmitted from time to , the packet is being served in the interval . Let be the number of bits (traffic) generated by the source of session in the interval . Set for . Unless specified otherwise, assume that there exist such that <ref type="bibr" target="#b0">(1)</ref> This model for the generated traffic is identical to the one proposed by Cruz <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, and consistent with the constraints imposed by rate control algorithms that have been accepted by standard bodies <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. We refer to and as the session traffic rate and burstiness, respectively.</p><p>Let be the speed of the input link over which traffic from session is sent to the multiplexer. Since we are dealing with a store-and-forward multiplexer, a packet has to be completely received before it is delivered to the scheduler. It can then be shown using the techniques in <ref type="bibr" target="#b7">[8]</ref> that the amount of (packetized) traffic from session delivered to the scheduler in the interval , , satisfies</p><p>Therefore, assuming infinite input link speeds (and using for consistency the convention when ), we have</p><p>To keep the discussion simple, we will mainly deal with constraints of the form (3) in this paper, and wherever possible we will mention interesting results that can be derived for more general constraints using similar arguments. More general constraints of the form of piecewise-linear concave functions are presented in <ref type="bibr" target="#b7">[8]</ref> while constraints of the form where is a nondecreasing subadditive function, are also possible <ref type="bibr" target="#b5">[6]</ref>. We call the "envelope" of . For simplicity, whenever there is no possibility for confusion, we will write to denote .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note:</head><p>The following general remark regarding the validity of the results under finite input link speeds can be made. Under constraint (3), the session traffic pattern is feasible. This traffic pattern, which we refer to as the "greedy" pattern, will be used in the various arguments in the sequel. Since, however, the greedy pattern is not consistent with <ref type="bibr" target="#b1">(2)</ref>, results depending on it will not hold in general for finite input link speeds. On the other hand, since (2) is stronger than (3), results that depend only on the inequality , will also hold for finite input link speeds. For example, upper bounds on buffer size will generally hold, while lower bounds may not.</p><p>In the sequel and unless otherwise specified, we make the stability assumption <ref type="bibr" target="#b3">(4)</ref> We denote by the set of vectors of session traffic arrivals, that are constrained by ( <ref type="formula" target="#formula_1">3</ref>) and (4), with rate and burstiness vectors and , respectively.</p><p>Next, we introduce some notation needed in the rest of the paper. Let the scheduler implement policy and let be the session traffic arrival vector. We denote by the number of session bits served in the interval and by the number of session bits stored at time . Define as the largest amount of bits from session that can be stored in the memory under policy and under any traffic vector , i.e.,</p><p>The delay of a packet is defined as the time it spends in the system, i.e., the sum of the time spent waiting in the memory since its last bit arrives and the time taken to transmit it on the output link. The maximum delay experienced by packets in session under any traffic vector , is denoted by . For notational convenience, when there is no possibility for confusion, we may not indicate explicitly the dependence of the quantities defined above on , , , or .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Tracking Service Disciplines</head><p>In this section, we introduce the notion of Tracking Service Disciplines which is used in several instances in the following sections. This notion was introduced in <ref type="bibr" target="#b19">[20]</ref> for the purpose of tracking the Generalized Processor Sharing (GPS) discipline. It turns out that the fundamental properties of these policies (see Theorems 1 and 2 below) hold for tracking policies other than GPS, and this enables us to prove the delay and buffer optimality of various tracking service disciplines.</p><p>Given a preemptive policy , the notion of tracking is to derive a work-conserving, nonpreemptive policy that operates as follows: Let be the time at which packet departs from a multiplexer that implements policy assuming that there are no arrivals after time . Then at each decision epoch of , the server schedules a packet with the minimum value of over all eligible packets present in the system at time . Thus attempts to preserve the order in which packets depart under the preemptive system. At each decision epoch , the server picks the next packet that would depart from the system under the preemptive system if no more packets were to arrive after time . Since more than one packet may leave the preemptive system simultaneously, ties are broken arbitrarily.</p><p>When obeys the following Ordering Property, we can establish a tight coupling between the sample paths of and : Let packets and both be in the system at time and suppose that packet completes service before packet if there are no arrivals after time . Then packet will also complete service before packet for any pattern of arrivals after time . Further, if and leave the system simultaneously when there are no arrivals after time , then they leave the system simultaneously for any pattern of arrivals after time . The ordering property essentially requires that future arrivals do not modify the relative priorities of packets waiting to be transmitted. A consequence of the ordering property is that if the tracking server schedules a packet at time before another packet that is also backlogged at time , then packet cannot leave later than packet in the preemptive system. This leads to the following results (first developed in the context of Generalized Processor Sharing in <ref type="bibr" target="#b19">[20]</ref>). Let be the time at which packet departs from the preemptive system and let be the time it departs from the tracking system. Then Theorem 1: Suppose the ordering property holds for the preemptive system. For all packets <ref type="bibr" target="#b5">(6)</ref> Proof: The proof follows along the lines of the proof of <ref type="bibr" target="#b20">[21,</ref><ref type="bibr">Theorem 1]</ref>. We present it here for the convenience of the reader.</p><p>Since both the preemptive and tracking systems are workconserving disciplines, their busy periods coincide, i.e., the preemptive system server is in a busy period iff the tracking server is in a busy period. Hence, it suffices to prove the result for each busy period. Consider any given busy period and denote the time that it begins as time zero. Let be the length of the th packet (packet ) to depart under the tracking server and let be its arrival time. We now show that for Let be the largest integer that satisfies both and . Thus for <ref type="bibr" target="#b6">(7)</ref> Then packet is transmitted before packets in the tracking system, but after all these packets in the preemptive system. If no such integer exists then set . Now for the case , packet begins transmission at , so from the Ordering Principle <ref type="bibr" target="#b7">(8)</ref> Since packets arrive after , they receive all their service in the preemptive system after time . Also, from <ref type="bibr" target="#b6">(7)</ref>, they receive all their service before packet departs at time . Thus Since the right-hand side of the above inequality is equal to , we finally obtain</p><formula xml:id="formula_3">(9)</formula><p>If , then all leave the preemptive system before packet does, and since the tracking server is workconserving Theorem 2: Suppose the ordering property holds for the preemptive policy . Then for all times and for each session <ref type="bibr" target="#b9">(10)</ref> Proof: Follows from Theorem 1 and identical arguments as in <ref type="bibr" target="#b20">[21,</ref><ref type="bibr">Theorem 2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BUFFER ALLOCATION MECHANISMS</head><p>AND BUFFER REQUIREMENTS In this section, we address the problem of designing scheduling policies with minimal buffer requirements. We will assume that the session burstiness vector (or the supremum over all the session burstiness vectors) is known and fixed, and that the rate vector , while known, can vary as long as it satisfies the stability condition ( <ref type="formula">4</ref>). An important factor that affects the design of such policies and the corresponding buffer sizes, is the flexibility of the buffer allocation mechanism (the function of assigning memory locations to arriving packets) used in the multiplexer. We consider three natural ways in which the multiplexer can structure its buffers.</p><p>1) Flexible Allocation (FL): Packets from all arrival streams share a common pool of memory, i.e., buffers are not allocated by session. This provides the most efficient use of memory, but may be difficult to implement since the multiple input links require that multiple parallel writes be implemented by a single control logic. In addition, a dynamic linked list structure is also needed to maintain packet order. In this case, the minimum multiplexer buffer size needed when policy is implemented, , is</p><p>2) Semi-Flexible Allocation (SE): There are bits of buffer allocated to packets from session . The value of cannot be changed after , however, the multiplexer is allowed to allocate the buffers based on the knowledge of and . This limits the amount of memory sharing, but only requires the multiplexer to be programmable so that the allocations can match the session traffic characteristics. The link list structure then becomes simpler to implement than with a flexible allocation. Also, the multiple parallel writes can now be implemented through separate control logic modules. In this case <ref type="bibr" target="#b11">(12)</ref> 3) Fixed Allocation (FI): There are bits of buffer allocated to packets from each session that should be sufficient for all consistent with (4), i.e., Therefore, <ref type="bibr" target="#b12">(13)</ref> Note that knowledge of is not useful in the design of a Fixed Allocation policy since, according to the definition, the allocated buffer space is fixed and sufficient to accommodate all possible consistent with (4). Clearly, we have that while the complexity and cost of implementation reduces from FL to SE to FI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given</head><p>Flexible, Semi-Flexible, Fixed , policy is a buffer-optimal policy among the class of admissible policies , if for all</p><p>We also define ( <ref type="formula">14</ref>)</p><p>Unless otherwise specified, in the following, the class of admissible policies, , will be the class of work-conserving nonpreemptive policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Buffer-Optimal Multiplexers</head><p>In this section, we address the issue of determining (as defined in ( <ref type="formula">14</ref>)) and the scheduling policies that achieve for flexible, semi-flexible, and fixed buffer allocation multiplexers.</p><p>Proposition 1: For flexible allocation, and this value is achieved by any work-conserving service policy.</p><p>Proof: Suppose is some work-conserving policy. Consider an arbitrary busy period that starts at and ends at . Notice that the maximum number of bits from session that can enter the system in the interval , , is , i.e., the maximum number of bits that can be in the system corresponds to the greedy traffic pattern, starting from time . Since continuously serves packets in , we have Constraint (4) implies that the right-hand side in the previous inequality reaches its maximum at time . Thus</p><p>This bound is achieved under the greedy traffic pattern.</p><p>Note: The previous argument can be extended in a straightforward fashion if session has envelope . Let be the earliest time at which the slope of the function becomes less than or equal to . Then, observing that the maximum of occurs at time and following identical arguments we conclude that Next, we investigate the buffer requirements of the semiflexible allocation.</p><p>Proposition 2: For semiflexible allocation, Proof: Fix an integer , and consider the following arrival rates: and We assume that all packets are of size . Let be the time taken to transmit a packet. Let the system operate under a scheduling policy and denote by the following traffic pattern. A packet of length from session arrives at time , and no more traffic from session arrives afterwards. The greedy traffic patterns from sessions to arrives at time</p><p>. By time we mean "immediately after," i.e., at time</p><p>, where is arbitrarily small. Thus since is work-conserving and nonpreemptive, the packet from session will be transmitted in the interval . We will use this notation in the sequel, but will avoid the incorporation of , since it would complicate the discussion unnecessarily. Note also that although the packets are of constant length, the greedy pattern of each session can still appear at the input link to the multiplexer. However, the number of packets from session that will be delivered to the scheduler at time is . The rest of the bits, must wait in memory until a complete packet is formed. Define</p><p>Note the difference between and : in the latter, we take in addition the supremum over all arrival patterns consistent with (3) and ( <ref type="formula">4</ref>). We will show that (15) Since we clearly have that and , <ref type="bibr" target="#b14">(15)</ref> implies that for any and letting we conclude that as desired.</p><p>For simplicity of notation, we will drop the dependence on and in the remainder of this proof. To show (15), let us consider the following slightly more general system , that consists of sessions to . The buffer content of session , , at time is and session , , sends traffic greedily at rate after time , but it cannot use the server in the interval . Considering the traffic of sessions to only, the original system differs from only in the initial conditions (in the original system we have the special case ). Note that under both systems, the traffic from sessions to cannot use the server in the interval (by definition in system , while in the original system a packet from session is served in</p><p>). Setting , we will show that for system , under any policy (including idling) <ref type="bibr" target="#b15">(16)</ref> which is equivalent to <ref type="bibr" target="#b14">(15)</ref>.</p><p>For the proof of ( <ref type="formula">16</ref>), we will use induction on . For , ( <ref type="formula">16</ref>) is clearly true since session will have to wait at least until time before it is served (notice that session will have to wait even longer if since there will be no complete packet in the multiplexer.) Assume now that ( <ref type="formula">16</ref>) is true for . Consider a system consisting of sessions and let be the first time that session is served under an arbitrary policy . Note that since by the definition of system no session can use the server in , we have that . The following two possibilities arise. 1)</p><p>. Consider policy that serves only packets from session to in exactly the same manner as policy . Whenever serves a packet from session , idles. Note that satisfies the requirements of the inductive hypothesis for . Therefore, using the fact that , we have Since session was not served in the interval , we have also and, therefore, (16) holds for .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>. The traffic served from sessions to in the interval is at most (it may be less if there are no packets from sessions to to be served at some time in or the server idles). Therefore, the sum of the buffer contents of sessions to at time is <ref type="bibr" target="#b16">(17)</ref> Since a packet from session is served in the interval , we can apply the inductive hypothesis to the policy that schedules only packets from sessions to after time in exactly the same manner as , and with initial buffer contents , . Using also <ref type="bibr" target="#b16">(17)</ref> we get where Since the buffer requirements of session are at least we finally have that where Since by assumption , we have and, therefore, . Hence, the induction hypothesis holds for . Before dealing with the fixed allocation case, we present a preemptive service policy called Rate Proportional Processor Sharing (RPPS) that was introduced in <ref type="bibr" target="#b20">[21]</ref>. Recall that under our model, bits of a packet are only eligible for service once the last bit of packet has arrived. Let a session be backlogged at time , if a positive amount of eligible session traffic is queued at time . Then the RPPS server ensures that for any session , if session is continuously backlogged in the interval , then <ref type="bibr" target="#b17">(18)</ref> Notice that if and are both continuously backlogged in the interval, then ( <ref type="formula">18</ref>) is met with equality. Also note that the RPPS policy obeys the Ordering Property discussed in Section II-B. The following result is adapted from <ref type="bibr" target="#b20">[21]</ref>. Proposition 3: For fixed allocation and this value is achieved by T(RPPS). Proof: We show first that the buffer requirements of session under any policy are at least . Consider the following arrival pattern. The system is empty at time . A packet of length from session arrives at time . At time traffic from session arrives greedily. Since is work-conserving and nonpreemptive, the packet from session begins service at time and the traffic from session cannot begin service before time . Therefore, the queue size of session at the time when traffic from session is first served is at least Letting , we conclude that the buffer requirements of session are at least , and this implies that</p><p>To see that T(RPPS) meets this bound note that since under RPPS the rate of service received by session is at least , <ref type="bibr" target="#b20">[21]</ref> Applying Theorem 2 and summing over , we get the desired result.</p><p>Since , from Propositions 2 and 3, we immediately get the following result.</p><p>Corollary 1:</p><p>Notes: 1) Although Corollary 1 indicates that the semiflexible allocation does not provide significant savings in terms of buffer requirements compared to the fixed allocation, we will see in the next sections that when packet delays are also considered, the semiflexible allocation provides the flexibility of designing delay-optimal policies with low buffer requirements. This remark notwithstanding, it should be pointed out that the T(RPPS) policy, which from Proposition 3 has low buffer requirements under fixed allocation, is also capable of providing low, albeit not optimal, delay bounds.</p><p>2) In <ref type="bibr" target="#b3">[4]</ref>, it was shown that when , , and when the first-come-first-served (FCFS) policy is employed By summing over all , we conclude that . Together with Proposition 2, this implies that when , , the FCFS is bufferoptimal for semiflexible allocation. However, this is not true for general , as the following example shows.</p><p>Consider the following arrival pattern. A packet of length together with a burst of size arrives from each of the sessions at time . At time a packet from session of length arrives, followed immediately by a burst of packets of total size . After time , traffic from session arrives at rate . Assume also that . It is easy to see that at the time when packet enters service Summing over we see that which by Corollary 1 can be larger than in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. BUFFER REQUIREMENTS VERSUS DELAY: DELAY OPTIMAL POLICIES</head><p>In this section, we address the issue of designing scheduling policies that provide predetermined delay bounds to each of the sessions and have low buffer requirements. We start with a result that we need later and which is of independent interest. It expresses the relationship that exists between bounds on the delays and buffer requirements.</p><p>Recall the definition of and from Section II. In Theorem 3, we establish a useful lower bound on as a function of and the characteristics of session . Theorem 3: For any zero-loss multiplexer implementing policy that serves packets from session in an FCFS order, it holds <ref type="bibr" target="#b18">(19)</ref> Proof: We drop the superscript of and the dependence on for notational convenience. Consider the traffic pattern under which the supremum in the definition of (see <ref type="bibr" target="#b4">(5)</ref>) is achieved and let be such that under this traffic pattern (since is a supremum, it may not be achieved at any time; however, the same argument as the one that follows can be used by using appropriate "epsilons"). We focus on the first complete packet present in the queue of session at time (since the multiplexer is of store-and-forward type, and therefore there is always a complete packet in the queue of session at time ). Let be the arrival time of that packet (recall that the arrival time of the packet is the time the last bit of the packet arrives to the scheduler). Then, since packets from session are served in an FCFS order or <ref type="bibr" target="#b19">(20)</ref> where we have used the fact that due to the FCFS property, the amount of traffic stored in the buffer at time is at most the amount of work that session can generate in the time interval which in turn is bounded by and . Letting be the delay of the packet at the head of the queue at time , we have from <ref type="bibr" target="#b19">(20)</ref> Notes: 1) One of the reviewers suggested the following bound on the delay. Consider the last complete packet in the queue of session at time . The amount of traffic that needs to be transmitted in order for this packet to be sent on the output link is at least . Therefore, even if the scheduler is allocated solely to session , the delay of the this last packet will be at least . Therefore, we have another bound <ref type="bibr" target="#b20">(21)</ref> In general, the bounds ( <ref type="formula">19</ref>) and ( <ref type="formula">21</ref>) do not imply each other and therefore a tighter bound can be obtained by taking the maximum of the two. For our purposes, bound <ref type="bibr" target="#b18">(19)</ref> is sufficient. 2) Clearly, bound <ref type="bibr" target="#b20">(21)</ref> holds for general traffic envelopes.</p><p>Bound <ref type="bibr" target="#b18">(19)</ref> can also be extended to general envelopes. Indeed, consider that the session envelope is , where is (strictly) increasing and subadditive. Then, repeating the arguments in the proof of Theorem 3, we conclude that where is the inverse of . If is nondecreasing, a similar formula can be given by going through the obvious modifications to account for intervals where is not strictly increasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Delay-Optimal Policies</head><p>In this section, we address first the issue of designing delayoptimal policies. In the next section, we address the issue of designing policies that are delay-optimal and also have low buffer requirements.</p><p>To proceed, we need some notation and definitions. Let the nonnegative vector be a list of required upper bounds on delay so that no session packet is delayed by more than time units in the multiplexer. The deadline of packet from session that arrives at time is defined as . If is the finishing time of , its lateness is defined as . Given a zero-loss multiplexer that implements service policy , the vector is schedulable under if for all arrival patterns consistent with (3) and ( <ref type="formula">4</ref>), and for all sessions , no session packet is delayed by more than time units. The schedulable region of the policy is the set of all vectors schedulable under . Given a class of admissible policies , the schedulable region of is and a vector is schedulable in if it belongs to the schedulable region of . We define a scheduling policy to be delay-optimal in if <ref type="bibr" target="#b21">(22)</ref> for all policies . It has been shown in <ref type="bibr" target="#b10">[11]</ref>, that under any arrival pattern the preemptive earliest deadline first (PEDF), i.e., the policy that at any instant schedules the packet with the smallest deadline first (ties are resolved by picking one of the packets with equal minimal deadlines in an arbitrary fashion), minimizes the maximum lateness of all the packets. This implies that the PEDF policy is delay-optimal among all scheduling policies. To see this, assume that the vector is schedulable under a policy . Then the lateness of every packet under is nonpositive, and therefore the maximum lateness of all packets is nonpositive under . But then, the same conclusion is true for PEDF (since it minimizes the maximum lateness) and, therefore, the lateness of all packets under PEDF is nonpositive. This means of course that the vector is schedulable under PEDF, which implies that the schedulable region of PEDF is a superset of that of . For nonpreemptive policies, no policy is known that minimizes the maximum lateness of all packets over all arrival patterns. However, we will show that under constraints (3) and (4) the nonpreemptive EDF (NPEDF) (i.e., the policy that behaves like PEDF but it takes decisions only at packet transmission completions or upon arrival of a new packet in an empty system) and the PEDF tracking policy (T(PEDF)) are delay-optimal. We will also provide the schedulable region of these nonpreemptive policies. We note that in general NPEDF may differ significantly from T(PEDF). This is demonstrated in Example 1 of Section V-B, where we also show that in the important special case of fixed-size packets, T(PEDF) and NPEDF behave identically.</p><p>We now proceed to show the optimality of both the NPEDF and T(PEDF) policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4:</head><p>The NPEDF and T(PEDF) policies are delayoptimal among the class of nonpreemptive policies. The schedulable regions of NPEDF and T(PEDF) consist of the set of vectors which satisfy the constraints whenever</p><p>The Theorem is a conclusion of the following two lemmas. The first one establishes the necessary conditions for a vector to be schedulable under any nonpreemptive policy, and the second demonstrates the sufficiency of these constraints for schedulability under NPEDF and T(PEDF). Let if and , otherwise. Lemma 1: Let If the vector is schedulable under a nonpreemptive policy then necessarily (23) <ref type="bibr" target="#b23">(24)</ref> and <ref type="bibr" target="#b24">(25)</ref> Proof: We follow the method of proof in <ref type="bibr" target="#b25">[26]</ref>. Assume that all packets meet their deadlines under a nonpreemptive policy. Clearly, we should have , since otherwise maximum-length packets from any session are not schedulable. Consider the following arrival pattern. At time the last bit of a packet of maximum length from session , together with a burst of bit-size packets of total size arrives in the system. At time the last bit of a packet of maximum length from session , , together with a burst of bit-size packets of total size arrives. Afterwards, packets from session , , arrive in bit size at fixed rate . Let . Since all packets meet their deadlines at time , all packets from session that arrived before or at time must be transmitted by . The number of bits contained in these packets is . Therefore, the number of bits from sessions to that must be transmitted by time is Since the policy is nonpreemptive and the packet from session arrives first, the number of bits transmitted by time from the rest of the sessions is at most and this implies <ref type="bibr" target="#b23">(24)</ref>. To show inequality <ref type="bibr" target="#b24">(25)</ref>, let and observe, as before, that the number of bits from all the sessions that can be transmitted by time can be at most while the number of bits that must be transmitted is Lemma 2: Let . Any vector that satisfies the constraints of Lemma 1 is schedulable under both NPEDF and T(PEDF).</p><p>Proof: Let be the amount of work in the system with deadlines at most at time under either NPEDF or T(PEDF). We show that for all , which implies the lemma.</p><p>If the server is idle at time , then since both policies are work-conserving, we have . Assume, therefore, that the server is serving a packet at time and define as follows. If the server is serving a packet with deadline larger than at time , set . Otherwise, let be the smallest time such that the server is continuously busy serving packets with deadlines at most in the interval . Let be the set of packets with deadlines at most that either are served in , or are in the system at time . If , then clearly . Assume therefore that and let be the packet with the earliest arrival time among the packets in . Observe that the amount of work of the packets in is and that all this work arrives at or after time . Notice also that from <ref type="bibr" target="#b22">(23)</ref> and the fact that packet has deadline at most , we have . If then using the upper bound on the amount of work with deadlines at most that can arrive in the interval , determined in the proof of Lemma 1, we get</p><p>If , ( <ref type="formula">24</ref>) and ( <ref type="formula" target="#formula_5">26</ref>) imply that and therefore this case cannot occur. If , ( <ref type="formula">25</ref>) and ( <ref type="formula" target="#formula_5">26</ref>) imply that . Assume now . We will show that this case cannot occur. Let be the packet that completes service or is in service at time and let be its arrival time. By the definition of , packet has a larger deadline than which implies that . This is so since under both NPEDF and T(PEDF) packet cannot leave later than packet if . Note that since the deadline of packet is larger than , we have that . Taking also into account that , we have . Since all the work of the packets in arrives at or after time , setting we have that We will show next that (27) which will imply that This inequality together with the fact that, as discussed above, and <ref type="bibr" target="#b23">(24)</ref> imply that which shows that the case cannot occur. To show (27) for NPEDF observe that by the definition of this policy, packet must have arrived after packet entered service and therefore is less than the time to transmit a maximum-length packet.</p><p>Consider now that the system operates under the T(PEDF) policy. If , then by the definition of T(PEDF), packet must have arrived after packet entered service and, therefore, (27) is true. If then note that from the definition of PEDF (28) since</p><p>. Now recall from Theorem 1 that Combining this with (28) yields ( <ref type="formula">27</ref>). The schedulable region of PEDF under the arrival patterns considered in this section can be found using similar arguments as those used to prove Theorem 4. For completeness, we present this result in the next theorem.</p><p>Theorem 5: The schedulable region of PEDF consists of the set of vectors which satisfy the constraints whenever . In Figs. <ref type="figure" target="#fig_1">2</ref> and<ref type="figure" target="#fig_2">3</ref>, we show the schedulable regions of PEDF and NPEDF under various parameters. As we see, in both figures the two regions differ by two strips which have width . In fact, by examining the schedulable regions it is easy to see that if the vector is schedulable under PEDF, then the vector is schedulable under NPEDF. As we will see in the next section, this is a consequence of a general result that holds for any arrival patterns. Also, we see in Fig. <ref type="figure" target="#fig_1">2</ref>, where , that any schedulable vector under NPEDF has coordinates larger than . Since, as is easy to see, the vector is schedulable under the FCFS policy, it follows that in this case, from the point of view of schedulability, there is no point in employing another scheduling policy. In fact, as can be seen from Theorem 4, this is true always when and . Note: Lemmas 1 and 2 extend in a straightforward fashion to general session envelopes , . Indeed, defining for , and replacing in the arguments the quantity with , we obtain Theorem 6: Let . If session , , has envelope , then the NPEDF and T(PEDF) policies are delay-optimal among the class of nonpreemptive policies and their schedulable region consists of the set of vectors which satisfy the constraints and The schedulable region of PEDF under general session envelopes can be similarly derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Delay-Optimal Policies with Low Buffer Requirements</head><p>In this section, we address the issue of designing delayoptimal policies with low buffer requirements. We propose a policy that is delay-optimal and under semiflexible allocation has low buffer requirements. Note that based on Proposition 1, a delay-optimal policy will also have minimum buffer requirements if a flexible allocation is used. However, we will see that the improvement over the semiflexible case is small and may, therefore, not warrant the additional cost and complexity.</p><p>We first motivate the use of semiflexible allocation by showing that, under fixed allocation, the buffer requirements of any delay-optimal policy are at least . Proposition 4: Let be any nonpreemptive policy that is delay-optimal for all traffic patterns consistent with (3) and ( <ref type="formula">4</ref>). Under fixed allocation Proof: Consider the vector of delays given as the solution of the following system of equations:</p><p>The vector is schedulable in the class of nonpreemptive policies. This will follow from Theorem 4 once we show the inequality , , which is easily seen from the observation that by the definition of Assume that a packet of length from session arrives at time followed by a burst of bit-size packets of total length . At time a packet of length together with a burst of bit-size packets of total length arrives from session . After time , session sends traffic at rate . Let us estimate the buffer content of session at time . Since all the packets meet their deadlines, the server must have served bits from sessions to . Therefore, the bits from class served in are at most It follows that where . Proof: To show this proposition, we need first some definitions and observations. Consider the following greedy arrival pattern. A packet of size together with bit-size packets of total size from session , arrive at time . After time , bit-size packets from session arrive at rate . Let the sessions to be scheduled under a strict (nonpreemptive) priority rule with session having the highest priority. Let be the first time at which the buffer content of session becomes zero and define , where . Note that since the sessions are served in a strict priority order, at time the buffer contents of sessions to are zero and therefore at this time the first packet from session is scheduled. Let be the buffer size of session when the first packet from this session is scheduled. We then have This is due to the fact that since the scheduler serves the sessions in strict priority and traffic from sessions to arrives at rate , the rate by which the buffer content of session is depleted is . Therefore, it will take units of time to empty a buffer content of size . Since traffic arrives greedily and the first packet from session is served at time , we have</p><p>Assume next without loss of generality that , and consider again the greedy arrival pattern. Let either the NPEDF or the T(PEDF) policy be applied. Let and define the differences large enough so that both NPEDF and T(PEDF) schedule the sessions in a strict priority order ( to ) in the interval . According to the discussion in the previous paragraph, the buffer requirements of session are at least .</p><p>Let us now assume that . Taking , it can be seen from ( <ref type="formula" target="#formula_6">30</ref>) by an inductive argument that Therefore,</p><p>The question now arises whether one can design policies for semiflexible allocation, that have buffer requirements lower than . We show next that this is indeed the case. Specifically, we construct delay-optimal policies with buffer requirements . The design is based on the following lemma.</p><p>Lemma 3: Let be a vector that satisfies the conditions of Theorem 4, and in addition the last inequality is strict Then, we can find a vector such that , and in addition satisfies the conditions of Theorem 4 with equality for the last constraint.</p><p>Proof: Let us assume without loss of generality that . Let be the smallest index such that Let (see the expression at the bottom of this page). Define a new vector as follows.</p><p>, and . It is easy to see that the vector satisfies the inequalities of Theorem 4, and that for some , , one of them is met with equality. We will show that in addition, . The case is trivial. Assume now that . Since , it is sufficient to show that . Notice first, that from the definition of we have that (31) If , using the definition of we would have which contradicts (31). If we then set . Otherwise, define as the smallest integer such that and create another vector . Note that since by construction the vector satisfies one of the inequalities with equality for some , , we have that . In general, if in the th step the vector satisfies we set . Otherwise, we define analogously and repeat the process to create a vector . Since is increasing in and is at most , the iteration will stop in a finite number of steps and at the end we will have the vector .</p><p>Theorem 7: There is a delay-optimal policy among the class of nonpreemptive policies such that for all arrival patterns consistent with (3) and ( <ref type="formula">4</ref>) Proof: Let be a feasible vector of delays. If satisfies the conditions of Theorem 4 with equality for the last constraint, set . Otherwise, construct the vector as described in Lemma 3. Therefore, always satisfies Let be either the NPEDF or the T(PEDF) policy that uses vector as the vector of delays. Since the vector is schedulable by design, we have Using also Theorem 3, we conclude that and, therefore, (</p><p>Taking into account Lemma 3 and the fact that , we have (33) Conditions (32) and (33) imply the theorem.</p><p>Note that because of its constructive nature, the proof of Lemma 3 provides a simple algorithm for constructing policy , which is both delay-optimal and has "low" buffer requirements.</p><p>Notes: 1) As it affects the buffer requirements at subsequent nodes, it may be of interest to provide a characterization of the burstiness and rate of the session's departing traffic, when an upper bound on its delay through the multiplexer is known. From [8, Theorem 2.1], it is known that the departing traffic of session , , verifies 2) From the previous note and assuming a schedulable vector , we can then obtain an upper bound on the burstiness of session departing traffic. In those cases where satisfies the constraints of Theorem 4 with strict inequalities, it is then possible to reduce this bound following a method similar to that of Lemma 3. The reason is again that in this case, the vector of actual session delay bounds induced by NPEDF or T(PEDF) is smaller (component-wise) than . In fact, assume that all the inequalities in Theorem 4 are strict, and following the method of Lemma 3, let be the largest number such that the vector remains schedulable. The NPEDF policy that operates with parameters schedules identically to the one that operates with parameters and, therefore, these policies induce the same session delays. However, the latter policy induces delay bounds since by the choice of , is schedulable. Therefore, a bound on the burstiness of session traffic is .</p><p>3) The technique in the previous note cannot be applied to policy since by design the parameters of this policy will satisfy one of the constraints in Theorem 4 with strict equality. However, since policy always has smaller delay bounds than the corresponding NPEDF policy, it will also have smaller burstiness bounds for the departing session traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. OPTIMALITY CRITERIA FOR SOFT DEADLINES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Minimization of Maximum Lateness</head><p>In the previous section, we provided the schedulable region of NPEDF, T(PEDF), and PEDF under the assumption that the arriving traffic satisfies certain constraints. In this section, we consider the problem of designing scheduling policies when the objective is to keep the lateness of all packets as low as possible. This criterion is of interest in situations where the deadlines represent a desirable time by which the packets should be transmitted, and it is important to transmit each packet as early as possible and in a fair manner relative to the transmission times of the rest of the packets. PEDF is a good policy with respect to this type of objectives in the sense that among all scheduling policies, it minimizes the maximum lateness of all packets under any arrival pattern <ref type="bibr" target="#b10">[11]</ref>. However, it is easy to construct arrival patterns for which the NPEDF policy is not optimal with respect to the criterion of minimizing the maximum lateness among the nonpreemptive policies. In spite of this, we show in the next theorem, that NPEDF is still a good policy in the sense that the maximum lateness under NPEDF is at most larger than the maximum lateness under PEDF for any arrival pattern, i.e., even for traffic streams that do not satisfy the conditions of ( <ref type="formula" target="#formula_1">3</ref>) and (4). Let be the arrival time of packet . In the rest of this section, to avoid unimportant technical complications, we make the assumption that (34) Let be the finishing time of packet under the PEDF and NPEDF policies, respectively, and let be its deadline. Theorem 8: Under any arrival pattern For the proof of Theorem 8, we need the next lemma and some notation. We assume that packet numbering is according to the order in which packets enter service under the NPEDF policy. Let be the time packet entered service under the PEDF and NPEDF policies, respectively. Let also denote the amount of work (in bits) with deadline less than or equal to at time in a system that employs scheduling policy . Finally, if under the NPEDF policy, at time the server is idle or the packet in service has deadline at most set . Otherwise, let be the remaining length (in bits) of the packet that is in service at time -which by definition must have a deadline larger than .</p><p>Lemma 4: For every and , and every policy</p><formula xml:id="formula_8">(35)<label>(36)</label></formula><p>Proof: To show (35), note that where is the amount of work with deadline at most that arrived in the interval , and is the amount of work with a deadline at most served under policy in the interval . It, therefore, suffices to show that Define as the supremum of times such that at time , PEDF serves traffic with a deadline larger than or does not serve any traffic, and serves traffic with a deadline at most . If there is no such time, i.e., in the interval , PEDF serves traffic with a deadline at most whenever does so, set . At time sufficiently close but smaller than , there is no backlogged traffic with a deadline at most under PEDF (otherwise, by definition PEDF would be serving such traffic). Therefore, In the interval , PEDF always serves packets with a deadline at most whenever does so. Note also that PEDF, by definition, is serving these packets at the highest rate (link rate). Therefore, . We conclude that We use induction on the instants at which packets begin service under NPEDF to prove (36) as follows. We assume that the first packet arrives in the system at time and, therefore, . Relation (36) holds trivially at time . Assuming that (36) holds up to time and for all , we will show that it holds for all in the interval and all , and, therefore, up to time and for all . Since by (34) , we will conclude that (36) holds for all and . It fact, it is sufficient to show <ref type="bibr">(36)</ref>  </p><p>i.e., there is no work in the system with deadlines less than at time , under both policies. Then since the same amount of work arrives in the system under both policies and no work with a deadline at most is served by the nonpreemptive EDF, we have Proof of Theorem 8: Assume first that Since no deadline is missed by more than under PEDF, the scheduler must be able to transmit all the traffic backlogged at time with deadlines at most within an interval of length . Therefore, , and from (36) we conclude that Packets that arrive after time have deadlines larger than and therefore they cannot be scheduled before packet under NPEDF. Therefore, the maximum delay of packet after time is which implies that for any packet as desired. Assume next that . Consider the PEDF and NPEDF policies that operate with packet delay bounds .</p><p>Notice that these are valid bounds, i.e., , since clearly and, therefore,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let</head><p>. Observe that since all delay bounds are decreased by the same amount, the new PEDF and NPEDF policies behaves identically to the original ones and, therefore, the finishing times of the packets do not change. Also, Therefore, applying the argument corresponding to the case , we have i.e., we again have Corollary 2: If under any arrival pattern the vector of packet deadlines is schedulable under PEDF, then the vector is schedulable under NPEDF. Proof: Notice first that the PEDF (NPEDF) policy that operates with deadlines schedules identically as the PEDF (NPEDF) policy that operates with deadlines . Using this observation, we have</p><p>The first inequality follows from Theorem 8 and the previous observation. The equality that follows is simply a mathematical equality, while the second inequality is an immediate consequence of the assumption that the vector of packet deadlines is schedulable under PEDF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Lexicographic Optimization</head><p>A stronger optimality criterion than minimizing the maximum lateness, one which relates closer to fairness, is the criterion of lexicographic optimization of packet lateness, which is defined below.</p><p>Let , be two -dimensional vectors and let , be index permutations such that The vector is called lexicographically smaller than the vector , denoted as , if 1) , 2)</p><p>for some implies that for some .</p><p>Let be a set of -dimensional vectors. Vector is lexicographically optimal in if for all . Note that Condition 1 implies that a lexicographically optimal point is also a point that minimizes its maximum coordinate. The opposite is not always true.</p><p>The property of the lexicographically optimal vector that relates to fairness is that if one attempts to reduce coordinate by picking another vector in , then necessarily another coordinate that is larger than coordinate will have to be increased (see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr">Sec. 6.5.2]</ref>).</p><p>It turns out that if preemptions are allowed, one of the PEDF policies is lexicographically optimal. Specifically, let PEDF be the policy that serves preemptively the packets with the earliest deadline first, and that among the packets with the earliest deadline serves first the packets with the shortest remaining service time, i.e., time to transmit at rate the remaining bits in the packet. Among packets with the same deadline and the same remaining service time, PEDF selects one in an arbitrary fashion. To provide a precise formulation of the optimality of PEDF , we will assume that the number of arrivals in finite intervals is finite and where is the work that arrives to the system up to time . These constraints imply that the busy periods of any workconserving policy, as well as the number of packets served within a busy period are finite.</p><p>Theorem 9: Among all policies, PEDF minimizes lexicographically the lateness vector of the packets that arrive during any busy period.</p><p>Before proving this theorem we need the next lemma which is a direct consequence of the above definition of lexicographical ordering. Also, for a given policy , recall the notations (service start time), (service completion time), and (lateness) of packet .</p><p>Proof of Theorem 9: It is known <ref type="bibr" target="#b10">[11]</ref>, that for every policy one can find a work-conserving (nonidling, preemptive) policy such that for every . Therefore, from now on we concentrate on work-conserving policies. The proof is based on the following lemma.</p><p>Lemma 6: Let be a work-conserving policy and suppose that at time during a busy period there are packets , in the system such that either , or and , and policy schedules packet first. Then there is a policy such that • schedules identically to in the interval ; • after time , policy never schedules packet while packet is in the system; • , where are the lateness vectors of the packets that arrive during the busy period under policies and , respectively. Proof: To show this, we argue as follows. Denote by , , the maximum intervals of time, after time , during which schedules either one of packets or . Consider the policy that rearranges only the scheduling of packets in the intervals by scheduling first packet until it is completely transmitted, and then packet . Policy satisfies the first two conditions of the lemma. To show that it also satisfies the third condition, consider the following cases. Note that by construction we have 1)</p><p>In this case, . However, by construction of , we have and therefore, . It follows that Since the lateness of the rest of the packets in the busy period do not change, the result follows from Lemma 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>. In this case, and . We need to distinguish two subcases. a)</p><p>. Then Also, clearly . Therefore, we again have b) . In this case, . However, since the remaining service time of packet does not exceed that of packet at time , we have , i.e., . We conclude again that Using now repeatedly the proposition, it can be shown that if policy does not schedule packet according to PEDF in the busy period, one can construct a policy that schedules according to PEDF and is no worse than in the lexicographic sense. Repeating this procedure for all packets within the busy period, we eventually obtain the PEDF policy, which by construction is no worse than in the lexicographic sense.</p><p>The next observation, which follows directly from Theorem 1, shows that T(PEDF ) is "almost" lexicographically optimal.</p><p>Corollary 3: Let and be the lateness vectors for a given set of arrivals when the service policy is PEDF and T(PEDF ), respectively. Then for each packet arrival</p><p>The natural question to ask at this point is the performance of NPEDF with respect to the lexicographic criterion. The following example shows that for certain arrival patterns the policy is far from being lexicographically optimal.</p><p>Example 1: Assume that the server works at rate (bits per unit of time) and let packets arrive as follows: At time a maximum size packet with deadline arrives and at time , 1-bit packets with deadline arrive. Thereafter, at each time , a maximum-size packet with deadline arrives. Under PEDF , the 1-bit packets will be transmitted upon arrival and will depart from the system by time , and under both NPEDF and T(PEDF ) the packet arriving at time goes into service upon arrival and stays in service until it departs at time . The difference between the two nonpreemptive policies manifests itself after time , when T(PEDF ) serves the 1-bit packets, while NPEDF serves the packet with deadline . Observe that, in fact, under NPEDF, all 1-bit packets leave the system after time . Under PEDF the 1-bit packets will be transmitted consecutively starting from time and, therefore, their lateness is a most . Under T(PEDF ), the lateness of these packets is at most , as guaranteed by Corollary 3. However, under any of the NPEDF policies, the lateness of the packets is at least , i.e., the lateness of all the 1-bit packets has increased by at least relative to the lateness provided by the (lexicographically optimal) PEDF policy.</p><p>The example notwithstanding, NPEDF is almost lexicographically optimal for fixed-size packets since as we show in the next proposition, in this case T(PEDF ) behaves like NPEDF. Note that in general two NPEDF policies may differ only by the rules by which packets with the same deadlines are selected for transmission. When, however, all packets have the same length, the resulting packet lateness are identical in value (although may differ by packet indices) under any NPEDF policy and, therefore, all these policies have the same performance as far as lexicographic optimization is concerned.</p><p>Proposition 6: For all arrival patterns, T(PEDF ) behaves like NPEDF when all packet sizes are fixed at .</p><p>Proof: Suppose this is not true. Then for some sequence of arrivals, there must exist packets and with , such that the following two conditions hold:</p><p>(37) i.e., packet departs before packet under the tracking policy; and (38) i.e., both packets have arrived before either is scheduled by the tracking policy (a unit service rate is assumed).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now if</head><p>, then from (38) the tracking policy must schedule packet before packet which contradicts (37). If , then by the definition of PEDF we must have (39) Combining (38) and (39) which contradicts Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS AND EXTENSIONS</head><p>This paper was motivated by the need to support multiple sessions with varying traffic characteristics and performance requirements in fast packet-switched networks. It addressed the problem of characterizing and designing policies that are optimal in the sense of minimizing buffer and/or delay requirements, under the assumption of commonly accepted traffic constraints. Buffer optimal policies were investigated for three typical memory allocation methods, that represent different tradeoffs between efficiency and complexity. The aspect of also minimizing delay was then taken into account, and it was shown that delay and buffer requirements could not be jointly optimized unless some level of flexibility was available in allocating memory. Delay optimal policies were investigated and the results were used to construct policies that are both delay-optimal and have low (near-optimal) buffer requirements. Finally, the important problem of designing fair policies for users with soft deadlines was also addressed, and optimal or near-optimal policies were identified.</p><p>The main conclusions of this paper are the following. If the only objective is to have low buffer requirements the fixed allocation mechanism is adequate in practice. If however, good delay performance is also required, fixed allocation leads to large buffer requirements. In contrast, under the semiflexible allocation, delay-optimal policies with low buffer requirements can be designed. While it is easier to implement NPEDF than T(PEDF), T(PEDF) may be the policy of choice if it is desirable to apportion lateness in packet finishing times in a fair manner.</p><p>The class of tracking policies that was introduced in this paper may be of independent interest in other applications. The natural direction in which the results should be extended is to multiple nodes. This has been the focus of <ref type="bibr" target="#b13">[14]</ref>, which partially addresses some of these issues.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The multiplexer model.</figDesc><graphic coords="3,117.60,55.02,365.04,152.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Schedulable regions for 1 = 2 = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Schedulable regions for 1 ; 2 6 = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>be easily shown that and taking limits as in (29) we conclude that By interchanging the indices we conclude that and summing over we get the desired result. It turns out that even under semiflexible allocation, the delay-optimal policies NPEDF and T(PEDF) still have buffer requirements of at least . Proposition 5: With NPEDF, T(PEDF)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>packet ; remaining service time of packet at time under policy .</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors are grateful to the Associate Editor, Prof. R. L. Cruz, for many suggestions that not only enhanced the overall presentation of the paper, but also helped clarify and improve numerous subtle arguments in the proofs.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Framework for providing additional packet mode bearer services</title>
		<idno>CCITT Recommendation I.122</idno>
	</analytic>
	<monogr>
		<title level="j">CCITT Subworking Party</title>
		<imprint>
			<biblScope unit="volume">XVIII</biblScope>
			<date type="published" when="1988-02-01">1-2, 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">ATM UNI specification version 3.1, Tech. Rep., ATM Forum</title>
		<imprint>
			<date type="published" when="1994-09">Sept. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Data Networks, 2nd ed</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gallager</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Buffer sizing in an ISDN frame relay switch</title>
		<author>
			<persName><forename type="first">A</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>-C. Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guérin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Res., IBM T. J. Watson Res. Ctr</title>
		<imprint>
			<biblScope unit="volume">704</biblScope>
			<date type="published" when="1989-08">Aug. 1989</date>
			<pubPlace>Yorktown Heights, NY</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. RC 14386</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An optimal service policy for buffer systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Gail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Hantler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rosberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Comput. Mach</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="641" to="657" />
			<date type="published" when="1991-04">May 1995. Apr. 1991</date>
		</imprint>
	</monogr>
	<note>see also IBM Res. Rep. RC 16641</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stability, queue length and delay of deterministic and stochastic queueing networks</title>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="913" to="931" />
			<date type="published" when="1994-05">May 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-time packet switching: A performance analysis</title>
		<author>
			<persName><forename type="first">I</forename><surname>Cidon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Select. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1576" to="1586" />
			<date type="published" when="1988-12">Dec. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A calculus of delay, Part I: Network element in isolation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="114" to="131" />
			<date type="published" when="1991-01">Jan. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A calculus of delay, Part II: Network analysis</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="132" to="141" />
			<date type="published" when="1991-01">Jan. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis and simulation of a fair queueing algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Demers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Keshav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet. Res. and Exper</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Control robotics: The procedural control of physical processes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Dertouzos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IFIP Cong</title>
		<meeting>IFIP Cong</meeting>
		<imprint>
			<date type="published" when="1974">1974</date>
			<biblScope unit="page" from="807" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A scheme for real-time channel establishment in wide-area networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="368" to="379" />
			<date type="published" when="1990-04">Apr. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Buffer size requirements under longest queue first</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Gail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guérin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Hantler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rosberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Perf. Dist. Syst. Integr. Commun. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992">Sept. 1993. 1992</date>
		</imprint>
	</monogr>
	<note>Perform. Eval.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient network QoS provisioning based on per node traffic shaping</title>
		<author>
			<persName><forename type="first">L</forename><surname>Georgiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guérin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Peris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sivarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Networking</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="482" to="501" />
			<date type="published" when="1996-08">Aug. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Duration-limited statistical multiplexing of delay sensitive traffic in packet networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Golestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM&apos;91</title>
		<meeting>IEEE INFOCOM&apos;91</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On optimal scheduling of periodic and sporadic tasks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jeffay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Anderson</surname></persName>
		</author>
		<idno>TR 88-11-06</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci. FR</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<date type="published" when="1988-11">Nov. 1988</date>
			<pubPlace>Seattle, WA 98195</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. of Washington</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On non-preemptive scheduling of periodic and sporadic tasks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jeffay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Stanat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">U</forename><surname>Martel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Real-Time Systems Symp</title>
		<meeting>IEEE Real-Time Systems Symp<address><addrLine>San Antonio, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="129" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Control of resources in broadband networks with quality of service guarantees</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pacifici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Mag</title>
		<imprint>
			<date type="published" when="1991-09">Sept. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scheduling algorithms for multiprogramming in a hard-real-time environment</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Layland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Comput. Mach</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="61" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A generalized processor sharing approach to flow control in integrated services networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Parekh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Elec. Eng. Comput. Sci., MIT</title>
		<imprint>
			<date type="published" when="1992-02">Feb. 1992</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A generalized processor sharing approach to flow control in integrated services networks-The single node case</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Gallager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Networking</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="344" to="357" />
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Input buffer requirements for round robin polling systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Allerton Conf. on Communication, Control and Computing</title>
		<meeting>Allerton Conf. on Communication, Control and Computing</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Delay jitter control for real-time communication in a packet switching network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. TRICOMM&apos;91</title>
		<meeting>TRICOMM&apos;91<address><addrLine>Chapel Hill, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-04">Apr. 1991</date>
			<biblScope unit="page" from="35" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rate-controlled service disciplines</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. High Speed Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="389" to="412" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new architecture for packet switching network protocols</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Elec. Eng. Comput. Sci., MIT</title>
		<imprint>
			<date type="published" when="1989-08">Aug. 1989</date>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Real-time fault-tolerant communication in computer networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
