<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contents lists available at ScienceDirect Information Fusion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qingchen</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology</orgName>
								<address>
									<country>China China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">St. Francis Xavier University</orgName>
								<address>
									<settlement>Antigonish</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Laurence</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
							<email>ltyang@stfx.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology</orgName>
								<address>
									<country>China China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">St. Francis Xavier University</orgName>
								<address>
									<settlement>Antigonish</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhikui</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Software Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Software Technology</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Contents lists available at ScienceDirect Information Fusion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.inffus.2017.10.006</idno>
					<note type="submission">Received 30 August 2017; Accepted 17 October 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Deep learning Big data Stacked auto-encoders Deep belief networks Convolutional neural networks Recurrent neural networks</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning, as one of the most currently remarkable machine learning techniques, has achieved great success in many applications such as image analysis, speech recognition and text understanding. It uses supervised and unsupervised strategies to learn multi-level representations and features in hierarchical architectures for the tasks of classification and pattern recognition. Recent development in sensor networks and communication technologies has enabled the collection of big data. Although big data provides great opportunities for a broad of areas including e-commerce, industrial control and smart medical, it poses many challenging issues on data mining and information processing due to its characteristics of large volume, large variety, large velocity and large veracity. In the past few years, deep learning has played an important role in big data analytic solutions. In this paper, we review the emerging researches of deep learning models for big data feature learning. Furthermore, we point out the remaining challenges of big data deep learning and discuss the future topics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, the cyber-physical-social systems, together with the sensor networks and communication technologies, have made a great progress, enabling the collection of big data <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Big data can be defined by its four characteristics, i.e., large volume, large variety, large velocity and large veracity, which is usually called 4V's model <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. The most remarkable characteristic of big data is large-volume that implies an explosive in the data amount. For example, Flicker generates about 3.6 TB data and Google processes about 20,000 TB data everyday. The National Security Agency reports that approximately 1.8 PB data is gathered on the Internet everyday. One distinctive characteristic of big data is large variety that indicates the different types of data formats including text, images, videos, graphics, and so on. Most of the traditional data is in the structured format and it is easily stored in the twodimensional tables. However, more than 75% of big data is unstructured. Typical unstructured data is multimedia data collected from the Internet and mobile devices <ref type="bibr" target="#b5">[6]</ref>. Large velocity argues that big data is generating fast and requires to be processed in real time. The realtime analysis of big data is crucial for e-commerce to provide the online services. Another important characteristic of big data is large veracity that refers to the existence of a huge number of noisy objects, incomplete objects, inaccurate objects, imprecise objects and redundant objects <ref type="bibr" target="#b6">[7]</ref>. The size of big data is continuing to grow at an unprecedented rate and is will reach 35 ZB by 2020. However, only having massive data is inadequate. For most of the applications such as industry and medical, the key is to find and extract valuable knowledge from big data for prediction services support. Take the physical devices that suffer mechanical malfunctions occasionally in the industrial manufacturing for an example. If we can analyze the collected parameters of devices effectively before the devices break down, we can take the immediate actions to avoid the catastrophe. While big data provides great opportunities for a broad of areas including e-commerce, industrial control and smart medical, it poses many challenging issues on data mining and information processing. Actually, it is difficult for traditional methods to analyze and process big data effectively and efficiently due to the large variety and the large veracity.</p><p>Deep learning is playing an important role in big data solutions since it can harvest valuable knowledge from complex systems <ref type="bibr" target="#b7">[8]</ref>. Specially, deep learning has become one of the most active research points in the machine learning community since it was presented in 2006 <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>. Actually, deep learning can track back to the 1940s. However, traditional training strategies for multi-layer neural networks always result in a locally optimal solution or cannot guarantee the convergence. Therefore, the multi-layer neural networks have not received wide applications even though it was realized that the multilayer neural networks could achieve the better performance for feature and representation learning. In 2006, Hinton et al. <ref type="bibr" target="#b11">[12]</ref> proposed a twostage strategy, pre-training and fine-tuning, for training deep learning effectively, causing the first back-through of deep learning. In addition, the increase of computing power and data size also contributes to the popularity of deep learning. As the era of big data comes, a large number of samples can be collected to train the parameters of deep learning models. Meanwhile, training a large-scale deep learning model requires high-performance computing systems. Take the large-scale deep belief network with more than 100 million free parameters and millions of training samples developed by Raina et al. <ref type="bibr" target="#b12">[13]</ref> for example. With a GPU-based framework, the training time for such the model is reduced from several weeks to about one day. Typically, deep learning models use an unsupervised pre-training and a supervised fine-tuning strategy to learn hierarchical features and representations of big data in deep architectures for the tasks of classification and recognition <ref type="bibr" target="#b13">[14]</ref>. Deep learning has achieved state-of-the-art performance in a broad of applications such as computer vision <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, speech recognition <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> and text understanding <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>In the past few years, deep learning has made a great progress in big data feature learning <ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>. Compared to the conventional shallow machine learning techniques such as supported vector machine and Naive Bayes, deep learning models can take advantage of many samples to extract the high-level features and to learn the hierarchical representations by combining the low-level input more effectively for big data with the characteristics of large variety and large veracity. In this paper, we review the emerging research work on deep learning models for big data feature learning. We first present four types of most typical deep learning models, i.e., stacked auto-encoder, deep belief network, convolutional neural network and recurrent neural network, which are also the most widely used for big data feature learning, in Section 2. Afterwards, we provide an overview on deep learning models for big data according to the 4V's model, including large-scale deep learning models for huge amounts of data, multi-modal deep learning models and deep computation model for heterogeneous data, incremental deep learning models for real-time data and reliable deep learning models for low-quality data. Finally, we discuss the remaining challenges of deep learning on big data and point out the potential trends.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Typical deep learning models</head><p>Since deep learning was presented in Science magazine in 2006, it has become an extremely hot research topic in the machine learning community. Various deep learning models have been developed in the past few years. The most typical deep learning models include stacked auto-encoder (SAE), deep belief network (DBN), convolutional neural network (CNN) and recurrent neural network (RNN), which are also most widely used models. Most of other deep learning models can be variants of these four deep architectures. In the following parts, we review the four typical deep learning models briefly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Stacked auto-encoder (SAE)</head><p>A stacked auto-encoder model is usually constructed by stacking several auto-encoders that are the most typical feed-forward neural networks <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>. A basic auto-encoder has two stages, i.e., encoding stage and decoding stage, as presented in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>In the encoder stage, the input x is transformed to the hidden layer h via the encoding function f:</p><formula xml:id="formula_0">= + h f W x b ( ) .</formula><p>(</p><formula xml:id="formula_1">) (1)<label>1</label></formula><p>Afterwards, the hidden representation h is reconstructed back to the original input that is denoted by y in the decoding stage:</p><formula xml:id="formula_3">= + y g W h b ( ) .</formula><p>(</p><formula xml:id="formula_4">) (2)<label>2</label></formula><p>Typically, the encoding function and the decoding function are nonlinear mapping functions. Four widely used non-linear activation functions are the Sigmoid function</p><formula xml:id="formula_6">= + − f x e ( ) 1/(1 ), x the tanh func- tion = − + − − f x e e e e ( ) (</formula><p>)/( ), <ref type="bibr">)</ref> and the ReLu (Rectified Linear Units) function = f x max x ( ) (0, ). The functional graph of the four non-linear activa- tion functions is presented in Fig. <ref type="figure" target="#fig_1">2</ref></p><formula xml:id="formula_7">x x x x the softsign function = + f x x x ( ) /<label>(1</label></formula><formula xml:id="formula_8">. = θ W b W b { , ; , }<label>(1) (1)</label></formula><p>(2) (2) is the parameter set of the basic auto-encoder and it is usually trained by minimizing the loss function J θ with regard to m training samples:</p><formula xml:id="formula_9">∑ = − = J m y x 1 ( ), θ i m i i 1 ( ) ( ) 2<label>(3)</label></formula><p>where x (i) denotes the ith training sample.</p><p>Obviously, the parameters of the basic auto-encoder are trained in an unsupervised strategy. The hidden layer h is viewed as the extracted feature or the hidden representation for the input data x. When the size of h is smaller than that of x, the basic auto-encoder can be viewed as an approach for data compression.</p><p>The basic auto-encoder model has some variants. For example, a regularization named wight-decay is usually integrated into the loss function to prevent the over-fitting:</p><formula xml:id="formula_10">∑ ∑ = − + = = J m y x λ W 1 ( ) , θ i m i i j j 1 ( ) ( ) 2 1 2 ( )<label>(4)</label></formula><p>where λ is a hiper-parameter used to control the strength of the weightdecay.</p><p>Another representative variant is sparse auto-encoder <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. To make the learned features sparse, the sparse auto-encoder adds a sparsity constraint into the hidden units, leading to the corresponding loss function as:</p><formula xml:id="formula_11">∑ ∑ = − + = J m y x KL p p 1 ( ) ( ) , θ i m i i j n j 1 ( ) ( ) 2<label>(5)</label></formula><p>where n denotes the number of neurons in the hidden layer and the second item denotes the KL-divergence. Specially, the KL-divergence with regard to the jth neuron is defined as:  </p><formula xml:id="formula_12">j j j (<label>6</label></formula><formula xml:id="formula_13">)</formula><p>where p denotes a predefined sparse parameter that is close to 0 and p j denotes the average activation value of the jth neuron in the hidden layer over all the training samples. Generally, a small p value close to 0 will result in a very sparse hidden representation learned by the autoencoder.</p><p>Several auto-encoders can be stacked to construct a deep learning model, called stacked auto-encoder, to learn hierarchical features or representations for the input, as presented in Figs. <ref type="figure" target="#fig_3">3 and 4</ref>.</p><p>The stacked auto-encoder is typically trained by two stages, i.e., pretraining and fine-tuning. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, let = X h 0 and h i denote the input layer and the ith hidden layer, respectively. In the pre-training stage, each auto-encoder model is trained in a unsupervised layer-wise manner from bottom to top. In detail, the auto-encoder takes = h X 0 as input and takes Y 0 as output to train the parameters of the first hidden layer, and then h 1 is fed as the input to train the parameters of the second hidden layer. This operation is repeated until the parameters of all the hidden layers are trained. After pre-training, the parameters are set to the initial parameters of the stacked auto-encoder. Some labeled samples are used as the supervised objects to fine-tune the parameters from top to bottom in the fine-tuning stage, as presented in Fig. <ref type="figure" target="#fig_3">4</ref>.</p><p>According to Hinton et al. <ref type="bibr" target="#b11">[12]</ref>, this two-stage training strategy can avoid the local optima effectively and achieve a better convergency for deep learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Deep belief network (DBN)</head><p>The first deep learning model that is successfully trained is the deep belief network <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b28">29]</ref>. Different from the stacked auto-encoder, the deep belief network is stacked by several restricted Boltzmann machines. The restricted Boltzmann machine consists of two layers, i.e., visible layer v and hidden layer h, as presented in Fig. <ref type="figure" target="#fig_4">5</ref>  <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>A typical restricted Boltzmann machine uses the Gibbs sampling to train the parameters. Specially, the restricted Boltzmann machine uses the conditional probability P(h|v) to calculate the value of each unit in the hidden layer and then uses the conditional probability p(h|v) to calculate the value of each unit in the visible layer. This process is performed repeatedly until convergence.</p><p>The joint distribution of the restricted Boltzmann machine with regard to all the units is defined as:</p><formula xml:id="formula_14">= − p v h θ E v h θ Z ( , ; ) exp( ( , ; )) ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_15">= ∑ ∑ − Z E v h θ exp( ( , ; ) v h</formula><p>is used for normalization. E denotes the energy function with the Bernoulli distribution that is calculated via:</p><formula xml:id="formula_16">∑ ∑ ∑ ∑ = − − − = = = = E v h θ w v h b v a h ( , ; ) , i I j J ij i j i I i i j J j j 1 1 1 1<label>(8)</label></formula><p>where I and J denote the number of the visible units and the hidden units, respectively. = θ W b a { , , } denotes the parameter set of the re- stricted Boltzmann machine.</p><p>The sampling probability of each unit is calculated as follows:</p><formula xml:id="formula_17">∑ = = ⎛ ⎝ ⎜ + ⎞ ⎠ ⎟ = p h v θ f w v a ( 1 ; ) , j i I ij i j 1 (9) ∑ = = ⎛ ⎝ ⎜ + ⎞ ⎠ ⎟ = p v h θ f w h b ( 1 ; ) , j j J ij j i 1 (<label>10</label></formula><formula xml:id="formula_18">)</formula><p>where f is typically a Sigmoid function.</p><p>An important variant is the restricted Boltzmann machine with Gauss-Bernoulli distribution whose energy function is calculated as follows <ref type="bibr" target="#b31">[32]</ref>:</p><formula xml:id="formula_19">= − ∑ ∑ + ∑ − − ∑ = = = = E v h θ w v h v b a h ( , ; ) ( ) . i I j J ij i j i I i i j J j j 1 1 1 2 1 1<label>(11)</label></formula><p>The corresponding conditional probability of each visible unit is calculated via:   </p><formula xml:id="formula_20">∑ = = ⎛ ⎝ ⎜ + ⎞ ⎠ ⎟ = p v h θ N w h b ( 1 ; ) ,1 , j j J ij j i 1 (12)</formula><p>where v i denotes the real-value that satisfies the Gauss distribution with the mean value of</p><formula xml:id="formula_21">∑ + = w h b j J ij j i 1</formula><p>and the variance of 1. The restricted Boltzmann machine with Gauss-Bernoulli distribution can transform the real random variable to the binary variable.</p><p>Several restricted Boltzmann machines can be stacked into a deep learning model, called deep belief network, as presented in Fig. <ref type="figure">6</ref>  <ref type="bibr" target="#b11">[12]</ref>.</p><p>Similar to the stacked auto-encoder, the deep belief network is also trained by a two-stage strategy. The pre-training stage is used to train the initial parameters in a greedy layer-wise unsupervised manner while the fine-tuning stage uses the supervised strategy to fine-tune the parameters with regard to the labeled samples by adding a softmax layer on the top layer. Deep belief networks have a wide range applications in image classification <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref> and acoustic modeling <ref type="bibr" target="#b34">[35]</ref> and so on <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Convolutional neural network (CNN)</head><p>Convolutional neural network is the most widely used deep learning model in feature learning for large-scale image classification and recognition <ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref>. A convolutional neural network consists of three layers, i.e., convolutional layer, subsampling layer (pooling layer) and fully-connected layer, as presented in Fig. <ref type="figure">7</ref>  <ref type="bibr" target="#b43">[44]</ref>.</p><p>The convolutional layer uses the convolution operation to achieve the weight sharing while the subsampling is used to reduce the dimension. Take a 2-dimensional image x as example. The image is firstly</p><formula xml:id="formula_22">decomposed into a sequential input = … x x x x { , , , } N 1 2</formula><p>. To share the weight, the convolutional layer is defined as:</p><formula xml:id="formula_23">∑ ⎜ ⎟ = ⎛ ⎝ ⊗ + ⎞ ⎠ y f K x b , j i ij i j (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>where y j denotes the jth output for the convolutional layer and K ij denotes the convolutional kernel with the ith input map x i . ⊗ denotes the discrete convolution operator and b j denotes the bias. In addition, f denotes the non-linear activation, typically a scaled hyperbolic tangent function.</p><p>The subsampling layer aims to reduce the dimension of the feature map. It can typically be implemented by an average pooling operation or a max pooling operation. Afterwards, several fully-connected layers and a softmax layer are typically put on the top layer for classification and recognition.</p><p>The deep convolutional neural network usually includes several convolutional layers and subsampling layers for feature learning on large-scale images.</p><p>In recent years, convolutional neural networks have also made a great success in language processing and speech recognition and so on <ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Recurrent neural network (RNN)</head><p>The traditional deep learning models such as stacked auto-encoders, deep belief networks and convolutional neural networks do not take the time series into account, so they are not suitable to learn features for the time series data. Take one natural language sentence that is a kind of typical time series data as an example. Since each word is closely related to other words in a sentence, the previous one or more words should be used as inputs when using the current word to predict the next word. Obviously, the feed-forward deep learning models cannot work well for this task since they do not store the information of previous inputs.</p><p>The recurrent neural network is a typical sequential learning model. It learns features for the series data by a memory of previous inputs that are stored in the internal state of the neural network. A directed cycle is introduced to construct the connections between neurons, as presented in Fig. <ref type="figure">8</ref> . As shown in Fig. <ref type="figure">8</ref>, at the time step t, the recurrent neural network takes the current sample x t and the previous hidden representation − s t 1 as input to obtain the current hidden representation s t :</p><formula xml:id="formula_25">= − s f x s ( , ), t t t 1<label>(14)</label></formula><p>where f denotes the encoder function.</p><p>One widely used recurrent neural network is vanilla one, which at the time step t is defined as the following forward pass:</p><formula xml:id="formula_26">= + + − s f W x W s b ( ) , t s xt s st s 1 (15) = + y g W s b ( ) , t ys t y (<label>16</label></formula><formula xml:id="formula_27">)</formula><p>where f and g denote the encoder and decoder, respectively, and</p><formula xml:id="formula_28">= θ W W b W b { , , ;</formula><p>, } sx ss s ys y denotes the parameter set. Therefore, the recurrent neural network captures the dependency between the current sample x t with the previous one −</p><p>x t 1 by integrating the previous hidden representation − s t 1 into the forward pass. From a theoretical point of view, the recurrent neural network can capture arbitrary-length dependencies. However, it is difficult for the recurrent neural network to capture a long-term dependency because of the gradient vanishing with the back-propagation strategy for training the parameters. To tackle this problem, some models, such as long shortterm memory, have been presented by preventing the gradient vanishing or gradient exploding <ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref>.</p><p>Multiple recurrent neural networks can be stacked into a deep learning model. The recurrent neural network and its variants have achieved super performance in many applications such as natural language processing, speech recognition and machine translation <ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Deep learning models for big data feature learning</head><p>Big data is typically defined by the following four characteristics: volume, variety, velocity and veracity. In this section, we review the deep learning models for big data feature learning from four aspects, i.e., deep learning models for huge amounts of data, deep learning models for heterogeneous data, deep learning models for real-time data and deep learning models for low-quality data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Deep learning models for huge amounts of data</head><p>First and foremost, huge amounts of data poses a big challenge on deep learning models. A big dataset often includes a great many samples, each with a large number of attributes. Furthermore, there are many class types of samples in a big dataset. In order to learn features and representations for large amounts of data, some large-scale deep learning models have been developed. Generally, a large-scale deep learning model involves a few hidden layers, each with a large number of neurons, leading to millions of parameters. It is a typically difficult task to train such large-scale deep learning models.</p><p>In recent years, many algorithmic methods have been presented to train large-scale models, which can roughly grouped into three categories, i.e., parallel deep learning models, GPU-based implementation, and optimized deep learning models.</p><p>One of the most representative parallel deep learning models is called deep stacking network which is presented by Deng et al. <ref type="bibr" target="#b59">[60]</ref>. A deep stacking network is constituted by some modules. Fig. <ref type="figure">9</ref> shows a specific example of the deep stacking network with three modules.</p><p>In a deep stacking network, each module is also a neural network with a hidden layer and two sets of weights, as presented in Fig. <ref type="figure">9</ref>. The lowest module consists of three layers from bottom to up. The bottom is a linear layer which uses the original data as input while the hidden layer is a non-linear one with some hidden neurons. Similar to most of deep learning models, the deep stacking network uses the Sigmoid function to map the input to the hidden layer by a weight matrix and a bias vector. The top is also a linear layer, constituted by C output neurons which denote the targets of classification.</p><p>The original data is concatenated with the previous output layer(s) and the concatenated vector is used as the input of each module above the lowest module. For example, if each original data object is represented by an n-dimensional vector and there are c class types, the dimension, D, of the input vector of the ith counting from bottom to up, is</p><formula xml:id="formula_29">= + × − D n c m ( 1)</formula><p>. The deep stacking network is efficient for training since it can be paralleled. Furthermore, a tensor deep stacking network was presented to improve the training efficiency further on CPU clusters <ref type="bibr" target="#b60">[61]</ref>.</p><p>Recently, a software framework called DistBelief was developed to train large-scale deep learning models in a large number of machines in parallel <ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref>. DistBelief is efficient to train large-scale models with billions of free parameters and huge amounts of data by combination of data parallelism and model parallelism. In order to achieve the model parallelism, a large deep learning model is partitioned into some small blocks and each block is assigned to a computer for training. Fig. <ref type="figure" target="#fig_6">10</ref> presents one example of DistBelief with four blocks <ref type="bibr" target="#b7">[8]</ref>.</p><p>DistBelief needs to transfer data among the computers for training the deep learning models, which will result in a great deal of communication, especially for the fully-connected network such as stacking auto-encoder and deep belief network. In spite of this, DistBelief still improves the training efficiency significantly by partitioning a large deep model into 144 blocks, as reported in <ref type="bibr" target="#b61">[62]</ref>.</p><p>DistBelief achieves data parallelism by implementing two optimization procedures, i.e., Downpour and Sandblaster. The former is used for online optimization while the latter is used for batch optimization.</p><p>DistBelief has obtained a high speedup for training several largescale deep learning models. For example, it achieved a speedup of 12 × than using only one machine for a convolutional neural network with 1.7 billion parameters and 16 million images on 81 machines. Besides, it also achieved a significant improvement of training efficiency for another deep learning architecture with 14 million images, each one with a size of 200 × 200 pixels, on 1000 machines, each with 16 CPU cores. Therefore, DistBelief is very suitable for big data feature learning since it is able to scale up over many computers, which is the most remarkable advantage of DistBelief <ref type="bibr" target="#b7">[8]</ref>.</p><p>Deep stacking network and DistBelief typically use multiple CPU cores to improve the training efficiency for large-scale deep learning models. Some details about the use of multiple CPU cores for scaling up deep belief networks, such as implementing data layout and using SSE2 instructions, were discussed in <ref type="bibr" target="#b64">[65]</ref>.</p><p>More recently, some large-scale deep learning frameworks based on graphic processors units (GPUs) have been explored. GPUs are typically equipped by great computing power and a big memory bandwidth, so they are suitable for parallel computing for large-scale deep learning models. Some experiments have demonstrated a great advance of largescale deep learning frameworks based on GPUs.</p><p>For example, Raina et al. <ref type="bibr" target="#b12">[13]</ref> developed a deep learning framework based on GPUs for parallel training large-scale deep belief networks and sparse coding with more than 100 million parameters and millions of training objects. In order to improve the efficiency for parallelizing the Fig. <ref type="figure">9</ref>. A deep stacking network with three modules. learning models, Raina et al. <ref type="bibr" target="#b12">[13]</ref> used some specialized strategies in their developed learning framework <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b66">67]</ref>, For instance, they put the parameters and some training objects into the global memory to reduce the data transfer. Besides, they implemented a parallel Gibbs sampling of hidden and visible neurons by producing two sampling matrices, i.e., p(h|x) and p(x|h). With this framework, a deep belief network constructed by multiple restricted Boltzmann machines, each with 45 million free parameters and 1 million training objects, was sped up by a factor of 70 × .</p><p>Another recent developed large-scale deep learning system is the commodity off-the-shelf high performance computing system, which is constituted by 16 GPU servers. Each server consists of 4 NVIDIA GTX680 GPUs, everyone with 4GB memory. This system trains large deep learning models by implementing CUDA kernels with effective memory usage and efficient computation <ref type="bibr" target="#b67">[68]</ref>. For instance, Coates et al. <ref type="bibr" target="#b67">[68]</ref> makes full use of the matrix sparseness and local receptive field to improve the calculation efficiency for large matrices multiplication. Compare with DistBelief that needs 16 thousand CPU cores to train a large deep learning model with 10 million images and billion parameters, the commodity off-the-shelf high performance computing system achieved almost training efficiency (e.g., about 3 days) for training the same model on three computers.</p><p>FPGA-based approaches have also explored for large-scale deep learning models in recent years <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b69">70]</ref>. Chen and Lin reviews the recent progress in large-scale deep learning frameworks in <ref type="bibr" target="#b7">[8]</ref>.</p><p>Generally, large-scale deep learning models can only be trained in high-performance computing servers which are equipped with multiple CPU cores or GPUs, limiting the application of such models on low-end devices. Based on the recent researches indicating that the parameters of large-scale deep learning models especially with fully-connected layers are of high redundance, some methods have been presented to improve the training efficiency by compressing the parameters significantly without a large accuracy drop.</p><p>One typical and straightforward method for compressing deep learning models is the use of a low-rank representation of the parameter matrices <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref>. For example, Sainath et al. <ref type="bibr" target="#b71">[72]</ref> applied the low-rank factorization to a deep neural network with 5 hidden layers for speech recognition. Specially, they decomposed the last weight matrix into two smaller matrices to compress the parameters significantly since more than half of the parameters are included in the final layer in the deep learning models for speech recognition. In detail, A is denoted as the weight matrix and A is m × n-dimensional with the rank of r. Sainath et al. <ref type="bibr" target="#b71">[72]</ref> decomposed A into B and C, namely = × A B C, which are of dimension with m × r and r × n, respectively. Obviously, if + &lt; mr rn mn, the parameters of the deep learning model are com- pressed. Furthermore, if we want to compress the parameters of the final layer by a factor of p, the following condition must be satisfied.</p><formula xml:id="formula_30">&lt; + r pmn m n . (<label>17</label></formula><formula xml:id="formula_31">)</formula><p>The low-rank factorization of the deep learning model is able to constrain the space of search directions, which is helpful to optimize the objective function more efficiently. Some experiments indicated that they could reduce the number of parameters of the deep learning models up to 50% which leads to about 50% speedup without a large loss of accuracy.</p><p>Chen et al. <ref type="bibr" target="#b73">[74]</ref> employed the Hashing Trick to compress large-scale deep learning models. In detail, they employed a hash function to gather the network connections into several hash groups randomly and the connections in one group share the weights. Fig. <ref type="figure" target="#fig_8">11</ref> shows one example of a network with one hidden layer <ref type="bibr" target="#b73">[74]</ref>.</p><p>In the neural network in Fig. <ref type="figure" target="#fig_8">11</ref>, the connections between the input layer and the hidden layer are represented by V 1 while the connections between the hidden layer and the output layer are represented by V 2 . With a hash function h l ( • , • ) that projects an index (i, j) to a natural number, the item V ij l is assigned into an item of w l indexed by h l (i, j):</p><formula xml:id="formula_32">= V w . ij l h i j l ( , ) l (18)</formula><p>Thus, the connections can be gathered into 3 groups. Furthermore, the connections marked by the same color share the same weights that are denoted as w 1 and w 2 . Therefore, the parameters of the neural network in Fig. <ref type="figure" target="#fig_8">11</ref> are compressed to 1/4, i.e., 24 parameters are denoted by 6 parameters. Experiments demonstrated that this approach could compress the parameters of a neural network by a factor of up to 8 × on MNIST without an accuracy drop.</p><p>More recently, tensor decomposition schemes have been used to compress the parameters of large-scale deep learning models <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b75">76]</ref>. For example, Novikov et al. <ref type="bibr" target="#b74">[75]</ref> proposed a tensorizing learning model based on the tensor-train network. In order to use the tensor-train network to compress the parameters, they converted the neural network to the tensor format. Given a neural network with an N-dimen-</p><formula xml:id="formula_33">sional input ( = ∏ = N n k d k 1</formula><p>) and an M-dimensional hidden layer</p><formula xml:id="formula_34">( = ∏ = M m k d k 1</formula><p>), they defined a bijection = … μ l μ l μ l μ l ( ) ( ( ), ( ), , ( )) l . Similarly, they convert the hidden vector into the tensor format. Furthermore, they convert the weight matrix w ∈ R M × N into the tensor format W using the bijections = … ν t v t v t v t ( ) ( ( ), ( ), , ( ))</p><formula xml:id="formula_35">d 1 2 and = … μ l μ l μ l μ l ( ) ( ( ), ( ), , ( )) d 1 2</formula><p>that projects the index (t, l) of w into the corresponding index of the tensor format W. Afterwards, they convert the weight tensor W into the tensor-train format G:</p><formula xml:id="formula_36">= … = ⋯ w t l W ν t μ l ν t μ l G ν t μ l G ν t μ l ( .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) (( ( ), ( )), , ( ), ( )) [( ( ), ( )] [( ( ), ( )] ,</head><formula xml:id="formula_37">d d d d d 1 1 1 1 1<label>(19)</label></formula><p>where G k [(ν k (t), μ k (l)] denote the core matrices of the tensor-train representation for W, with the index (ν k (t), μ k (l). Therefore, a linear projection = + y wx b in a fully-connected lay can be transformed into the tensor-train form:</p><formula xml:id="formula_38">… = ∑ ⋯ … + … … Y i i i G ν t μ l G ν t μ l X j j B i i ( , , , ) [( ( ), ( )]</formula><p>[( ( ), ( )] ( , , ) ( , , ) .</p><formula xml:id="formula_39">d j j d d d d d 1 2 , ,<label>1 1 2 1 1</label></formula><p>d 1 <ref type="bibr" target="#b19">(20)</ref> This method could reduce the computational complexity of the forward pass and improve the training efficiency in the back-propagation procedure. Table <ref type="table">1</ref> summarizes the computational complexity and storage complexity of an M × N tensor-train layer (TT) compared with the original fully-connected layer (FC) <ref type="bibr" target="#b74">[75]</ref>.</p><p>Besides, Lebdev et al. <ref type="bibr" target="#b75">[76]</ref> employed the canonical polyadic decomposition to compress the parameters of the convolutional neural network and they achieved a significant speedup for the inference time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Deep learning models for heterogeneous data</head><p>A distinct characteristic of big data is its variety, implying that big data is collected in various formats including structured data and unstructured data, as well as semi-structured data, from a large number of sources. Specially, a great number of objects in big datasets are multimodel. For example, a webpage typically contains image and text simultaneously. Another multi-model example is a multimedia object such as a video clip which includes still images, text and audio. Each modality of multi-modal objects has different characteristic with each other, leading to the complexity of heterogeneous data. Therefore, heterogeneous data poses another challenge on deep learning models. Some multi-model deep learning models have been proposed for heterogeneous data representation learning. For example, Ngiam et al. <ref type="bibr" target="#b76">[77]</ref> developed a multi-modal deep learning model for audio-video objects feature learning. Fig. <ref type="figure" target="#fig_1">12</ref> shows the architecture of the multimodal deep learning model.</p><p>Ngiam et al. <ref type="bibr" target="#b76">[77]</ref> used the restricted Boltzmann machines to learn features and representations for audio and video separately. The learned features are concatenated into a vector as the joint representation of the multi-modal object. Afterwards, the joint representation vector is used as the input of a deep auto-encoder model for the tasks of classification or recognition.</p><p>Srivastava and Salakhutdinov developed another multi-model deep learning model, called bi-modal deep Boltzmann machine, for textimage objects feature learning, as presented in Fig. <ref type="figure" target="#fig_10">13</ref>  <ref type="bibr" target="#b77">[78]</ref>.</p><p>In this model, two deep Boltzmann machines are built to learn features for text modality and image modality, respectively. Similarly, the learned features of the text and the image are concatenated into a vector as the joint representation. In order to perform the classification task, the classifier such as the supported vector machine could be trained with the joint representation as input.</p><p>Another multi-modal deep learning model, called multi-source deep learning model, was presented by Ouyang et al. <ref type="bibr" target="#b78">[79]</ref> for human pose estimation. Different from above two multi-model models, the multi-source deep learning model aims to learn non-linear representation from different information sources, such as human body articulation and clothing for human pose estimation. In this model, each information source is used as input of a deep learning model with two hidden layers for extracting features separately. The extracted features are then fused for the joint representation.</p><p>Other representative multi-modal deep learning models include heterogeneous deep neural networks combined with conditional random fields for Chinese dialogue act recognition <ref type="bibr" target="#b79">[80]</ref>, multi-modal deep neural network with sparse group lasso for heterogeneous feature selection <ref type="bibr" target="#b80">[81]</ref> and so on <ref type="bibr" target="#b81">[82]</ref><ref type="bibr" target="#b82">[83]</ref><ref type="bibr" target="#b83">[84]</ref>. Although they have different architectures, their ideas are similar. Specially, multi-modal deep learning models first learn features for single modality and then combine the learned features as the joint representation for each multi-modal object. Finally, the joint representation is used as input of a logical regression layer or a deep learning model for the tasks of classification or recognition.</p><p>Multi-modal deep learning models achieved better performance than traditional deep neural networks such as stacked auto-encoders and deep belief networks for heterogeneous data feature learning. However, they concatenated the learned features of each modality in a linear way, so they are far away effective to capture the complex correlations over different modalities for heterogeneous data. To tackle this problem, Zhang et al. <ref type="bibr" target="#b84">[85,</ref><ref type="bibr" target="#b85">86]</ref> presented a tensor deep learning model, called deep computation model, for heterogeneous data.</p><p>Specially, they designed a tensor auto-encoder by extending the stacked auto-encoder model to the tensor space based on the tensor data representation. In the tensor auto-encoder model, the input layer X, the hidden layer H, and the parameters</p><formula xml:id="formula_40">= θ W b W b { , ; , }<label>(1)</label></formula><p>(1) 2</p><p>(2) are represented by tensors. Besides, tensor distance is used to reveal the complex features of heterogeneous data in the tensor space, which yields a loss function with m training objects of the tensor auto-encoder model:</p><formula xml:id="formula_41">⎜ ⎟ = ∑ − − + ⎛ ⎝ ∑ ∑ ∑ + ∑ ∑ ∑ ⎞ ⎠ = = × × = = = × × = = J θ h x y G h x y W W ( ) [ ( ( ( ) ) ( (<label>)</label></formula><formula xml:id="formula_42">))] ••• ( ) ••• ( ) , TAE m i m W b T W b λ p J J i I i I pi i q I I j J j J qj j 1 1 1 2 , ,<label>2 1 •</label></formula><formula xml:id="formula_43">•• 1 1 ••• (1) 2 1 ••• 1 1 ••• (2) 2 N N N n N N N n 1 1 1 1 1 1 1 1<label>(21)</label></formula><p>where G denotes the metric matrix of the tensor distance and the second item is used to avoid over-fitting. Furthermore, they built a deep computation model by stacking multiple tensor auto-encoder models. Experiments demonstrated that the deep computation model achieved about 2%-4% higher classification accuracy than multi-modal deep learning models for heterogeneous data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Deep learning models for real-time data</head><p>High velocity is another important characteristic of big data, which  requires to analyze big data in real time. Big data is usually collected at a high speed, posing a challenge on big data real-time processing. Unfortunately, most of deep learning models are of high computational complexity since they typically involves a large number of parameters for big data feature learning, especially large-scale deep neural networks. Therefore, it is difficult for traditional deep learning models to learn features and representations for big data in real time.</p><p>In recent years, a lot of incremental learning methods have been presented for high-velocity data feature learning. An kind of incremental learning methods is online learning which only updates the parameters when new objects are arriving with preserving the network structure.</p><p>Fu et al. <ref type="bibr" target="#b86">[87]</ref> presented an incremental back-propagation learning model based on a concept of bound. A validity bound is defined as a range of the weights that represent the knowledge learned by a neural network. To limit the weights in the validity bound in the updating procedure, a scaling factor s is introduced into weight modifications, yielding a learning rule in the kth iteration:</p><formula xml:id="formula_44">= W k s k ηδ k O k Δ ( ) ( ) ( ) ( ), ji j i (<label>22</label></formula><formula xml:id="formula_45">)</formula><p>where η and δ i denote the learning rate and the error gradient of the neuron j, O i denotes the activation level of the neuron Then, s should be set according to:</p><formula xml:id="formula_46">= ⎧ ⎨ ⎩ − ∑ ⎫ ⎬ ⎭ = − s k B p W t ηδ k O k ( ) min 1, [ ( ) Δ ( ) ] ( ) ( ) , j i t k ji j i , 1 1<label>(23)</label></formula><p>where B denotes a pre-defined bound on the weight modification for an object p.</p><p>Fu et al. <ref type="bibr" target="#b86">[87]</ref> applied the bounded weight adjustment to implement an incremental learning model. Specially, weights are not modified to prevent the over-training when the new arriving object is covered by the knowledge of the current network. However, it is difficult to define the bound beforehand since it is sensitive to the previous knowledge. Besides, this method is only suitable for two-layer neural network, so it is difficult to apply the bounded weight modification to the incremental deep learning models. Wan and Banta <ref type="bibr" target="#b87">[88]</ref> proposed an online learning model based on parameters updating. Specially, an incremental autoencoder model was presented by updating the current parameters θ to + θ θ Δ to adapt the new arriving objects. θ denotes the previous knowledge trained on the old objects while Δθ denotes the parameters increment on the new arriving objects. Given a new arriving object, to achieve the goal of adaptation that requires the updated parameters could learn the new objects effective, an objective function J adaptation is defined:</p><formula xml:id="formula_47">= J x x 1 2 Δ ΩΔ , adaptation T<label>(24)</label></formula><p>where Ω denotes a weight matrix defined as</p><formula xml:id="formula_48">= ⎛ ⎝ − ⎞ ⎠ ∂ ∂ ∂ ∂ − ( ) ( ) I μ Ω φ x θ θ T φ x θ θ ( , )<label>( , ) 1 and =</label></formula><formula xml:id="formula_49">+ − x φ x θ θ x Δ ( , Δ )</formula><p>denotes the post-reconstruction error.</p><p>To achieve the goal of preservation that requires the updated model could still learn old objects, an objective function J preservation is defined:</p><formula xml:id="formula_50">= J θθ . preservation μ T 1 2 (25)</formula><p>Furthermore, to obtain a tradeoff between adaptation and preservation, the global objective function is defined as: <ref type="figure">Δ</ref> ) .</p><formula xml:id="formula_51">+ = + J x θ θ J J ( ,</formula><p>adaptation preservation <ref type="bibr" target="#b25">(26)</ref> There, the parameters increment Δθ can be obtained by minimizing the above function with regard to the new arriving objects.</p><p>Online learning methods are efficient for big data feature learning since they do not need to re-train the parameters on the old training objects <ref type="bibr" target="#b88">[89]</ref><ref type="bibr" target="#b89">[90]</ref><ref type="bibr" target="#b90">[91]</ref>. This scheme is particularly suitable for big data because the data size is too big to hold in the memory. However, this strategy usually preforms poor for dynamic big data whose distribution is changing drastically over time.</p><p>To tackle this problem, another kind incremental learning method based on the structural modification has been presented. For example, a structure-based incremental auto-encoder model was implemented by adding one or more neurons into the hidden layer to adapt new arriving objects <ref type="bibr" target="#b91">[92]</ref><ref type="bibr" target="#b92">[93]</ref><ref type="bibr" target="#b93">[94]</ref>. Fig. <ref type="figure" target="#fig_11">14</ref> shows an example of this model with adding only one neuron.</p><p>After the network structure is modified, the parameters should be also updated accordingly.</p><formula xml:id="formula_52">Let = θ W b W b { , ; , }<label>(1) (1) (2)</label></formula><p>( 2) represent the parameters of a neural network with n-dimensional input an m-dimensional hidden layer. Thus, the parameters have the forms:</p><formula xml:id="formula_53">∈ ∈ ∈ ∈ × × W R b R W R b R . m n m n m n (1)<label>(1) (2) (2) (27)</label></formula><p>If only one neuron is added into the hidden layer, the weight matrices W (1) and W (2) add one row and one column, respectively. Also, the bias vector b (1) adds one element. Therefore, the parameters forms are updated as:</p><formula xml:id="formula_54">∈ ∈ + ∈ ∈ + × × + W R b Rm W R b R 1)</formula><p>.</p><formula xml:id="formula_55">m n n m n (1) ( 1)<label>(1) ( (2) ( 1)</label></formula><p>(2) <ref type="bibr" target="#b27">(28)</ref> If p new neurons are added into the hidden layer, the initial parameters are set to:</p><formula xml:id="formula_56">⎜ ⎟ ′ = ⎛ ⎝ ⎜ ⎜ ⎜ ⎞ ⎠ ⎟ ⎟ ⎟ = ⎛ ⎝ ⎜ ⎜ ⎜ ⎞ ⎠ ⎟ ⎟ ⎟ ′ = ⎛ ⎝ ⎞ ⎠ W W p b b p W p W 0 0 0 0 0 0 ( )<label>( ) ( ) .</label></formula><p>(</p><p>(1)</p><formula xml:id="formula_58">(2) (2)<label>(29)</label></formula><p>Furthermore, the final parameters can be trained by the learning algorithms such as the back-propagation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Deep learning models for low-quality data</head><p>Another emerging challenge for big data feature learning arises from its veracity. Specially, low-quality data is prevalent in big data, implied by the fact that there are a large number of incomplete objects, noise, inaccurate objects, imprecise objects and redundant objects in big data. Low-quality data is resulted from many reasons. For example, a large amount of data is collected from sensors. If some sensors are broken, we may collect some incomplete objects. The transmission fault of the network may also result in some noise in big data. The topics about big data quality have been studied in literatures <ref type="bibr" target="#b94">[95]</ref><ref type="bibr" target="#b95">[96]</ref><ref type="bibr" target="#b96">[97]</ref><ref type="bibr" target="#b97">[98]</ref>.</p><p>Most of deep learning models do not take low-quality data into account. In other words, most of deep learning models are designed for high-quality data feature learning. In the past few years, some methods have been proposed to learn features for low-quality data. Vincent et al. [99] presented a denoising auto-encoder model which could learn features and representations for data with noise. Specially, the denoising auto-encoder model trains the parameters by reconstructing the original input from the corrupted input, as shown in Fig. <ref type="figure" target="#fig_4">15</ref>.</p><p>To reconstruct the original input, the objective function of the denoising auto-encoder model is defined as:</p><formula xml:id="formula_59">∑ = J E Lx g f x [ ( , ( ( )))], ͠ t q x x t θ θ ( ) ( ) t ( )<label>(30)</label></formula><p>where x͠ denote the corrupted instances of the original input x (t) based on the corruption process q x x ( ) ͠ t ( ) and E</p><formula xml:id="formula_60">[•] q x x ( ) t ( )</formula><p>averages over the instances x͠ .</p><p>The parameters of the objective function can be trained by the gradient descent strategy. x͠ can be obtained by adding isotropic Gaussian noise or pepper noise. Furthermore, Vincent et al. <ref type="bibr" target="#b99">[100]</ref> developed stacked denoising auto-encoder models for feature learning on data with noise.</p><p>Zhang et al. <ref type="bibr" target="#b100">[101]</ref> proposed an imputation auto-encoder model to learn features for incomplete objects, as shown in Fig. <ref type="figure" target="#fig_0">16</ref>.</p><p>The simulated incomplete object x′ is obtained by setting a part of attributes values of the original object x to 0. The imputation autoencoder model takes the incomplete object x′ as input and output the reconstructed object z:</p><formula xml:id="formula_61">= z g f x ( ( )).</formula><p>θ θ <ref type="bibr" target="#b30">(31)</ref> The parameters θ are trained by minimizing the following objective function:</p><formula xml:id="formula_62">= J L x z ( , ).<label>(32)</label></formula><p>Furthermore, they built a deep imputation network for incomplete objects feature learning by stacking several imputation auto-encoders, as presented in Fig. <ref type="figure" target="#fig_14">17</ref>.</p><p>More recently, Wang and Tao presented a non-local auto-encoder to learn reliable features for corrupted data <ref type="bibr" target="#b101">[102]</ref>. Their work is motivated by the neurological observation that similar input should stimulate human brains to produce the similar response. Therefore, the neural networks should yield similar hidden representations for the similar input objects. In detail, suppose that h 1 , h 2 and h 3 are the learned representations of x 1 , x 2 and x 3 , respectively. If </p><formula xml:id="formula_63">− &lt; − x x x x , 1 2 1 3 − h h</formula><formula xml:id="formula_64">∑ − ω h h , i i i p<label>(33)</label></formula><p>where ω i denotes the weight of the ith corrupted instance. The objective function of the non-local auto-encoder model can be obtained by applying the regularization term:</p><formula xml:id="formula_65">∑ = − + − J x g f x λ ω h h ( ( )) . θ θ i i i p 2 2<label>(34)</label></formula><p>Experiments demonstrated that the non-local auto-encoder model achieved super performance in image denoising and restoration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Summary and perspectives</head><p>Deep learning is currently the most active topic of machine learning. In recent years, deep learning models have been widely used in many fields such as computer vision, health monitoring and natural language processing. The explosion of big data offers enough training objects, which helps to improve the performance of deep learning. Furthermore, high-performance computing devices and architectures such as graphic processing units and CPU cluster enable the training of large-scale deep learning models for big data feature leaning. Today, deep learning models enjoy the success with a great many parameters, typically millions of parameters, together with a large number of training objects. While big data brings enough training objects, it also poses some challenges on deep learning. Therefore, in the past few years, many deep learning models have been developed for big data learning. In this paper, we provide a survey of big data deep learning models. Big data is typically defined by the four V's model: volume, variety, velocity and veracity, which implies huge amount of data, various types of data, real-time data and low-quality data, respectively. Therefore, we summarized the deep learning models for big data learning from four aspects accordingly. In detail, we reviewed large-scale deep learning models for huge amount of data, multi-modal deep learning models and deep computation models for heterogeneous data, incremental deep learning models for real-time data, and reliable deep learning models for low-quality data. From the previous studies, we can see that deep learning models have made a great progress in big data feature learning. However, big data deep learning is still in its infancy, i.e.,  there are still some remaining challenges to be addressed for big data learning.</p><p>First and foremost, some large-scale deep learning models with millions or billions of free parameters have been trained to learn features for high volumes of data, which uses CPU clusters and GPUs to improve the training efficiency. Besides, some parallelizing schemes including data parallelism and model parallelism also contribute to the training of large-scale deep learning models. For instance, high volumes of data that cannot be loaded into memory are partitioned into blocks for parallel training while the back-propagation is run in parallel on multiple CPU cores. Therefore, some success have been achieved for large-scale deep learning models to address the challenges about huge amounts of data. However, the scale of current deep learning models that can be trained for big data is significantly depending on the growth of the high-performance computing architectures such as CPU clusters and GPUs. Unfortunately, the gain in computational performance is lagging far behind the growth rate of big data. Therefore, with the continuing growth of big data, much more large-scale deep learning models are needed to be built. Such large models with big data may no longer be trained effective depending on current techniques and computing power. So, one future direction to address this issue is to develop new learning frameworks and computing infrastructures. In addition, how to compress the large-scale deep learning models without scarifying accuracy further is another research direction for big data feature learning.</p><p>Secondly, two advanced deep learning models, i.e., multi-modal deep learning model and deep computation model, have been developed for heterogeneous data feature learning. Multi-modal deep learning modes extract the features for each modality separately and then concatenate the extracted features as the joint representation of the heterogeneous objects. Afterwards, the joint representation is used as the input of the specified deep learning model for the tasks of classification and recognition. Deep computation models utilize tensors to represent the heterogeneous objects for extending the stacking autoencoders to the tensor space. Deep computation models enjoy their success with the tensor-based big data representation methods that can reveal the correlations over different modalities. However, most of current multi-modal deep learning models focus on bi-modal data. Most objects in big data have more than two modalities such as a video clip that usually contains three modalities, i.e., image, audio and text. Besides, current multi-modal deep learning models concatenate learned features of each modality in a simply linear way, which often results in a poor result. Therefore, exploring effective fusion methods for learned features to improve the multi-modal deep learning models is a future direction. While deep computation models achieve super performance than multi-modal deep learning models, they include much more parameters, leading to a high computational complexity. How to reduce the computational complexity of deep computation models needs to be addressed.</p><p>While deep learning models for large volumes of data and heterogeneous data have made a great progress, only a limited progress on incremental deep learning models for high velocity of data has been made in the past few years. Some incremental learning algorithms based on parameters updating or structure updating have been proposed to adapt the new arriving objects. Most of these algorithms have been proved effective for traditional learning models with only one hidden layer. It is less clear, however, whether they can be applied to deep learning models and how they can be applied to deep architectures. For the structure-based incremental learning methods that modify the network structure by adding one or more neurons into the hidden layer, how many neurons should be added every time? Furthermore, the continuous incorporation of new neurons in the hidden layer will lead to a high redundancy of the network. So, how to optimize the network structure is another future work.</p><p>Last but not least, only several reliable deep learning models have been proposed to learn features and representations for low-quality data. Furthermore, they focus on only noisy data or incomplete data feature learning. Except for noisy objects and incomplete objects, there are a large number of redundant objects, imprecise objects and outdated objects in big data. With an explosive increase of low-quality data, reliable deep learning models for low-quality data need to be explored urgently.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Basic auto-encoder.</figDesc><graphic url="image-4.png" coords="2,65.42,638.14,195.60,91.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Functional graph of non-linear activation functions.</figDesc><graphic url="image-5.png" coords="2,350.14,56.81,164.16,176.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Stacked auto-encoder for pre-training.</figDesc><graphic url="image-6.png" coords="3,57.32,56.81,211.68,141.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Stacked auto-encoder for fine-tuning.</figDesc><graphic url="image-7.png" coords="3,54.03,522.60,218.40,206.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Restricted Boltzmann machine.</figDesc><graphic url="image-8.png" coords="3,342.14,56.81,180.00,164.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 . 8 .</head><label>678</label><figDesc>Fig. 6. Deep belief network.</figDesc><graphic url="image-9.png" coords="4,50.06,56.81,226.32,135.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Example of DistBelief with four blocks.</figDesc><graphic url="image-13.png" coords="5,326.55,56.81,211.20,142.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>coordinates of the input vector b and the coordinate of the corresponding tensor B, respectively. Therefore, the input tensor B can be obtained by =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Example of a neural network which is compressed by the trick.</figDesc><graphic url="image-14.png" coords="6,320.60,56.81,223.20,141.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Table 1 Fig. 12 .</head><label>112</label><figDesc>Fig. 12. Architecture of the multi-modal deep learning model.</figDesc><graphic url="image-15.png" coords="7,57.15,545.84,212.16,183.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Architecture of the bi-modal deep Boltzmann machine.</figDesc><graphic url="image-16.png" coords="7,320.20,56.81,223.92,118.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Structure-based incremental learning method with adding one hidden neuron.</figDesc><graphic url="image-17.png" coords="8,323.77,56.81,216.96,131.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>networks use the non-linear function such as the Sigmoid function as activation function. To learn reliable representations, Wang and Tao presented a regularization term and added the regularization term into the objective function. Given a training object x, some corrupted instances x i can be obtained by adding the noise into x. Let h and h i denote the learned hidden representations of x and x i , respectively. The regularization term is defined as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .Fig. 16 .</head><label>1516</label><figDesc>Fig. 15. Denoising auto-encoder.</figDesc><graphic url="image-18.png" coords="9,53.12,56.81,220.08,113.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Deep imputation network.</figDesc><graphic url="image-20.png" coords="9,324.91,56.81,214.56,163.35" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An integration framework on cloud for cyber physical social systems big data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCC.2015.2511766</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cloud Comput</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Communication energy modeling and optimization through joint packet size analysis of BSN and wifi networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1741" to="1751" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data-intensive applications, challenges, techniques and technologies: a survey on big data</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="314" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Data mining with big data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="107" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Social big data: recent achievements and new challenges</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orgaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Camacho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="45" to="59" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A framework for composition and enforcement of privacy-aware and context-driven authorization mechanism for multimedia big data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sarfraz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Haseeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basalamah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghafoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1484" to="1494" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Data quality: the other face of big data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Data Engineering</title>
				<meeting>IEEE International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1294" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Big data deep learning: challenges and perspectives</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="514" to="525" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Representation learning: a review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: an overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large-scale deep unsupervised learning using graphics processors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
				<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="873" to="C880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09039</idno>
		<title level="m">Efficient processing of deep neual networks: a tutoria and survey</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Application of deep learning to compuer vision: a comprehensive study</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M S</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shoyaib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Informatics, Electronics and Vision</title>
				<meeting>International Conference on Informatics, Electronics and Vision</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="592" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep hierarchies in the primate visual cortex: what can we learn for computer vision</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kalkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lappe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Rodriguez-Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1847" to="1871" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">New types of deep neual network learning for speech recognition and related applications: an overview</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multitask learning of deep neural networks for low-resource speech recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Mak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1172" to="1183" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning-based document modeling for personality detection from text</title>
		<author>
			<persName><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="74" to="79" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Training word embeddings for deep learning in biomedical text mining tasks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Bioinformatics and Biomedicine</title>
				<meeting>IEEE International Conference on Bioinformatics and Biomedicine</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="625" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spark based distributed deep learning framework for big data applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khumoyun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hanku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Information Science and Communications Technologies</title>
				<meeting>International Conference on Information Science and Communications Technologies</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mobile big data analytics using deep learning and apache spark</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Netw</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Big data and deep learning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Wilamowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Korniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Jubilee International Conference on Intelligent Engineering Systems</title>
				<meeting>IEEE Jubilee International Conference on Intelligent Engineering Systems</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Extracting deep bottleneck features using stacked auto-encoders</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Metze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning cascaded deep auto-encoder networks for face alignment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2066" to="2078" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unseen noise estimation using separable deep auto encoder for speech enhancement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Hmme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="104" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Measuring invariances in deep networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of Neural Information and Processing System</title>
				<meeting>eeding of Neural Information and essing System</meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="646" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Sparse autoencoder, CS294A Lecture notes</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning algorithms for the classification restricted boltzmann machine</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="643" to="669" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Restricted boltzmann machines for collaborative filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine learning</title>
				<meeting>International Conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improved learning of gaussian-bernoulli restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ilin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference in Artificial Neural Networks</title>
				<meeting>International Conference in Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="10C" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral image based on deep belief networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Image Processing</title>
				<meeting>IEEE International Conference on Image Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="5132" to="5136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An improved bilinear deep belief network algorithm for image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computational Intelligence and Security</title>
				<meeting>International Conference on Computational Intelligence and Security</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="189" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Acoustic modeling using deep belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="22" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep belief networks based voice activity detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="697" to="710" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep architecture for traffic flow prediction: deep belief networks with multitask learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2191" to="2201" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Application of deep belief networks for natural language understanding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deoras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="778" to="784" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Large-scale video classification with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for large-scale remote-sensing image classification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Maggiori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Charpiat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alliez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="645" to="657" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for predominant instrument recognition in polyphonic music</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="208" to="221" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
				<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">X</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.07640</idno>
		<title level="m">Deep learning and its applications to machine health monitoring: a survey</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A convolutional neural network for modeling sentences</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.2188</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A multichannel convolutional neural network for cross-language dialog state tracking</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ushio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamagami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Horii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Spoken Language Technology Workshop</title>
				<meeting>IEEE Spoken Language Technology Workshop</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="559" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Applying convolutional neural networks concepts to gybrid NN-HMM model for speech recognition</title>
		<author>
			<persName><forename type="first">O</forename><surname>Abdel-Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="4277" to="4280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Very deep convolutional neural networks for noise robust speech recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2263" to="2276" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for speech recognition</title>
		<author>
			<persName><forename type="first">O</forename><surname>Abdel-Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1533" to="1545" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for distant speech recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Swietojanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1120" to="1124" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1725" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning to torget: continual prediction with istm</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning precise timing with istm recurrent networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="115" to="143" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">3555</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">CUED-RNNLM-an opensource toolkit for efficient training and evaluation of recurrent neural network language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J F</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="6000" to="6004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Integrating prosodic information into recurrent neual network language model for speech recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Asia-Pacific Signal and Information Processing Association Annual Summit and Conference</title>
				<meeting>Asia-Pacific Signal and Information Processing Association Annual Summit and Conference</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1194" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Recurrent neural network language model for english-indonesian machine translation: Experimental study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hermanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Adji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Setiawan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Science in Information Technology</title>
				<meeting>International Conference on Science in Information Technology</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="132" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">End-to-end online writer identification with recurrent neural network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Hum. Mach. Syst</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="285" to="292" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bayesian recurrent neural network for language modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="374" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Scalable stacking and learning for building deep architectures</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2133 C2136</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Tensor deep stacking networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1944" to="1957" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Large scale distributed deep networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
				<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1223" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Multilingual acoustic models using distributed deep neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="8619" to="8623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Asynchronous stochastic optimization for sequence training of deep neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bacchiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="5587" to="5591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Improving the speed of neural networks on CPUs</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Deep Learning and Unsupervised Feature Learning Workshop, MIT</title>
				<meeting>Deep Learning and Unsupervised Feature Learning Workshop, MIT</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, gibbs distributions, and the bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Explaining the gibbs sampler</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Stat</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="174" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deep learning with COTS HPC systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1337" to="1345" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Optimizing FPGA-based accelerator design for deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM/ SIGDA International Symposium on Field-Programmable Gate Arrays</title>
				<meeting>ACM/ SIGDA International Symposium on Field-Programmable Gate Arrays</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="161" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">DLAU: a scalable deep learning accelerator unit on FPGA</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput. Aided Des. Integr. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="513" to="517" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Predicting parameters in deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shakibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
				<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2148" to="2156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Low-rank matrix factorization for deep neural network training with high-dimensional output targets</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Arisoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramabhadran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference of Acoustics, Speech, and Signal Processing</title>
				<meeting>IEEE International Conference of Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6655" to="C6659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Restructuring of deep neural network acoustic models with singular value decomposition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference of the International Speech Communication Association</title>
				<meeting>Conference of the International Speech Communication Association</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2365" to="C2369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Compressing neural networks with the hashing trick</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
				<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2285" to="C2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Tensorizing neural netwroks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Novikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Osokin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
				<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="442" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Speeding-up convolutional neural networks ssing fine-tuned CP-decomposition</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lebedev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rakhuba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oseledets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno>1412.6553</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Multimodal deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
				<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Multimodal learning with deep boltzmann machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
				<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2222" to="2230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Multi-source deep learning for human pose estimation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2337" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Combining heterogeneous deep neural networks with conditional random fields for chinese dialogue act recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="page" from="408" to="417" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Heterogeneous feature selection with multi-modal deep neural networks and sparse group LASSO</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1936" to="1948" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Large-margin multi-modal deep learning for RGB-d object recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1887" to="1898" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Moddrop: adaptive multi-modal gesture recognition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nebout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1692" to="1706" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">MDL-CW: a multimodal deep learning framework with crossweights</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rastegar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Baghshah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shojaee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2601" to="2609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Deep computation model for unsupervised feature learning on big data</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Serv. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="161" to="171" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Privacy preserving deep computation model on cloud for big data feature learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1351" to="1362" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Incremental backpropagation learning networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Principe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="757" to="761" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Parameter incremental learning algorithm for neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Banta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1424" to="1438" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Online learning and online convex optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="194" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Simnest: social media nested epidemic simulation via online semi-supervised deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Data Mining</title>
				<meeting>IEEE International Conference on Data Mining</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Integrating online and offline threedimensional deep learning for automated polyp detection in colonoscopy videos</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Incremental updating method for big data feature learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Eng. Appl</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="21" to="26" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Incremental learning in nonstationary environments with controlled forgetting</title>
		<author>
			<persName><forename type="first">R</forename><surname>Elwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Polikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Neural Networks</title>
				<meeting>International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="771" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="5880" to="5884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">The meaningful use of big data: four perspectives -four challenges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Boncz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Brodie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Erling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="56" to="60" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Data quality management, data usage experience and acquisition intention of big data analytics</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Inf. Manage</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="394" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Big data, big data quality problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Big Data</title>
				<meeting>IEEE International Conference on Big Data</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2644" to="2653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Big data quality: a roadmap for open data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ciancarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Poggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Russo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Big Data Computing Service and Applications</title>
				<meeting>IEEE International Conference on Big Data Computing Service and Applications</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="210" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine learning</title>
				<meeting>International Conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Incomplete big data impputation algorithm based on deep learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microelectr. Comput</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="173" to="176" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Non-local auto-encoder with collaborative stabilization for image restoration</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2117" to="2129" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
