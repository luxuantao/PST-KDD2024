<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interpretable &amp; Time-Budget-Constrained Contextualization for Re-Ranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Markus</forename><surname>Zlabinger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
						</author>
						<title level="a" type="main">Interpretable &amp; Time-Budget-Constrained Contextualization for Re-Ranking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Search engines operate under a strict time constraint as a fast response is paramount to user satisfaction. Thus, neural reranking models have a limited time-budget to re-rank documents. Given the same amount of time, a faster re-ranking model can incorporate more documents than a less efficient one, leading to a higher effectiveness. To utilize this property, we propose TK (Transformer-Kernel): a neural re-ranking model for ad-hoc search using an efficient contextualization mechanism. TK employs a very small number of Transformer layers (up to three) to contextualize query and document word embeddings. To score individual term interactions, we use a document-length enhanced kernel-pooling, which enables users to gain insight into the model. TK offers an optimal ratio between effectiveness and efficiency: under realistic time constraints (max. 200 ms per query) TK achieves the highest effectiveness in comparison to BERT and other re-ranking models. We demonstrate this on three large-scale ranking collections: MSMARCO-Passage, MSMARCO-Document, and TREC CAR. In addition, to gain insight into TK, we perform a clustered query analysis of TK's results, highlighting its strengths and weaknesses on queries with different types of information need and we show how to interpret the cause of ranking differences of two documents by comparing their internal scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The importance of efficient and fast search engines is well established <ref type="bibr" target="#b18">[19]</ref>. Therefore, the time spent on each part of the Information Retrieval (IR) pipeline has to be managed with time-constraints. Naturally, re-ranking models, which improve the effectiveness of initial rankings, need to stay within a certain time-budget to be deployable to a user facing search engine. In recent years neural network based re-ranking models matured and a distinct trade-off emerged between a neural re-ranking model's effectiveness and its efficiency. While IR-specific networks are reasonably fast <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b14">15]</ref>, large Transformer based models <ref type="bibr" target="#b31">[32]</ref>, such as BERT <ref type="bibr" target="#b5">[6]</ref>, show substantially better effectiveness at the cost of orders of magnitude longer inference time <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref>. Given the same amount of limited time, a faster reranking model can incorporate more documents than a less efficient one, leading to a higher effectiveness.</p><p>In this paper, we present TK -an interpretable neural re-ranking model for ad-hoc retrieval with a focus on a good ratio between efficiency and effectiveness, which is particularly suited for a timeconstrained environment. TK is short for Transformer-Kernel -the two main components of our model (Section 3).</p><p>TK brings two main contributions in terms of efficiency and explainability. First, we show how a small number of lightweight Trans-1 TU Wien, Austria, email: s.hofstaetter@tuwien.ac.at 2 TU Wien, Austria, email: markus.zlabinger@tuwien.ac.at 3 TU Wien, Austria, email: hanbury@ifs.tuwien.ac.at former layers <ref type="bibr" target="#b31">[32]</ref> (we evaluate up to three) can effectively contextualize query and document word embeddings. TK's second contribution is a network structure built for explainability. In contrast to BERT-based approaches, we contextualize query and document sequences independent from each other and distill the interactions between terms in a single interaction match matrix, followed by softhistogram scoring based on kernel-pooling <ref type="bibr" target="#b35">[36]</ref>. This allows us to explain scoring reasons by probing the model at the point of the information bottleneck to analyze contextualized term representations and interaction patterns.</p><p>We conduct experiments on three large retrieval collections: MSMARCO-Passage <ref type="bibr" target="#b1">[2]</ref>, MSMARCO-Document <ref type="bibr" target="#b1">[2]</ref>, and TREC CAR 2017 <ref type="bibr" target="#b6">[7]</ref>. We evaluate a broad range of traditional and neural ranking models. We introduce time-budget aware evaluation, which varies the re-ranking depth according to the available time and speed of each neural model. Our experiments show that TK is the best model choice for an average re-ranking budget per query under 200 ms for MRR, 500 ms for Recall, and 250 ms for nDCG. At 100 ms per query TK's MRR is 10% higher, Recall is 40% higher, and nDCG is 19% higher than BERT (Section 5).</p><p>To further understand our novel model, we conduct a query-level analysis of TK's effectiveness and explain the cause of ranking differences of two documents. We cluster queries based on their contextualized embeddings and inspect the cluster's median reciprocal rank. This allows us to robustly identify the strengths and weaknesses of our model on different types of the user's information need (Section 5.3). We demonstrate the interpretation capability of the TK model using the scenario in which a user would like to understand, for a given query, why two documents are ranked differently. We visualize word-level similarities (interaction features) and we report intermediate results of important kernels (Section 6).</p><p>We publish the source code of our work at github.com/sebastianhofstaetter/transformer-kernel-ranking. The repository contains all pre-processing and evaluation code, as well as clear and documented neural network implementations using PyTorch <ref type="bibr" target="#b26">[27]</ref> and Al-lenNLP <ref type="bibr" target="#b9">[10]</ref>.</p><p>In summary, the main contributions of this work are as follows:</p><p>• We propose TK: a re-ranking model using contextualized representations for time-constrained applications.</p><p>-Efficiency: We show that a small number of low-dimensional Transformers contextualize efficiently and effectively. -Interpretability: TK's architecture allows to extract and analyze the full information flow at a single point • We introduce time-budget &amp; re-ranking depth aware evaluation of neural IR models. • We conduct a robust query-level analysis and demonstrate the interpretability of TK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2002.01854v1 [cs.IR] 4 Feb 2020</head><p>The short history of neural re-ranking models already saw three waves of architectures: representation, interaction, and contextualized interaction models <ref type="bibr" target="#b10">[11]</ref>. The first representation-focused neural IR models unsuccessfully tried to match single vector representations per query and document <ref type="bibr" target="#b20">[21]</ref>. Then, interaction-focused models moved to a more fine-grained modelling of query-document interactions based on a match-matrix. Now, contextualization in various forms offers the most effective approaches. The core of interaction approaches are term by term similarities. A key success factor are fine-tuned word representations, covering most of the indexed vocabulary <ref type="bibr" target="#b12">[13]</ref>. Various approaches exist to reduce the match-matrix of term similarities to the matching score: using stacked Convolutional Neural Networks (CNN) <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b21">22]</ref>, parallel single-layered CNNs for n-gram interaction modelling <ref type="bibr" target="#b14">[15]</ref>, recurrent neural networks <ref type="bibr" target="#b7">[8]</ref>, and position independent counting methods. Guo et al. <ref type="bibr" target="#b10">[11]</ref> showed the promise of counting interactions with the histogram-based DRMM model. However, it suffered from the non-differentability of a hard histogram method and the resulting lack of fine-tuned word representations. Xiong et al. <ref type="bibr" target="#b35">[36]</ref> improve on the idea and propose the kernel-pooling technique as part of the KNRM model. Conceptually, it approximates a histogram with a set of Gaussian kernel functions for different similarity ranges instead of a hard binning. The kernel-pooling offers a solid foundation for analysis and interpretability <ref type="bibr" target="#b29">[30]</ref>, whereas pattern-based methods are harder to interpret post-hoc <ref type="bibr" target="#b8">[9]</ref>.</p><p>Contextualization allows neural IR models to vary the importance of otherwise identical term matches. The neural CO-PACRR model <ref type="bibr" target="#b15">[16]</ref> provides a lightweight contextualization. It averages word vectors with a sliding window and appends their similarities to the noncontextualized similarities of the PACRR <ref type="bibr" target="#b14">[15]</ref> model. The CONV-KNRM model <ref type="bibr" target="#b4">[5]</ref> extends KNRM by adding a CNN layer on top of the word embeddings, enabling word-level n-gram representation learning -a local contextualization, fixed by the n-gram size hyperparameter.</p><p>Vaswani et al. <ref type="bibr" target="#b31">[32]</ref> proposed the Transformer architecture in the context of language translation. Their encoder-decoder is built of Transformer layers, each containing multi-head self attention. These Transformer layers are the building blocks of versatile multi-task architectures, such as BERT <ref type="bibr" target="#b5">[6]</ref> and XLNet <ref type="bibr" target="#b38">[39]</ref>. These models rely on a computationally intensive pre-training. Publicly available pretrained models can then be fine-tuned for various tasks, including pairwise sequence classification. Nogueira et al. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref> first showed the applicability of BERT for re-ranking and the resulting substantial effectiveness gains. MacAvaney et al. <ref type="bibr" target="#b19">[20]</ref> show that it is beneficial to combine BERT's classification label with the output of interactionbased neural IR models. Both note that using BERT comes at a substantial performance cost -BERT taking two orders of magnitude longer than a simple word embedding.</p><p>In traditional learning-to-rank the trade-off between effectiveness and efficiency has been thoroughly studied <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b3">4]</ref>. This includes applying a temporal constraint on the number of features that are selected for a re-ranking model <ref type="bibr" target="#b34">[35]</ref>, incorporating an efficiency metric in the training of linear rankers <ref type="bibr" target="#b33">[34]</ref>, and comparing the effectiveness and efficiency of various learning-to-rank algorithms <ref type="bibr" target="#b3">[4]</ref>. In web search the speed of a response is crucial as determined by Kohavi et al. <ref type="bibr" target="#b18">[19]</ref> in a large scale experiment, however, in some expert tasks, users are willing to wait longer for better results, so that the best model choice becomes task dependent <ref type="bibr" target="#b30">[31]</ref>.</p><p>Recently, the issue of efficiency gained traction in the neural IR community. Hofstätter et al. <ref type="bibr" target="#b11">[12]</ref> establish efficiency baselines for common neural IR models (including BERT) and propose to incorporate speed metrics in replicability campaigns and public leaderboards. One way to make neural IR models faster at query time is to offload computation to the indexing phase, either by assuming query term independence <ref type="bibr" target="#b22">[23]</ref> or by approximating interaction similarities <ref type="bibr" target="#b16">[17]</ref>. When a large number of pre-trained Transformer layers is involved, inference can be sped up by removing later layers and scoring the intermediate results instead <ref type="bibr" target="#b19">[20]</ref> or by pruning unnecessary attention-heads <ref type="bibr" target="#b32">[33]</ref>. In this work we speed up Transformer contextualization by using very small and few Transformer blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TK: Transformer-Kernel Model</head><p>In this section, we present TK, our Transformer-Kernel neural reranking model. In the following, we describe how we learn contextualized term representations (Section 3.1) and how we transparently score their interactions (Section 3.2). Figure <ref type="figure" target="#fig_1">1</ref> gives an overview of the TK architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Contextualized Term Representation</head><p>TK uses a hybrid contextualization approach. The base representations are single-vector-per-word embeddings <ref type="bibr" target="#b27">[28]</ref>. We chose a simple word embedding structure over more complex methods -such as FastText <ref type="bibr" target="#b2">[3]</ref> or ELMo <ref type="bibr" target="#b28">[29]</ref> -as it offers many benefits in practice. Word embeddings are easy to pre-train on domain specific data <ref type="bibr" target="#b13">[14]</ref>. They require only one id per term, making the index consume less disk space, once prepared for re-ranking. Most importantly, at query time, their selection is a fast memory lookup.</p><p>In the contextualization phase of the TK model, we process query q1:m and document sequences d1:n separately, however the learned parameters are shared. The input consists of two sequences of query and document ids. We employ the lookup based word embedding to select non-contextualized representations for each term. The hybridcontextualized representation ti of a term with word embedding ti over its whole input sequence t1:n is defined as:</p><formula xml:id="formula_0">ti = ti * α + context(t1:n)i * (1 − α)<label>(1)</label></formula><p>We regulate the influence of the contextualization by the end-toend learned α parameter. This allows the model to decide the intensity of the contextualization. We calculate the context(t1:n) with a set of Transformer layers <ref type="bibr" target="#b31">[32]</ref>. First, the input sequence is fused with a positional encoding to form p1:n, followed by a set of l Transformer layers:</p><formula xml:id="formula_1">Transformer l (p1:n) = MultiHead(FF(p1:n)) + FF(p1:n) (2)</formula><p>Here, FF is a two-layer fully connected feed-forward layer including a non-linear activation function. The M ultiHead module projects the input sequence (via W * i ) to query, key, and value inputs of the scaled dot-product attention for each attention head. Then the results of the attention heads are concatenated and projected to the output (via W O ):</p><formula xml:id="formula_2">MultiHead(p1:n) = Concat(head1, ..., head h )W O where headi = softmax (p1:nW Q i )(p1:nW K i ) T √ d k (p1:nW V i )</formula><p>(3) We select Transformers for contextualization, because their positional encoding and sequence wide self-attention allows for local and global contextualization at the same time. This makes TK more powerful than previous local-only contextualization methods used in CONV-KNRM <ref type="bibr" target="#b4">[5]</ref> and CO-PACRR <ref type="bibr" target="#b15">[16]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interaction Scoring</head><p>After the contextualization, we match the query sequence q1:m and document sequence d1:n together in a single match-matrix M ∈ R q len ×d len with pairwise cosine similarity as interaction extractor:</p><formula xml:id="formula_3">Mi,j = cos( qi, dj)<label>(4)</label></formula><p>Then, we transform each entry in M with a set of RBF-kernels <ref type="bibr" target="#b35">[36]</ref>. Each kernel focuses on a specific similarity range with center µ k . The size of all ranges is set by σ. In contrast to Xiong et al. <ref type="bibr" target="#b35">[36]</ref> we do not employ an exact match kernel -as contextualized representations do not produce exact matches. Each kernel results in a matrix K ∈ R q len ×d len :</p><formula xml:id="formula_4">K k i,j = exp − (Mij − µ k ) 2 2σ 2<label>(5)</label></formula><p>Now, we process each kernel matrix in parallel, and we begin by summing the document dimension j for each query term and kernel:</p><formula xml:id="formula_5">K k i = j K k i,j<label>(6)</label></formula><p>At this point -as shown in Figure <ref type="figure" target="#fig_1">1</ref> -the model flow splits into two paths: log normalization and length normalization. The log normalization applies a logarithm with base b to each query term before summing them up:</p><formula xml:id="formula_6">s k log = i log b K k i (7)</formula><p>To incorporate the notion of different document lengths into the model we enhance the pooling process with document length normalization. We dampen the magnitude of each query term signal by the document length:</p><formula xml:id="formula_7">s k len = i K k i dlen<label>(8)</label></formula><p>Now, the set of kernel scores (one value per kernel) is weighted and summed up with a simple linear layer (W log , W len ) to produce a scalar, for both the log-normalized and length normalized kernels:</p><formula xml:id="formula_8">slog = s k log W log slen = s k len W len<label>(9)</label></formula><p>Finally, we compute the final score of the query-document pair as a weighted sum of the log-normalized and the length-normalized scores:</p><formula xml:id="formula_9">s = slog * β + slen * γ<label>(10)</label></formula><p>We employ kernel-pooling, because it makes inspecting temporary scoring results more feasible compared to pattern based scoring methods (for example PACRR <ref type="bibr" target="#b14">[15]</ref>). Each kernel is applied to the full document and the row-wise and the column-wise summing of the match-matrix allow to inspect individual matches independent from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Difference to Related Work</head><p>The main differences of TK in comparison to BERT <ref type="bibr" target="#b23">[24]</ref> are:</p><p>• TK's contextualization uses fewer and lower dimensional Transformer layers with less attention heads. This makes the query-time inference of TK with 2 layers 40 times faster than BERT-Base with 12 layers. • TK contextualizes query and document sequences independently; each contextualized term is represented by a single vector (available for analysis). BERT operates on a concatenated sequence of the query and the document, entangling the representations in each layer. • The network structure of TK makes it possible to analyze the model for interpretability and further studies. TK has an information bottleneck built in, through which all term information is distilled: the query and document term interactions happen in a single match matrix, containing exactly one cosine similarity value for each term pair. BERT on the other hand has a continuous stream of interactions in each layer and each attention head, making a focused analysis unfeasible.</p><p>The differences of TK to previous kernel-pooling methods are:</p><p>• KNRM <ref type="bibr" target="#b35">[36]</ref> uses only word embeddings, therefore a match does not have context or positional information. • CONV-KNRM <ref type="bibr" target="#b4">[5]</ref> uses a local-contextualization with limited positional information in the form of n-gram learning with CNNs. It cross-matches all n-grams in n 2 match matrices, reducing the analyzability.</p><p>For the first stage indexing and retrieval we use the Anserini toolkit <ref type="bibr" target="#b37">[38]</ref> to compute baselines as well as the initial ranking lists, which we use to generate training and evaluation inputs for the neural models. For our neural re-ranking training and inference we use PyTorch <ref type="bibr" target="#b26">[27]</ref> and AllenNLP <ref type="bibr" target="#b9">[10]</ref>. For BERT support we use the pytorch-transformer library <ref type="foot" target="#foot_0">4</ref> . We train all neural models with a pairwise hinge loss. We conduct our experiments and report timings with an NVIDIA GTX 1080 TI (11GB memory) GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baselines</head><p>We use tuned BM25, Language Modelling with Dirichlet smoothing (LM), and RM3 <ref type="bibr" target="#b0">[1]</ref> as traditional retrieval method baselines. In the following we give an overview over our neural baselines:</p><p>MatchPyramid <ref type="bibr" target="#b25">[26]</ref> applies several stacked CNN layers with max-pooling on top of a term-by-term interaction matrix. The pooling sizes become smaller with each layer -like a pyramid.</p><p>DUET <ref type="bibr" target="#b21">[22]</ref> is a hybrid model which applies CNNs to local termby-term interactions and it learns a single representation for query and document and then measures the similarity between the two vectors. The two paths are combined an jointly scored.</p><p>PACRR <ref type="bibr" target="#b14">[15]</ref> applies different sized CNNs on the match matrix followed by a max pooling. In contrast to MatchPyramid, the single CNN layer focuses on different n-gram sizes.</p><p>CO-PACRR <ref type="bibr" target="#b15">[16]</ref> extends the PACRR model with additional contextualized similarities (via fixed window neighborhood mean vectors) and improves the robustness of PACRR's pooling strategy with randomization during training.</p><p>KNRM <ref type="bibr" target="#b35">[36]</ref> uses a soft-histogram (differentiable Gaussian kernel functions) on top of the interaction matrix of query and document embeddings -summing the interactions by their similarity.</p><p>CONV-KNRM <ref type="bibr" target="#b4">[5]</ref> applies a CNN over the query and document word embeddings, resulting in word-level n-gram representations. CONV-KNRM cross-matches n-grams and subsequently scores the interactions with n KNRM instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BERT[CLS]</head><p>[6] is a multi-task Transformer based NLP model. Pretrained instances are commonly available in large and small sizeswe experiment with both. We follow Nogueira et al. <ref type="bibr" target="#b23">[24]</ref> and first concatenate the query and document sequences. To score the pair, we use the representation of BERT's [CLS] token and a linear layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets &amp; Resources</head><p>We train and evaluate our models on three web-focused test collections. The size statistics are shown in Table <ref type="table" target="#tab_0">1</ref> and in the following we describe the collections in more detail:</p><p>MSMARCO <ref type="bibr" target="#b1">[2]</ref> collections are based on real Bing queries and results. We use both the Passage and the Document version with different sets of queries. Originally purposed for the question answering task, the annotation data is now used to provide ranking labels for retrieval results <ref type="foot" target="#foot_1">5</ref> . If a passage contains the answer to a query (judged by a human annotator) it is deemed relevant in the retrieval task as well as the document containing it.</p><p>TREC CAR <ref type="bibr" target="#b6">[7]</ref> is created as part of the TREC Complex Answer Retrieval (CAR) task in 2017. It is based on Wikipedia sections: the heading is used as the query and the section body is the deemed relevant paragraph in the automatic annotations.</p><p>In addition to the collections, we use pre-trained GloVe <ref type="bibr" target="#b27">[28]</ref> word embeddings with 300 dimensions <ref type="foot" target="#foot_2">6</ref> for all non-BERT neural models and pre-trained weights for BERT from pytorch-transformer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Parameter Settings</head><p>We cap the query length at 30 tokens and the document length at 200 tokens.</p><p>For MSMARCO-Passage and TREC CAR this only removes a modest amount of outliers, however, for the MSMARCO-Document collection a majority of documents is longer than 200 tokens. Increasing the cap to fully include most documents would render all evaluated neural IR models less effective or unfeasible for efficiency reasons. Addressing this issue is out of scope of this work, although we plan to address it in future work. We use the Adam <ref type="bibr" target="#b17">[18]</ref> optimizer with a learning rate of 10 −4 for word embeddings and contextualization layers, 10 −3 for all other non-BERT network layers, and 10 −6 for BERT fine-tuning. We employ early stopping, based on the best MRR@10 value of the validation set. We use a training batch size of 64. For evaluation we use a batch size of 256 for all non-BERT models and a batch size of 4 for BERT. We use a vocabulary of all terms with a minimum collection occurrence of 5 for MSMARCO-Passage and TREC CAR; and a collection minimum of 10 for MSMARCO-Document as it contains more unique terms.</p><p>Regarding model-specific parameters, for the Transformer layers in TK we evaluate 1, 2, and 3 layers, each with 16 attention heads with size 32 and a feed-forward dimension of 100. For lognormalization in TK we use a base of 2. For kernel-pooling (in TK, KNRM, CONV-KNRM) we set the number of kernels to 11 with the mean values of the Gaussian kernels varying from −1 to +1, and standard deviation of 0.1 for all kernels (KNRM &amp; CONV-KNRM use 0.0001 for exact matching on the first kernel). CONV-KNRM's n-gram size is set to 3 and the CNN features are set to 128. In the MatchPyramid model, we set the number of CNN layers to 5, each with kernel size 3 × 3 and 16 convolution channels. We use DUET without dropout and a document pooling width of 100. For PACRR and CO-PACRR we use a maximum n-gram size of 3, 32 CNN features, and a k-max pooling of 5. For the traditional retrieval models we use the tuned parameters from the Anserini documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We first present the highest achievable effectiveness results for our evaluated models without any time limit (Section 5.1). Then, we present a novel time-budget evaluation, which is based on the realistic assumption that we trade effectiveness for efficiency and that users expect fast search results (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Effectiveness Evaluation</head><p>In Table <ref type="table" target="#tab_1">2</ref> we show the highest achievable effectiveness results per model, without a time-constraint. The first section contains the traditional baselines; the second contains the neural re-ranking baselines; in the third section we report the results of our TK model with three different Transformer layer settings. Beside the effectiveness measures (MRR@10, Recall@10, nDCG@10 -higher is better) we also report the best re-ranking depth per model, tuned on the validation set. We view this tuned parameter as a good indicator of a model's robustness on a collection and a useful analytical tool for the degree of difficulty of a collection. To incorporate the efficiency in the analysis, we report the average number of documents each model is able to re-rank per millisecond.</p><p>Of the three collections, the neural re-ranking models deliver the best results on MSMARCO-Passage, both in terms of effectiveness and re-ranking depth. Even simple neural baselines like KNRM and PACRR show significant effectiveness increases to the initial ranking baselines. TK and BERT show very strong results, especially on Recall@10, as they are able to incorporate almost all 1000 documents per query that we evaluated. Naturally, the more documents are reranked the higher is the potential for the Recall, as the Recall@10 is bound by the Recall of the first stage at the re-ranking depth. The more Transformer layers we use to contextualize embeddings in TK, the better the effectiveness becomes across all three measures, however, the differences are small. TK performs similar on the MSMARCO-Document collection as on the passage collection, however in general the results are closer together. The classic baselines are stronger as well as the non-BERT neural models. On the other hand both BERT results are reduced in comparison to their passage result. Overall, all neural models stagnate or reduce their effectiveness with a deeper re-ranking depth.</p><p>While BERT shows strong results on TREC CAR, it is especially challenging for non-BERT approaches. Except for MatchPyramid and DUET all non-BERT baselines fail to improve MRR@10 and nDCG@10 significantly. TK is the first non-BERT model offering strong improvements over the initial ranking baselines.</p><p>In conclusion, given unlimited time, BERT is the best re-ranking model, followed by TK, across all three collections. However, taking into consideration the average time a model spends on re-ranking a document it becomes apparent that utilizing BERT to its best reranking depth is prohibitively slow for most search applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Time-Budget Evaluation</head><p>Now we focus on the relationship between efficiency and effectiveness. It would be easy -yet unfair -to discard BERT as unfeasibly slow, based on the assumption that one always has to re-rank a thousand documents. Similarly, it would be unwise to solely judge the neural re-ranking models based on their unconstrained effectiveness results from the previous section.</p><p>We take a fine-grained approach to evaluate efficiency and effectiveness together, by starting from the assumption that search applications set a time-budget for various stages of the retrieval pipeline. Neural re-ranking models are a part of a larger system and therefore have to adhere to a maximum time-budget. We use the re-ranking depth to control the time spent by each model. We believe this to be a fair comparison, as we give each model the same time. The timings we measured exclude any pre-processing and solely focus on the time spent computing the scores on the GPU. We evaluated each model once and then pruned the documents, based on their first stage rank, to obtain results for every re-ranking depth. We average the documents per millisecond metric over all validation runs during the training, to obtain a noise reduced value. In a pilot study, we ensured that different validation batch sizes do not contradict the analytical results presented here.</p><p>Figure <ref type="figure">2</ref> shows the time-budget aware results for every collection on MRR@10, Recall@10, and nDCG@10. The x-axes show the available time in milliseconds (up to 300ms for MRR and nDCG; 600 ms for Recall) and each y-axis represents the effectiveness results. We selected TK with 2 layers as a good compromise between effectiveness and speed. Additionally, we report the results for both BERT sizes and the two best non-BERT neural baselines.</p><p>On the MSMARCO-Passage collection all fast models reach large re-ranking depths, except for BERT, where the base version only reaches 32 documents after 300 ms and the large version is only able to process 8 documents. TK is the best choice, after the first few ms of noise up to 190ms for MRR@10, 600 ms for Recall@10 and 300 ms for nDCG@10. BERT-Base overtakes the other neural baselines in around half the time it needs to be better than TK. If we choose a generous time-budget of 100 ms, TK's MRR@10 is 10% higher, Recall@10 is 40% higher, and nDCG@10 is 19% higher than BERT-Base. BERT-Base can only re-rank 10 documents in 100 ms, leaving it at the same Recall@10 as BM25. Even at 250 ms, when TK finished all thousand documents it has a 12 % higher Recall@10 than BERT-Base and is 9% above CONV-KNRM.</p><p>The MSMARCO-Document and TREC CAR collection are more challenging for non-BERT models, as their best re-ranking depth is shallow and more time would not yield better results. In Figure <ref type="figure">2</ref> this is shown as the colored dotted line. However, this does not change the time BERT needs to cross the best result of the other models. (c) TREC CAR Figure <ref type="figure">2</ref>. Time-budget analysis: We show the effectiveness (y-axis) of each model on the respective validation set by selecting the maximum number of documents to re-rank in the available time limit (x-axis). The marker indicates the best possible result; the dotted line indicates that additional time does not yield better results; the number of re-ranked documents is indicated for each best result.</p><p>TK is the best choice for MSMARCO-Document up to 200ms for MRR@10, 550 ms for Recall@10 and 260 ms for nDCG@10. For TREC CAR, TK yields the highest effectiveness for a time-budget up to 200ms for MRR@10, 480 ms for Recall@10 and 250 ms for nDCG@10. If we again apply a time-budget of 100 ms to TREC CAR, we observe that TK's MRR@10 is 12% higher, Recall@10 is 31% higher, and nDCG@10 is 17% higher than BERT-Base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Query Analysis</head><p>Following the presentation of the collection results, we now analyze the query results in more detail. Our aim is to understand TK's quality on different query types or information needs and how TK com-pares to BM25 and BERT-Base. We cluster MSMARCO-Passage validation queries based on their mean contextualized embedding of TK with k-means. We set k = 30, as we found it to be an appropriate choice with the elbow method. In Table <ref type="table" target="#tab_4">3</ref> we show a selection of those clusters and their median rank of the first relevant passage for each model, as a robust measure inspired by MRR. Additionally, we report the number of queries in each cluster (# Q). We manually assigned an information need or type of query summary to each cluster. In practice we observed most clusters to be unambiguous in their assignment, except for a few outliers per cluster. To keep the analysis simple, we do not place a time-constraint on the models.</p><p>The MSMARCO collections were created for question answering Query (Id:2) androgen receptor define Rank: TK 1 , BM25 9 (judged as relevant, Id: 4339068) Rank: TK 8 , BM25 1 (not relevant, Id: 1782337)</p><p>The androgen receptor ( AR ) , also known as NR3C4 ( nuclear receptor subfamily 3 , group C , member 4 ) , is a type of nuclear receptor that is activated by binding either of the androgenic hormones , testosterone , or dihydrotestosterone in the cytoplasm and then translocating into the nucleus . in some cell types , testosterone interacts directly with androgen receptors , whereas , in others , testosterone is converted by 5 -alpha -reductase to dihydrotestosterone , an even more potent agonist for androgen receptor activation . Enzalutamide is an androgen receptor inhibitor that acts on different steps in the androgen receptor signaling pathway . Enzalutamide has been shown to competitively inhibit androgen binding to androgen receptors and inhibit androgen receptor nuclear translocation and interaction with DNA . tasks and the queries reflect that. Only a minority of queries represents plain keyword queries -a type for which BM25 provides good results. Natural language question queries are particularly well suited for neural re-ranking models, especially when users ask for a definition or clarification ("what is") with two or more words. Here, both TK and BERT improve substantially over BM25, while BERT performs slightly better than TK. BERT has an advantage over TK on complex queries with more than 8 words, which suggest the language modelling in BERT is more useful. </p><formula xml:id="formula_10">µ k s k log 1 -<label>3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Interpretability</head><p>We now highlight the interpretation capabilities of the TK model with a qualitative example. This analysis is enabled by TK's architecture, which first contextualizes query and document sequences independently and then uses only a single interaction value per term pair, which is scored via soft-histogram kernels. This allows us to accurately represent the scoring process of the model in our analysis. In contrast BERT-based re-rankers cannot be analyzed in this way, as they have no clear single point of interaction and a much more complex scoring mechanism. We focus on the following scenario: a user would like to know why the neural model replaced the first result (a non-relevant document) of the first stage ranking with the actual relevant document. For this, we offer a side-by-side comparison view of two documents. Figure <ref type="figure" target="#fig_2">3</ref> shows the comparison of two documents the query "androgen receptor define". On the left side is a document judged as relevant, which is placed on the first position by TK. On the right side is the top BM25 document, which is not the correct answer and only partially relevant to the query -TK moved it to a lower position.</p><p>We show each document with its full-text and a selection of temporary results of TK. We aim to identify and highlight the differences that result in different ranking scores. We color words according to their closest affiliation with a kernel. An important fact to consider is the soft-matching nature of the kernels: A term is counted in more than one kernel at a time. For example, this explains the difference in kernel µ = 1, even though no word is closest associated with that kernel and therefore we omitted a color.</p><p>From the highlighted kernel scores (s k log ) it is apparent that the left document has more stronger matches than the right one, leading to higher scores. If we look at the corresponding colored words we observe that the sentence containing the definition in the left is most relevant to the query: The androgen receptor ( AR ) , also known as NR3C4 ( nuclear receptor subfamily. Even though TK does not contain a mechanism for strictly categorizing a region as relevant, it does so indirectly by strongly matching almost every term in this region. Of particular interest to us is the fact that the contextualization of TK learns to match the query term "define" with words and phrases that make up a definition: "also known as", "subfamily", "is a type" as well as the parentheses. This exceeds simple synonym mapping, suggesting once more the importance of training contextualized and relevance specific encoding models.</p><p>This analysis demonstrates the potential for future work on keyword based search. When a collection is not queried with natural language questions, but only keywords, one could expand such keyword queries with terms like "definition" or "meaning" both during training and inference of neural models, to promote documents closer related to the core of the information need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The work in this paper is based on the assumption that search tasks are time-constrained and neural re-ranking models have to fulfil this requirement to be deployable as part of user-facing search engines. To address this, we proposed TK: an interpretable ad-hoc neural reranking model with a very strong efficiency-effectiveness ratio. We introduced a realistic time-budget aware evaluation. Models are allowed to re-rank as many documents as they can within the given time-budget. This evaluation shows how the TK model is the overall best choice for a time-budget under 200 ms per query for precision based measures and 400 ms per query for recall. In addition -to not just propose a black-box model without insight -we provided a fine granular query analysis showing the different strengths of TK on various query types and we illustrated how TK can be analyzed and interpreted. TK makes it possible to obtain competitive neural re-ranking results with a limited time-budget.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The TK model architecture: 1 We contextualize query and document sequences individually. 2 The interaction match-matrix is created with pairwise cosine similarities. 3 Each kernel creates a new feature matrix. Then, the document dimension is summed and we normalize each query-term feature by logarithm and document length. 4 We combine log-and length-normalized scores with a single feed-forward (FF) layer to form the final result score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. TK's scoring results of two MSMARCO-Passage documents: We highlight two close similarity kernels (0.9 &amp; 0.7). In the text words are colored and underlined if they are closest to the center of the kernel. Individual kernel results (model weights included) are displayed in the middle for each document.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Collection statistics</figDesc><table><row><cell>Collection</cell><cell># Docs.</cell><cell># Terms</cell><cell cols="2"># Queries Val. Test</cell></row><row><cell>MS-Passage</cell><cell>8,841,823</cell><cell>1,834,055</cell><cell cols="2">6,980 48,598</cell></row><row><cell>MS-Document</cell><cell cols="2">3,213,835 44,991,958</cell><cell>5,000</cell><cell>5,193</cell></row><row><cell>TREC CAR</cell><cell>29,794,697</cell><cell>6,682,592</cell><cell>5,000</cell><cell>2,254</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Unconstrained effectiveness results on the test sets. Each measure is using a cutoff of 10. Depth refers to the re-ranking depth (which is tuned on MRR@10 on the validation set and the number shown per model is applied on the test set)</figDesc><table><row><cell>Model</cell><cell cols="5">MSMARCO-Passage MRR Recall nDCG Depth MRR Recall nDCG Depth MRR Recall nDCG Depth Docs./ms MSMARCO-Document TREC CAR Average</cell></row><row><cell>BM25</cell><cell>0.194 0.402 0.241</cell><cell>-0.252 0.500 0.311</cell><cell>-0.221 0.259 0.190</cell><cell>-</cell><cell>-</cell></row><row><cell>LM</cell><cell>0.171 0.358 0.213</cell><cell>-0.202 0.423 0.254</cell><cell>-0.190 0.222 0.166</cell><cell>-</cell><cell>-</cell></row><row><cell>RM3</cell><cell>0.169 0.388 0.219</cell><cell>-0.156 0.367 0.206</cell><cell>-0.220 0.253 0.189</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">MatchPyramid 0.249 0.476 0.301</cell><cell>71 0.286 0.531 0.344</cell><cell>15 0.238 0.279 0.205</cell><cell>40</cell><cell>27</cell></row><row><cell>DUET</cell><cell>0.248 0.468 0.299</cell><cell>42 0.266 0.520 0.327</cell><cell>15 0.233 0.272 0.199</cell><cell>39</cell><cell>14</cell></row><row><cell>PACRR</cell><cell>0.259 0.493 0.313</cell><cell>619 0.283 0.536 0.344</cell><cell>15 0.210 0.257 0.181</cell><cell>24</cell><cell>22</cell></row><row><cell>CO-PACRR</cell><cell>0.273 0.514 0.328</cell><cell>987 0.284 0.543 0.345</cell><cell>19 0.224 0.267 0.193</cell><cell>23</cell><cell>14</cell></row><row><cell>KNRM</cell><cell>0.235 0.465 0.288</cell><cell>127 0.261 0.519 0.323</cell><cell>14 0.191 0.213 0.163</cell><cell>6</cell><cell>49</cell></row><row><cell cols="2">CONV-KNRM 0.277 0.519 0.332</cell><cell>967 0.283 0.542 0.345</cell><cell>19 0.223 0.275 0.194</cell><cell>30</cell><cell>10</cell></row><row><cell>BERT-Base</cell><cell>0.376 0.639 0.437</cell><cell>997 0.352 0.623 0.417</cell><cell>58 0.388 0.426 0.333</cell><cell>650</cell><cell>0.1</cell></row><row><cell>BERT-Large</cell><cell>0.366 0.627 0.426</cell><cell>997 0.350 0.630 0.417</cell><cell>93 0.444 0.475 0.385</cell><cell>650</cell><cell>0.03</cell></row><row><cell>TK -1 Layer</cell><cell>0.303 0.560 0.361</cell><cell>997 0.305 0.572 0.369</cell><cell>29 0.285 0.312 0.241</cell><cell>63</cell><cell>6</cell></row><row><cell>TK -2 Layer</cell><cell>0.311 0.564 0.369</cell><cell>997 0.312 0.577 0.375</cell><cell>29 0.305 0.329 0.258</cell><cell>86</cell><cell>4</cell></row><row><cell>TK -3 Layer</cell><cell>0.314 0.570 0.373</cell><cell>997 0.316 0.586 0.380</cell><cell>31 0.307 0.328 0.259</cell><cell>72</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Comparing the median ranks of the first relevant document for BM25, TK, and BERT-Base on selected query clusters on the MSMARCO-Passage validation set</figDesc><table><row><cell>Information need</cell><cell># Q</cell><cell cols="3">Median Rank BM25 TK BERT</cell></row><row><cell>company phone number</cell><cell>115</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell>celebrity/movie facts</cell><cell>224</cell><cell>8</cell><cell>4</cell><cell>3</cell></row><row><cell>money: cost/salary/net worth</cell><cell>210</cell><cell>7</cell><cell>4</cell><cell>3</cell></row><row><cell>plain keyword(s) of diff. topics</cell><cell>224</cell><cell>6</cell><cell>4</cell><cell>2</cell></row><row><cell>how long is something</cell><cell>196</cell><cell>41</cell><cell>12</cell><cell>5</cell></row><row><cell>long question for a single number</cell><cell>326</cell><cell>15</cell><cell>7</cell><cell>5</cell></row><row><cell>what is/are 1 word</cell><cell>321</cell><cell>15</cell><cell>3</cell><cell>3</cell></row><row><cell>what is/are 2+ words</cell><cell>279</cell><cell>20</cell><cell>5</cell><cell>3</cell></row><row><cell>meaning/definition of 1 word</cell><cell>155</cell><cell>13</cell><cell>3</cell><cell>3</cell></row><row><cell>meaning/definition of 2+ words</cell><cell>208</cell><cell>23</cell><cell>4</cell><cell>3</cell></row><row><cell>symptoms of diseases</cell><cell>58</cell><cell>59</cell><cell>9</cell><cell>5</cell></row><row><cell>benefits/effects of prescriptions</cell><cell>106</cell><cell>13</cell><cell>4</cell><cell>4</cell></row><row><cell>All queries (with ≥ 1 relevant)</cell><cell>6058</cell><cell>13</cell><cell>5</cell><cell>3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0">https://github.com/huggingface/pytorch-transformers</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1">https://github.com/microsoft/MSMARCO-Passage-Ranking</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2">42B CommonCrawl lower-cased: https://nlp.stanford.edu/projects/glove/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements This work has received funding from the European Union's Horizon 2020 research and innovation program under grant agreement No 822670.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Nasreen</forename><surname>Abdul-Jaleel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leah</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Courtney</forename><surname>Wade</surname></persName>
		</author>
		<title level="m">UMass at TREC 2004: Novelty and HARD</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Proc. of TREC</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'ms</forename><surname>Marco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
				<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tr. of the ACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Quality versus efficiency in document scoring with learning-to-rank models</title>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Capannini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Lucchese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Nardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raffaele</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName><surname>Tonellotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing &amp; Management</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">52</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search</title>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM</title>
				<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
				<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Filip Radlinski, and Nick &apos;Trec complex answer retrieval overview</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manisha</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling Diverse Relevance Patterns in Ad-hoc Retrieval</title>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A study on the Interpretability of Neural Retrieval Models using DeepSHAP</title>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Zeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaspreet</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avishek</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><surname>Anand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Allennlp: A deep semantic natural language processing platform</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Deep Relevance Matching Model for Ad-hoc Retrieval</title>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM</title>
				<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Let&apos;s measure run time! Extending the IR replicability infrastructure to include performance aspects</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of OSIRRC</title>
				<meeting>of OSIRRC</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the Effect of Low-Frequency Terms on Neural-IR Models</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Enriching Word Embeddings for Patent Retrieval with Global Context</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hofstätter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navid</forename><surname>Rekabsaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECIR</title>
				<meeting>of ECIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">PACRR: A position-aware neural IR model for relevance matching</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melo</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
				<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Co-PACRR: A context-aware neural IR model for ad-hoc retrieval</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melo</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WSDM</title>
				<meeting>of WSDM</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient interaction-based neural ranking with locality sensitive hashing</title>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjin</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proc of. WWW</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online controlled experiments at large scale</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Pohlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGKDD</title>
				<meeting>of SIGKDD</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Contextualized embeddings for document ranking</title>
		<author>
			<persName><forename type="first">Sean</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
		<author>
			<persName><surname>Cedr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An introduction to neural information retrieval</title>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in IR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.07666</idno>
		<title level="m">An updated duet model for passage re-ranking</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Incorporating query term independence assumption for efficient retrieval and ranking using deep neural networks</title>
		<author>
			<persName><forename type="first">Corby</forename><surname>Bhaskar Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emine</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><surname>Yilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03693</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m">Passage re-ranking with bert</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Document expansion by query prediction</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08375</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Text Matching as Image Recognition</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of</title>
				<meeting>of</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS-W</title>
				<meeting>of NIPS-W</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of EMNLP</title>
				<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Deep contextualized word representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Proc. of NAACL</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Mary</forename><surname>Arpita Pyreddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narendra</forename><forename type="middle">Nath</forename><surname>Varshini Ramaseshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<title level="m">Consistency and Variation in Kernel Neural Ranking Model</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Proc. of SIGIR</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Slow search: Information retrieval without time constraints</title>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Teevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubin</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symposium on HCI and IR</title>
				<meeting>of the Symposium on HCI and IR</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
				<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned</title>
		<author>
			<persName><forename type="first">Elena</forename><surname>Voita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Moiseev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
				<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to efficiently rank</title>
		<author>
			<persName><forename type="first">Lidan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ranking under temporal constraints</title>
		<author>
			<persName><forename type="first">Lidan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CIKM</title>
				<meeting>of CIKM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">End-to-End Neural Ad-hoc Ranking with Kernel Pooling</title>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The greedy miser: learning under test-time budgets</title>
		<author>
			<persName><forename type="first">Zhixiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
				<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Enabling the use of Lucene for information retrieval research</title>
		<author>
			<persName><forename type="first">Peilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><surname>Anserini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR</title>
				<meeting>of SIGIR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName><surname>Xlnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
