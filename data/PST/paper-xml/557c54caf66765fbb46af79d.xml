<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Adaptive Differential Evolution Algorithm for Global Optimization in Dynamic Environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Swagatam</forename><surname>Das</surname></persName>
							<email>swagatam.das@isical.ac.in</email>
						</author>
						<author>
							<persName><forename type="first">Ankush</forename><surname>Mandal</surname></persName>
							<email>ankushmandal19@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Rohan</forename><surname>Mukherjee</surname></persName>
							<email>rohan.mukherjii@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">ECSU</orgName>
								<orgName type="institution">Indian Statistical Institute (ISI)</orgName>
								<address>
									<postCode>700108</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electronics and Telecommunication Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700108</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An Adaptive Differential Evolution Algorithm for Global Optimization in Dynamic Environments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1B07FDCEE20C5E77A74711BECFBF2236</idno>
					<idno type="DOI">10.1109/TCYB.2013.2278188</idno>
					<note type="submission">received July 30, 2012; revised July 11, 2013; accepted July 27, 2013.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Differential evolution</term>
					<term>diversity</term>
					<term>double mutation strategy</term>
					<term>dynamic optimization problems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article proposes a multipopulation-based adaptive differential evolution (DE) algorithm to solve dynamic optimization problems (DOPs) in an efficient way. The algorithm uses Brownian and adaptive quantum individuals in conjunction with the DE individuals to maintain the diversity and exploration ability of the population. This algorithm, denoted as dynamic DE with Brownian and quantum individuals (DDEBQ), uses a neighborhood-driven double mutation strategy to control the perturbation and thereby prevents the algorithm from converging too quickly. In addition, an exclusion rule is used to spread the subpopulations over a larger portion of the search space as this enhances the optima tracking ability of the algorithm. Furthermore, an aging mechanism is incorporated to prevent the algorithm from stagnating at any local optimum. The performance of DDEBQ is compared with several state-of-theart evolutionary algorithms using a suite of benchmarks from the generalized dynamic benchmark generator (GDBG) system used in the competition on evolutionary computation in dynamic and uncertain environments, held under the 2009 IEEE Congress on Evolutionary Computation (CEC). The simulation results indicate that DDEBQ outperforms other algorithms for most of the tested DOP instances in a statistically meaningful way.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>fore, no separate probability distribution (like the Gaussian distributions used in evolutionary programming (EP) and evolution strategies (ES) or the Cauchy distributions used in case of the fast EPs) is used to generate offspring.</p><p>Several optimization problems in the real world are dynamic in nature. For these dynamic optimization problems (DOPs), the function landscape changes with time, i.e., optima of the problem to be solved change their locations over time and, thus, the optimizer should be able to track the optima continually by responding to the dynamic environment <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Practical examples of such situations are price fluctuations, financial variations, stochastic arrival of new tasks in a scheduling problem, machine breakdown, or maintenance. Under dynamic environments, converging tendency of a conventional EA (implying the tendency of the population members of an EA to concentrate within a small basin of the search space as the iterations progress) imposes severe limitations on performance of the EA. If the population members of the EA converge rapidly, they will be unable to effectively respond to the environmental changes. Therefore, in case of DOPs the main challenge is to maintain a diverse population and at the same time to produce high quality solutions by tracking the moving optima. At this point, we would like to mention that there are also DOP instances where the optimal solution does not need to be tracked. For example, Allmendinger and Knowles <ref type="bibr" target="#b4">[5]</ref> investigate DOPs where the constraints [ephemeral resource constraints (ERCs)] change over time but not the landscape and thus, also not the optimal solutions. In this paper, we focus on the real parameter-bound constrained DOPs where the objective function landscape explicitly changes with time and not on the problems with ERCs.</p><p>Classical DE faces difficulties when applied to DOPs due to two main factors. Firstly, DE individuals have a tendency to converge prematurely into small basins of attraction surrounding the local and global optima as the search progresses <ref type="bibr" target="#b5">[6]</ref>. Thereafter, if any change occurs in the position of the optima, DE starts lacking sufficient explorative power to track down the new optima due to the individuals being similar and the consequently small perturbations. Secondly, DE may occasionally stop proceeding toward the global optimum even though the population has not converged to a local optimum or any other point <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Researchers have made some attempts to introduce suitable algorithmic modifications in DE for enabling it to continually track changing optima under dynamic conditions. A brief account of such approaches is presented in Section II-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2168-2267 c 2013 IEEE</head><p>This article proposes a multipopulation-based adaptive DE with Brownian and Quantum individuals (DDEBQ) to address DOPs. In each subpopulation, one individual is an adaptive quantum individual, analogous to particles following the laws of quantum mechanics and one individual is a Brownian individual, whose trajectory is similar to the trajectory of any particle in Brownian motion. Other individuals in the subpopulation evolve in the DE framework with a neighborhoodbased double mutation strategy. As quantum and Brownian individuals do not follow the same DE rules as others, they help in controlling the diversity of the population and thereby, in enhancing the search efficiency of the algorithm. A double mutation strategy is developed under the DE-framework to prevent the algorithm from converging quickly. In order to circumvent the problem of stagnation, an aging mechanism is integrated within DE. Also an exclusion scheme is used so that subpopulations may distribute themselves evenly over the entire search space. This increases the explorative power and the ability of the algorithm to track the global optimum. The performance of the proposed algorithm is primarily tested on a suite of DOPs generated by the generalized dynamic benchmark generator (GDBG) that was proposed for the special session and competition on "Evolutionary Computation in Dynamic and Uncertain Environments," held under the IEEE Congress on Evolutionary Computation (CEC) 2009 <ref type="bibr" target="#b6">[7]</ref>. A comparison of DDEBQ with several state-of-the-art dynamic evolutionary optimizers reflects the statistical superiority of the algorithm over a wide variety of real-parameter DOPs. A list of terminologies used to describe DDEBQ can be found in Table <ref type="table" target="#tab_4">IV</ref> of the appendix.</p><p>The rest of the paper is organized as follows. Section II provides a brief description of classical DE and also presents a compact survey of the different modified DE schemes previously used for solving DOPs. Section III describes the proposed DDEBQ algorithm with all its salient features in sufficient detail. Section IV describes the benchmarks used and explains the simulation strategies used for undertaking the experiments reported in the subsequent sections. Results of comparing DDEBQ with several state-of-the-art EAs are presented and discussed in Section V. Finally, conclusions are drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Background A. Classical DE</head><p>A generation of the classical DE algorithm consists of four basic steps-initialization, mutation, crossover, and selection, of which, only last three steps are employed into DE generations. The generations continue till some termination criterion (such as exhaustion of maximum functional evaluations) is satisfied.</p><p>1) Initialization of Population:: DE searches for a global optimum within a continuous search space of dimensionality D. It begins with an initial population of target vectors</p><formula xml:id="formula_0">X i = [x 1 i , x 2 i , ..., x D i ]</formula><p>, where i = 1, 2, 3 . . . .Np (Np is the population size). The individuals of the initial population are randomly generated from a uniform distribution within the search-space. The search-space has maximum and minimum bounds in each dimension and the bounds can be expressed as </p><formula xml:id="formula_1">X max = x 1 max , x</formula><formula xml:id="formula_2">x j i,0 = x j min + rand j i (0, 1) • (x j max -x j min ), j ∈ {1, 2, . . ., D}<label>(1)</label></formula><p>where rand j i (0, 1) is a uniformly distributed random number in (0, 1) and it is instantiated independently for each jth component of the ith individual.</p><p>2) Mutation: After initialization, DE creates a donor vector V i,G corresponding to each population member or target vector X i,G in the current generation through mutation. The three most frequently referred mutation strategies for DE are listed below as</p><formula xml:id="formula_3">DE/rand/1 : V i,G = X r i 1 ,G + F • ( X r i 2 ,G -X r i 3 ,G )<label>(2)</label></formula><formula xml:id="formula_4">DE/best/1 : V i,G = X best,G + F • ( X r i 1 ,G -X r i 2 ,G )<label>(3)</label></formula><p>DE/current-to-best/1: <ref type="formula">4</ref>) The indices r i 1 , r i 2 , and r i 3 are mutually exclusive integers randomly chosen from the range {1, 2, . . . , Np}, and all are different from the base index i. These indices are randomly generated anew for each donor vector. The scaling factor F is a positive control parameter for scaling the difference vectors. X best,G is the best individual vector with the best fitness (i.e., having the highest objective function value for a maximization problem) in the population at generation G. The general convention used for naming the various offspring generation strategies of DE is DE/x/y/z, where x represents a string denoting the vector to be perturbed and y is the number of difference vectors considered for perturbation of x. z stands for the type of crossover being used (exp: exponential; bin: binomial).</p><formula xml:id="formula_5">V i,G = X i,G +F • ( X best,G -X i,G )+F • ( X r i 1 ,G -X r i 2 ,G ). (</formula><p>3) Crossover: The donor vector mixes its components with the target vector X i,G under the crossover operation to form a trial vector of the same index denoted as</p><formula xml:id="formula_6">U i,G = [u 1 i,G , u 2 i,G , ....., u D i,G ].</formula><p>The DE family of algorithms primarily uses two kinds of crossover schemes-exponential (or twopoint modulo) and binomial (or uniform) <ref type="bibr" target="#b1">[2]</ref>. The binomial crossover scheme is briefly explained below since it is used in the proposed algorithm. Under this scheme the trial vector is created as follows:</p><formula xml:id="formula_7">u j i,G = v j i,G if rand j i (0, 1)≤CR or j = j rand x j i,G otherwise (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where Cr is a user-specified parameter (crossover rate) in the range [0, 1) and j rand ∈ {1, 2, ...., D} is a randomly chosen index, which ensures that the trial vector U i,G differs from its corresponding target vector X i,G by at least one component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Selection:</head><p>The next step of the algorithm calls for selection to determine which of the target or the trial vectors survives to the next generation, i.e., at G = G + 1. For a maximization problem, if the objective function value of the trial vector is not less than that of the corresponding target vector, then the trial vector is selected for the next generation; otherwise the target vector is selected for the next generation. Obviously, for a minimization problem the condition for selection is just the opposite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dynamic Optimization With DE-Brief Overview</head><p>Since the late 1990s, DE started to receive attention from DOP researchers. Mendes and Mohais presented DynDE <ref type="bibr" target="#b7">[8]</ref>, a multipopulation DE algorithm, developed specifically to optimize slowly time-varying objective functions. In DynDE, the diversity of the population is maintained in two ways: first, by reinitializing a population if the best individual of the population moves too close to the best individual of another population and secondly, by randomization of one or more population vectors by adding a random deviation to the components. The authors showed that DynDE is capable of solving the Moving Peaks Benchmark (MPB) problems efficiently. Brest et al. <ref type="bibr" target="#b8">[9]</ref> investigated a self-adaptive DE algorithm (jDE), where the control parameters F and Cr are self-adapted and a multipopulation method with an aging mechanism is used to improve performance on DOPs. This algorithm ranked first in the competition on "Evolutionary Computation in Dynamic and Uncertain Environments" under IEEE CEC, 2009. Some other interesting research efforts on modifying DE for optimizing in dynamic environments can be found in <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b12">[13]</ref>. Recently, Halder et al. <ref type="bibr" target="#b13">[14]</ref> proposed a multipopulation DE for solving DOPs. In this proposal, the entire population is partitioned into several clusters according to the spatial locations of the trial solutions. The clusters are evolved separately using a standard DE algorithm. The number of clusters is an adaptive parameter and its value is updated after a certain number of iterations.</p><p>Various niching strategies <ref type="bibr" target="#b14">[15]</ref> have been proposed by the EA researchers to adapt an EA for detecting and maintaining multiple optima over a multimodal functional landscape. Niching also helps in preserving the population diversity in the course of an EA and track moving peaks in dynamic optimization. DE has been modified to induce efficient niching behavior on multimodal landscapes in some prominent works, such as bi-objective DE with mean distance-based selection <ref type="bibr" target="#b15">[16]</ref>, crowding-based DE <ref type="bibr" target="#b16">[17]</ref>, and DE-based multimodal optimization using the principle of locality <ref type="bibr" target="#b17">[18]</ref>. Parrott and Li <ref type="bibr" target="#b18">[19]</ref> used the speciation technique to track multiple peaks in a dynamic environment. Subsequently in 2006, Li et al. <ref type="bibr" target="#b19">[20]</ref> used speciation-based particle swarm optimization (SPSO) to tackle DOPs by using detection and response. The method is designed for solving problems with primarily unknown numbers of peaks. Lung and Dumitrescu <ref type="bibr" target="#b20">[21]</ref> used crowding DE to maintain diversity and combined it with PSO, called collaborative evolutionary-swarm optimization (CESO) to solve dynamic optimization problems. In 2009, Lung and Dumitrescu <ref type="bibr" target="#b21">[22]</ref> further improved and extended their work by introducing one more crowing DE population that acted as a memory for the main population. However, most of the dynamic niching techniques necessitate the use of niching parameters, such as the niching radius or the crowding factor, which in turn require prior knowledge about the functional landscape for proper tuning <ref type="bibr" target="#b14">[15]</ref>. This may lead to poor performance on complicated dynamic functions like those designed with the GDBG system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DDEBQ Algorithm A. Dynamic DE Scheme</head><p>In order to maintain diversity of the population to a larger extent, DDEBQ introduces adaptive quantum and Brownian individuals along with the DE individuals in the population. These quantum and Brownian individuals do not follow the same rule as the DE individuals. Actually, within a subpopulation, two individuals are randomly chosen at each generation. The quantum individual generation rules are applied to one of them and the Brownian individual generation rules to the other. If one of the chosen individuals happens to be the best individual of that subpopulation, then the choice is discarded and another individual is randomly picked for subjecting it to the Brownian or quantum individual generation processes.</p><p>1) Quantum Individuals: In quantum mechanics, due to the uncertainty in position measurement, the position of a particle is probabilistically defined. This idea is used here to generate individuals within a specific region around the local best position. The steps for stochastically generating an individual, whose position is inside a hyper-sphere of radius R and centered at the local best position Lb can be outlined as follows.</p><p>1) Generate a radial distance randomly from a uniform distribution within the range (0, R) as:r ∼ U(0, R). This implies 0≤r≤R. 2) Generate a vector with each component being sampled at random from a normal distribution having zero mean and unity variance:</p><formula xml:id="formula_9">X = [x 1 , x 2 , ..., x D ] ; x d = N(0, 1)</formula><p>, where 1≤ d ≤ D and N(μ, σ) denotes the normal distribution with mean μ and standard deviation σ. 3) Compute the distance of the vector from the origin</p><formula xml:id="formula_10">X = D i=1 x 2 i . 4)</formula><p>The new quantum individual's position will be</p><formula xml:id="formula_11">X q = Lb + r X X. (<label>6</label></formula><formula xml:id="formula_12">)</formula><p>In DDEBQ, the radius R within which the quantum individuals are generated is adaptive in nature, i.e., the radius is automatically updated according to certain conditions and with the progress of the search. The adaptation of R is explained in Section III-E as it depends on the control parameter C.</p><p>2) Brownian Individuals: Brownian motion is used to describe the random movement of particles suspended in a fluid. In mathematics, Brownian motion is described by the Wiener process (a continuous-time stochastic process named in honor of Norbert Wiener). The Wiener process W t is characterized by the following three facts: 1)W 0 = 0; 2) is almost surely continuous; and 3) W t has independent increments with distribution, i.e., W t -W s ∼ N(0, ts). for 0≤s≤t. DDEBQ employs a very simple method to simulate the Brownian motion. New individuals are generated within a Gaussian hyper-ellipsoid centered at the local best position. If the local best position is Lb, then, the new Brownian individual's position will be</p><formula xml:id="formula_13">X B = Lb + (7)</formula><p>where the Gaussian perturbation vector = [ 1 , 2 , ..., D ]; d = N(0, σ), with 1 ≤ d≤D and σ is the standard deviation of the multivariate normal distribution from which each component of the perturbation is randomly sampled. Here, the value σ = 0.2 is used following <ref type="bibr" target="#b7">[8]</ref> and considering the fact that this value gave the best results for most of the tested benchmark instances.</p><p>We would like to mention here that Wong et al. <ref type="bibr" target="#b22">[23]</ref> proposed a niching algorithm where, in the species-specific exploration stage, random individuals are generated to maintain the diversity of the population for detecting multiple peaks on a static landscape. However, the proposed Brownian and quantum individual generation schemes are considerably different from what was done in <ref type="bibr" target="#b22">[23]</ref>.</p><p>3) DE Individuals: These individuals evolve following the standard DE algorithm. The donor vectors are generated following a new mutation scheme that is detailed below. However, these individuals follow the same binomial crossover and selection process as that of the standard DE algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Double Mutation Strategy</head><p>In a dynamic environment, if the population is concentrated around the global optimum, then the individuals will lose their ability to detect the global optimum again when the position of the latter changes. Thus, here the idea is to control the perturbation to slow down the searching process and make the subpopulations evenly distributed over the entire search space. An exclusion rule is employed to meet the second objective and the rule is discussed in Subsection III-C. For the first objective, DDEBQ follows a double mutation scheme, which is conceptually motivated by the work of Das et al. <ref type="bibr" target="#b23">[24]</ref> in a different context. Under this scheme, first a mutant vector is generated according to a neighborhood-based mutation scheme and then the final donor vector is produced as a linear combination of the mutant vector with the local best vector (of the corresponding subpopulation) formed through a constant weight factor.</p><p>1) Neighborhood-Based Mutation Strategy: In order to overcome the limitations of the fast but less reliable convergence characteristics of DE/current-to-best/ 1/bin, some changes are introduced in the process of generating the difference vectors. For the first difference vector, the original scheme uses the difference between the global best individual and the current individual; however, in the modified scheme, the difference between the nearest memory individual and the current individual is considered. The memory archive contains a collection of the best individuals from the previous subpopulations. This modification is done to control the convergence of the population toward global optima and to encourage the subpopulations to explore the vicinity of the corresponding local best positions. For the second differential vector, instead of taking the difference between two randomly chosen individuals, DDEBQ uses the difference between the best individual in the neighborhood and the worst individual in the neighborhood with respect to the current individual. This modification is likely to guide the mutant vector to explore the neighborhood of the current individual within the subpopulation.</p><p>Note that the concept of neighborhood in <ref type="bibr" target="#b23">[24]</ref> is solely based on the index graph of the DE vectors and two given vectors are neighbors if they have adjacent indices, albeit they may not be adjacent geographically or according to fitness values. In this paper, the neighborhoods bear a completely different meaning as will be evident from the following discussion. The first mutation can be expressed as</p><formula xml:id="formula_14">v j mut,G = x j i,G +F j mem •(x j mem,G -x j i,G )+F j bw •(x j n best,G -x j n worst,G )<label>(8)</label></formula><p>where j {1, 2, . . . , D} and x j i,G is the jth component of X i,G that is the current vector. Similarly x j n best,G is the jth component of X n best,G that is the best vector in the neighborhood with respect to the current vector. It is the vector within the corresponding subpopulation for which 1 <ref type="figure">m</ref>, where m = number of individuals in the subpopulation and k = i) is maximum. Here, r ik is the Euclidean distance between the vectors X i,G and X k,G . x j n worst,G denotes the jth component of X n worst,G , which is the worst vector in the neighborhood with respect to the current vector. For this vector, 1 During the process of generating the mutant vector, for each dimension of each difference vector, the respective scaling factors are randomly generated from a uniform distribution within a range and this range is varied inversely with the magnitude of the differential vector along the corresponding dimension. DDEBQ generates the scaling factors for each jth component in the following way:</p><formula xml:id="formula_15">r ik f ( X k,G ) f ( X i,G ) -1 (k = 1, 2, . . . ,</formula><formula xml:id="formula_16">r ik 1 -f ( X k,G ) f ( X i,G ) (k = 1,</formula><formula xml:id="formula_17">F j mem = 0.3 + 0.7 • rand j i [0, 1] • 1 - |x j mem,G -x j i,G | |SR j | (9a) F j bw = 0.3 + 0.7 • rand j i [0, 1] • 1 - |x j best,G -x j worst,G | |SR j | (9b)</formula><p>where |SR j | is the search range corresponding to the jth dimension. Clearly, as the difference increases, i.e., approaches |SR j |, the value of the scaling factor reduces to 0.3. Zaharie <ref type="bibr" target="#b24">[25]</ref> suggested that the values of F, which satisfy the equation, 2F 2 -2 m + Cr m = 0 can be considered to be critical.</p><p>Here, m is the number of individuals in a subpopulation. In case of a single population algorithm, m should be replaced by Np. In DDEBQ, Cr is kept constant at 0.9 and m is six. Putting these values in the equation, the critical value for the scaling factor F becomes 0.285. Therefore, the lowest value of the scaling factor is set to 0.3 for convenience. However, the above equation can be used only for the DE/rand/1/bin scheme <ref type="bibr" target="#b1">(2)</ref>. For the DE-variants involving best individuals, the expression describing the influence of F and Cr becomes more complicated. The above equation is used here only to provide an indication of the actual critical value of F; it is not meant to give a precise estimate.</p><p>2) Second Stage Mutation: A linear combination of the mutant vector from the 1st stage of mutation to the local best vector is formed by using a weight factor. This way the local best vector is perturbed in a controlled manner. The second mutation can be expressed as</p><formula xml:id="formula_18">V final,G = (1 -ω) • L b,G + ω • V mut,G<label>(10)</label></formula><p>where L b,G is the local best vector, i.e., the best vector of the corresponding subpopulation, V mut,G is the mutant vector generated from 1st stage mutation and ω is the weight factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Exclusion Rule</head><p>In DDEBQ, an exclusion rule is employed to ensure that different subpopulations are located around different basins of attraction. However, this rule is slightly different from the existing one <ref type="bibr" target="#b7">[8]</ref> as it uses a new empirical formula to calculate the marginal distance between two subpopulations. Here, the strategy is to calculate the Euclidean distance between the best individuals from two different subpopulations at each generation. If the distance between the best individuals of any two subpopulations falls below a marginal value, then the subpopulation having the best individual of lower objective function value (i.e., worse fitness for a maximization problem) between the two is marked for reinitialization. The marginal value of the distance is calculated according to the following rule:</p><p>If there are D dimensions with search ranges SR and there are Nsub subpopulations, then the marginal value for the distance is</p><formula xml:id="formula_19">Dis marginal = SR/(Nsub • D). (<label>11</label></formula><formula xml:id="formula_20">)</formula><p>Here, the idea is to partition the search space almost equally among the Nsub subpopulations. Note that the DyneDE <ref type="bibr" target="#b7">[8]</ref> algorithm uses the linear diameter of the basin of attraction as an indicator for this exclusion radius. Unlike DyneDE's exclusion scheme [(1) of <ref type="bibr" target="#b7">[8]</ref>], the formula given in <ref type="bibr" target="#b11">(12)</ref> does not make implicit assumption that the peaks are evenly distributed in the search space. It also eliminates the need for knowing the number of peaks of the objective function beforehand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Aging Mechanism</head><p>DDEBQ employs a simple aging mechanism to get rid of the individuals stagnating at some local optimum. Algorithm 1 In the same way, the (i, j)th entry of Age -worst matrix represents how many times consecutively the jth individual of ith subpopulation has been the worst individual of the ith subpopulation. If an individual is reinitialized owing to its consistently bad performance then the corresponding entry of the Age -worst matrix is reset to 0 but the Age -best matrix remains unaltered. If a subpopulation is reinitialized due to stagnating at any local optimum, then the corresponding row entries of the Age -best and Age -worst matrices are all reset to 0. The reinitialization is done randomly covering the entire search space.</p><p>Aging is a heuristic method and its objective is to reinitialize the individuals that may be trapped at some local optimum. Except for the experimental results, it is difficult to justify the choice for the thresholds. They should be set in such a fashion that the reinitialization may occur only when stagnation is heuristically sensed. In DDEBQ, the aging thresholds are set to 30 and 20 for Age -best and Age -worst, respectively, through a series of experiments carried on the available benchmarks. A lower aging threshold will mean more reinitializations that might be unnecessary whereas a high aging threshold will mean more wastage of FEs to achieve the same level of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Adaptation of Control Parameter and Radius of Generating Quantum Individuals</head><p>In order to actuate the diversity within the subpopulations, a control parameter is introduced in DDEBQ. Depending on the conditions, this parameter can take any value among 0, 1, and 2. This parameter, denoted by C, helps the search process to achieve better convergence characteristics. If C becomes one, then, the quantum individuals are not generated; if C becomes two, then, the Brownian individuals are not generated, and if C becomes 0 then the search process progresses in normal way, i.e., with quantum, Brownian, and DE individuals.</p><p>As mentioned previously, when C is 0, the algorithm generates all the individuals (DE, Brownian, and quantum) to maintain the diversity at a higher level. When the population concentrates around a global best position before the occurrence of a dynamic change, as determined by the control parameter C, the diversity should be reduced separately within each of the subpopulations to ensure high precision in locating the global optima. If the diversity of the individuals in each of the subpopulations is reduced separately, then irrespective of the whole population's diversity, the subpopulation containing the global best individual converges to the global best position and the algorithm is likely to achieve a high degree of accuracy. In this way, while preserving the population diversity as a whole, DDEBQ can also obtain high quality solutions. This is possible because the subpopulations are located at different regions of the search space due to the exclusion rule, which is described earlier. In DDEBQ, the diversity is reduced in two steps, first by stopping the generation of quantum individuals and then by stopping the generation of Brownian individuals and starting the generation of quantum individuals. As quantum individuals are likely to possess less diversity than Brownian individuals <ref type="bibr" target="#b25">[26]</ref>, after the second step, the diversity is expected to decrease more.</p><p>The value of C is chosen in the following way. First, the difference of the global best objective function values before and after the first update interval (UI) generations is defined as PR. From this point onward, if the global best objective function values over UI generations have a difference greater than PR, then the current value of PR is replaced by this new value. If the difference becomes less than (PR /10) but greater than (PR /50), then C is set to one. If the difference is less than (PR /50), then C is set to two. A value too low as indicated by (PR /50), indicates that the algorithm has not experienced severe explorations in last UI generations and it can be concluded to be incisively searching around a possible optima. A higher value, even greater than (PR /10), can be referred to be in its explorative phase. A moderate value within these extremes can indicate an algorithm in its balanced explorative and exploitative phase. With respect to these values the control parameter C can be determined, which wheels the dynamics of the search process in DDEBQ by controlling the generation of the Brownian and quantum individuals. The strategy for adapting control parameter C is presented as Algorithm 2.</p><p>Note that the adaptation of C depends on monitoring of the progress of search (in terms of the frequency of variation of the globally best individual) at regular intervals and this bears some conceptual resemblance with the cooling schedules used in adaptive simulated annealing (SA) algorithms <ref type="bibr" target="#b26">[27]</ref>. For example, the cooling schedule in hide-and-seek SA <ref type="bibr" target="#b27">[28]</ref> depends on the best objective function values obtained up to a certain number of generations and an estimation of the unknown global optimum after the same number of generations. The performance is monitored after a specific UI (defined in  </p><formula xml:id="formula_21">k = |Gbest fit k -Gbest fit k-1 | 8. if PR k &gt; PR k-1 9. Update PR. 10. if (PR k -PR k-1 ) &lt; PR k-1 /50, C = 2 11. else if PR k-1 /50 &lt; (PR k -PR k-1 ) &lt; PR k-1 /10, C = 1 12. else C = 0. 13. k = k + 1.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Dynamic Dimensional Change Addressing</head><p>In addition to changing the search landscape and thereby changing the functional values of the individuals, some challenging benchmark problems, such as GDBG with change type T7 <ref type="bibr" target="#b6">[7]</ref>, accompanies altering height, width, position of the optima, varying dynamics in orientation, scalability of the problem as well as a dimensionality contrast after a specific number of FEs. In that case, the algorithm needs to detect whether a dimensional change has occurred or not. The objective function of GDBG changes the dimension by some rules within a limit. It modifies the current solution vector by adding or deleting dimensions of the current solution and returns the changed dimension of the problem along with the modified solution vector. Hence, the occurrence of a dimensional change can be detected by examining the test solution vector returned by the cost function in every generation. Whenever the dimension of the new test solution returned by the cost function does not match the dimension of the previous one, it can be inferred that a dimensional change has occurred in the environment. If the dimension is increased by one, then an extra dimension is added to the other individuals within the population. The values of extra dimensions of the individuals are randomly sampled from a uniform distribution within the corresponding bounds of the search space. If the dimension is decreased by one, then the additional dimension of other individuals within the population is eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Complexity Issues-Empirical Discussion</head><p>Apart from the computational burdens of evaluating the objective function (measured in terms of the number of FEs), another aspect of complexity of the algorithm can arise from the calculations of Euclidian distances between the current individual and the memory individuals during construction of the mutant vector for the current individual. This is because computing the Euclidean distances can demand a considerable amount of processor time. If each subpopulation contains m number of individuals and the total population size is denoted by Np then the number of subpopulations is N sub = (Np/m)). As the memory archive contains the best individuals from each subpopulation, the number of memory individuals is also(Np/m). Hence, the total number of evaluations of Euclidian distances in one generation is total population size × number of evaluations of Euclidian distances for each individual. Therefore, the total number of evaluations of Euclidian distances in one generation is Np 2 m . As can be observed, if the number of individuals in each subpopulation is increased, i.e., as the multipopulation scheme approaches to a single-population scheme, part of the complexity of the algorithm decreases but it also loses the effectiveness of having multiple subpopulations. On the other hand, if the number of subpopulations is increased, the number of individuals in each subpopulation decreases and the complexity of the algorithm increases (the complexity gradually approachesO(Np 2 )), but the effectiveness of the multipopulation scheme increases. Note that, according to Yang and Li <ref type="bibr" target="#b28">[29]</ref>, the timing complexity of the clustering operation in the clustering PSO algorithm that also uses Euclidean distance calculations heavily is O(Np 2 ), Np being the initial population size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Repairing Rule</head><p>For every newly generated individual (whether it is a DE, Brownian, or adaptive quantum individual), the algorithm checks whether any component of the new individual is outside the bounds. If any component is outside the bound, then it is randomly reinitialized by sampling from a uniform distribution within the bounds as per <ref type="bibr" target="#b0">(1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Benchmark Problems</head><p>CEC 2009 benchmark problems for dynamic optimization were generated by using the GDBG system proposed in <ref type="bibr" target="#b6">[7]</ref>, which constructs dynamic environments for the location, height, and width of peaks. Li et al. <ref type="bibr" target="#b6">[7]</ref> introduced a rotation method instead of shifting the positions of peaks as done in the MPB <ref type="bibr" target="#b29">[30]</ref> problems. The GDBG system poses greater challenges for optimization than the MPB problems due to the rotation method, larger number of local optima, and higher dimensionalities. There are seven change types for each test functions in the GDBG system, which are small step change, large step change, random change, chaotic change, recurrent change, recurrent change with noise, and dimensional change.</p><p>The test functions in real space instance are as follows: F1: rotation peak function, F2: composition of sphere functions, F3: composition of Rastrigin's functions, F4: composition of Griewank's functions, F5: composition of Ackley's functions and F6: hybrid composition functions. Only F1 is a maximization problem and others are minimization problems. In F1, there are two tests, one using 10 peaks and another using 50 peaks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Simulation Strategies</head><p>Simulation environment (hardware and software) used for carrying out the experiments described in the subsequent sections can be summarized as CPU: 3.2 GHz Intel Core i5, RAM: 2 GB DDR3, and MATLAB 2009b edition. The performance of DDEBQ is measured in terms of the mean error <ref type="bibr" target="#b6">[7]</ref> and the adaptability metric <ref type="bibr" target="#b30">[31]</ref> obtained in 20 independent runs. The mean error is calculated according to the following expression <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_22">E mean = 1 (runs * num change) runs i=1 num change j=1 E last i,j . (<label>13</label></formula><p>) Here, runs is the total number of runs, num -change is the number of dynamic changes that occur during each independent run, and E last i,j is the error recorded before the jth dynamic change of ith independent run. Note that the error E last corresponds to the absolute fitness difference between the best solution found by an EA (before a landscape change) and the known best solution (for that landscape), i.e., E last (t) = f ( X best (t))f ( X * (t)) . In all result tables, the best results are marked in boldface.</p><p>The adaptability metric measures a difference between the value of the current best individual of each generation and the optimum value averaged over the entire run and can be expressed as</p><formula xml:id="formula_23">Ada = 1 num change num change i=1 ⎡ ⎣ 1 τ τ-1 j=0 err i,j ⎤ ⎦ (<label>14</label></formula><formula xml:id="formula_24">)</formula><p>where τ is the number of generations between changes when the environment remains static. err i, j denotes the absolute difference between the fitness values of the current best individual in the population of the jth generation and after the last change and the optimum value for the fitness landscape after the ith change. Evidently for both mean error and adaptability, the smaller the measured values are, the better the result is. For results of the comparative studies, a nonparametric statistical test, called the Wilcoxon's rank sum test for independent samples <ref type="bibr" target="#b31">[32]</ref>, is conducted at the 5% significance level, in order to judge the statistical significance of the best results obtained in each experimental scenario. The statistical test results are indicated within parentheses throughout all the result tables as "+", " -", or "≈", when the result of DDEBQ is statistically significantly better than, worse than, or statistically equivalent to the corresponding result, respectively. The rank sum test is conducted between the results of DDEBQ and the other dynamic EAs considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Parameter Settings</head><p>Table <ref type="table">1</ref> lists the parametric values that keep the performance of DDEBQ considerably good over a wide range of benchmarks. Please refer to the supplementary document for a detailed account of the simulation experiments that empirically validate these values. Also once set, the same parameter values are used for DDEBQ on all the benchmark instances of GDBG in Section V, where performance of the algorithm is compared with some of the best-known evolutionary DOP solvers. No function-dependent tuning of the parameters is allowed anywhere for DDEBQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Results and Discussions</head><p>This section presents a comparative study of the performance of DDEBQ with several other state-of-the-art evolutionary dynamic optimizers on the GDBG benchmarks. The performance of DDEBQ is compared with the following seven algorithms by using the benchmark suite of the GDBG system: Differential Ant-Stigmergy Algorithm (DASA) <ref type="bibr" target="#b32">[33]</ref>, jDE <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b32">[33]</ref>, DynDE <ref type="bibr" target="#b8">[9]</ref>, dopt-aiNET <ref type="bibr" target="#b33">[34]</ref>, CPSO <ref type="bibr" target="#b27">[28]</ref>, CESO <ref type="bibr" target="#b20">[21]</ref>, and PSO with Composite particles (PSO-CP) <ref type="bibr" target="#b34">[35]</ref>. DASA is based on the classical ant colony optimization methods. CPSO uses a hierarchical clustering method to locate and track multiple peaks. In addition, CPSO incorporates a fast local search method to search for optimal solutions in a promising subregion found by the clustering method. PSO-CP uses the idea of composite particles from physics to maintain the diversity of the population through a scattering operator. Dopt-aiNet introduces a set of complementary mutation operators and a better mechanism to maintain the diversity of solutions in the original opt-aiNet <ref type="bibr" target="#b35">[36]</ref> algorithm, which was meant for solving static and multimodal function optimization problems For the competitor algorithms, the best parametric setup is employed in accordance with their respective literatures. An identical experimental condition guided by the technical report of <ref type="bibr" target="#b6">[7]</ref> is maintained for all the algorithms compared. Tables II and III provide the simulation results obtained over all the test cases mentioned in <ref type="bibr" target="#b6">[7]</ref> by using DDEBQ and seven other algorithms in terms of the mean best-of the-run error values and the adaptability metric values achieved over 20 independent runs. The tables also show the average runtime (in seconds) consumed by all the algorithms compared. Sample convergence graphs are provided for functions F1 (number of peaks = 10), F2, F3, F4, F5, and F6 with change type T7 over 300,000 FEs in Fig. <ref type="figure" target="#fig_1">1</ref>. In this case, dimension of the search space changes when the dynamic change occurs. This change type is similar to T3 (random change) except for the dimensional change. The y-axis of these plots contains the relative value r(t) that is calculated as f ( X best (t))/f ( X * (t)) for function F1 (as it is a maximization problem) and for other functions as f ( X * (t))/f ( X best (t)). The highest possible value of r(t) is one. As can be observed from the convergence graphs, the relative value is lowest in case of function F3 and it is highest in case of function F1. The convergence characteristics also indicate that as each dynamic change occurs, the relative value r(t) attains a sharp downfall.</p><p>A close scrutiny of Tables II and III reveals that DDEBQ outperforms all the seven evolutionary dynamic optimizers in a statistically significant fashion over 36 out of the 49 test instances. It yielded statistically inferior results compared to any one of the competitor algorithms in four test instances and statistically equivalent results with one or two competitors over the rest nine instances. For function F3, the jDE algorithm could attain lower best error values than DDEBQ over change types T2, T4, and T6. However, results of the Wilcoxon's rank sum test reveals that for change types T1, T3, T5, and T7, the differences between the results of jDE and DDEBQ are not statistically significant. Also DDEBQ exhibited a statistically better performance than the other six EAs for all the change   The exclusion rule also helps the algorithm to explore much greater portion of the search space-a feature that leads to high success rate in locating the global optimum. Also, a high degree of precision in locating the global optimum observed in rotation peak function (F1 with number of peaks = 10, 50) is a consequence of introducing the control parameter C that has an important role in controlling the diversity of the population and adaptively changing the radius within which the quantum individuals are to be generated. From the average runtimes listed in Tables II and III, it is evident that the runtime of DDEBQ is in several cases comparable to DyneDE, dopt-aiNet, and CESO. However, CPSO takes higher average runtime on most of the functions due to the incurrence of several Euclidean distance calculations. PSO-CP also involves various computational overheads and in general is slower or comparable to DDEBQ in majority of the cases. DASA and jDE appear to be marginally faster than DDEBQ. However, when the accuracy appears to be the major bottleneck, DDEBQ has several advantages to offer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Conclusion</head><p>In this paper, a variant of the DE algorithm referred to as DDEBQ is proposed to solve DOPs in a statistically efficient manner. The proposed algorithm uses a dynamic DE scheme that obviously shares the traditional DE framework. In addition to DE individuals, it uses adaptive quantum and Brownian individuals to increase the diversity and exploration ability of the search process. A control parameter is introduced to control the diversity as necessary. The algorithm also employs an aging mechanism to get rid of stagnation. The DE individuals produce the donor vectors according to a neighborhood-based double mutation strategy to control the perturbation. An exclusion scheme is used so that the subpopulations become evenly distributed over the entire search space.</p><p>The statistical summary of the simulation results indicates that DDEBQ can provide consistently superior performance as compared to the other state-of-the-art evolutionary dynamic optimizers in terms of average level of accuracy. Future work may focus on introducing more co-operation and information exchange among the subpopulations in DDEBQ. It can also be fruitful to make the crossover probability adaptive to the condition of the fitness landscape. Algorithmic components of DDEBQ can be integrated with some of the adaptive DE variants ( <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>) to improve their performance on dynamic landscapes as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>2, . . . , m and k = i) is maximum among all individuals within the subpopulation. x j mem,G denotes jth component of the nearest memory individual (memory individuals are the best individuals from the previous subpopulations) to X i,G in terms of Euclidean distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample convergence graphs for DDEBQ algorithm. (a) For F1 with T7. (b) For F2 with T7. (c) For F3 with T7. (d) For F4 with T7. (e) For F5 with T7. (f) For F6 with T7. types of F3. For all the change types of the functions F1, F2, F4, and F5, and for change types T1, T4, T5, T7 of F6, DDEBQ yielded statistically superior performance to jDE, which was the winner of 2009 IEEE CEC Competition on Evolutionary Dynamic Optimizers.DDEBQ performed statistically better than CPSO in all test cases. There are two test instances where DDEBQ performed statistically similar to CESO (F4 with T6, F6 with T1). DDEBQ performed worse than PSO-CP and comparable to DynDE in only one instance: F4 with change type T7. In 43 out of the 49 tested instances, DDEBQ achieved the lowest values of the adaptability metric. This indicates that for majority of the tested instances the best individual in the DDEBQ population remained closer the optimum for all generations, i.e., the optimum was better tracked by the proposed algorithm. For function F3 with change types T2, T4, and T6, jDE yielded the best adaptability metric values while DDEBQ attained the second best values. For function F6 with change types T3 and T4, despite yielding the lowest mean errors, DDEBQ was marginally surpassed by jDE in terms of the adaptability values. Note that for the instances where DDEBQ is statistically outperformed by any one of the seven contender algorithms, it ranked second best outperforming the other six algorithms. No other evolutionary DOP solver considered in this article could keep such a consistent performance on the wide variety of the tested DOP instances. As the double mutation strategy prevents the population from converging too quickly and the aging mechanism helps the population to get rid of local optima, DDEBQ is able to perform very well over such highly complex and multimodal functions. Extremely good performances over the sphere function (F2), the Ackley's function (F5), and the composition function (F6) have resulted from the incorporation of the dynamic DE scheme and exclusion principle. As the dynamic DE scheme maintains a good diversity level of the population, DDEBQ is able to locate the global optimum after any dynamic change more efficiently than other algorithms. The exclusion rule also helps the algorithm to explore much greater portion of the search space-a feature that leads to</figDesc><graphic coords="11,66.72,53.72,477.60,192.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,139.22,114.01,332.88,624.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,57.50,233.28,237.60,316.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>2 max , ..., x D max and X min = x 1 min , x 2 min , ..., x D min . The jth component of the ith individual is initialized in the following way:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Algorithm 1 Algorithm for Aging Mechanism: (</head><label></label><figDesc>Considering jth individual of the ith subpopulation) 1. if the ith subpopulation contains the global best individual, then do not perform aging mechanism on the subpopulation. 2. else if the j-th individual is the best individual in the i-th subpopulation, then Age -best(i, j) = Age -best(i, j) + 1. if Age -best(i, j) ≥ 30, then reinitialize the i-th subpopulation and reset Age -best(i,:) and Age -worst(i,:) entries to 0. 3. else if j-th individual is the worst individual in the i-th subpopulation, then Age -worst(i, j) = Age -worst(i, j) + 1. if Age -worst(i, j) ≥ 20, then reinitialize the individual and reset Age -worst(i, j) entries to 0 leaving other members of the subpopulation intact. 4. else the Age -worst(i, j) and Age -best(i, j) of the j-th individual are reset to 0. shows a schematic procedure to implement the aging mechanism. Age -best and Age -worst are two matrices with dimensions (Nsub, m), m being the number of individuals per subpopulation. The (i, j)th entry of Age -best matrix represents how many times consecutively the jth individual of ith subpopulation has been the best individual of the ith subpopulation.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Algorithm 2</head><label>2</label><figDesc>Algorithm for Control Parameter (C) Adaptation 1. Initialize generation counter G = 0 and calculate initial Gbest fit 0 = f ( X best,0 ), C = 0. // X best,G is the globally best solution at generation G and f (.) is the function under test. 2. Initialize counter k = 1. 3. Start Loop 4. Carry out the optimization steps of DDEBQ 5. if mod (Gen, UI) == 0 6. Calculate new Gbest fit k = f ( X best,G ). 7. Calculate PR k as:PR</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>14. G=G+1 15. if termination condition satisfies break Loop, else return to Step 4. the terminology list of the appendix). Based on the rate of change of the globally best solution during the intervals of the UI number of generations, the diversity is controlled by generating either Brownian or adaptive quantum or both kinds of individuals. Hence, selecting a proper value for frequency of update is decisive to performance of the algorithm. If the test is conducted too frequently, i.e., UI is very low, the search agents may not get enough scope to thoroughly explore the space. On the other hand, if UI is relatively high with respect to the frequency of occurrence of the dynamical changes, the detection of proper stages of optimization may be hampered. For GDBG problems, where E is 100000 FEs, UI = 20 gives optimal performance. In fact, the performance of the algorithm is not sensitive to UI values lying in the range of 15 to 35 and remains more or less consistent on different benchmarks from the GDBG suite. Our simulation experiments (not reported in the paper for space economy) indicate that a lower value of UI is suitable for lower change intervals while a higher value of UI is suited to higher change intervals. From our detailed empirical study, a value of UI = 20 can provide optimized performance over a wide range of functions. It can be noted that UI of 20 is in same range as aging thresholds age -best and age -worst. In the experimentation part, UI is fixed to 20 for all benchmark instances and no problem specific tunings were allowed. Adaptation of the radius R for the generation of control parameters depend on C. If C is 0, then R is set to one. If C is two, then R changes according to the following rule depending upon the difference (Diff ) of global best objective function values before and after UI generations</figDesc><table><row><cell>R = Diff • log 10 10 +</cell><cell>PR 50 • Diff</cell><cell>.</cell><cell>(12)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE I</head><label>I</label><figDesc></figDesc><table><row><cell>Experimentally Determined Best Parametric Settings</cell></row><row><cell>for DDEBQ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE II Mean</head><label>II</label><figDesc>Error Values, Ada Metric Values, and Average Runtime (in Seconds) Achieved by the Algorithms Compared for Test Functions F1-F3 of the GDBG System. Wilcoxon's Rank Sum Test Results of Comparing DDEBQ With the Contender Algorithms Indicated in Parentheses.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE III Mean</head><label>III</label><figDesc>Error Values and Standard Deviations Achieved by DDEBQ and Other Algorithms for Test Functions F4-F6 of GDBG System. Wilcoxon's Rank Sum Test Results of Comparing DDEBQ With Contender Algorithms Indicated in Parentheses.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rohan Mukherjee was born in West Bengal, India, in 1992. He is currently pursuing the B.E. degree in electronics and telecommunication engineering at Jadavpur University, Kolkata, India.</p><p>He has published research articles in peer-reviewed journals and international conference proceedings under the guidance of his teacher Dr. Swagatam Das. He has acted as a reviewer for international conferences. His current research interests include smart grids, game theoretic applications, power systems, wireless communications, and evolutionary computing.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Differential evolution: A simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Differential evolution: A survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="31" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evolutionary optimization in uncertain environments: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="317" />
			<date type="published" when="2005-06">Jun. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evolutionary optimization in nonstationary environments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Trojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="93" to="124" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On-line purchasing strategies for an evolutionary algorithm performing resource-constrained optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Allmendinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PPSN XI</title>
		<meeting>PPSN XI</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="161" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On stagnation of the differential evolution algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zelinka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Mendel Conf. Soft Comput</title>
		<meeting>6th Int. Mendel Conf. Soft Comput</meeting>
		<imprint>
			<date type="published" when="2000-06">Jun. 2000</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Benchmark generator for CEC&apos;2009 competition on dynamic optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008-09">Sep. 2008</date>
		</imprint>
		<respStmt>
			<orgName>Univ. Leicester, Univ. Birmingham, Nanyang Technol. Univ., Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">DynDE: A differential evolution for dynamic optimization problems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Mohais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2005-09">Sep. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2808" to="2815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic optimization using self-adaptive differential evolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zamuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boskovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Maucec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2009-05">May 2009</date>
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimization of dynamic systems: A trigonometric differential evolution approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Angira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Chem. Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1055" to="1063" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A trigonometric mutation operation to differential evolution</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optimization</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="129" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using competitive population evaluation in a differential evolution algorithm for dynamic environments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="20" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CellularDE: A cellular based differential evolution for dynamic optimization problems</title>
		<author>
			<persName><forename type="first">V</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Meybodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICANNGA, part I</title>
		<title level="s">LNCS</title>
		<meeting>ICANNGA, part I</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6593</biblScope>
			<biblScope unit="page" from="340" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A cluster-based differential evolution algorithm with external archive for optimization in dynamic environments</title>
		<author>
			<persName><forename type="first">U</forename><surname>Halder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maity</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="881" to="897" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-parameter evolutionary multimodal optimization: A survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B-Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="71" to="88" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multimodal optimization using a biobjective differential evolution algorithm enhanced with mean distance based selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multimodal optimization using crowding-based differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thomsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="1382" to="1389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evolutionary multimodal optimization using the principle of locality</title>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K P</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="138" to="170" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Locating and tracking multiple dynamic optima by a particle swarm model using speciation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Parrott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="440" to="458" />
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Particle swarm with speciation and adaptation in a dynamic environment</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A collaborative model for tracking optima in dynamic environments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dumitrescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="564" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evolutionary swarm cooperative optimization in dynamic environments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dumitrescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An evolutionary algorithm with species-specific explosion for multimodal optimization</title>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Genetic Evol. Comput. Conf</title>
		<imprint>
			<biblScope unit="page" from="923" to="930" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Differential evolution using a neighborhood based mutation operator</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="526" to="553" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Critical values for the control parameters of differential evolution algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaharie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Mendel Conf. Soft Comput</title>
		<meeting>8th Int. Mendel Conf. Soft Comput</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="62" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Particle swarm optimization in dynamic environments</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Computation in Dynamic and Uncertain Environments</title>
		<editor>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Ong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jin</forename><surname>Eds</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="29" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adaptive simulated annealing (ASA): Lessons learned</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ingber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Cybern</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="54" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simulated annealing for constrained global optimization</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Romeijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optimization</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="126" />
			<date type="published" when="1994-09">Sep. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A clustering particle swarm optimizer for locating and tracking multiple optima in dynamic environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="959" to="974" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Memory enhanced evolutionary algorithms for changing optimization problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1875" to="1882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Searching for optima in nonstationary environments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Trojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1843" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Differential evolution and differential antstigmergy on dynamic optimisation problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Korošec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Šilc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zamuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bošković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Sepesy</forename><surname>Maučec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="663" to="679" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A dynamic artificial immune algorithm applied to challenging benchmarking problems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">O</forename><surname>De Franca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Von Zuben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with composite particles in dynamic environments</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1634" to="1648" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An artificial immune network for multimodal optimization</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>De Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Timmis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="page" from="699" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An adaptive differential evolution algorithm with novel mutation and crossover strategies for global numerical optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="482" to="500" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Enhanced differential evolution with adaptive strategies for numerical optimization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="397" to="413" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
