<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Learning and Control for MIMO System Based on Adaptive Dynamic Programming</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jian</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Haibo</forename><surname>He</surname></persName>
							<email>he@ele.uri.edu</email>
						</author>
						<author>
							<persName><forename type="first">Xinmin</forename><surname>Zhou</surname></persName>
							<email>zhouxinmin2003@163.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Wuhan University of Technol-ogy</orgName>
								<address>
									<postCode>430070</postCode>
									<settlement>Wuhan</settlement>
									<region>Hubei</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical, Computer, and Biomedical Engineering</orgName>
								<orgName type="institution">University of Rhode Island</orgName>
								<address>
									<postCode>02881</postCode>
									<settlement>Kingston</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical, Computer and Biomedical Engineering</orgName>
								<orgName type="institution">University of Rhode Island</orgName>
								<address>
									<postCode>02881</postCode>
									<settlement>Kingston</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Wuhan University of Technol-ogy</orgName>
								<address>
									<postCode>430070</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Learning and Control for MIMO System Based on Adaptive Dynamic Programming</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">36005E73357281FC61BEEDFE4DB316CC</idno>
					<idno type="DOI">10.1109/TNN.2011.2147797</idno>
					<note type="submission">received October 15, 2010; revised February 21, 2011; accepted April 6, 2011. Date of publication June 17, 2011; date of current version July 7, 2011. This work was supported in part by the National Science Foundation under Grant ECCS 1053717.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Adaptive dynamic programming</term>
					<term>Levenberg-Marquardt method</term>
					<term>looper system</term>
					<term>multiple-input-multipleoutput</term>
					<term>online learning and control</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Adaptive dynamic programming (ADP) is a promising research field for design of intelligent controllers, which can both learn on-the-fly and exhibit optimal behavior. Over the past decades, several generations of ADP design have been proposed in the literature, which have demonstrated many successful applications in various benchmarks and industrial applications. While many of the existing researches focus on multiple-inputs-single-output system with steepest descent search, in this paper we investigate a generalized multiple-input-multipleoutput (GMIMO) ADP design for online learning and control, which is more applicable to a wide range of practical realworld applications. Furthermore, an improved weight-updating algorithm based on recursive Levenberg-Marquardt methods is presented and embodied in the GMIMO approach to improve its performance. Finally, we test the performance of this approach based on a practical complex system, namely, the learning and control of the tension and height of the looper system in a hot strip mill. Experimental results demonstrate that the proposed approach can achieve effective and robust performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>given a system with a performance cost function, the objective of dynamic programming is to choose a control sequence u(k) so that the cost function is minimized</p><formula xml:id="formula_0">J * (x(k)) = min u(k) U (x(k), u(k)) + α J * (x(k + 1))<label>(1)</label></formula><p>where x(k) is the state vector of the system, u(k) is the control action, U is the immediate cost, and α is a discount factor. In this way, ADP can successfully achieve learning and control by using a functional approaching structure to approximate the cost function in order to get similar resolution as with the Bellman equation which overcomes "the curse of dimensionality" <ref type="bibr" target="#b10">[11]</ref> to a great extent. For instance, universal approximators like neural networks with the backpropagation have been widely adopted in the literature.</p><p>Existing ADP design can be categorized into three major groups: heuristic dynamic programming (HDP), dual heuristic dynamic programming (DHP), and globalized dual heuristic dynamic programming (GDHP) <ref type="bibr" target="#b3">[4]</ref>. Many variations of these major categories of approaches, such as the actiondependent (AD) version of these methods, have also been developed in the community. Some important recent research in this field include the development of the second generation of ADP design ("two-brains-in-one model" <ref type="bibr" target="#b1">[2]</ref>) and the further advancement toward the "mouse-level intelligence" in the third and fourth generation of ADP design. We encourage the readers to refer to <ref type="bibr" target="#b1">[2]</ref> for a detailed discussion on this. We would also like to note that since ADP is an interdisciplinary field, different terminologies are used in different situations, such as adaptive critic design, neurodynamic programming (NDP), and approximate dynamic programming <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. In this paper, we adopt the term ADP for uniformity throughout.</p><p>As far as engineering applications are concerned, many successful cases have been presented. For instance, in <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b14">[15]</ref>, ADP has been successfully applied to complex helicopter control based on a structured cascade action network and an associated trim network. In <ref type="bibr" target="#b15">[16]</ref>, a synchronous generator neurocontroller in a power system with an HDP structure was implemented by multilayer perceptron (MLP) and radial basis function neural networks. Online process control of a continuously stirred tank reactor based on temporal difference (TD) Levenberg-Marquardt (LM) algorithms was presented in <ref type="bibr" target="#b16">[17]</ref>, and tracking applications in engine torque and air fuel ratio control were presented in <ref type="bibr" target="#b17">[18]</ref> by ADP design with timelagged recurrent neural network.</p><p>Although there are many successful ADP applications, many of the existing studies either consider only a single output control variable or require extensive domain knowledge. Motivated by our previous research results in <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>, in this paper we aim to develop a general multiple-input-multipleoutput (GMIMO) ADP structure and study its application in the looper system of a hot strip mill, which is a typical nonlinear closely coupled MIMO system. The main challenges in a looper controller design arise from the coupling between its two target outputs: external disturbances and inner perturbation. Nearly every branch of the modern and classical control theory has studied the problem of looper control <ref type="bibr" target="#b21">[22]</ref>. For instance, the mixed sensitivity method was recently proposed in <ref type="bibr" target="#b22">[23]</ref> to reduce tension fluctuation. In <ref type="bibr" target="#b23">[24]</ref>, an adaptive robust looper controller is studied by online estimation of the damping coefficient for the looper system. A fuzzy logic control with online self-tuning method implemented by neural network was presented in <ref type="bibr" target="#b24">[25]</ref> to achieve improved performance. The track of research in this area indicates more or less that the underlying philosophy is transferred from passive tolerating the environment to active learning from it.</p><p>To our best knowledge, this is the first study investigating ADP techniques for complex industrial MIMO system of looper control. In addition to the development of a GMIMO ADP structure, we also embed an improved weight-updating scheme based on recursive LM method in our approach to improve the learning robustness and convergence. We hope the proposed research in this paper will not only provide a useful framework for the ADP based research for MIMO systems but also will motivate future research and development of such techniques to other real systems beyond the looper control as discussed in this paper.</p><p>The rest of this paper is organized as follows. Section II presents the GMIMO ADP design and its implementation details, such as the adaptation and tuning of parameters in various neural networks. Section III provides revised recursive LM algorithm and its integration into the online weight updating of the proposed ADP structure, followed by an analysis of the convergence of the proposed approach in Section IV. In Section V, we present in detail the application to the height and tension control of the looper in a hot strip mill. In addition, detailed experimental settings and results are presented and analyzed. Finally, conclusions are given in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. FRAMEWORK FOR GENERALIZED ADP WITH MULTIPLE OUTPUTS</head><p>It is well known that many real engineering problems can be formulated as cost minimization (or reward maximization) problems, which can be achieved by employing an appropriate control strategy. Dynamic programming is one of the best candidates to solve these problems. For example, in the deterministic case, the expected operation can be calculated by the solution of the Hamilton-Jacobi-Bellman (HJB) equation, which gives the optimal cost-to-go for a given dynamical system with an associated cost function. However, the inherent disadvantage of such solving-backwards-in-time and the curse of dimensionality limits its application. ADP avoids such shortcomings by using a function approximation structure <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b25">[26]</ref>, such as a universal approximator like neural networks, to approximate the cost function instead of finding the exact solution of the HJB equation <ref type="bibr" target="#b4">[5]</ref>. In this paper, we build our MIMO ADP based on the classic ADP architecture as presented in [6, Fig. <ref type="figure">1</ref>]. In this structure, the TD is obtained by calculating the current cost-togo J (k) and its previous value J (k -1) in the diagram. The binary reinforcement signal r is provided from the external environment, which we mark as the reinforcement signal explicitly. There have been many discussions in the literature especially from the reinforcement learning point of view regarding the source and nature of the reward signal, such as the evolutionary style optimal reward function based on a fitness function and some distribution of environments <ref type="bibr" target="#b26">[27]</ref>, the concept of intrinsic reward and extrinsic reward <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b29">[30]</ref>, and others. In this paper, we use a simple strategy as adopted in many of the ADP research to use "0" and "-1" to represent "success" and "failure," respectively. Whereas a reward indicates what is good and what is bad in an immediate sense, a value function specifies what is good in the long term, which can be approximated by a critic network.</p><formula xml:id="formula_1">Action Network System Critic Network Critic Network u(k-1) X(k) X(k -1) r(k-1) + - - Reinforcement signal Uc α Action Network u(k) J(X(k-1)) J(X(k))</formula><p>The action neural network (ANN) and the critic neural network (CNN) are both randomly initialized in their weights at the beginning. Once a system state is determined, an action will be subsequently produced by the action network. Usually, an "appropriate" control value under the specific states makes the principle of optimality equation balanced approximately. Furthermore, these "appropriate" operations will be reinforced through memory and association between states and control output in the action network. Otherwise, the control value will be adjusted through tuning the weights by backpropagation or other methods in the action network to balance the equation of the principle of optimality as much as possible.</p><p>In many of the existing ADP designs <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b16">[17]</ref>, it is normally assumed that only one output value of the action network is required. In this paper, we generalize the output of the action network to multiple variables instead of a single one. The generalized approach can be applied in many real physical systems that require multiple control variables. For better illustration of the signal flows we considered in this paper, Fig. <ref type="figure">2</ref> shows the relationship between an action network and a critic network. We now proceed to discuss the detailed learning approach for such a system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Critic Network</head><p>We assume that a neural network with MLP system is used in both ANN and CNN. Therefore, in the critic network, the output can be defined as</p><formula xml:id="formula_2">q i (k) = N cin j =1</formula><p>w (1)  </p><formula xml:id="formula_3">c i j (k) • x j (k), i = 1, . . . , N ch (<label>2</label></formula><formula xml:id="formula_4">)</formula><formula xml:id="formula_5">p i (k) = 1 -exp -q i (k) 1 + exp -q i (k) , i = 1, . . . , N ch (3) J (k) = N ch i=1 w (2) c i (k) • p i (k) (4)</formula><p>where q i is the i th hidden node input of the critic network, p i is the corresponding output of the hidden node q i , N cin is the total number of the input nodes in the critic network including N x inputs from the system states and N out inputs from the output nodes in the action network, and N ch is the total number of the hidden nodes in the critic network. Similar to <ref type="bibr" target="#b5">[6]</ref>, in this structure J can be estimated by minimizing the following error over time:</p><formula xml:id="formula_6">E h = 1 2 k [J (k) -r (k) -α J (k + 1)] 2 . (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>When E h = 0 for all k, (5) implies</p><formula xml:id="formula_8">J (k) = r (k) + α J (k + 1) . (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>Putting one time step backward, we can get</p><formula xml:id="formula_10">J (k -1) = r (k -1) + α J (k) . (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>This is exactly illustrated in Fig 1 . So the objective function to be minimized in the critic network is</p><formula xml:id="formula_12">e c (k) = α J (k) -[ J (k -1) -r (k -1)] (8) E c (k) = 1 2 e 2 c (k) . (<label>9</label></formula><formula xml:id="formula_13">)</formula><p>We can reach the adaptation of the critic network by applying the chain backpropagation rule <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b30">[31]</ref>. This process is summarized as follows:</p><p>1) w <ref type="bibr" target="#b1">(2)</ref> c (hidden to output layer)</p><formula xml:id="formula_14">w (2) c i (k) = l c (k) - ∂ E c (k) ∂w (2) c i (k) , (<label>10</label></formula><formula xml:id="formula_15">)</formula><formula xml:id="formula_16">∂ E c (k) ∂w (2) c i (k) = ∂ E c (k) ∂e c (k) • ∂e c (k) ∂ J (k) • ∂ J (k) ∂w (2) c i (k) = αe c (k) p i (k) (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>where l c (k) &gt; 0 is the learning rate of the critic network at time k and w</p><p>(2</p><formula xml:id="formula_18">)</formula><p>c i is the weight between i th hidden node with output node in the critic network.</p><p>2) w (1)  c (input to hidden layer)</p><formula xml:id="formula_19">w (1) c i j (k) = l c (k) - ∂ E c (k) ∂w (1) c i j (k) , (<label>12</label></formula><formula xml:id="formula_20">)</formula><formula xml:id="formula_21">∂ E c (k) ∂w (1) c i j (k) = ∂ E c (k) ∂e c (k) • ∂e c (k) ∂ J (k) • ∂ J (k) ∂ p i (k) • ∂ p i (k) ∂q i (k) • ∂q i (k) ∂w (1) c i j (k)<label>(13)</label></formula><p>= αe c (k) w (2)  c i (k)</p><formula xml:id="formula_22">• 1 2 1 -p 2 i (k) • x j (k) (<label>14</label></formula><formula xml:id="formula_23">)</formula><p>where w</p><p>(1) c i j is the weight between j th input node with i th hidden node in the critic network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Action Network</head><p>Next, we investigate weight-tuning in the action network. Note that, in this case we consider the action network to have multiple control outputs N aout . The associated equations for the action network are k) , m = 1, . . . , N aout <ref type="bibr" target="#b17">(18)</ref> where h i is the i th hidden node input of the action network, g i is the i th hidden node output of the action network, v m is the mth output node input of the action network, u m is the mth output node output of the action network, N ain is the total number of the input nodes in the action network, N ah is the total number of the hidden nodes in the action network, and N aout is the total number of the output nodes in the action network.</p><formula xml:id="formula_24">h i (k) = N ain j =1 w (1) a i j (k) • x j (k), i = 1, . . . , N ah (<label>15</label></formula><formula xml:id="formula_25">)</formula><formula xml:id="formula_26">g i (k) = 1 -exp -h i (k) 1 + exp -h i (k) , i = 1, . . . , N ah (16) v m (k) = N ah i=1 w (2) a mi (k) • g i (k) , m = 1, . . . , N aout (<label>17</label></formula><formula xml:id="formula_27">)</formula><formula xml:id="formula_28">u m (k) = 1 -exp -v m (k) 1 + exp -v m (</formula><p>The purpose of adapting the action network is to implicitly backpropagate the error between the desired ultimate object U c and approximate J function from the critic network. U c is in accordance with the signal of the reinforcement when the state conducted by the action implies a success. In this paper, we set U c (k) equal to zero.</p><p>The error of the action network is defined as</p><formula xml:id="formula_29">e a (k) = J (k) -U c (<label>19</label></formula><formula xml:id="formula_30">)</formula><formula xml:id="formula_31">E a (k) = 1 2 e 2 a (k) . (<label>20</label></formula><formula xml:id="formula_32">)</formula><p>The update rule for the nonlinear multilayer action network also contains two sets of equations. When the classic gradient descent search is used, the generalized approach for MIMO system can be summarized as follows:</p><p>1) w (2)  a (hidden to output layer)</p><formula xml:id="formula_33">w (2) a mi = l a (k) - ∂ E a (k) ∂w (2) a mi (k) (21) ∂ E a (k) ∂w (2) a mi (k) = ∂ E a (k) ∂e a (k) • ∂e a (k) ∂ J (k) • ∂ J (k) ∂u m (k) • ∂u m (k) ∂v m (k) • ∂v m (k) ∂w (2)</formula><p>a mi (k)</p><formula xml:id="formula_34">(22) = ∂ E a (k) ∂e a (k) • ∂e a (k) ∂ J (k) • N ch l=1 ∂ J (k) ∂ p l (k) • ∂ p l (k) ∂q l (k) • ∂q l (k) ∂u m (k) • ∂u m (k) ∂v m (k) • ∂v m (k) ∂w (2)</formula><formula xml:id="formula_35">a mi (k) (23) = e a (k) 1 2 1 -u (2) m (k) g i (k) • N ch l=1 w (2) c l (k)• 1 2 1 -p 2 l (k) • w (1) c l(Nx +m) (k) . (<label>24</label></formula><formula xml:id="formula_36">)</formula><p>Here, u m (k) is the output of the action network, which also serves as part of the inputs to the critic network as well. One should note that under a MIMO scenario, the ∂ J (k)/∂u m (k) need to be calculated by summarizing the respective partial derivatives in all hidden nodes in the critic network. 2) w <ref type="bibr" target="#b0">(1)</ref> a (hidden to output layer) w (1)  a i j = l a (k) -</p><formula xml:id="formula_37">∂ E a (k) ∂w (1)</formula><formula xml:id="formula_38">a i j (k) (25) ∂ E a (k) ∂w (1)</formula><formula xml:id="formula_39">a i j (k) = ∂ E a (k) ∂e a (k) • ∂e a (k) ∂ J (k) • Naout m=1 ∂ J (k) ∂u m (k) • ∂u m (k) ∂v m (k) • ∂v m (k) ∂ g i (k) • ∂ g i (k) ∂h i (k) • ∂h i (k) ∂w (1) a i j (26) = ∂ E a (k) ∂e a (k) • ∂e a (k) ∂ J (k) • Naout m=1 ⎧ ⎨ ⎩ N ah l=1 ∂ J (k) ∂ p l (k) • ∂ p l (k) ∂q l (k) • ∂q l (k) ∂u m (k) ∂u m (k) ∂v m (k) • ∂v m (k) ∂ g i (k) • ∂ g i (k) ∂h i (k) • ∂h i (k)</formula><p>∂w (1)   </p><formula xml:id="formula_40">a i j (27) = Naout m=1 ⎧ ⎨ ⎩ N ah l=1 w (2) c l (k) w (1) c l(Nx +m) (k) 1 2 1 -p 2 l (k)</formula><p>w (2)  a mi (k) x j (k) We would like to note that, for the GMIMO system, the information provided by w (1) a i j , the hidden node p l of the CNN, and output node u m are all intermediate variables. They all contribute as a part to ∂ J (k)/∂w <ref type="bibr" target="#b0">(1)</ref> a i j (k) in terms of the nested pattern. In other words, there is a sum of derivatives on of p l (k) with respect to specific u m (k). Meanwhile, we need to calculate the sum of all the derivatives of u m (k).</p><formula xml:id="formula_41">1 2 1 -u 2 m (k) 1 2 1 -g 2 i (k) • e a (k) . (<label>28</label></formula><formula xml:id="formula_42">)</formula><p>Similar to <ref type="bibr" target="#b5">[6]</ref>, normalization is performed during the learning process for both networks to limit the value of the weights into an appropriate range by</p><formula xml:id="formula_43">w c (k + 1) = w c (k) + w c (k) a , a = max( a i j ) ∀a i j ∈ w c (k) + w c (k) (<label>29</label></formula><formula xml:id="formula_44">)</formula><formula xml:id="formula_45">w a (k + 1) = w a (k) + w a (k) b , b = max( b i j ) ∀b i j ∈ w a (k) + w a (k) . (<label>30</label></formula><formula xml:id="formula_46">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. INTEGRATION OF THE LM ALGORITHM INTO ADP DESIGN</head><p>While the gradient-descent-based approach as discussed in Section II has been demonstrated in many successful applications, in this section we investigate the integration of the LM algorithm into the ADP design for improved performance. We feel that such an approach might be able to provide better learning and control performance for challenging complex real-world applications with the MIMO ADP design.</p><p>Briefly, the LM algorithm is one of the most widely used optimization algorithms, which can be considered as a blend of vanilla gradient descent and Gauss-Newton iteration. It can be descried briefly as the follows.</p><p>Given a function f : R n → R m , consider the problem of finding the least square solutions z</p><formula xml:id="formula_47">* z * = arg min z F (z) = 1 2 f (z) 2 (31)</formula><p>where • denotes the Euclidean norm. When the components</p><formula xml:id="formula_48">f i (z) of f (z) = [ f 1 (z) f 2 (z) . . . f m (z)]</formula><p>T are nonlinear functions, we usually use the following iterative process: from a starting point z 0 , we continually compute a series of z 1 , z 2 ,…until z * is obtained with the assumption that the descending condition</p><formula xml:id="formula_49">F (z i+1 ) ≤ F (z i ) is satisfied.</formula><p>Our proposed approach with integrated LM algorithm for MIMO ADP can be outlined in the following pseudocodes. <ref type="foot" target="#foot_0">1</ref>Based on this high-level procedure, a detailed algorithmlevel implementation is given in Appendix . In this algorithm, <ref type="formula">41</ref>) is the Jacobian matrix and I is the identity matrix. The damping parameter μ is a strictly positive scalar. If z is close to the solution z * , we set the μ to be a small value so h≈-</p><formula xml:id="formula_50">J f c(k) (z) (step</formula><formula xml:id="formula_51">(J T f c(k) (z)J f c(k) (z)) -1 F (z)</formula><p>, which is a Gauss-Newton representation with quadratic convergence. When z is far from z * , we set the μ to be a large value so h≈-μ -1 F (z), which corresponds to the steepest descent method. Before we proceed to discuss the proposed approach in detail, we would also like to point out that, in practical applications, one will need to consider both the advantages and limitations of this approach according to their applications. For instance, although the LM approach can improve the convergence speed (see Section IV) and also provide better control performance in a complex industrial application case study as discussed in this paper (see Section V), it also introduces the complexity of selecting more appropriate parameters for learning and control. Therefore, how to integrate the domain knowledge, or using an effective and efficient way to select those parameters, will be important for different domain applications. Some interesting discussions on LM algorithm can be found in <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b34">[35]</ref>.</p><p>We now discuss the use of LM algorithm to tune the parameters in action network. There are three important components in the proposed approach: calculation of the Jacobian matrix J f c(k) (w a ) (step 34), determining whether z is getting closer to the optimal solution z * or not (step 51), and finally, updating the damping parameter μ (step 51-56). We now proceed to discuss each of these components in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Calculation of the Jacobian Matrix J f c(k) (w a ) for MIMO ADP Design.</head><p>Since we use a neural network with multiple outputs as the action network, we can express such a vector-valued nonlinear function in the form of u = f a (w a ). To facilitate the derivation process, we can define</p><formula xml:id="formula_52">J = f c (w c , u, x) = f c (w c , f a (w a , x) , x) . (<label>32</label></formula><formula xml:id="formula_53">)</formula><p>For every specific time interval k, the current state x (k) is determinate. To integrate the LM algorithm into the action network of the proposed approach, we define the F function as</p><formula xml:id="formula_54">F (k) = 1 2 e T a (k) e a (k) = 1 2 J 2 (k) = 1 2 f 2 c (w c , f a (w a , x) , x) . (<label>33</label></formula><formula xml:id="formula_55">)</formula><p>In our training process, we use a sequential training strategy similar to that in <ref type="bibr" target="#b5">[6]</ref>. This means we first tune the parameters of the critic network, and then train the action network. In this way, when we train the action network, the weights of critic network (w c ) and system state (x) can be considered as fixed values. In this way, (31) can be simplified as</p><formula xml:id="formula_56">F (w a ) = 1 2 f 2 c(k) (w a ) . (<label>34</label></formula><formula xml:id="formula_57">)</formula><p>Here, we denote J f c(k) (w a ) as the expression of cost-to-go function when we train the action network in epoch k.</p><p>Therefore, the optimal weights of action network w * a can be calculated as</p><formula xml:id="formula_58">w * a = arg min w a F (w a ) = 1 2 f c(k) (w a ) 2 . (<label>35</label></formula><formula xml:id="formula_59">)</formula><p>Now we proceed to derive the expression of the parameter modification of the action network. To do this, we will need to calculate the Jacobian matrix J f c(k) (w a ). To be clear, here we use the term δw (1)  a to represent the weight modification for the input to the hidden layer and δw (2)   a to represent the weight modification for the hidden to the output neuron in the action network. We would like to note that in the classic gradient decent approach as discussed in Section II, we calculate the derivative of E a with respect to w a [see <ref type="bibr" target="#b21">(22)</ref> and <ref type="bibr" target="#b25">(26)</ref>]. In our case, when the LM algorithm is used, we need to calculate the derivative of e a with respect to w a [see <ref type="bibr" target="#b35">(36)</ref> and <ref type="bibr" target="#b39">(40)</ref>]. Therefore, we can get δw (1)  </p><formula xml:id="formula_60">a i j (k) = ∂e a (k) ∂w (1)</formula><formula xml:id="formula_61">a i j (k) (36) = ∂e a (k) ∂ J (k) • Naout m=1 ∂ J (k) ∂u m (k) • ∂u m (k) ∂v m (k) • ∂v m (k) ∂ g i (k) • ∂ g i (k) ∂h i (k) • ∂h i (k) ∂w (1) a i j (37) = Naout m=1 ⎧ ⎨ ⎩ N ah l=1 w (2) c l (k) w (1) c l(N cin +m) (k) 1 2 1 -p 2 l (k) ⎫ ⎬ ⎭ w (2) a mi (k) x j (k) 1 2 1 -u 2 m (k) 1 2 1 -g 2 i (k) . (<label>38</label></formula><formula xml:id="formula_62">)</formula><p>In this way, we can represent the</p><formula xml:id="formula_63">J f c(k) (w (1)</formula><p>a ) part of the Jacobian matrix J f c(k) (w a ) in the following way: (1)  a ) = δw (1)  a 11 δw (1)  a 12 • • • δw (1)   a 1N ain δw (1)   a 21</p><formula xml:id="formula_64">J f c(k) (w</formula><p>δw ( <ref type="formula" target="#formula_0">1</ref>)</p><formula xml:id="formula_65">a 22 • • • w (1) a 2N ain • • • w (1) a N ah 1 • • • w (1) a N ah N ain . (<label>39</label></formula><formula xml:id="formula_66">)</formula><p>Accordingly, we can also get</p><formula xml:id="formula_67">δw (2) a mi (k) = ∂e a (k) ∂w (2) a mi (k) (40) = ∂e a (k) ∂ J (k) • ∂ J (k) ∂u m (k) • ∂u m (k) ∂v m (k) • ∂v m (k) ∂w (2) a mi (k) (41) = 1 2 1 -u (2) m (k) g i (k) • ⎧ ⎨ ⎩ N ch l=1 w (2) c l (k) • 1 2 1 -p 2 l (k) • w (1) c ll(N cin +m) (k) . (<label>42</label></formula><formula xml:id="formula_68">)</formula><p>In the same way, we can represent the J f c(k) (w (2)  a ) part of the Jacobian matrix J f c(k) (w a ) in the following way: (2)  a ) = δw (2)  a 11 δw (2)  a 12 • • • δw (2)   a 1N ain δw (2)   </p><formula xml:id="formula_69">J f c(k) (w</formula><formula xml:id="formula_70">a 21 δw (2) a 22 • • • w (2) a 2N ain • • • w (2) a N ah 1 • • • w (2) a N ah N ain . (<label>43</label></formula><formula xml:id="formula_71">)</formula><p>By combining ( <ref type="formula" target="#formula_65">39</ref>) and ( <ref type="formula" target="#formula_70">43</ref>), we can get the Jacobian matrix as</p><formula xml:id="formula_72">J f c(k) (w a ) = J f c(k) w (1) a J f c(k) w (2) a . (<label>44</label></formula><formula xml:id="formula_73">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation of the Current z</head><p>In order to evaluate whether z in the current iteration is getting closer to the solution z * or not, we adopt the term "gain factor" as proposed in <ref type="bibr" target="#b35">[36]</ref> as a criterion. Here, the gain factor ρ is defined as follows:</p><formula xml:id="formula_74">ρ = F (w a ) -F (w a + h) L (0) -L (h) (<label>45</label></formula><formula xml:id="formula_75">)</formula><p>where L(h) is defined as</p><formula xml:id="formula_76">L (h) = 1 2 l T (h) l (h) (46) = 1 2 f c(k) (w a ) + J f c(k) (w a ) h T × f c(k) (w a ) + J f c(k) (w a ) h (47) = 1 2 f T c(k) (w a ) f c(k) (w a ) + h T J T f c(k) (w a ) f c(k) (w a ) + 1 2 h T J T f c(k) (w a ) J f c(k) (w a ) h<label>(48)</label></formula><p>and</p><formula xml:id="formula_77">L (0) = 1 2 l T (0) l (0) = 1 2 f T c(k) (w a ) f c(k) (w a ) . (<label>49</label></formula><formula xml:id="formula_78">)</formula><p>Also we can use critic network in an iterative way (step 46-50) in the algorithm in the Appendix to get the value of F (w a ) -F (w a + h).</p><p>In this way, we can assess whether the current w a is approaching the optimal solution w a * or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Update the Damping Parameter μ</head><p>Here we adopt the strategy presented in <ref type="bibr" target="#b35">[36]</ref> to update the damping parameter μ in our proposed ADP design. Specifically, the key idea of this strategy is to convert the traditional updating method from a piecewise function with discontinuities to a smooth function. The relationship between gain factor ρ and updating of damping parameter μ is illustrated in Fig. <ref type="figure" target="#fig_1">3</ref>. In this way, once we have ρ according to <ref type="bibr" target="#b44">(45)</ref>, we can obtain the updated μ value based on this figure. In summary, in our proposed approach with integrated LM algorithm for MIMO ADP design, we can summarize the main steps as follows.</p><p>1) We first tune the parameters w c for the critic network. </p><formula xml:id="formula_79">μ = λ • max diag J T f c(k) (w a ) J f c(k) (w a ) . (<label>50</label></formula><formula xml:id="formula_80">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. ANALYTICAL CHARACTERISTICS OF MIMO ADP</head><p>We now proceed to discuss the analytical properties of the MIMO ADP approach. Generally speaking, the typical online actor-critic structure and learning strategy can be considered as a generalized policy iteration approach with sequential updating of the critic and actor network <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. In the stage of policy iteration, it solves the Hamiltonian in the iteration pattern with respect to the current policy, which then achieves the respective policy that minimizes the current value function in the policy improvement stage.</p><p>Concretely speaking, consider the time-invariant affine in the input dynamic system given by</p><formula xml:id="formula_81">ẋ (t) = f (x (t)) + g (x (t)) u (x (t)) , x (0) = x 0 (51) with x (t) ∈ R n , f (x (t)) ∈ R n , g (x (t)) ∈ R n×m and the input u (t) ∈ U ⊂ R m .</formula><p>We presume that f (0) = 0 and f (x)+g (x) u is Lipchitz continuous on a set ⊆ R n . Meanwhile, we also define the infinite horizon integral cost as</p><formula xml:id="formula_82">V (x 0 ) = ∞ 0 r (x (τ ) , u (τ ))dτ (52) where r (x, u) = Q (x) + u T Ru with Q (x) positive definite.</formula><p>According to the depiction of general optimal control problem, we can set the Hamiltonian of the problem as</p><formula xml:id="formula_83">H (x, u, V x ) = r (x (t) , u (t)) + V T x (f (x (t)) +g (x (t)) u (t)) (53) where V u</formula><p>x denotes the partial derivative of value function V u with respect to x. This leads to two interesting conclusions <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>: the optimal cost function V * (x) satisfies the HJB equation 0 = min u∈ ( )</p><formula xml:id="formula_84">H x, u, V * x (<label>54</label></formula><formula xml:id="formula_85">)</formula><p>and the optimal control function for the problem is</p><formula xml:id="formula_86">u * (x) = -R -1 g T (x) V * x (x) . (<label>55</label></formula><formula xml:id="formula_87">)</formula><p>Ordinarily, policy iteration consists of policy evaluation based on (54) and policy improvement based on (55). Specifically, in the case of our proposed MIMO ADP, we use policy evaluation</p><formula xml:id="formula_88">t +T 0 t r x, u (i) dτ + V u (i) x t +T 0 -V u (i) (x t ) = 0, V u (i) (0) = 0 (56)</formula><p>to replace the direct method</p><formula xml:id="formula_89">r x, u (i) (x) + V u (i) x (x) T f (x) + g (x) u (i) (x) = 0, V u (i) x (0) = 0.<label>(57)</label></formula><p>In (57), x t and x t +T 0 are short notations for x (t) and x t , respectively. The merit of this strategy is that the online learning works even when the internal dynamics of the system is unavailable. Furthermore, if we define the operator T u :X→X</p><formula xml:id="formula_90">T u V (x t ) = t +T 0 t r (x, u)dτ + V x t +T 0 (<label>58</label></formula><formula xml:id="formula_91">)</formula><p>which maps the cost function V (•) ∈ X into the cost function denoted T u V (•) ∈ X using the control policy u ∈ ψ ( ) over the time interval [t, t + T 0 ]. We can learn that the mapping has a unique fixed point on X satisfying (56), which can be obtained through the following equation by applying the Banach fixed theorem:</p><formula xml:id="formula_92">V u (i) (x t ) = lim k→∞ T k u (i) V (x t ) , ∀V (x t ) ∈ X. (<label>59</label></formula><formula xml:id="formula_93">)</formula><p>Accordingly, the optimal control policy can be obtained by (55).</p><p>Strictly speaking, here we use the MLP NN to solve the cost function V u (i) k (•), and there exists a complete independent basis set {ϕ i (x)} such that cost functional V (•) and its gradient are uniformly approximated by the Weierstrass higher order approximate theorem. In other words, the NN approximation errors of V (•) and ∂ V (•)/∂ x are bounded by constant on compact set given that the number of hidden layer neuron is fixed. Therefore, we can rewrite (56) as</p><formula xml:id="formula_94">w k a T ϕ (x t ) = t +T 0 t r x, u (i) (x) dτ + w k-1 a T ϕ x t +T 0 (60)</formula><p>to obtain the solution w * c , which minimizes the square of the TD residual error. In the same way, we can obtain w * a which constructs a least squares (LS) approximation of optimal policy. From the aforementioned analysis, we can see that the actor-critic structure and learning strategy guarantee the convergence. A more detailed analysis can be found in <ref type="bibr" target="#b36">[37]</ref> and <ref type="bibr" target="#b37">[38]</ref>.</p><p>We now proceed to discuss how the ANN and CNN in our approach can obtain a (local) minimum for the "average" (in statistics) error measured by iterative weight updating strategy based on steepest descent algorithms. Specifically, in the case of the online learning ADHDP which has similar structure to the design approach as discussed in this paper, a recursive procedure was proposed in detail in <ref type="bibr" target="#b5">[6]</ref> based on Robbins-Monro stochastic approximation</p><formula xml:id="formula_95">wa (k + 1) = wa (k) -l a e a ∂ ẽa ∂ wa (61) ∂ Ẽa ∂w a = E x ẽa ∂ ẽa ∂w a (<label>62</label></formula><formula xml:id="formula_96">)</formula><p>where</p><formula xml:id="formula_97">Ẽa = 1 2 E x (J -U c ) 2 . (<label>63</label></formula><formula xml:id="formula_98">)</formula><p>It is also stated in <ref type="bibr" target="#b5">[6]</ref> that the same is true for the CNN.</p><p>In this paper, the proposed MIMO ADP attains better performance compared to the steepest descent algorithm (typical BP algorithm) with the help of LM algorithm in weight updating in the ANN. To analyze the convergence of the proposed approach, let us consider the problem presented by <ref type="bibr" target="#b30">(31)</ref>. For a clear presentation, we can rewrite the objective as</p><formula xml:id="formula_99">F (x) = 1 2 m i=1 ( f i (x)) 2 = 1 2 f (x) 2 = 1 2 f T (x) f (x) .</formula><p>(64) Furthermore, we can obtain the formula by Taylor expansion with any search step h from x as</p><formula xml:id="formula_100">F (x + h) = F (x) + f T (x) J (x) h + 1 2 h T J T (x) J (x) h + 1 2 h T m i=1 f i (x) f i (x)h + O h 3 . (65)</formula><p>Generally, we consider the first two items of (65) as an approximation of the new objective value in the case of steepest descent algorithms</p><formula xml:id="formula_101">F (x + h) ≈ F (x) + f T (x) J (x) h<label>(66)</label></formula><p>and the corresponding searching algorithm is</p><formula xml:id="formula_102">h = -f T (x) J (x) . (<label>67</label></formula><formula xml:id="formula_103">)</formula><p>In the case of the Gauss-Newton method, the first three items are considered as an estimation</p><formula xml:id="formula_104">F (x + h) ≈ 1 2 f T (x) f (x) + h T F (x) + 1 2 h T J T (x) J (x) h<label>(</label></formula><p>68) and respective searching algorithms is</p><formula xml:id="formula_105">J T f (x) J f (x) h = -J T f (x) f (x) . (<label>69</label></formula><formula xml:id="formula_106">)</formula><p>As for the LM method, it takes the formula</p><formula xml:id="formula_107">J T f (x) J f (x) + μI h = -J T f (x) f (x) (<label>70</label></formula><formula xml:id="formula_108">)</formula><p>where μ is a positive parameter and I is the identity matrix. Apparently, the LM algorithm considers more information in the approximation process than the steepest descent algorithms in each iteration. Meanwhile, it can ensure that h is always a descent direction of F (x), which Gauss-Newton algorithms cannot guarantee. This is because J T f (x) J f (x) + μI in (70) is always positive with controllable damping μ, while <ref type="formula" target="#formula_105">69</ref>) is positive definite on condition that the columns of J f (x) are linearly independent.</p><formula xml:id="formula_109">J T f (x) J f (x) in (</formula><p>In this way, since J T f (x) J f (x) + μI is always positive definite, we can have the following:</p><formula xml:id="formula_110">∇ F T (x) h = -J T f (x) f (x) T J T f (x) J f (x) + μI -1 J T f (x) f (x) &lt; 0. (<label>71</label></formula><formula xml:id="formula_111">)</formula><p>Therefore, the LM approach with Armijo's step size rule attains global convergence to a stationary point of F (x) when ∇ F (x) = 0. We would also like to note that, in the case of singularity of F (x), <ref type="bibr" target="#b38">[39]</ref> showed that the LM method has a quadratic rate of convergence under the assumption that F (x) provides a local error bound for F (x) = 0 . In <ref type="bibr" target="#b39">[40]</ref>, the authors extended the result to establish a quadratic convergence result for the LM method without the nonsingularity assumption by <ref type="bibr" target="#b38">[39]</ref>. In summary, in this section we provided an analysis in terms of both the actor-critic structure and the learning algorithm to demonstrate the convergence of the proposed approach. We now proceed to present a case study of the application of this approach into a real industrial complex problem.</p><formula xml:id="formula_112">using μ = F (x) δ (δ ∈ [1, 2]) instead of μ = F (x) 2 in</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CASE STUDY WITH LINEAR LOOPER TENSION/HEIGHT SYSTEM MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Application Scenario</head><p>In this section, we test the performance of our proposed GMIMO ADP design based on a real industrial looper system currently deployed at the Wuhan Iron and Steel (Group) Corporation. Briefly, a looper is an uplifted device commonly found in modern hot strip mills <ref type="bibr" target="#b40">[41]</ref>. Fig. <ref type="figure" target="#fig_2">4</ref> shows a diagram of the looper system. From Fig. <ref type="figure" target="#fig_2">4</ref>, one can see that the looper is located approximately midway between adjacent stands of the multistand hot strip rolling mill. It is pivoted on a short arm so that it can be raised above the pass line to form a "loop" in the strip between the stands. One purpose of the looper is to direct the strip into a loop for emergency storage when the mass flow of material within two adjacent stands is temporarily out of equilibrium. Furthermore, proper tension should be provided in the material to guarantee the accurate dimension of the strip since different tension presets lead to different finishing widths of the hot strip.</p><p>As a typical apparatus used in the hot tandem rolling mill, the looper tension and angle control are important in hot strip mills because they affect both the dimensional quality and the mass flow of a strip. The high strip tension between stands induces width shrinkage and thickness reduction, and can even produce an edge wave on a strip. On the other hand, the tension can also contribute to the mass flow stability. As far as the looper angle is concerned, it enables stable operation of the process by absorbing an excessive loop of the strip arising from a mass flow imbalance that is produced by the steel strip speed difference between the incoming and outgoing masses. Furthermore, the looper can also reduce tension variations by changing its angle. Therefore, the strip tension and angle should be kept to a desired value simultaneously, which is called the "nominal operation point" to ensure proper product quality and strip rolling. Ordinarily, a constant looper height and tension state can be maintained by adjusting the roller motor speed ratio and the looper motor current <ref type="bibr" target="#b24">[25]</ref>. Since the looper height and tension state are closely coupled, it is very difficult to achieve the optimal control performance (target variables are height /angle of the looper and stress of the strip) simultaneously by means of these two manipulated variables. Generally speaking, this is an unstable system, and therefore adaptive control is of critical importance for the operation of such a system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Looper System Physical Model</head><p>We now proceed to derive the looper tension and height model based on their physical principles. There are two principles to be considered here. First, the tension is caused by the difference between the strip exit velocity v i = v 0 i (1 + f ) in the stand i and the strip entry velocity v i+1 = v 0 i+1 (1 -β) in the stand i + 1. f and β 0 indicate the strip forward slip and backward slip, respectively. v 0 i and v 0 i+1 are the line speeds of the roller in stand i and i + 1, respectively. Second, looper height is related to the looper storage length by the mass conservation principle.</p><p>We present a schematic diagram of the looper system in Fig. <ref type="figure" target="#fig_2">4</ref> for intuitive perception and a series of equations for comprehending it theoretically.</p><p>The symbols in Fig. <ref type="figure" target="#fig_2">4</ref>  </p><formula xml:id="formula_113">M T : tension moment M T (w, h, τ, θ) ; M W : weight moment M W (w, h, l, θ, ρ ir ) .</formula><p>In general, the model of the looper system in hot strip mill can be presented by the following equations <ref type="bibr" target="#b41">[42]</ref>. The looper dynamic equation can be presented by</p><formula xml:id="formula_114">M = C m i lp = M T + M W + J ω (72)</formula><p>J : moment of inertia of the looper; M: total moment; C m : torque coefficient of dc motor; i lp : the actual current of the looper's motor.</p><p>The strip tension is generated from the elongation of the hot strip, which can be simplified to a completely elastic deformation. The associated tension between two stands is</p><formula xml:id="formula_115">τ = E lp L + t t 0 (v i -v i+1 ) dτ • L 1 (θ ) + L 2 (θ ) -L + t t 0 (v i -v i+1 ) dτ (73)</formula><p>E lp : Young modulus; v i : delivery strip velocity in the stand i ; v i+1 : entry strip velocity in the downstream stand i + 1. real amount of the reduction. During the rolling process, the neutral plane (denoted by neutral angle γ ) is where the strip velocity is the same as the surface line velocity of the work roll v 0 i . At the entry side, the strip velocity is less than v 0 i . However, at the exit side, the strip speed becomes higher than v 0 i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average deformation speed can be expressed by</head><formula xml:id="formula_116">u m = v 0 i l c log H h (<label>74</label></formula><p>The definition of forward-slip ratio f can be expressed as</p><formula xml:id="formula_117">v i = v 0 i (1 + f ) (<label>76</label></formula><formula xml:id="formula_118">)</formula><p>v i : exit speed of the strip in the stand; v 0 i : speed of the work roll in the stand.</p><p>The neutral angle can be calculated in the following way:</p><formula xml:id="formula_119">γ = h R tan 1 2 arctan ε 1 -ε + π 8 ln (1 -ε) h R + 1 2 h R τ f K - τ b K (77) γ : neutral angle; h:</formula><p>exit thickness of the strip; R: radius of the roller; ε:</p><p>relative reduction; τ f : forward tension of strip in the stand (equals τ in this case); τ b : backward tension of strip in the stand. Forward-slip ratio f can be calculated by</p><formula xml:id="formula_120">f = (1 -cos γ ) (2R cos γ -h) h . (<label>78</label></formula><formula xml:id="formula_121">)</formula><p>Each actuator is modeled as a first-order lag with a time constant. The equivalent inertia element for the current loop of the looper system can be represented by</p><formula xml:id="formula_122">i lp = 1 1 + T i s i lpr (<label>79</label></formula><formula xml:id="formula_123">)</formula><p>i lp : the actual current of the looper's motor; i lpr : the reference current of the looper's motor; T i : time constant of the inertia element in looper's current loop; s:</p><p>Laplace operator. The equivalent inertia element for the speed loop of roll in the stand can be represented by</p><formula xml:id="formula_124">v 0 i = 1 1 + T v s v 0 ir (<label>80</label></formula><formula xml:id="formula_125">)</formula><p>v 0 i : the actual speed of the roll in the stand; v 0 ir : the reference speed the roll in the stand; T v : time constant of the inertia element in roll's speed loop; s:</p><p>Laplace operator. In this way, we present the complete physical model of which will be used to derive the control model of the system. </p><formula xml:id="formula_126">JS 1 i ref_i v ref_i v 0_i T ref_i - + - - - - i act_i ω motor i θ motor_i θ i E lp LS df i dτ f_i v 0i C m 1 G R Looper motor 1 G R 1 G Rfi ∂M load • ∂τ f_i τ f_i + dL 1 dθ dL 2 dθ 1 ∂M load R G • ∂θ 360 2π 1 S 1 1+T i S 1+f i 1 1+T v S -v 0_i+1 dβ i dβ f_i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Looper System Control Model</head><p>Fig. <ref type="figure" target="#fig_3">5</ref> shows the looper tension and height dynamic block diagram for a real engineering system currently deployed at Wuhan Iron and Steel (Group) Corporation. We note that state variables in the model are the deviation from the nominal operating point in the incremental form. The nominal operating point is defined as follows: τ = 6.86 Mpa, θ = 22°, ω = 0 rad/s, i lp = 26.6781 A, and v 0 i = 6.2707 m/s. We now summarize all the associated parameters for this real system.</p><p>Strip type: Q235(A3F); Entry strip height: 3.95mm; Exit strip height: 3.01mm; Temperature of the strip: 920.8. The symbols in Fig. <ref type="figure" target="#fig_3">5</ref>  horizontal distance between two successive stand; v 0_i : actual line speed of the roller in the stand i ; v 0_i+1 : actual line speed of the roller in the stand i + 1; M load : complex moment including tension moment and weight moment. We select state variables as</p><formula xml:id="formula_127">x = τ i , θ i , ω motor_i , i act i , v o_i T (81)</formula><p>the manipulated variables as</p><formula xml:id="formula_128">u = i ref _i , v o re f _i T (82)</formula><p>and the output variables as</p><formula xml:id="formula_129">y = [ θ i , τ i , ] T . (<label>83</label></formula><formula xml:id="formula_130">)</formula><p>Thus a state space model is obtained as follows <ref type="bibr" target="#b42">[43]</ref>:</p><formula xml:id="formula_131">ẋ = A p x + B p x y = C p x (<label>84</label></formula><formula xml:id="formula_132">)</formula><p>where</p><formula xml:id="formula_133">A p = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ - E lp L v 0 i d f i dτ i + v 0 i+1 dβ i+1 dτ i 0 0 0 - 1 G R ∂ M load ∂τ i 1 J 360 2π - ∂ M load ∂θ i 1 J G R 360 2π 0 0 0 0 E lp L d L 1 dθ i + d L 2 dθ i 1 G R 0 - E lp L (1 + f i ) 1 G R 0 0 - K D J 360 2π C m J 360 2π 0 0 - 1 T l 0 0 0 - 1 T v ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦<label>(85)</label></formula><formula xml:id="formula_134">B p = 0 0 0 1 T l 0 0 0 0 0 1 T v T (86) C p = 0 1 0 0 0 1 0 0 0 0 . (<label>87</label></formula><formula xml:id="formula_135">)</formula><p>As shown in Fig. <ref type="figure" target="#fig_3">5</ref>, the complete system includes two subsystems which are closely coupled. The angle control system is in the upper part, and the tension control system is in the lower part. The connections between the two subsystem arise from the inner physical principles, which are described in terms of (72) and (73). In the upper subsystem, the current of the looper motor i lp employ the moment M to overcome the load moment [sum of the tension moment M T (w, h, τ, θ) and weight moment M W (w, h, l, θ, ρ ir )] to change the speed of the looper. Therefore, the variation of tension τ (the second output) can influence the looper angle θ (the first output), and vice versa. Furthermore, the fluctuation of the looper angle θ will in turn have an impact on L 1 (θ ) and L 2 (θ ), which will further affect the tension τ .</p><p>The proposed GMIMO ADP design has been implemented based on the model. Originally, the self-learning controller has no prior knowledge about the looper tension/height control system. Only online measurement is available. The objective is to keep the deviation of the two outputs, i.e., tension and angle, within the given range during the run time by controlling the looper current and roller speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experiment 1: Nominal Model with External Noise</head><p>In our experiments, a run consists of a maximum of 1000 consecutive trials. It is considered successful for a run provided that a trial has lasted 6000 time steps and the index of that trial is equal to or less than 1000. Otherwise, the run is considered unsuccessful. The time for each time step is 0.02 s, and a trial is a complete process from start to finish which is regarded when either the tension is outside the range [-1.029 1.029] Mpa or the angle is outside the range of <ref type="bibr">[-3.3 3.3]</ref> °. We conduct 100 runs in this paper. For each run, we generate them randomly within the range of ±5% of the nominal working point. For fair comparison, in each experiment, the initial state of the dynamic system is identical in each specific run between the different comparative methods.</p><p>Several experiments were conducted to evaluate the effectiveness of our proposed leaning and control design. The CNN is chosen as a 7-10-1 MLP structure and the ANN is chosen as a 5-6-2 MLP structure. Here we compare two approaches: the classic approach by using backpropagation in both the critic network and the action network (denoted as BP + BP), and our proposed approach by integrated LM method to the action network (denoted as BP + LM). The parameters used in simulations are summarized in Table <ref type="table" target="#tab_5">I</ref> with the notations defined in the following: l c (0): initial learning rate of the critic network; l a (0): initial learning rate of the action network; l c (k): learning rate of the critic network which is decreased by 0.05 every 5 time step until it reach l c ( f ) and stay thereafter; l a (k): learning rate of the action network which is decreased by 0.05 every 5 time step until it reach l a ( f ) and stay thereafter; N c : internal cycle of the critic network; N a : internal cycle of the action network;  coefficient to calculate initial μ in LM method.</p><p>Besides, we have added both sensor and actuator noise to the state measurements and action network outputs. In our current study, we consider both uniform and Gaussian noise on actuators and sensors in the following way: θ = (1 + noise percentage) × θ .</p><p>Table <ref type="table" target="#tab_5">II</ref> shows the performance evaluations for classic BP + BP approach and our proposed approach (BP + LM). We also present a histogram in Figs. <ref type="figure">6</ref> and<ref type="figure" target="#fig_5">7</ref> to illustrate the success rate and the average number of trials it takes to learn to balance the looper. The results demonstrate that the proposed methods can achieve better performance.</p><p>Fig. <ref type="figure">8</ref> shows a typical trajectory of the looper's tension and angle under GMIMO ADP control for a successful learning trial, subject to a uniform 5% noise on actuators. Fig. <ref type="figure">9</ref> illustrates another successful learning case when the looper system is subject to disturbance within both actuators and sensors in terms of Gaussian noise σ 2 = 0.1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experiment 2: Generalized Model with Internal Perturbation and External Noise</head><p>In the previous experiments, we assumed the looper tension and height model are nominal. Though we have already  reduction ratio. The latter plays an important role in the looper dynamics. Perturbations in temperature and reduction ratio, in principle, can cause the change of the neutral angle, which can further influence the value of the forward slip. According to a rough estimation, an increment of the entry strip height by as much as 50 μm will result in 5% delta of forward slip in current situation. Therefore, we imitate the practical looper object via the nominal model with the perturbation in the elements of the matrix A p (85). In his way, the generalized plant model with the matrix Ã p can be presented as follows: </p><formula xml:id="formula_136">Ã p = A p + A p = ⎡ ⎢ ⎢ ⎢ ⎣ a 11 (1 + δ)</formula><formula xml:id="formula_137">⎤ ⎥ ⎥ ⎥ ⎦ . (<label>88</label></formula><formula xml:id="formula_138">)</formula><p>Since the deviation in the strip thickness is mostly below 100 μm or so, a Gaussian distribution with a mean zero and variance 0.001 is chosen to simulate the perturbation.  Table <ref type="table" target="#tab_5">III</ref> shows the results for classic BP + BP approach and our proposed approach (BP + LM). From the results, we can see the proposed approach demonstrates better performance when the system is subject to not only the external noise in sensors and actuators but also internal parameter perturbations. We also show a histogram in Fig. <ref type="figure">10</ref> to demonstrate the success rate comparison between the BP + BP method and the BP + LM method. Comparison of the average number of trials it took to learn to balance the looper under different conditions is illustrated in Fig. <ref type="figure" target="#fig_7">11</ref>.</p><p>A typical trajectory of the looper tension and angle under GMIMO ADP control for a successful learning trial in this situation is given in Fig. <ref type="figure" target="#fig_0">12</ref>. The system is subject to a uniform 5% disturbance with actuator, sensor, and internal forward slip. Fig. <ref type="figure" target="#fig_1">13</ref> shows another typical experimental result for a successful trial, in which the system is subject to external noise in actuators and sensors (Gaussian distribution with σ 2 = 0.2), as well as internal perturbation in a generalized plant model (Gaussian distribution with σ 2 = 0.001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we proposed a GMIMO ADP design for online learning and control. An improved weight-updating algorithm based on recursive LM method was presented and embedded into ADP design to improve its performance. We also discussed the analytical convergence characteristics of the proposed approach under an online actor-critic framework. To demonstrate the effectiveness of our approach, we evaluated the performance of the proposed approach based on a real industrial application of the tension and height control of a looper system in a hot strip mill. Various simulation results under different types of noise conditions demonstrated the effectiveness of this approach.</p><p>There are a few interesting future research directions along this topic. First, in this paper, we considered only the integration of LM algorithm into the action network design. It will be a natural extension to integrate the LM algorithm into the critic network design as well. It would be interesting to observe and analyze how the system will perform when both the action network and the critic network use the LM algorithm to tune their parameters. Second, our current approach in this paper is based on the AD HDP category of ADP methods, and it would be useful to investigate the integration of this approach with other types of ADP design, such as DHP and GDHP design, to explore its capabilities to handle large-scale complex optimization problems. In fact, it is well known that the ADP methods not only depend on the weight-tuning algorithms but also on the structure selection and learning of the critic and actor networks <ref type="bibr" target="#b43">[44]</ref>, therefore, the integration of the proposed algorithm into different actor-critic design architecture under different structure regularization and learning scenarios will be an important future topic, such as policy iteration and value iteration under reinforcement learning <ref type="bibr" target="#b44">[45]</ref>, tree-type neural network for ACD <ref type="bibr" target="#b45">[46]</ref>, single-network adaptive critic architecture <ref type="bibr" target="#b46">[47]</ref>, neuro-fuzzy controller with self-tuning ACD <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>, and others. Third, our approach in this paper is built on the online actor-critic framework without model network. It is well known that model networks play an important role in many of the complex adaptive control and optimization problems, ranging from power system control <ref type="bibr" target="#b49">[50]</ref> to optimal tracking problems <ref type="bibr" target="#b50">[51]</ref>. In fact, the importance of model networks has advanced from the first-generation of ADP design to predict the changes of the environment and estimate the objective state of reality, to much more powerful brainlike prediction capability to facilitate the ADP design through recurrent networks <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. The integration of model network into our approach will be another interesting future research direction to accomplish the integrated prediction and optimization capability in the ADP design. Finally, another important future direction from practical application point of view is to demonstrate the applications of our approach across different complex control benchmarks to fully justify its learning and optimization capabilities. Our group is currently investigating all these issues. Motivated by our results in this paper, we hope that the proposed approach will not only advance the ADP research for MIMO systems but can also provide potential new techniques and tools for critical engineering applications across different domains.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Schematic diagram for implementation of online learning and control based on ADP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Relationship between gain factor ρ and damping parameter μ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Schematic diagram of the looper system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. System model of looper tension and height.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>u s s i a n σ 2 Fig. 6 .</head><label>26</label><figDesc>Fig.6. Success rate of BP + BP method versus BP + LM method in nominal looper model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Average number of trials to balance the looper by BP + BP method versus BP + LM method in nominal looper model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .Fig. 9 .Fig. 10 .</head><label>8910</label><figDesc>Fig.8. Trajectory of looper tension and angle in a successful learning trial when the system is subject to a noise on actuators (nominal model).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Average number of trials to balance the looper by BP + BP method versus BP + LM method in generalized looper model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 12 .Fig. 13 .</head><label>1213</label><figDesc>Fig.<ref type="bibr" target="#b11">12</ref>. Typical trajectory of looper tension and angle in a successful learning trial when the system is subject to uniform disturbance with actuators, sensors, and internal forward slip (generalized model).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>APPENDIX LM ALGORITHM FOR ADP WITH MIMOAlgorithm 2 LM algorithm for ADP with MIMO /* u = AN N (w a , x) is a neural network for control output calculation; x: state vector; w a : weight of ANN; u: control output of ANN; f a (w a , x): an alternative function express of AN N (w a , x);J = C N N (w c , x,u) is a neural network for calculate cost-to-go approximately; w c : weight of CNN; J : total cost-to-go; f c (w c , x, u): an alternative function expression of C N N (w a , x, u); MaxT r: maximum number of trials; MaxStepNum: maximum elapsed step times for each trial */; 1: initiate x (0); 2: initiate w c (0) and w a (0) randomly; 3:u (0) ← AN N (w a (0) , x (0)); 4: J (0) ← C N N (w c (0) , x (0) , u (0)); 5: J prev = J (0); 6: for tri al = 1 to Max T r do; 7: NewState = x (0); // w c and w a memorize the experience in previous online learning trials; 8: u ← AN N (w a , NewState); 9: J ← C N N (w c , NewState, u); 10: J prev = J ; 11: k = 1; 12: while k ≤ Max StepNum do 13:x (k) ← (x (k -1) , u (k -1)) via external environment; 14:w a (k) = w a (k -1); 15: u (k) ← AN N (w a (k) , x (k)); 16: w c (k) = w c (k -1); 17: J (k) ← C N N (w c (k) , x (k) , u (k)); 18: if x (k) ∈ threshold then; 19: r (k -1) = 0; //reinforcement signal 20: else 21: r (k -1) = -1; f ailure = -1; // f ailure is symbol to indicate the failure of current trial 22: end if 23: E c (k) = 0.5 × (α • J (k) -J prevr (k -1)) 2 ; // J prev = J (k -1) in the previous codes 24: cyc = 0; 25:while(E c (k) &gt; T c ) &amp; (cyc ≤ N crit ) do // T cis the preset threshold for CNN training // N crit is preset training times 26: w c (k) ← E c (k); // update w c using backpropagation 27: cyc = cyc + 1; 28:J (k) ← C N N (w c (k) , x (k) , u (k));// calculate new cost-to-go based on new w c (k) 29:E c (k) = 0.5 × (α • J (k) -J prevr (k -1)) 2 ; 30:end while 31:E a (k) = 0.5 × (J (k)) 2 ; /* we can depict it in an alternative expression E a (k) = 0.5 f 2 c (w c (k) , f a (w a (x) , x (k)) , x (k)) = 0.5 f 2 c(k) (w a (k)) simplify the equation by regarding the f c (w c , u, x) as varied function series f c(k) (w a ) with respect to the time interval k.*</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>can be described as follows.</figDesc><table><row><cell>α:</cell><cell>angle between strip of the upstream stand i and</cell></row><row><cell></cell><cell>pass line;</cell></row><row><cell>β:</cell><cell>angle between strip of the downstream stand</cell></row><row><cell></cell><cell>i + 1 and pass line;</cell></row><row><cell cols="2">R lp : length of the looper's arm;</cell></row><row><cell>d:</cell><cell>diameter of the looper roller;</cell></row><row><cell>τ :</cell><cell>tensile stress of the strip;</cell></row><row><cell>W :</cell><cell>weight of the strip applied to the looper;</cell></row><row><cell>L 1 :</cell><cell>distance between top of the looper with upstream</cell></row><row><cell></cell><cell>stand i ;</cell></row><row><cell>L 2 :</cell><cell>distance between top of the looper with</cell></row><row><cell></cell><cell>downstream stand i + 1;</cell></row><row><cell>l:</cell><cell>original strip length between adjacent stands;</cell></row><row><cell>w:</cell><cell>strip width;</cell></row><row><cell>h:</cell><cell>strip thickness;</cell></row><row><cell>ρ ir :</cell><cell>strip density;</cell></row></table><note><p>L: horizontal distance between two successive stand; C: horizontal distance between stand i and its associated looper's axis; D: vertical distance between looper's axis and pass line; B: vertical distance from the top of the looper to the pass line; θ : angle between looper's arm and pass line;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE I SUMMARY</head><label>I</label><figDesc>OF THE PARAMETERS USED IN OBTAINING THE RESULTS GIVEN INTABLE II</figDesc><table><row><cell>Parameter</cell><cell cols="4">l c (0) l a (0) l c ( f ) l a ( f )</cell><cell>*</cell></row><row><cell>Value</cell><cell>0.28</cell><cell>0.28</cell><cell>0.005</cell><cell>0.005</cell><cell>*</cell></row><row><cell>Parameter</cell><cell>N c</cell><cell>N a</cell><cell>T c</cell><cell>T a</cell><cell>λ</cell></row><row><cell>Value</cell><cell>100</cell><cell>200</cell><cell>0.04</cell><cell>0.004</cell><cell>20000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>* a: actuators are subject to the noise. † s: sensors are subject to the noise. a.s: both actuators and sensors are subject to the noise.</figDesc><table><row><cell></cell><cell></cell><cell>TABLE II</cell><cell></cell><cell></cell></row><row><cell cols="5">PERFORMANCE EVALUATION OF BP(CNN) + BP(ANN) METHOD VERSUS</cell></row><row><cell cols="5">BP(CNN) + LM(ANN) METHOD (EXPERIMENT 1: NOMINAL MODEL WITH</cell></row><row><cell></cell><cell></cell><cell>EXTERNAL NOISE)</cell><cell></cell><cell></cell></row><row><cell>Noise type</cell><cell cols="2">BP(CNN) + BP(ANN) Success rate No of trial</cell><cell cols="2">BP(CNN) + LM(ANN) Success rate No of trial</cell></row><row><cell>Noise-free</cell><cell>96%</cell><cell>224.9</cell><cell>99%</cell><cell>176.9</cell></row><row><cell>Uniform 5% a.  *</cell><cell>96%</cell><cell>236.3</cell><cell>98%</cell><cell>186.8</cell></row><row><cell>Uniform 10% a.</cell><cell>94%</cell><cell>190</cell><cell>100%</cell><cell>177.1</cell></row><row><cell>Uniform 5% s.  †</cell><cell>92%</cell><cell>208.2</cell><cell>98%</cell><cell>205.3</cell></row><row><cell>Uniform 10% s.</cell><cell>93%</cell><cell>196.4</cell><cell>99%</cell><cell>223.7</cell></row><row><cell>Gaussian σ 2 (0.1) s.</cell><cell>88%</cell><cell>273.8</cell><cell>99%</cell><cell>233.5</cell></row><row><cell>Gaussian σ 2 (0.2) s.</cell><cell>79%</cell><cell>301.3</cell><cell>97%</cell><cell>291.2</cell></row><row><cell>Uniform 5% a.s.</cell><cell>95%</cell><cell>208.9</cell><cell>98%</cell><cell>209.8</cell></row><row><cell>Uniform 10% a.s.</cell><cell>94%</cell><cell>280.6</cell><cell>97%</cell><cell>196.7</cell></row><row><cell>Gaussian σ 2 (0.1) a.s.</cell><cell>84%</cell><cell>324.8</cell><cell>97%</cell><cell>259.2</cell></row><row><cell>Gaussian σ 2 (0.2) a.s.</cell><cell>74%</cell><cell>372.6</cell><cell>89%</cell><cell>361.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>a 12 a 13 a 14 a 15(1 + δ)   </figDesc><table><row><cell>a 21 . . .</cell><cell>a 22 a 23 a 24 . . . . . . . . .</cell><cell>a 25 . . .</cell></row><row><cell>a 51</cell><cell>a 52 a 53 a 54</cell><cell>a 55</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Conditions then /*Conditions include small gradient, small h norm, over maximum iteration times, singular matrix appears etc.*/</figDesc><table><row><cell>/ 32: 33: 34:</cell><cell cols="3">calculate δw a ; (1) calculate δw (2) a ; J f c(k) (w a ) = δw</cell><cell>(1) a δw</cell><cell>(2) a ;</cell></row><row><cell cols="5">// calculate the Jacobian matrix of which is presented later in</cell></row><row><cell cols="2">this paper</cell><cell></cell><cell></cell></row><row><cell>35:</cell><cell>z 0 = w</cell><cell>(1) a ; w</cell><cell cols="2">(2) a ;</cell></row><row><cell cols="5">// reshape the weight matrix to a vector</cell></row><row><cell>36:</cell><cell>z = z 0 ;</cell><cell></cell><cell></cell></row><row><cell>37:</cell><cell cols="2">μ = μ 0 ;</cell><cell></cell></row><row><cell>38:</cell><cell>β = 2;</cell><cell></cell><cell></cell></row><row><cell>39:</cell><cell cols="2">stop = 0;</cell><cell></cell></row><row><cell>40:</cell><cell cols="3">while ¬stop do</cell></row><row><cell>41:</cell><cell cols="3">solve J T f c(k)</cell></row><row><cell>43:</cell><cell cols="4">assign variable stop a number other than zero;</cell></row><row><cell>44:</cell><cell cols="2">end if</cell><cell></cell></row><row><cell>45:</cell><cell cols="3">if ¬stop then</cell></row><row><cell>46:</cell><cell cols="3">z = z + h;</cell></row><row><cell cols="5">47: w 50: E a (k) = 0.5 × (J (k)) 2 ;</cell></row><row><cell>51:</cell><cell cols="4">if ρ (z, h) &gt; 0 then</cell></row><row><cell>52:</cell><cell cols="4">z = z + h;</cell></row><row><cell>53:</cell><cell cols="4">μ = μ • max 1 3 , 1 -(2ρ -1) 3 ; β = 2;</cell></row><row><cell>54:</cell><cell cols="2">else</cell><cell></cell></row><row><cell>55:</cell><cell cols="4">μ = μ • β; β = 2β;</cell></row><row><cell>56:</cell><cell cols="4">end if // corresponding to step 51</cell></row><row><cell>57:</cell><cell cols="4">end if // corresponding to step 45</cell></row><row><cell>58:</cell><cell cols="4">end while // corresponding to step 40</cell></row><row><cell>59:</cell><cell cols="4">if ¬ f ailure then</cell></row><row><cell>60:</cell><cell cols="4">J prev = J (k);</cell></row><row><cell>61:</cell><cell>else</cell><cell></cell><cell></cell></row><row><cell>62:</cell><cell cols="4">break; // escape the current trial for next trial</cell></row><row><cell>63:</cell><cell>end if</cell><cell></cell><cell></cell></row><row><cell cols="5">64: end while //corresponding to step 8</cell></row><row><cell cols="5">65: end for //corresponding to step 1</cell></row></table><note><p><p><p><p><p>(z) J f c(k) (z) + μI h = -F (z); 42:</p>if Current Situation ∈ a (k) ← z; //reshape the vector to matrix 48:</p>u (k) ← AN N (w a (k) , x (k)); 49: J (k) ← C N N (w c (k) , x</p>(</p>k) , u (k));</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The source code of MATLAB implementation can be obtained from authors.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>He was a Visiting Scholar with Gdansk University of Technology, Gdansk, Poland, in 1999. He is currently an Associate Professor at the School of Automation, WHUT. His current research interests include networked control systems and motion control.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Foreword -ADP: The key direction for future research in intelligent control and understanding brain intelligence</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B: Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="898" to="900" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intelligence in the brain: A theory of how it works and how to build it</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="200" to="212" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neuro-dynamic programming: An overview</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 34th IEEE Conf. Decis. Control</title>
		<meeting>34th IEEE Conf. Decis. Control<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-12">Dec. 1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="560" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive critic designs</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="997" to="1007" />
			<date type="published" when="1997-09">Sep. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming: An introduction</title>
		<author>
			<persName><forename type="first">F.-Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="39" to="47" />
			<date type="published" when="2009-05">May 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Online learning control by association and reinforcement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-T</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="276" />
			<date type="published" when="2001-03">Mar. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lendaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saeks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part C: Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="140" to="153" />
			<date type="published" when="2002-05">May 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming for finite-horizon optimal control of discrete-time nonlinear systems with ε-error bound</title>
		<author>
			<persName><forename type="first">F.-Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural-network-based near-optimal control for a class of discrete-time affine nonlinear systems with control constraints</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1490" to="1503" />
			<date type="published" when="2009-09">Sep. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Approximate robust policy iteration using multilayer perceptron neural networks for discounted infinite-horizon Markov decision processes with uncertain correlated transition matrices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1270" to="1280" />
			<date type="published" when="2010-08">Aug. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Approximate Dynamic Programming: Solving the Curses of Dimensionality</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Wiley-Blackwell</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<title level="m">Dynamic Programming and Optimal Control</title>
		<meeting><address><addrLine>Nashua, NH</addrLine></address></meeting>
		<imprint>
			<publisher>Athena Scientific</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Approximate dynamic programming strategies and their applicability for process control: A review and future directions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Control Autom. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="278" />
			<date type="published" when="2004-09">Sep. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Apache helicopter stabilization using neural dynamic programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Guid. Control Dyn</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="25" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Helicopter trimming and tracking control using direct neural dynamic programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="929" to="939" />
			<date type="published" when="2003-07">Jul. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptivecritic-based optimal neurocontrol for synchronous generators in a power system using MLP/RBF neural networks</title>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Venayagamoorthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1529" to="1540" />
			<date type="published" when="2003-10">Sep.-Oct. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Second-order training of adaptive critics for online process control</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Govindhasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Mcloone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B: Cybern</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="381" to="385" />
			<date type="published" when="2005-04">Apr. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adaptive critic learning techniques for engine torque and air-fuel ratio control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Javaherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kovalenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B: Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="988" to="993" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An online actor-critic learning approach with Levenberg-Marquardt algorithm</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw</title>
		<meeting>Int. Joint Conf. Neural Netw<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adaptive dynamic programming with balanced weights seeking strategy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. Series Comput. Intell. -IEEE Symp</title>
		<meeting>IEEE Symp. Series Comput. Intell. -IEEE Symp<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An adaptive dynamic programming approach for closely-coupled MIMO system control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp</title>
		<meeting>Int. Symp<address><addrLine>Guiling, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05">May 2011</date>
			<biblScope unit="volume">6677</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Looper and tension control in hot rolling mills: A survey</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rossiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Process Control</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="509" to="521" />
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Looper H-infinity control for hot-strip mills</title>
		<author>
			<persName><forename type="first">H</forename><surname>Imanari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Morimatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sekiguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ezure</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Matuoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tokuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Otobe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Appl</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="790" to="796" />
			<date type="published" when="1997-06">May-Jun. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive and robust control method with estimation of rolling characteristics for looper angle control at hot strip mill</title>
		<author>
			<persName><forename type="first">H</forename><surname>Asada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Konishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iron Steel Inst. Jpn. Int</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="358" to="365" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A neuro-fuzzy system for looper tension control in rolling mills</title>
		<author>
			<persName><forename type="first">F</forename><surname>Janabi-Sharifi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Eng. Practice</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Advanced forecasting methods for global crisis warning and models of intelligence</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">General Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="25" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Where do rewards come from?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Cognit</title>
		<meeting>Annu. Conf. Cognit<address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-08">Aug. 2009</date>
			<biblScope unit="page" from="2601" to="2606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Intrinsically motivated reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annu. Conf. Neural Inf</title>
		<meeting>Annu. Conf. Neural Inf<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-12">Dec. 2004</date>
			<biblScope unit="page" from="1281" to="1288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Intrinsically motivated learning of hierarchical collections of skills</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Develop. Learn</title>
		<meeting>Int. Conf. Develop. Learn<address><addrLine>La Jolla, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-10">Oct. 2004</date>
			<biblScope unit="page" from="112" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Intrinsically motivated reinforcement learning: A promising framework for developmental robot learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Konidaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Spring Symp. Develop. Robot</title>
		<meeting>AAAI Spring Symp. Develop. Robot</meeting>
		<imprint>
			<date type="published" when="2005-03">Mar. 2005</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Backpropagation through time: What it does and how to do it</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2002-08">Aug. 2002</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Methods for non-linear least squares problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tingleff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Informatics and Mathematical Modelling</title>
		<meeting><address><addrLine>Kongens Lyngby, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>DTU</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Numerical Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Iterative Methods for Optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kelley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Damping-undamping strategies for the Levenberg-Marquardt nonlinear least-squares method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lampton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Phys. J</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="110" to="115" />
			<date type="published" when="1997-01">Jan. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Damping Parameter in Marquardt&apos;s Method</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Nielsen</surname></persName>
		</author>
		<ptr target="http://www2.imm.dtu.dk/documents/ftp/tr99/tr05_99.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Online actor-critic algorithm to solve the continuous-time infinite horizon optimal control problem</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="878" to="888" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adaptive optimal controllers based on generalized policy iteration in a continuous-time framework</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vrabie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vamvoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Medit. Conf. Control Autom., vols. 1-3</title>
		<meeting>17th Medit. Conf. Control Autom., vols. 1-3<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="1402" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the rate of convergence of the Levenberg-Marquardt method</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Suppl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="239" to="249" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">On the quadratic convergence of the Levenberg-Marquardt method without nonsingularity assumption</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="39" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Precise looper simulation for hot strip mills using an auto-tuning approach</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-Y</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Manuf. Technol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="481" to="487" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">High-Quality Steel Rolling: Theory and Practice</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Ginzburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Lmis based h-infinity decoupling method and the looper height and tension control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kongzhi Juece/Control Decis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="883" to="891" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Handbook of Learning and Approximate Dynamic Programming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Wunsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Wiley</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Introduction to Reinforcement Learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">SVM-based tree-type neural networks as a critic in adaptive critic designs for control</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jayadeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1016" to="1030" />
			<date type="published" when="2007-07">Jul. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A single network adaptive critic (SNAC) architecture for optimal control synthesis for a class of nonlinear systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Padhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Unnikrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1648" to="1660" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fully evolvable optimal neurofuzzy controller using adaptive critic designs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohagheghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Venayagamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Harley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1450" to="1461" />
			<date type="published" when="2008-12">Dec. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adaptive critic design based neuro-fuzzy controller for a static compensator in a multimachine power system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohagheghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Venayagamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Harley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Power Syst</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1744" to="1754" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">DHP-based wide-area coordinating control of a power system with a large wind farm and multiple FACTS devices</title>
		<author>
			<persName><forename type="first">W</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venayagamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Neural Netw</title>
		<meeting>IEEE Int. Conf. Neural Netw<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-08">Aug. 2007</date>
			<biblScope unit="page" from="2093" to="2098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A novel infinite-time optimal tracking control scheme for a class of discrete-time nonlinear systems via the greedy HDP iteration algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tran. Syst., Man, Cybern., Part B: Cybern</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="937" to="942" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
