<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Faces Engage Us: Photos with Faces Attract More Likes and Comments on Instagram</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Saeideh</forename><surname>Bakhshi</surname></persName>
							<email>sbakhshi@cc.gatech.edu</email>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Gilbert</surname></persName>
							<email>gilbert@cc.gatech.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<country>Georgia Tech</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Yahoo Labs</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<country>Georgia Tech</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<addrLine>April 26May 1</addrLine>
									<postCode>2014, 2014</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Faces Engage Us: Photos with Faces Attract More Likes and Comments on Instagram</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">647071971CEC4B679D085B6BCF1BBF55</idno>
					<idno type="DOI">10.1145/2556288.2557403</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>mobile</term>
					<term>photo</term>
					<term>Instagram</term>
					<term>faces</term>
					<term>face detection</term>
					<term>engagement</term>
					<term>age</term>
					<term>demographics</term>
					<term>gender</term>
					<term>content</term>
					<term>image</term>
					<term>social media</term>
					<term>image sharing community H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing production and distribution. One common type of photo content that is shared on social media, is the photos of people. From studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how presence of a face, it's age and gender might impact social engagement on the photo. We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. This work presents the first results on how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Even as babies, humans love to look at faces; infants, barely minutes old, turn toward faces, sensing that they are important <ref type="bibr" target="#b37">[39]</ref>. It is widely accepted in neuroscience that face perception is perhaps the most highly developed human visual skill <ref type="bibr" target="#b24">[26]</ref>. Faces are also powerful channels of nonverbal communication <ref type="bibr" target="#b43">[45]</ref>. We constantly monitor faces because they provide vital clues in an impressive variety of contexts: attraction, the complexity of emotions, identity, age, humor, and a person's regional and national background <ref type="bibr" target="#b22">[24]</ref>.</p><p>Many of the faces we see everyday now have an online presence. Photo sharing communities such as Instagram have made it possible to communicate with large groups of distributed people through an image-be it a picture of whats for dinner or a selfie-perhaps more easily than through words alone. As Kelsey puts it, "we are moving away from photography as a way of recording and storing the past, and instead turning photography into a social medium in its own right" <ref type="bibr" target="#b33">[35]</ref>.</p><p>Online photo sharing communities have grown at an impressive pace. At the time of this writing, Instagram users upload 55 million photos a day to the site<ref type="foot" target="#foot_0">1</ref> . This presents a key research challenge for photo sharing communities like Instagram (cf. Flickr, Imgur, Tumblr): how do we discover the mechanisms by which users communicate around visual content and engage with such content. In other words, since engagement is vital to photo sharing communities, it is critical to understand what form of content drives engagement. While several research studies have focused on how users engage with textual content <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b36">38]</ref>, there are few studies on what makes visual content socially engaging online. To investigate this, we ask the following research questions in this paper, driven by social psychology work on face perception: RQ1: Do photos with faces differ in online engagement compared to photos without them?</p><p>RQ2: If so, how do characteristics of the image subject, such as gender and age, affect engagement?</p><p>We use Instagram to answer our research questions. Instagram has over 150 million active monthly users who collectively generate 1.2 billion likes per day. There are two social aspects of engagement here: the number of likes and the number of comments on the Instagram image <ref type="foot" target="#foot_1">2</ref> . Using a corpus of 1 million images from the community, we find that on an average a photo that contains a face receives 38% more likes and 32% more comments compared to a photo that does not contain any faces (even after controlling for user activity levels and social network reach). Further, we find that the number of faces in the photo, their age and their gender do not impact engagement.</p><p>To our knowledge, our study is one of the first to show, systematically and at scale, how photos with faces drive online social engagement. In addition to contributing to the ongoing research conversation surrounding engagement, we believe that these findings create a path for future work, not only to uncover the impact of faces on other aspects of online user behavior, but also to use computer vision techniques to discover other antecedents of engagement. For example, we may be able to apply vision techniques to relate facial expressions of emotion to social behavior.</p><p>We begin with a review of related research on content and face perception, and a summary of the Instagram community. Next, we introduce the corpus we collected from Instagram and describe the statistical methods we used to isolate the effect of faces on likes and comments. Finally, we interpret our findings within the frame of existing work, both in theory and in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LITERATURE REVIEW</head><p>In this section, we describe related work on role of content in engagement, face perception theories and HCI studies of faces. We then summarize the media community of our study, Instagram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Role of Content on User Engagement</head><p>As Ellison and colleagues note, "the primary function of these [social network] sites is to consume and distribute personal content about the self" <ref type="bibr" target="#b20">[22]</ref>. Sharing content can in turn ensure that users remain engaged and committed in the future visits <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b45">47]</ref>. On the other hand, users have diverse motivations to share content on social network sites. For example, users may share useful content to appear knowledgeable or simply to help out <ref type="bibr" target="#b48">[50]</ref>. Not only the content of posts, but also the emotional valence behind it can drive its usage. For example, in a recent study, researchers used New York Times articles to examine the relationship between the emotion evoked by content and its virality <ref type="bibr" target="#b7">[9]</ref>, finding that that there is a direct relationship.</p><p>Much research attention has gone into investigating what makes content in an online community interesting to its members. In a series of studies conducted on Usenet newsgroups, researchers investigated properties that influenced the likelihood of reply, a measure of the community's engagement. Explicit requests, personal testimonials relating one's connection to the group, and staying on-topic increased the probability of receiving a reply. Newcomers to a group were less likely to receive a reply than veterans <ref type="bibr" target="#b4">[6]</ref>. Following up on this work, Burke et al. studied the role of self-disclosing introductions, mentions of the poster's age, and an acknowledgment that this is the poster's first post; these factors were found to increase reply probability <ref type="bibr" target="#b9">[11]</ref>.</p><p>In another study, Burke and Kraut, studied the effect of the politeness of a post, finding that politeness leads to more replies in certain types of groups, while in other types of groups, rudeness actually increases replies <ref type="bibr" target="#b10">[12]</ref>. On Twitter, researchers have used retweeting as a measure of community interest/engagement, and have investigated the features that predict retweeting. Suh et al. found that the presence of URLs and hashtags in tweets predicted more retweeting, as did a richer connection with the community <ref type="bibr" target="#b42">[44]</ref>. In a recent work, Gilbert et. al. studied Pinterest-a social networking site based on images-and found that which properties of an image makes the content more interesting to users <ref type="bibr" target="#b21">[23]</ref>. The properties used in this work are based on meta data and not the content of images.</p><p>As far as we know, however, we have no such similar line of work on how image content can affect different aspects of online behavior, such as engagement, diffusion or link formation. In our work, we intend to provide an understanding of image engagement by looking at the photo content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Face perception</head><p>One of the common types of photo content shared on social networking sites is the photos of people or the ones with human faces in them. Through daily experience, we know that human faces are readily distinguishable. People tend to find faces in unexpected scenes and photographs even where faces do not exist. For example, the 1976 Viking 1 prob photographed a shadowed region on Mars' northern planes that resembled a face. While higher resolution imagery has shown the region to actually be a mesa, the face on Mars remains a pop icon and the source of many books, TV shows, and films <ref type="bibr" target="#b38">[40]</ref>.</p><p>Faces have long been a source of scientific interest in a wide range of disciplines. In recent years, this breadth of interests, approaches and expertise has led directly to rapid advances in our understanding of many different aspects of how we perceive and process faces <ref type="bibr" target="#b8">[10]</ref>. The human brain has evolved to recognize faces within hours after birth <ref type="bibr" target="#b31">[33]</ref>. Human infants only minutes old attend particularly to face-like stimuli relative to equally complicated non-face stimuli <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b28">30]</ref>. We prefer to look at faces from that early age and thereafter, often opting to spend more time looking at faces than any other type of object <ref type="bibr" target="#b51">[53]</ref>. By the age of two months, infants begin to differentiate specific visual features of the face <ref type="bibr" target="#b37">[39]</ref> and process facial expressions <ref type="bibr" target="#b18">[20]</ref>. Our brains have a specific region, Fusiform Face Area (FFA), that is specialized for facial recognition <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b39">41]</ref>. Faces are important for social cognition as well, not only because we are able to recognize them earlier than other objects, but also because they display our feelings about past, current and future events through expressions <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b19">21]</ref>. This can be highly important to very practical concerns: faces, particularly attractive ones, are found to be effective in improving consumer responses to advertisements <ref type="bibr" target="#b5">[7]</ref>.</p><p>Our research examines the presence of this phenomena online, by analyzing the effect of having faces in engaging users on Instagram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Faces and HCI research</head><p>In HCI research, there is a great deal of work exploring the benefits of using face icons and faces in interfaces <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b43">45,</ref><ref type="bibr" target="#b47">49]</ref>. Walker et al. <ref type="bibr" target="#b47">[49]</ref> studied how having faces and facial expressions for a computer application affects users' performance and productivity. They compared subjects' responses to an interview survey under three conditions: questions spoken by a synthesized face with neutral expressions, spoken by a face with stern expressions, or text only. Subjects who responded to the spoken face made more effort to answer the questions by spending more time, writing more comments and making fewer mistakes. They reported that having a face is engaging and takes more effort and attention from the user.</p><p>Takeuchi et al. <ref type="bibr" target="#b44">[46]</ref> compared users' impressions of an agent which helped them to win a card game. The agent was represented either as an arrow or a face. They showed that users respond differently to systems having a face than to those without. The arrow was recognized as useful and reliable, while the face was rated as fun and entertaining. They conclude that a face in an interface captures more attention and people try to interpret the meaning behind the expression.</p><p>Studies on embodied interfaces showed similar results. Agents are visual digital representations of a computer interface often in the form of human-like faces <ref type="bibr" target="#b13">[15]</ref>. In a review study of embodied agents <ref type="bibr" target="#b16">[18]</ref>, authors reported that adding an embodied agent to an interface made the experience more engaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Role of Age and Gender</head><p>Age and gender have been studied extensively as factors affecting social media use <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b26">28]</ref>. Recent data 3 shows that women form a majority of Facebook and Twitter users, as well as dominating Pinterest; however, men are the majority of users on Google+ and LinkedIn. In a recent study Gilbert et. al. <ref type="bibr" target="#b21">[23]</ref> found that females are more likely to receive repins and fewer followers than males on Pinterest. Moreover, Pew Internet Research <ref type="bibr" target="#b2">[4]</ref> ran a survey to give marketers a clearer picture of who they can expect to reach on Instagram.</p><p>According to the source, 28% of U.S. internet users aged 18 to 29 snapped and posted photos on the network in December 2012. 14% of those aged 30 to 49 did the same, and very few users older than 50 participated in any way on Instagram.</p><p>Inspired by previous research on disparities in internet usage and social network audience, we used age and gender variables to investigate whether they affect the number of likes and comments on photos. Instagram is a social network site designed around photoand video-sharing. It enables users to take photos and videos with their mobile devices, apply digital filters to them and share them on variety of social networking services, such as Facebook, Twitter, Tumblr and Flickr <ref type="bibr" target="#b0">[2]</ref>, all of which are social media sites in their own right. Instagram has rapidly gained popularity with over 100 million active users as of April 2012 <ref type="bibr" target="#b17">[19]</ref>. The total number of photographs uploaded recently exceeded one billion <ref type="bibr">[1,</ref><ref type="bibr" target="#b1">3]</ref>.</p><p>Instagram accounts are public by default, unless users elect to create a private account; there is no tier privacy photo by photo. To add a photo, users can take a photo from inside the app. It is also possible to choose a photo from an existing album on the mobile device to share with Instagram followers.</p><p>Instagram users can apply filters on their photos. An Instagram filter is a digital layer that when added to a photo, gives it the appearance of stylistic editing. Some filters enhance the colors in a photo, while others dull the light to a soft glow for an aged, vintage appearance.</p><p>Despite the popularity of Instagram, there is little scholarly work on it. In a recent piece, Hochman et al. <ref type="bibr" target="#b27">[29]</ref> analyzed colors in photos uploaded from two different cities of New York and Tokyo and found differences across the two locations. For instance, hues of pictures in New York were mostly blue-gray, while those in Tokyo were characterized by dominant red-yellow tones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS</head><p>We take a quantitative approach in this paper to investigate the relationship between faces and engagement. While engagement can be quantified in various ways, we use two essential aspects of content on Instagram that can signal for engagement: likes and comments. The number of likes signals for the extent to which the content is interesting to users and the number of comments quantifies the level of discussion on the social network. In this section, we describe the data we collected from Instagram and how we detected faces and their age and gender; followed by clarifying our statistical methods and analysis process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Face detection</head><p>Face detection and recognition from images or video is a popular topic in vision research and it has received lots of attention <ref type="bibr" target="#b46">[48,</ref><ref type="bibr" target="#b49">51]</ref>. A general statement of the problem of machine recognition of faces is usually formulated as follows: given still or video images of a scene, identify or verify one or more persons in the scene using a stored database of faces or facial features. The solution to the problem involves segmentation of faces (face detection) from cluttered scenes and extraction of features from the face.</p><p>While the current state of the art in face detection and recognition is highly accurate <ref type="bibr" target="#b30">[32]</ref>, we did not have access to an implementation that can work for large scale image analysis. We therefore used a publicly available face detection API developed by Face++ <ref type="bibr" target="#b3">[5]</ref>. We only use the detection modules, as the goal of this paper is to find relationship between existence of faces and the social engagement. Face++ provides a set of compact, powerful, and cross-platform vision services, which enabled us to use cutting-edge vision techniques. The API does not provide us with an estimation of accuracy, so we turn to a crowd-sourced validation method to confirm the accuracy of our face detector described later in the validation section.</p><p>Face++ provides us with an API that accepts the URL of an Instagram image and returns information about detected faces. This information includes the position of the face in the image, as well as the detected gender and age range of all faces. We then reduce the dimensionality of data by converting the results into a binary space, where we mark only when there is a face in an image. We also identify whether any of the faces in the image belong to certain age ranges. The three age ranges we consider in this paper are (1) children and teensyounger than 18, (2) young adults-faces with age between 18 and 35, and (3) older adults-older than 35. To evaluate the role of gender, we construct another binary feature which determines whether at least one female or one male face is in the image. Figure <ref type="figure" target="#fig_1">1</ref> shows an example Face++ detection and how we construct our variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>Our goal is to obtain a random sample of photos from Instagram. Even though Instagram provides us with a publicly available API, gathering a random subset of photos is a challenging task. We can either search for photos by location or query on the list of most recent popular photos. We opted to start with a set of 2,000 popular Instagram photos, collected on November 2012. We then used snowball sampling <ref type="bibr" target="#b23">[25]</ref> to collect the users and their followers as well as a random set of their photos. Our dataset consists of 23 million Instagram photos and over 3 million Instagram users. To soften biases due to snowball sampling, we randomly selected 1.1 million photos from this data set. The snowball sampling method was necessary because Instagram does not provide any mechanism by which to monitor the global stream of photos. Figure <ref type="figure" target="#fig_3">2</ref> shows a detailed flowchart of data collection, evaluation and analysis processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response variables (dependent measures)</head><p>Our goal in this paper is to investigate the role of photos in predicting user engagement on Instagram. We chose number of likes and number of comments as two features that represent fundamental aspects of engagement on the site. An overview of each of these variables is provided in Table <ref type="table">1</ref>.</p><p>Likes: Number of likes is a measure of engagement for the photo. It quantifies the number of distinct users who liked the photo. Like is a strong social signal on Instagram that demonstrates the extent to which users liked the photo.</p><p>Comments: Number of comments is another measure of engagement, or as Yew and Shamma <ref type="bibr" target="#b50">[52]</ref> note, a measure of explicit action on the content. The number of comments is the number of distinct comments posted on the photo. The number of comments determines the extent to which users discussed the photo and hence it can be considered as measure of discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predictor variables</head><p>In this paper, we use two major control variables to adjust for the impact of social network reach and a user's activity.</p><p>Control: user's followers count. An Instagram photo is posted by an Instagram user. The nature of relationship on Instagram is follower/following. Users form a social network based on "follow" relationships. When A follows B, B's photos will show up in A's photo-stream. The number of followers signals the social network reach. The more number of followers, the more people can see the photo and there is presumably a higher chance of receiving likes and comments.</p><p>Control: user's photo count. Photo count is the feature we use to quantify a user's activity on the site. It represents the number of photos on a user's profile. The larger values of photo count show the user has shared more content on the site; in other words the user is more active.</p><p>As we discussed in related work section, faces are found to be effective stimuli <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b28">30]</ref> in attracting people's attention. We use a binary variable as our predictor to account for presence of a face in the photo.  Has face. For each Instagram photo, we determine whether at least one human face exists in the photo. This is a binary feature; when it is set to 1, there is at least one face in the image, otherwise it is set to 0.</p><p>Other than presence of faces, we consider variables identifying age and gender of them. Our age and gender variables are derived using face detection method.</p><p>Has children and teens-has face &lt; 18 years old. We use a binary feature to determine whether the photo has any faces in the age group &lt;18 years old. The variable is set to 1 when at least one of the identified faces in the image appears to be younger than 18 years old, and set to 0 otherwise.</p><p>Has young adults-has face &gt; 18 and &lt; 35 years old. This is another age feature that is set to 1 when at least one of the identifies faces in the image appears to be between 18 and 35 years old, and it is set to 0 otherwise.</p><p>Has older adults-Has face &gt; 35 years old. Our final age feature is to identify presence of older adults in the image.</p><p>If at least one of the faces in the image appears to be older than 35 years old, this variable is set to 1, 0 otherwise.</p><p>Has female face. This feature is a binary feature reflecting whether there is a female face in the photo. When the variable is set to 1, the image has at least one female face, and it is set to 0 otherwise.</p><p>Has male face. This feature is a binary feature reflecting whether there is a male face in the photo. When the variable is set to 1, the image has at least one male face, and it is set to 0 otherwise.</p><p>The distribution and short summary of each of these features is provided in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical methods</head><p>Next, we present statistical methods we used to model our two dependent variables, number of likes and number of comments. Both dependent variables are count variables. We model the number of likes and the number of comments using negative binomial regression, on two classes of independent variables: the control variables (followers count and photos count) and our variables of interest (related to existence of a face, age group of the face and gender of the face). Negative binomial regression is well-suited for over-dispersed distributions of count dependent variable <ref type="bibr" target="#b12">[14]</ref>. We use negative binomial regression instead of Poisson regression since the variance of the dependent variable is larger than the mean for both likes and comments. We use over-dispersion to test whether Poisson or negative binomial regression should be used. This test was suggested by Cameron and Trivedi <ref type="bibr" target="#b12">[14]</ref>, and involves a simple least-squares regression to test the statistical significance of the over-dispersion coefficient.</p><p>The regression coefficients β allow us to understand the effect of an independent variable on the number of likes and comments (note that to be able to compare coefficients, we zscore all numerical variables before performing regression).</p><p>For the variables with heavy tail distribution, such as followers count and photos count, we log transformed the variables before performing regression. We use Chi-squared statistics to find the statistical significance of our regression models, computing the reduction in deviance as compared to a null model. has male face 1 if there is at least one male face in the photo, 0 otherwise.</p><formula xml:id="formula_0">0e+00 3e+05 6e+05 9e+05</formula><p>Table <ref type="table">1</ref>. Distributions of quantitative and binary variables used in this paper. Variables marked with '*' are log-transformed. The red and blue lines identify mean and median of the distribution, respectively. Orange refers to 1's in the bar graphs. The engagement variables are our dependent measures.</p><p>Audience and activity variables are used as controls, and faces variables are the focal point of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FACE DETECTION VALIDATION</head><p>As we mentioned in the previous section, we use Face++ API to detect faces in Instagram photos. Even though the currently used face detection mechanisms are high in accuracy (over 95%), we undertake an additional evaluation step to validate and confirm the accuracy of our methods. For this purpose, we crowd-source a random sample of photos from our dataset to Mechanical Turkers in order to verify the results of API.</p><p>The validation process is as follows: we select a random sample of 2,000 images from our dataset. We then create tasks on Mechanical Turk, where the image is shown to five different Turkers. We ask questions regarding the faces they see in the image. They answer the questions about each image by identifying how many human faces they see in the image, how many of them are female and how many are male. We then ask Turkers to categorize the faces into different age groups and report the number of people in each age group. We specifically ask Turkers to only report the human faces and avoid reporting the people they see in the picture if the faces are not visible.</p><p>We take the majority votes on each image and the results of Mechanical Turkers evaluations are in agreement with API output 97% ± 0.75% of the time. 93% ± 1.11% of the Turker evaluations are in agreement in detecting faces with age range under 18, 96% ± 0.86% in age range agreement between 18 and 35, and 99% ± 0.44% in detecting ages over 35. Overall the evaluation of our face detecting API shows high accuracy.</p><p>The results of the human validation are summarized in Table <ref type="table" target="#tab_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>We use negative binomial regression to model the number of likes and comments on photos. The results of the regression are presented in Table <ref type="table" target="#tab_4">3</ref>. We use the Chi-squared Test to find the significance of the regression model, by computing the reduction in deviance from a null model. For our likes model, we find reduction in deviance of χ 2 = (5.2M -1.2M ), or 76%, on 8 degrees of freedom. The test rejected the null hypothesis of a null model (p &lt; 10 -15 ); hence, the model is well-suited to characterize the effects of the described variables.</p><p>For our comments model, the reduction in deviance is χ 2 = (1.79M -1.1M ), or 38%, on 8 degrees of freedom. The test rejected the null hypothesis of a null model (p &lt; 10 -15 ). The model for comments is also well-suited to characterize the effects of the independent variables.</p><p>We test coefficients of all independent variables for the null hypothesis of a zero-valued coefficient (two-sided) and find that the test rejects the null hypothesis (p &lt; 10 -5 ) in all cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of control variables</head><p>We use number of followers and number of photos as our control variables. As expected, the followers count has a large positive effect on the number of likes and comments. This  means the higher the number of followers, the more likely it is for the photo to receive likes and comments. The higher number of followers guarantees a larger audience and so the photo is expected to be seen by more number of people, increasing the likelihood of receiving likes and comments.</p><p>On the other hand the number of photos shared by user shows a negative effect on both likes and comments. The number of photos is an indicator of activity on Instagram. As we can see in our results (Table <ref type="table" target="#tab_4">3</ref>) the higher activity (number of photos), the lower chances of receiving likes and comments. This might also be interpreted another way: the more photos a user has, the lower probability any single one has of being liked or commented on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of faces</head><p>All other predictors in our model come from the face detection results. We are interested in quantifying the effect of faces and their comparative importance on social engagement. We use a binary variable that reflects the existence of a face in the image. We can see in Table <ref type="table" target="#tab_4">3</ref> that number of likes and comments are significantly higher when there is at least one face in the image (β likes = 0.32, β comments = 0.28, p &lt; 10 -15 ). This means that photos with faces are 38% more likely (IRR = 0.38) to receive likes and 32% more likely (IRR = 0.32) to receive comments<ref type="foot" target="#foot_2">4</ref> ).</p><p>We also check the effect of number of faces on engagement and find that while existence of a face positively correlates with the number of likes and comments, the number of faces does not particularly change this effect. Regardless of whether it is a group photo or a single person's photo, the fact that a face is in the image significantly impacts the number of likes and comments. It does not matter how many faces are in the image. We did not include the number of faces in the final model to avoid co-linearity of the predictor variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of age and gender</head><p>To test whether the demographic of users <ref type="bibr" target="#b2">[4]</ref> biases toward photos with younger face groups, we considered using three binary variables each identifying the age of a face. Table <ref type="table" target="#tab_4">3</ref> shows that the age group of the faces are generally not strong predictors for the number of likes. In case of number of comments the photos with adult age groups negatively affects the number of comments. This could be related to lower presence of older age groups in the social network of Instagram.</p><p>Gender of the faces in the image does not show any strong effect on the image's engagement. Table <ref type="table" target="#tab_4">3</ref> shows that the β coefficients for gender variables are of negligible size compared to some other features such as existence of a face.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>Using Instagram as our research context, we set out to investigate how photos with faces relate to engagement, as measured as the number of likes and comments, compared to those without. We considered presence of a face in a photo, it's gender and age as predictors, controlling for social network reach and activity. From this we asked two research questions: are photos with faces more engaging than those without and if so how do the characteristics of a face in a photo affect engagement?</p><p>As expected, we find that among the factors we measured, the number of followers is the main driver of engagement for both likes and comments on the photo. The number of followers is a proxy for the size of a user's audience. Having a larger audience increases the likelihood of a like or comment, a common sense fact realized in our models. Furthermore, we find that activity level is negatively correlated with likes and comments. The more photos a user posts, the less likely it is that her photos receive likes and comments. As we mentioned earlier, this most likely represents the intuition that the more photos a user posts, the less likely any one of them is to be highly liked or commented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Faces engage us</head><p>The major finding of this paper is that the existence of a face in a photo significantly affects its social engagement. This effect is substantial, increasing the chances of receiving likes by 38% and comments by 32%. We also find that number of faces in the image does not have significant impact on engagement. Having a photo with a face, regardless of how many faces are in the photo, increases the likelihood of receiving likes and comments. Our findings connect to the findings from offline studies in psychology, marketing and social behavior, as well as qualitative studies of HCI, confirming that people engage more with photos of faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Age and gender do not impact engagement</head><p>Our results show that the age and gender of faces in the photo does not seem to drive or hinder it's engagement values. This is a surprising finding, given the bias of demographics using the site and the general belief that photos of kids or female faces may get more attention. For comments, we see in the results that there is a small negative effect of older adult photos. Since the comments are mostly related to the extent to which a photo is discussed, the lower number of comments on this type of photos can be related to the lower demographics of older adults on Instagram. Future work can look at effect of similar factors on other photo sharing communities such as Pinterest with biased gender demographics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications and future work</head><p>This work raises many fundamental questions about the nature of social interaction around multimedia content. We believe that this is an initial step and there is a rich landscape of research directions and open questions in this area. Future work can look at other visual characteristics of multimedia and study their impact on online behavior. Here we find that faces might have an impact on engagement, but faces are just one visual feature. Other signals can be gathered from people in photos, including facial expression, gaze direction, as well as, body posture and movement. Although facial expressions reliably signal the so-called basic emotions such as fear or happiness, human viewers are also surprisingly adept at making reliable judgments about social information from impoverished stimuli, such as faint changes in facial expressions <ref type="bibr" target="#b28">[30]</ref>. Emotional expressions in faces are known to activate several areas of the brain <ref type="bibr" target="#b22">[24]</ref>. Future work can look at emotional expressions of faces and explore the effects on user behavior. For example, are we more likely to comment on wry smiles or broad grins?</p><p>Our quantitative results illuminate what is the response to the photos with faces, but not why users behave this way or what kind of connections they make with such photos. Additional work, particularly using qualitative methods, is needed to answer these questions. Some of the most compelling questions concern the person in the photo; for example, are users engaging with faces as generic objects or are they connecting with the face as a person they know.</p><p>As our work is based on quantitative studies and observational data, we cannot make any strong causal claims. We find that photos with faces have higher chances of being liked and commented on, but we don't know if faces are the exact cause of this. More experimental work needs to corroborate these findings. Further, the statistical methods we used examine only a small segment of behavior on the site.</p><p>Faces and their presence connect to psychological studies of human behavior, and emphasize the importance of engaging our unconscious perceptual biases-instantiated in this work as face perception. Future work can investigate the relationship between face perception theories and other aspects of online user behavior. For example are faces effective when it comes to spreading the content on the social network? Are photos or topics, accompanied by human faces more/less persuasive in terms of delivering the content?</p><p>The context in which faces appear also invites interesting questions about individual and group behavior. Are photos of friends group more/less popular than the family ones? What about selfies and people's reaction to self portraits? It is worth studying the cultural impacts on photo sharing, say for example are group photos more engaging in collectivism cultures rather than individualistic ones?</p><p>Camera-phones and mobile photo capture has changed how we perceive photo-work in the academic community. This work takes one of the first steps into understanding modern photo capture and consumption through the study of Instagram. That said, Instagram is one online ecosystem and it has been claimed that perception and semantics in social media sites is a construction of the community on that site <ref type="bibr" target="#b40">[42]</ref>. For example, Instagram is a people-centric site and the influence of faces might be different in a product-centric site such as Pinterest. On the other hand a community such as Instagram, which is strongly based on social connections might react differently to faces than a professional photography community such as Flickr.</p><p>The practical implication of social engagement in online photo sharing lies strongly in search and recommendation. Knowing photos with faces increase engagement suggests one could increase their search ranking to keep people on site and active. Our results highlight the importance of effective methods that take advantage of presence of faces in photos for personalization of site content. Additionally, while we have seen face finding applications for social media sites <ref type="bibr" target="#b35">[37]</ref>, these tools have been designed for the utility of retrieval and not for conversation and comments.</p><p>For designers, the present findings may shed light on how to filter, prioritize and highlight photos from the global image stream, especially ones that have just been submitted and therefore haven't had time to accumulate very many likes and comments. platforms, a key challenge in research community is to understand the role of the image content in online user behavior. In this paper, we took a first step toward uncovering an important feature of some of images, the human faces. We find that photos with faces are 38% more likely to be liked and 32% more likely to be commented on. Our results, however, show that number of faces, their age and gender do not have significant impact. In addition to speaking to the ongoing studies in online user behavior and social engagement, our findings open a new thread of future work, suggesting research in visual analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Instagram 3</head><label>3</label><figDesc>http://mashable.com/2012/07/04/ men-women-social-media/ (Accessed 9/2013)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Example Face++ face detection and how we construct our variables. The photo used in this example is a photo under Creative Commons license from Flickr.</figDesc><graphic coords="4,54.48,81.00,152.12,151.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>✐✡✝✓✎✌ ✔✠♦ ✡✎✕✖✠✟ ✎✗✝☛✘✝✕✐✠✞✙ ❋✠♦ ✎✝✚✖ ✐✡✝✓✎✑ ✱ ❚✘✉✎♦✌ ✛✘✟✓✎✟ ✝☛✓✠♦✐✕✖✡Õ✌ ✔✝✚✎ ✜ ✝✓✎ ♦✎✌✘☛✕✌✙ ❋✝✚✎✑ ✝✓✎✑ ✓✎✞✟✎♦ ♦✎✌✘☛✕✌ ✗✝☛✐✟✝✕✎✟✙ ❛✆❛✁✢s✄s ❋✠♦ ✝☛☛ ✣▼ ✐✡✝✓✎✌✑ ✚♦✎✝✕✎✟ ✤✐✞✝♦☞ ✔✎✝✕✘♦✎✌ ✔✠♦ ✔✝✚✎✑ ✝✓✎✑ ✓✎✞✟✎♦✙ ◆✎✓✝✕✐✗✎ ✤✐✞✠✡✐✝☛ ✡✠✟✎☛ ✝✌✌✎✌✌✎✟ ✎✦✎✚✕ ✠✞ ✎✞✓✝✓✎✡✎✞✕✙ ❞❛t❛ ✥☎✁✁❡✥t✄☎✆ ❯✌✐✞✓ ✧✞✌✕✝✓♦✝✡ ★✩✧✑ ✚✠☛☛✎✚✕✎✟ ✏✑✒✒✒ ✍✠✍✘☛✝♦ ✐✡✝✓✎✌✙ ❱✐✝ ✌✞✠✇✤✝☛☛ ✌✝✡✍☛✐✞✓✑ ✚✠☛☛✎✚✕✎✟ ✏✪▼ ✡✠♦✎ ✐✡✝✓✎✌✙ |✝✞✟✠✡☛☞ ✌✝✡✍☛✎✟ ✕✠ ✣▼✙ ❊✝✚✖ ✐✡✝✓✎ ✝✘✓✡✎✞✕✎✟ ✇✐✕✖ ✍♦✠✫☛✎ ✟✝✕✝ ✜ ✝✞✝☛☞✬✎✟ ✔✠♦ ✔✝✚✎✌✙</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An overview of the steps taken in this paper for collection, evaluation and analysis of the data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Faces</head><label></label><figDesc>are shown to be powerful visual tool used in human non verbal communication. With the widespread use of image sharing communities, most of which are on top of social Session: Personal Values and Preferences CHI 2014, One of a CHInd, Toronto, ON, Canada</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Results of Mechanical Turk evaluation for our face detection approach. Margin of Error is computed for 95% confidence. Our face detector works correctly 97% ± 0.75% of the time.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Session: Personal Values and Preferences CHI 2014, One of a CHInd, Toronto, ON, Canada</head><label></label><figDesc></figDesc><table><row><cell>Variable</cell><cell cols="3">β Std.Err p</cell><cell>Variable</cell><cell cols="3">β Std.Err p</cell></row><row><cell>number of followers</cell><cell>1.32</cell><cell>0.00</cell><cell>&lt; 10 -15</cell><cell>number of followers</cell><cell>0.97</cell><cell>0.00</cell><cell>&lt; 10 -15</cell></row><row><cell>number of photos</cell><cell>-0.21</cell><cell>0.00</cell><cell>&lt; 10 -15</cell><cell>number of photos</cell><cell>-0.12</cell><cell>0.00</cell><cell>&lt; 10 -15</cell></row><row><cell>has face</cell><cell>0.32</cell><cell>0.01</cell><cell>&lt; 10 -15</cell><cell>has face</cell><cell>0.28</cell><cell>0.00</cell><cell>&lt; 10 -15</cell></row><row><cell>has face &lt;18 years old</cell><cell>0.02</cell><cell>0.01</cell><cell>&lt; 10 -15</cell><cell>has face &lt;18 years old</cell><cell>-0.01</cell><cell>0.01</cell><cell>&lt; 10 -15</cell></row><row><cell>has face &gt;18 and &lt;25</cell><cell>-0.03</cell><cell>0.01</cell><cell>&lt; 10 -15</cell><cell>has face &gt;18 and &lt;25</cell><cell>-0.07</cell><cell>0.01</cell><cell>&lt; 10 -15</cell></row><row><cell>has face &gt;25 years old</cell><cell>-0.03</cell><cell>0.01</cell><cell>&lt; 10 -15</cell><cell>has face &gt;25 years old</cell><cell>-0.04</cell><cell>0.01</cell><cell>&lt; 10 -15</cell></row><row><cell>has female face</cell><cell>-0.04</cell><cell>0.01</cell><cell>&lt; 10 -8</cell><cell>has female face</cell><cell>-0.01</cell><cell>0.01</cell><cell>&lt; 10 -4</cell></row><row><cell>has male face</cell><cell>-0.02</cell><cell>0.01</cell><cell>&lt; 10 -3</cell><cell>has male face</cell><cell>-0.02</cell><cell>0.01</cell><cell>&lt; 10 -6</cell></row><row><cell>(Intercept)</cell><cell>3.47</cell><cell>0.00</cell><cell>&lt; 10 -15</cell><cell>(Intercept)</cell><cell>3.47</cell><cell>0.00</cell><cell>&lt; 10 -15</cell></row><row><cell>Null deviance</cell><cell></cell><cell></cell><cell>5208940</cell><cell>Null deviance</cell><cell></cell><cell></cell><cell>1790136</cell></row><row><cell>Residual deviance</cell><cell></cell><cell></cell><cell>1227787</cell><cell>Residual deviance</cell><cell></cell><cell></cell><cell>1105145</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Results of negative binomial regression with number of likes (left) and number of comments (right) as dependent variable.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://instagram.com/press (Accessed 9/2013)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We use the terms image and photo interchangeably throughout this paper to refer to the images on Instagram.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We use IRR to refer to Incidence Rate Ratio. We compute IRR for a categorical independent variables x as the ratio of amount of change in the dependent variable (outcome) for x relative to a reference level of x.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This material is based upon work supported in part by the Defense Advanced Research Projects Agency (DARPA) under Contract No. W911NF-12-1-0043. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the U.S. Government. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressly or implied, of the Defense Advanced Research Projects Agency or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Here&apos;s how to use instagram</title>
		<ptr target="http://www.businessinsider.com/instagram-2010-11?op=1" />
		<imprint>
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Testing</forename><surname>Testing</surname></persName>
		</author>
		<ptr target="http://blog.instagram.com/post/8758396471/testing-testing" />
		<imprint>
			<date type="published" when="2011-07">July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://pewinternet.org/Reports/2013/" />
		<title level="m">Social-media-users/ Social-Networking-Site-Users/Demo-portrait. aspx</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>A demographic portrait of users of various social media services</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="http://en.faceplusplus.com/" />
		<title level="m">Face++</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Talk to me: foundations for successful individual-group interactions in online communities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Arguello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Joyce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kraut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in computing systems</title>
		<meeting>the SIGCHI conference on Human Factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="959" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The impact of physically attractive models on advertising evaluations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Churchill</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of marketing research</title>
		<imprint>
			<biblScope unit="page" from="538" to="555" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tinkering and gender in end-user programmers&apos; debugging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kissinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiedenbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lawrance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in computing systems</title>
		<meeting>the SIGCHI conference on Human Factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="231" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What makes online content viral</title>
		<author>
			<persName><forename type="first">J</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Milkman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of marketing research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="192" to="205" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">In the eye of the beholder: the science of face perception</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Introductions and requests: Rhetorical strategies that elicit response in online communities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Joyce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kraut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communities and Technologies</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="21" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mind your ps and qs: the impact of politeness and rudeness in online communities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kraut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM conference on Computer supported cooperative work</title>
		<meeting>the 2008 ACM conference on Computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="281" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Feed me: motivating newcomer contribution in social network sites</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Marlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>acm</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="945" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Regression analysis of count data (econometric society monographs)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Trivedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-09">September 1998</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nudge nudge wink wink: elements of face-to-face conversation for embodied conversational agents</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cassell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Embodied Conversational Agents</title>
		<imprint>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A gender based study of tagging behavior in twitter</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Magno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gonc ¸alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM conference on Hypertext and social media</title>
		<meeting>the 23rd ACM conference on Hypertext and social media</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="323" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The expression of the emotions in man and animals</title>
		<author>
			<persName><forename type="first">C</forename><surname>Darwin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The impact of animated interface agents: a review of empirical research</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Mulken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of human-computer studies</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Facebook&apos;s instagram says it has 90 million monthly active users</title>
		<author>
			<persName><forename type="first">C</forename><surname>Desmarais</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-02">February 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effects of deindividuation variables on stealing among halloween trick-or-treaters</title>
		<author>
			<persName><forename type="first">E</forename><surname>Diener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Beaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Kelem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">178</biblScope>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Pictures of facial affect</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Friesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>consulting psychologists press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Connection strategies: social capital implications of facebook-enabled communication practices</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ellison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Steinfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lampe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New media &amp; society</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="873" to="892" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">L. I need to try this?: a statistical overview of pinterest</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bakhshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terveen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2427" to="2436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simulationist models of face-based emotion recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Sripada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="193" to="213" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Snowball sampling</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="148" to="170" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The distributed human neural system for face perception</title>
		<author>
			<persName><forename type="first">J</forename><surname>Haxby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gobbini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="223" to="233" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Gender and power in on-line communication. The handbook of language and gender</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Herring</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page">202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Women and children last: The discursive construction of weblogs</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Herring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kouper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Scheidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Into the blogosphere: Rhetoric, community, and culture of weblogs</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Visualizing instagram: Tracing cultural visual rhythms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hochman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<idno>ICWSM-12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on social media visualization (socmedvis) in conjunction with the sixth international AAAI conference on weblogs and social media</title>
		<meeting>the workshop on social media visualization (socmedvis) in conjunction with the sixth international AAAI conference on weblogs and social media</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reafferent copies of imitated actions in the right superior temporal cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Iacoboni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Koski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bekkering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dubeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mazziotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the national academy of sciences</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="13995" to="13999" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Digging digg: comment mining, popularity prediction, and social network analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rangwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Information Systems and Mining</title>
		<imprint>
			<publisher>ieee</publisher>
			<date type="published" when="2009">2009. 2009. 2009</date>
			<biblScope unit="page" from="32" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">100% accuracy in automatic face recognition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Burton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="page">435</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Newborns&apos; preferential tracking of face-like stimuli and its subsequent decline</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dziurawiec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">cognition</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The fusiform face area: a module in human extrastriate cortex specialized for face perception</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Chun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="4302" to="4311" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The meaning of photography</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kelsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stimson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Clark Art Institute</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Interface agents: Metaphors with character. Human values and the design of computer technology</title>
		<author>
			<persName><forename type="first">B</forename><surname>Laurel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="207" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Photo search by face positions and facial attributes on touch devices</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on Multimedia, MM &apos;11</title>
		<meeting>the 19th ACM international conference on Multimedia, MM &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="651" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stimulating social engagement in a community network</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Millen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 ACM conference on Computer supported cooperative work</title>
		<meeting>the 2002 ACM conference on Computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="306" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Conspec and conlern: a two-process theory of infant face recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">164</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Unmasking the face on mars. new high-resolution images and 3d altimetry from nasa&apos;s mars global surveyor spacecraft reveal the face on mars for what it really is: a mesa</title>
		<author>
			<persName><forename type="first">T</forename><surname>Phillips</surname></persName>
		</author>
		<ptr target="http://science.nasa.gov/science-news/science-at-nasa/2001/ast24may_1/" />
		<imprint>
			<date type="published" when="2001-05">May 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Functional neuroanatomy of face and object processing: a position emission tomography study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sergent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="15" to="36" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Watch what i watch: using community activity to understand content</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Shafton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIR &apos;07: Proceedings of the international workshop on Workshop on multimedia information retrieval</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">When the interface is a face</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sproull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiesler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Waters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="97" to="124" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Want to be retweeted? large scale analytics on factors impacting retweet in twitter network</title>
		<author>
			<persName><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Second International Conference on Social Computing (SocialCom)</title>
		<imprint>
			<biblScope unit="page" from="177" to="184" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Communicative facial displays as a new conversational modality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the INTERSECT&apos;93 and CHI&apos;93 conference on human factors in computing systems</title>
		<meeting>the INTERSECT&apos;93 and CHI&apos;93 conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="187" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Situated facial displays: towards social interaction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Takeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>acm press/addison-wesley publishing co</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="450" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cultural differences, experience with social networks and the nature of true commitment in facebook</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vasalou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Courvoisier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of human-computer studies</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="719" to="728" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Using a human face in an interface</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sproull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="85" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Word-of-mouth as self-enhancement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wojnicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Godes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HBS marketing research paper</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="6" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation. Pattern analysis and machine intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Know your data: Understanding implicit usage versus explicit action in video content classification. IS&amp;T/SPIE Electronic Imaging</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-01">January 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Matching familiar and unfamiliar faces on identity and expression</title>
		<author>
			<persName><forename type="first">A</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcweeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="63" to="68" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
