<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Markov random field image segmentation model for color textured images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zoltan</forename><surname>Kato</surname></persName>
							<email>kato@inf.u-szeged.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
								<address>
									<postBox>P.O. Box 652</postBox>
									<postCode>H-6701</postCode>
									<settlement>Szeged</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ting-Chuen</forename><surname>Pong</surname></persName>
							<email>tcpong@cs.ust.hk</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Markov random field image segmentation model for color textured images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2CD1C4980A45BB5FF1735D3A29CE76F6</idno>
					<idno type="DOI">10.1016/j.imavis.2006.03.005</idno>
					<note type="submission">Received 9 February 2004; received in revised form 13 March 2006; accepted 31 March 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Segmentation</term>
					<term>Color</term>
					<term>Texture</term>
					<term>Markov random fields</term>
					<term>Parameter estimation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a Markov random field (MRF) image segmentation model, which aims at combining color and texture features. The theoretical framework relies on Bayesian estimation via combinatorial optimization (simulated annealing). The segmentation is obtained by classifying the pixels into different pixel classes. These classes are represented by multi-variate Gaussian distributions. Thus, the only hypothesis about the nature of the features is that an additive Gaussian noise model is suitable to describe the feature distribution belonging to a given class. Here, we use the perceptually uniform CIE-L*u*v* color values as color features and a set of Gabor filters as texture features. Gaussian parameters are either computed using a training data set or estimated from the input image. We also propose a parameter estimation method using the EM algorithm. Experimental results are provided to illustrate the performance of our method on both synthetic and natural color images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image segmentation is an important early vision task where pixels with similar features are grouped into homogeneous regions. A broadly used class of models is the so-called cartoon model, which has been extensively studied from both probabilistic <ref type="bibr" target="#b0">[1]</ref> and variational <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> viewpoints. The model assumes that the real world scene consists of a set of regions whose observed low-level features changes slowly, but across the boundary between them, these features change abruptly. What we want to infer is a cartoon u consisting of a simplified, abstract version of the input image I: regions R i has a constant value (called a label in our context) and the discontinuities between them form a curve G-the contour. The pair (u, G) specifies a segmentation. Note that depending on the segmentation approach G may not be included explicitly in the model. Once u is determined, G is simply obtained as the discontinuities of u. Herein, we will also concentrate on u.</p><p>Taking the probabilistic approach, one usually wants to come up with a probability measure on the set U of all possible segmentations of I and then select the one with the highest probability. Note that U is finite, although huge. A widely accepted standard, also motivated by the human visual system <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, is to construct this probability measure in a Bayesian framework <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>: we shall assume that we have a set of observed (Y) and hidden (X) random variables. In our context, the observation F 2Y represents the low-level features used for partitioning the image, and the hidden entity u2X represents the segmentation itself. First, we have to quantify how well any occurrence of u fits F. This is expressed by the probability distribution PðFjuÞ-the imaging model. Second, we define a set of properties that any segmentation u must posses regardless the image data. These are described by P(u), the prior, which tells us how well any occurrence u satisfies these properties. Factoring these distributions and applying the Bayes theorem gives us the posterior distribution PðujFÞf PðFjuÞPðuÞ. Note that the constant factor 1=PðFÞ has been dropped, as we are only interested in û which maximizes the posterior, i.e. the Maximum A Posteriori (MAP) estimate of the hidden field X.</p><p>The models of the above distributions depend also on certain parameters that we denote by q. Supervised segmentation assumes that these parameters are either known or a set of joint realizations of the hidden field X and observations Y (called a training set) is available <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9]</ref>. In the unsupervised case, however, we know neither q nor X. This is called the incomplete data problem where both q and X has to be inferred from the only observable entity Y.</p><p>Expectation maximization (EM) <ref type="bibr" target="#b9">[10]</ref> and its variants (Stochastic EM <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, Gibbsian EM <ref type="bibr" target="#b12">[13]</ref>), as well as iterated conditional expectation (ICE) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> are widely used to solve such problems. It is important to note, however, that these methods calculate a local maximum <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">State of the art and the proposed approach</head><p>There are many features that one can take as observation F for the segmentation process: gray-level, color, motion, different texture features, etc. However, most of the segmentation algorithms presented in the literature are based on only one of these features. Recently, the segmentation of color images (textured or not) has received more attention <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>. In this paper, we are interested in the segmentation of color textured images. In <ref type="bibr" target="#b21">[22]</ref>, a multi-layer MRF model is proposed: each feature has its own layer, called feature layer, where an MRF model is defined using only the corresponding feature. A special layer is assigned to the combined MRF model. This layer interacts with both color and texture layers and provides the segmentation based on the combination of those features. Another approach is <ref type="bibr" target="#b17">[18]</ref>, where an unsupervised segmentation algorithm is proposed which uses Gaussian MRF models for color textures. These models are defined in each color plane with interactions between different color planes. The segmentation algorithm is based on agglomerative hierarchical clustering. Our approach is different in two major points. First, we use a stochastic monogrid model-based segmentation framework instead of multilayer clustering. Second, we use a combination of classical, gray-level based, texture features and color instead of direct modeling of color textures. Hence, most of the classical texture features can be used.</p><p>We have also compared our method to JSEG <ref type="bibr" target="#b20">[21]</ref>, which is a recent unsupervised segmentation algorithm for color textured images. It consists of two independent steps: First, colors in the image are quantized to several representative classes. The output is a class map where pixels are replaced by their corresponding color class labels. Then a region growing method is used to segment the image based on the multi-scale J-images. A J-image is produced by applying a criterion to local windows in the class-map (see <ref type="bibr" target="#b20">[21]</ref> for details on that). Although there have been other unsupervised segmentation methods proposed (like normalized cuts <ref type="bibr" target="#b23">[24]</ref>), we have chosen JSEG as it is also region based and uses similar cues than our method. The main difference is that JSEG is not a model-based approach.</p><p>The proposed segmentation model consists of an MRF defined over a nearest neighborhood system. The pixel classes are represented by multi-variate Gaussian distributions over image features (basically an additive Gaussian noise model). Since, the different texture-types are described by a set of Gaussian parameters, it is possible to classify or recognize textures based on prior learning of the possible parameters. Of course, if we do not have training data, parameter estimation can be a difficult task. Here, we apply the expectation-maximization (EM) algorithm <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref> to identify Gaussian mixture components.</p><p>In our approach, the image features F consist of the perceptually uniform CIE-L*u*v* color values, and texture features derived from the Gabor filtered gray-level image. Of course, the nature of the texture features is not crucial to the algorithm from the segmentation point of view. The only requirement in the current model is that Gaussian models should be suitable for describing the texture feature distributions. Most of the filtering approaches (see <ref type="bibr" target="#b25">[26]</ref> for a comparative study of different filtering techniques) fall into this category. A detailed study about Gaussian mixture modelization of different color and texture features can be found in <ref type="bibr" target="#b26">[27]</ref>. One can think of this kind of modelization as clustering the image pixels into different classes: The mean value represents the cluster center and the covariance matrix determines the (approximate) extent of the cluster. However, clustering algorithms work only in the feature space while our MRF segmentation model also takes into account the spatial relationship of pixels in the image domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Feature extraction</head><p>First, we briefly describe the color and texture features extracted from the input image I. Let us assume that images are defined over a finite rectangular lattice SZ fs 1 ; s 2 ; .; s N g, where sZ(i, j) denotes lattice sites (or pixels). At each pixel s, the features can be represented by a vector ð f s . The dimension of the vector is determined by the number of features extracted. Therefore, features form a vector field FZ f ð f s js 2Sg (the observation), which is the input of our MRF segmentation algorithm discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Color features</head><p>The first question, when dealing with color images, is how to measure quantitatively the color difference between any two arbitrary colors. Experimental evidence suggests that the RGB tristimulus color space may be considered as a Riemannian space <ref type="bibr" target="#b27">[28]</ref>. Due to the complexity of determining color distance in such spaces, several simple formulas have been proposed. These formulas approximate the Riemannian space by a Euclidean color space yielding a perceptually uniform spacing of colors. One of these formulas is the CIE-L*u*v* <ref type="bibr" target="#b27">[28]</ref> color space that we use here. Fig. <ref type="figure">1</ref> demonstrates the difference between RGB and CIE-L*u*v* color metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Texture features</head><p>Many different techniques have been proposed for analyzing image texture <ref type="bibr" target="#b25">[26]</ref>. Herein, we will adopt multichannel filtering where the channels are represented by a bank of real-valued, even-symmetric Gabor filters. Segmentation requires simultaneous measurements in both the spatial and frequency domains. However, spatial localization of boundaries requires larger bandwidths whereas smaller bandwidths give better texture measurements. Fortunately, Gabor filters have optimal joint localization in both domains <ref type="bibr" target="#b28">[29]</ref>. In addition, when we are combining texture features with color, the spatial resolution is considerably increased.</p><p>The Fourier domain representation H(u, v) of the basic evensymmetric Gabor filter oriented at 08 is given by <ref type="bibr" target="#b28">[29]</ref> A exp K 1 2</p><formula xml:id="formula_0">ðuKu 0 Þ 2 s 2 u C v 2 s 2 v Cexp K 1 2 ðu C u 0 Þ 2 s 2 u C v 2 s 2 v ;<label>(1)</label></formula><p>where s u Z1/2ps x , s v Z1/2ps y , AZ2s x s y , u 0 is the frequency of a sinusoidal plane wave along the x-axis, and s x and s y are the deviations of the Gaussian envelope along the x and y-axes.</p><p>Filters with other orientations can be obtained by rotating the coordinate system. In our tests, we used four orientations: 08, 458, 908, 1358 and the radial frequencies u 0 were 1 octave apart:</p><formula xml:id="formula_1">ffiffi ffi 2 p ; ffiffi ffi 2 p =2; ffiffi ffi 2 p =4; ffiffi ffi 2 p =8;</formula><p>.. For a 2 W pixel wide image, the highest radial frequency falling inside the image array is ffiffi ffi 2</p><formula xml:id="formula_2">p =2 WK2 .</formula><p>From each filtered image g, we compute a feature image, which allows the segmentation of the image by its pixel values alone. As shown in Fig. <ref type="figure" target="#fig_1">3</ref>, such a feature image is basically a grayscale image with similar intensities within similarly textured regions. The feature image is obtained via a local energy function applied to the filtered image. The objective of the local energy function is to estimate the energy in a local region of the filter output. The local energy function consists of a nonlinearity and smoothing (see <ref type="bibr" target="#b25">[26]</ref> for a comparative study of different approaches). Our experiments follow the procedure reported in <ref type="bibr" target="#b28">[29]</ref>: First, the nonlinear transformation, jtanhðag s Þj; s 2S (a rectified sigmoid) is applied which transforms negative amplitudes to the corresponding positive amplitudes. This is followed by a Gaussian smoothing filter whose deviation is proportional to the center frequency of the Gabor filter: sZk/ u 0 . Note that accurate edge localization calls for a small Gaussian window while accurate energy estimation calls for larger window sizes. This is why the filter size is set as a function of the band center frequency. In our experiments, the Gabor filtered images are scaled to the interval [K1,1] and we set aZ40 and kZ1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MRF segmentation model</head><p>As discussed in Section 1, the segmentation is obtained as a cartoon image, which is basically a labeling of the input image I. Hence for each pixel s, the region-type (or pixel class) that the pixel belongs to is specified by a class label, u s , which is modeled as a discrete random variable taking values in LZ{1, 2,.,L}. The set of these labels uZ fu s ; s 2Sg is a random field, called the label process. Furthermore, the observed image features (color and texture) are supposed to be a realization Ff ð f s js 2Sg from another random field, which is a function of the label process u. Basically, the image process F represents the manifestation of the underlying label process. Thus, the overall segmentation model is composed of the hidden label process u and the observable noisy image process F. Our goal is to find an optimal labeling û which maximizes the posterior probability PðujFÞ, that is the maximum a posteriori (MAP) estimate <ref type="bibr" target="#b0">[1]</ref> û Z arg max u2U PðFjuÞPðuÞ;</p><p>(2) where U denotes the set of all possible labelings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Label process</head><p>The label process u is modeled as a MRF with respect to a first order neighborhood system (see Fig. <ref type="figure">1</ref>). According to the Hammersley-Clifford theorem <ref type="bibr" target="#b0">[1]</ref>, P(u) follows a Gibbs distribution Fig. <ref type="figure">2</ref>. Plot of the misclassification rate vs. b in case of supervised segmentation of the synthetic images shown in Fig. <ref type="figure" target="#fig_2">5</ref>-Fig. <ref type="figure" target="#fig_5">8</ref>. For bR 2.0, the error rate reaches its minimum and stabilizes. Fig. <ref type="figure">1</ref>. First order neighborhood system with corresponding cliques.</p><formula xml:id="formula_3">PðuÞ Z 1 Z expðKUðuÞÞ Z 1 Z exp K X C2C V C ðu C Þ ! ;<label>(3)</label></formula><p>where U(u) is called an energy function, ZZ P </p><formula xml:id="formula_4">V C Z dðu s ;u r Þ Z C1 if u s su r K1 otherwise (<label>(4)</label></formula><p>This potential is also know as the Potts model in statistical physics <ref type="bibr" target="#b29">[30]</ref>. From Eq. (3), the full prior is as follows:</p><formula xml:id="formula_5">PðuÞ Z 1 Z exp K X fs;rg2C dðu s ;u r Þ !<label>(5)</label></formula><p>Note that this energy is proportional to the length of the region boundaries. Thus, homogeneous segmentations will get a higher probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Image process</head><p>The multivariate Normal density is typically an appropriate model for most classification problems where the feature vectors ð f s for a given class l are continuous valued, mildly corrupted versions of a single mean vector m l <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31]</ref>. Samples from this type of distribution tend to cluster about the mean, and the extent to which they spread out depends on the variance. This kind of modelization corresponds well to our features: Texture feature images are constructed in such a way that similar textures map to similar intensities. Hence, pixels with a given texture will be assigned a well-determined value with some variance. Furthermore, the CIEKL*u*v* colors form an Euclidean space <ref type="bibr" target="#b27">[28]</ref>: pixels with similar color map to CIEKL*u*v* vectors that are close to their average (see Fig. <ref type="figure">4</ref>). Putting these feature distributions into one multivariate Normal mixture, the modes will correspond to clusters of pixels, which are homogeneous in both color and texture properties. Therefore, regions will be formed where both features are homogeneous while boundaries will be present where there is a discontinuity in either color or texture (see Fig. <ref type="figure" target="#fig_4">7</ref> as an example). Applying these ideas, the image process Fcan be formalized as follows: Pð ð f s ju s Þ follows a Normal distribution Nð ð m;SÞ, each pixel class l2LZ{1,2,.,L} is represented by its mean vector ð m l and covariance matrix S l</p><formula xml:id="formula_6">Nðm l ;S l Þ Z 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð2pÞ n jS l j p exp K 1 2 ð ð f K ð m l ÞS K1 l ð ð f K ð m l Þ T (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>where n is the dimension of the combined color-texture feature space. Note that pixel features are assumed independent which yields to the following simplified form of the likelihood PðFjuÞ:</p><formula xml:id="formula_8">PðFjuÞ Z Y s2S Pð ð f s ju s Þ (7) Z Y s2S 1 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð2pÞ n jS u s j q exp K 1 2 ð ð f s K ð m u s ÞS K1 u s ð ð f s K ð m u s Þ T<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Posterior energy</head><p>Before calculating the posterior probability PðujFÞ, we can further simplify it: first of all, the whole posterior can be expressed as a first order MRF by including the contribution of the likelihood term via the singletons (i.e. pixel sites s 2S). Indeed, the singleton energies directly reflect the probabilistic modeling of labels without context, while doubleton clique potentials express relationship between neighboring pixel labels. Therefore, after dropping the normalizing constant, we get PðujFÞf expðKUðu;FÞÞ (9)</p><formula xml:id="formula_9">fexp K X s2S V s ðu s ; ð f s Þ C b X fs;rg2C dðu s ;u r Þ ! ! (<label>10</label></formula><formula xml:id="formula_10">)</formula><p>where bO0 is a weighting parameter controlling the importance of the prior. As b increases, the resulting regions become more homogeneous. The singleton potentials V s ðu s ; ð f s Þ are obtained from Eq. ( <ref type="formula" target="#formula_8">8</ref>):</p><formula xml:id="formula_11">V s ðu s ; ð f s Þ Z ln ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð2pÞ n jS u s j q C 1 2 ð ð f s K ð m u s ÞS K1 u s ð ð f s K ð m u s Þ T<label>(11)</label></formula><p>Thus, the energy function Uðu; FÞ of the so defined MRF image segmentation model has the following form:</p><formula xml:id="formula_12">X s2S ln ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ð2pÞ n S u s q C 1 2 ð ð f s K ð m u s ÞS K1 u s ð ð f s K ð m u s Þ T C b X fs;rg2C dðu s ;u r Þ<label>(12)</label></formula><p>It is clear that the original MAP estimation in Eq. ( <ref type="formula">2</ref>) is equivalent to the following energy minimization problem:</p><formula xml:id="formula_13">û Z arg min u2U Uðu;FÞ<label>(13)</label></formula><p>Now, the segmentation problem is reduced to the minimization of the above function. Since, it is non-convex, combinatorial optimization techniques are needed to find the global minimum. Our experiments used simulated annealing with Gibbs sampler <ref type="bibr" target="#b0">[1]</ref> and Iterated conditional modes (ICM) <ref type="bibr" target="#b31">[32]</ref>. A comparative study of these algorithms along with other combinatorial optimization techniques applied for Bayesian image segmentation can be found in <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Parameter estimation</head><p>The proposed segmentation model has the following parameters:</p><p>(1) The weight b of the prior term, (2) the number of pixel classes L, (3) the mean vector ð m l and covariance matrix S l of each class l2L.</p><p>The automatic determination of L usually requires some additional, higher level information, which also depends on the particular application. Nevertheless, estimation of L based solely on the input image is also possible but it requires special sampling algorithms. One of these techniques is the Reversible Jump Markov Chain Monte Carlo algorithm, which can deal with the model dimension switching <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. However, this is out of the scope of the paper. In our experiments, we simply set L manually.</p><p>While L strongly depends on the input image data, b is largely independent of it. Experimental evidence suggests that the model is not sensitive to a particular setting of b (see Fig. <ref type="figure">2</ref>). As long as b is large enough, the quality of segmentations are quite similar. When b is close to 0, however, the prior becomes too weak and we get inhomogeneous segmentations. Although automatic estimation methods exist <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b36">37]</ref>, b is rather a hyper-parameter, which can be fixed a priori. We found that setting bR2.0 gives satisfactory and stable segmentations.</p><p>Unlike the first two parameters, the mean and covariance of the Gaussians must be computed directly from the input image. In the remaining part of this section, we will describe how this task can be tackled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Gaussian mixture identification</head><p>Estimating the parameters of a mixture density is a wellknown statistical problem. The most widely used approach is Fig. <ref type="figure">4</ref>. Color histograms of the image in Fig. <ref type="figure" target="#fig_1">3</ref> generated by the ColorSpace software <ref type="bibr" target="#b38">[39]</ref>. In CIE-L*u*v* space, similar colors are well clustered but in RGB metric, these colors spread out across the whole space. This property makes the former color space a good choice when using Gaussian modelization. One can easily identify the ellipsoids corresponding to the different regions in the original image (the ellipsoid corresponding to the middle region is occluded).</p><p>probably the method of maximum likelihood. If a labeled training set is available, then an unbiased estimate of ð m l and S l can be obtained as the first and second moments of the labeled data <ref type="bibr" target="#b30">[31]</ref>. Assuming ð</p><p>x l i ðiZ 1;.;N l Þ denotes the feature vectors assigned to class l2L and N l denotes the number of these vectors, the following formulas can be used:</p><formula xml:id="formula_14">ð m l Z 1 N l X N l iZ1 ð x l i (14) S l Z 1 N l K1 X N l iZ1 ðð x l i K ð m l Þ T ðð x l i K ð m l Þ<label>(15)</label></formula><p>Such a training set can be obtained by manually selecting representative regions on the input image (as shown in Fig. <ref type="figure" target="#fig_2">5</ref>, for example). However, this procedure requires user interaction, which may not be acceptable in real life applications.</p><p>In case of incomplete data (i.e. when observations are unlabeled), a general iterative algorithm, known as the EM algorithm, has been proposed in <ref type="bibr" target="#b9">[10]</ref> to compute the maximum likelihood estimates. Herein, we specialize this method to the mixture density context <ref type="bibr" target="#b24">[25]</ref>. Basically, we will fit a Gaussian mixture of L components to the histogram of the image features. The observations consist of the histogram data ð d i ðiZ 1;.;DÞ of the feature images. D denotes the number of histogram points and the dimension of a data point equals to the dimension of the combined color-texture feature space. Assuming there are L classes, we want to estimate the mean values ð m l and covariance matrices S l for each pixel class l2L.</p><p>The EM algorithm aims at finding parameter values, which maximize the normalized log-likelihood function:</p><formula xml:id="formula_15">L Z 1 D X D iZ1 log X l2L Pðlj ð d i Þ !<label>(16)</label></formula><p>The underlying model is that the complete data includes not only the observable ð d i but also the hidden data labels ð [ i specifying which Gaussian process generated the data ð d i Actually, ð [ i is also a vector of dimension L and ð [ l i Z 1. if ð d i belongs to class l and 0 otherwise. The idea is that if labels were known, the estimation of model parameters would be equivalent to the supervised case. Hence, the following algorithm is alternating two steps: the estimation of a tentative labeling of the data followed by updating the parameter values based on the tentatively labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. (EM for Gaussian mixture identification)</head><p>[Estimation] Replace ð [ i with its conditional expectation based on the current parameter estimates. Since, the labels may only take values 0 or 1, the expectation is basically equivalent to the posterior probability</p><formula xml:id="formula_16">Pðlj ð d i Þ Z Pð ð d i jlÞPðlÞ P l2L Pð ð d i jlÞPðlÞ ;<label>(17)</label></formula><p>where P(l) denotes the component weight.</p><p>[Maximization] Then, using the current expectation of the labels ð [ i as the current labeling of the data, the estimation of the parameters is simple</p><formula xml:id="formula_17">PðlÞ Z K l D<label>(18)</label></formula><formula xml:id="formula_18">ð m l Z 1 K l X D iZ1 Pðlj ð d i Þ ð d i<label>(19)</label></formula><formula xml:id="formula_19">S l Z 1 K l X D iZ1 Pðlj ð d i Þð ð d i K ð m l Þ T ð ð d i K ð m l Þ<label>(20)</label></formula><p>where</p><formula xml:id="formula_20">K l Z P D iZ1 Pðlj ð d i Þ.</formula><p>Basically, the posteriors Pðlj ð d i Þ are used as a weight of the data vectors. They express the contribution of a particular data point ð d i to the class l.</p><p>Go to step until convergence. Each iteration is guaranteed to increase the likelihood of the estimates <ref type="bibr" target="#b9">[10]</ref>. The algorithm is stopped when the change of the log-likelihood L is less than a predetermined threshold (our test cases used 10 K7 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results</head><p>The proposed algorithm has been tested on a variety of color images including synthetic images (Figs. <ref type="figure" target="#fig_2">5</ref><ref type="figure" target="#fig_3">6</ref><ref type="figure" target="#fig_4">7</ref><ref type="figure" target="#fig_5">8</ref>), and real (Figs. 9 and 10) scenes. We have used MIT's VisTex database <ref type="bibr" target="#b37">[38]</ref> to compose the synthetic color textured images. The test program has been implemented in C and run on an Intel Pentium4 3 GHz workstation. Here, we present a few examples of these results and compare supervised and unsupervised segmentation results using color-only, texture-only and combined features. Furthermore, we also compare the results obtained via a deterministic (ICM <ref type="bibr" target="#b31">[32]</ref>) and stochastic (simulated annealing with Gibbs sampler <ref type="bibr" target="#b0">[1]</ref>) relaxation. For the latter algorithm, we have used an exponential annealing schedule (T kC1 Z0.98T k ) with an initial temperature T 0 Z4.0. The evaluation of the results is done in terms of both computing time and segmentation quality. The quality is measured quantitatively on the synthetic images as the percentage of misclassified pixels.</p><p>In the case of supervised segmentation, the mean vectors and covariance matrices were computed over representative regions selected by the user (see Fig. <ref type="figure" target="#fig_2">5</ref>). In all cases, we set bZ 2.5. This value has been found to provide satisfactory results. An optimal Gabor filter set containing 2-4 filters have been picked manually for each image. We remark, however, that it is also possible to automatically select these filters (see <ref type="bibr" target="#b25">[26]</ref> for a collection of methods).</p><p>We found in all test cases that segmentation based purely on texture gives fuzzy boundaries but usually homogeneous regions, whereas segmentation based on color is more sensitive to local variations but provides sharp boundaries. As for the combined features, the advantages of both color and texture based segmentation have been preserved: we obtained sharp boundaries and homogeneous regions (see Fig. <ref type="figure" target="#fig_2">5</ref> as a good example). The power of combined features is well demonstrated by Fig. <ref type="figure" target="#fig_3">6</ref>. Three regions contain a wooden texture with nearly matching colors and a small difference in the direction (left and lower part) or scale (middle part) in texture. The two other regions have similar texture but completely different color. Comparing color-and texture-only segmentations, the latter two regions are perfectly separated in the color segmentation but they are mixed in the texture one. On the other hand, the former three regions are much better separated in the texture segmentation than in the color one. As for the combined segmentation, the five regions are well separated, and the error rate is half of the separate segmentation rates. Of course, the quality of unsupervised segmentation is inferior to the supervised one. Due to the difficult separability of the regions, the EM algorithm cannot provide better parameter estimates. Especially, the three regions containing the wooden texture are completely mixed, but one could argue that three classes would be more reasonable in the unsupervised case.</p><p>We can see in Table <ref type="table" target="#tab_0">1</ref> that supervised, color-only segmentation provides slightly better results than combined features. However, the difference is not significant (z0.9). The reason is that color features have higher resolution, hence edges are better preserved, while the additional information provided by texture features is not enough to improve the quality of segmentation. We can observe a similar effect in Table <ref type="table">2</ref>, where color features alone provide good quality supervised segmentation when the Gibbs sampler is used. In both cases, however, the advantage of combined features is evident in the case of the ICM algorithm or unsupervised segmentation.</p><p>We found that combined features can considerably increase the quality of unsupervised segmentations. For example, three regions are merged in the color-only segmentation of Fig. <ref type="figure" target="#fig_4">7</ref>. Since, these regions have similar colors and we have another region on the right hand side with several different colors, the EM algorithm detects only one class in these three regions and three or four classes in the region on the right hand side. As for the texture-only segmentation, the regions on the left and right hand side have similar textures thus parameter estimation tends to merge them. Similarly, the middle and upper regions are also merged. This is largely due to the fact that in the middle region, only the finer fiber texture is detected since the region size is too small to detect the larger pattern. In case of combined features, the five regions are well separated, and results are comparable to the supervised segmentation. The findings were the same on Fig. <ref type="figure" target="#fig_5">8</ref>.</p><p>Regarding the different optimization techniques, we can see that the suboptimal ICM provides somewhat lower quality compared to the optimal Gibbs sampler but it converges much faster (see Tables <ref type="table" target="#tab_0">1</ref><ref type="table">2</ref><ref type="table">3</ref><ref type="table">4</ref>). However, this difference in quality is less important in the case of combined features and for the real images it is nearly invisible.</p><p>In Figs. 6, 7, 8, unsupervised segmentation results has also been compared to those obtained by the JSEG algorithm <ref type="bibr" target="#b20">[21]</ref>. For producing the JSEG results, we have used the code provided by the authors and kept its default settings throughout Fig. <ref type="figure">9</ref>. Segmentation results on a 384 ! 384 real color image with 4 classes using combined features and ICM algorithm. We have used 3 Gabor filters to extract texture features.  our test: automatic quantization threshold and number of scales. The region merge threshold was also set to its default value (0.4). Note that JSEG is not model based, therefore there are no pixel classes, regions are identified based on the underlying color and texture properties of the input image. This is why we have got more than five regions on these results. It is clear that our method outperforms JSEG. However, JSEG's advantage is that we do not have to specify the image dependent parameter L.</p><p>We also ran a test on the images published in <ref type="bibr" target="#b17">[18]</ref> (see Figs. 9 and 10) and found that our results are comparable to those reported in <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We have proposed an MRF image segmentation model, which combines color and texture features. The model itself is not restricted to a specific texture feature. In fact, any feature is suitable as far as feature values belonging to a pixel class can be modeled by a Gaussian distribution. Due to our model-based approach, it is also possible to classify different kind of textures based on a prior training of the corresponding parameters. The quality of the segmentation is improved with respect to coloronly and texture-only segmentations. We also proposed a parameter estimation method using the EM algorithm and found that combined features can help to obtain correct estimates. Of course, unsupervised segmentation provides slightly lower quality results, but on real images, the results are comparable to supervised ones. We also tested different optimization methods and found that the suboptimal but fast ICM is a good tradeoff between quality and computing time when using combined features. Although our implementation is sequential, the segmentation algorithm is highly parallel due to the local nature of the MRF model. Thus, a parallel implementation can further improve the computing speed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>u2U exp(KU(u)) is the normalizing constant (or partition function) and V C denotes the clique potential of clique C 2C having the label configuration u C . In our case, C is the set of spatial second order cliques (doubletons). Each clique corresponds to a pair of neighboring pixels. The prior P(u) will represent the simple fact that segmentations should be locally homogeneous. Therefore, in our model, these potentials favor similar classes in neighboring pixels:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Feature images derived from different Gabor filters.</figDesc><graphic coords="4,94.73,71.22,396.00,127.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Segmentation results on a 128 ! 128 synthetic image with 5 classes using combined features. We have used 2 Gabor filters to extract texture features. We also show the training regions used for the computation of supervised Gaussian parameters.</figDesc><graphic coords="6,112.71,71.22,360.28,292.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Segmentation results on a 256 ! 256 synthetic color textured image with 5 classes. We have used 4 Gabor filters to extract texture features.</figDesc><graphic coords="7,122.23,71.22,360.76,483.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Segmentation results on 128 ! 128 synthetic color textured image with 5 classes. We have used 3 Gabor filters to extract texture features.</figDesc><graphic coords="8,112.42,71.22,360.76,483.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Segmentation results on a 128 ! 128 synthetic color textured image with 5 classes. We have used 3 Gabor filters to extract texture features.</figDesc><graphic coords="9,122.23,71.22,360.76,483.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Segmentation results on a 256 ! 256 real image with 3 classes using combined features and ICM algorithm. We have used 2 Gabor filters to extract texture features.</figDesc><graphic coords="10,112.48,253.94,360.86,129.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,122.17,71.22,361.05,218.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Computing times and segmentation error (misclassification rate) on a 128!128 synthetic image (Fig.7)</figDesc><table><row><cell>Feature</cell><cell>EM</cell><cell>Gibbs (s)</cell><cell>Error (%)</cell><cell>ICM (s)</cell><cell>Error (%)</cell></row><row><cell cols="2">Supervised Gaussian parameters</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Texture</cell><cell>N/A</cell><cell>8.82</cell><cell>22.3</cell><cell>0.10</cell><cell>25.6</cell></row><row><cell>Color</cell><cell>N/A</cell><cell>4.78</cell><cell>1.5</cell><cell>0.18</cell><cell>7.5</cell></row><row><cell>Combined</cell><cell>N/A</cell><cell>12.32</cell><cell>2.4</cell><cell>0.42</cell><cell>3.9</cell></row><row><cell cols="2">Unsupervised Gaussian parameters</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Texture</cell><cell>4.57 s</cell><cell>8.98</cell><cell>52.8</cell><cell>0.07</cell><cell>53.1</cell></row><row><cell>Color</cell><cell>3.94 s</cell><cell>6.62</cell><cell>36.6</cell><cell>0.15</cell><cell>41.0</cell></row><row><cell>Combined</cell><cell>7.14 s</cell><cell>13.34</cell><cell>5.85</cell><cell>0.34</cell><cell>6.8</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was partially supported by the Janos Bolyai research fellowship of the Hungarian Academy of Sciences, the</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Visual Reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimal approximations by piecewise smooth functions and associated variational problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="577" to="685" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Object perception as Bayesian inference</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="271" to="304" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<title level="m">Perception as Bayesian Inference</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Knill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Richards</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Chalmond</surname></persName>
		</author>
		<title level="m">Modeling and Inverse Problems in Image Analysis</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Random Fields and Markov Chain Monte Carlo cMethods</title>
		<author>
			<persName><forename type="first">G</forename><surname>Winkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Bayesian rationale for energy functionals</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geometry-Driven Diffusion in Computer Vision</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Romeny</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="141" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Color image segmentation by supervised pixel classification in a color texture feature space. Application to soccer image segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vandenbroucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Macaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Postaire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition</title>
		<meeting>the International Conference on Pattern Recognition<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">III</biblScope>
			<biblScope unit="page" from="621" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The SEM algorithm: a probabilisitic teacher algorithm derived from the EM algorithm for the mixture problem</title>
		<author>
			<persName><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Diebolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics Quaterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="73" to="82" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SEM algorithm and unsupervised statistical segmentation of satellite images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Masson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pieczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="618" to="633" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An iterative Gibbsian technique for reconstruction of M-ary images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chalmond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="747" to="762" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Global and Local Methods of Unsupervised Bayesian Segmentation of Images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Braathen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pieczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Masson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Graphics and Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="52" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised adaptive image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berthod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pieczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>International Conference on Acoustics, Speech and Signal Processing<address><addrLine>Detroit, Michigan, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2399" to="2402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Color images segmentation using scale space filter and Markov random field</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1217" to="1229" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multiresolution color image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="689" to="700" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Markov random field models for unsupervised segmentation of textured color images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Panjwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="939" to="954" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Segmentation of color textures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mirmehdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="142" to="159" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Markov random field image segmentation model using combined color and texture</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Pong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Analysis of Images and Patterns</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Skarbek</surname></persName>
		</editor>
		<meeting>International Conference on Computer Analysis of Images and Patterns<address><addrLine>Warsaw, Poland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2124</biblScope>
			<biblScope unit="page" from="547" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised segmentation of color-texture regions in images and video</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<ptr target="http://vision.ece.ucsb.edu/segmentation/jseg/)" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="800" to="810" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised segmentation of color textured images using a multi-layer MRF model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Pong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Q</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Image Processing</title>
		<meeting>International Conference on Image Processing<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="961" to="964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Integration of feature distributions for colour texture segmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nammalwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ghita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Whelan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Petrou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nixon</surname></persName>
		</editor>
		<meeting>the International Conference on Pattern Recognition<address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="716" to="719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mixture densities, maximum likelihood and the EM algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Redner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="239" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Filtering for texture classification: A comparative study</title>
		<author>
			<persName><forename type="first">T</forename><surname>Randen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Husoy</surname></persName>
		</author>
		<ptr target="http://www.ux.his.no/~tranden/)" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="291" to="310" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A study of Gaussian mixture models of colour and texture features for image classification and segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Permuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Francos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jermyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="695" to="706" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m">The Colour Image Processing Handbook</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Sangwine</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E N</forename><surname>Horne</surname></persName>
		</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman &amp; Hall</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised texture segmentation using Gabor filters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1167" to="1186" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Exactly Solved Models in Statistical Mechanics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Baxter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Clements</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing and Statistical Classification, Artech House</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>ISBN 1580531350</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="302" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bayesian image classification using Markov random fields</title>
		<author>
			<persName><forename type="first">M</forename><surname>Berthod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="285" to="295" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised image segmentation using Markov random field models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J W</forename><surname>Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="587" to="602" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reversible jump Markov chain Monte Carlo for unsupervised MRF color image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Brithish Machine Vision Conference</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Hoppe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Barman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Ellis</surname></persName>
		</editor>
		<meeting>Brithish Machine Vision Conference<address><addrLine>Kingston, UK</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bayesian image analysis by adaptive annealing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Geoscience and Remote Sensing Symposium</title>
		<meeting>International Geoscience and Remote Sensing Symposium<address><addrLine>Amherst, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="269" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised parallel image classification using Markovian models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zerubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berthod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="591" to="604" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<ptr target="http://vismod.media.mit.edu/vismod/imagery/VisionTextur%e/vistex.html" />
		<title level="m">MIT VisTex, texture database</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Colantoni</surname></persName>
		</author>
		<ptr target="http://www.couleur.org/)" />
		<title level="m">ColorSpace 1.06, software</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
