<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Curvelet based face recognition via dimension reduction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-03-18">18 March 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tanaya</forename><surname>Mandal</surname></persName>
							<email>tanaya@ece.ubc.ca</email>
							<affiliation key="aff0">
								<orgName type="department">ECE</orgName>
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<addrLine>2332 Main Mall</addrLine>
									<postCode>2010</postCode>
									<region>Kaiser, BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Q</forename><forename type="middle">M Jonathan</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">ECE</orgName>
								<orgName type="institution">University of Windsor</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
							<email>yuany1@aston.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">School of Engineering and Applied Science</orgName>
								<orgName type="institution">Aston University</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Curvelet based face recognition via dimension reduction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-03-18">18 March 2009</date>
						</imprint>
					</monogr>
					<idno type="MD5">A76E7316C5F334778196C825D22C9FDD</idno>
					<idno type="DOI">10.1016/j.sigpro.2009.03.007</idno>
					<note type="submission">Received 31 October 2008 Received in revised form 9 March 2009 Accepted 9 March 2009</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Digital curvelet transform LDA Multiresolution analysis PCA Subbands Wavelet transform</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multiresolution ideas, notably the wavelet transform, have been proved quite useful for analyzing the information content of facial images. Numerous papers and research articles have discussed the application of wavelet transform in face recognition. However, little attention has been paid to the newly developed multiresolution tools (contourlet, curvelet, etc.) despite their improved directional elements and other promising abilities compared to traditional wavelet transform. In this article we introduce the application of digital curvelet transform in conjunction with different dimensionality reduction tools, looking particularly at the problem of facial feature extraction from 2D images. The purpose of this paper is exploratory. We do not claim that the results achieved here are the best possible. Rather, we aim at showing that curvelets can serve as an effective alternative to wavelets as a feature extraction tool. This work can be seen as a stepping stone for further research in this direction. Our methods have been evaluated on well-known databases like ORL, Essex Grimace and Yale face. Curvelet based results have been compared with that achieved using wavelets and other existing techniques to show that curvelets indeed has the potential to supersede wavelet based results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Face recognition has been studied diligently for more than 30 years now and has emerged as one of the most successful applications of image analysis. Compared to other biometrics (fingerprint or iris recognition), face recognition might not have a superior level of accuracy, but working with faces certainly has a number of advantages. Firstly, the data (facial images) can be collected using a simple camera (compare the cost and difficulties of collecting good fingerprints or iris scan); and secondly, the images can be collected even without the knowledge of the subject. Clearly, from the security point of view, face recognition is a means of biometric identification which is hassle-free and inexpensive. The subject has become a major issue in the past decade-due to its important real-world applications in areas like video surveillance, smart cards, database security, telecommunication, digital libraries and medical records <ref type="bibr" target="#b0">[1]</ref>. Usually, the available images are 2D intensity images of human faces, which are 3D objects. So this problem can also be seen as a task of identifying 3D objects from their 2D images.</p><p>Feature extraction is a key step prior to face recognition. Extraction of a representative feature set can greatly enhance the performance of any face recognition system. Direct use of pixel values as features is not possible due to huge dimensionality of the images. Traditionally, Principal Component Analysis (PCA) is employed to obtain a lower dimensional representation of the data in standard eigenface based methods <ref type="bibr" target="#b1">[2]</ref>. Though PCA provides effective approximation, the method suffers from greater computational load and poor discriminatory power <ref type="bibr" target="#b2">[3]</ref>. In order to resolve these limitations of PCA, researchers suggest the use of other dimensionality reduction tools like Independent Component Analysis (ICA), Linear Discriminant Analysis (LDA), Kernel PCA <ref type="bibr" target="#b3">[4]</ref> and Kernel LDA <ref type="bibr" target="#b4">[5]</ref>. ICA is a generalization of PCA and finds notnecessarily orthogonal basis to represent the data. Based on the belief that ICA is capable of providing a better probabilistic model it was used in <ref type="bibr" target="#b5">[6]</ref> to extract facial features and a performance improvement over PCA was reported. <ref type="bibr">Belhumeur et al. worked</ref> with Fisherfaces <ref type="bibr" target="#b6">[7]</ref>, which involves Fisher Linear Discriminant (FLD). LDA has been found to improve the classification accuracy of a system when multiple images are available per class. LDA based recognition methods aim at simultaneously maximizing between-class scatter and minimizing withinclass scatter. KPCA, which takes into account higher order statistics in contrast to PCA, has also been successfully applied in the context of face recognition <ref type="bibr" target="#b7">[8]</ref>. More recently, a faster and efficient technique called Binary Two-Dimensional PCA (B-2DPCA) has been proposed <ref type="bibr" target="#b8">[9]</ref>; this method relies on Two-Dimensional PCA (2DPCA) based <ref type="bibr" target="#b9">[10]</ref> decomposition for fast numerical computations. The algorithm is particularly suitable for large-scale and high-resolution image based biometric systems. The problem of high dimensional feature extraction has been very well-addressed in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Most recently tensor based approaches <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> have been quite popular. Motivated by the success of 2DLDA <ref type="bibr" target="#b14">[15]</ref>, General Tensor Discriminant Analysis (GTDA) has been developed in <ref type="bibr" target="#b12">[13]</ref>. This method uses an alternating projection optimization algorithm, which, unlike 2DLDA always converges to a solution. In <ref type="bibr" target="#b13">[14]</ref>, another new manifold learning method called Discriminant Locally Linear Embedding (DLLE) has been presented. In this technique, the intra-class local geometric properties are preserved according to a locally linear embedding criterion and inter-class separability is enforced by maximizing margins between point pairs on different classes <ref type="bibr" target="#b13">[14]</ref>. The method has been reported to achieve significant performance improvement compared to state-of-the-art gait recognition algorithms.</p><p>Another way to handle huge dimensionality in face recognition problems is to employ dimensionality reduction tools on some kind of transformation domain. In <ref type="bibr" target="#b15">[16]</ref>, the authors argued that, when raw images are subjected to PCA, the correlation of facial features is not well-reflected in eigenspace. So, they suggested using Gabor filter to extract facial features first and then use PCA to classify the features optimally. It has been claimed that several problems like, deformation of face images due to in-plane in-depth rotation, illumination and contrast variation can be solved by extracting facial features using Gabor filters. Nowadays, multiresolution analysis is often performed as a pre-processing step to dimensionality reduction. The most popular multiresolution analysis tool is the wavelet transform. It has enjoyed a wide-spread popularity in the field of face recognition <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. In wavelet analysis an image is usually decomposed at different scales or resolutions using a wavelet basis vector. Thereafter, the component which corresponds to the maximum variance is selected for further operation. This way, the image can be represented by a small number of wavelet coefficients and the effect of variable facial appearances (expression variation, illumination variation, facial detail variation, etc.) on the classification systems can also be lessened in turn. Another approach has been introduced of late by Pang et al. in <ref type="bibr" target="#b18">[19]</ref>. They have used Gabor-based Region Covariance Matrices (RCM) for face recognition problems. From the experiments performed on FERET, it has been shown that the proposed methodology provides significant improvement over the conventional RCM framework.</p><p>Over the past two decades, following the success of wavelets, a series of new multiresolution analysis tools like, ridgelets <ref type="bibr" target="#b19">[20]</ref>, contourlets <ref type="bibr" target="#b20">[21]</ref>, etc. were developed. 'Curvelet transform' <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref>, developed by Candes and Donoho is a recent addition to this list. Compared to wavelets, curvelets have improved directional elements and better ability to represent edges and other singularities along curves. Curvelets, being a relatively new concept has not yet been very popular. So far, its successful applications have been found mostly in the fields of image processing, e.g. image denoising <ref type="bibr" target="#b22">[23]</ref>, image compression <ref type="bibr" target="#b24">[25]</ref>, image fusion <ref type="bibr" target="#b25">[26]</ref>, contrast enhancement <ref type="bibr" target="#b26">[27]</ref>, image deconvolution <ref type="bibr" target="#b27">[28]</ref>, high quality image restoration <ref type="bibr" target="#b28">[29]</ref>, astronomical image representation <ref type="bibr" target="#b29">[30]</ref> etc; but not much work has been done to explore the potential of curvelet transform to solve pattern recognition problems. In some recent works, Majumdar showed that curvelets can serve as the basis for pattern recognition problems like character recognition <ref type="bibr" target="#b30">[31]</ref>. Curvelet based face recognition has been discussed in <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>. In <ref type="bibr" target="#b32">[33]</ref>, a SVM based face recognition system has been developed, which uses curvelet coefficients without employing any dimensionality reduction. In our previous work <ref type="bibr" target="#b31">[32]</ref>, curvelet transform has been employed to extract features from bit quantized facial images, where we showed that curvelets can indeed supersede the performance of wavelets. The work presented in <ref type="bibr" target="#b33">[34]</ref> is an extension of <ref type="bibr" target="#b31">[32]</ref>. In <ref type="bibr" target="#b33">[34]</ref>, the authors used the bitquantized images to extract curvelet features at five different resolutions. A total of 15 sets of approximate coefficients are collected and used to train 15 Support Vector Machines. The results are fused using majority voting. However, working with large number of curvelet features (as done in all previous face recognition works with curvelets) can be computationally expensive. So, the natural aim is to reduce the dimension further. In this article a thorough study of application of digital curvelet transform in conjunction with dimensionality reduction tools like PCA and LDA will be presented. The proposed methods have been evaluated by carrying out different experiments on three well-known databases: ORL, Essex Grimace and Yale Face Database. Our prime objective has been to explore the potential of curvelet transform to be used as an alternative feature extraction tool.</p><p>The rest of the paper is organized as follows: Section 2 discusses the idea of curvelet transform, followed by a comparative study of curvelets and wavelets in Section 3. The proposed methods are described in Section 4. Section 5 contains experimental results and discussion; Section 6 concludes the article and suggests future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Curvelet transform</head><p>Curvelet transform was developed by Candes and Donoho in 1999. Its development was motivated by the need of image analysis <ref type="bibr" target="#b21">[22]</ref>. The transform has improved directional capability, better ability to represent edges and other singularities along curves as compared to other traditional multiscale transforms, e.g. wavelet transform. In the past few years curvelet construction has been redesigned in order to make it simpler to understand and use. This second generation curvelet transform <ref type="bibr" target="#b34">[35]</ref>, introduced in 2006 is not only simpler, but is faster and less redundant compared to its first generation version <ref type="bibr" target="#b23">[24]</ref>. Curvelet transform is multiscale and multidirectional. Curvelets exhibit highly anisotropic shape obeying parabolic-scaling relationship (they take the shape of elongated needles at finer scales). In order to implement curvelet transform, first a 2D FFT of the image is taken. Then the 2D Fourier frequency plane is divided into 'parabolic' wedges. Finally an inverse FFT of each wedge is taken to find the curvelet coefficients at each scale j and angle '. Fig. <ref type="figure">1</ref> (left) shows the division of wedges of the Fourier frequency plane. The wedges are the result of partitioning the Fourier plane in radial (concentric circles) and angular divisions. Concentric circles are responsible for decomposition of the image in multiple scales (used for bandpassing the image) and angular divisions correspond to different angles or orientation. Hence, to address a particular wedge one needs to define the scale and angle first. In the spatial domain, each wedge corresponds to a particular curvelet at that given scale and angle. Fig. <ref type="figure">1</ref> (right) represents curvelets in spatial Cartesian grid associated with a given scale and angle <ref type="bibr" target="#b34">[35]</ref>.</p><p>There are two different digital implementations of Fast Digital Curvelet Transform (FDCT) <ref type="bibr" target="#b34">[35]</ref>:</p><p>Curvelets via USFFT (Unequally Spaced Fast Fourier Transform).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Curvelets via Wrapping.</head><p>These transforms are linear and take as input a Cartesian array f[t 1 ,t 2 ], 0pt 1 , t 2 on and provide an output of discrete coefficients. Though both the implementations use same digital coronization, they differ in the choice of spatial grid to translate curvelets at each scale and angle. Both the FDCTs run in O(n 2 log n) flops for n by n Cartesian arrays <ref type="bibr" target="#b34">[35]</ref>. In case of wrapping a rectangular grid is assumed. All the experimental work presented in this article use numerically tight FDCT Wrapping, as this is the fastest curvelet transform algorithm currently available <ref type="bibr" target="#b34">[35]</ref>. The algorithm has been described below.</p><p>Let f ½n 1 ; n 2 denote 2D discrete Fourier transform of f[t 1 ,t 2 ]. Let U j (o) be a localizing window and Ũj ½n 1 ; n 2 is supported on some rectangle of length L 1,j and width L 2,j <ref type="bibr" target="#b34">[35]</ref> </p><formula xml:id="formula_0">P j ¼ fðn 1 ; n 2 Þ : n 1;0 pn 1 on 1;0 þ L 1;j ; n 2;0 pn 2 on 2;0 þ L 2;j g (1)</formula><p>Implementation steps of FDCT via Wrapping <ref type="bibr" target="#b34">[35]</ref>:</p><p>(1) Apply 2D FFT and obtain Fourier samples f ½n 1 ; n 2 , Àn=2pn 1 , n 2 on=2. (2) For each scale j and angle ', form the product Ũj;' ½n 1 ; n 2 f ½n 1 ; n 2 .</p><p>(3) Wrap this product around the origin and obtain</p><formula xml:id="formula_1">f j;' ½n 1 ; n 2 ¼ Wð Ũj;' f Þ½n 1 ; n 2 ,<label>(2)</label></formula><p>where the range n 1 and n 2 is now 0pn 1 oL 1;j and 0pn 2 oL 2;j . (4) Apply the inverse 2D FFT to each f j;' , hence collecting the discrete coefficients.</p><p>In first two steps, the Fourier frequency plane of the image is divided into radial and angular wedges owing to the parabolic relationship between curvelet's length and width, as shown in Fig. <ref type="figure">1</ref>. Each wedge corresponds to curvelet coefficients at a particular scale and angle.</p><p>Step 3 is basically re-indexing the data around the origin. Finally, using inverse FFT, discrete curvelet coefficients are collected in the spatial domain. It is not possible to delve into the mathematical details of curvelet transform within the scope of this paper; interested reader may refer to the works of Candes and Donoho <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b34">35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Wavelet vs. curvelet</head><p>The sparsity of Fourier series is destroyed due to discontinuities (Gibbs phenomenon); it requires a large number of terms to reconstruct a discontinuity in Fourier series within a good accuracy. Later, wavelets are found to have the ability to solve the problems of Fourier series, as they are localized and multiscale. However, though wavelets do work efficiently in one-dimension, they fail to represent higher dimensional singularities effectively due to limited orientation selectivity. Wavelets and related classical multiresolution ideas exploit a limited dictionary made up of roughly isotropic elements occurring at all scales and locations <ref type="bibr" target="#b35">[36]</ref>. These dictionaries do not exhibit highly anisotropic elements and there are only a fixed number of directional elements (standard orthogonal wavelet transforms have wavelets with primarily vertical, primarily horizontal and primarily diagonal orientations) independent of scale. Images do not always exhibit isotropic scaling and thus these limitations of wavelets call for other kinds of multiscale representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scale j Scale j-1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parabolic wedge</head><p>Fig. <ref type="figure">1</ref>. Curvelets in Fourier frequency (left) and spatial domain (right) <ref type="bibr" target="#b34">[35]</ref>.</p><p>The most interesting fact about curvelets is that it has been developed specially to represent objects with 'curvepunctuated smoothness' <ref type="bibr" target="#b35">[36]</ref> i.e. objects which display smoothness except for discontinuity along a general curve; images with edges would be good example of this kind of objects. Wavelet transform has been profusely employed to address different problems of pattern recognition and computer vision because of their capability of detecting singularities. But, though wavelets are good at representing point singularities in both 1D and 2D signals, they fail to detect curved singularities efficiently. Fig. <ref type="figure" target="#fig_2">2</ref> shows the edge representation capability of wavelet (left) and curvelet transform (right). For the square shape of wavelets at each scale, more wavelets are required for an edge representation than that compared to the number of required curvelets, which are of elongated needle shape. One more novelty of curvelet transform is that it is based on anisotropic scaling principal, whereas wavelets rely on isotropic scaling.</p><p>Let us consider an image function f, which has a discontinuity across a curve and is otherwise smooth; if it is approximated by the best m terms in Fourier expansion, the squared error is given by <ref type="bibr" target="#b36">[37]</ref> kf À</p><formula xml:id="formula_2">f F m k 2 / m À1=2 ; m ! þ1 For wavelets, kf À f W m k 2 / m À1 ; m ! þ1 For curvelets, we have kf À f C m k 2 / logðm 3 Þm À2</formula><p>; m ! þ1 which approaches the ideal reconstruction rate asymptotically. The main idea here is that the edge discontinuity is better approximated by curvelets than wavelets. To summarize, wavelet transform suffers from the following limitations:</p><p>Edge representation-though wavelets perform better than FFT, it is not optimal.</p><p>Crude directional elements independent of scale. No highly anisotropic element.</p><p>Curvelet transform is capable of solving the above problems. At any scale j, curvelets provide a sparse representation O(2 j/2 ) of the images compared to wavelets O(2 j ). Now, we will empirically try to show that similar (or better) accuracy can be achieved using curvelet transform as the bases of face recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Curvelet based face recognition</head><p>In the previous section, we have argued theoretically, that curvelet transform, because of its improved directional elements and highly anisotropic scaling property can provide an equally good (or superior) basis for face recognition compared to wavelets. To validate this empirically, various experiments have been designed and performed. Our face recognition system is divided into two stages: training stage and classification stage. During training, curvelet transform is applied to decompose the images into curvelet subbands. It has been stated repeatedly that curvelets are very good at representing objects with 'curve-punctuated smoothness' <ref type="bibr" target="#b35">[36]</ref>, i.e. objects which display smoothness except for discontinuity along a general curve. Facial images with edges are good examples of this kind of objects. Say, the images are represented by eight bits, i.e. 256 gray levels. In such an image two very close regions can have differing pixel values. Such a gray scale image will then have a lot of ''curved edges'' (which are typically curved in facial images)-and consequently the curvelet transform will capture this crucial edge information. Extracted curvelet coefficients can then be directly fed to a classifier to perform the identification task. An image of size, say 64 Â 64, when decomposed using curvelet transform at scale 3 (coarse, fine, finest) and angle 8 will produce 1 approximate (coarse) subband of size 21 Â 21 and 24 detailed coefficients of slightly larger size. Working with such large number of feature vectors is extremely expensive. Hence it is of utmost importance to determine a representative set of features. Selection of subbands has been done on the basis of the amount of variance they account for. We have selected the coarse coefficients, (as they account for the maximum variance and contain maximum energy of the image-data) and a set of fine coefficients with next highest amount of total variance. Thus selecting the appropriate curveletfaces reduces the dimension of the original image (represented as a vector) from 1 Â 4096 to 1 Â1258. Yet a feature vector of length 1 Â1258 needs some kind of dimensionality reduction. Traditional dimensionality reduction methods like PCA/ LDA can be applied on the selected subbands thereafter and an efficient and representative dataset can be produced. A simple Nearest Neighbor (NN) classifier is used to carry out the recognition task. Unless mentioned otherwise, a scale value of 3 has been used through out this work, in order to strike a balance between the speed and performance of the system. It has been observed that higher scale (4 or 5) has shown only marginal improvement or even no improvement in terms of recognition accuracy. Fig. <ref type="figure" target="#fig_3">3</ref>   them are of size 66 Â 123 and rest four are of size 149 Â 54) for eight different angles. Fig. <ref type="figure" target="#fig_3">3</ref> shows these nine curvelet coefficients. The images though are of different size, have been resized to same size only for the sake of neat presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Recognition using curvelet based PCA</head><p>PCA has been successfully applied on wavelet decomposed images which resolves the limitations of using PCA directly <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b37">38]</ref>. Inspired by the success of subband PCA and superiority of curvelets over wavelets, PCA has been applied on curvelet decomposed images for dimensionality reduction; a representational basis is formed. Curvelet transform presents the edge information efficiently and forms a set of distinctive features for the images. In classification stage the test images are subjected to the same operations and they are transformed to the same representational basis. A simple distance based classifier like NN classifier has been employed. Curvelet parameters are set to scale ¼ 3 and angle ¼ 8. PCA has been applied on the selected subbands. This solves the problem of computational load. With PCA, it is always an issue to select the optimum number of principal components. This has been studied by varying the number of eigenvectors and showing the corresponding variation in recognition accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Recognition using curvelet based LDA</head><p>Researchers argue that PCA suffers from poor discriminatory power and prefer LDA over PCA. LDA is said to be able to improve inter-class separability by maximizing within-class similarity as well as between-class variance. We have employed LDA in stead of PCA this time. After decomposing the images using curvelet transform, LDA has been performed on the resulting approximate curveletfaces. A matrix S ¼ S À1 w S b is derived, where S w is the within-class scatter matrix and S b is the between-class scatter matrix <ref type="bibr" target="#b38">[39]</ref>. Then n numbers of eigenvectors corresponding to largest n eigenvalues are selected. During the experiments n has been varied to study the change in recognition accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">PCA+LDA framework</head><p>LDA, though successfully applied for face recognition problems, encounters two major difficulties <ref type="bibr" target="#b39">[40]</ref>. Firstly, the size of the training set is often less than the dimensionality of images. In such cases, the traditional LDA algorithm fails as the within-class scatter matrix becomes singular. Secondly, computational difficulty occurs while working with such high-dimensional image-vectors. In high-dimensional and singular cases, LDA is often performed on a PCA transformed space. In this method each image is subjected to curvelet transform in order to extract the intrinsic features of the facial images. The selected curvelet subimages are then projected on eigenspace using PCA. Now on this PCA transformed space, LDA is performed; where there is no possibility of the within-scatter matrix to be degenerate. Then the resultant PCA+LDA features extracted from curvelet decomposed images form the final feature set for classification. The test images undergo a similar process and are converted to the same PCA+LDA representational basis. NN rule is used for identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">ORL database [41]</head><p>This database contains 10 different images of each of 40 distinct subjects taken between April 1992 and April 1994 at Olivetti Research Laboratory, Cambridge, UK. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open/closed eyes, smiling/not smiling) and facial details (glasses/no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). The images are in '.pgm' format and of dimension 92 Â 112 (width Â height) 8-bit gray levels (Fig. <ref type="figure" target="#fig_5">4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Essex Grimace database [42]</head><p>A sequence of 20 images each for 18 individuals consisting of male and female subjects was taken, using a fixed camera. During the sequence the subjects move their head and make grimaces which get more extreme </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3.">Yale face database [43]</head><p>The Yale face database contains 165 grayscale images in GIF format (320 Â 243) of 15 individuals. There are 11 images per subject, one per different facial expression or configuration: center-light, w/glasses, happy, left-light, w/ no glasses, normal, right-light, sad, sleepy, surprised, and wink (Fig. <ref type="figure" target="#fig_6">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Implementation and experimental results</head><p>To design the experiments, we randomly selected five images per subject for ORL database, eight images per subject for Essex Grimace and six images per subject for Yale face database as prototype and used the rest for testing. A five-fold cross-validation has been performed in each case. The color images of Essex Grimace dataset have been converted to gray-scale images, as color information does not have much contribution in this edge-based method. As a preprocessing step, the images have been reduced to half of their size. ORL images have not been resized. For curvelet based PCA and PCA+LDA framework, resized images are decomposed using curvelet transform at scale ¼ 3 and angle ¼ 8. For extraction of curvelet discriminant features, scale value is changed to 4, in order to avoid within-scatter matrix singular cases as mentioned in Section 4.3. This produces 33 components, including 1 approximate and 32 detailed subbands. We have worked with two subbands only. To further reduce the dimensionality of feature vectors PCA/LDA/PCA+LDA is applied on these approximate components. After the curvelet sub-images are projected to desired featurespace, a simple distance based (L1 Norm) NN classifier is employed to perform the identification task. Number of principal components is varied to display how recognition rate changes with selection of eigenvectors. The recognition rates for these three approaches are shown in Figs. 7, 9 and 11. These results have been achieved by averaging the recognition rates of five different rounds of face recognition. However, the imaging system is not perfect and facial images can be noisy. Hence evaluation of our system under various noise levels. Noise with mean 0 and variance 0-0.2 has been added to the input images and recognition error rate has been graphed against noise level for three subspaces, considering 60 components each time. Results under noisy condition are shown in Figs. 8, 10 and 12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparative study</head><p>In Section 5.2, different results of curvelet based PCA/ LDA/PCA+LDA techniques have been presented. In order to establish the reliability of the proposed methods we have compared them against well-established existing techniques like standard eigenface based methods and wavelet based methods. For wavelet based schemes, a 3-level wavelet decomposition using standard 'Haar' wavelet (as it is often used in wavelet based face recognition methods) was performed. Feature size is 60 for each case; ratio of training and test images remains same as before. We have duplicated some recently developed techniques to compare with curvelet based results: wavelet based kernel Associative Memory (kAM) <ref type="bibr" target="#b40">[44]</ref>, wavelet based weighted   modular PCA <ref type="bibr" target="#b41">[45]</ref> and discriminant waveletfaces using Nearest Feature Line (NFL) classifier <ref type="bibr" target="#b42">[46]</ref>. Recognition rates reported in Table <ref type="table" target="#tab_0">1</ref> are achieved after a five-fold cross-validation.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Discussion</head><p>Various results presented in Sections 5.2 and 5.3 demonstrate that high recognition accuracy can be achieved using curvelet subspaces for face recognition. It seems that for Essex Grimace database (Fig. <ref type="figure" target="#fig_9">9</ref>) recognition rate is almost perfect for all curvelet based methods, indicating the robustness of curvelet based approaches against extreme expression variation. Our techniques have been found to be robust against significant variation in illumination and facial details (present in ORL and Yale) as well. For all the databases, most prominently for Yale database (Fig. <ref type="figure" target="#fig_11">11</ref>), PCA-LDA framework shows significant performance improvement over the PCA based and LDA based schemes. Though, LDA is usually expected to do better than PCA, it is not reflected in our experimental study as we have worked with small databases. LDA is particularly suited for high-dimensional data and can be outperformed by PCA otherwise. When compared to standard techniques like eigenface and waveletface based methods, curvelets show promise. Even simple curvelet features alone can outperform standard eigenface and waveletface. Curveletface and PCA-LDA framework works the best and shows 5.5% and 5.2% gain in accuracy over eigenface and waveletface for ORL. In <ref type="bibr" target="#b32">[33]</ref> an average recognition accuracy of 92% for ORL database is reported. Using training and test sets of same size our curvelet-PCA framework shows an improvement of about 4.6% and PCA-LDA scheme shows 5.7% performance improvement over the proposed method in <ref type="bibr" target="#b32">[33]</ref>. In case of Yale dataset, results of curvelet subspaces and wavelet subspaces are comparable, though curvelet based PCA-LDA scheme is able to achieve almost 8% higher matching rate. In Section 3 we argued that since curvelets are capable of capturing the crucial edge information, they can perform competently as the bases of face recognition. By comparing the results of curvelets with wavelets, its nearest cousin, we can definitely prove our point-curvelets are an efficient or even better alternative to wavelets. However, the trade off is, wavelet features are faster to compute, while curvelets can provide high accuracy. It has been found empirically, that in a standard personal computer with 2 GHz AMD processor and 1 GB RAM computation of wavelet features is almost 1.5 times faster than that of curvelet's using same image size and a decomposition level of 3. Increasing curvelet's scale or angle parameters can improve the accuracy, but has the overhead of extra computation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The main contribution of this paper is the identification of three new feature spaces to address the problem of human face recognition from still images. These feature spaces are based on the PCA/LDA/PCA+LDA spaces of the features extracted by a new multiresolution analysis tool called digital curvelet transform. This is the first time curvelet subspaces are being explored. It is unlikely that the best possible results can be produced in this initial attempt. Rather, our work can be considered as a stepping stone for future works in this direction. Future work is suggested towards developing a complete curvelet based face recognition system and working on newly developed dimensionality reduction methods like 2DPCA, B-2DPCA. Performance of employing different classification methods can also be studied. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/sigpro Signal Processing ARTICLE IN PRESS 0165-1684/$ -see front matter &amp; 2009 Elsevier B.V. All rights reserved. doi:10.1016/j.sigpro.2009.03.007</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>shows the curvelet subbands for a sample face taken from ORL dataset. These curvelet decomposed images are named 'CURVELETFACES'. Digital curvelet transform (scale ¼ 2, angle ¼ 8) is applied on the original image of size 112 Â 92. This produces 1 approximate (75 Â 61) and eight detailed curvelet coefficients (four of ARTICLE IN PRESS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Edge representation by wavelet and curvelet transform [37].</figDesc><graphic coords="4,43.44,56.57,216.00,99.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Curvelet transform of faces: first image in the first row is the original image, second image in the first row is the approximate coefficients and others are detailed coefficients at eight angles; all the images are resized to same dimension for the purpose of illustration only.</figDesc><graphic coords="5,114.01,56.57,312.12,124.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Sample images from Essex Grimace.</figDesc><graphic coords="6,118.00,146.01,312.12,69.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Sample images from ORL.</figDesc><graphic coords="6,118.00,56.57,312.12,57.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Sample images from Yale face.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Curvelet based results for ORL.</figDesc><graphic coords="7,39.46,56.57,216.00,174.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. System performance under noisy condition (ORL).</figDesc><graphic coords="7,39.46,302.23,216.00,164.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Curvelet based results for Essex Grimace.</figDesc><graphic coords="7,39.46,517.99,216.00,157.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. System performance under noisy condition (Essex Grimace).</figDesc><graphic coords="7,284.53,56.57,216.00,158.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Curvelet based results for Yale.</figDesc><graphic coords="7,284.55,255.32,216.00,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. System performance under noisy condition (Yale).</figDesc><graphic coords="7,284.54,454.07,216.00,159.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Comparative study.</figDesc><table><row><cell>Method</cell><cell cols="3">Recognition accuracy (%)</cell></row><row><cell></cell><cell>ORL</cell><cell>Essex</cell><cell>Yale</cell></row><row><cell>Standard eigenface [2]</cell><cell>92.2</cell><cell>69.4</cell><cell>76.0</cell></row><row><cell>Waveletface [3]</cell><cell>92.5</cell><cell>92.5</cell><cell>83.3</cell></row><row><cell>Curveletface</cell><cell>94.5</cell><cell>97.2</cell><cell>82.6</cell></row><row><cell>Waveletface+PCA [3]</cell><cell>94.5</cell><cell>98.5</cell><cell>84.0</cell></row><row><cell>Waveletface+LDA [46]</cell><cell>94.7</cell><cell>100</cell><cell>84.6</cell></row><row><cell cols="2">Waveletface+weighted modular PCA [45] 95.0</cell><cell>98.4</cell><cell>83.6</cell></row><row><cell>Waveletface+LDA+NFL [46]</cell><cell>95.2</cell><cell>100</cell><cell>83.5</cell></row><row><cell>Curveletface+LDA</cell><cell>95.6</cell><cell>100</cell><cell>83.5</cell></row><row><cell>Waveletface+kAM [44]</cell><cell>96.6</cell><cell>100</cell><cell>84.0</cell></row><row><cell>Curveletface+PCA</cell><cell>96.6</cell><cell>100</cell><cell>83.9</cell></row><row><cell>Curveletface+PCA+LDA</cell><cell>97.7</cell><cell>100</cell><cell>92.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>T.Mandal  et al. / Signal Processing 89 (2009) 2345-2353</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Face recognition: a literature survey</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="page" from="399" to="458" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Face recognition using eigenfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Computer Vision and Pattern Recognition</title>
		<meeting>the Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Human face recognition using PCA on wavelet subband</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic Imaging</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="233" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Kernel principal component analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">KPCA Plus LDA: a complete kernel Fisher discriminant framework for feature extraction and recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="230" to="244" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Independent component representation for face recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Lades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE Symposium on Electronic Imaging: Science and Technology</title>
		<meeting>the SPIE Symposium on Electronic Imaging: Science and Technology</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="528" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Eigenfaces vs. Fisherfaces: recognition using class specific linear projection</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hespanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PAMI</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="711" to="720" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Face recognition using kernel principal component analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1558" to="2361" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Binary two-dimensional PCA</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1176" to="1180" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two-dimensional PCA: a new approach to appearance based face representation and recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="137" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Effective feature extraction in high dimensional space</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1652" to="1656" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Human gait recognition with matrix representation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="896" to="903" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">General tensor discriminant analysis and Gabor features for gait recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1700" to="1715" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminant locally linear embedding with high-order tensor data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="342" to="352" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Part B</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">D-LDA: a statistical linear discriminant analysis for image matrix</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="527" to="532" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Face recognition using principal component of Gabor filter responses</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="53" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combination of PCA and wavelet transforms for face recognition on 2.5D images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Image and Vision Computing</title>
		<meeting>the Image and Vision Computing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="343" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wavelet based normalization for face recognition</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CGIM</title>
		<meeting>CGIM</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gabor based region covariance matrices for face recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="989" to="993" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The finite ridgelet transform for image representation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The contourlet transform: an efficient directional multiresolution image representation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2091" to="2106" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Curvelets-A Suprisingly Effective Nonadaptive Representation for Objects with Edges</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Vanderbilt University Press</publisher>
			<pubPlace>Nashville, TN</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The curvelet transform for image denosing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="670" to="684" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<title level="m">Curvelets, multiresolution representation and scaling laws, in: SPIE Wavelet Applications in Signal and Image Processing</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Curvelet transform based embedded lossy image compression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Manikandan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saravanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Bagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSCN</title>
		<meeting>ICSCN</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="274" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The curvelet transform for image fusion</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISPRS Congress</title>
		<meeting>ISPRS Congress<address><addrLine>Istanbul</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gray and color image contrast enhancement by the curvelet transform</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="706" to="717" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deconvolution based on the curvelet transform</title>
		<author>
			<persName><forename type="first">J</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Murtagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Very high quality image restoration by combining wavelets and curvelets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proceedings of SPIE</title>
		<imprint>
			<biblScope unit="volume">4478</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Astronomical image representation by curvelet transform</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomy &amp; Astrophysics</title>
		<imprint>
			<biblScope unit="volume">398</biblScope>
			<biblScope unit="page" from="785" to="800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bangla basic character recognition using digital curvelet transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pattern Recognition Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Face recognition by curvelet based feature extraction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">M J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICIAR</title>
		<meeting>ICIAR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4633</biblScope>
			<biblScope unit="page" from="806" to="817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Face recognition based on curvefaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Natural Computation</title>
		<meeting>Natural Computation</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Face recognition by multi-resolution curvelet transform on bit quantized facial images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computational Intelligence and Multimedia Applications</title>
		<meeting>the Conference on Computational Intelligence and Multimedia Applications</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="209" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fast discrete curvelet transform</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Demanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM Multiscale Modeling and Simulations</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">What is curvelet</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Notices of American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1402" to="1403" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Starck</surname></persName>
		</author>
		<title level="m">Image Processing by the Curvelet Transform</title>
		<imprint>
			<publisher>PPT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A feature based approach to face recognition</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V D</forename><surname>Malsburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="373" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Statistical Pattern Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Why can LDA be performed on PCA transformed space?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="563" to="566" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Face recognition by applying wavelet subband representation and kernel associative memory</title>
		<author>
			<persName><forename type="first">B.-L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sam Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="166" to="177" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Face recognition based on wavelet transform weighted modular PCA</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Congress in Image and Signal Processing</title>
		<meeting>the Congress in Image and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Discriminant waveletfaces and nearest feature classifiers for face recognition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1644" to="1649" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
