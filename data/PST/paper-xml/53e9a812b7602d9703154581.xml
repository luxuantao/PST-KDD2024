<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="laboratory">Real-Time Computing Laboratory</orgName>
								<orgName type="institution">The University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">14C06F309BB76609DCD2CB2C28E3E017</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimal Obstacle Avoidance Based on the</head><p>Hamilton-Jacobi-Bellman Equation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S. Sundar and Z. Shiller</head><p>Abstract-This paper solves the on-line obstacle avoidance problem using the Hamilton-Jacobi-Bellman (HJB) theory. Formulating the shortest path problem as a time optimal control problem, the shortest paths are generated by following the negative gradient of the return function, which is the solution of the HJB equation. To account for multiple obstacles, we avoid obstacles optimally one at a time. This is equivalent to following the pseudoreturn function, which is an approximation of the true return function for the multi-obstacle problem. Paths generated by this method are near-optimal and guaranteed to reach the goal, at which the pseudoreturn function is shown to have a unique minimum. The proposed method is computationally very efficient, and applicable for on-line applications. Examples for circular obstacles demonstrate the advantages of the proposed approach over traditional path planning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>One of the most efficient approaches for on-line obstacle avoidance, to date, is based on the use of potential fields <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Representing the goal with an attractive potential, and the obstacles with repulsive potentials, the potential field method generates paths by following the negative gradient of the potential function. While this approach is computationally efficient and is suitable for on-line feedback control, it suffers from local minima, which may cause the path to terminate at a point other than the goal. This problem was overcome using harmonic potentials <ref type="bibr" target="#b3">[4]</ref> and navigation functions <ref type="bibr" target="#b8">[9]</ref>. These potentials, however, address only the obstacle avoidance problem with no concern for path optimality.</p><p>A method for generating shortest paths by following the direction of steepest descent of a discretized distance function was proposed in <ref type="bibr" target="#b5">[6]</ref>. Its main drawback is that it requires extensive off-line computation of the distance function, which increases rapidly with the number of obstacles and with grid resolution.</p><p>Efficient methods for generating shortest paths for mobile robots have been proposed <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b6">[7]</ref>. They are based on searching for the shortest path over the tangent graph, consisting of the collision-free tangents between all obstacles. Although these methods are more efficient than the traditional search over the entire visibility graph, they compute the entire path before motion is initiated.</p><p>This paper presents a novel approach to the on-line shortest path problem. It was motivated by Hamilton-Jacobi-Bellman (HJB) theory, which establishes a sufficient condition of optimality for optimal control problems <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>. One can compute an optimal trajectory by solving the HJB equation, which is a sufficient condition for global optimality <ref type="bibr" target="#b1">[2]</ref>. The solution of the HJB equation, called the return function, represents the cost-to-go to the goal, or the minimum distance to the goal from any given point. The optimal trajectory is computed by following the direction of steepest descent of the return function. Since the return function is shown to have a unique minimum at the goal, paths generated by following the negative Manuscript received <ref type="bibr">May 10, 1994</ref>; revised November 28, 1995. This paper was recommended for publication by Associate Editor J. Wen and Editor S. E. Salcudean upon evaluation of the reviewers' comments.</p><p>S. gradient of the return function are globally optimal and guaranteed to reach the goal from all initial points. The return function may be too difficult to compute for on-line avoidance of a large number of obstacles. We, therefore, propose to generate near-optimal paths by avoiding obstacles one at a time, or equivalently, by following the negative gradient of an approximation of the return function, called the pseudoreturn function. The path is generated incrementally, permitting robot motion before the entire path to the goal has been computed. The pseudoreturn function is shown to have a unique minimum at the goal, which guarantees convergence to the goal from all initial points. Since it considers only one obstacle at a time, the pseudoreturn function is computed independently of the number of obstacles at all but a finite number of points along the path. In contrast, traditional potential field methods typically consider all obstacles at every point along the path.</p><p>The proposed approach is treated in this paper for a point moving amongst nonintersecting circular obstacles in R 2 . Extensions to higher dimensions are conceptually simple, except that the return function for a single obstacle in higher dimensions might be more difficult to compute. It is important to note that the use of the return function is not limited to shortest path problems, but is rather applicable to general cost functions and systems <ref type="bibr" target="#b1">[2]</ref>. However, the intuition gained in solving the shortest path problem was instrumental in solving the more difficult time-optimal obstacle avoidance problem <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>.</p><p>The approach is demonstrated in several examples for on-line avoidance of 100 circular obstacles, requiring typical computation times of 10-20 ms on a Silicon Graphics 4D-70 (an old and slow machine by today's standards). The paths generated by this method are shown to correlate closely with the optimal paths. They are also shown to be far shorter than the paths generated by the navigation function <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. THE HAMILTON-JACOBI-BELLMAN EQUATION</head><p>We now formulate the shortest path problem as an optimal control problem. First, we note that differentiating a curve x(s) 2 R n with respect to the path arc length s produces the path tangent x t (s) 2 R n : dx(s) ds = x t (s):</p><p>(1)</p><p>Treating distance as time t and the tangent vector x t (s) as the control, we can rewrite (1) as the first-order dynamical system</p><formula xml:id="formula_0">_ x = u; x; u 2 R n (2)</formula><p>The Shortest Path Problem can then be formulated as the following time-optimal control problem:  x(0) = x0; x(t f ) = x f <ref type="bibr" target="#b5">(6)</ref> 1042-296X/97$10.00 Â© 1997 IEEE where the path length t f is free, m is the number of obstacles, and k1 k denotes the Euclidean norm. Note that the control constraint <ref type="bibr" target="#b3">(4)</ref> represents the fact that the norm of the path tangent, _ x(t), is unity.</p><p>We assume that the free space is connected, and that the obstacles are nonintersecting, finite in size and not overlapping with the goal. Further, we assume that the obstacles are circular, which implies that g is strictly convex and differentiable. In the following, we will denote the set of obstacles as O; O = fx : g(x) &lt; 0g:</p><formula xml:id="formula_1">(7)</formula><p>Formulating the Shortest Path Problem as an optimal control problem permits the use of well established optimal control theory <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, particularly, the Hamilton-Jacobi-Bellman equation. Though we do not directly use the HJB equation to solve problem (3), we use the properties of the return function to prove convergence of the proposed approach.</p><p>We now present the formulation of the HJB equation for problems with state constraints, specialized to the case of the Shortest Path Problem (3), selecting the goal, without loss of generality, to be the origin, 0.</p><p>Theorem 1 <ref type="bibr" target="#b7">[8]</ref>:</p><formula xml:id="formula_2">The control u 3 (x) is the solution to problem (3)</formula><p>if it satisfies, on R n 0 f0g 0 O, the HJB equation min u hv x (x); ui = 01 <ref type="bibr" target="#b7">(8)</ref> subject to ( <ref type="formula">4</ref>) and ( <ref type="formula">5</ref>), where v(x) is a continuous scalar function,</p><formula xml:id="formula_3">which is piecewise C 1 on R n 0 f0g 0 O, satisfying v(0) = 0<label>(9)</label></formula><p>v(x) &gt; 0;</p><p>x 6 = 0:</p><p>The subscript x represents partial derivatives with respect to x. The scalar function v(x) is the return function <ref type="bibr" target="#b1">[2]</ref> (also called the value function) representing the minimum distance-to-go to the origin.</p><p>To show that the optimal path is generated by following the negative gradient of the return function, we minimize (8) subject to the constraint (4) to yield the optimal control u 3 (x):</p><formula xml:id="formula_5">u 3 (x) = 0 v x (x) kv x (x)k :<label>(11)</label></formula><p>Substituting u 3 (x) back in (8) yields</p><formula xml:id="formula_6">kv x (x)k = 1 (12)</formula><p>Substituting ( <ref type="formula" target="#formula_5">11</ref>) and (12) in the system dynamics (2) results in</p><formula xml:id="formula_7">_ x = 0v x (x)<label>(13)</label></formula><p>Obstacle free paths are, thus, generated by following 0v x (x), the negative gradient of the return function. This is similar to potential field methods, where paths are generated by following the negative gradient of a potential function <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>. The return function, however, generates paths that are globally optimal since v(x) has a unique minimum at the goal (the origin), as stated in the following Corollary.</p><p>Corollary 1: The function v(x), satisfying ( <ref type="formula">8</ref>), has a unique minimum at the goal.</p><p>Proof: See the Appendix. It is generally difficult to find an analytical solution to (8), even for simple cases. For the shortest path problem, we compute it geometrically, taking advantage of the known structure of the shortest path. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Return Function</head><p>Here, we derive the return function for one circular obstacle in R 2 . The extension to spheres in R n is conceptually simple <ref type="bibr" target="#b9">[10]</ref> and will not be discussed.</p><p>Consider the circular obstacle, denoted OB, with radius r and center at c 2 R 2 , as shown in Fig. <ref type="figure" target="#fig_2">1</ref>. We define the obstacle shadow as the sector S of the cone with apex at the origin, shown grey in Fig. <ref type="figure" target="#fig_2">1</ref>: (1) ; 6 T (2) ]; kx 0 ck 2 r 2 ; kx 0 x f k kc 0 x f kg</p><formula xml:id="formula_8">S = fx : 6 x 2 [ 6 T</formula><formula xml:id="formula_9">(14)</formula><p>where 6 x is the angle made by x with the x-axis, and It is easy to show that if the initial point lies outside the obstacle shadow, then the optimal path is simply a straight line to the goal. Otherwise, the shortest path consists of a straight line, a constrained arc that follows the obstacle boundary, then a straight line to the goal.</p><formula xml:id="formula_10">T (i) 2 R 2 , i = 1; 2,</formula><p>The return function v(x; c; r) for any point x 2 R 2 , equals the length of the optimal path, and is of the form: where the angles i(x) are shown in Fig. <ref type="figure" target="#fig_2">1</ref>.</p><formula xml:id="formula_11">v(x; c; r) = w c (x; c; r) if x 2 S kx 0 x f k; if x 2 S (</formula><p>A typical contour plot of the return function (15) for a circular obstacle is shown in Fig. <ref type="figure" target="#fig_5">2</ref>. Note that the effect of the obstacle on the return function is local as it creates a "tail" in the obstacle shadow, which diminishes with the distance from the origin.</p><p>The negative gradient of the return function, 0v x (x), which is used to generate the optimal path, is not defined along singular surfaces <ref type="bibr" target="#b4">[5]</ref>. In the case of the return function for one obstacle (15), a section of the straight line that passes through 0 and c is a singular curve, as shown in Fig. <ref type="figure" target="#fig_5">2</ref>. The gradient at singular points can be computed using small perturbations perpendicular to the singular curve. Perturbation in either direction would produce one of the two shortest (equal in length) paths.</p><p>Though it is relatively simple to compute the return function for one obstacle, it might be computationally difficult for a large number of obstacles, even for a simple case such as circles. For on-line applications, we propose an efficient method that is based on avoiding obstacles one at a time, or equivalently, by following the gradient of the pseudoreturn function, as discussed next.</p><p>Note that in computing the return function for one obstacle, we in fact solve the shortest path problem for that obstacle, i.e., construct the optimal path to the goal. We use the initial slope of the path, which, by (13), is the gradient of the return function, to move incrementally toward the exit point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PSEUDORETURN FUNCTION</head><p>To solve the multiple obstacle avoidance problem, we observe that the effect of an obstacle on the return function is local, as can be seen in Fig. <ref type="figure" target="#fig_5">2</ref> for a circular obstacle. This suggests that a given obstacle needs to be considered only at points in the shadow that are sufficiently close to that obstacle. We, therefore, propose to treat multiple obstacles by avoiding the obstacles optimally, one at a time. The avoidance procedure is simple: follow the gradient of the constrained return function of one (nearest) obstacle, denoted OB k , until leaving its obstacle shadow at one of the two tangency points T (j) k , j = 1; 2. If at this point, the path enters the shadow of another obstacle, then, repeat this procedure using the constrained return function of the new obstacle. Otherwise, go to the goal, using the unconstrained return function (15). Though computationally simple, this strategy is guaranteed to generate paths terminating at the origin for all initial conditions, as stated later in Theorem 2.</p><p>This procedure requires the selection of the nearest obstacle to be avoided at a given point. One choice is the geometrically nearest obstacle, selected from the set J, defined as J = j : kx 0 cjk = min fi:x2S g fkx 0 cikg :</p><formula xml:id="formula_12">(17)</formula><p>Another choice of the nearest obstacle is the maximum cost obstacle, i.e., the one that maximizes the value of the return function (15) at the current point, x. The set J is then defined as: J = fj : v j (x; c j ; r j ) &gt; kxk; v j (x; c j ; r j ) v i (x; c i ; r i ) 8i 6 = j; i = 1; 111; mg</p><formula xml:id="formula_13">(18)</formula><p>where vj (x; cj; rj) represents the return function for the jth obstacle OB j .</p><p>Note that to compute J, we need to consider only those obstacles with shadows containing x. If x does not lie in the shadow of any obstacle, then the set J is empty, and the optimal solution is the straight line to the goal.</p><p>The geometrically nearest criterion (17) is easier to compute than the maximum cost (18). However, (17) generally produces longer paths for concave obstacles <ref type="bibr" target="#b9">[10]</ref>.</p><p>The path is thus generated by following the negative gradient of what we call, the pseudoreturn function !(x; k) defined, using (15), as</p><formula xml:id="formula_14">!(x; k) = d (k) 1 + d (k) 2 + r k min [ (k) 1 ; (k) 2 ] if k 6 = 0 kx 0 x f k; if k = 0 (<label>19</label></formula><formula xml:id="formula_15">)</formula><p>where</p><formula xml:id="formula_16">d (k) 1 = kx 0 c k k 2 0 r 2 k ; d (k) 2 = kc k 0 x f k 2 0 r k 2</formula><p>and the angles This procedure is summarized in the following algorithm. Algorithm 1:</p><p>Step 1. Determine the nearest obstacle, OB k , using (17). If k = 0, go to Step 3.</p><p>Step 2. Follow the negative gradient of the pseudoreturn function (19), 0! x (x; k) until reaching one of the tangency points T (j) k , j = 1; 2. Go to Step 1.</p><p>Step 3. Follow the negative gradient of the unconstrained return function (15), kx 0 x f k, until reaching the goal. STOP.</p><p>We call a path generated by Algorithm 1 a simple path since it ignores the special cases discussed later. The simple paths are guaranteed to reach the goal, selected without loss of generality as the origin, as stated in the following theorem.</p><p>Theorem 2: The obstacle-free path generated by Algorithm 1 is guaranteed to terminate at the goal for all initial conditions x 0 2 R 2 0 O.</p><p>Proof: The theorem is proven in the Appendix by showing that the Euclidean norm of the path x 3 (t) generated by Algorithm 1 is a monotonically decreasing function of time.</p><p>The paths generated by the pseudoreturn function have the same structure as the optimal path in that they consist of straight lines, connected by constrained arcs that coincide with the obstacle boundaries. Consequently, the near-optimal paths may pass between closely spaced obstacles, unlike the paths generated by most potential fields. However, the near-optimal paths may have slope discontinuities (corners) wherever the path switches from one obstacle shadow to another, since then it switches to another return function, which might have a different value and gradient at that point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SPECIAL CASES</head><p>Algorithm 1 ignores special cases in which the simple path may intersect other obstacles while avoiding the nearest obstacle. We distinguish between two such cases, as shown in Fig. <ref type="figure" target="#fig_7">3</ref>: i) the path intersects the obstacle, which has just been avoided and ii) the path intersects another obstacle in the shadow of the nearest obstacle. Both cases can be treated by defining the tangency point to the next obstacle as an intermediate goal, as shown schematically in Fig. <ref type="figure" target="#fig_7">3</ref>. In case i), the path exits the shadow of OB1 at point P (1) 1 , switching to the return function of the nearest obstacle, OB 2 . However, the straight line path that avoids OB 2 from P (1) 1 , i.e., the simple path, intersects OB1 . We, therefore, define P (2) 1 as an intermediate goal.</p><p>In that case, the current point (P Case ii) is treated similarly, as shown in Fig. <ref type="figure" target="#fig_7">3</ref>. Here, the current point lies in the shadow of OB1 but not of OB2. However, the path that avoids OB1 intersects OB2. Similarly to the previous case, we define P (2) 1 as the intermediate goal, and use Algorithm 1 to avoid OB 2 . After P (2) 1 has been reached, we use Algorithm 1 to the original goal.</p><p>More generally, if any segment, fpi; pj g; j &gt; i (p0 = x0), of the simple path generated by Algorithm 1 intersects an obstacle, then Algorithm 1 is used to compute a simple path from pi to pj . If this path intersects any other obstacle, then this procedure is repeated until the simple path to the last defined intermediate goal is collision free.</p><p>This proposed approach is guaranteed to converge to the goal since by Theorem 2, the computation of the simple path is convergent, and by the assumption of a finite number of non intersecting circular obstacles, the number of intermediate goals is finite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. COMPUTATIONAL EFFICIENCY</head><p>This method is most efficient for on-line applications, when compared to potential field methods. First, we do not require any precomputation, unlike numerical potential field approaches <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, which precompute the potential function, and global potential methods <ref type="bibr" target="#b8">[9]</ref>, which preselect the parameters of the potential field so as to avoid local minima. Second, the computational effort at a typical point along the path is independent of the number of obstacles. The only points at which all obstacles are considered are the tangency At those points, the nearest obstacle to the current intermediate goal is determined, and the shortest path that avoids that obstacle to that intermediate goal is computed. Determining the nearest obstacle requires computation of the tangents from the goal to (m 0 p) obstacles, where p is the number of obstacles avoided so far, which is O(m 0 p), and determining the nearest obstacle, which is also O(m0p). Computing the shortest path for a circular obstacle requires computing two tangents from the current point to the obstacle, which is done once and is therefore O (1). The avoidance of one obstacle (Step 1) is therefore O(m 0 p).</p><p>Considering intermediate points, the typical computational effort at a given tangency point is O[q(m 0 p)], where q is the number of intermediate goals. The maximum number of intermediate points is m 0 1 since for circular obstacles, an obstacle is avoided only once <ref type="bibr" target="#b9">[10]</ref>. The worst case computational complexity is, therefore, O(m 2 ). The worst case can occur at the initial point (p = 0) if we need to define (m 0 1) intermediate goals (to all but one obstacle) before a free segment can be found. This requires that we select the obstacles in the worst sequence possible, which is highly improbable. The average complexity at a typical step is, therefore, much better than O(m 2 ). In comparison, existing methods that compute paths similar to ours require the computation of the entire path, done in m 2 log m time, before motion can begin <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXAMPLES</head><p>Algorithm 1 was implemented in C on a Silicon Graphics IRIS 4D-70 machine. It generates and displays the path incrementally from any given point. Although this is a slow machine by today's standards, the computation time, even for a large (100) number of circular obstacles, is instantaneous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Example 1</head><p>This example compares our approach to the optimal solution and to the path generated by the navigation function <ref type="bibr" target="#b8">[9]</ref> for the four circular obstacles shown in Fig. <ref type="figure" target="#fig_9">4</ref>. The near-optimal path generated by the pseudoreturn function, and shown in Fig. <ref type="figure" target="#fig_9">4</ref>, overlaps the optimal path generated by the exact return function for this case. The contour plot of the pseudoreturn function, shown in Fig. <ref type="figure" target="#fig_1">5</ref>, is close to that of the exact return function (not shown). This is mainly due to the local effect of the obstacles on the exact return function, which also explains the optimality of the path generated by the pseudoreturn function.</p><p>Also shown in Fig. <ref type="figure" target="#fig_9">4</ref> is the path computed by the navigation function <ref type="bibr" target="#b8">[9]</ref>:  The path generated by the navigation function is much longer than the near-optimal path as it passes around obstacles 1, 2, and 3. The paths generated by other potential fields are quite similar to this path as they tend to avoid tight spaces between obstacles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Example 2</head><p>This example demonstrates our approach for a large number (100) of circular obstacles. Fig. <ref type="figure" target="#fig_13">6</ref> shows four near-optimal paths computed on-line using Algorithm 1. The computation times for each path varied around 10-20 ms. Note that the paths are very close to the straight lines from each initial point, and are therefore nearoptimal. They also pass between closely spaced obstacles, which would be infeasible for typical potential functions. Further, increasing the number of obstacles had very little effect on the computation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>An on-line method for generating near-shortest paths amongst circular obstacles has been presented. It is similar to potential field methods, except that the path is generated by following the negative gradient of the return function, which satisfies the HJB equation <ref type="bibr" target="#b7">(8)</ref>. Unlike typical potential functions, the return function has a unique global minimum, and is thus guaranteed to yield paths terminating at the goal.</p><p>To avoid the computationally expensive return function for multiple obstacles, we propose to avoid obstacles one at a time, following the negative gradient of the pseudoreturn function. The pseudoreturn function is shown to have a unique minimum at the goal. The paths generated by this method are therefore guaranteed to reach the goal from all initial points in the connected free space. These paths are also near-optimal since they consist of edges of the tangent graph (a reduced visibility graph).</p><p>The proposed method is computationally very efficient since its computational complexity is independent of the number of obstacles at all but a finite number of points along the path. The on-line nature of this method is due to its incremental generation of the path, which takes into account the current position of the robot and obstacles.</p><p>Although demonstrated for a point moving amongst planar circular obstacles, this approach is extendible to higher dimensions, at the cost of a higher computational expense for the return function.</p><p>The efficiency of this approach was demonstrated in several examples for a large number (100) of circular obstacles, requiring negligible computation time. These paths compare favorably to the optimal path and are shown to be far shorter than paths generated by the navigation function. This approach, therefore, represents significant improvements over traditional on-line path planning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Proof of Corollary 1: Substituting vx(x) = 0, x 2 R n 0f0g0O, in (8) makes the left-hand side of (8) 0, which contradicts the right-hand side. Now, in an obstacle free open neighborhood about the origin, the distance function v(x) = kxk (25) uniquely satisfies Theorem 1. Since the gradient of (25) vanishes at the origin for n &gt; 1, we can conclude that the return function satisfying Theorem 1 has a unique minimum at the origin.</p><p>To prove Theorem 2, we need the following Lemma: Lemma 1: The gradient, vx(x), of the return function v(x) for a single obstacle, defined in (15), satisfies hv x (x); xi &gt; 0; x 2 R 2 0 f0g 0 O:</p><formula xml:id="formula_17">(26)</formula><p>Proof of Lemma 1: The lemma is proved in <ref type="bibr" target="#b9">[10]</ref> by using the structure of the optimal path for a circular obstacle (Fig. <ref type="figure" target="#fig_2">1</ref>) and noting that the gradient of the return function is the slope of the optimal path.</p><p>We are now ready to prove Theorem 2.</p><p>Proof of Theorem 2: Recall that the path, x 3 (t), is generated by following the negative gradient of the pseudoreturn function </p><formula xml:id="formula_18">_ x 3 (t) = 0!x(x</formula><p>Equations ( <ref type="formula">27</ref>) and (28) imply</p><formula xml:id="formula_20">d dt kx 3 (t)k 2 = 2h _ x 3 (t); x 3 (t)i = h0! x (x 3 (t); i); x 3 (t)i &lt; 0:<label>(29)</label></formula><p>Hence the path norm kx 3 (t)k is monotonically decreasing. Hence kx 3 (t)k ! 0, i.e., the path is guaranteed to terminate at the goal 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scheduling Messages on Controller Area Network for Real-Time CIM Applications</head><p>Khawar M. Zuberi and Kang G. Shin</p><p>Abstract-Scheduling messages on the controller area network (CAN) corresponds to assigning identifiers (ID's) to messages according to their priorities. In this paper we present the mixed traffic scheduler (MTS), which provides higher schedulability than fixed-priority schemes like deadline-monotonic (DM) while incurring less overhead than dynamic earliest-deadline (ED) scheduling. Through simulations, we compare the performance of MTS with that of DM and ED* (an imaginary scheduler which works like ED, except it incurs less overhead). Our simulations show that MTS performs much better than DM and at the same level as ED*, except under high loads and tight deadlines, when ED* is superior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Local area networks (LAN's) are becoming increasingly popular in industrial automation and other real-time control applications <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. LAN's allow field devices like sensors, actuators, and controllers to be interconnected at low cost-using less wiring and requiring less maintenance than point-to-point interconnections <ref type="bibr" target="#b1">[2]</ref>. Several architectures have been proposed for such LAN's, including Controller Area Network (CAN) <ref type="bibr" target="#b2">[3]</ref>, SP-50 FieldBus <ref type="bibr" target="#b3">[4]</ref>, MAP <ref type="bibr" target="#b4">[5]</ref>, TTP <ref type="bibr" target="#b5">[6]</ref>, etc. Of these networks, CAN has gained wide-spread acceptance in the industry <ref type="bibr" target="#b6">[7]</ref>-first in the automotive industry and then for industrial automation and computer-integrated manufacturing (CIM) as well. CAN is popular because of its low cost (a CAN interface chip costs about $5) and its useful features like reliability in noisy environments and priority-based bus arbitration.</p><p>Control networks must carry both periodic and sporadic real-time messages, as well as nonreal-time messages. All these messages must be properly scheduled on the network so that real-time messages meet their deadlines while co-existing with nonreal-time messages (we limit the scope of this paper to scheduling messages whose characteristics like deadline and period are known a priori). Previous work regarding scheduling such messages on CAN includes <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, but they focused on fixed-priority scheduling. Shin <ref type="bibr" target="#b9">[10]</ref> considered ED scheduling, but did not consider its high overhead which makes earliest-deadline (ED) impractical for CAN. In this paper, we present a dynamic scheduling scheme for CAN called the mixed traffic scheduler (MTS) which increases schedulable utilization and performs better than fixed-priority schemes while incurring less overhead than ED.</p><p>The next section describes the CAN protocol in detail. Section III describes the various types of messages in our target application workloads. Section IV gives the MTS algorithm and its schedulability conditions. Section V gives simulation results and the paper concludes with Section VI.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 5 )</head><label>5</label><figDesc>and the boundary conditions:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. One circular obstacle.</figDesc><graphic coords="2,341.76,59.60,179.67,139.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>are the points of contact on OB, of the two tangents from the goal. The region S is called the obstacle shadow because it coincides with the shadow of OB created by a point light source at x f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>15) where c and r are the center and radius of the circle, respectively, and the set S is the complement of S in R 2 0O. The function kx0x f k is called the unconstrained return function since it is the return function for problem (3) without obstacles. The function w c (x; c; r), called the constrained return function, is the return function for points inside the obstacle shadow S and is dependent on the obstacle parameters c and r: w c (x; c; r) = min i=1; 2 kx 0 ck 2 0 r 2 +r i (x) + kc 0 x f k 2 0 r 2 (16)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Contour plot for one obstacle.</figDesc><graphic coords="3,62.16,59.58,212.88,176.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>) are shown in Fig.1, k is the index of the nearest obstacle, selected from the set J (17) or (18), and k = 0 if J is empty. We call !(x; k) the pseudoreturn function since it does not satisfy the properties of a return function. In particular, it is discontinuous along the boundaries of the obstacle shadows, where k changes values and the return function "jumps" from one obstacle to another.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Special cases.</figDesc><graphic coords="4,79.68,59.58,177.84,255.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( 1 ) 1 ) 1 ) 2 ,</head><label>1112</label><figDesc>lies in the shadow of OB1 to the intermediate goal (P (2) 1 ). We then use Algorithm 1 to reach P (2) 1 by avoiding OB 1 . The path follows the boundary of OB 1 until point P (at which the algorithm switches to the unconstrained return function to P (2) 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Optimal and near-optimal avoidance of four obstacles. points T (j) i , where the path switches from one obstacle shadow to another (Step 1 of Algorithm 1).At those points, the nearest obstacle to the current intermediate goal is determined, and the shortest path that avoids that obstacle to that intermediate goal is computed. Determining the nearest obstacle</figDesc><graphic coords="4,311.82,59.60,239.56,232.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Contour plot for the pseudoreturn function.</figDesc><graphic coords="5,66.48,59.58,204.24,215.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Near-shortest paths for 100 circular obstacles.</figDesc><graphic coords="5,313.62,59.58,235.96,226.80" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Manuscript received January 9, 1995; revised February 2, 1996. This work was supported in part by the National Science Foundation by Grant MIP-9203895 and Grant DDM-9313222, and by the Office of Naval Research by Grant N00014-94-1-0229. This paper was recommended for publication by Associate Editor P. B. Luh and Editor A. Desrochers upon evaluation of the reviewers' comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Numerical potential field techniques for robot path planning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barraquand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Latombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="224" to="241" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Optimization-Theory and Applications: Problems with Ordinary Differential Equations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cesari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Path planning for a mobile robot</title>
		<author>
			<persName><forename type="first">C</forename><surname>Alexopolous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Griffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="318" to="322" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Path planning using Laplace&apos;s equation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Connoly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Automat</title>
		<meeting>IEEE Int. Conf. Robot. Automat<address><addrLine>Cincinnati, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2102" to="2106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Dynamic Programming and the Calculus of Variations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dreyfus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
			<publisher>Academic</publisher>
			<pubPlace>New York, London, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Collision-free trajectory planning using distance transforms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Jarvis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Inst. Eng., Mech. Eng., Australia</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="187" to="191" />
			<date type="published" when="1985-09">Sept. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Path planning using a tangent graph for mobile robots among polygonal and curved obstacles</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="376" to="382" />
			<date type="published" when="1992-08">Aug. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bellman equations for optimal processes with constraints on the phase coordinates</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Moskalenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autom. Remote Cont., A Translation Avtomatika i Telemekhanika</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1853" to="1864" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exact robot navigation using artificial potential functions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rimon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koditschek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="501" to="518" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Time optimal obstacle avoidance for robotic manipulators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sundar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Mech. Eng., Univ. Calif</title>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Time-optimal obstacle avoidance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Automat</title>
		<meeting>IEEE Int. Conf. Robot. Automat<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="3075" to="3080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
