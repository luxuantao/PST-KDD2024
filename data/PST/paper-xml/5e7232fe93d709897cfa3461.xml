<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A New Method of Fuzzy Support Vector Machine Algorithm for Intrusion Detection</title>
				<funder ref="#_GqtkGmD">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_fwSBNtb">
					<orgName type="full">National High Technology Research and Development Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-02-05">5 February 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer department</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Linlin</forename><surname>Ci</surname></persName>
							<email>cilinlin_bit@126.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer department</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liping</forename><surname>Liu</surname></persName>
							<email>liuliping_bit@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer department</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A New Method of Fuzzy Support Vector Machine Algorithm for Intrusion Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-02-05">5 February 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3390/app10031065</idno>
					<note type="submission">Received: 27 December 2019; Accepted: 29 January 2020;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>support vector machine</term>
					<term>SVDD</term>
					<term>system call sequence</term>
					<term>intrusion detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Since SVM is sensitive to noises and outliers of system call sequence data. A new fuzzy support vector machine algorithm based on SVDD is presented in this paper. In our algorithm, the noises and outliers are identified by a hypersphere with minimum volume while containing the maximum of the samples. The definition of fuzzy membership is considered by not only the relation between a sample and hyperplane, but also relation between samples. For each sample inside the hypersphere, the fuzzy membership function is a linear function of the distance between the sample and the hyperplane. The greater the distance, the greater the weight coefficient. For each sample outside the hypersphere, the membership function is an exponential function of the distance between the sample and the hyperplane. The greater the distance, the smaller the weight coefficient. Compared with the traditional fuzzy membership definition based on the relation between a sample and its cluster center, our method effectively distinguishes the noises or outlies from support vectors and assigns them appropriate weight coefficients even though they are distributed on the boundary between the positive and the negative classes. The experiments show that the fuzzy support vector proposed in this paper is more robust than the support vector machine and fuzzy support vector machines based on the distance of a sample and its cluster center.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Intrusion detection systems (IDS) are essential to information security. IDS can be divided into signature-based IDS and anomaly-based IDS <ref type="bibr" target="#b0">[1]</ref>. Both are based on pattern detection. Signaturebased IDS matches the system behavior against the known attack and lacks the ability to detect zeroday attack. Anomaly-based methods construct normal behavior based on prior knowledge and judge the deviation between the current behavior and the normal behavior <ref type="bibr" target="#b1">[2]</ref>. The advantage of the anomaly-based method is the ability to detect new attacks.</p><p>A system call requested by an application is a function built into the operation system kernel. A system call sequence is a detailed account of the system calls occurring on a host. The behavior of an application can be described in terms of the sequence of system calls. It is easy to get the system call sequence in real-time. Therefore, the data of a system call sequence is often used as audit data for analysis and classification of malicious processes.</p><p>The current methods of anomaly detection are based on traditional statistics, which is the study of the asymptotic theory. That is, the limit property can be reached when the number of samples approaches infinity. In intrusion detection systems, the observation samples are limited or even a small number. This cannot satisfy the preconditions of a detection method based on traditional statistics. As a result, the false alarm rate and missing rate are high. The algorithms of a system call in anomaly-based IDS need a lot of data. This is because these algorithms are based on traditional statistics, which is the study of the asymptotic theory. That is, the limit property can be reached when the number of samples approaches infinity. Unfortunately, the anomaly data in the intrusion detection system is very limited. Therefore, we classify system calls using an SVM-based algorithm, which is based on statistical learning theory. Statistical learning theory makes the SVM-based classifier only depend on a small part of the support vectors (SVs). This is very helpful for the training of classifiers with insufficient data. SVM-based algorithm, like the other algorithm, also has an inherent shortcoming, that is, it is sensitive to noises and outliers. In order to distinguish noises near the boundary from SV, fuzzy support vector machine is proposed to solve the problem. Because there are no uniform guiding principles, the existing FSVM-based algorithms are inconsistent with reality when classifying system call sequences. Therefore, the purpose of our paper is to construct a fuzzy support vector machine that is suitable for classifying system call sequences.</p><p>Support vector machine <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>, as a machine learning method based on statistical learning theory, derives from the idea of the dual form to solve the large dimensional problems, makes the classifier only depend on a small part of the support vectors, implements the structural risk minimization principle in statistical learning theory, and solves the problems of nonlinearity and local minima. A system call sequence can be converted into a vector in a high dimensional space by the frequency of short system call sequences of a certain length. Therefore, abnormal detection can be carried out based on SVM.</p><p>There are always noises and outliers in solving practical engineering applications due to statistical methods, human error and other factors. These noises and outliers cannot satisfy the precondition that all samples are independent and identically distributed. The noises and outliers near the boundary play the same role as SVs in constructing the optimal classification hyperplane. To solve this problem, researchers proposed fuzzy support vector machine (FSVM), that is, different weights are assigned to different samples, so that different samples contribute differently to the optimal classification hyperplane. In order to eliminate the influence of noises and outliers, the small weights are given to these samples. The design of the membership function is the key of the whole fuzzy algorithm and is no uniform criterion to be followed. At present, there are many ways to construct a membership function. Most of these methods are based on the distance between a sample and its cluster center. The closer the sample is to the cluster center, the greater the weight coefficient is. The noises and SVs distributed on the boundary are far from the cluster center. They are all given less weight coefficients. This is quite different from the objective situation. SVs should be given greater weight coefficients.</p><p>To solve the above problem, our paper proposed a new fuzzy support machine method based on support vector data description (SVDD). The contributions of our work are as follows:</p><p>? Our paper proposed a new fuzzy membership function which can effectively distinguish the noises and SVs distributed on the boundary based on SVDD. SVs are given larger weight coefficients while noises are given smaller coefficients. In this way, our method avoids imperfection of FSVM based on the distance between a sample and its cluster center. Such a fuzzy membership function structure method is more in line with reality. ? The method proposed in our paper uses the hyperplane, which passes through the cluster center and takes the line of two cluster centers as the normal vector to replace each cluster center. This is in accordance with the geometric principle of SVM. In other words, two hyperplanes with maximum space are used to separate the training samples. Therefore, using the hyperplane in class to replace the cluster center can better approximate the actual situation. ? Our method is more efficient, especially for anomaly-based IDS with high real-time requirements.</p><p>In our method, the noises and outliers are identified by a sphere with minimum volume while containing the maximum of the samples. Some uncontributed vectors are eliminated by preextracting the boundary vector set containing the support vectors. This reduces the number of training samples and speeds up the training. It is important that IDS speed up detection as much as possible by reducing computation and storage.</p><p>The remainder of the paper is organized as follows. In Section 2, the previous work based on system calls are reviewed, while Section 3 describes the proposed method. In Section 4, experiments and evaluations are presented. Section 5 gives some conclusions. Section 6 gives acknowledgment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Previous Work</head><p>Anomaly detection can be studied by system call sequence from different angles. These methods focus primarily on data processing, data representation and other feature selections derived from system call sequences. In this section, some methods of anomaly-based IDSs based on system call will be discussed.</p><p>As the original data of system call traces is large, preprocessing and feature selection methods contribute to obtaining typical features and avoiding the influence of irrelevant and redundant features on detection rate and processing cost <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. Methods commonly used for natural language processing are used to preprocess system call traces. The n-gram method is used to construct the system call databases of normal behavior by a sliding window with a single length or multiple lengths <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. Aron Laszka et al. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> investigated and claimed that the optimal n-gram is 6-gram in UNM dataset and 7-gram in ADFA-LD dataset. Suaad et al. <ref type="bibr" target="#b12">[13]</ref> continued to prove that 6-gram and 10gram have the advantage of time efficiency and detection rate respectively in a dataset collected from a virtual machine. Feature selection methods reduce redundancy and irrelevance by selecting interesting features. These methods facilitate the reduction of computation time and storage requirements, understanding data out noise and avoiding the over-fitting problem, increasing the accuracy rate. Feature selection can be divided into th wrapper approach <ref type="bibr" target="#b13">[14]</ref>, filter approach <ref type="bibr" target="#b14">[15]</ref> and hybrid approach <ref type="bibr" target="#b15">[16]</ref> according to the correlation of algorithms. This depends on the feedback represented by the accuracy rate; the wrapper approach implements the selection of best features. The filter approach evaluates the attributes of a learning algorithm by using the statistical learning data. The wrapper approach gets better classification performance than filter approach at the expense of expensive computation. The filter approach is better suited to handle high dimensional data than the wrapper approach. A hybrid approach was produced by combining the advantages and disadvantages of the filter approach and wrapper approach.</p><p>The enumerating sequences-based <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref> methods are simple and efficient to implement by removing system call parameters. During database construction stage, normal behaviors are represented by short system sequences. During the monitoring stage, the short sequences of testing data are obtained and tested. The enumerating sequences-based methods need constructing, updating and maintainance of the normal database for each individual program <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. The Murmurhash <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> is utilized with the Bloom-filter-based method to ensure that it has the advantage over STIDE in terms of memory occupation, searching speed and privacy preservation. Although the Bloom-filter-based method shows simplicity and effectiveness, it has the limitation of false positives.</p><p>The system call sequence can be represented as a vector. Qing et al. extracted a minimized set of rules to define a normal behavior and detected anomaly behavior based on a rough set <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>. Pandit predefined workflow and added a knowledge base of workflow <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref>. A search engine is then applied to discover the hidden knowledge <ref type="bibr" target="#b29">[30]</ref>. The drawback of a rule-based approach <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref>, since these rules are derived from small-scale datasets, is that the rules are constantly updated. Matej et al. <ref type="bibr" target="#b33">[34]</ref> presented a new tool data collection system for Windows PC. Different from previously distributed data collection systems, this system uses less resources based on host and client structures. The system shows good performance in the real test environment. However, it is just a preliminary stage and is going to be a lot of work. IDS plays an important role in the network. Qiuhua et al. <ref type="bibr" target="#b34">[35]</ref> proved a classification algorithm based on data clustering and data reduction by mini batch K-Means algorithm in the training stage and sorting cluster in the detection stage. Experiments indicated that the computational complexity was reduced significantly and the accuracy maintained high. However, the implementation of this classification method is complex.</p><p>In recent years, neural networks have made remarkable achievements in computer vision <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref> and natural language processing <ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref>. Researchers have also tried to use neural networks to process system call sequences <ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref>. AnRAD <ref type="bibr" target="#b46">[47]</ref> performs probabilistic inference by selfstructuring confabulation network. Their network continuously refines their knowledge base and is capable of fast incremental learning. Sheraz et al. <ref type="bibr" target="#b47">[48]</ref> implemented intrusion detection in a real environment based on a convolutional neural network. In order to accelerate the training process, multiple GPUs must be deployed on a physical host. The challenge of solutions based on a neural network is pricey and space consuming due to the increasing amount of data.</p><p>Ambusaidi et al. <ref type="bibr" target="#b48">[49]</ref> proved that their method contributes more critical features for the least square support vector machine to achieve a better detection rate and lower computation cost. Gideon <ref type="bibr" target="#b49">[50]</ref> applied a semantic structure to system calls. This approach facilitates the representation of software behavior and obtains excellent results in UNM dataset and KD98 dataset. Wael et al. <ref type="bibr" target="#b50">[51]</ref> presented a heterogeneous detector which consisted of sequence time-delay embedding, hidden Markov model <ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref> and a one-class support machine. In addition to satisfactory results, the heterogeneous detector also exhibits the reliability. Michael et al. <ref type="bibr" target="#b54">[55]</ref> detected features of the system in the hypervisor. The experiments demonstrated that their detection accuracy achieves 90% whilst the method has the detecting ability of DoS attacks. The algorithms based on frequency can be realized at a lower computation cost by reducing the dimension of the frequency vectors <ref type="bibr" target="#b55">[56]</ref>. SVM is sensitive to noises and outliers <ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref>. FSVM is based on fuzzy theory to reduce the influence of noises or outliers on the classification hyperplane <ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref><ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b65">[66]</ref>. Lin et al. <ref type="bibr" target="#b66">[67]</ref> proposed a method based on the relation between samples and their cluster center. Zhang et al. <ref type="bibr" target="#b67">[68]</ref> proposed a new FSVM method after considering the imperfection of a distance-based algorithm. However, the above methods also reduce the effect of SVs on the hyperplane when reducing the influence of noises or outliers on the hyperplane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology based on SVDD</head><p>Due to human error, random error and other factors in the data collection process, the sample set contains a small number of noise samples. Noise samples have a great influence on the construction of the optimal classification hyperplane, which makes it deviate from the optimal position, reduces the normalization ability of the classifier, and affects the classification effect. FSVM assigns different weight coefficients to different samples. The purpose is to make each sample have a different effect on the optimal classification hyperplane.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the overview of our algorithm. The algorithm consists of three steps. The first step is to obtain the positive and negative minimum hyperspheres based on the training data and SVDD. By finding the minimum volume hypersphere containing a sample set, the target samples are included in the hypersphere as much as possible, and the non-target samples are excluded from the hypersphere. The second step is to calculate the distance between the samples and the hyperplanes. The sample position is determined by distance and radius difference. In the third step, different samples inside and outside the hyperspheres are represented by different functions. Our algorithm is described in detail below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Analysis</head><p>The definition of fuzzy membership function is the key of FSVM algorithm. There are many definitions of fuzzy membership functions, but there are no general guidelines. Traditional fuzzy membership functions based on the distance between the sample and its cluster center are not effective to distinguish noises or outliers from SVs. Sometimes the distance is not the only criterion for judging whether it is normal. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, point A on the left has a high probability of being a valid sample. Point A on the right has a high probability of being a noise or outlier. It is not enough to just rely on linear functions of distance. The relative position relation between samples should be considered. That is, fuzzy membership function must consider the affinity between samples. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, the distance between B and the cluster center is not the same as the distance between C and the cluster center. Since these two points have the same distance to the classification hyperplane, they contribute the same to the hyperplane. Compared with point B and point C, point D is further away from the cluster center, but closer to the classification hyperplane. Point D is the point that contributes the most to the hyperplane. So we have to take that into account when we design membership functions. The optimal classification hyperplane and its nearby support vectors are far away from the cluster center. The closer the sample is to the cluster center, the greater the weight coefficient. The noises and SVs distributed on the boundary are far from the cluster center. They are all given less weight coefficients. This is quite different from the objective situation. SVs should be given greater weight coefficients.</p><p>The optimal hyperplane of standard SVM is determined by SVs. The geometric principle of SVM is to use two hyperplanes with maximum spacing to separate the training samples as far as possible in the original space or feature space. Therefore, using the hyperplane in class to replace the center can better approximate the actual situation.</p><p>The solution of the optimal classification hyperplane of SVM is usually converted to solving quadratic programming problem. However, the solving complexity of the quadratic programming problem will increase significantly with the sample increase. When the sample size is large, the traditional fuzzy support vector machine needs large memory to store and calculate the kernel function matrix. Therefore, by selecting the boundary vector containing SVs in advance, the number of training samples and the number of quadratic programming solutions can be reduced. This has practical significance for improving training speed and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Support Vector Data Description</head><p>The task of one-class classification is to distinguish the target sample from non-target samples. The boundary has to be constructed by a hypersphere around the target samples. By finding the minimum volume hypersphere containing the sample set, the target samples are included in the hypersphere as much as possible, and the non-target samples are excluded from the hypersphere.</p><p>For ease of description, ?: R n ? H represents the mapping of the input space to the highdimensional space. Assume T = {x i , i=1, 2, ?, l} contains l data objects, and the hypersphere is described by center a and radius R. The minimum hypersphere can be obtained by solving the following quadratic programming <ref type="bibr" target="#b0">(1)</ref>.</p><formula xml:id="formula_0">min R, ?, ? R 2 + ? ? ? ? ? ?=1 ?. ?. ??(? ? ) -?? ? ? R 2 + ? ? ? ? ? 0, ? = 1,2, ? , ?<label>(1)</label></formula><p>Where ||?|| is the Euclidean distance, ? i is slack variables, and C is the trade-off between the volume of the hypersphere and the errors. Lagrangian multipliers ? i and ? i are introduced to construct a Lagrangian function. The Lagrangian function is constructed as shown in equation ( <ref type="formula" target="#formula_1">2</ref>). (</p><formula xml:id="formula_1">?(?, ?, ?, ?, ?) = R 2 + ? ? ? ? ? ?=1 -? ? ? ? ?=1 [R 2 + ? ? -??(? ? ) -?? ? ] -? ? ? ? ?=1 ? ?<label>(2)</label></formula><p>The center a and radius R can be obtained from the solution to the dual problem and the solution to KKT conditions. a and R are calculated according to formulas (3) and ( <ref type="formula" target="#formula_3">4</ref>) respectively. </p><formula xml:id="formula_2">? = ? ? ? * ? ?=1 ?(? ? )<label>(3)</label></formula><p>According to <ref type="bibr" target="#b4">(5)</ref>, if the Euclidean distance between the point ?(x) and center a is less than radius R then it is normal. Conversely, it is the noise point when the Euclidean distance is greater than radius R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??(?) -??</head><formula xml:id="formula_4">? = ?(?, ?) -2? ?=1 ? ? ? * ?(? ? , ?) + ? ?=1 ? ? ?=1 ? ? ? * ? ? * ?(? ? , ? ? ) ? R (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Design Fuzzy Membership Function</head><p>According to the basic principle of the support vector machine, the optimal classification hyperplane is determined by the support vectors. If each class of the two classification problems is considered as a convex set, then these support vectors lie on the relative boundary of the two convex sets far away from the center of the two classes.</p><p>Given T = {(x i , y i ), i =1, 2, ?, l} contains l data objects. If l + and l -respectively represent the number of positive samples x i + , i =1, 2, ?, l + and the number of negative samples x i -, i =1, 2, ?, l -, then l + +l -= l.</p><p>If a + and a -respectively represent the minimum hypersphere center of positive samples and the minimum hypersphere center of negative samples, R + and R -respectively represent the minimum hypersphere radius of positive samples and minimum hypersphere radius of negative samples, then a + and a -are always located in the geometric center, if the normal vector of the hyperplane is established by the maximum sum of the distance <ref type="bibr" target="#b68">[69]</ref> from two centers to the hyperplane. As shown in Figure <ref type="figure" target="#fig_3">4</ref>, in order to maximize the sum of the distances, it should satisfy d=||a + -A||+||a --B||?||a + -O||+||a --O|| = ||a + -a -||. That is, the distance is maximized d=||a + -a -|| when hyperplane and vector a + -a -are perpendicular to each other. For the given data, the relative positions of the two hyperspheres can be intersected, tangent and separated. The two separate cases and tangent case can be classified as one case. Although in the case of intersection, the radial basis kernel function can always choose parameters to make the two hyperspheres separated, this will cause an overfitting phenomenon. Therefore, our paper summarizes the above three cases as two cases of separation and intersection.</p><p>As shown in the Figures <ref type="figure" target="#fig_4">5</ref> and<ref type="figure" target="#fig_5">6</ref>, the normal vector to the hyperplane is w = a + -a -according to the principle of maximum distance. These two hyperplanes that go through a + and a -with a normal vector of a normal vector of w are H + ?w T (x-a + ) = 0 and H -?w T (x-a -) = 0.  The optimal classification hyperplane is only determined by the SVs. Therefore, samples can be screened in advance, and those samples that may become support vectors can be selected to be trained as new training samples, which will simplify the computation of quadratic programming and improve the training speed. The optimal classification hyperplane lies between positive and negative hypersphere centers. Then, positive and negative samples between H + and H -can be selected as the new training sample set. As shown in the above two figures, the shaded parts inside the hyperspheres are the normal sample, in which the positive class is represented by orange slashes, while the negative class is represented by blue slashes. The samples with "+" and "*" in the new training sample set located outside the hypersphere represent noises or outliers respectively.</p><p>If l new + and l new are the number of positive and negative samples in the new sample set, then the distance between the samples and the hyperplane in each class is calculated according to <ref type="bibr" target="#b5">(6)</ref>.</p><formula xml:id="formula_5">{ ?(? ? + ) = |? ? (? -? + )| ??? , ? = 1,2, ? , ? ??? + ?(? ? -) = |? ? (? -? -)| ??? , ? = 1,2, ? , ? ??? -<label>(6)</label></formula><p>where w T (x-a + ) = 0 and H -?w T (x-a -) = 0 are the two hyperplanes that go through a + and a -; w = a + -a -is the normal vector to the hyperplane.</p><p>The distance between the samples and the center of the hypersphere is calculated according to <ref type="bibr" target="#b6">(7)</ref>.</p><formula xml:id="formula_6">{ ?(? ? + ) = ?? ? + -? + ?, ? = 1,2, ? , ? ??? + ?(? ? -) = ?? ? --? -?, ? = 1,2, ? , ? ??? -<label>(7)</label></formula><p>Therefore, membership functions of both positive and negative sample points are constructed according to <ref type="bibr" target="#b7">(8)</ref>  </p><p>The minimum value of the membership function inside the hypersphere is 0.4, and the maximum value of the membership function outside the hypersphere is 0.4. The membership value of the sample increases with the value of the distance between the sample and hyperplane. Given p ? 2, the bigger p , the faster s i + and s i -decay. Similarly, for nonlinear cases, mapping function ?(x) is introduced by kernel function K(x i , x j ) to map data to a high-dimensional space. The normal vector is w = a + -a -by a rule for the maximum sum of distance from two hyperspheres' centers to the separation hyperplane. The hyperplanes of the two classes with w as the normal vector and going through a + and a -respectively are H + ?w T (?(x)-a + ) = 0 and H -?w T (?(x)-a -) = 0. If l new + and l new are the number of positive and negative samples in the new sample set, then the distance between the samples and the hyperplane in each class is calculated according to <ref type="bibr" target="#b9">(10)</ref>. </p><p>The distance between the sample and its center of the hypersphere in each class is calculated according to <ref type="bibr" target="#b10">(11)</ref>. </p><p>Therefore, membership functions of both positive and negative sample points are constructed according to <ref type="bibr" target="#b11">(12)</ref> and <ref type="bibr" target="#b12">(13)</ref>. </p><formula xml:id="formula_10">? ? + = { 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluation</head><p>This section presents the evaluation of our method in terms of detection performance, overhead and impaction of parameters. In order to test the performance of our algorithm, in addition to comparing the SVM-based algorithms SVM, FSVM1 <ref type="bibr" target="#b65">[66]</ref>, FSVM2 <ref type="bibr" target="#b64">[65]</ref>, and FSVM3 <ref type="bibr" target="#b67">[68]</ref>, the proposed algorithm is also compared with other algorithms in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Experimental Data</head><p>In order to facilitate an experimental performance comparison with similar studies?the system call datasets UNM_sendmail and UNM_live_lpr published by the New Mexico university are used in this section <ref type="bibr" target="#b69">[70]</ref>. The UNM_sendmail data set consists of 346 normal traces and 25 abnormal traces. The abnormal data contains sunsendmailcp (sccp) intrusions and decode intrusions, in which the sccp intrusions enable the local user to obtain the root access by using special command options to make sendmail attach an e-mail message to a file, and the decode intrusions enable remote users to make changes to certain files on the local system. Data for UNM_live_lpr data set includes 15 months of activity and consists of 4298 normal tracks and 1003 abnormal tracks. The abnormal data contains lprcp symbolic link intrusions that take advantage of the vulnerability of the lpr program to control the files on the host computer and tamper with the contents of the files.</p><p>The trace consists of a sequence of system calls in chronological order. The meaning of trace varies from program to program. Each trace file lists pairs of numbers, the first number represents the process identity (PID) of the execution process, and the second number represents the specific system call (SC). The child processes forked by the parent process are traced individually. We take UNM_sendmail as an example to show the specific format of experimental data as follows: The data consists of different data units. Each data unit consists of PID and SC. In the experiment, data is segmented according to the PID number and the SCs after the same PID are arranged together in chronological order. In the above data, the numbers 8840, 8843 and 6545 are PIDs and the number 4, 2, 5, 66, ? , 2 are SCs. The lists of system calls issued by 8840, 8843 and 6545 are denoted as R8840 = (4, 2, 5, 66, 5, ? ,6), R8843 = (115, 15, 99, 120, ? ,17) and R6545 = (2, 55, ? , 2) respectively.</p><p>The vector form of a system call sequence composed of the frequency of the short system call sequences. Given n is the number of traces, m is the total number of short system call sequences. Then the ith element in the vector is the frequency at which the short system sequence numbered i occurs in the system call sequence of the process. The vector corresponding to the jth trace, represented by the frequency of short system call sequence, is denoted by (f1j,?,fmj). That is to say, samples are represented as (Xj, yj) j=1,?,n, where Xj = (f1j ,?, fmj), yj ? (+1, -1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">The Experimental Performance</head><p>The experimental data of UNM_live_lpr process were composed of 4298 normal tracks and 1003 abnormal tracks. The 1003 anomaly traces contain LPRCP attacks that control and tamper with host files. The experimental data for the UNM_sendmail process consisted of 346 normal traces and 25 abnormal traces, including 20 SCCPS that used E-mail to obtain root directory information and 5 decode attacks that remotely modified local files.</p><p>False alarm is to judge the normal behavior of the program as abnormal behavior. If L N normal traces participate in the evaluation, and N FAR normal traces are misjudged as abnormal traces, then the false alarm rate is equal to N FAR /L N . Detection rate refers to the proportion of detected abnormal traces in the total number of abnormal traces. If L AN abnormal traces participate in the test and N HR were detected, then the detection rate is N HR /L AN . The missing rate indicates the proportion of unrecognized abnormal traces in the total number of abnormal traces. If L AN abnormal traces participate in the evaluation and N M cannot be detected, then the missing rate is N M /L AN . DR = ? HR * (1-? FAR ) is used as the comprehensive detection formula, in which ? HR and ? FAR stands for detection rate and missing rate respectively. Gauss kernel k (x, y) = exp (-|| x-y || 2 /2? 2 ) is used in all algorithms during training. ? 1 and ? 2 can be selected according to the maximum error rate allowed in the target set. C 1 and C 2 can be adjusted according to the equality of upper bound of positive and negative error rate. That is,</p><formula xml:id="formula_12">1/ l 1 C 1 =1/ l 2 C 2 ?1/ l 1 ? C 1 ? 1?1/ l 2 ? C 2 ? 1.</formula><p>Grid search method is adopted to select the optimal parameters. The search range of parameter C is {2 -24 , 2 -23 ,?, 2 23 , 2 24 }. The parameter ? and ? both have a search range of {2 -24 , 2 -23 ,?, 2 23 , 2 24 }. The step length and short sequence length are set to 1 and 6 respectively.</p><p>Table <ref type="table" target="#tab_3">1</ref> summarizes the comparison results of detection performance between our method and the other eight methods on UNM_live_lp. The detection rate of SVM, FSVM1, FSVM2, FSVM3, and our algorithm are 61.53%,76.92%, 76.92%, 83.21%, and 84.61% respectively. The missing rates of SVM, FSVM1, FSVM2, FSVM3, and our algorithm are 38.47%, 23.08%, 23.08%, 16.23%, and 15.39% respectively. The false alarm rates of SVM, FSVM1, FSVM2, FSVM3, and our algorithm are 10.14%, 9.57%, 8.17%, 6.92%, and 4.51% respectively. In all the algorithms, our algorithm has the highest detection rate and the lowest false alarm rate and missing rate. As shown in Table <ref type="table" target="#tab_3">1</ref>, SVM has the lowest detection rate, 79.88%, among the five algorithms. Due to the construction of a fuzzy membership function, the other four algorithms treat the different contributions of different samples in the construction of the objective function differently, which makes their average detection rate reach 87.03%. FSVM1 algorithm designs a fuzzy membership function based on the linear function of the distance between the sample and its cluster center. The larger the distance is, the smaller the coefficients is. However, this membership design method is sometimes unable to distinguish abnormal points effectively. The FSVM2 algorithm not only considers the distance in the FSVM1 algorithm, but also considers the position relation between samples. FSVM2 algorithm determines the membership function according to the position of the sample and hypersphere. When the samples are located inside the hypersphere, the membership function is defined by the linear function of the distance. The coefficient of the sample decreases with the increase of the distance. When the samples are located outside the hypersphere, these samples are regarded as abnormal samples. The membership function is represented by different functions. The FSVM3 algorithm, like the FSVM2 algorithm, takes account of the distance between the sample and its cluster center and the affinity between samples. The difference between the FSVM3 and FSVM2 is that the FSVM3 algorithm is based on the SVDD algorithm by introducing two different parameters to control the affinity between positive and negative samples.</p><p>The method treats all samples equally during the training process, which makes the contribution of samples to constructing the optimal classification hyperplane equal. As a result, when training samples contain abnormal samples, the classification hyperplane obtained is not the optimal hyperplane. Our algorithm abides by the maximum sum of distance from the hypersphere to hyperplane, replaces the cluster center with the hyperplane inside the class, and designs the membership function according to the distance from the sample to the hyperplane inside the hypersphere. Therefore, it can be seen from the table that with the continuous improvement of the membership function, the detection rate of the algorithm increases successively. The detection rate changed from 83.71% of FSVM1 algorithm to 85.56% of FSVM2 algorithm, then to 86.20% of WCS-FSVM algorithm, and finally reached 92.63% of our algorithm.</p><p>The formula of comprehensive detection rate is closer to reality. The comprehensive detection rates of SVM, FSVM1, FSVM2, and FSVM3 are 72.97%, 77.59%, 78.56%, and 80.23% respectively. As show in Figure <ref type="figure" target="#fig_9">7</ref>, our algorithm has the highest comprehensive detection rate, 86.92%, among five algorithms. At the same time, it is also evident from the data in Table <ref type="table" target="#tab_4">2</ref> that the detection rate, false alarm rate and missing rate of UNM_sendmail data are all lower than that of UNM_live_lpr data. The reason for this is the amount of data. The UNM_sendmail process data consists of 346 normal tracks and 25 abnormal tracks, which is less experimental data than the 4298 normal tracks and 1003 abnormal tracks of the UNM_live_lpr process. Therefore, there is sufficient data for UNM_live_lpr process training, which is conducive to pre-extracting relative boundary vectors containing enough support vectors and ensuring sufficient data parameters. In the experiments of UNM_live_lpr process and UNM_sendmail process, SVM uses the same error penalty factor for all samples. It will have a negative impact on the classification results when the SVM algorithm classifies unbalanced samples. This is the reason that the SVM always has the lowest detection rate among all algorithms. FSVM1 algorithm, FSVM2 algorithm, FSVM3 algorithm, and our algorithm are equivalent to using a penalty factor for each sample to be treated differently. When these algorithms are used to classify the quantity imbalance samples, good classification results can be obtained. In other words, membership function can be used to describe error penalty on samples. This is consistent with the conclusion that fuzzy support vector machine is equivalent to a multi-penalty support vector machine. The comprehensive detection rates of SVM algorithm, FSVM1 algorithm, FSVM2 algorithm, FSVM3 algorithm, and our algorithm on UNM sendmail process data were 55.29%, 69.58%, 70.63%, 77.45%, and 80.79%, respectively. As shown in figure <ref type="figure" target="#fig_10">8</ref>, among the five detection algorithms, SVM algorithm has the lowest comprehensive detection rate and the weakest detection performance. The algorithm proposed in this paper has the highest comprehensive detection rate and the strongest detection performance. The comprehensive detection performance of FSVM1 algorithm, FSVM2 algorithm and FSVM3 algorithm also varies with the fuzzy membership function, but the overall trend is consistent with the test results obtained from UNM_live_lpr process data, that is, the detection performance is improved with the improvement of fuzzy membership function. As shown in Tables <ref type="table" target="#tab_6">3</ref> and<ref type="table" target="#tab_7">4</ref>, the length of the system call short sequence k has a direct impact on the detection performance. When k increases from 3 to 5, the detection rate, missing alarm rate and false alarm rate are increasing. When k is 6, our algorithm obtains the highest detection rate, the lowest false alarm rate and the lowest missing rate. When k is greater than 6, the detection rate of our algorithm starts to decrease, and the missing rate and false alarm rate start to increase. On UNM_sendmail data, the detection rate, false alarm rate, and missing alarm rate of PVFSVM algorithm have the same trend as on UNM_live_lpr data. As shown in Figures <ref type="figure" target="#fig_11">9</ref> and<ref type="figure" target="#fig_12">10</ref>, if k=6, the comprehensive detection rates of our algorithm on UNM_live_lpr and UNM_sendmail are 86.92% and 80.79% respectively, which are higher than the comprehensive detection rate corresponding to other k values on UNM_live_lpr and UNM_sendmail. When k increases from 3 to 6, the comprehensive detection rate also increases gradually. When k increases from 6 to 8, the comprehensive detection rate decreases gradually.  This is consistent with professor Forrest's conclusion on the selection of short sequence length, and professor Wenke Lee's conclusion from the perspective of information theory that the best system call short sequence length is 6 or 7. Compared with the value of k of 6, when the value of short sequence is too small, the timing relation between short sequence patterns is lost. When the short sequence becomes longer, the short sequence pattern loses local information, no matter what kind of information loss will make the comprehensive detection performance worse. Therefore, the short sequence length can only be chosen as 6, which makes the detection performance of our algorithm reach the optimal level.  These two methods, Compression method and Sequence Matching method, respectively consider the detection problem from the aspect of data reversibility and similarity matching degree, and fail to consider the sequence characteristics between system calls. Therefore, they are the two algorithms with the worst comprehensive detection performance. The IPMA method and Hybrid Markov method are complicated due to investigating the transition characteristics of system calls one by one. Although the ? FAR of IPMA method and Hybrid Markov method are 7.58% and 14.26%, the ? MR is 47.37% and 40.22%. The ? MR of Bayes 1-step Markov method is 33.3% and the ? FAR is 4.1%.</p><p>The comprehensive test performance evaluation formula has a high value, so the test performance is good. Since this method looks the frequency of rare system calls, the ? MR of Uniqueness method is 55.3% and the ? FAR is 2.3%. However, this requires statistics for all the system calls that are used. N.bayes belongs to Naive Bayesian method in essence, and it has good noise tolerance and fast calculation, but the false alarm rate is too high. Therefore, the comprehensive detection performance is good. The closeness method extracts user behavior patterns from the perspective of combination. It shows good detection performance under different closeness thresholds, but it ignores the characteristics of attack intensity. That is, the attacker will complete the attack task in the shortest possible time and try to behave normally the rest of the time. As show in Figure <ref type="figure" target="#fig_0">11</ref>, our algorithm has the highest comprehensive detection rate 86.92% among five algorithms. In all the algorithms, our algorithm has the highest detection rate, and the lowest false alarm rate and missing rate. The formula of the comprehensive detection rate is closer to reality. The comprehensive detection rate of N.bayes, Uniqueness, Hybrid Markov, Bayes1-step Markov, IPMA, Sequence matching, Compression, Closeness, and our algorithm are 62%, 36.91%, 39.13%, 60.03%, 41.63%, 34.82%, 28.47%, 73.22%, and 86.92% respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In order to solve the defects of FSVM. This paper presents a new FSVM algorithm based on SVDD. In our method, the noises and outliers are identified by a hypersphere with minimum volume while containing the maximum of the samples. The definition of fuzzy membership considered not only the position of samples inside the hypersphere, but also the distance between the hyperplane and samples. For the samples inside the hypersphere, the fuzzy membership function is a linear function of the distance. The greater the distance is, the greater the coefficient is. For the samples outside the hypersphere, the fuzzy membership function is an exponential function of the distance. The greater the distance is, the smaller the coefficient is. Compared with the FSVM based on the relation between the sample and its cluster center, our algorithm effectively distinguishes the noises or outliers from samples. The experiments show that our FSVM is more robust than the SVM and FSVM based on the distance between the sample and its cluster center. Our algorithm is suitable for the data of system call sequence and can contribute to accurate prediction. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The overview of the proposed algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The difference of the affinity among samples at two different classes.</figDesc><graphic url="image-3.png" coords="5,155.70,139.76,284.02,150.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The membership function design based on the position of samples and the hypersphere.</figDesc><graphic url="image-4.png" coords="5,200.23,415.21,194.60,137.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Maximize the sum of the distances.</figDesc><graphic url="image-5.png" coords="7,182.98,142.46,228.91,111.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The case of separation.</figDesc><graphic url="image-6.png" coords="7,150.73,408.78,293.39,137.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The case of intersection.</figDesc><graphic url="image-7.png" coords="7,192.50,577.78,210.41,131.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>8840 4 ,</head><label>4</label><figDesc>8840 2, 8840 5, 8840 66, 8840 5, ?, 8840 6 8843 115, 8843 15, 8843 99, 8843 120, 8843 17, ?, 8843 12, 6545 2, 6545 5, ?, 6545 2, 6545 2, 6545 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Performance comparisons on UNM_live_lpr data set.</figDesc><graphic url="image-8.png" coords="12,158.23,73.79,278.71,183.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Performance comparisons on UNM_sendmail data set.</figDesc><graphic url="image-9.png" coords="13,167.98,73.79,258.96,186.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The comprehensive detection rate of different k on UNM_live_lpr data.</figDesc><graphic url="image-10.png" coords="14,152.88,73.79,289.70,176.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. The comprehensive detection rate of different k on UNM_sendmail data.</figDesc><graphic url="image-11.png" coords="14,170.98,283.64,253.40,189.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 .Figure 12 .</head><label>1112</label><figDesc>Figure 11. The DR comparation of different algorithms on UNM_live_lp. N .b a y e s U n iq u e n e s s H y b ri d M a rk o v B a y e s 1 -s te p M a rk o v IP M A S e q u e n c e M a tc h in g C o m p re s s io n C lo s e n e s s O u r m e th o d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>N</head><label></label><figDesc>.b a y e s U n iq u e n e s s H y b ri d M a rk o v B a y e s 1 -s te p M a rk o v IP M A S e q u e n c e M a tc h in g C o m p re s s io n C lo s e n e s s O u r m e th o</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>and (9).</figDesc><table><row><cell></cell><cell></cell><cell>0.6  *</cell><cell>?(? ? + ) ?(? ? + )</cell><cell>*</cell><cell cols="3">?(? ? + ) ? + + 0.4,</cell><cell>?(? ? + ) ? ? + ,</cell><cell>? = 1,2, ? , ? ??? +</cell></row><row><cell>? ? + =</cell><cell>{</cell><cell>0.4  *</cell><cell cols="3">[ ?(? ? + ) ? + + 1</cell><cell>? + ) ] ?(? ? ?(? ? + )</cell><cell>,</cell><cell>?(? ? -) &gt; ? -,</cell><cell>? = 1,2, ? , ? ??? +</cell><cell>(8)</cell></row><row><cell></cell><cell></cell><cell>0.6  *</cell><cell>?(? ? -) ?(? ? -)</cell><cell>*</cell><cell cols="3">?(? ? -) ? -+ 0.4,</cell><cell>?(? ? -) ? ? -,</cell><cell>? = 1,2, ? , ? ??? -</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>?</cell><cell></cell><cell></cell></row><row><cell>? ? -=</cell><cell>{</cell><cell>0.4  *</cell><cell cols="3">[ ?(? ? -) ? -+ 1</cell><cell>?(? ? -) ] ?(? ? -)</cell><cell>,</cell><cell>?(? ? -) &gt; ? -,</cell><cell>? = 1,2, ? , ? ??? -</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison on data set UNM_live_lp.</figDesc><table><row><cell>Algorithm</cell><cell cols="3">Detection Rate(%) Missing Rate(%) False Alarm Rate(%)</cell></row><row><cell>SVM</cell><cell>79.88%</cell><cell>20.12%</cell><cell>8.64%</cell></row><row><cell>FSVM1</cell><cell>83.71%</cell><cell>16.29%</cell><cell>7.30%</cell></row><row><cell>FSVM2</cell><cell>85.56%</cell><cell>14.44%</cell><cell>8.17%</cell></row><row><cell>FSVM3</cell><cell>86.20%</cell><cell>13.80%</cell><cell>6.92%</cell></row><row><cell>Our algorithm</cell><cell>92.63%</cell><cell>7.37%</cell><cell>6.16%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison on data set UNM_sendmail.</figDesc><table><row><cell>Algorithm</cell><cell>Detection Rate(</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>%) Missing Rate(%) False Alarm Rate(%)</head><label></label><figDesc></figDesc><table><row><cell>SVM</cell><cell>61.53%</cell><cell>38.47%</cell><cell>10.14%</cell></row><row><cell>FSVM1</cell><cell>76.92%</cell><cell>23.08%</cell><cell>9.57%</cell></row><row><cell>FSVM2</cell><cell>76.92%</cell><cell>23.08%</cell><cell>8.17%</cell></row><row><cell>FSVM3</cell><cell>83.21%</cell><cell>16.23%</cell><cell>6.92%</cell></row><row><cell>Our algorithm</cell><cell>84.61%</cell><cell>15.39%</cell><cell>4.51%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Detection performance of different k on UNM_live_lpr data.</figDesc><table><row><cell>Our method</cell><cell>k = 3</cell><cell>k = 4</cell><cell>k = 5</cell><cell>k = 6</cell><cell>k = 7</cell><cell>k = 8</cell></row><row><cell>Detection rate</cell><cell cols="6">78.30% 83.25% 86.31% 92.63% 88.26% 83.27%</cell></row><row><cell>Missing rate</cell><cell cols="6">21.70% 16.75% 13.69% 7.37% 11.74% 16.73%</cell></row><row><cell cols="5">False alarm rate 11.76% 11.32% 10.60% 6.16%</cell><cell>6.30%</cell><cell>7.56%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 .</head><label>4</label><figDesc>Detection performance of different k on UNM_sendmail data.</figDesc><table><row><cell>Our method</cell><cell>k = 3</cell><cell>k = 4</cell><cell>k = 5</cell><cell>k = 6</cell><cell>k = 7</cell><cell>k = 8</cell></row><row><cell>Detection rate</cell><cell cols="6">77.22% 82.45% 85.37% 84.61% 86.46% 81.37%</cell></row><row><cell>Missing rate</cell><cell cols="6">22.78% 17.55% 14.63% 15.39% 13.54% 18.63%</cell></row><row><cell cols="5">False alarm rate 14.67% 12.12% 11.68% 4.51%</cell><cell>6.85%</cell><cell>9.53%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5</head><label>5</label><figDesc>summarizes the comparison results of detection performance between our method and the other eight methods on UNM_live_lp. The detection rate of N.bayes, Uniqueness, Hybrid Markov, Bayes1-step Markov, IPMA, Sequence matching, Compression, Closeness, and our algorithm are 65.11%, 39.1%, 45.6%, 62.6%, 45.05%, 36.7%, 33.9%, 76.5%, and 92.63% respectively. The missing rates of N.bayes, Uniqueness, Hybrid Markov, Bayes1-step Markov, IPMA, Sequence matching, Compression, Closeness, and our algorithm are 30.12%, 55.3%, 40.22%, 33.3%, 47.37%, 58.2%, 50.1%, 19.2%, and 7.37% respectively. The false alarm rates of N.bayes, Uniqueness, Hybrid Markov, Bayes1-step Markov, IPMA, Sequence matching, Compression, Closeness, and our algorithm are 4.77%, 2.30%, 14.26%, 4.1%, 7.58%, 5.91%, 16%, 4.3%, and 6.16% respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 .</head><label>5</label><figDesc>Comparison between different algorithms on UNM_live_lp.</figDesc><table><row><cell>Algorithm</cell><cell cols="3">Detection Rate(%) Missing Rate(%) False Alarm Rate(%)</cell></row><row><cell>N.bayes</cell><cell>65.11%</cell><cell>30.12%</cell><cell>4.77%</cell></row><row><cell>Uniqueness</cell><cell>39.1%</cell><cell>55.3%</cell><cell>2.30%</cell></row><row><cell>Hybrid Markov</cell><cell>45.6%</cell><cell>40.22%</cell><cell>14.26%</cell></row><row><cell>Bayes1-step Markov</cell><cell>62.6%</cell><cell>33.3%</cell><cell>4.1%</cell></row><row><cell>IPMA</cell><cell>45.05%</cell><cell>47.37%</cell><cell>7.58%</cell></row><row><cell>Sequence matching</cell><cell>36.7%</cell><cell>58.2%</cell><cell>5.91%</cell></row><row><cell>Compression</cell><cell>33.9%</cell><cell>50.1%</cell><cell>16%</cell></row><row><cell>Closeness</cell><cell>76.5%</cell><cell>19.2%</cell><cell>4.3%</cell></row><row><cell>Our algorithm</cell><cell>92.63%</cell><cell>7.37%</cell><cell>6.16%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment?System call data from New Mexico university and the Massachusetts institute of technology are used in this paper.</p></div>
			</div>
			<div type="funding">
<div><p>Funding: This research was supported by the <rs type="funder">National Natural Science Foundation of China</rs> under grant No. <rs type="grantNumber">61370134</rs>, the <rs type="funder">National High Technology Research and Development Program of China</rs> (<rs type="programName">863 Program</rs>) under grant No. <rs type="grantNumber">2013AA013901</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GqtkGmD">
					<idno type="grant-number">61370134</idno>
				</org>
				<org type="funding" xml:id="_fwSBNtb">
					<idno type="grant-number">2013AA013901</idno>
					<orgName type="program" subtype="full">863 Program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Similarly, the Compression method and Sequence Matching method pay attention to reversibility and similarity matching degree, respectively, and fail to consider the sequence characteristic between system calls. The IPMA method and Hybrid Markov method are complicated due to investigating transition characteristics of system calls one by one. Although the ? FAR of IPMA method and Hybrid Markov method is 17% and 14.26%, the ? MR is 42.37% and 40.44%. The ? MR of Bayes 1-step Markov method is 30.8%, and the ? FAR is 1.9%. The comprehensive test performance evaluation formula has a high value, so the test performance is good. Since this method looks at the frequency of rare system calls, the ? MR of Uniqueness method is 60.3%, and the ? FAR is 2.3%. However, this requires statistics for all the system calls that are used. N.bayes belongs to Naive Bayesian method in essence, and it has good noise tolerance and fast calculation, but the false alarm rate is too high. Therefore, the comprehensive detection performance is good. The closeness method extracts user behavior patterns from the perspective of combination. It shows good detection performance under specific closeness thresholds, but it ignores the characteristics of attack intensity. That is, the attacker will complete the attack task in the shortest possible time and try to behave normally the rest of the time. As shown in Figure <ref type="figure">12</ref>, our algorithm has the highest comprehensive detection rate 86.92% among five algorithms. In all the algorithms, our algorithm has the highest detection rate, and the lowest false alarm rate and missing rate. The formula of comprehensive detection rate is closer to reality. The comprehensive detection rates of N.bayes, Uniqueness, Hybrid Markov, Bayes1-step Markov, IPMA, Sequence matching, Compression, Closeness, and our algorithm are 61.32%, 36.54%, 38.84%, 60.02%, 33.72%, 34.49%, 23.81%, 71.67%, and 80.79% respectively. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A novel Ensemble of Hybrid Intrusion Detection System for Detecting Internet of Things Attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khraisat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vamplew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kamruzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alazab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1210</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improved Neighborhood Search for Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">No</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Fuzzy Log. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="29" to="40" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the uniform convergence of relative frequencies of events to their probabilities</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Chervonenkis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Probab. Its Appl</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="264" to="279" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Online semi-supervised support vector machine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">439</biblScope>
			<biblScope unit="page" from="125" to="141" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Density-dependent quantized least squares support vector machine for large data sets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Toh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="94" to="106" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pattern Recognition of Ship Navigational Data Using Support Vector Machine</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Fuzzy Log. Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Feature selection algorithms in intrusion detection system: A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Maza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Touahria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KSII Trans. Internet Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="5079" to="5099" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hybrid of binary gravitational search algorithm and mutual information for feature selection in intrusion detection systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bostani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sheikhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2307" to="2324" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Android malware detection based on system call sequences and LSTM</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mercaldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sangaiah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimed. Tools. Appl</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="3937" to="3999" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiresolution abnormal trace detection using variedlength n-grams and automata</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ungureanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshihira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. Part C Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="86" to="97" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimal thresholds for intrusion detection systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Laszka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vorobeychik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Koutsoukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium and Bootcamp on the Science of Security</title>
		<meeting>the Symposium and Bootcamp on the Science of Security</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Defining the operational limits of Stide, an anomaly-based intrusion detector</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Maxion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 IEEE Symposium on Security and Privacy</title>
		<meeting>the 2002 IEEE Symposium on Security and Privacy<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="page" from="188" to="201" />
		</imprint>
	</monogr>
	<note>Why 6?</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detecting anomalies in IaaS environments through virtual machine host system call analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Alarifi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Wolthusen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 International Conference for Internet Technology and Secured Transactions</title>
		<meeting>the 2012 International Conference for Internet Technology and Secured Transactions<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12-12">10-12 December 2012</date>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A multi-objective particle swarm optimisation for filter-based feature selection in classification problems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cervante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connect. Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="91" to="116" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A new dependency and correlation analysis for features</title>
		<author>
			<persName><forename type="first">G</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hariri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yousif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1199" to="1207" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel intrusion detection system based on feature generation with visualization strategy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="4139" to="4147" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A three-way decision making approach to malware analysis using probabilistic rough sets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="page" from="193" to="209" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey of network anomaly detection techniques</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="19" to="31" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning for effective Android malware detection using API call graph embeddings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pektas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Acarman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1027" to="1043" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Evolution of System-Call Monitoring. The evolution of systemcall monitoring</title>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hofmeyr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Somayaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual Computer Security Applications Conference</title>
		<meeting>the 24th Annual Computer Security Applications Conference<address><addrLine>Anaheim, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-12">December 2008</date>
			<biblScope unit="page" from="418" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computer immunology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Beauchemin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Somayaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Immunol. Rev</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="page" from="176" to="197" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Low overhead scheduling of LoRa transmissions for improved scalability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Haxhibeqiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoebeke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Things J</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3097" to="3109" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic android malware classification using graph-based representations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cavazos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 IEEE 3rd International Conference on Cyber Security and Cloud Computing</title>
		<meeting>the 2016 IEEE 3rd International Conference on Cyber Security and Cloud Computing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="220" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">HFil: A High Accuracy Bloom Filter</title>
		<author>
			<persName><forename type="first">R</forename><surname>Patgiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 21st International Conference on High Performance Computing and Communications</title>
		<meeting>the IEEE 21st International Conference on High Performance Computing and Communications<address><addrLine>Zhangjiajie, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-12">10-12 August 2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
		<title level="m">nd International Conference on E-business and Information System Security</title>
		<meeting><address><addrLine>Wuhan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010 2. May 2010</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Survey of Intrusion Detection Systems Leveraging Host Data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Glass-Vanderlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Iannacone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bridges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Classification of ransomware families with machine learning based on N-gram of opcodes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mercaldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sangaiah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="211" to="212" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Diversification of system calls in linux kernel</title>
		<author>
			<persName><forename type="first">S</forename><surname>Laur?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rauti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lepp?nen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Computer Systems and Technologies</title>
		<meeting>the 16th International Conference on Computer Systems and Technologies<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-25">25 June 2015</date>
			<biblScope unit="page" from="284" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust and reliable reconfiguration of cloud applications</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dur?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sala?n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Syst. Softw</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="524" to="537" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Thesis-Generating Knowledgebase of Common Behavior and Workflow Patterns for Secure Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bigyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Greenville, NC, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>East Carolina University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos; Thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An approach for intrusion detection using text mining techniques</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mangathayaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Narasimha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Engineering &amp; MIS</title>
		<meeting>the International Conference on Engineering &amp; MIS</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Evaluation of android malware detection based on system calls</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dimja?evi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Atzeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ugrina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rakamaric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on International Workshop on Security and Privacy Analytics</title>
		<meeting>the ACM on International Workshop on Security and Privacy Analytics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Trusted system-calls analysis methodology aimed at detection of compromised virtual machines using sequential mining</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lapidot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Elovici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Based Syst</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="147" to="175" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Intrusion detection system for home windows based computers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zuzcak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sochor</forename><surname>Tsochor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zenka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KSII Trans. Internet Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="4706" to="4726" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A classification algorithm based on data clustering and data reduction for intrusion detection system over big data</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Q</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KSII Trans. Internet Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3714" to="3732" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="16" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning Dual Convolutional Neural Networks for Low-Level Vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3070" to="3079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Advances in natural language processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A Primer on Neural Network Models for Natural Language Processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="67" to="77" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Artificial Neural Network based Intrusion Detection System: A Survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="13" to="18" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Evaluating performance of long short-term memory recurrent neural networks on intrusion detection data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Staudemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Omlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference on-SAICSIT</title>
		<meeting>the South African Institute for Computer Scientists and Information Technologists Conference on-SAICSIT</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">218</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">LSTM-Based System-Call Language Modeling and Robust Ensemble Method for Designing Host-Based Intrusion Detection Systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Paek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01726</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sultana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sahita</surname></persName>
		</author>
		<author>
			<persName><surname>Henet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02318</idno>
		<title level="m">A Deep Learning Approach on Intel circled Processor Trace for Effective Exploit Detection. arXiv</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">AnRAD: A neuromorphic anomaly detection framework for massive concurrent data streams</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1622" to="1636" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Enhanced network intrusion detection using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Naseer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Saleem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ksii Trans. Internet Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="5159" to="5178" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Building an intrusion detection system using a filter-based feature selection algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ambusaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="2986" to="2998" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A semantic approach to host-based intrusion detection systems using contiguous and discontiguous system call patterns</title>
		<author>
			<persName><forename type="first">G</forename><surname>Creech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="807" to="819" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Combining heterogeneous anomaly detectors for improved software security</title>
		<author>
			<persName><forename type="first">W</forename><surname>Khreich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Murtaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamou-Lhadj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Talhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Syst. Softw</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="415" to="429" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Intrusion prediction systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abdlhamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lifayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q;</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Fusion for Cyber-Security Analytics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1358" to="1363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Intrusion prediction with system-call sequence-to-sequence model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1358" to="1363" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The Study of Intrusion Prediction Based on HsMM</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asia Pacific Services Computing Conference, 2008 (APSCC &apos;08)</title>
		<meeting>the Asia Pacific Services Computing Conference, 2008 (APSCC &apos;08)<address><addrLine>Yilan, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-12">December 2008</date>
			<biblScope unit="page" from="1358" to="1363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Malware detection in cloud computing infrastructures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Marnerides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mauthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hutchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Dependable Secur. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="192" to="205" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Evaluating host-based anomaly detection systems: Application of the one-class SVM algorithm to ADFA-LD</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Slay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 11th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD&apos;14)</title>
		<meeting>the 2014 11th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD&apos;14)<address><addrLine>Xiamen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08">August 2014</date>
			<biblScope unit="page" from="978" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A distance-based weighted under sampling scheme for support vector machines and its application to imbalanced classification</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="4152" to="4165" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Survey on SVM and their application in image classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Inf. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Using weighted support vector machine to address the imbalanced classes problem of intrusion detection system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alabdallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Awad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KSII Trans. Internet Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="5143" to="5158" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fuzzy support vector machines for multilabel classification</title>
		<author>
			<persName><forename type="first">Shigeo</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2110" to="2117" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Fuzzy support vector machines for pattern recognition and data mining</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="826" to="835" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A fuzzy twin support vector machine based on information entropy for class imbalance learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deepak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bharat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parashjyoti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="7153" to="7164" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A new fuzzy twin support vector machine for pattern classification</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mach. Learn. Cybern</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1553" to="1564" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A new fuzzy support vector machine to evaluate credit risk</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="820" to="831" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Fuzzy support vector machine based on within-class scatter for classification problems with outliers or noises</title>
		<author>
			<persName><forename type="first">W</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Fuzzy SVM with a new fuzzy membership function</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fuzzy support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="464" to="471" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Guang-You, X.U. Fuzzy Support Vector Machine Based on Affinity among Samples</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao-Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Softw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="951" to="958" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Using class-center vectors to build support vector machines</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Signal Processing Society Workshop</title>
		<meeting>the IEEE Signal Processing Society Workshop<address><addrLine>Madison, WI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-08-25">25 August 1999</date>
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Detecting intrusions using system calls: Alternative data models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Warrender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pearlmutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy</title>
		<meeting>the IEEE Symposium on Security and Privacy<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-05-14">14 May 1999</date>
			<biblScope unit="page" from="133" to="145" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
