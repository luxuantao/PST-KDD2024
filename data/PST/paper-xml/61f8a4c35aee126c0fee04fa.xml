<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-01-31">31 Jan 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Siqi</forename><surname>Miao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<region>West Lafayette</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miaoyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<settlement>West Lafayette</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
							<email>&lt;panli@purdue.edu&gt;.</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<region>West Lafayette</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-01-31">31 Jan 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2201.12987v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Interpretable graph learning is in need as many scientific applications depend on learning models to collect insights from graph-structured data. Previous works mostly focused on using post-hoc approaches to interpret a pre-trained model (graph neural network models in particular). They argue against inherently interpretable models because good interpretation of these models is often at the cost of their prediction accuracy. And, the widely used attention mechanism for inherent interpretation often fails to provide faithful interpretation in graph learning tasks. In this work, we address both issues by proposing Graph Stochastic Attention (GSAT), an attention mechanism derived from the information bottleneck principle. GSAT leverages stochastic attention to block the information from the task-irrelevant graph components while learning stochasticity-reduced attention to select the task-relevant subgraphs for interpretation. GSAT can also apply to fine-tuning and interpreting pre-trained models via stochastic attention mechanism. Extensive experiments on eight datasets show that GSAT outperforms the state-of-the-art methods by up to 20%↑ in interpretation AUC and 5%↑ in prediction accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Graph learning models are widely used in science, such as physics <ref type="bibr" target="#b4">(Bapst et al., 2020)</ref> and biochemistry <ref type="bibr" target="#b19">(Jumper et al., 2021)</ref>. In many such disciplines, building more accurate predictive models is typically not the only goal. It is often more crucial for scientists to discover the patterns from the data that induce certain predictions <ref type="bibr" target="#b10">(Cranmer et al., 2020)</ref>. For example, identifying the functional groups in a molecule that yield its certain properties may provide insights to guide sci-Many works have been recently proposed to extract critical data patterns for the prediction by interpreting GNNs in post-hoc ways <ref type="bibr">(Ying et al., 2019;</ref><ref type="bibr">Yuan et al., 2020a;</ref><ref type="bibr" target="#b40">Vu &amp; Thai, 2020;</ref><ref type="bibr" target="#b25">Luo et al., 2020;</ref><ref type="bibr" target="#b31">Schlichtkrull et al., 2021;</ref><ref type="bibr">Yuan et al., 2021;</ref><ref type="bibr" target="#b23">Lin et al., 2021;</ref><ref type="bibr" target="#b14">Henderson et al., 2021)</ref>. They work on a pre-trained model and propose different types of combinatorial search to detect the subgraphs of the input data that affect the model predictions the most.</p><p>In contrast to the above post-hoc methods, inherently interpretable models have been rarely investigated for graph learning tasks. There are two main concerns regarding such models. First, the prediction accuracy and inherent interpretability of a model often forms a trade-off <ref type="bibr" target="#b12">(Du et al., 2019)</ref>. Practitioners may not allow sacrificing prediction accuracy for better interpretability. Second, attention mechanism, a widely-used technique to provide inherent interpretability, often cannot provide faithful interpretation <ref type="bibr" target="#b24">(Lipton, 2018)</ref>. The rationale of the attention mechanism is to learn weights for different features during the model training, and the rank of the learned weights can be interpreted as the importance of certain features <ref type="bibr" target="#b2">(Bahdanau et al., 2014;</ref><ref type="bibr">Xu et al., 2015)</ref>. However, recent extensive evaluations in NLP tasks <ref type="bibr" target="#b32">(Serrano &amp; Smith, 2019;</ref><ref type="bibr" target="#b17">Jain &amp; Wallace, 2019;</ref><ref type="bibr" target="#b26">Mohankumar et al., 2020)</ref> have shown that the attention may not weigh the features that dominate the model output more than other features. In particular, for graph learning tasks, the widely-used graph attention models <ref type="bibr" target="#b39">(Veličković et al., 2018;</ref><ref type="bibr" target="#b22">Li et al., 2015)</ref> seem unable to provide any reliable interpretation of the data <ref type="bibr">(Ying et al., 2019;</ref><ref type="bibr">Yu et al., 2020)</ref>.</p><p>In this work, we are to address the above concerns by proposing Graph Stochastic Attention (GSAT), a novel attention mechanism to build inherently interpretable GNNs. The rationale of GSAT roots in the notion of information bottle- that randomly drop the edges and obtain a perturbed graph GS. f θ encodes GS to make predictions. GSAT does not constrain the size of GS but injects stochasticity to constrain information. The subgraph of GS with learnt reduced-stochasticity (edges with pe → 1) provides interpretation. GSAT is a unified model by adopting just one GNN for both g φ and f θ . GSAT can be either trained from scratch or start from a pre-trained GNN predictor f θ . neck (IB) <ref type="bibr" target="#b37">(Tishby et al., 2000;</ref><ref type="bibr" target="#b36">Tishby &amp; Zaslavsky, 2015)</ref>. We formulate the attention as an IB by injecting stochasiticity into the attention to constrain the information flow from the input graph to the prediction <ref type="bibr" target="#b33">(Shannon, 1948)</ref>. Such stochasticity over the label-irrelevant graph components will be kept during the training while that over the label-relevant ones can automatically get reduced. Such difference eventually provides model interpretation.</p><p>Our study achieves the following observations and contributions. First, the IB principle frees GSAT from any potentially biased assumptions adopted in previous methods such as the size or the connectivity constraints on the detected graph patterns. Even when those assumptions are satisfied, GSAT still works the best without using such assumptions. See the sampled interpretation result visualizations in Fig. <ref type="figure" target="#fig_1">2</ref> and Fig. <ref type="figure" target="#fig_2">3</ref>. Second, from the perspective of IB, all post-hoc interpretation methods are sub-optimal. They essentially optimize a model without any information control and then perform a single-step projection to an information-controlled space, which suffers from an initialization issue. Third, by just blocking the task-irrelevant information, GSAT almost does not degenerate the prediction performance and may even achieve better generalization capability. Fourth, if a pre-trained model is provided, GSAT may further improve both of its interpretation and prediction accuracy.</p><p>We evaluate GSAT in terms of both interpretability and label-prediction performance. Experiments over 8 datasets show that GSAT outperforms the state-of-the-art (SOTA) methods by up to 20%↑ in interpretation AUC and 5%↑ in prediction accuracy. Notably, GSAT achieves the SOTA performance on molhiv on OGB <ref type="bibr" target="#b15">(Hu et al., 2020)</ref> among the models that do not use manually-designed expert features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>As preliminaries, we define a few notations and concepts.</p><p>Graph. An attributed graph can be denoted as G = (A, X)   <ref type="bibr" target="#b31">(Schlichtkrull et al., 2021)</ref> (second row) on a motif example, where graphs with three house motifs and graphs with two house motifs represent two classes. Samples may contain disconnected interpretable subgraphs, while GSAT detects them accurately. More details can be found in Appendix D.4.</p><p>where A is the adjacency matrix and X includes node attributes. Let V and E denote the node set and the edge set, respectively. We focus on graph-level tasks: A training set of graphs with their labels (G (i) , Y (i) ), i = 1, ..., n are given, where each sample (G (i) , Y (i) ) is assumed to be IID sampled from some unknown distribution P Y×G = P Y|G P G .</p><p>Label-relevant Subgraphs. A label-relevant subgraph refers to the subgraph G S of the input graph G that mostly indicates the label Y . For example, to determine the solubility of a molecule, the hydroxy group -OH is a positivelabel-relevent subgraph, as if it exists, the molecule is often soluble to the water. Finding label-relevant subgraphs is a common goal of interpretable graph learning.</p><p>Attention Mechanism. Attention mechanism has been widely used in inherently interpretable neural network models for NLP and CV tasks <ref type="bibr" target="#b2">(Bahdanau et al., 2014;</ref><ref type="bibr">Xu et al., 2015;</ref><ref type="bibr" target="#b38">Vaswani et al., 2017)</ref>. However, GNNs with attention <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref> often generate low-fidelity attention weights. As it learns multiple weights for every edge, it is far from trivial to combine those weights with the irregular graph structure to perform graph label-relevant feature selection.</p><p>There are two types of attention models: One normalizes the attention weights to sum to one <ref type="bibr" target="#b2">(Bahdanau et al., 2014)</ref>, while the other learns weights between [0, 1] without normalization <ref type="bibr">(Xu et al., 2015)</ref>. As the counterparts in GNN models, GAT adopts the normalized one <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref> while GGNN adopts the unnormalized one <ref type="bibr" target="#b22">(Li et al., 2015)</ref>. Our method belongs to the second category.</p><p>Graph Neural Networks. GNNs are neural network models that encode graph-structured data into node representations or graph representations. They initialize each node feature representation with its attributes h (0) v = X v and then gradually update it by aggregating representations from its neighbors, i.e., h</p><formula xml:id="formula_0">(l+1) v ← q(h (l) v , {h (l) u |u : (u, v) ∈ E})</formula><p>where q(•) denotes a function implemented by NNs <ref type="bibr" target="#b13">(Gilmer et al., 2017)</ref>. Graph representations are often obtained via an aggregation (sum/mean) of node representations.</p><p>Learning to Explain (L2X). L2X <ref type="bibr" target="#b7">(Chen et al., 2018)</ref>  (1)</p><p>Our model is inspired by L2X. However, as graph features and their interpretable counterparts are in an irregular space without a fixed dimension, directly applying L2X may achieve subpar performance in graph learning tasks. We propose to use information constraint instead in Sec. 3.1.</p><p>Later, we will also use the entropy defined as H(a) − a P(a) log P(a) and the KL-divergence defined as KL(P(a)||Q(a))</p><p>a P(a) log P(a) Q(a) <ref type="bibr" target="#b9">(Cover, 1999)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Graph Learning Interpretation via GIB</head><p>In this section, we will first propose the GIB-based objective for interpretable graph learning and point out the issues of post-hoc GNN interpretation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">GIB-based Objective for Interpretation</head><p>Finding label-relevant subgraphs in graph learning tasks has unique challenges. As for the irregularity of graph structures, graph learning models often have to deal with the input graphs of various sizes. The critical subgraph patterns may be also of different sizes and be highly irregular. Consider the example of molecular solubility again, although the functional groups for positive solubility such as -OH, -NH 2 are of similar sizes, those for negative solubility range from small groups (e.g., -Cl) to extremely large ones (e.g. -C 10 H 9 ). And, a molecule may contain multiple functional groups that determine its properties scattered in the  graph. Given this observation, it is not proper to just mimick the cardinality constraint used for a regular dimension space (Eq. ( <ref type="formula">1</ref>)) and select subgraphs of certain size as done in <ref type="bibr">(Ying et al., 2019)</ref>. Inspired by the graph information bottleneck (GIB) principle <ref type="bibr" target="#b42">(Wu et al., 2020;</ref><ref type="bibr">Yu et al., 2020)</ref>, we propose to use information constraint instead to select label-relevant subgraphs, i.e., solving max</p><formula xml:id="formula_1">G S I(G S ; Y ), s.t. I(G S ; G) ≤ γ, G S ∈ G sub (G) (2)</formula><p>where G sub (G) denotes the set of the subgraphs of G. Note that GIB does not impose any potentially biased constraints such as the size or the connectivity of the selected subgraphs. Instead, GIB uses the information constraint I(G S ; G) ≤ γ to select G S that inherits only the most indicative information from G to predict the label Y by maximizing I(G S ; Y ). As thus, G S provides model interpretation. <ref type="formula">2020</ref>) also considered using GIB to select subgraphs. However, we adopt a fundamentally different mechanism that we will provide a detailed comparison in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yu et al. (</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Issues of Post-hoc GNN Interpretation Methods</head><p>Almost all previous GNN interpretation methods are posthoc, such as GNNExplainer <ref type="bibr">(Ying et al., 2019)</ref>, PGExplainer <ref type="bibr" target="#b25">(Luo et al., 2020)</ref> and GraphMask <ref type="bibr" target="#b31">(Schlichtkrull et al., 2021)</ref>. Given a pre-trained predictor f θ (•) : G → Y, they try to find out the subgraph G S that impacts the model predictions the most, while keeping the pre-trained model where Ω implies a subset of the subgraphs G sub (G) that satisfy some constraints, e.g., the cardinality constraint adopted by GNNExplainer and PGExplainer. Let us temporarily ignore the difference between different constraints and just focus on the optimization objective. The post-hoc objective Eq. (4) and GIB (Eq. ( <ref type="formula">2</ref>)) share some similar spirits. However, the post-hoc methods may not give or even approximate the optimal solution to Eq. (2) because f θ • g φ GSAT is trained with 10 different random seeds. And for post-hoc methods, we pre-train 10 models with different random seeds and run these methods on each model. Interpretation performance and the training losses of Eq. 2 for GSAT and Eq. 4 for others are shown. Note that we guarantee that all the pre-trained models achieve good performance in their pre-training stage (Acc.∼100% Ba-2Motif, ∼90% Mutag).</p><p>is not jointly trained. From the optimization perspective, post-hoc methods just perform one-single step projection (see Fig. <ref type="figure" target="#fig_5">4</ref>) from the model f θ in an unconstrained space to f θ • g φ in the information-constrained space Ω where the projection rule follows that the induced MI decrease</p><formula xml:id="formula_2">I(f θ (G); Y ) − I(f θ (g φ(G)); Y ) gets minimized.</formula><p>In practice, such a suboptimal behavior will yield two undesired concequences. First, f θ may not fully extract the information from G S = g φ (G) to predict Y during the optimization of Eq. ( <ref type="formula">4</ref>) because f θ is originally trained to make</p><formula xml:id="formula_3">I(f θ (G); Y ) approximate I(G, Y ) while (G S , Y ) = (g φ (G), Y ) follows a distribution different from (G, Y ).</formula><p>Therefore, I(f θ (G S ); Y ) may not well approximate I(G S ; Y ), and thus may mislead the optimization of g φ and disable g φ to select G S that indeed indicates Y . GN-NExplainer suffers from this issue over Ba-2Motif as shown in Fig. <ref type="figure" target="#fig_6">5</ref>: The training loss, −I(f θ (G S ); Y ) keeps high and the interpretation performance is subpar. It is possible to further decrease the training loss via a more aggressive optimization of g φ . However, the models may risk overfitting the data, which yields the second issue.</p><p>An aggressive optimization of g φ may give a large empirical MI Î f θ (g φ (G)); Y (or a small training loss equivalently) by selecting features that help to distinguish labels for training but are essentially label-irrelevant in the population level. Previous works have shown that label-irrelevant features are known to be discriminative enough to even identify each graph in the training dataset let alone the labels <ref type="bibr" target="#b35">(Suresh et al., 2021)</ref>. Empirically, we indeed observe such overfitting problems of all post-hoc methods over Mutag as shown in Fig. <ref type="figure" target="#fig_6">5</ref>, especially PGExplainer and GraphMask. In the first 5 to 10 epochs, these two models succeed in selecting good explanations while having a large training loss. Further training successfully decreases the loss (after 10 epochs) but degenerates the interpretation performance substantially. This might also be the reason why in the original literatures of these post-hoc methods, training over only a small number of epochs is suggested. However, in practical tasks, it is hard to have the ground truth interpretation labels to verify the results and decide a trusty stopping criterion.</p><p>Another observation of Fig. <ref type="figure" target="#fig_6">5</ref> also matches our expectation: From the optimization perspective, post-hoc methods suffer from an initialization issue. Their interpretation performance can be highly sensitive to the pre-trained model f θ , as empirically demonstrated by the large variances in Fig. <ref type="figure" target="#fig_6">5</ref>. Only if the pre-trained f θ approximates the optimal f θ * , the performance can be roughly guaranteed. Therefore, a joint training of f θ • g φ according to the GIB principle Eq. ( <ref type="formula">2</ref>) is typically needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Stochastic Attention Mechanism for GIB</head><p>In this section, we will first give a tractable variational bound of the GIB objective (Eq. ( <ref type="formula">2</ref>)), and then introduce our model GSAT with the stochastic attention mechanism. We will further discuss how the stochastic attention mechanism improves both model interpretation and generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">A Tractable Objective for GIB</head><p>GSAT is to learn an extractor g φ with parameter φ to extract G S ∈ G sub (G). g φ blocks the label-irrelevant information in the data G via injected stochasticity while allowing the label-relevant information kept in G S to make predictions. In GSAT, g φ (G) essentially gives a distribution over G sub (G). We also denote this distribution as P φ (G S |G).</p><p>Later, g φ (G) and P φ (G S |G) are used interchangeably.</p><p>Putting the constraint into the objective (Eq.( <ref type="formula">2</ref>)), we obtain the optimization of g φ via GIB, i.e., for some β &gt; 0, We obtain a lower bound:</p><formula xml:id="formula_4">min φ −I(G S ; Y ) + βI(G S ; G), s.t. G S ∼ g φ (G).</formula><formula xml:id="formula_5">I (G S ; Y ) ≥ E G S ,Y [log P θ (Y |G S )] + H(Y ). (6)</formula><p>Note that P θ (Y |G S ) essentially works as the predictor f θ : G → Y with parameter θ in our model. For the term I(G S ; G), we introduce a variational approximation Q(G S ) for the marginal distribution P(G S ) = G P φ (G S |G)P G (G). And, we obtain an upper bound:</p><formula xml:id="formula_6">I (G s ; G) ≤ E G [KL(P φ (G S |G)||Q(G S ))]<label>(7)</label></formula><p>Plugging in the above two inequalities, we obtain a variational upper bound of Eq. ( <ref type="formula">5</ref>) as the objective of GSAT:</p><formula xml:id="formula_7">min θ,φ −E [log P θ (Y |G S )] + βE [KL(P φ (G S |G)||Q(G S ))] , s.t. G S ∼ P φ (G S |G).<label>(8)</label></formula><p>Next, we specify P θ (aka f θ ), P φ (aka g φ ) and Q in GSAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">GSAT and Stochastic Attention Mechanism</head><p>For clarity, we introduced the predictor f θ and the extractor g φ separately. Actually, GSAT is a unified model as f θ , g φ share the same GNN encoder except their last layers.</p><p>Stochastic Attention via P φ . The extractor g φ first encodes the input graph G via the GNN into a set of node representations {h v |v ∈ V }. For each edge (u, v) ∈ E, g φ contains an MLP layer plus sigmoid that maps the concatenation</p><formula xml:id="formula_8">(h u , h v ) into p uv ∈ [0, 1].</formula><p>Then, for each forward pass of the training, we sample stochastic attention from Bernoulli distributions α uv ∼ Bern(p uv ). To make sure the gradient w.r.t. p uv is computable, we apply the gumbelsoftmax reparameterization trick <ref type="bibr" target="#b18">(Jang et al., 2017)</ref>. The extracted graph G S will have an attention-selected subgraphs as A S = α A. Here α is the matrix with entries α uv for (u, v) ∈ E or zeros for the non-edge entries. A is the adjacency matrix of G and is entry-wise product. The distribution of G S given G through the above procedure characterizes P φ (G S |G), so P φ (G S |G) = u,v∈E P(α uv |p uv ), where p uv is a function of G.</p><p>Prediction via P θ . The predictor f θ adopts the same GNN to encode the extracted graph G S to a graph representation, and finally passes such representation through an MLP layer plus softmax to model the distribution of Y . This procedure gives the variational distribution P θ (Y |G S ).</p><p>Marginal Distribution Control via Q. The bound Eq.( <ref type="formula" target="#formula_6">7</ref>) is always true for any Q(G S ). We define Q(G S ) as follows.</p><p>For every graph G ∼ P G and every two directed node pair (u, v) in G, we sample α uv ∼ Bern(r) where r ∈ [0, 1] is a hyperparameter. We remove all edges in G and add all edges (u, v) if α uv = 1. Suppose the obtained graph is G S . This procedure defines the distribution</p><formula xml:id="formula_9">Q(G S ) = G P(α |G)P G (G). As α is independent from the graph G given its size n, Q(G S ) = n P(α |n)P G (G = n) = P(n) n u,v=1 P(α uv ).</formula><p>The probability of an n-sized graph P(n) is a constant and thus will not affect the model.</p><p>Using the above P θ , the first term in Eq.( <ref type="formula" target="#formula_7">8</ref>) reduces to a standard cross entropy loss. Using P φ and Q, the KL-divergence term becomes, for every G ∼ P G , n as the size of G,</p><formula xml:id="formula_10">KL(P φ (G S |G)||Q(G S )) = (9) (u,v)∈E p uv log p uv r + (1 − p uv ) log 1 − p uv 1 − r + c(n, r).</formula><p>where c(n, r) is a constant without any trainable parameters.</p><p>Note that GSAT is substantially different from the previous methods, as we do not use any sparisity constraints such as 1 -norm <ref type="bibr">(Ying et al., 2019;</ref><ref type="bibr" target="#b25">Luo et al., 2020)</ref>, 0 -norm <ref type="bibr" target="#b31">(Schlichtkrull et al., 2021)</ref> or 2 -regression to {0, 1} (Yu et al., 2020) to select size-constrained (or connectivity-constrained) subgraphs. We actually observe that setting r away from 0 in the marginal regularization (Eq. ( <ref type="formula">9</ref>)), i.e., pushing G S away from being sparse often provides more robust interpretation. This matches our intuition that GIB by definition does not make any assumptions on the selected subgraphs but just constrains the information from the original graphs. Our experiments show that GSAT outperform baselines significantly without leveraging those assumptions in the optimization even if the label-relevant subgraphs satisfy these assumptions. If the label-relevant subgraphs are indeed disconnected or vary in sizes, the improvement of GSAT is expected to be even more.</p><p>Our interpretation essentially comes from the information control: GSAT decreases the information from the input graphs by injecting stochasticity via attention into G S . In the training, driven by the term max I(G S , Y ), GSAT can learn to automatically reduce such stochasticity of the attention on the task-relevant subgraphs. So, it is not the entire G S but the part of G S with the stochasticity-reduced attention, aka p uv → 1, that provide model interpretation. Therefore, when GSAT provides interpretation, we rank all edges according to p uv and use those top ranked ones (given a certain budget) as the detected subgraph for interpretation. The contribution of injecting stochasticity to the performance is so significant as shown in experiments (Table <ref type="table" target="#tab_4">4</ref>), so is the contribution of our regularization term (Eq. ( <ref type="formula">9</ref>)) when we compare it with the sparsity-driven 1 -norm (Fig. <ref type="figure">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Further Comparison on Interpretation Mechanism</head><p>PGExplainer and GraphMask also have stochasticity in their models <ref type="bibr" target="#b25">(Luo et al., 2020;</ref><ref type="bibr" target="#b31">Schlichtkrull et al., 2021)</ref>. However, their main goal is to enable a gradient-based search over a discrete subgraph-selection space rather than control the information as GSAT does. Hence, they did not in principle derive the informatic regularization as ours (Eq. ( <ref type="formula">9</ref>)) but adopt sparsity constraints.</p><p>IB-subgraph (Yu et al., 2020) considers using GIB as the objective but does not inject any stochasticity, so its se-lected subgraph G S is a deterministic function of G. In this case I(G S ; G)(= H(G S ) − H(G S |G)) reduces to the entropy H(G S ). Therefore, IB-subgraph is actually to control H(G S ), which tends to give a small-sized G S , because the space of small graphs is small and has a lower upper bound of the entropy. In contrast, GSAT implements GIB mainly by increasing H(G S |G) via injecting stochasticity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Better Generalization Performance via GSAT</head><p>Although our main goal is for model interpretation, GSAT is also possible to achieve better generalization, by capturing only label-relevant information. We may prove that if there exists a correspondence between a subgraph pattern G *</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S</head><p>and the label Y , the optimal solution of the GIB objective (Eq. ( <ref type="formula">2</ref>)) will detect that subgraph pattern (Thm. 4.1).</p><formula xml:id="formula_11">Theorem 4.1. Suppose each G contains a subgraph G * S such that Y is determined by G * S in the sense that Y = f (G * S ) + for some deterministic invertible function f with randomness that is independent from G. Then, G S = G * S maximizes GIB I (G S ; Y ) − βI (G S ; G) for all β ∈ [0, 1].</formula><p>This indicates that GSAT by optimizing the GIB objective also has the capability to address the correlation shift issue <ref type="bibr" target="#b27">(Pearl et al., 2016;</ref><ref type="bibr" target="#b1">Arjovsky et al., 2019;</ref><ref type="bibr" target="#b6">Chang et al., 2020)</ref>: Although G * S uniquely determines Y , in the training dataset the data G and Y may have some spurious correlation caused by the environment, i.e., G\G * S (illustrated in Fig. <ref type="figure">6</ref>). Training a model over G to predict Y via just MI maximization may capture such spurious correlation. In the testing dataset, if such correlation is changed, the obtained model suffers from performance decay. However, GSAT may avoid that by only extracting G * S .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Fine-tuning and Interpreting a Pre-trained Model</head><p>GSAT can also fine-tune and interpret a pre-trained GNN. Given a GNN f θ pre-trained by</p><formula xml:id="formula_12">max θ I(f θ (G); Y ), GSAT can fine-tune it via max θ,φ I(f θ (G S ); Y ) − βI(G S ; G), G S ∼ g φ (G</formula><p>) by initializing the GNN used in g φ and f θ as the one in the pre-trained model f θ .</p><p>We observe that this framework almost never hurts the original prediction performance (and sometimes even boosts it). Moreover, this framework often achieves better interpretation results compared with training the GNN from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Other Related Works</head><p>Besides the models <ref type="bibr">(Ying et al., 2019;</ref><ref type="bibr" target="#b25">Luo et al., 2020;</ref><ref type="bibr" target="#b31">Schlichtkrull et al., 2021;</ref><ref type="bibr">Yu et al., 2020)</ref> that we have compared with in detail in Sec. 3.2 and Sec. 4.3, we review some other interpretation methods here.</p><p>Most previous works on GNN interpretation are postdoc <ref type="bibr" target="#b30">(Ribeiro et al., 2016)</ref>. Some works strongly rely on </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>We evaluate our method from both interpretability and prediction performance<ref type="foot" target="#foot_0">1</ref> . We will compare our method with both state-of-the-art (SOTA) post-hoc interpretation methods and inherently interpretable models. We briefly introduce the datasets, the baselines and the experiment settings here, and more details can be found in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Datasets</head><p>Mutag <ref type="bibr" target="#b11">(Debnath et al., 1991)</ref> is a molecular property prediction dataset. Following <ref type="bibr" target="#b25">(Luo et al., 2020)</ref>, -NO 2 and -NH 2 in mutagen graphs are labeled as ground-truth explanations.</p><p>BA-2Motifs <ref type="bibr" target="#b25">(Luo et al., 2020</ref>) is a synthetic dataset with binary graph labels. House motifs and cycle motifs give class labels and thus are regarded as ground-truth explanations for the two classes respectively.</p><p>Spurious-Motif <ref type="bibr" target="#b43">(Wu et al., 2022</ref>) is a synthetic dataset with three graph classes. Each class contains a particular motif that can be regarded as the ground-truth explanation. Some spurious correlation between the rest graph components (other than the motifs) and the labels also exists in the training data. The degree of such correlation is controlled by b, and we include datasets with b = 0.5, 0.7 and 0.9.</p><p>MNIST-75sp <ref type="bibr" target="#b21">(Knyazev et al., 2019</ref>) is a image classifica- Graph-SST2 <ref type="bibr" target="#b34">(Socher et al., 2013;</ref><ref type="bibr">Yuan et al., 2020b</ref>) is a sentiment analysis dataset, where each text sequence in SST2 is converted to a graph. Following the splits in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref>, this dataset contains degree shifts and no ground-truth explanation labels. So, we only evaluate prediction performance and provide interpretation visualizations.</p><p>OGBG-Molhiv <ref type="bibr" target="#b44">(Wu et al., 2018;</ref><ref type="bibr" target="#b15">Hu et al., 2020</ref>) is a molecular property prediction datasets. We also evaluate GSAT on molbace, molbbbp, molclintox, moltox21 and molsider datasets from OGBG. As there are no ground truth explanation labels for these datasets, we only evaluate the prediction performance of GSAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Baselines and Setup</head><p>Interpretability Baselines. We compare interpretability with post-hoc methods GNNExplainer (Ying et al., 2019), PGExplainer <ref type="bibr" target="#b25">(Luo et al., 2020)</ref>, GraphMask <ref type="bibr" target="#b31">(Schlichtkrull et al., 2021)</ref>, and inherently interpretable models DIR <ref type="bibr" target="#b43">(Wu et al., 2022)</ref> and <ref type="bibr">IB-subgraph (Yu et al., 2020)</ref>.</p><p>Prediction Baselines. We compare prediction performance with the backbone models GIN <ref type="bibr">(Xu et al., 2019)</ref> and PNA <ref type="bibr" target="#b8">(Corso et al., 2020)</ref>, and inherently interpretable models DIR <ref type="bibr" target="#b43">(Wu et al., 2022)</ref> and <ref type="bibr">IB-subgraph (Yu et al., 2020)</ref>.</p><p>Metrics. For interpretation evaluation, we report explanation ROC AUC following <ref type="bibr">(Ying et al., 2019;</ref><ref type="bibr" target="#b25">Luo et al., 2020)</ref>. For prediction performance, we report classification ROC AUC for all OGBG datasets and report accuracy for all other datasets. All the results are averaged over 10 times tests with different random seeds. For the post-hoc methods, we do not cherry pick a pre-trained model. Instead, in each test, we interpret a model pre-trained independently that achieves the best validation performance.</p><p>Setup. Since we focus on graph classification tasks, GIN <ref type="bibr">(Xu et al., 2019)</ref> is used as the backbone model for both baselines and GSAT. We also apply PNA <ref type="bibr" target="#b8">(Corso et al., 2020)</ref> to further test the wide applicability of GSAT, for which we adopt the no-scalars version since the scalars used in PNA are essentially a type of attention, which may conflict with our method. In addition, we apply GSAT to fine-tune and interpret pre-trained models as described in Sec. 4.5, which is highlighted as GSAT * . As some baselines adopted other backbone models in their original literature, we also evaluate GSAT on those backbone models in Appendix. D.4. In all the experiments, we use r = 0.7 in Eq. ( <ref type="formula">9</ref>) by default or otherwise specified. Our studies have shown that GSAT is generally robust when r ∈ [0.5, 0.9] (see Fig. <ref type="figure">7</ref> later).  <ref type="bibr" target="#b25">(Luo et al., 2020)</ref> as we do not cherry pick the pre-trained model. However, GSAT still significantly outperforms their reported performance in the Appendix D.4. We also provide visualizations of the subgraphs discovered by GSAT in Appendix E.</p><p>Prediction Results. As explained in Sec. 4.4, being trained via the GIB principle, GSAT is more generalizable and thus may achieve even better prediction performance. As shown in Table <ref type="table" target="#tab_2">2</ref>, GIN+GSAT significantly outperforms the backbone GIN over the Spurious-Motif datasets, where spurious correlation exists in the training data. For other datasets, GIN+GSAT can achieve comparable results, which matches our claim that GSAT provides interpretation without hurting the prediction. IB-subgraph, trained via the GIB principle, also achieves good prediction performance though its interpretability is poor (Table <ref type="table" target="#tab_1">1</ref>). When PNA is used, GSAT improves it by about 1 − 5% on the datasets in the first three columns. Notably, GSAT * achieves the SOTA performance on molhiv among all models that do not incorporate expert knowledge according to the leaderboard. Unexpectedly, PNA achieves very good performance on Spurious-Motif and GSAT * just slightly improves it. Our results on the other 5 molecular datasets from OGBG are showed in Table <ref type="table" target="#tab_3">3</ref>, where GSAT and GSAT * mostly outperform PNA.</p><p>We note that DIR achieves a bit lower performance than what reported in <ref type="bibr" target="#b43">(Wu et al., 2022</ref>) even after we extensively tune its parameters, which is probably due to the different backbone models used. Hence, we also compare with DIR by using their backbone model. Results are shown in Table <ref type="table" target="#tab_9">6</ref> on interpretation and Table <ref type="table">7</ref> on prediction in the appendix. GSAT still significantly outperforms DIR.</p><p>Ablation Studies. We conduct ablation studies from three Info. Constraint (Eq.9)</p><p>1 Norm Regularization 0.9/1e-5 0.8/1e-4 0.7/5e-4 0.6/1e-3 0.5/5e-3 0.4/1e-2 0.3/5e-2 0.2/1e-1 0.1/1 r/λ1 Info. Constraint (Eq.9)</p><p>1 Norm Regularization</p><p>Figure <ref type="figure">7</ref>. Comparison between (a) using the information constraint in Eq. ( <ref type="formula">9</ref>) and (b) replacing it with 1-norm. Results are shown for Spurious-Motif b = 0.5, where r is tuned from 0.9 to 0.1 and the coefficient of the 1-norm λ1 is tuned from 1e-5 to 1.</p><p>aspects: First, the importance of stochasticity in GSAT, where we replace the Bernoulli sampling procedure with setting attention α uv = p uv without stochasticity; Second, the importance of the information regularization term (Eq. ( <ref type="formula">9</ref>)), where we set its coefficient β = 0 in Eq. ( <ref type="formula" target="#formula_7">8</ref>); Third, the superiority of the information regularization term over the sparsity-driven term 1 -norm. As shown in Table <ref type="table" target="#tab_4">4</ref>, the performance drops significantly when there is either no stochasticity or β = 0. No stochasticity yields the biggest drop, which well matches our theory. This also implies that directly using the deterministic attention mechanisms such as GAT <ref type="bibr" target="#b39">(Veličković et al., 2018)</ref> or GGNN <ref type="bibr" target="#b22">(Li et al., 2015)</ref> may not yield good model interpretation.</p><p>Fig. <ref type="figure">7</ref> shows that our information regularization term can achieve consistently better performance than the sparsitydriven 1 -norm regularization even when the grid search is used to tune hyperparameters. We also observe that when r is close to 0, the results often get decreased or have higher variance. The best performance is often achieved when r ∈ [0.5, 0.9], which matches our theory. More results on other datasets can be found in Fig. <ref type="figure" target="#fig_12">8</ref> in the appendix. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supplementary Notations for Information Theory and Graph Neural Networks</head><p>Entropy. Given a discrete random variable a, its entropy is defined as H(a) − a P(a) log P(a). If a is a continuous random variable, its differential entropy is defined as H(a) − a P(a) log P(a)da.</p><p>KL-Divergence. Given two distributions P(x) and Q(x), KL-Divergence is used to measure the difference between P and Q, and it is defined as KL(P(x)||Q(x))</p><p>x P(x) log P(x) Q(x) . Mutual Information. Given two random variables a and b, the mutual information (MI) I(a; b) is a measure of the mutual dependence between them. MI quantifies the amount of information regarding one random variable if another random variable is known. Formally, I(a; b) Graph Neural Networks (GNNs). Given an L-layer GNN, let h (l) v denote the node representation for node v in the i th layer and N (v) denote a set of nodes adjacent to node v. Let h (0) v be the node feature X v . Most GNNs follow a message passing scheme, where there are two main steps in each layer: (1) neighbourhood aggregation, m</p><formula xml:id="formula_13">(l) v = AGG({h (l−1) u |u ∈ N (v)}); (2) node representation update, h (l) v = UPDATE(m (l) v , h (l−1) v</formula><p>). For graph classification tasks, after obtaining h (L) v for each node, the graph representation is given by h G = POOL({h</p><formula xml:id="formula_14">(L) v |v ∈ V })</formula><p>and h G will be used to make predictions. The above AGG, UPDATE, POOL are three functions. AGG and POOL are typically implemented via SUM, MEAN and MAX while UPDATE is a fully connected (typically shallow) neural network. In some cases, edge representations may be in need, and they are often given by h</p><formula xml:id="formula_15">(l) u,v = CONCAT(h (l) u , h (l) v ).</formula><p>B. Variational Bounds for The GIB Objective -Eq. (6) and Eq. (7) From Eq. ( <ref type="formula">5</ref>), the IB objective is:</p><formula xml:id="formula_16">min φ −I(G S ; Y ) + βI(G S ; G), s.t. G S ∼ g φ (G).<label>(10)</label></formula><p>To optimize it, we introduce two variational bounds on the two terms, respectively.</p><p>For the first term I (G S ; Y ), by definition:</p><formula xml:id="formula_17">I (G S ; Y ) = E G S ,Y log P(Y |G S ) P(Y ) .<label>(11)</label></formula><p>Since P(Y |G S ) is intractable, we introduce a variational approximation P θ (Y |G S ) for it. Then, we obtain a lower bound for Eq. ( <ref type="formula">6</ref>):</p><formula xml:id="formula_18">I (G S ; Y ) = E G S ,Y log P θ (Y |G S ) P(Y ) + E G S [KL(P(Y |G S )||P θ (Y |G S ))] ≥ E G S ,Y log P θ (Y |G S ) P(Y ) = E G S ,Y [log P θ (Y |G S )] + H(Y ).<label>(12)</label></formula><p>For the second term I (G; G S ), by definition:</p><formula xml:id="formula_19">I (G; G S ) = E G S ,G log P(G S |G) P(G S ) . (<label>13</label></formula><formula xml:id="formula_20">)</formula><p>Since P(G S ) is intractable, we introduce a variational approximation Q(G S ) for the marginal distribution P(G S ) = G P φ (G S |G)P G (G). Then, we obtain an upper bound for Eq. ( <ref type="formula" target="#formula_6">7</ref>):</p><formula xml:id="formula_21">I (G; G S ) = E G S ,G log P φ (G S |G) Q(G S ) − KL (P(G S )||Q(G S )) ≤ E G [KL (P φ (G S |G)||Q(G S ))] .<label>(14)</label></formula><p>C. Proof of Theorem 4.1</p><p>Theorem C.1. Suppose each G contains a subgraph G * S such that Y is determined by G * S in the sense that Y = f (G * S ) + for some deterministic invertible function f with randomness that is independent from G. Then, for any β ∈</p><formula xml:id="formula_22">[0, 1], G S = G * S maximizes the GIB I (G S ; Y ) − βI (G S ; G), where G S ∈ G sub (G).</formula><p>Proof. Let G S ∈ G sub (G). Consider the following derivation,</p><formula xml:id="formula_23">I(G S ; Y ) − βI(G S ; G) = I(Y ; G, G S ) − I(G; Y |G S ) − βI(G S ; G) = I(Y ; G, G S ) − (1 − β)I(G; Y |G S ) − βI(G; G S , Y ) = I(Y ; G) − (1 − β)I(G; Y |G S ) − βI(G; G S , Y ) = I(Y ; G) − (1 − β)I(G; Y |G S ) − βI(Y ; G) − βI(G; G S |Y ) = (1 − β)I(Y ; G) − (1 − β)I(G; Y |G S ) − βI(G; G S |Y )</formula><p>where the third equality is because G S ∈ G sub (G) so (G S , G) holds no more information than G.</p><formula xml:id="formula_24">If β ∈ [0, 1], G S that maximizes I(G S , Y ) − βI(G S ; G) also minimizes (1 − β)I(G; Y |G S ) + βI(G; G S |Y ). As I(G; Y |G S ) ≥ 0, I(G; G S |Y ) ≥ 0, so the lower bound of (1 − β)I(G; Y |G S ) + βI(G; G S |Y ) is 0. G * S is the subgraph that makes (1 − β)I(G; Y |G * S ) + βI(G; G * S |Y ) = 0. This is because (a) Y = f (G * S ) + where is independent of G so I(G; Y |G * S ) = 0 and (b) G * S = f −1 (Y − ) where is independent of G so I(G; G * S |Y ) = 0. Therefore, G S = G * S maximizes GIB I (G S ; Y ) − βI (G S ; G), where G S ∈ G sub (G).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Supplementary Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Details of the Datasets</head><p>Mutag <ref type="bibr" target="#b11">(Debnath et al., 1991)</ref> is a molecular property prediction dataset, where nodes are atoms and edges are chemical bonds. Each graph is associated with a binary label based on its mutagenic effect. Following <ref type="bibr" target="#b25">(Luo et al., 2020)</ref>, -NO 2 and -NH 2 in mutagen graphs are labeled as ground-truth explanations.</p><p>BA-2Motifs <ref type="bibr" target="#b25">(Luo et al., 2020</ref>) is a synthetic dataset, where the base graph is generated by Barabási-Albert (BA) model. Each base graph is attached with a house-like motif or a five-node cycle motif. House motifs and cycle motifs give class labels and thus are regarded as ground-truth explanations for the two classes respectively.</p><p>Spurious-Motif <ref type="bibr" target="#b43">(Wu et al., 2022</ref>) is a synthetic dataset with three graph classes. Following the notations in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref>, each graph consists of a base graph (tree/ladder/wheel denoted by ḠS = 0, 1, 2 respectively, with some abuse of notations) and a motif (cycle/house/crane denoted by G S = 0, 1, 2, respectively, with some abuse of notations). The label is determined only by G S , while there also exists spurious correlation between the label and ḠS . Specifically, to construct a graph in the training set, G S will be sampled uniformly, while ḠS will be sampled with probability P( ḠS ), where</p><formula xml:id="formula_25">P( ḠS ) = b if ḠS = G S ; otherwise P( ḠS ) = (1 − b)/2.</formula><p>So, b is a parameter used to control the degree of such spurious correlation. When b = 1/3, there is no spurious correlation. We include datasets with b = 0.5, b = 0.7 and b = 0.9. Note that for testing data, the motifs and bases are randomly attached to each other, which can test if the model overfits the spurious correlation.</p><p>MNIST-75sp <ref type="bibr" target="#b21">(Knyazev et al., 2019)</ref> is a image classification dataset, where each image in MNIST is converted to a superpixel graph. Each node in the graph represents a superpixel and edges are formed based on spatial distance between superpixel centers. Node features are the coordinates of their centers of masses. Nodes with nonzero pixel values provide ground-truth explanations. Note that the subgraphs that provide explanations are of different sizes in this dataset.</p><p>Graph-SST2 <ref type="bibr" target="#b34">(Socher et al., 2013;</ref><ref type="bibr">Yuan et al., 2020b)</ref> is a sentiment analysis dataset, where each text sequence in SST2 is converted to a graph. Each node in the graph represents a word and edges are formed based on relationships between different words. We follow the dataset splits in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref> to create degree shifts in the training set, which can better test generalizability of models. Specifically, graphs with higher average node degree will be used to train and validate models, while graphs with fewer nodes will be used to test models. And this dataset contains no ground-truth explanation labels, so we only evaluate prediction performance here and provide interpretation visualizations in Appendix E.</p><p>OGBG-Molhiv <ref type="bibr" target="#b44">(Wu et al., 2018;</ref><ref type="bibr" target="#b15">Hu et al., 2020)</ref> is a molecular property prediction datasets, where nodes are atoms and edges are chemical bonds. A binary label is assigned to each graph according to whether a molecule inhibits HIV virus  <ref type="table" target="#tab_9">6</ref>. Direct comparison with the interpretation precision@5 of DIR reported in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref> based on the backbone model in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref>. As there are no ground truth explanation labels for these datasets, we only evaluate the prediction performance of GSAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPURIOUS-MOTIF</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Details on Hyperparameter Tuning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.1. BACKBONE MODELS</head><p>Backbone Architecture. We use a two-layer GIN <ref type="bibr">(Xu et al., 2019)</ref> with 64 hidden dimensions and 0.3 dropout ratio. We use the setting from <ref type="bibr" target="#b8">(Corso et al., 2020)</ref> for PNA, which has 4 layers with 80 hidden dimensions, 0.3 dropout ratio, and no scalars are used. For OGBG-Mol datasets, we directly follow <ref type="bibr" target="#b8">(Corso et al., 2020)</ref> using (mean, min, max, std) aggregators for PNA; yet we find PNA has convergence issues on other datasets when sum aggregator is not used. Hence, PNA uses (mean, min, max, std, sum) aggregators for all other datasets.</p><p>Dataset Splits. For Ba-2Motifs, we split it randomly into three sets (80%/10%/10%). For Mutag, we split it randomly into 80%/20% to train and validate models, and following <ref type="bibr" target="#b25">(Luo et al., 2020)</ref> we use mutagen molecules with -NO 2 or -NH 2 as test data (because only these samples have explanation labels). For MNIST-75sp, we use the default splits given by <ref type="bibr" target="#b21">(Knyazev et al., 2019)</ref>; due to its large size in the graph setting, we also reduce the number of training samples following <ref type="bibr" target="#b43">(Wu et al., 2022)</ref> to speed up training. For Graph-SST2, Spurious-Motifs and OGBG-Mol, we use the default splits given by <ref type="bibr">(Yuan et al., 2020b)</ref> and <ref type="bibr" target="#b43">(Wu et al., 2022)</ref>. Following <ref type="bibr" target="#b8">(Corso et al., 2020)</ref>, edge features are not used for all OGBG-Mol datasets.</p><p>Epoch. We tune the number of epochs to make sure the convergence of all models. When GIN is used as the backbone model, MNIST-75sp and OGBG-Molhiv are trained for 200 epochs, and all other datasets are trained for 100 epochs. When PNA is used, Mutag and Ba-2Motifs are trained for 50 epochs and all other datasets are trained for 200 epochs. We report the performance of the epoch that achieves the best validation prediction performance and use the models that achieve such best validation performance as the pre-trained models. When multiple epochs achieve the same best performance, we report the one with the lowest validation prediction loss.</p><p>Batch Size. All datasets use a batch size of 128; except for MNIST-75sp we use a batch size of 256 to speed up training due to its large size in the graph setting.</p><p>Learning Rate. GIN uses 0.003 learning rate for Spurious-Motifs and 0.001 for all other datasets. PNA uses 0.01 learning rate with scheduler following <ref type="bibr" target="#b8">(Corso et al., 2020)</ref>, 0.003 learning rate for Graph-SST2 and Spurious-Motifs, and 0.001</p><p>Table <ref type="table">7</ref>. Direct comparison with the prediction accuracy of DIR reported in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref> based on the backbone model in <ref type="bibr" target="#b43">(Wu et al., 2022)</ref>. Learning Rate. When PNA is used, GSAT uses 0.001 learning rate for all OGBG-Mol datasets; otherwise it uses the same learning rate as mentioned above. r in Equation ( <ref type="formula">9</ref>). Ba-2Motif and Mutag use r = 0.5, and all other datasets use r = 0.7. We find r = 0.7 can generally provide great performance for all datasets. Inspired by curriculum learning <ref type="bibr" target="#b5">(Bengio et al., 2009)</ref>, r will initially set to 0.9 and gradually decay to the tuned value. We adopt a step decay, where r will decay 0.1 for every 10 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPURIOUS-MOTIF</head><formula xml:id="formula_26">b = 0.5 b = 0.7 b =</formula><p>β in Equation (8). β is not tuned and is set to<ref type="foot" target="#foot_1">1</ref> |E| for all datasets. Temperature. Temperature used in the Gumbel-softmax trick <ref type="bibr" target="#b18">(Jang et al., 2017)</ref> is not tuned, and we use 1 for all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.3. BASELINE INTERPRETABLE METHODS/MODELS</head><p>Basic Setting. If not specified, baselines use the same settings mentioned for the backbone models.</p><p>GNNExplainer. We tune the learning rate from (1, 0.1, 0.01, 0.001) and the coefficient of the 1 -norm from (0.1, 0.01, 0.001), based on validation interpretation ROC AUC. The coefficient of the entropy regularization term is set to the recommended value 1. Again, in a real-world setting, post-hoc methods have no clear metric to tune hyper-parameters.</p><p>PGExplainer. We use the tuned recommended settings from <ref type="bibr" target="#b25">(Luo et al., 2020)</ref>, including the temperature, the coefficient of 0.9/1e-5 0.8/1e-4 0.7/5e-4 0.6/1e-3 0.5/5e-3 0.4/1e-2 0.3/5e-2 0.2/1e-1 0.1/1 r/λ1 Info. Constraint (Eq.9)</p><p>1 Norm Regularization 0.9/1e-5 0.8/1e-4 0.7/5e-4 0.6/1e-3 0.5/5e-3 0.4/1e-2 0.3/5e-2 0.2/1e-1 0.1/1 r/λ1 Info. Constraint (Eq.9)</p><p>1 Norm Regularization 0.9/1e-5 0.8/1e-4 0.7/5e-4 0.6/1e-3 0.5/5e-3 0.4/1e-2 0.3/5e-2 0.2/1e-1 0.1/1 r/λ1  <ref type="formula">9</ref>) and (2) replacing it with 1-norm, where r is tuned from 0.9 to 0.1 and the coefficient of the 1-norm λ1 is tuned from 1e-5 to 1.</p><p>and the coefficient of 0 -norm regularization.</p><p>DIR. Causal ratio is tuned for Ba-2Motif and Mutag. Since the other datasets we use are the same, we use the recommended settings from <ref type="bibr" target="#b43">(Wu et al., 2022)</ref>. However, even though datasets are the same, we find the same α specified in their source code do not work well in our setting. Hence, we tune α from (10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001).</p><p>IB-subgraph. Due to the extreme inefficiency of IB-subgraph, we are only able to tune its mi-weight around the recommended value from (2, 0.2, 0.02). And we use the default inner loop iterations and con-weight as specified in their source code. IB-subgraph needs ∼40 hours to train 100 epochs for 1 seed on Spurious-Motif and ∼150 hours for OGBG-Molhiv on a Quadro RTX 6000.</p><p>Random Seed. All methods are trained with 10 different random seeds; except for IB-subgraph we train it for 5 different random seeds due to its inefficiency. For post-hoc methods, the pre-trained models are also trained with 10 different random seeds instead of a fixed pre-trained model in <ref type="bibr" target="#b25">(Luo et al., 2020)</ref>. For inherently interpretable models, GSAT, IB-subgraph and DIR, we average the best epoch's performance according to their validation prediction performance. For post-hoc baselines, we average their last epoch's performance. For IB-subgraph, we stop training when there is no improvement over 20 epochs to make the training possible on large datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. Node/Edge Attention</head><p>We also explore node-level attention, and we find it is especially useful for molecular datasets and datasets with large graph sizes. Hence, we use node-level attention for on Mutag, MNIST-75sp and OGBG-Mol datasets, and for all other datasets we use edge attention. Specifically, when node attention is used, the MLP layers in P φ will take as input the node embeddings and output p v for each v ∈ V . Then, the stochastic node attention is sampled for each node α v ∼ Bern(p v ). After that, α uv is obtained by α uv = α u α v .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. Further Supplementary Experiments</head><p>Fig. <ref type="figure" target="#fig_2">3</ref> shows an experiment with disconnected critical subgraphs, where the dataset is generated in a similar way used to generate Ba-2Motifs. Specifically, each base graph is generated using the BA model and will be attached with two house motifs or three house motifs randomly. The number of house motifs represents the graph class. Both GSAT and GraphMask are trained with the same settings used on Ba-2Motifs.</p><p>Table <ref type="table" target="#tab_6">5</ref> shows a direct comparison with PGExplainer and GNNExplainer between the interpretation ROC AUC reported in <ref type="bibr" target="#b25">(Luo et al., 2020)</ref> and the performance of GSAT. And GSAT still outperforms their methods significantly.  <ref type="table">7</ref> show direct comparisons with DIR, where we apply GSAT with the backbone model used in DIR. And GSAT still greatly outperforms their method.</p><p>Table <ref type="table" target="#tab_8">8</ref> shows the ablation study on β and stochasticity in GSAT, where PNA is the backbone model. Figure <ref type="figure" target="#fig_12">8</ref> shows the ablation study of the information constraint introduced in Eq. ( <ref type="formula">9</ref>) on Spurious-Motif b = 0.7 and b = 0.9. We observe the same trends from these ablation studies as discussed in Sec. 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Interpretation Visualization</head><p>We provide visualizations of the label-relevant subgraphs discovered by GSAT on eight datasets, as shown from Fig. <ref type="figure">9</ref> to Fig. <ref type="figure" target="#fig_0">16</ref>. The transparency of the edges shown in the figures represents the normalized attention weights learned by   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. The architecture of GSAT. g φ encodes the input graph G and learns stochastic attention α (from Bernoulli distributions) that randomly drop the edges and obtain a perturbed graph GS. f θ encodes GS to make predictions. GSAT does not constrain the size of GS but injects stochasticity to constrain information. The subgraph of GS with learnt reduced-stochasticity (edges with pe → 1) provides interpretation. GSAT is a unified model by adopting just one GNN for both g φ and f θ . GSAT can be either trained from scratch or start from a pre-trained GNN predictor f θ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Visualizing attention (normalized to [0, 1]) of GSAT (second row) v.s. masks of GraphMask (Schlichtkrull et al., 2021) (third row) on MNIST-75sp. The first row shows the ground-truth. Different digit samples contain interpretable subgraphs of different sizes, while GSAT is not sensitive to such varied sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure3. Visualizing attention (normalized to [0, 1]) of GSAT (first row) and masks of GraphMask<ref type="bibr" target="#b31">(Schlichtkrull et al., 2021)</ref> (second row) on a motif example, where graphs with three house motifs and graphs with two house motifs represent two classes. Samples may contain disconnected interpretable subgraphs, while GSAT detects them accurately. More details can be found in Appendix D.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>studies the feature selection problem in the regular feature space and proposed a mutual information (MI) maximization rule to select a fixed number of features. Specifically, let I(a; b) a,b P(a, b) log P(a,b) P(a)P(b) denote the MI between two random variables a and b. Large MI indicates certain high correlation between two random variables. Hence, with input features X ∈ R F , L2X is to search a k-sized set of indices S ⊆ {1, 2, ..., F }, where k = |S| &lt; F , such that the features in the subspace indexed by S (denoted by X S ) maximizes the mutual information with the labels Y , i.e., max S⊆{1,2,...,F } I(X S ; Y ), s.t. |S| ≤ k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure4. Post-hoc methods just perform one-step projection to the information-constrained space, which is always suboptimal and the interpretation performance is sensitive to the pre-trained model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure5. Issues of post-hoc interpretation methods. GSAT is trained with 10 different random seeds. And for post-hoc methods, we pre-train 10 models with different random seeds and run these methods on each model. Interpretation performance and the training losses of Eq. 2 for GSAT and Eq. 4 for others are shown. Note that we guarantee that all the pre-trained models achieve good performance in their pre-training stage (Acc.∼100% Ba-2Motif, ∼90% Mutag).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>follow Alemi et al. (2016);<ref type="bibr" target="#b28">Poole et al. (2019)</ref>;<ref type="bibr" target="#b42">Wu et al. (2020)</ref> to derive a tractable variational upper bound of the two terms in Eq. (5). Detailed derivation is given in Appendix B. For the term I (G S ; Y ), we introduce a parameterized variational approximation P θ (Y |G S ) for P(Y |G S ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>a,b P(a, b) log P(a,b) P(a)P(b) , where P(a, b) is the joint distribution and P(a), P(b) are the marginal distributions. By definition, I(a, b) = KL(P(a, b)||P(a)P(b)) = a,b P(a, b) log P(a|b)− b P(b) log P(b) = −H(a|b) + H(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 .</head><label>8</label><figDesc>Figure8. Ablation study on (1) using the info. constraint in Eq. (9) and (2) replacing it with 1-norm, where r is tuned from 0.9 to 0.1 and the coefficient of the 1-norm λ1 is tuned from 1e-5 to 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 .Figure 10 .Figure 11 .</head><label>91011</label><figDesc>Figure 9. Visualizing label-relevant subgraphs discovered by GSAT for Ba-2Motifs. Nodes colored pink are ground-truth explanations, and each row represents a graph class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Visualizing label-relevant subgraphs discovered by GSAT for Spurious-Motif b = 0.7. Nodes colored pink are ground-truth explanations, and each row represents a graph class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 13 .Figure 14 .</head><label>1314</label><figDesc>Figure 13. Visualizing label-relevant subgraphs discovered by GSAT for Spurious-Motif b = 0.9. Nodes colored pink are ground-truth explanations, and each row represents a graph class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc><ref type="bibr" target="#b23">Lin et al., 2021)</ref> checking Granger causality and Graphlime<ref type="bibr" target="#b16">(Huang et al., 2020)</ref> using HSIC Lasso are only applied to node-level task interpretation. Much fewer works have considered intrinsic interpretation. Pope et al. (2019) and Baldassarre &amp; Azizpour (2019) check the gradients w.r.t. the input features to determine important features. Recently, Wu et al. (2022) has proposed DIR to make the model avoid overfitting spurious correlations and only capture invariant rationales to provide interpretability. However, DIR needs to iteratively break graphs into subgraphs and assemble subgraphs into graphs during the model training, which is far more complicated than GSAT.</figDesc><table><row><cell></cell><cell cols="2">Spurious Correlation</cell></row><row><cell>H O</cell><cell></cell><cell></cell></row><row><cell>The environment</cell><cell></cell><cell></cell></row><row><cell>may contain spurious correlation with</cell><cell>H</cell><cell>O</cell></row><row><cell cols="3">Figure 6. G  *  S determines Y . However, the environment features in</cell></row><row><cell cols="3">G\G  *  S may contain spurious (backdoor) correlation with Y .</cell></row><row><cell cols="3">the connectivity assumption and only search over the space</cell></row><row><cell cols="3">of connected subgraphs for interpretation. They adopt either</cell></row><row><cell cols="3">reinforcement learning (Yuan et al., 2020a) or Monte Carlo</cell></row><row><cell cols="3">tree search (Yuan et al., 2021). Other methods including</cell></row><row><cell cols="3">PGM-Explainer (Vu &amp; Thai, 2020) leveraging graphical</cell></row><row><cell>models, Gem (</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Interpretation Performance (AUC). The underlined results highlight the best baselines. The bold font and bold † font highlight when GSAT outperform the means of the best baselines based on the mean of GSAT and the mean-2*std of GSAT, respectively. 97.43 † ± 1.77 97.75 † ± 0.92 83.70 † ± 1.46 85.55 † ± 2.57 85.56 † ± 1.93 83.59 † ± 2.56 PNA+GSAT 93.77 ± 3.90 99.07 † ± 0.50 84.68 † ± 1.06 83.34 † ± 2.17 86.94 † ± 4.05 88.66 † ± 2.44 PNA+GSAT * 89.04 ± 4.92 96.22 † ± 2.08 88.54 † ± 0.72 90.55 † ± 1.48 89.79 † ± 1.91 89.54 † ± 1.78</figDesc><table><row><cell></cell><cell>BA-2MOTIFS</cell><cell>MUTAG</cell><cell>MNIST-75SP</cell><cell>b = 0.5</cell><cell>SPURIOUS-MOTIF b = 0.7</cell><cell>b = 0.9</cell></row><row><cell>GNNEXPLAINER</cell><cell>67.35 ± 3.29</cell><cell>61.98 ± 5.45</cell><cell>59.01 ± 2.04</cell><cell>62.62 ± 1.35</cell><cell>62.25 ± 3.61</cell><cell>58.86 ± 1.93</cell></row><row><cell>PGEXPLAINER</cell><cell>84.59 ± 9.09</cell><cell>60.91 ± 17.10</cell><cell>69.34 ± 4.32</cell><cell>69.54 ± 5.64</cell><cell>72.33 ± 9.18</cell><cell>72.34 ± 2.91</cell></row><row><cell>GRAPHMASK</cell><cell>92.54 ± 8.07</cell><cell>62.23 ± 9.01</cell><cell>73.10 ± 6.41</cell><cell>72.06 ± 5.58</cell><cell>73.06 ± 4.91</cell><cell>66.68 ± 6.96</cell></row><row><cell>IB-SUBGRAPH</cell><cell>86.06 ± 28.37</cell><cell>91.04 ± 6.59</cell><cell>51.20 ± 5.12</cell><cell>57.29 ± 14.35</cell><cell>62.89 ± 15.59</cell><cell>47.29 ± 13.39</cell></row><row><cell>DIR</cell><cell>82.78 ± 10.97</cell><cell>64.44 ± 28.81</cell><cell>32.35 ± 9.39</cell><cell>78.15 ± 1.32</cell><cell>77.68 ± 1.22</cell><cell>49.08 ± 3.66</cell></row><row><cell>GIN+GSAT</cell><cell cols="4">98.74  † ± 0.55 99.60  † ± 0.51 83.36  † ± 1.02 78.45  † ± 3.12</cell><cell>74.07 ± 5.28</cell><cell>71.97 ± 4.41</cell></row><row><cell>GIN+GSAT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>*   </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Prediction Performance (Acc.). The bold font highlights the inherently interpretable methods that significantly outperform the corresponding backbone model, GIN or PNA, when the mean-1*std of a method &gt; the mean of its corresponding backbone model.</figDesc><table><row><cell></cell><cell cols="3">MOLHIV (AUC) GRAPH-SST2 MNIST-75SP</cell><cell>b = 0.5</cell><cell>SPURIOUS-MOTIF b = 0.7</cell><cell>b = 0.9</cell></row><row><cell>GIN</cell><cell>76.69 ± 1.25</cell><cell>82.73 ± 0.77</cell><cell>95.74 ± 0.36</cell><cell>39.87 ± 1.30</cell><cell>39.04 ± 1.62</cell><cell>38.57 ± 2.31</cell></row><row><cell>IB-SUBGRAPH</cell><cell>76.43 ± 2.65</cell><cell>82.99 ± 0.67</cell><cell cols="4">93.10 ± 1.32 54.36 ± 7.09 48.51 ± 5.76 46.19 ± 5.63</cell></row><row><cell>DIR</cell><cell>76.34 ± 1.01</cell><cell>82.32 ± 0.85</cell><cell cols="3">88.51 ± 2.57 45.49 ± 3.81 41.13 ± 2.62</cell><cell>37.61 ± 2.02</cell></row><row><cell>GIN+GSAT</cell><cell>76.47 ± 1.53</cell><cell>82.95 ± 0.58</cell><cell cols="4">96.24 ± 0.17 52.74 ± 4.08 49.12 ± 3.29 44.22 ± 5.57</cell></row><row><cell>GIN+GSAT  *</cell><cell>76.16 ± 1.39</cell><cell>82.57 ± 0.71</cell><cell cols="3">96.21 ± 0.14 46.62 ± 2.95 41.26 ± 3.01</cell><cell>39.74 ± 2.20</cell></row><row><cell>PNA (NO SCALARS)</cell><cell>78.91 ± 1.04</cell><cell>79.87 ± 1.02</cell><cell>87.20 ± 5.61</cell><cell>68.15 ± 2.39</cell><cell>66.35 ± 3.34</cell><cell>61.40 ± 3.56</cell></row><row><cell>PNA+GSAT</cell><cell>80.24 ± 0.73</cell><cell cols="3">80.92 ± 0.66 93.96 ± 0.92 68.74 ± 2.24</cell><cell>64.38 ± 3.20</cell><cell>57.01 ± 2.95</cell></row><row><cell>PNA+GSAT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* 80.67 ± 0.95 82.81 ± 0.56 92.38 ± 1.44 69.72 ± 1.93 67.31 ± 1.86 61.49 ± 3.46 tion dataset, where each image in MNIST is converted to a superpixel graph. Nodes with nonzero pixel values provide ground-truth explanations. Note that the subgraphs that provide explanations are of different sizes in this dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Generalization ROC AUC on other OGBG-Mol datasets. The bold font highlights when GSAT outperforms PNA.</figDesc><table><row><cell></cell><cell>MOLBACE</cell><cell>MOLBBBP</cell><cell>MOLCLINTOX</cell><cell>MOLTOX21</cell><cell>MOLSIDER</cell></row><row><cell>PNA</cell><cell cols="2">73.52 ± 3.02 67.21 ± 1.34</cell><cell>86.72 ± 2.33</cell><cell cols="2">75.08 ± 0.64 56.51 ± 1.90</cell></row><row><cell>GSAT</cell><cell cols="5">77.41 ± 2.42 69.17 ± 1.12 87.80 ± 2.36 74.96 ± 0.66 57.58 ± 1.23</cell></row><row><cell cols="2">GSAT  *  73.61 ± 1.59</cell><cell cols="4">66.30 ± 0.79 89.26 ± 1.66 75.71 ± 0.48 59.19 ± 1.03</cell></row><row><cell cols="5">6.3. Result Comparison and Analysis</cell></row><row><cell cols="6">Interpretability Results. As shown in Table 1, our meth-</cell></row><row><cell cols="6">ods significantly outperform the baselines by 9%↑ on aver-</cell></row><row><cell cols="6">age and up to 20%↑. If we just compare among inherently</cell></row><row><cell cols="6">interpretable models, the boost is even more significant.</cell></row><row><cell cols="6">Moreover, GSAT also provides much stabler interpretation</cell></row><row><cell cols="6">than the baselines as for the much smaller variance. GSAT  *</cell></row><row><cell cols="6">via fine-tuning a pre-trained model can often further boost</cell></row><row><cell cols="6">the interpretation performance. Also, when the more expres-</cell></row><row><cell cols="6">sive model PNA is used as the backbone, we find the posthoc</cell></row><row><cell cols="6">methods are likely to suffer from the overfitting issue as ex-</cell></row><row><cell cols="6">plained in Sec. 3.2. However, GSAT does not suffer from</cell></row><row><cell cols="6">that and can yield even better interpretation results. Over</cell></row><row><cell cols="6">Ba-2Motifs and Mutag, GNNExplainer and PGExplainer</cell></row><row><cell cols="4">work worse than what reported in</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Ablation study on β and stochasticity in GSAT (GIN as the backbone model) on Spurious-Motif. We report both interpretation ROC AUC (top) and prediction accuracy (bottom).</figDesc><table><row><cell></cell><cell>SPURIOUS-MOTIF</cell><cell>b = 0.5</cell><cell>b = 0.7</cell><cell>b = 0.9</cell></row><row><cell></cell><cell>GSAT</cell><cell>79.81 ± 3.98</cell><cell>74.07 ± 5.28</cell><cell>71.97 ± 4.41</cell></row><row><cell></cell><cell>GSAT-β = 0</cell><cell>66.00 ± 11.04</cell><cell>65.92 ± 3.28</cell><cell>66.31 ± 6.82</cell></row><row><cell></cell><cell>GSAT-NOSTOCH</cell><cell>59.64 ± 5.33</cell><cell>55.78 ± 2.84</cell><cell>55.27 ± 7.49</cell></row><row><cell></cell><cell>GSAT-NOSTOCH-β = 0</cell><cell>63.37 ± 12.33</cell><cell>60.61 ± 10.08</cell><cell>66.19 ± 7.76</cell></row><row><cell></cell><cell>GIN</cell><cell>39.87 ± 1.30</cell><cell>39.04 ± 1.62</cell><cell>38.57 ± 2.31</cell></row><row><cell></cell><cell>GSAT</cell><cell>51.86 ± 5.51</cell><cell>49.12 ± 3.29</cell><cell>44.22 ± 5.57</cell></row><row><cell></cell><cell>GSAT-β = 0</cell><cell>45.97 ± 8.37</cell><cell>49.67 ± 7.01</cell><cell>49.84 ± 5.45</cell></row><row><cell></cell><cell>GSAT-NOSTOCH</cell><cell>40.34 ± 2.77</cell><cell>41.90 ± 3.70</cell><cell>37.98 ± 2.64</cell></row><row><cell></cell><cell>GSAT-NOSTOCH-β = 0</cell><cell>43.41 ± 8.05</cell><cell>45.88 ± 9.54</cell><cell>42.25 ± 9.77</cell></row><row><cell>Intrepretation ROC AUC</cell><cell>40 50 60 70 80</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">0.9/1e-5 0.8/1e-4 0.7/5e-4 0.6/1e-3 0.5/5e-3 0.4/1e-2 0.3/5e-2 0.2/1e-1 0.1/1 30</cell><cell></cell></row><row><cell></cell><cell>r/λ1</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>or other potentially biased assumptions in graph learning interpretation without performance decay. It can also remove spurious correlation to better the model generalization. As a by-product, we also disclose a potentially severe issue behind post-doc interpretation methods from the optimization perspective of information bottleneck.</figDesc><table><row><cell>Neural image caption generation with visual attention.</cell></row><row><cell>In Proceedings of the 32nd International Conference on</cell></row><row><cell>Machine Learning, volume 37, pp. 2048-2057. PMLR,</cell></row><row><cell>2015.</cell></row><row><cell>Xu, K., Hu, W., Leskovec, J., and Jegelka, S. How powerful</cell></row><row><cell>are graph neural networks? In International Conference</cell></row><row><cell>on Learning Representations, 2019.</cell></row><row><cell>Ying, Z., Bourgeois, D., You, J., Zitnik, M., and Leskovec, J.</cell></row><row><cell>Gnnexplainer: Generating explanations for graph neural</cell></row><row><cell>networks. In Advances in Neural Information Processing</cell></row><row><cell>Systems, volume 32, 2019.</cell></row><row><cell>Yu, J., Xu, T., Rong, Y., Bian, Y., Huang, J., and He, R.</cell></row><row><cell>Graph information bottleneck for subgraph recognition.</cell></row><row><cell>In International Conference on Learning Representations,</cell></row><row><cell>2020.</cell></row><row><cell>Yuan, H., Tang, J., Hu, X., and Ji, S. Xgnn: Towards</cell></row><row><cell>model-level explanations of graph neural networks. In</cell></row><row><cell>Proceedings of the 26th ACM SIGKDD International</cell></row><row><cell>Conference on Knowledge Discovery &amp; Data Mining, pp.</cell></row><row><cell>430-438, 2020a.</cell></row><row><cell>Graph Stochastic Attention (GSAT) is a novel attention</cell></row><row><cell>mechanism to build interpretable graph learning models.</cell></row></table><note>GSAT injects stochasticity to block label-irrelevant information and leverages stochasticity reduction to select labelrelevant subgraphs. Such rationale is grounded by the information bottleneck principle. GSAT provides tons of disruptive contributions. For example, it removes the sparsity, continuity Yuan, H., Yu, H., Gui, S., and Ji, S. Explainability in graph neural networks: A taxonomic survey. arXiv preprint arXiv:2012.15445, 2020b.Yuan, H., Yu, H., Wang, J., Li, K., and Ji, S. On explainability of graph neural networks via subgraph explorations. In Proceedings of the 38th International Conference on Machine Learning, volume 139, pp. 12241-12252. PMLR, 2021.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Direct comparison with the interpretation ROC AUC of GNNExplainer and PGExplainer reported in<ref type="bibr" target="#b25">(Luo et al., 2020)</ref> (given a selected pre-trained model).</figDesc><table><row><cell></cell><cell>BA-2MOTIFS</cell><cell>MUTAG</cell></row><row><cell>GNNEXPLAINER</cell><cell>74.2</cell><cell>72.7</cell></row><row><cell>PGEXPLAINER</cell><cell>92.6</cell><cell>87.3</cell></row><row><cell>GSAT</cell><cell cols="2">98.74  † ± 0.55 99.60  † ± 0.51</cell></row><row><cell>GSAT  *</cell><cell cols="2">97.43  † ± 0.02 97.75  † ± 0.92</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>± 0.022 0.503 † ± 0.034 0.416 † ± 0.081 GSAT * 0.532 † ± 0.019 0.512 † ± 0.011 0.520 † ± 0.022 replication or not. We also evaluate GSAT on molbace, molbbbp, molclintox, moltox21 and molsider datasets from OGBG.</figDesc><table><row><cell></cell><cell>b = 0.5</cell><cell>b = 0.7</cell><cell>b = 0.9</cell></row><row><cell>GNNEXPLAINER</cell><cell>0.203 ± 0.019</cell><cell>0.167 ± 0.039</cell><cell>0.066 ± 0.007</cell></row><row><cell>DIR</cell><cell>0.255 ± 0.016</cell><cell>0.247 ± 0.012</cell><cell>0.192 ± 0.044</cell></row><row><cell>GSAT</cell><cell>0.519  †</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 .</head><label>8</label><figDesc>Ablation study on β and stochasticity in GSAT (PNA as the backbone model) on Spurious-Motif. We report both interpretation ROC AUC (top) and prediction accuracy (bottom). If not specified, GSAT uses the same settings mentioned for the backbone models.</figDesc><table><row><cell>0.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 and table</head><label>6</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Code available at https://github.com/Graph-COM/GSAT</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1">-norm regularization and the coefficient of entropy regularization. GraphMask. We use the recommended settings from(Schlichtkrull et al.,  </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2021" xml:id="foot_2">), including the temperature, gamma, zeta</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep variational information bottleneck</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<title level="m">Invariant risk minimization</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Explainability techniques for graph convolutional networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Baldassarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning Workshops, 2019 Workshop on Learning and Reasoning with Graph-Structured Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unveiling the predictive power of static structure in glassy systems</title>
		<author>
			<persName><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Keck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grabska-Barwińska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Donner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Obika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="448" to="454" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
				<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Invariant rationalization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
				<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1448" to="1458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to explain: An information-theoretic perspective on model interpretation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
				<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="883" to="892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Principal neighbourhood aggregation for graph nets</title>
		<author>
			<persName><forename type="first">G</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cavalleri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Beaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="13260" to="13271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discovering symbolic models from deep learning with inductive biases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Spergel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17429" to="17442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="786" to="797" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Techniques for interpretable machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving molecular graph neural network explainability with orthonormalization and induced sparsity</title>
		<author>
			<persName><forename type="first">R</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
				<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="4203" to="4213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Open graph benchmark: Datasets for machine learning on graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="22118" to="22133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Graphlime</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.06216</idno>
		<title level="m">Local interpretable model explanations for graph neural networks</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention is not explanation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3543" to="3556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Highly accurate protein structure prediction with alphafold</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jumper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figurnov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tunyasuvunakool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Žídek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Potapenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">596</biblScope>
			<biblScope unit="issue">7873</biblScope>
			<biblScope unit="page" from="583" to="589" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Understanding attention and generalization in graph neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Knyazev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generative causal explanations for graph neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
				<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="6666" to="6679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queue</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="57" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parameterized explainer for graph neural network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards transparent and explainable attention models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mohankumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4206" to="4216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Causal Inference in Statistics: A Primer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
				<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="5171" to="5180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Explainability methods for graph convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rostami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10772" to="10781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Model-agnostic interpretability of machine learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning Workshops, 2016 Workshop on Human Interpretability in Machine Learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Interpreting graph neural networks for {nlp} with differentiable edge masking</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Is attention interpretable?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2931" to="2951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A mathematical theory of communication. The Bell system technical journal</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948">1948</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="379" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
				<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adversarial graph augmentation to improve graph contrastive learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep learning and the information bottleneck principle</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zaslavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Information Theory Workshop (ITW)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The information bottleneck method</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
		<idno>arXiv preprint physics/0004057</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pgm-explainer: Probabilistic graphical model explanations for graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Thai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12225" to="12235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">C-h bond activation enables the rapid construction and late-stage diversification of functional molecules</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wencel-Delord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glorius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature chemistry</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="369" to="375" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Graph information bottleneck</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="20437" to="20448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discovering invariant rationales for graph neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Moleculenet: a benchmark for molecular machine learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Geniesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leswing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="530" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><surname>Show</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
