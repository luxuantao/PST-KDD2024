<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Meta-level sentiment models for big social data analysis 4 5 6</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-06-05">5 June 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Felipe</forename><surname>Bravo-Marquez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Waikato</orgName>
								<address>
									<addrLine>Private Bag 3105</addrLine>
									<postCode>3240</postCode>
									<settlement>Hamilton</settlement>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Yahoo! Labs Santiago</orgName>
								<address>
									<addrLine>Av. Blanco Encalada 2120, 4h floor</addrLine>
									<settlement>Santiago</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marcelo</forename><surname>Mendoza</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Técnica Federico Santa María</orgName>
								<address>
									<addrLine>Av. Vicuña Mackenna 3939</addrLine>
									<settlement>Santiago</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
							<email>bpoblete@dcc.uchile.cl</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Chile</orgName>
								<address>
									<addrLine>Av. Blanco Encalada 2120</addrLine>
									<settlement>Santiago</settlement>
									<country key="CL">Chile</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Waikato</orgName>
								<address>
									<addrLine>Private Bag 3105</addrLine>
									<postCode>3240</postCode>
									<settlement>Hamilton</settlement>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Meta-level sentiment models for big social data analysis 4 5 6</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-06-05">5 June 2014</date>
						</imprint>
					</monogr>
					<idno type="MD5">D83B68984B3BBA9D0A820D5564DC362F</idno>
					<idno type="DOI">10.1016/j.knosys.2014.05.016</idno>
					<note type="submission">Received 22 November 2013 16 Received in revised form 6 May 2014 17 Accepted 15 May 2014 18</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>20 Sentiment</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>People react to events, topics and entities by expressing their personal opinions and emotions. These reactions can correspond to a wide range of intensities, from very mild to strong. An adequate processing and understanding of these expressions has been the subject of research in several fields, such as business and politics. In this context, Twitter sentiment analysis, which is the task of automatically identifying and extracting subjective information from tweets, has received increasing attention from the Web mining community. Twitter provides an extremely valuable insight into human opinions, as well as new challenging Big Data problems. These problems include the processing of massive volumes of streaming data, as well as the automatic identification of human expressiveness within short text messages. In that area, several methods and lexical resources have been proposed in order to extract sentiment indicators from natural language texts at both syntactic and semantic levels. These approaches address different dimensions of opinions, such as subjectivity, polarity, intensity and emotion. This article is the first study of how these resources, which are focused on different sentiment scopes, complement each other. With this purpose we identify scenarios in which some of these resources are more useful than others. Furthermore, we propose a novel approach for sentiment classification based on meta-level features. This supervised approach boosts existing sentiment classification of subjectivity and polarity detection on Twitter. Our results show that the combination of meta-level features provides significant improvements in performance. However, we observe that there are important differences that rely on the type of lexical resource, the dataset used to build the model, and the learning strategy. Experimental results indicate that manually generated lexicons are focused on emotional words, being very useful for polarity prediction. On the other hand, lexicons generated with automatic methods include neutral words, introducing noise in the detection of subjectivity. Our findings indicate that polarity and subjectivity prediction are different dimensions of the same problem, but they need to be addressed using different subspace features. Lexicon-based approaches are recommendable for polarity, and stylistic part-of-speech based approaches are meaningful for subjectivity. With this research we offer a more global insight of the resource components for the complex task of classifying human emotion and opinion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Moreover, the emotional load of a message, written or verbal, is 58 extremely important when it comes to understanding its true 59 meaning. Therefore, opinion and sentiment comprehension are a key aspect of human interaction. For many years, emotions have been studied individually and also collectively, in order to understand human behavior. The collective or social analysis of opinions and sentiment responds to the need to measure the impact or polarization that a certain event or entity has on a group of individuals. Social sentiment has been studied in politics to understand and forecast election outcomes, and also in marketing, to predict the success of a certain product and to recommend others.</p><p>Before the rise of online social media, gathering data on opinions was expensive and usually achieved at very small scale. When users on the Web started communicating massively through this channel, social networks became overloaded with opinionated data. In that aspect, social media has opened new possibilities for human interaction. Microblogging platforms, in particular, allow real-time sharing of comments and opinions. Twitter, 1 an extremely popular microblogging platform, has millions of users that share millions of personal posts on a daily basis. This rich and enormous volume of user generated data offers endless opportunities for the study of human behavior.</p><p>Manual classification of millions of posts for opinion mining is an unfeasible task. Therefore, several methods have been proposed</p><p>to automatically infer human opinions from natural language texts.</p><p>Computational sentiment analysis methods attempt to measure different opinion dimensions. A number of methods for polarity estimation have been proposed in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23]</ref> discussed in depth in Section 2. Polarity estimation is reduced into a classification problem with three polarity classes -positive, negative and neutral -with supervised and unsupervised approaches being proposed for this task. In the case of unsupervised approaches, a number of lexicon resources with positive and negative scores for words exist. A related task is the detection of subjectivity, which is the specific task of separating factual from opinionated text. This problem has also been addressed with supervised approaches <ref type="bibr" target="#b32">[33]</ref>. In addition, opinion intensities (strengths) have also become a matter of study, for example, SentiStrength <ref type="bibr" target="#b29">[30]</ref> estimates positive and negative strength scores at sentence level. Finally, the emotion estimation problem has also been addressed with the creation of lexicons. The Plutchik wheel of emotions, proposed in <ref type="bibr" target="#b27">[28]</ref>, is composed of four pairs of opposite emotion states: joy-trust, sadnessanger, surprise-fear, and anticipation-disgust. Mohammad et al.</p><p>[20] labeled a number of words according to Plutchik emotional categories, developing the NRC word-emotion association lexicon.</p><p>All of the approaches described above perform sentiment analysis at a syntactic-level. On the other hand, there are approaches that use semantic knowledge bases to perform sentiment analysis at a semantic-level <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Regardless of the growing amount of work in this research area, sentiment analysis remains a widely open problem, due in part to the inherent subjectivity of the data, as well as language and communication subtleties. In particular, opinions are multidimensional semantic artifacts. When people are exposed to information regarding a topic or entity, they normally respond to this external stimuli by developing a personal point of view or orientation. This orientation reveals how the opinion holder is polarized by the entity. Additionally, people manifest emotions through opinions, which are the driving forces behind motivations and personal dispositions. This indicates that emotions and polarities are mutually influenced by each other, conditioning opinion intensities and emotional strengths.</p><p>In this article we analyze the existing literature in the field of sentiment analysis. Our literature overview shows that current sentiment analysis approaches mostly focus on a particular opinion dimension. Although these scopes are difficult to categorize independently, we propose the following taxonomy for existing work:</p><p>1. Polarity: These methods and resources aim to extract polarity information from a passage. Polarity-oriented methods normally return a categorical variable whose possible values are positive, negative and neutral. On the other hand, polarity-oriented lexical resources are composed of positive and negative words lists. We analyze how each approach can be used in a complemen-147 tary way. In order to achieve this, we introduce a novel meta-fea-148 ture classification approach for boosting the sentiment analysis 149 task. This approach efficiently combines existing sentiment analy- Twitter is a straightforward task using the public Twitter API.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>198</head><p>As the creation of a large corpus of manually-labeled data for 199 sentiment classification tasks involves significant human effort, 200 numerous studies have explored the use of emoticons as labels 201 <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b28">29]</ref>. The use of emoticons assumes that they could be asso- the use of emoticons as sentiment labels can introduce noise. How- <ref type="bibr" target="#b11">[12]</ref> and later Baccianella et al. <ref type="bibr" target="#b0">[1]</ref> extended the well known Wordnet lexical database <ref type="bibr" target="#b18">[19]</ref> by introducing sentiment ratings to a number of synsets, creating SentiWordnet. The development of lexicon resources for strength estimation was addressed by Thelwall et al. <ref type="bibr" target="#b29">[30]</ref>, leveraging SentiStrength. Finally, NRC, a lexicon resource for emotion estimation was released by Mohammad and Turney <ref type="bibr" target="#b19">[20]</ref>, where a number of English words were tagged with emotion ratings, according to the emotional wheel taxonomy introduced by Plutchik <ref type="bibr" target="#b27">[28]</ref>.</p><p>All methods and resources discussed so far address the sentiment analysis problem by relying on syntactic-level techniques such as opinion lexicons, word occurrence counts and corpusbased statistical methods. However, these approaches present significant limitations when applied to real-world scenarios. On one hand, lexicon-based approaches cannot properly handle expressions with negations, and on the other hand, corpus-based statistical models tend to produce poor results when applied to domains that differ from those in which they were trained <ref type="bibr" target="#b7">[8]</ref>. In light of the above, a new generation of methods and resources referred to as concept-based approaches have been developed in recent years.</p><p>Concept-based approaches perform a semantic analysis of the text using semantic knowledge bases such as Web ontologies <ref type="bibr" target="#b23">[24]</ref> and semantic networks <ref type="bibr" target="#b24">[25]</ref>. In this manner, concept-based methods allow the detection of subjective information which can be expressed implicitly in a text passage. Furthermore, concept-level techniques have also been widely used in sentiment analysis problems such as for domain adaptation of sentiment classifiers <ref type="bibr" target="#b33">[34]</ref> and for building knowledge-based sentiment lexicons <ref type="bibr" target="#b30">[31]</ref>.</p><p>A publicly available concept-based resource to extract sentiment information from common sense concepts is SenticNet. This resource was built using both graph-mining and dimensionalityreduction techniques <ref type="bibr" target="#b4">[5]</ref>, a description of its most recent version (SenticNet 3) can be found in <ref type="bibr" target="#b8">[9]</ref>. For further details about sentiment analysis methods and applications we refer the reader to the survey by Pang and Lee <ref type="bibr" target="#b26">[27]</ref> and to the book by Liu <ref type="bibr" target="#b17">[18]</ref>. For a deeper understanding of common sense computing techniques that work on the semantic-level of text, the readers should refer to the book by Cambria and Hussain <ref type="bibr" target="#b5">[6]</ref> on the sentic computing paradigm. Finally, to review the evolution of natural language processing (NLP) techniques readers can refer to the article by Cambria and White <ref type="bibr" target="#b9">[10]</ref>. This article discusses three major NLP paradigms, namely Syntactics, Semantics, and Pragmatics Curves, analyzing how the approaches that belong to such curves may eventually evolve into the computational understanding of natural language text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Tweet sentiment representation</head><p>In this section we describe the proposed feature representation of tweets for sentiment classification purposes. In contrast to the common text classification approach in which the words contained within the passage are used as features (e.g., unigrams, n-grams), we rely on two types of features: meta-level features and part-ofspeech features. and OpinionFinder Negative Words (ONW), these are the numbers of positive and negative words of the tweet that matche the OpinionFinder lexicon, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Bing Liu's opinion lexicon</head><p>This Lexicon is maintained and distributed by Bing Liu <ref type="foot" target="#foot_1">5</ref> and was used in several papers authored or co-authored by him <ref type="bibr" target="#b17">[18]</ref>. The lexicon is polarity oriented and is formed by 2,006 positive words and 4,683 negative words. It includes misspelled words, slang words as well as some morphological variants. As is done in OpinionFinder, we extract the features Bing Liu Positive Words (BLPW) and Bing Liu Negative Words (BLNW).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">AFINN lexicon</head><p>This lexicon is based on the Affective Norms for English Words lexicon (ANEW) proposed by Bradley and Lang <ref type="bibr" target="#b2">[3]</ref>. ANEW provides emotional ratings for a large number of English words. These ratings are calculated according to the psychological reaction of a person to a specific word, being ''valence'' the most useful value for sentiment analysis. ''Valence'' ranges in the scale from pleasant to unpleasant. ANEW was released before the rise of microblogging and hence, many slang words commonly used in social media were not included. Considering that there is empirical evidence about significant differences between microblogging words and the language used in other domains <ref type="bibr" target="#b1">[2]</ref> a new version of ANEW was required. Inspired by ANEW, Nielsen <ref type="bibr" target="#b22">[23]</ref> created the AFINN lexicon, which is more focused on the language used in microblogging platforms. The word list includes slang and obscene words and also acronyms and Web jargon. Positive words are scored from 1 to 5 and negative words from À1 to À5. Thus, this lexicon is useful for strength estimation. The lexicon includes 2,477 English words.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.6.">NRC-hashtag</head><p>The NRC Hashtag Sentiment Lexicon is an automatically created sentiment lexicon which was built from a collection of 775,310 tweets that contain positive or negative hashtags such as #good, #excellent, #bad, and #terrible. The tweets are labeled as positive or negative according to the hashtag's polarities. A sentiment score is calculated for all the words and bigrams found in the collection using the point wise mutual information (PMI) measure between each word and the corresponding polarity label of the tweet. This score is a strength oriented sentiment dimension that ranges from À5 to 5. A positive value indicates a positive sentiment and a negative value indicates the opposite. The resource was created by the NRC-Canada team that won the SemEval task <ref type="bibr" target="#b20">[21]</ref> and is available for download. 8 From each tweet we extract the features NRC-Hashtag Positivity (NRCHashPos) and NRC-Hashtag Negativity (NRC-HashNeg) that are the sum of scores of positive and negative words of the tweet that match the unigram list of the lexicon, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.7.">Sentiment140 lexicon</head><p>This lexicon was also provided by the NRC-Canada team and was created following the same approach used for creating the NRC-Hashtag lexicon. Instead of using hashtags as tweet labels, a corpus of 1.6 million tweets with positive and negative emoticons was used to calculate the sentiment words. The tweet collection is the same one as the one used to train the Sentiment140 method in <ref type="bibr" target="#b12">[13]</ref>. The lexicon is used to extract the strength oriented features S140Lex Positivity (S140LexPos) and S140Lex Negativity (S140Lex Positivity) which are calculated in the same manner as the features from the NRC-Hashtag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.8.">Sentiment140 method</head><p>Sentiment140 9 is a Web application that classifies tweets according to their polarity. The evaluation is performed using the distant supervision approach proposed by Go et al. <ref type="bibr" target="#b12">[13]</ref> that was previously discussed in the related work section. The approach relies on supervised learning algorithms. Due to the difficulty of obtaining a largescale training dataset for this purpose, the problem is tackled using positive and negative emoticons and noisy labels. The method provides an API 10 that allows the classification of tweets to positive, negative and neutral polarity classes. We extract from each tweet one feature related to the Sentiment140 output, Sentiment140 class (S140), that corresponds to the output returned by the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.9.">SentiStrength method</head><p>SentiStrength is a lexicon-based sentiment evaluator that is especially focused on short social Web texts written in English <ref type="bibr" target="#b29">[30]</ref>. SentiStrength considers linguistic aspects of the passage such as a negating word list and an emoticon list with polarities. The implementation of the method can be freely used for academic purposes and is available for download. 11 For each passage to be evaluated, the method returns a positive score, from 1 (not positive) to 5 (extremely positive), a negative score, from À1 (not negative) to À5 (extremely negative), and a neutral label taking the values:    The number of words that overlap between each pair of resources are shown in Table <ref type="table" target="#tab_5">3</ref>. From the table we can see that resources created semi-automatically and completely automatically, SWN3, NRC-hash, and S140Lex are much larger than resources created manually. This is intuitive, because while SWN3 was created from WordNet, which is a large lexical database, NRC-hash and S140Lex are both formed by all the different words found in their respective large collections of tweets. The word interaction of the lexicons created manually is better represented in the Venn diagram shown in Fig. <ref type="figure" target="#fig_9">1(a)</ref>. We observe that both polarity-oriented lexicons Liu and OpinionFinder present an important overlap between each other. Fig. <ref type="figure" target="#fig_9">1(b)</ref> shows the interaction of lexicons created semi-automatically and completely automatically. We can see that the overlap between both lexicons built from Twitter data is greater than the overlap they have with SWN3. This suggests that Twitter-made lexicons contain several expressions that are specific to Twitter.</p><p>The level of uniqueness of each resource is shown in Table <ref type="table" target="#tab_6">4</ref>.</p><p>This value corresponds to the fraction of words of the lexicon that are not included in any of the remaining resources. We can see that as lexicons created manually tend to have a low uniqueness, resources created semi-automatically and completely automatically tend to have an important level of uniqueness. Nevertheless, regarding the AFINN lexicon, despite being the smallest lexicon created manually, it contains several words that are not included in other lexicons. This is because AFINN contains several Internet acronyms and slang words.</p><p>We also studied the level of neutrality of each resource, as is shown in the second column of Table <ref type="table" target="#tab_6">4</ref>. This value corresponds to the fraction of words of the lexicon marked as neutral, and hence, does not provide relevant sentiment information. The criteria for determining if a word is neutral varies from one lexicon to another. In OpinionFinder neutral words are marked explicitly.</p><p>Conversely, AFINN and Liu do not have neutral words. For the case of S140Lex and NRC-hash we consider as neutral, all the words in which the absolute value of its score was less than one. In a similar manner, we consider as neutral, all the words of SWN3 with a zero sentiment score. Finally, for NRC-emotion we consider as neutral, all words that are part of the lexicon and are not associated with any emotion or polarity class. Regarding the lexicons created manually we see that only NRC-emotion has a significant level of neutrality. Resources created semi-automatically and completely automatically present the highest levels of neutrality. This is because they include all the words from the sources used to create them (WordNet and Twitter). Then, as WordNet and Twitter contain a great diversity of words or expressions, it is expected for their derived lexicons to contain many words with no sentiment orientation.</p><p>In addition to comparing the words contained in the lexicons, we also compared the level of agreement between them. We extracted the 609 words that intersect all the different lexicons.</p><p>Afterwards, all the sentiment values assigned by each lexicon were converted to polarity categories: positive and negative. For strength-oriented lexicons we converted positive and negative scores to positive and negative labels respectively. Then, for NRCemotion we used the polarity dimensions provided by the lexicon.</p><p>The agreement between two lexicons is calculated as the fraction of words from the global intersection where both lexicons assigned the same polarity label to the word. The levels of agreement between all lexicons are shown in Table <ref type="table" target="#tab_7">5</ref>. From the From the 609 words that are contained in all the lexicons, 292 of them present at least one disagreement between two different lexicons. A group of words presenting disagreements along the different types of lexicons is presented in Table <ref type="table" target="#tab_8">6</ref>. We can see that words such as ''excuse'', ''joke'', and ''stunned'' may be used to express either positive and negative opinions, depending on the context.</p><p>Considering that it is very hard to associate all the words with a single polarity class, we think that emotion tags explain in a better manner the diversity of sentiment states triggered by these kinds of words. For instance, the word ''stunned'' which is associated with both positive and negative polarities, is also associated with surprise and fear emotions. As this word would more likely be negative in a context of ''fear'', it would also be more likely to be ''positive'' in a context of ''surprise''.</p><p>All the insights revealed from this analysis indicate that the resources considered in this work complement each other,   providing different sentiment information and also present different levels of noise. A previous study on the relationship between different opinion lexicons was presented as a tutorial by Christopher Potts at the Sentiment Analysis Symposium. 13     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Sentiment classification</head><p>We follow a supervised learning approach for which we model each tweet as a vector of sentiment features. A dataset of manually annotated tweets is required for training and evaluation purposes.</p><p>Two classification tasks are considered: subjectivity and polarity classification. In the former, tweets are classified as subjective (non-neutral) or objective (neutral), and in the latter as positive or negative. Moreover, positive and negative tweets are considered as subjective.</p><p>Once the feature vectors of all the tweets from the dataset have been extracted, they are used together with the annotated sentiment labels as input for supervised learning algorithms. Several learning algorithms can be used to fulfill this task, e.g., naive Bayes, SVM, decision trees. Finally, the resulting learned function can be used to automatically infer the sentiment label regarding an unseen tweet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Training and testing datasets</head><p>We consider three collections of labeled tweets for our experiments: Stanford Twitter Sentiment (STS), 14 which was used by Go et al. <ref type="bibr" target="#b12">[13]</ref> in their experiments, Sanders, 15 and SemEval, 16 which provide training and testing datasets for a range of interesting and challenging semantic analysis problems, among them, tweets with human annotations for subjectivity and polarity prediction. Each tweet includes a positive, negative or neutral tag. Table <ref type="table" target="#tab_9">7 summa</ref> Negative and positive tweets were considered as subjective.</p><p>Neutral tweets were considered as objective. Subjective/objective tags favor the evaluation of subjectivity detection. For polarity detection tasks, positive and negative tweets were considered, discarding neutral tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Feature analysis</head><p>For each tweet of the three datasets we compute the features summarized in Table <ref type="table" target="#tab_2">1</ref> and<ref type="table" target="#tab_3">Table 2.</ref> As a first analysis we explore how well each feature splits each dataset regarding polarity and subjectivity detection tasks. We do this by calculating the information gain criterion of each feature in each category. The information gain criterion measures the reduction of the entropy within each class after performing the best split induced by the feature. Table <ref type="table">8</ref> shows the information gain values obtained for the subjectivity detection task and Table <ref type="table">9</ref> for polarity.</p><p>As shown in Table <ref type="table">8</ref> and Table <ref type="table">9</ref>, good subjectivity and polarity splits are achieved by using the outcomes of SSPOL and Sent140.</p><p>Lexical-based features retrieved from SentiWordNet, OpinionFinder and AFINN are very useful for polarity and subjectivity detection. We observe also that features retrieved from SenticNet are useful for both tasks. In the case of subjectivity detection, the 669 use of POS-based features is also useful, but is useless for polarity  this approach can be viewed as a feature fusion approach. To 687 explore the combination at the level of features, we discard the 688 use of SSPOL and Sent140 in our classifiers, avoiding the combina-689 tion of labels. In the next section we illustrate that this design deci-   Fig. <ref type="figure" target="#fig_17">2</ref> allows us a side-by-side comparison between score distributions. We observe that in general, the median is located around zero for neutral instances, above zero for positive instances and below zero for negative instances, ratifying the correctness of several of the word hits. Regarding score variance, these plots show that the spread of AFINN, NRC-hash and S140Lex is bigger than the spread of NRC-emotion, Liu and OpFinder. Intuitively, this fact can be explained by the size of the lexicons. AFINN spreads more than NRC-hash and S140Lex in Sanders, but NRC-hash spreads more than AFINN and S140Lex in SemEval on neutral instances. The spread among these three lexicons is very similar in positive and negative Sanders instances. We can conclude that polarity and strength scores vary in median and spread across the different datasets and lexical resources, offering multiple views of the same objects that can be combined using a feature-based fusion strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5.">Fusion of features for sentiment analysis</head><p>In this section we present the methodology we use to create our models for automatic subjectivity and polarity prediction for tweets. We do this by using labels and instances from STS, Sanders and SemEval. We train supervised classifiers to determine subjectivity at tweet level. For this supervised training task we use the labeled tweets obtained from each of the datasets. These labels consider two classes (SUBJECTIVE/NEUTRAL), discussed in Section 4.2.</p><p>We compare our classifiers against a number of strategies: Sent140 and SentiStrength Polarity (SSPOL), as baseline methods.</p><p>We conduct a comparison with NRC-emotion, SenticNet, Liu lexicon, NRC-hash, S140Lex, AFINN, SWN3, and OpinionFinder.</p><p>We experimentally compare the performance of a number of learning algorithms: Naive Bayes, Logistic Regression, Multilayer Perceptron, and Radial Basis Function SVM. All of the experiments are conducted using 10-fold cross-validation for evaluation.</p><p>The use of these learning algorithms allows for the exploration of different aspects of the datasets, such as their suitability for generalization or the presence/absence of non-linearities in the data.</p><p>We study how features contribute in the prediction of subjectivity and evaluate features by dividing them into the following subsets:</p><p>Polarity. Considers all of the features that are based on polarity estimates at tweet-level. This includes the features based on Opin-ionFinder, Bing Liu and NRC lexicons. For each of these lexicons we consider two features: number of positive and negative words.</p><p>Table <ref type="table" target="#tab_2">1</ref> shows a detailed description of these eight features. Emotion. Considers all the features that are based on emotion 776 estimates at tweet level. This includes the features based on 777 NRC-emotion, that is to say, the number of words that match each 778 emotion list, which give us 8 features. Also, those related to Sentic-779 Net, that consider the sum of the scores for each of the opinion 780 aspects modeled by this method (pleasantness, attention, sensitiv-781 ity and aptitude). These twelve features are described in Table <ref type="table" target="#tab_2">1</ref>.  <ref type="table">8</ref>. We observe that in each subset, SSPOL and S140 were 794 selected as features. We exclude them from this subset because 795 they are considered as methods, and their output ranges in the 796 same label space as our learning task. Accordingly, each subset con-797 tains 15 features. In addition, we also test the use of all the features. We now study how features contribute to the prediction of polarity. We train supervised classifiers to determine polarity at tweet level. For this supervised training task we use the labeled tweets obtained from each of the datasets. These labels consider two classes (POSITIVE/NEGATIVE), discussed in Section 4.2. We evaluate features by dividing them into the same subsets considered in the former evaluation. In addition, we consider the same baselines.</p><p>We also test combinations of feature subsets, selecting arbitrary sets of features with a best-first strategy based on information gain criteria. The best features and their information gain values are shown in Table <ref type="table">9</ref>. As was done for subjectivity, we exclude SSPOL and S140 from this subset. In this way, each subset contains 15 features. We observe that for this task, POS-based features do not show good properties regarding information gain, being outperformed for feature selection by lexicon-based features. In addition, we test the use of all the features. Table <ref type="table" target="#tab_13">13</ref> shows the results for the subjectivity classification task.</p><p>Table <ref type="table" target="#tab_13">13</ref> shows that the best baselines are SentiStrength Polarity and Sent140Lex. However, we observe that the combination of  We can see that in STS the feature variance in error instances is smaller than the one achieved by hits. Something similar occurs for the polarity task in Sanders. This fact indicates that a great proportion of the feature values are concentrated around zero, and hits can be explained because one or more lexical resources hit the terms of the tweet, deviating the feature value from zero. This fact indicates also that these errors are related to lexical coverage, that is to say, testing instances that do not hit the lexical resource. We can observe also that STS (for both tasks) and Sanders (polarity) exhibit the best accuracy results in our evaluation, and that this task is almost method-independent (see Tables <ref type="table" target="#tab_12">12</ref> and<ref type="table" target="#tab_13">13</ref>).</p><p>On the other hand, Sanders subjectivity and SemEval (both tasks) show similar variances for error and hits. This fact suggests that features tend to achieve significant values (different from zero), indicating that several lexical resources match the terms used in these testing instances. Error instances exhibit significant intra-variance values, indicating that these errors are related to ambiguity, that is to say, an inherent difficulty to label these instances. However, as Tables <ref type="table" target="#tab_12">12</ref> and<ref type="table" target="#tab_13">13</ref> show, our method achieves good performance values, suggesting that the use of multiple lexical resources offers benefits for sentiment analysis disambiguation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.7.">Cross-transferability of results</head><p>We evaluate the transferability of the best models for each dataset considered in our experiments. One of the goals of this study is to observe how well a given model can generalize to a  <ref type="table" target="#tab_14">14</ref>.</p><p>We observe that the models created using the best features have better generalization properties than those created using all the features, confirming that the performance achieved by the models that use all the features relies entirely on overfitting. This fact is particularly clear in STS and Sanders, where the models    <ref type="table" target="#tab_15">15</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>927</head><p>In terms of transferability, we can observe that the models that 928 were created using the best features are better than the ones cre-929 ated by using all the features. However, the performance gap 930 between both cases is not so significant as the one observed for 931 subjectivity. For instance, STS-all features achieves 0.787% in Sand-932 ers, and STS-best achieves 0.801%. The gap between All and Best is 933 then around two accuracy points. The same comparison gets a 5% 934 gap for subjectivity. We observe also that the models created using Our research shows that the combination of sentiment dimensions provides significant improvements in performance. However, we observe that there are significant differences in performance that rely on the type of lexicon used, the dataset used to build a model, and the learning strategy. Our results indicate that manual-generated lexicons are focused on emotional words, being very useful for polarity prediction. On the other hand, lexicons generated by automatic methods can cover neutral words, introducing noise. We observe that polarity and subjectivity prediction are independent aspects of the same problem that need to be solved using different subspace features. Lexicon-based approaches are recommendable for polarity classification, and stylistic part-ofspeech based approaches are useful for subjectivity.</p><p>Finally, it is important to emphasize that opinions are multidimensional objects. Therefore, when we classify tweets into polarity classes, we are essentially projecting these multiple dimensions to one single categorical dimension. Furthermore, it is not clear how to project tweets having mixed positive and negative expressions to a single polarity class. We have to be aware that the sentiment classification of tweets may lead to the loss of valuable sentiment information.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>about the environment that surrounds them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>57</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 . 3 .</head><label>23</label><figDesc>Strength: These methods and resources provide intensity levels according to a polarity sentiment dimension. Strength-oriented methods return numerical scores indicating the intensity or the 135 strength of positive and negative sentiments expressed in a text 136 passage. Strength-oriented lexical resources provide lists of 137 opinion words together with intensity scores regarding positiv-138 ity and negativity. 139 Emotion: These methods and resources are focused on extract-140 ing emotion or mood states from a text passage. An emotion-141 oriented method should classify the message to an emotional 142 category such as sadness, joy, surprise, among others. Emo-143 tion-oriented lexical resources provide a list of words or expres-144 sions marked according to different emotion states. 145 146</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>202 ciated with positive and negative polarities regarding the subject 203 mentioned in the tweet. Although there are cases where this basic 204 assumption holds, there are some cases where the relation 205 between the emoticon and the tweet subject is not clear. Hence, 206</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>377icon:</head><label></label><figDesc>AFINN Positivity (APO) and AFINN Negativity (ANE), that are 378 the sum of the ratings of positive and negative words of the tweet 379 that matches the AFINN lexicon, respectively. 380 3.1.4. SentiWordNet lexicon 381 SentiWordNet 3.0 (SWN3) is a lexical resource for sentiment 382 classification introduced by Baccianella et al. [1], that is an 383 improvement over the original SentiWordNet proposed by Esuli 384 and Sebastiani [12]. SentiWordNet is an extension of WordNet, 385 the well-known English lexical database where words are clus-386 tered into groups of synonyms known as synsets [19]. In Senti-387 WordNet each synset is automatically annotated in the range 388 ½0; 1 according to positivity, negativity and neutrality. These scores 389 are calculated using semi-supervised algorithms. The resource is 390 available for download. 6 In order to extract strength scores from 391 SentiWordNet, we use word scores to compute a real value from 392 À1 (extremely negative) to 1 (extremely positive), where neutral 393 words receive a zero score. We extract from each tweet two features 394 related to the SentiWordnet lexicon, SentiWordnet Positiveness 395 (SWP) and SentiWordnet Negativeness (SWN), that are the sum 396 of the scores of positive and negative words of the tweet that 397 matches the SentiWordnet lexicon, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>398 3 . 1 . 5 .</head><label>315</label><figDesc>NRC-emotion 399 NRC word-emotion association Lexicon includes a large set of 400 human-provided words with their emotional tags. By conducting 401 a tagging process in the crowdsourcing Amazon Mechanical Turk 402 platform, Mohammad and Turney [20] created a word lexicon that 403 contains more than 14,000 distinct English words annotated 404 according to the Plutchik wheel of emotions. These words can be 405 tagged to multiple categories. Eight emotions were considered dur-406 ing the creation of the lexicon, joy-trust, sadness-anger, surprise-407 fear, and anticipation-disgust, which compounds four opposing 408 pairs. Additionally, NRC words are tagged according to polarity 409 classes positive and negative, which are also considered in this 410 work. The word list is available on request. 7 We extract from each 411 tweet eight emotion features: NRC Joy (NJO), NRC Trust (NTR), NRC Sadness (NSA), NRC Anger (NANG), NRC Surprise (NSU), NRC Fear (NFE), NRC Anticipation (NANT), and NRC Disgust (NDIS), and two polarity features: NRC positive (NRCpos) and NRC negative (NRCneg), that are the number of words of the tweet that matches each category.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>469 tweet three features related to the SentiStrength method: Senti-470 Strength Negativity (SSN) and SentiStrength Positivity (SSP), that 471 correspond to the strength scores for the negative and positive clas-472 ses, respectively, and SentiStrength Polarity (SSPOL), a polarity-ori-473 ented feature corresponding to the neutral label. 474 3.1.10. SenticNet method 475 SenticNet 2 [5] is a concept-based sentiment analysis method 476 that follows the sentic computing paradigm. In contrast to tradi-477 tional sentiment analysis approaches that perform a syntactic-478 level analysis of natural language texts, sentic computing tech-479 niques exploit AI and Semantic Web techniques to conduct a 480 semantic-level analysis. SenticNet extracts both sentiment and 481 semantic information from over 14,000 common sense knowledge 482 concepts found in the message. The concepts are extracted using a 483 graph-based technique. The method returns sentiment variables 484 associated with each of the concepts found in the message: the 485 polarity score, and the sentic vector. The polarity score is a real 486 value similar to strength polarity values provided by other meth-487 ods. The sentic vector is composed of emotion-oriented scores 488 regarding the following emotions: pleasantness, attention, sensi-489 tivity and aptitude. These dimensions are based on the Hourglass 490 model of emotions [7], which in turn, is inspired by Plutchik's stud-491 ies on human emotions. SenticNet concepts as well as the sentic 492 parser are, available to download. 12 493 The features extracted from SenticNet are SenticNet Positivity 494 (SNpos) and SenticNet Negativity(SNneg) that are the sum of the 495 polarity of positive and negative concepts found on the message 496 respectively. Additionally, we extract the following emotion-497 oriented features: SenticNet Pleasantness (SNpleas), SenticNet 498 Attention (SNatten), SenticNet Sensitivity (SNsensi), and 499 SenticNet Aptitude (SNapt) that are the sum of the scores of each 500 sentic dimension for all the concepts found in the message.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>502 4 . 1 .</head><label>41</label><figDesc>Lexicon analysis 503 In this section we study the interaction between the different 504 lexical resources considered in this work: SWN3, NRC-emotion, 505 OpinionFinder, AFINN, Liu Lexicon, NRC-Hashtag, and S140Lex. 506 The aim of this study is to understand which type of information 507 is provided by these resources and how they are related to each 508 other. The lexicons may be compared according to different crite-509 ria: their sentiment scope, the approach used to build them, and 510 the words that they contain. Regarding the sentiment scope we 511 have two polarity-oriented resources: OpinionFinder and Liu, four 512 strength-oriented resources: AFINN, SWN3, NRC-hash, and 513 S140Lex, and one emotion-oriented lexicon: NRC-emotion, which 514 also provides polarity values. 515 Regarding the mechanisms used to build the lexicons, we have 516 three categories: resources created manually, resources created 517 semi-automatically, and resources created completely automati-518 cally. The lexicons Liu, AFINN, OpinionFinder, and NRC-emotion 519 were manually created resources. They were created by taking 520 words from different sources, and their sentiment values were 521 mostly determined by human judgments using tools such as 522 crowdsourcing. SWN3 is a resource created semi-automatically, 523 because its words were taken from a fixed resource (WordNet 524 synsets), but its sentiment values were computed using a 525 semi-supervised approach. Finally, the lexicons NRC-hash and 526 S140Lex are resources created completely automatically, because its words and their sentiment values were jointly extracted from large collections of tweets in an automatic way.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Venn diagrams for the lexicons used in our experiments. (a) Lexicons created manually, and (b) lexicons created semi-automatically and completely automatically.</figDesc><graphic coords="7,167.24,188.50,270.03,145.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>rizes the three datasets. STS and Sanders exhibit unbalance between the number of subjective/neutral instances. Something similar occurs in SemEval between the number of positive/negative instances. We balance these training instances by conducting resampling with replacement, avoiding the creation of models biased toward a specific class. The balanced datasets are available upon request.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>values for subjectivity, we observe 672 that the best splits are achieved in STS. On the other hand, Sanders 673 is very hard to split. Regarding polarity, we observe that the best 674 splits are achieved in STS and Sanders, though SemEval is hard to 675 split. 676 By analyzing the scope, we observe that polarity and strength-677 based features are the most informative for both tasks. This fact is 678 intuitive because the target variables belong to the same scope. In 679 addition, POS-based features are useful for subjectivity. Finally, 680 although emotion features from NRC-emotion lexicon provide 681 almost no information for subjectivity, the emotion joy is able to 682 provide some information for the polarity classification task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>690 sion allows us to elude the effect of label clashes, which is very 691 significant in our evaluation datasets. Accordingly, SSPOL and 692 Sent140 are only considered as baselines in our experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>693 4 . 2 . 3 .</head><label>423</label><figDesc>Clash analysis 694 We conduct a label comparison between baselines and each 695 evaluation dataset used in our experiments. We compare the nom-696 inal labels provided by the datasets, and the labels of Sent140 and 697 SSPOL. The comparison was performed by splitting each dataset 698 into two subsets for each task: (1) Neutral and subjective labeled 699 instances, and (2) Positive and negative labeled instances. For each 700 split, we count the number of label clashes. Then, an error rate 701 (number of mismatches over total number of labeled instances) 702 considered over the total amount of instances per label was calcu-703 lated. Tables 10 and 11 show error rates for subjectivity and polar-704 ity tasks, respectively. 705 Tables 10 and 11 show that error rates are very significant. In 706 particular, Sent140 consistently exhibits very high errors for the 707 polarity task, with rates over the 50%, illustrating its incapacity 708 to generalize to these datasets. On the other hand, SSPOL shows 709 better properties for the detection of positive tweets, but poor abil-710 ities for negativity detection. These high error rates explain why 711 these methods are not suitable for subjectivity detection, indicat-712 ing that the combination of output labels introduces label inconsis-713 tency, discouraging the use of label ensemble methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>714 4 . 2 . 4 .</head><label>424</label><figDesc>Lexical diversity715In this section we argue that the use of multiple lexical 716 resources offers benefits for sentiment analysis tasks. The rationale 717 behind our approach is based on diversity. Multiple lexical 718 resources can be used to describe an object (e.g., a tweet) in the 719 hope that if one or more fail, the others will compensate for it by 720 producing correct features. This principle had sustained it over 721 the independence assumption. As lexical resources were indepen-722 dently created, errors are also independent. 723 We explore diversity by showing the output scores of lexical 724 resources in each dataset split (neutral, positive, and negative 725 instances). Polarity or strength scores of each instance were 726 calculated by adding positive and negative scores. Fig. 2 shows these score distributions, using boxplots with density (a.k.a. vioplots).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>782POS.</head><label></label><figDesc>Considers all the features that are based on Part-Of-Speech 783 estimates at tweet level. This includes the features based on 784 TweetNLP, which give us the number of words in each tweet that 785 match a given POS label. Tweet NLP considers five scopes, Three 786 of them are related to conventional POS tags (Nominal, Open-class 787 words, and closed-class words), another related to Twitter specific 788 tags, and a last one related to punctuation. These five scopes con-789 tain twenty-one features described in Table 2. 790 We test combinations of feature subsets, selecting arbitrary sets 791 of features with a best-first strategy based on information gain cri-792 teria. The best features and their information gain values are shown 793 in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>798</head><label></label><figDesc>The results for the subjectivity classification task are shown in 799Table 12. The best baseline for STS and SemEval is AFINN. In the 800 case of Sanders, the best baseline is Liu Lexicon. The combination 801 of features outperforms the baselines by several accuracy and F-802 measure points. In particular, we observe that the use of the best 803 features subset outperforms baselines and other feature subsets 804 in STS and SemEval. In the case of Sanders, best results are 805 achieved by using all the features, suggesting that this dataset is 806 not well conditioned for generalization. We observe also that the 807 best performance results are achieved by Perceptron and SVM 808 learning algorithms, outperforming Logistic and Bayes learning methods by several accuracy points. This suggests the presence of non-linearities in the feature space. For STS, best results are achieved by Perceptron using All and Best features. However, we observe that POS-based features are useful for this task, outperforming Best features performance. Something similar occurs in Sanders, where Best and All features outperform the other models by several points. In fact, we observe that the best result is achieved by Perceptron over the whole set of features. In this case we observe also that POS-based features are useful for this task, and that the use of Strength features in combination with SVMs offers good results. Regarding SemEval, the best results are achieved by combining Best features with Perceptron-based learning, without significant differences with an SVM model created over the whole feature set, suggesting that Best feature subset offers good generalization properties in this dataset. Once again, the use of POS features in combination with SVMs offers very good results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Neutral, positive and negative instances of each dataset used in our experiments and their polarity or strength score distributions (boxplots with densities, a.k.a. vioplots) in each lexical resource.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>864 4 . 2 . 6 .</head><label>426</label><figDesc>Error analysis865In this section we analyze error instances in each dataset used 866 in our experiments. We conduct a comparison of the intra-variance 867 of each feature vector between hits and error instances. The intra-868 variance of each feature vector is the variance calculated over the 869 set of values that the feature vector registers for a specific data 870 instance. Intuitively, the intra-variance decreases as lexical 871 resources achieve more agreements. Thus, a high intra variance is 872 a measure of disagreement. For each testing instance, we calculate 873 the variance across the features used in the best features-based model. Fig.3shows variance distributions for error and hits instances using boxplots with densities (a.k.a. violin plots).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Feature variance in each dataset used in our experiments for errors and hits classification instances. For each data set, a boxplot with densities is showed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Q1</head><label></label><figDesc>et al. / Knowledge-Based Systems xxx (2014) xxx-xxx KNOSYS 2857 No. of Pages 14, Model 5G 5 June 2014 Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016 created using best features outperform the all features-based mod-913 els by more than 5 accuracy points. We observe also that SemEval914 is the best dataset in terms of generalization. In fact, by using the 915 best feature subspace, the performance in STS (0.831%) is better 916 than the one achieved by the model in its own cross-validation 917 training phase (0.73%), suggesting that STS is a kind of subset of 918 SemEval. On the other hand, we note that it is very difficult to gen-919 eralize through Sanders, and the best results are achieved only by 920 using its own training/testing instances. Finally, STS and Sanders 921 cannot generalize SemEval, falling from 0.911% and 0.815% to 922 0.663% and 0.647% in accuracy, respectively. 923 We continue this section by signaling model transfer for the 924 polarity prediction task. For each dataset we explore the perfor-925 mance of the best model, calculated using all features and best fea-926 tures. These results are shown in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>935 the best features show good generalization properties through the 936 other datasets. For instance SemEval, that achieves a 0.85% accu-937 racy performance in its own training/testing instances, achieves 938 0.844% and 0.804% in STS and Sanders, respectively. In fact, SemE-939 val outperforms the training/testing instances in STS, that achieves 940 0.836%. This fact confirms that STS is a kind of subset of SemEval in 941 terms of polarity. This fact can also explain that STS generalizes 942 well through SemEval. Finally, we observe that the models created 943 using Sanders instances cannot generalize well to the other data-944 sets, confirming that the performance achieved by the Sanders-945 based models relies entirely on overfitting. 946 5. Conclusions 947 We present a novel approach for sentiment classification on 948 microblogging messages or short texts, based on the combination 949 of several existing lexical resources and sentiment analysis meth-950 ods. Our experimental validation shows that our classifiers achieve very significant improvements over any individual method, outperforming state-of-the-art methods by more than 5% in accuracy and F 1 points. Considering that the proposed feature representation does not depend directly on the vocabulary size of the collection, it provides a considerable dimensionality reduction in comparison to word-based representations such as unigrams or n-grams. Likewise, our approach avoids the sparsity problem presented by word-based feature representations for Twitter sentiment classification discussed in [22]. Hence, our low-dimensional feature representation allows us to efficiently use several learning algorithms. The classification results varied significantly from one dataset to another. The manual sentiment classification of tweets is a subjective task that can be biased by the evaluator's perceptions. This fact should serve as a warning against bold conclusions from inadequate evidence in sentiment classification. It is very important to check beforehand whether the labels in the training dataset correspond to the desired values, and if the training examples are able to capture the sentiment diversity of the target domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>features based on the 325 frequency of each POS tag found in the message. The tagging task 326 was done through the Carnegie Mellon University (CMU) Twitter 327 NLP tool 4 which is focused on informal, online conversational mes- 328 sages such as tweets. These features are summarized in Table 2 329 and can be grouped into the following categories: nominal words,</head><label></label><figDesc></figDesc><table><row><cell>The meta-level features are based on existing lexical resources and sentiment analysis methods which summarize the main efforts discussed in Section 2. All of these methods and resources et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// F. Bravo-Marquez analysis method, all their outcomes are included as dimensions in Q1 Q1 the feature vector. These features are summarized in Table 1 and are described together with their respective methods and resources in Section 3.1. Furthermore, all the resources and meth-ods from which they are calculated are publicly available, facilitat-ing repeatability of our experiments. We also calculated part-of-speech (POS) 330 319 320 321 322 323 324 open and closed class words, Twitter specific and miscellaneous. 331 3.1. Meta-level features 332 3.1.1. OpinionFinder lexicon 333 The OpinionFinder Lexicon is a polarity oriented lexical 334 resource created by Wilson et al. [33]. It is an extension of the 335 Multi-Perspective Question-Answering dataset (MPQA), that 336 includes phrases and subjective sentences. A group of human 337 annotators tagged each sentence according to the polarity classes: 338 positive, negative, neutral. The lexicon also includes 17 words with 339 mixed positive and negative polarities tagged as ''both'', which 340 were omitted in this work. A pruning phase was conducted over 341 the dataset to eliminate tags with low agreement. Thus, a list of 342 sentences and single words was consolidated with their polarity 343 tags. In this study we consider single words (unigrams) tagged as 344 positive or negative, that correspond to a list of 6,884 English 345 words. We extract from each tweet two features related to the et al. / Knowledge-Based Systems xxx (2014) xxx-xxx Please cite this article in press as: F. Bravo-Marquez 346 OpinionFinder lexicon, OpinionFinder Positive Words (OPW)</cell></row><row><cell>dx.doi.org/10.1016/j.knosys.2014.05.016</cell></row></table><note><p>represent different approaches for extracting sentiment information from textual data: unsupervised, semi-supervised, and concept-based approaches. Likewise, three different sentiment dimensions can be covered by these approaches: polarity, strength, and emotions. From each lexical resource we calculate a number of features according to the number of matches between the words from the tweet and the words from the lexicon. If the lexical resource provides strength values for words, then the features are calculated through a weighted sum. Finally, for each sentiment 3 http://www.cs.york.ac.uk/semeval-2013/task2/.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Sentiment-based features can be grouped into three classes of scope: polarity, strength, and emotion.</figDesc><table><row><cell>Scope</cell><cell>Feature</cell><cell>Source</cell><cell>Description</cell></row></table><note><p>NDIS . . . matches the disgust word list f0; 1; . . . ; ng SNpleas SenticNet Sum of the pleasantness scores for the concepts that matches the lexicon ½0; . . . ; 1½ SNatten Sum of the attention scores for the concepts that matches the lexicon ½0; . . . ; 1½ SNsensi Sum of the sensitivity scores for the concepts that matches the lexicon ½0; . . . ; 1½ SNapt Sum of the aptitude scores for the concepts that matches the lexicon ½0; . . . ; 1½ Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016 We extract from each tweet two features related to the AFINN lex-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Part-of-speech-based features.À1 (negative), 0 (neutral), and 1 (positive). We extract from each</figDesc><table><row><cell>KNOSYS 2857</cell><cell></cell><cell></cell><cell>No. of Pages 14, Model 5G</cell></row><row><cell>5 June 2014</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Q1</cell><cell></cell><cell>F. Bravo-Marquez</cell><cell>et al. / Knowledge-Based Systems xxx (2014) xxx-xxx</cell><cell>5</cell></row><row><cell>Scope</cell><cell>Feature</cell><cell>Description</cell><cell></cell></row><row><cell>Nominal</cell><cell>VN</cell><cell cols="2">Common noun</cell></row><row><cell></cell><cell>VO</cell><cell cols="2">Personal pronoun</cell></row><row><cell></cell><cell>VPROP</cell><cell>Proper noun</cell><cell></cell></row><row><cell></cell><cell>VS</cell><cell cols="2">Nominal + possessive</cell></row><row><cell></cell><cell>VZ</cell><cell cols="2">Proper noun + possessive</cell></row><row><cell>Open-class words</cell><cell>VV</cell><cell>Verb</cell><cell></cell></row><row><cell></cell><cell>VA</cell><cell>Adjective</cell><cell></cell></row><row><cell></cell><cell>VR</cell><cell>Adverb</cell><cell></cell></row><row><cell></cell><cell>VI</cell><cell>Interjection</cell><cell></cell></row><row><cell>Closed-class words</cell><cell>VD</cell><cell>Determiner</cell><cell></cell></row><row><cell></cell><cell>VP</cell><cell cols="2">Pre or postposition</cell></row><row><cell></cell><cell>VAND</cell><cell>Conjunction</cell><cell></cell></row><row><cell></cell><cell>VT</cell><cell>Verb particle</cell><cell></cell></row><row><cell></cell><cell>VX</cell><cell cols="2">Predeterminers</cell></row><row><cell>Twitter/online-specific</cell><cell>VHASH</cell><cell>Hashtag</cell><cell></cell></row><row><cell></cell><cell>VARRO</cell><cell cols="2">@ -at mention</cell></row><row><cell></cell><cell>VU</cell><cell cols="2">URL or email address</cell></row><row><cell></cell><cell>VE</cell><cell>Emoticon</cell><cell></cell></row><row><cell>Miscellaneous</cell><cell>V$</cell><cell>Numeral</cell><cell></cell></row><row><cell></cell><cell>VPUNCT</cell><cell>Punctuation</cell><cell></cell></row><row><cell></cell><cell>VG</cell><cell>Foreign words</cell><cell></cell></row></table><note><p><p>6 </p>http://sentiwordnet.isti.cnr.it/. 7 mailto: saif.mohammad@nrc-cnrc.gc.ca. 8 http://www.umiacs.umd.edu/$saif/WebDocs/NRC-Hashtag-Sentiment-Lexicon-v0.1.zip. 9 http://www.sentiment140.com/. 10 http://help.sentiment140.com/api. 11 http://sentistrength.wlv.ac.uk/. Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table we see that the agreement between lexicons created manually is very high, indicating that different human judgements tend to agree with each other. On the other hand, large lexicons created semiautomatically and completely automatically shows a high level of</figDesc><table><row><cell></cell><cell>KNOSYS 2857</cell><cell></cell><cell>No. of Pages 14, Model 5G</cell></row><row><cell></cell><cell>5 June 2014</cell><cell></cell><cell></cell></row><row><cell>Q1</cell><cell>6</cell><cell>F. Bravo-Marquez</cell><cell>et al. / Knowledge-Based Systems xxx (2014) xxx-xxx</cell></row><row><cell></cell><cell cols="3">disagreement with the human-made lexicons and even greater lev-</cell></row><row><cell>594</cell><cell cols="3">els of disagreement between each other. That means, that these</cell></row><row><cell>595</cell><cell cols="3">resources, despite being larger, tend to provide noisy information,</cell></row><row><cell>596</cell><cell>which is far from being consolidated.</cell><cell></cell><cell></cell></row></table><note><p><p>12 </p>http://sentic.net/. Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Intersection of words.</figDesc><table><row><cell>Intersection</cell><cell>OpFinder</cell><cell>AFINN</cell><cell>S140Lex</cell><cell>NRC-hash</cell><cell>Liu</cell><cell>SWN3</cell><cell>NRC-emotion</cell></row><row><cell>OpFinder</cell><cell>6884</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>AFINN</cell><cell>1245</cell><cell>2484</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>S140Lex</cell><cell>3460</cell><cell>1789</cell><cell>60; 113</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>NRC-hash</cell><cell>3541</cell><cell>1816</cell><cell>27; 012</cell><cell>42; 586</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>Liu</cell><cell>5413</cell><cell>1313</cell><cell>3268</cell><cell>3312</cell><cell>6783</cell><cell>Â</cell><cell>Â</cell></row><row><cell>SWN3</cell><cell>6199</cell><cell>1783</cell><cell>16; 845</cell><cell>17; 314</cell><cell>5480</cell><cell>146; 977</cell><cell>Â</cell></row><row><cell>NRC-emotion</cell><cell>3596</cell><cell>1207</cell><cell>8815</cell><cell>8995</cell><cell>3024</cell><cell>13; 634</cell><cell>14; 182</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Neutrality and uniqueness of each lexicon.</figDesc><table><row><cell>Lexicon</cell><cell>Uniqueness</cell><cell>Neutrality</cell></row><row><cell>OpFinder</cell><cell>0.01</cell><cell>0.06</cell></row><row><cell>AFINN</cell><cell>0.19</cell><cell>0.00</cell></row><row><cell>S140Lex</cell><cell>0.51</cell><cell>0.62</cell></row><row><cell>NRC-hash</cell><cell>0.29</cell><cell>0.72</cell></row><row><cell>Liu</cell><cell>0.05</cell><cell>0.00</cell></row><row><cell>SWN3</cell><cell>0.82</cell><cell>0.74</cell></row><row><cell>NRC-emotion</cell><cell>0.01</cell><cell>0.54</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Agreement of lexicons.</figDesc><table><row><cell>Agreement</cell><cell>OpFinder</cell><cell>AFINN</cell><cell>S140Lex</cell><cell>NRC-hash</cell><cell>Liu</cell><cell>SWN3</cell><cell>NRC-emotion</cell></row><row><cell>OpFinder</cell><cell>1</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>AFINN</cell><cell>0.99</cell><cell>1</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>S140Lex</cell><cell>0.82</cell><cell>0.82</cell><cell>1</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>NRC-hash</cell><cell>0.79</cell><cell>0.79</cell><cell>0.72</cell><cell>1</cell><cell>Â</cell><cell>Â</cell><cell>Â</cell></row><row><cell>Liu</cell><cell>0.99</cell><cell>0.99</cell><cell>0.82</cell><cell>0.79</cell><cell>1</cell><cell>Â</cell><cell>Â</cell></row><row><cell>SWN3</cell><cell>0.85</cell><cell>0.76</cell><cell>0.66</cell><cell>0.64</cell><cell>0.84</cell><cell>1</cell><cell>Â</cell></row><row><cell>NRC-emotion</cell><cell>0.99</cell><cell>0.99</cell><cell>0.84</cell><cell>0.82</cell><cell>0.99</cell><cell>0.86</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Sentiment values for different words.</figDesc><table><row><cell>Word</cell><cell>OpFinder</cell><cell>AFINN</cell><cell>S140Lex</cell><cell>NRC-hash</cell><cell>LiuLex</cell><cell>SWN3</cell><cell>NRC-emotion</cell></row><row><cell>Excuse</cell><cell>pos</cell><cell>À1</cell><cell>0.34</cell><cell>À1.08</cell><cell>neg</cell><cell>0.00</cell><cell>neg</cell></row><row><cell>Futile</cell><cell>neg</cell><cell>2</cell><cell>0.05</cell><cell>0.07</cell><cell>neg</cell><cell>À0.50</cell><cell>sad</cell></row><row><cell>Irresponsible</cell><cell>neg</cell><cell>2</cell><cell>À1.11</cell><cell>À1.87</cell><cell>neg</cell><cell>0.50</cell><cell>neg</cell></row><row><cell>Joke</cell><cell>pos</cell><cell>2</cell><cell>À0.02</cell><cell>À1.50</cell><cell>neg</cell><cell>0.32</cell><cell>neg</cell></row><row><cell>Stunned</cell><cell>pos</cell><cell>À2</cell><cell>À0.14</cell><cell>0.38</cell><cell>pos</cell><cell>À0.31</cell><cell>neg, sur, fea</cell></row></table><note><p>Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc>Datasets statistics.We use information gain as a criterion for feature selection.</figDesc><table><row><cell></cell><cell></cell><cell>STS</cell><cell>Sanders</cell><cell></cell><cell>SemEval</cell></row><row><cell>#negative</cell><cell></cell><cell>177</cell><cell>636</cell><cell></cell><cell>3639</cell></row><row><cell>#neutral</cell><cell></cell><cell>139</cell><cell>2429</cell><cell></cell><cell>4585</cell></row><row><cell>#positive</cell><cell></cell><cell>182</cell><cell>560</cell><cell></cell><cell>1458</cell></row><row><cell>#total</cell><cell></cell><cell>498</cell><cell>3625</cell><cell></cell><cell>9682</cell></row><row><cell>Table 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Ranked features for subjectivity classification.</cell><cell></cell><cell></cell></row><row><cell>STS</cell><cell></cell><cell>Sanders</cell><cell></cell><cell>SemEval</cell><cell></cell></row><row><cell>Inf gain</cell><cell>Feature</cell><cell>Inf gain</cell><cell>Feature</cell><cell>Inf gain</cell><cell>Feature</cell></row><row><cell>0.217</cell><cell>SWP</cell><cell>0.090</cell><cell>SNneg</cell><cell>0.113</cell><cell>APO</cell></row><row><cell>0.199</cell><cell>SSPOL</cell><cell>0.089</cell><cell>SWP</cell><cell>0.109</cell><cell>SSPOL</cell></row><row><cell>0.198</cell><cell>SNpleas</cell><cell>0.088</cell><cell>SSPOL</cell><cell>0.105</cell><cell>SSP</cell></row><row><cell>0.161</cell><cell>SNpos</cell><cell>0.079</cell><cell>SNpos</cell><cell>0.082</cell><cell>BLPW</cell></row><row><cell>0.152</cell><cell>BLNW</cell><cell>0.077</cell><cell>NRCHashNeg</cell><cell>0.062</cell><cell>SWP</cell></row><row><cell>0.151</cell><cell>SWN</cell><cell>0.074</cell><cell>SNatten</cell><cell>0.055</cell><cell>OPW</cell></row><row><cell>0.135</cell><cell>ONW</cell><cell>0.073</cell><cell>SNsensi</cell><cell>0.046</cell><cell>Sent140</cell></row><row><cell>0.134</cell><cell>SNsensi</cell><cell>0.072</cell><cell>SNpleas</cell><cell>0.044</cell><cell>S140LexNeg</cell></row><row><cell>0.132</cell><cell>ANE</cell><cell>0.070</cell><cell>VU</cell><cell>0.038</cell><cell>NJO</cell></row><row><cell>0.129</cell><cell>SSP</cell><cell>0.070</cell><cell>S140LexNeg</cell><cell>0.033</cell><cell>ANE</cell></row><row><cell>0.123</cell><cell>S140LexPos</cell><cell>0.070</cell><cell>Sent140</cell><cell>0.026</cell><cell>VPROP</cell></row><row><cell>0.122</cell><cell>APO</cell><cell>0.067</cell><cell>ANE</cell><cell>0.026</cell><cell>VP</cell></row><row><cell>0.122</cell><cell>VU</cell><cell>0.065</cell><cell>BLNW</cell><cell>0.024</cell><cell>SNpos</cell></row><row><cell>0.119</cell><cell>Sent140</cell><cell>0.064</cell><cell>SWN</cell><cell>0.024</cell><cell>SNpleas</cell></row><row><cell>0.119</cell><cell>S140LexNeg</cell><cell>0.062</cell><cell>SSN</cell><cell>0.024</cell><cell>VU</cell></row><row><cell>0.116</cell><cell>BLPW</cell><cell>0.050</cell><cell>S140LexPos</cell><cell>0.023</cell><cell>VE</cell></row><row><cell>0.100</cell><cell>SNapt</cell><cell>0.050</cell><cell>VARRO</cell><cell>0.022</cell><cell>SSN</cell></row><row><cell>Table 9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Ranked features for polarity classification.</cell><cell></cell><cell></cell></row><row><cell>STS</cell><cell></cell><cell>Sanders</cell><cell></cell><cell>SemEval</cell><cell></cell></row><row><cell cols="2">Inf gain Feature</cell><cell cols="2">Inf gain Feature</cell><cell cols="2">Inf gain Feature</cell></row><row><cell>0.318</cell><cell>S140LexNeg</cell><cell>0.323</cell><cell>SWN</cell><cell>0.261</cell><cell>S140LexNeg</cell></row><row><cell>0.318</cell><cell>Sent140</cell><cell>0.260</cell><cell cols="2">NRCHashNeg 0.261</cell><cell>Sent140</cell></row><row><cell>0.283</cell><cell>SSPOL</cell><cell>0.220</cell><cell>Sent140</cell><cell>0.190</cell><cell>SSPOL</cell></row><row><cell>0.260</cell><cell>BLNW</cell><cell>0.220</cell><cell>S140LexNeg</cell><cell>0.178</cell><cell>ANE</cell></row><row><cell>0.219</cell><cell>SSP</cell><cell>0.199</cell><cell>S140LexPos</cell><cell>0.151</cell><cell>NRCHashNeg</cell></row><row><cell>0.207</cell><cell>SSN</cell><cell>0.179</cell><cell>SNsensi</cell><cell>0.148</cell><cell>BLNW</cell></row><row><cell>0.204</cell><cell>ANE</cell><cell>0.172</cell><cell>SSPOL</cell><cell>0.142</cell><cell>S140LexPos</cell></row><row><cell>0.193</cell><cell>S140LexPos</cell><cell>0.162</cell><cell>NRCHashPos</cell><cell>0.137</cell><cell>SSP</cell></row><row><cell>0.172</cell><cell>APO</cell><cell>0.141</cell><cell>SNapt</cell><cell>0.131</cell><cell>SWN</cell></row><row><cell>0.152</cell><cell>BLPW</cell><cell>0.135</cell><cell>SNneg</cell><cell>0.131</cell><cell>APO</cell></row><row><cell>0.141</cell><cell>SWN</cell><cell>0.134</cell><cell>SSP</cell><cell>0.119</cell><cell>SSN</cell></row><row><cell>0.139</cell><cell>ONW</cell><cell>0.128</cell><cell>SNpleas</cell><cell>0.108</cell><cell>NRCHashPos</cell></row><row><cell>0.129</cell><cell>SNneg</cell><cell>0.126</cell><cell>ANE</cell><cell>0.107</cell><cell>BLPW</cell></row><row><cell>0.106</cell><cell>NRCHashPos</cell><cell>0.124</cell><cell>APO</cell><cell>0.098</cell><cell>SNpleas</cell></row><row><cell>0.099</cell><cell cols="2">NRCHashNeg 0.119</cell><cell>BLNW</cell><cell>0.095</cell><cell>SNneg</cell></row><row><cell>0.090</cell><cell>SNpleas</cell><cell>0.108</cell><cell>SSN</cell><cell>0.082</cell><cell>ONW</cell></row><row><cell>0.082</cell><cell>OPW</cell><cell>0.104</cell><cell>BLPW</cell><cell>0.070</cell><cell>NJO</cell></row></table><note><p><p><p><p><p><p><p><p>13 </p>http://sentiment.christopherpotts.net/lexicons.html.</p>14 </p>http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip.</p>15 </p>http://www.sananalytics.com/lab/twitter-sentiment/.</p>16 </p>http://www.cs.york.ac.uk/semeval-2012/. Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10</head><label>10</label><figDesc>Number of clashes (percentage over number of labeled instances) per dataset for neutral and subjectivity errors for the baseline methods used in our evaluation.</figDesc><table><row><cell>Dataset</cell><cell>Sent140</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11</head><label>11</label><figDesc>Number of clashes (percentage over number of labeled instances) per dataset for positive and negative errors for the baseline methods used in our evaluation. Considers all the features that are based on strength 773 estimates at tweet level. Table1shows a detailed description of</figDesc><table><row><cell>Dataset</cell><cell>Sent140</cell></row></table><note><p>Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016 Strength. 774 these twelve features. 775</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12</head><label>12</label><figDesc></figDesc><table><row><cell>Q7</cell><cell>10-Fold cross-validat</cell><cell cols="2">ion subjectivity classification performances.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Features</cell><cell>Methods</cell><cell>STS</cell><cell></cell><cell>Sanders</cell><cell></cell><cell>SemEval</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Accuracy</cell><cell>F 1</cell><cell>Accuracy</cell><cell>F 1</cell><cell>Accuracy</cell><cell>F 1</cell></row><row><cell></cell><cell>Baselines</cell><cell>Sent140</cell><cell>0.688 ± 0.06</cell><cell>0.596 ± 0.09</cell><cell>0.623 ± 0.02</cell><cell>0.574 ± 0.03</cell><cell>0.62 ± 0.01</cell><cell>0.573 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>SSPOL</cell><cell>0.769 ± 0.07</cell><cell>0.772 ± 0.07</cell><cell>0.636 ± 0.01</cell><cell>0.681 ± 0.02</cell><cell>0.683 ± 0.01</cell><cell>0.719 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>NRC-emotion</cell><cell>0.618 ± 0.08</cell><cell>0.602 ± 0.05</cell><cell>0.599 ± 0.08</cell><cell>0.59 ± 0.07</cell><cell>0.611 ± 0.01</cell><cell>0.61 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>SenticNet</cell><cell>0.682 ± 0.07</cell><cell>0.673 ± 0.02</cell><cell>0.611 ± 0.09</cell><cell>0.605 ± 0.03</cell><cell>0.593 ± 0.02</cell><cell>0.594 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>Bing Liu Lex</cell><cell>0.75 ± 0.03</cell><cell>0.74 ± 0.02</cell><cell>0.664 ± 0.06</cell><cell>0.65 ± 0.02</cell><cell>0.663 ± 0.01</cell><cell>0.66 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>NRC-hash</cell><cell>0.631 ± 0.07</cell><cell>0.61 ± 0.05</cell><cell>0.622 ± 0.02</cell><cell>0.62 ± 0.01</cell><cell>0.55 ± 0.1</cell><cell>0.53 ± 0.08</cell></row><row><cell></cell><cell></cell><cell>Sent140 Lex</cell><cell>0.701 ± 0.09</cell><cell>0.68 ± 0.08</cell><cell>0.623 ± 0.1</cell><cell>0.63 ± 0.05</cell><cell>0.608 ± 0.06</cell><cell>0.602 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>AFINN</cell><cell>0.792 ± 0.03</cell><cell>0.796 ± 0.01</cell><cell>0.649 ± 0.1</cell><cell>0.64 ± 0.04</cell><cell>0.703 ± 0.01</cell><cell>0.7 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>SWN3</cell><cell>0.742 ± 0.04</cell><cell>0.73 ± 0.02</cell><cell>0.618 ± 0.06</cell><cell>0.62 ± 0.02</cell><cell>0.63 ± 0.02</cell><cell>0.63 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>OpFinder</cell><cell>0.744 ± 0.02</cell><cell>0.74 ± 0.01</cell><cell>0.62 ± 0.02</cell><cell>0.61 ± 0.01</cell><cell>0.613 ± 0.08</cell><cell>0.611 ± 0.02</cell></row><row><cell></cell><cell>Best</cell><cell>Naive Bayes</cell><cell>0.792 ± 0.03</cell><cell>0.771 ± 0.05</cell><cell>0.656 ± 0.02</cell><cell>0.582 ± 0.03</cell><cell>0.719 ± 0.01</cell><cell>0.689 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Logistic</cell><cell>0.79 ± 0.04</cell><cell>0.782 ± 0.04</cell><cell>0.693 ± 0.03</cell><cell>0.677 ± 0.02</cell><cell>0.726 ± 0.01</cell><cell>0.719 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Perceptron</cell><cell>0.911 ± 0.02</cell><cell>0.911 ± 0.01</cell><cell>0.75 ± 0.02</cell><cell>0.75 ± 0.01</cell><cell>0.73 ± 0.01</cell><cell>0.735 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>SVM</cell><cell>0.837 ± 0.04</cell><cell>0.85 ± 0.04</cell><cell>0.815 ± 0.01</cell><cell>0.831 ± 0.01</cell><cell>0.726 ± 0.01</cell><cell>0.715 ± 0.02</cell></row><row><cell></cell><cell>All</cell><cell>Naive Bayes</cell><cell>0.788 ± 0.04</cell><cell>0.767 ± 0.06</cell><cell>0.661 ± 0.02</cell><cell>0.612 ± 0.03</cell><cell>0.688 ± 0.01</cell><cell>0.656 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>Logistic</cell><cell>0.765 ± 0.08</cell><cell>0.758 ± 0.08</cell><cell>0.698 ± 0.02</cell><cell>0.687 ± 0.02</cell><cell>0.732 ± 0.01</cell><cell>0.724 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Perceptron</cell><cell>0.945 ± 0.02</cell><cell>0.945 ± 0.01</cell><cell>0.929 ± 0.01</cell><cell>0.93 ± 0.01</cell><cell>0.713 ± 0.01</cell><cell>0.713 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>SVM</cell><cell>0.818 ± 0.08</cell><cell>0.813 ± 0.08</cell><cell>0.872 ± 0.01</cell><cell>0.855 ± 0.02</cell><cell>0.734 ± 0.01</cell><cell>0.726 ± 0.01</cell></row><row><cell></cell><cell>Polarity</cell><cell>Naive Bayes</cell><cell>0.787 ± 0.04</cell><cell>0.754 ± 0.08</cell><cell>0.652 ± 0.02</cell><cell>0.594 ± 0.04</cell><cell>0.69 ± 0.02</cell><cell>0.661 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>Logistic</cell><cell>0.793 ± 0.06</cell><cell>0.782 ± 0.06</cell><cell>0.686 ± 0.02</cell><cell>0.678 ± 0.02</cell><cell>0.709 ± 0.01</cell><cell>0.717 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Perceptron</cell><cell>0.914 ± 0.03</cell><cell>0.914 ± 0.02</cell><cell>0.758 ± 0.02</cell><cell>0.758 ± 0.01</cell><cell>0.63 ± 0.03</cell><cell>0.636 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>SVM</cell><cell>0.782 ± 0.07</cell><cell>0.787 ± 0.06</cell><cell>0.733 ± 0.03</cell><cell>0.729 ± 0.03</cell><cell>0.712 ± 0.01</cell><cell>0.707 ± 0.01</cell></row><row><cell></cell><cell>Strength</cell><cell>Naive Bayes</cell><cell>0.803 ± 0.06</cell><cell>0.781 ± 0.07</cell><cell>0.657 ± 0.02</cell><cell>0.595 ± 0.02</cell><cell>0.697 ± 0.01</cell><cell>0.658 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Logistic</cell><cell>0.797 ± 0.04</cell><cell>0.79 ± 0.05</cell><cell>0.693 ± 0.02</cell><cell>0.675 ± 0.02</cell><cell>0.721 ± 0.01</cell><cell>0.708 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Perceptron</cell><cell>0.88 ± 0.04</cell><cell>0.87 ± 0.03</cell><cell>0.717 ± 0.04</cell><cell>0.717 ± 0.01</cell><cell>0.719 ± 0.03</cell><cell>0.71 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>SVM</cell><cell>0.792 ± 0.04</cell><cell>0.767 ± 0.06</cell><cell>0.876 ± 0.02</cell><cell>0.861 ± 0.02</cell><cell>0.725 ± 0.01</cell><cell>0.715 ± 0.02</cell></row><row><cell></cell><cell>Emotion</cell><cell>Naive Bayes</cell><cell>0.649 ± 0.06</cell><cell>0.592 ± 0.1</cell><cell>0.594 ± 0.02</cell><cell>0.494 ± 0.02</cell><cell>0.602 ± 0.01</cell><cell>0.533 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Logistic</cell><cell>0.679 ± 0.06</cell><cell>0.633 ± 0.09</cell><cell>0.601 ± 0.03</cell><cell>0.545 ± 0.03</cell><cell>0.617 ± 0.01</cell><cell>0.583 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>Perceptron</cell><cell>0.763 ± 0.1</cell><cell>0.752 ± 0.04</cell><cell>0.669 ± 0.1</cell><cell>0.667 ± 0.02</cell><cell>0.614 ± 0.02</cell><cell>0.614 ± 0.01</cell></row><row><cell></cell><cell></cell><cell>SVM</cell><cell>0.694 ± 0.05</cell><cell>0.655 ± 0.07</cell><cell>0.794 ± 0.02</cell><cell>0.808 ± 0.02</cell><cell>0.623 ± 0.01</cell><cell>0.589 ± 0.02</cell></row><row><cell></cell><cell>POS</cell><cell>Naive Bayes</cell><cell>0.714 ± 0.09</cell><cell>0.71 ± 0.03</cell><cell>0.665 ± 0.02</cell><cell>0.668 ± 0.01</cell><cell>0.695 ± 0.1</cell><cell>0.694 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>Logistic</cell><cell>0.775 ± 0.05</cell><cell>0.77 ± 0.02</cell><cell>0.691 ± 0.04</cell><cell>0.69 ± 0.02</cell><cell>0.655 ± 0.04</cell><cell>0.653 ± 0.03</cell></row><row><cell></cell><cell></cell><cell>Perceptron</cell><cell>0.914 ± 0.02</cell><cell>0.914 ± 0.01</cell><cell>0.758 ± 0.02</cell><cell>0.75 ± 0.01</cell><cell>0.637 ± 0.03</cell><cell>0.63 ± 0.02</cell></row><row><cell></cell><cell></cell><cell>SVM</cell><cell>0.789 ± 0.1</cell><cell>0.765 ± 0.08</cell><cell>0.821 ± 0.04</cell><cell>0.822 AE0.01</cell><cell>0.749 ± 0.01</cell><cell>0.749 ± 0.01</cell></row></table><note><p>Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016 different dataset. We start this section by analyzing model transfer 903 for the subjectivity prediction task. 904 For each dataset we explore the performance of the best model, 905 computed from all features and best features, evaluating this 906 model in the other datasets. These results are shown in Table</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 10</head><label>13</label><figDesc>-fold cross-validation polarity classification performances.</figDesc><table><row><cell>Features</cell><cell>Methods</cell><cell>STS</cell><cell></cell><cell>Sanders</cell><cell></cell><cell>SemEval</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Accuracy</cell><cell>F 1</cell><cell>Accuracy</cell><cell>F 1</cell><cell>Accuracy</cell><cell>F 1</cell></row><row><cell>Baselines</cell><cell>Sent140</cell><cell>0.712 ± 0.05</cell><cell>0.691 ± 0.04</cell><cell>0.688 ± 0.07</cell><cell>0.673 ± 0.03</cell><cell>0.725 ± 0.05</cell><cell>0.712 ± 0.01</cell></row><row><cell></cell><cell>SSPOL</cell><cell>0.772 ± 0.03</cell><cell>0.764 ± 0.05</cell><cell>0.729 ± 0.04</cell><cell>0.734 ± 0.03</cell><cell>0.755 ± 0.02</cell><cell>0.754 ± 0.02</cell></row><row><cell></cell><cell>NRC-emotion</cell><cell>0.668 ± 0.07</cell><cell>0.66 ± 0.06</cell><cell>0.656 ± 0.05</cell><cell>0.654 ± 0.04</cell><cell>0.659 ± 0.02</cell><cell>0.657 ± 0.02</cell></row><row><cell></cell><cell>SenticNet</cell><cell>0.592 ± 0.05</cell><cell>0.687 ± 0.06</cell><cell>0.534 ± 0.03</cell><cell>0.645 ± 0.03</cell><cell>0.568 ± 0.03</cell><cell>0.688 ± 0.03</cell></row><row><cell></cell><cell>Bing Liu Lex</cell><cell>0.769 ± 0.05</cell><cell>0.739 ± 0.06</cell><cell>0.72 ± 0.02</cell><cell>0.675 ± 0.04</cell><cell>0.727 ± 0.02</cell><cell>0.695 ± 0.02</cell></row><row><cell></cell><cell>NRC-hash</cell><cell>0.729 ± 0.05</cell><cell>0.727 ± 0.05</cell><cell>0.676 ± 0.03</cell><cell>0.581 ± 0.04</cell><cell>0.704 ± 0.02</cell><cell>0.73 ± 0.02</cell></row><row><cell></cell><cell>Sent140 Lex</cell><cell>0.797 ± 0.06</cell><cell>0.777 ± 0.09</cell><cell>0.729 ± 0.05</cell><cell>0.714 ± 0.05</cell><cell>0.753 ± 0.01</cell><cell>0.77 ± 0.02</cell></row><row><cell></cell><cell>AFINN</cell><cell>0.771 ± 0.08</cell><cell>0.759 ± 0.07</cell><cell>0.724 ± 0.03</cell><cell>0.707 ± 0.04</cell><cell>0.742 ± 0.02</cell><cell>0.731 ± 0.03</cell></row><row><cell></cell><cell>SWN3</cell><cell>0.72 ± 0.05</cell><cell>0.72 ± 0.06</cell><cell>0.625 ± 0.04</cell><cell>0.64 ± 0.04</cell><cell>0.68 ± 0.02</cell><cell>0.693 ± 0.02</cell></row><row><cell></cell><cell>OpFinder</cell><cell>0.743 ± 0.06</cell><cell>0.735 ± 0.06</cell><cell>0.632 ± 0.05</cell><cell>0.621 ± 0.04</cell><cell>0.675 ± 0.03</cell><cell>0.676 ± 0.04</cell></row><row><cell>Best</cell><cell>Naive Bayes</cell><cell>0.817 ± 0.05</cell><cell>0.827 ± 0.06</cell><cell>0.803 ± 0.02</cell><cell>0.812 ± 0.02</cell><cell>0.826 ± 0.02</cell><cell>0.83 ± 0.02</cell></row><row><cell></cell><cell>Logistic</cell><cell>0.834 ± 0.05</cell><cell>0.835 ± 0.05</cell><cell>0.816 ± 0.02</cell><cell>0.815 ± 0.03</cell><cell>0.84 ± 0.02</cell><cell>0.84 ± 0.02</cell></row><row><cell></cell><cell>Perceptron</cell><cell>0.796 ± 0.01</cell><cell>0.796 ± 0.01</cell><cell>0.914 ± 0.01</cell><cell>0.915 ± 0.01</cell><cell>0.85 ± 0.01</cell><cell>0.85 ± 0.01</cell></row><row><cell></cell><cell>SVM</cell><cell>0.836 ± 0.03</cell><cell>0.837 ± 0.04</cell><cell>0.915 ± 0.02</cell><cell>0.908 ± 0.02</cell><cell>0.84 ± 0.01</cell><cell>0.837 ± 0.01</cell></row><row><cell>All</cell><cell>Naive Bayes</cell><cell>0.808 ± 0.03</cell><cell>0.817 ± 0.03</cell><cell>0.771 ± 0.03</cell><cell>0.786 ± 0.02</cell><cell>0.81 ± 0.02</cell><cell>0.816 ± 0.02</cell></row><row><cell></cell><cell>Logistic</cell><cell>0.807 ± 0.07</cell><cell>0.814 ± 0.06</cell><cell>0.823 ± 0.02</cell><cell>0.824 ± 0.02</cell><cell>0.841 ± 0.01</cell><cell>0.84 ± 0.02</cell></row><row><cell></cell><cell>Perceptron</cell><cell>0.799 ± 0.01</cell><cell>0.799 ± 0.01</cell><cell>0.981 ± 0.01</cell><cell>0.982 ± 0.01</cell><cell>0.937 + 0.02</cell><cell>0.937 ± 0.02</cell></row><row><cell></cell><cell>SVM</cell><cell>0.826 ± 0.05</cell><cell>0.824 ± 0.06</cell><cell>0.908 ± 0.02</cell><cell>0.907 ± 0.02</cell><cell>0.839 ± 0.02</cell><cell>0.836 ± 0.01</cell></row><row><cell>Polarity</cell><cell>Naive Bayes</cell><cell>0.806 ± 0.03</cell><cell>0.814 ± 0.04</cell><cell>0.758 ± 0.03</cell><cell>0.771 ± 0.03</cell><cell>0.799 ± 0.02</cell><cell>0.803 ± 0.02</cell></row><row><cell></cell><cell>Logistic</cell><cell>0.811 ± 0.05</cell><cell>0.811 ± 0.06</cell><cell>0.784 ± 0.02</cell><cell>0.787 ± 0.02</cell><cell>0.814 ± 0.02</cell><cell>0.812 ± 0.02</cell></row><row><cell></cell><cell>Perceptron</cell><cell>0.777 ± 0.03</cell><cell>0.776 ± 0.02</cell><cell>0.729 ± 0.02</cell><cell>0.729 ± 0.01</cell><cell>0.719 ± 0.08</cell><cell>0.718 ± 0.07</cell></row><row><cell></cell><cell>SVM</cell><cell>0.795 ± 0.03</cell><cell>0.801 ± 0.03</cell><cell>0.865 ± 0.02</cell><cell>0.863 ± 0.02</cell><cell>0.819 ± 0.02</cell><cell>0.817 ± 0.02</cell></row><row><cell>Strength</cell><cell>Naive Bayes</cell><cell>0.81 ± 0.06</cell><cell>0.826 ± 0.05</cell><cell>0.777 ± 0.04</cell><cell>0.79 ± 0.05</cell><cell>0.811 ± 0.02</cell><cell>0.819 ± 0.01</cell></row><row><cell></cell><cell>Logistic</cell><cell>0.838 ± 0.05</cell><cell>0.839 ± 0.05</cell><cell>0.806 ± 0.02</cell><cell>0.804 ± 0.03</cell><cell>0.828 ± 0.01</cell><cell>0.828 ± 0.01</cell></row><row><cell></cell><cell>Perceptron</cell><cell>0.763 ± 0.01</cell><cell>0.76 ± 0.01</cell><cell>0.886 ± 0.01</cell><cell>0.886 ± 0.01</cell><cell>0.838 ± 0.02</cell><cell>0.83 ± 0.02</cell></row><row><cell></cell><cell>SVM</cell><cell>0.85 ± 0.04</cell><cell>0.846 ± 0.05</cell><cell>0.907 ± 0.01</cell><cell>0.904 ± 0.01</cell><cell>0.834 ± 0.02</cell><cell>0.832 ± 0.02</cell></row><row><cell>Emotion</cell><cell>Naive Bayes</cell><cell>0.66 ± 0.06</cell><cell>0.718 ± 0.05</cell><cell>0.675 ± 0.03</cell><cell>0.72 ± 0.04</cell><cell>0.689 ± 0.02</cell><cell>0.701 ± 0.02</cell></row><row><cell></cell><cell>Logistic</cell><cell>0.675 ± 0.05</cell><cell>0.653 ± 0.08</cell><cell>0.693 ± 0.03</cell><cell>0.693 ± 0.03</cell><cell>0.7 ± 0.02</cell><cell>0.693 ± 0.02</cell></row><row><cell></cell><cell>Perceptron</cell><cell>0.66 ± 0.1</cell><cell>0.656 ± 0.04</cell><cell>0.763 ± 0.04</cell><cell>0.76 AE 0.01</cell><cell>0.71 ± 0.06</cell><cell>0.709 ± 0.02</cell></row><row><cell></cell><cell>SVM</cell><cell>0.685 ± 0.05</cell><cell>0.685 ± 0.05</cell><cell>0.868 ± 0.02</cell><cell>0.863 ± 0.02</cell><cell>0.702 ± 0.02</cell><cell>0.694 ± 0.02</cell></row><row><cell>POS</cell><cell>Naive Bayes</cell><cell>0.529 AE 0.08</cell><cell>0.528 AE 0.02</cell><cell>0.638 ± 0.03</cell><cell>0.639 AE 0.03</cell><cell>0.58 ± 0.01</cell><cell>0.58 ± 0.01</cell></row><row><cell></cell><cell>Logistic</cell><cell>0.587 ± 0.04</cell><cell>0.568 ± 0.01</cell><cell>0.655 ± 0.03</cell><cell>0.657 ± 0.01</cell><cell>0.619 ± 0.01</cell><cell>0.61 ± 0.02</cell></row><row><cell></cell><cell>Perceptron</cell><cell>0.484 ± 0.02</cell><cell>0.48 ± 0.01</cell><cell>0.889 ± 0.03</cell><cell>0.88 ± 0.01</cell><cell>0.681 ± 0.03</cell><cell>0.68 ± 0.02</cell></row><row><cell></cell><cell>SVM</cell><cell>0.506 AE 0.08</cell><cell>0.503 ± 0.07</cell><cell>0.823 ± 0.02</cell><cell>0.824 ± 0.01</cell><cell>0.738 ± 0.02</cell><cell>0.738 ± 0.06</cell></row><row><cell></cell><cell>Errors</cell><cell>Hits</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14</head><label>14</label><figDesc>Cross-transfer subjectivity classification performances.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15</head><label>15</label><figDesc>Cross-transfer polarity classification performances.</figDesc><table><row><cell>KNOSYS 2857</cell><cell></cell><cell></cell><cell>No. of Pages 14, Model 5G</cell></row><row><cell>5 June 2014</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Q1</cell><cell>F. Bravo-Marquez</cell><cell>et al. / Knowledge-Based Systems xxx (2014) xxx-xxx</cell><cell>13</cell></row></table><note><p>Please cite this article in press as: F. Bravo-Marquez Q1 et al., Meta-level sentiment models for big social data analysis, Knowl. Based Syst. (2014), http:// dx.doi.org/10.1016/j.knosys.2014.05.016</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>http://www.ark.cs.cmu.edu/TweetNLP/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>http://www.cs.uic.edu/liub/FBS/sentiment-analysis.html. 4 F. Bravo-Marquez Q1 et al. / Knowledge-Based Systems xxx (2014) xxx-xxx</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>et al. / Knowledge-Based Systems xxx (2014) xxx-xxx</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sentiwordnet 3.0: an enhanced lexical 1001 resource for sentiment analysis and opinion mining</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1002 Seventh International Conference on Language Resources and Evaluation</title>
		<meeting>the 1002 Seventh International Conference on Language Resources and Evaluation<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1003">1003. 2010</date>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rello</surname></persName>
		</author>
		<title level="m">How Bad Do You Spell?: The Lexical Quality of Social 1005 Media, The Future of the Social Web, Papers from the 2011 ICWSM Workshop</title>
		<meeting><address><addrLine>Barcelona, Catalonia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Workshops</publisher>
			<date type="published" when="1006">1006. 2011</date>
			<biblScope unit="page">1007</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<title level="m">Affective Norms for English Words (ANEW) Instruction 1008 Manual and Affective Ratings</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">1010</biblScope>
		</imprint>
		<respStmt>
			<orgName>The Center for Research in 1009 Psychophysiology University of Florida</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report C-1</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining strengths, emotions and 1011 polarities for boosting Twitter sentiment analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bravo-Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poblete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1012 Second International Workshop on Issues of Sentiment Discovery and Opinion 1013 Mining, WISDOM &apos;13</title>
		<meeting>the 1012 Second International Workshop on Issues of Sentiment Discovery and Opinion 1013 Mining, WISDOM &apos;13<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SenticNet 2: a semantic and affective 1015 resource for opinion mining and sentiment analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FLAIRS Conference</title>
		<imprint>
			<date type="published" when="1016">1016 2012</date>
			<biblScope unit="page" from="202" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<title level="m">Sentic Computing, Techniques, Tools, and Applications</title>
		<imprint>
			<date type="published" when="1018">1018 Springer, 2012. 1019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The hourglass of emotions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Livingstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive 1020 Behavioural Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="144" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">New avenues in opinion mining and 1022 sentiment analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SenticNet 3: a common and common-sense 1024 knowledge base for cognition-driven sentiment analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Olsher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1025 Twenty-Eighth AAAI Conference on Artificial Intelligence Quebec City</title>
		<meeting>the 1025 Twenty-Eighth AAAI Conference on Artificial Intelligence Quebec City</meeting>
		<imprint>
			<date type="published" when="1027">1026 2014. 1027</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Jumping NLP curves: a review of natural language 1028 processing research</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intell. Mag</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clues for detecting irony in 1030 user-generated contents: oh. . .!! it&apos;s so easy;-)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sarmento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 1st 1031 International CIKM Workshop on Topic-sentiment Analysis for Mass Opinion 1032 Hong Kong</title>
		<meeting>eeding of the 1st 1031 International CIKM Workshop on Topic-sentiment Analysis for Mass Opinion 1032 Hong Kong<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">1033</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sentiwordnet: a publicly available lexical resource for 1034 opinion mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Conference on Language Resources 1035 and Evaluation</title>
		<meeting>the 5th Conference on Language Resources 1035 and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">1036</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant 1037 supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">1038</biblScope>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing and combining 1039 sentiment analysis methods</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Benevenuto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First ACM Conference on 1040 Online Social Networks, COSN &apos;13</title>
		<meeting>the First ACM Conference on 1040 Online Social Networks, COSN &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Target-dependent Twitter sentiment 1042 classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association 1043 for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association 1043 for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1044" to="1151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Twitter sentiment analysis: the good the bad and the OMG!</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kouloumpis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Emoticon smoothed language models for Twitter sentiment analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 26th AAAI Conference on Artificial Intelligence<address><addrLine>Toronto, Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Sentiment Analysis and Opinion Mining, Synthesis Lectures on Human Language Technologies series</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wordnet: an on-line lexical database</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Lexicogr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="235" to="244" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Crowdsourcing a word-emotion association lexicon</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nrc-canada: building the state-of-theart in sentiment analysis of tweets</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation Exercises (SemEval-2013)</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation Exercises (SemEval-2013)<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Alleviating data sparsity for Twitter sentiment analysis, in: Workshop of Making Sense of Microposts co-located with WWW</title>
		<author>
			<persName><forename type="first">H</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A new anew: evaluation of a word list for sentiment analysis in microblogs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ESWC2011 Workshop on &apos;Making Sense of Microposts&apos;: Big Things Come in Small Packages</title>
		<meeting>the ESWC2011 Workshop on &apos;Making Sense of Microposts&apos;: Big Things Come in Small Packages<address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05-30">May 30, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Piazza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sentic web: a new paradigm for managing social media affective information</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="480" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Full spectrum opinion mining: integrating domain, syntactic and lexical knowledge</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Olsher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 IEEE 12th International Conference on Data Mining Workshops</title>
		<meeting>the 2012 IEEE 12th International Conference on Data Mining Workshops</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="693" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Twitter as a corpus for sentiment analysis and opinion mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Paroubek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Opinion mining and sentiment analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inform. Retr</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The nature of emotions human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice</title>
		<author>
			<persName><forename type="first">R</forename><surname>Plutchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Sci</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="344" to="350" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using emoticons to reduce dependency in machine learning techniques for sentiment classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Read</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Michigan, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sentiment strength detection for the social web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thelwall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Paltoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Inform. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="173" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Building a concept-level sentiment dictionary based on commonsense knowledge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Charng-Rurng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tzong-Han Tsai</surname></persName>
		</author>
		<author>
			<persName><surname>Yung-Jen Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyonov</surname></persName>
		</author>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computation Linguistics</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Semeval-2013 task 2: sentiment analysis in Twitter</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phraselevel sentiment analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies Conference/Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP 2005)</title>
		<meeting>Human Language Technologies Conference/Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP 2005)<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Feature ensemble plus sample selection: domain adaptation for sentiment classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chengqing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fine-grained sentiment analysis with structural features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zirn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP)</title>
		<meeting>the 5th International Joint Conference on Natural Language Processing (IJCNLP)<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="336" to="344" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
