<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Where Have You Been? Inferring Career Trajectory from Academic Social Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chenhui</forename><surname>Zhang</surname></persName>
							<email>ch-zhang15@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Where Have You Been? Inferring Career Trajectory from Academic Social Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A person's career trajectory is composed of her/his past work or educational affiliations (institutions) at different points of times. Knowing people's, especially scholars', career trajectories can help the government make more scientific strategies to allocate resources and attract talent and help companies make smart recruiting plans. It could also support individuals find appropriate co-researchers or job opportunities. The paper focuses on inferring career trajectories in the academic social network. For about 1/3 of authors not having any affiliations in the dataset, we need to infer the missings at various years. Traditional affiliation/location inferring methods focus on inferring a stationary location (one and only) for a person. Nevertheless, people won't stay at a place all their lives. We propose a Space-Time Factor Graph Model (STFGM) incorporating spatial and temporal correlations to fulfill the challenging and new task of inferring temporal locations. Experiments show our approach significantly outperforms baselines. At last, as case study, we develop several applications based on our approach which demonstrate the effectiveness further.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The tough competition on personalized information services in a variety of domains such as personalized search engine, intelligent recommendation for TV programs, merchandise, jobs etc. has driven the demand for more precise user profiling <ref type="bibr" target="#b3">[Iguchi, 2007;</ref><ref type="bibr">Park and Chang, 2009;</ref><ref type="bibr">Sugiyama et al., 2004;</ref><ref type="bibr" target="#b6">Yu et al., 2006;</ref><ref type="bibr" target="#b0">Abel et al., 2011;</ref><ref type="bibr" target="#b6">Xue, 2010]</ref>. A user's affiliation is an important part of her/his profile. Just as the saying goes: "You cannot judge a man till you know his whole story". Exploring the past affiliations of a person has been studying or working at different times can help better profile her/him, knowing the career trajectories of many people in a specific research area can better understand the development of the area. These can benefit many applications. For instance, the government could better grasp the transitions of talents and accordingly make more scientific policies relating resources allocating, talent attracting. In addition, companies can design smart recruiting plans or just find candidates with specific experience and individuals can find appropriate coresearchers or job opportunities to extend the academic or professional network.</p><p>There are some efforts to collect the affiliations of researchers, e.g. ORCID, which requires the user to add her/his profile manually. Unfortunately, the information obtained solely from users themselves is sometimes incomplete. To automatically get the affiliation of a specified user, a usual way is to find her/his home page and then use machine learning techniques to extract from it. Nevertheless, extracting the formatted temporal affiliations from an unstructured biography paragraph is non-trivial, let alone many even don't have home pages <ref type="bibr">[Ceglowski et al., 2003;</ref><ref type="bibr" target="#b5">Tang et al., 2010]</ref>.</p><p>Thanks to the development of the academic social networks such as AMiner<ref type="foot" target="#foot_0">1</ref> and MAG<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b5">[Tang et al., 2008;</ref><ref type="bibr" target="#b4">Sinha et al., 2015]</ref>, we can relatively easier get authors' affiliations in published papers. However, the problem of inferring affiliations trajectories from academic social networks still poses challenges. The affiliation information is sparse in the dataset. We sampled about 1.5 million authors in AMiner and found that 0.55 million authors (accounting for 35.9%) don't have any affiliations in their papers, and there are only 11.8% of them having more than one affiliation (Figure <ref type="figure" target="#fig_0">1</ref>.a). We also investigated a sample of ORCID for comparison. There are 59.7% (about 5 times of previous one) of people with more than one affiliation (Figure <ref type="figure" target="#fig_0">1</ref>.b).</p><p>Moreover, traditional affiliation/location inferring methods rarely concern about the time, but people do not tend to stay in one place all their lives. Inferring temporal affiliations is more challenging. To the best of our knowledge, there has not been any research about this.</p><p>To address the novel problem and the obstacles related, we propose a Space-Time Factor Graph Model (STFGM) which directly models the similarity between authors, and incorporates time and space correlations. At last, for the case study, we develop several applications based on our approach which demonstrate the effectiveness further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>Assume G = {G t } is a time-aware academic network with</p><formula xml:id="formula_0">G t = (V t L , V t U , E t )</formula><p>where all the superscripts t denote time, V t L is the affiliation-known authors at time t, V t U is the affiliation-unknown authors,</p><formula xml:id="formula_1">V t = V t L ∪ V t</formula><p>U , E t is the coauthoring relations. Suppose A is the affiliation set, the objective is to learn a predictive function, f :  <ref type="bibr" target="#b3">[Ikawa et al., 2012]</ref>. One of the limitations of these methods is that they could not get high-resolution locations such as some university or some corporation, because language style won't change significantly in small scale of an area, let alone the more objective academic language in research papers.</p><formula xml:id="formula_2">V t U → A 3 Related Work</formula><p>The second category leverages the network correlations of users. For example, Davis Jr et al. predicted the user's location with the highest frequent one in the friends, and confirmed friend number would influence precision <ref type="bibr" target="#b2">[Davis Jr et al., 2011]</ref>. Jurgens tried to use the social network to predict the user's location. He used Spatial Label Propagation to select a known neighbors' label for unlabeled users and propagate the inferred mappings until convergence <ref type="bibr" target="#b3">[Jurgens, 2013]</ref>. Backstrom et al. modeled friendship probability as a function of distance, and they selected the predicted location which maximizes the joint likelihood <ref type="bibr" target="#b0">[Backstrom et al., 2010]</ref>. McGee et al. incorporated social tie strengths between users to improve location prediction <ref type="bibr" target="#b3">[McGee et al., 2013]</ref>.</p><p>The third category uses both users' content and network connections. Li et al. treated users and user-tweeted venues as nodes in a network and used respective gaussian distributions to model the nodes' influence scopes. The model tends to select the neighbor with the smallest influence scope <ref type="bibr" target="#b3">[Li et al., 2012]</ref>. Another work leveraged users' content to infer their locations if the content contains local words and used friendship to infer locations of users without local words <ref type="bibr">[Ryoo and Moon, 2014]</ref>.</p><p>The general focus of previous methods using network connections is how to select out the nearest neighbor. Most used an indirect metric of neighbors such as the highest frequent, geometric median or the smallest influence scope. In fact, it often may not be the best choice because few took into account the features of the target person and the neighbor pair, which function together to determine the distance. Previous efforts inspired us to build our model and our work was motivated most by McGee et al.'s with the following differences: We directly model the tuple of the user, neighbor and time simultaneously to allow social tie strengths varying with time.</p><p>In addition, we incorporate the correlations of the tuples in space and time which boost our performance further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Method</head><p>Before proceeding, we first introduce some baseline solutions for this problem.</p><p>Time Stretch. If we know a person's affiliations at some discrete years, then the missing affiliations between the years can be predicted with the ones near the affiliation-known years. The approach cannot be adopted if none of the affiliations of a person are known.</p><p>Statistics-Based Model. The idea is that the opportunities to work with someone in the same affiliation are much larger than that in different affiliations. Our survey of 2 million randomly selected papers confirmed the assumption, which showed that about 71.3% papers have two or more coauthors from the same affiliation. To predict a missing affiliation of an author at a time t, we can use the affiliation that the most coauthors belong to.</p><p>Influence Model. We borrow the idea from <ref type="bibr" target="#b3">[Li et al., 2012]</ref>, the affiliation-known author i's influence at different locations can be modeled by a gaussian distribution with mean L i and covariance Σ i = σ i 0 0 σ i , where L i is the author's location, σ i reflects the influence ability and can be estimated by affiliation-known coauthors. A person with a wider influence collaborates with many people geographically far apart, while a person with small influence tends to collaborate with people nearby. To predict a missing affiliation of an author in a year, we compute that year's affiliation-known coauthors' influence abilities and choose the one with the smallest. Space Label Propagation. When the affiliation-missing author's affiliations are inferred, they can be used as known nodes to infer other unknown ones. When inferring a missing affiliation, we choose the affiliation that the most coauthors belong to rather than their locations' simplex median used in <ref type="bibr" target="#b3">[Jurgens, 2013]</ref>. Because simplex median often results in wield or institution-free locations such as seas or coast.</p><p>Rank-SVM. The problem of inferring affiliation can be formulated as a multiclass classification where the classes are the set of available affiliations. However, the number of dif- ferent affiliations exceeds 10 thousand in our dataset. The 1 vs. 10k+ classification model will fail with limited features. Thus, we change the multiclass classification problem into a binary classification problem. At time t, each author a is associated with individual features vec(a) t while each coauthorship &lt; a i1 , a i2 &gt; is associated with coauthoring features vec(a i1 , a i2 ) t and a binary label y t i to indicate whether a i1 and a i2 belong to the same affiliation. Then given a training data, we can build a two-class rankSVM model based on MLE <ref type="bibr" target="#b4">[Scholz, 1985]</ref> </p><formula xml:id="formula_3">y t i = arg max P (y t i |x t i )<label>(1)</label></formula><p>where</p><formula xml:id="formula_4">x t i [vec(a i1 ), vec(a i2</formula><p>), vec(a i1 , a i2 )] t is the combination of individual and coauthoring features. The approach predicts the coauthor with the highest similarity score.</p><p>Some of the methods above use some temporal connection, some leverage the spatial connection and some capture the features of the node pairs. But none can model them all in a unified way. We now introduce our model in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Space-Time Factor Graph Model(STFGM)</head><p>The general idea of our model is trying to find the affiliationknown coauthors who share the same affiliations as the target authors with missing affiliations.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> gives a simplified picture of our STFGM. Each green point with common t outside, representing a tuple &lt;Time t, Author a i1 , Author a i2 &gt;, is an observation instance where a i1 is the target author and a i2 is a coauthor with known affiliation at t. For example, the green point (b, 6) circled by t-1 represents target author b coauthored with person 6 at time t − 1. We have</p><formula xml:id="formula_5">a i1 ∈ V t U , a i2 ∈ V t L , (a i1 , a i2</formula><p>) ∈ E t . Associated with each observation instance is a hidden binaryvalued variable representing the affiliation similarity between the two authors. If they belong to the same affiliation at that time, the hidden value is 1, otherwise 0.</p><p>Attribute Factor Function: captures the features of each tuple &lt; t, a i1 , a i2 &gt; and characterizes how the observed tuple features (the respective features of the two authors and the concurrent features between them) contribute to the similarity of the authors in the tuple. The function is defined as an exponential-linear function:</p><formula xml:id="formula_6">f (x t i , y t i ) 1 Z ω exp ω T Φ(x t i , y t i ) (2)</formula><p>where</p><formula xml:id="formula_7">x t i</formula><p>[vec(a i1 ), vec(a i2 ), vec(a i1 , a i2 )] t is the feature vector embracing a i1 and a i2 's respective and shared common features at time t; y t i ∈ {0, 1} denotes whether the two authors in tuple &lt; t, a i1 , a i2 &gt; are in the same affiliation at time t ; ω (ω 0 , ω 1 ) is the weighting vector; Φ (Φ 0 , Φ 1 ) T is the vector of feature functions with Φ k (x t i , y t i ) 1 y t i =k x t i , k ∈ {0, 1} defined as indicator function.</p><p>Given any a tuple &lt; t, a i1 , a i2 &gt;, the attributes extracted in our system include the features of target author a i1 (consisting of the number of coauthors of author a i1 at time t, the number of all the coauthors of author a i1 , the number of papers published by author a i1 at time t, the number of all papers published by author a i1 ), the features of the coauthor a i2 (made up of the number of coauthors of author a i2 at time t, the number of all the coauthors of author a i2 , the number of papers published by author i at time a i2 , the number of all papers published by author a i2 ), and the shared features of author a i1 and a i2 (comprised by the number of times author a i1 and a i2 collaborated at time t, the number of all the times author a i1 and a i2 collaborated ever).</p><p>Space Factor Function: captures the correlation between the hidden variables at the same time (We refer to this correlation as spatial correlation). It's defined as an exponentiallinear function:</p><formula xml:id="formula_8">S(y t i , N S (y t i )) 1 Z β exp    y t j ∈N S (y t i ) β T Ψ(y t i , y t j )   <label>(3)</label></formula><p>where N S (y t i ) denotes neighbors which have spatial correlations with</p><formula xml:id="formula_9">y t i , Ψ (Ψ 1 , ..., Ψ C ) T , C is the number of types of spatial correlations, Ψ c (Ψ 00 c , Ψ 01 c , Ψ 10 c , Ψ 11 c ), Ψ kl c (y t i , y t j ) 1 (y t i =k,y t j =l) , 1 ≤ c ≤ C, 0 ≤ k, l ≤ 1.</formula><p>We extract two kinds of spatial correlation edges in our implemented system. Suppose the hidden variables corresponding to instances &lt; t, a, i &gt; and &lt; t, a, j &gt; are y t i and y t j respectively, 1) If author i and j have the same affiliation at time t, we add a space-correlation edge between y t i and y t j . 2) If author i and j have the same affiliation at any time, we add another space-correlation edge between y t i and y t j . Time Factor Function: captures the temporal correlation between different times on the same author pair (We call the correlation temporal correlation). It's defined as an exponential-linear function:</p><formula xml:id="formula_10">T (y t i , N T (y t i )) 1 Z γ exp    y t i ∈N T (y t i ) γ T Ω(y t i , y t i )    (4)</formula><p>where N T (y t i ) denotes neighbors who have temporal correlations with</p><formula xml:id="formula_11">y t i , Ω (Ω 1 , ..., Ω C ) T , C is the number of types of temporal correlations, Ω c (Ω 00 c , Ω 01 c , Ω 10 c , Ω 11 c ), Ω kl c (y t i , y t i ) 1 (y t i =k,y t i =l) , 1 ≤ c ≤ C , 0 ≤ k, l ≤ 1.</formula><p>We extract two kinds of temporal correlation edges also. 1) If the two instances &lt; t, a, i &gt; and &lt; t + 1, a, i &gt; are observed, suppose the corresponding hidden variables are y t i and y t+1 i respectively, we add an one-order time-correlation edge between y t i and y t+1 i .</p><p>2) If the two instances &lt; t, a, i &gt; and &lt; t+2, a, i &gt; are observed, suppose the corresponding hidden variables are y t i and y t+2 i respectively, we add another two-order time-correlation edge between y t i and y t+2 i . Model Learning: Now we combine all the factors, observation instances and hidden variables into a unified model. We reuse N S and N T to denote all the space and time relations. Define X {x t i } ∪ N S ∪ N T and Y {y t i } which are two sets representing all the observation instances and the hidden variables respectively.</p><formula xml:id="formula_12">P (Y |X, θ) = t i f (x t i , y t i )S(y t i , NS(y t i ))T (y t i , NT (y t i )) = 1 ZωZ β Zγ exp (ω T , β T , γ T ) t i g(y t i ) = 1 Z θ exp θ T G(Y )<label>(5)</label></formula><p>where g(y t i ) (Φ(x t i , y t i ) T ,</p><formula xml:id="formula_13">y t j Ψ(y t i , y t j ),</formula><p>The computing of P θ (Y |Y L , X) and P θ (Y |X) can be approximated using Loopy Belief Propagation (LBP) <ref type="bibr" target="#b3">[Murphy et al., 1999]</ref>. We perform LBP twice, one time giving the labeled data and another time not giving it. Denoting η as the learning rate, finally, the θ * can be iteratively updated until convergence by:</p><formula xml:id="formula_14">θ new = θ old + η ∂O(θ) ∂θ<label>(8)</label></formula><p>Inferring Missing Affiliations: After learning out parameter set θ, we can compute the similarity probability of each tuple instance. Given a ∈ V t U , for each candidate i ∈ V t L satisfying (a, i) ∈ E t , suppose the corresponding hidden variable for the tuple &lt; t, a, i &gt; is y t i , then the most likely person with the same affiliation at t is:</p><formula xml:id="formula_15">i * = arg max i P θ (y t i = 1|X) (9)</formula><p>Finally, the affiliation of author a at t can be predicted as:</p><formula xml:id="formula_16">P redict(a, t) = Af f iliation(i * , t)<label>(10)</label></formula><p>5 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup Datasets</head><p>We evaluate our method on datasets constructed from two famous academic networks: AMiner and MAG. AMiner: (ArnetMiner) is an expertise search and mining service for researcher social networks. Currently, the academic network includes more than 231,832,378 publications and 127,513,531 researchers.</p><p>MAG: (Microsoft Academic Graph) is a heterogeneous graph containing scientific publication records, citation relationships between those publications, as well as authors, institutions, journals, conferences, and fields of study, which has more than 126,909,021 papers and 114,698,044 authors.</p><p>Datasets Construction: To simultaneously construct our training and testing datasets from AMiner and MAG respectively, we first randomly choose 1336 target authors with at least ten years of affiliations available in their papers and present in both AMiner and MAG. We then collect all their and their coauthors' information in AMiner and MAG respectively. The total authors involved in our datasets constructed from AMiner and MAG are 57037, 147543 respectively. After that, in order to generate training and testing datasets, we introduce two split methods: First one, we randomly split the target authors into training and testing datasets, with the testing authors not knowing any affiliations in training datasets. We call this splitting method Inter-person traintest split. Another one, we randomly select some affiliationknown years of every author into training datasets and other years into testing. We call this Intra-person train-test split.</p><p>According to the testing-dataset "ground truth", we can compute the algorithms' precision in the dataset (abbreviated to P1). The way of getting "ground truth" in the last paragraph is very common in machine learning, especially when getting the real ground truth is impossible or the cost is huge. One shortcoming of the above setting is that the ground truth extracted from the dataset could be inaccurate, e.g., the affiliations of a paper are ascribed to the wrong coauthors, or a paper is ascribed to a wrong author due to name ambiguity. Therefore, we further evaluate the performance in terms of the true precision in the real world (abbreviated to P2). To get the real world ground truth, we organized a group of researchers to search out the target authors' curricula vitae on the Internet and to organize the information searched out into &lt;when, who, where&gt; format. The granularity of time is year. Each result item was rechecked by two people. Finally, 722 curricula vitae were found along with 21544 high-quality information items. We released the dataset at the site<ref type="foot" target="#foot_3">3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>We use Ratcliff &amp; Obershelp pattern matching algorithm to compute the affiliation strings' similarity scores <ref type="bibr" target="#b3">[Ratcliff and Metzener, 1988]</ref>. If the score is greater than 0.6 (maximum is 1), we treat them the same; otherwise, the different. Because many affiliations can be written in different ways by different people, we have tested other thresholds and found 0.6 can get most positive pairs with a less than 5% false positive ones. When the inferred &lt;author, time, affiliation&gt; tuple is the same as the ground truth, the right items increase 1. The precision is the ratio of the right items to the total items. The train-test ratio is set to 6:4. For each splitting, we run 10 times and report average results in the following section. It's worth noting that this is a "hit at one problem", so we don't compute recall and F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Analysis</head><p>We compare the performance of all methods in two datasets and on two precision evaluation metrics. Table <ref type="table" target="#tab_1">1</ref> shows the performance. We find that precisions in the real world have a 6% -17% drop than ones in the dataset. The performance drop in the real world is inevitable and easy to understand because we never use any information in the real world ground truth to train our models. For STFGM, the Inter-person splits have lower performance than their Intra-person counterparts, because it's harder to predict a person's affiliations without knowing any her/his affiliations in any years. However, the models other than Time-Stretch and STFGM don't achieve significant improvement even with some known affiliations in the Intra-person split, because these models cannot capture the temporal connections. The Time-Stretch method can beat methods other than STFGM because a person's temporal connections with himself are stronger than space connections with other coauthors. Overall, STFGM achieves the best performance because it incorporates spatial and temporal connections together as well as personal attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factor Contribution Analysis</head><p>We now give an in-depth analysis of the effects of different factors. We examine the contribution of different factors by removing each of them. Train/Test Ratio Analysis From Figure <ref type="figure">3</ref>(a), we can see the performance with the Interperson split keeps relatively stable as test sample ratio increases. While with the Intra-person split, Figure <ref type="figure">3</ref>(b) demonstrates the performance goes down slightly with the increasing of test sample ratio. This is because the time connections from training instances to testing instances in target persons decreases as train sample ratio drops. However, even with a low training ratio of 0.1 (test ratio 0.9), the performance is still highly acceptable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Complexity Analysis</head><p>Suppose the number of instances and edges in STFGM is |V | and |E|, the time complexity is O(|V | + |E|). Generally, our model takes 50 -100 iterations to converge. For a typical configuration of 80719 instances and 133947 edges, it takes 4 minutes to converge in a MacBook with 2.5 GHz Intel Core i7 and 16G 1600MHz DDR3 Memory, while the other methods take less than a minute. Good news is this can be done offline when precision is the priority concern, and the learning process of the model can be further accelerated by graph partition and parallel computing technologies.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Case Study</head><p>Based on our proposed STFGM model, we then developed several applications as the case study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">APP 1: Scholar Career Trajectory</head><p>Given an author in the academic social network, this application can automatically list out the author's career experiences and draw the trajectory path on the map. Figure <ref type="figure" target="#fig_3">5</ref> is the results generated automatically for "Tim Berners-Lee", 2016 Turing Award winner. The results basically accord with the bio on his homepage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">APP 2: Scholars Group Migration Heatmap</head><p>In this application, we collect top 10000 scientists in academic network sorted by h-index, then we infer and draw all their trajectories covering one century (from 1913 to 2016) into one dynamic map. The reason for selecting top scientists is they often attract a bunch of other scientists working with them, so their migrations are more representative and may reflect some trends. We then merge nearby persons into hotspots with radius 50km and take hotspots as our research objects in order that their group behavior can be more robust. For a vivid example of the application, as is well-known, Los Angeles became a focus for intellectual discourse in the 1970s after 10 years of urban decay in 1960s. 4 Figure <ref type="figure" target="#fig_4">6</ref> certificate the history, clearly showing that many from the east coast of the U.S. migrated to Los Angeles in 1970.</p><p>On further analysis, we find some interesting phenomena. Figure <ref type="figure">7</ref>(a) plots the distribution of the active scholars over years. "Active" indicates that they still published some paper(s). We see most of the top scholars are still active in recent ten years. shows the dynamics of some big cities. We can see cities at East coast of the United States such as Boston and Baltimore enjoy a considerably higher growth rate than other places, but the uptrend turns to the downside after the year 2005. Beijing exhibits a very different growth pattern -starting up very late near the year 1990, but the immigration trend rises significantly in recent years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>The paper focuses on temporal location inferring in the academic social network. It proposed a Space-Time Factor Graph Model (STFGM) incorporating spacial and temporal correlations to fulfill the task. Experiments on two datasets (AMiner and MAG) demonstrate that STFGM outperforms baselines significantly by 5%-27%. The model developed is generic and can be adopted to other datasets with time and space dimensions. At last, two applications were developed to demonstrate the effectiveness of our model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Affiliation statistics on AMiner vs ORCID.</figDesc><graphic url="image-1.png" coords="1,297.66,216.00,260.02,104.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Space-Time Factor Graph Model(STFGM).</figDesc><graphic url="image-2.png" coords="3,57.30,46.80,238.89,144.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3(a)  shows the results in two datasets with the Inter-person split. Figure3(b) is the counterpart with intra-person split. In Figure3(a), we can see clearly that the performance drops significantly about 7% -11% without space factors. The time factors also have 1% (a) (b) Figure 3: Factor contribution analysis. A-P and M-P stand for precision in AMiner and MAG respectively. P1 stands for precision in the dataset and P2 stands for precision in the real world. TimeFac-tor1, TimeFactor2, SpaceFactor1 and SpaceFactor2 each stands for removing the corresponding correlations in factor graph. (a) Performance comparison of Inter-person train-test split. (b)Performance comparison of Intra-person train-test split. (a) (b) Figure 4: Train/test Ratio Analysis. P1 stands for precision in the dataset and P2 stands for precision in the real world. (a) Performance comparison of Inter-person train-test split. (b) Performance comparison of Intra-person train-test split. -3% performance boost contribution. While in Figure 3(b), time factors contribute more than space factors. Especially in MAG, time factors contribute 13% -39 %. This is because with the Intra-person split there are more time connections from training instances to testing instances in target persons, while with Inter-person split all the affiliations of the target persons are unknown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Scholar Career Trajectory for Tim Berners-Lee.</figDesc><graphic url="image-8.png" coords="6,51.79,54.00,240.22,97.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Scholars Group Migration Heatmap in 1970.</figDesc><graphic url="image-9.png" coords="6,53.61,178.73,236.58,72.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 7: (a) People distribution. (b) Hotspots distribution.</figDesc><graphic url="image-12.png" coords="6,295.89,190.81,136.79,136.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Performance comparison of different methods</figDesc><table><row><cell></cell><cell cols="4">Precision in dataset(P1) Precision in real world(P2)</cell></row><row><cell>Method</cell><cell>AMiner</cell><cell>MAG</cell><cell>AMiner</cell><cell>MAG</cell></row><row><cell>Inter-person train-test split</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Statistics-based</cell><cell>67.48</cell><cell>70.31</cell><cell>56.61</cell><cell>64.49</cell></row><row><cell>Influence model</cell><cell>68.98</cell><cell>74.22</cell><cell>55.97</cell><cell>64.68</cell></row><row><cell>Space label propagation</cell><cell>71.00</cell><cell>79.23</cell><cell>54.58</cell><cell>60.18</cell></row><row><cell>SVM-Rank</cell><cell>73.91</cell><cell>76.47</cell><cell>55.56</cell><cell>66.48</cell></row><row><cell>STFGM</cell><cell>82.98</cell><cell>87.32</cell><cell>66.87</cell><cell>76.89</cell></row><row><cell>Intra-person train-test split</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Statistics-based</cell><cell>67.07</cell><cell>71.86</cell><cell>55.35</cell><cell>64.31</cell></row><row><cell>Influence model</cell><cell>62.77</cell><cell>70.01</cell><cell>50.93</cell><cell>61.49</cell></row><row><cell>Space label propagation</cell><cell>70.77</cell><cell>80.18</cell><cell>54.51</cell><cell>59.31</cell></row><row><cell>SVM-Rank</cell><cell>69.35</cell><cell>78.16</cell><cell>51.02</cell><cell>68.51</cell></row><row><cell>Time-Stretch</cell><cell>82.02</cell><cell>86.83</cell><cell>68.57</cell><cell>75.98</cell></row><row><cell>STFGM</cell><cell>90.43</cell><cell>92.42</cell><cell>72.18</cell><cell>82.48</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://aminer.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://www.microsoft.com/en-us/research/project/microsoftacademic-graph/ Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3">https://www.aminer.cn/careerMap Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://en.wikipedia.org/wiki/Recession of 1953 Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Find me if you can: improving geographical prediction with social and spatial proximity</title>
		<author>
			<persName><surname>Abel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
				<editor>
			<persName><forename type="first">Maciej</forename><surname>Ceglowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aaron</forename><surname>Coburn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Cuadrado</surname></persName>
		</editor>
		<meeting>the 27th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2011. 2011. 2004. 2004. 2010. 2010. 2003. 2013. 2013</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
		<respStmt>
			<orgName>National Institute for Technology and Liberal Education</orgName>
		</respStmt>
	</monogr>
	<note>AAAI&apos;13</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">You are where you tweet: a content-based approach to geo-locating twitter users</title>
		<author>
			<persName><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on Information and knowledge management</title>
				<meeting>the 19th ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="759" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inferring the location of twitter messages based on user relationships</title>
		<author>
			<persName><forename type="first">Davis</forename><surname>Jr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP&apos;10</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2011. 2011. 2010. 2010</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1277" to="1287" />
		</imprint>
	</monogr>
	<note>A latent variable model for geographic lexical variation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">You-Jin Park and Kun-Nyeong Chang. Individual and group behavior-based customer profile model for personalized product recommendation</title>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Iguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Iguchi</surname></persName>
		</author>
		<author>
			<persName><surname>Ikawa</surname></persName>
		</author>
		<idno>App. 11/772,071</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1988">2007. June 29 2007. 2012. 2012. Jurgens, 2013. 2013. 2012. 2012. 2013. 2013. 1999. 1999. 2009. 2009. 1988. 1988. 2014</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="643" to="648" />
		</imprint>
	</monogr>
	<note type="report_type">US Patent</note>
	<note>Dr Dobbs Journal. Ryoo and Moon, 2014] KyoungMin Ryoo and Sue Moon. Inferring twitter user locations with 10 km accuracy. In WWW&apos;14</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive web search based on user profile constructed without any effort from users</title>
		<author>
			<persName><forename type="first">;</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on world wide web</title>
				<editor>
			<persName><forename type="first">Kazunari</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kenji</forename><surname>Hatano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Masatoshi</forename><surname>Yoshikawa</surname></persName>
		</editor>
		<meeting>the 24th international conference on world wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1985">1985. 1985. 2015. 2015. 2004</date>
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
	<note>Proceedings of the 13th international conference on World Wide Web</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008. 2008. 2010. 2010. 2011. 2011</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="955" to="964" />
		</imprint>
	</monogr>
	<note>ACL&apos;11</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Research on the book intelligent recommendation system based on data mining [j]. Information Studies: Theory &amp; Application</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Xue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2010. 2010. 2006. 2006</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="63" to="82" />
		</imprint>
	</monogr>
	<note>Tv program recommendation for multiple viewers based on user profile merging. User modeling and user-adapted interaction</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
