<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ensembles for Unsupervised Outlier Detection: Challenges and Research Questions [Position Paper]</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Arthur</forename><surname>Zimek</surname></persName>
							<email>zimek@dbs.ifi.lmu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Ludwig-Maximilians-Universität Munich</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ricardo</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
							<email>campello@icmc.usp.br</email>
							<affiliation key="aff1">
								<orgName type="institution">University of São</orgName>
								<address>
									<settlement>Paulo São Carlos</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Örg Sander</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Alberta Edmonton</orgName>
								<address>
									<region>AB</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ensembles for Unsupervised Outlier Detection: Challenges and Research Questions [Position Paper]</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2C80270D1EEAF3FDCE924361AC75E6CA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ensembles for unsupervised outlier detection is an emerging topic that has been neglected for a surprisingly long time (although there are reasons why this is more difficult than supervised ensembles or even clustering ensembles). Aggarwal recently discussed algorithmic patterns of outlier detection ensembles, identified traces of the idea in the literature, and remarked on potential as well as unlikely avenues for future transfer of concepts from supervised ensembles. Complementary to his points, here we focus on the core ingredients for building an outlier ensemble, discuss the first steps taken in the literature, and identify challenges for future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Outlier detection is the process of identifying those observations which deviate substantially from the remaining data. Many definitions of outliers exist in the statistics literature, usually tied to specific assumptions on the underlying data distribution. The most common general definitions remain rather vague, such as these classic examples: "an observation which deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism." <ref type="bibr" target="#b31">[30]</ref> "An outlying observation, or 'outlier,' is one that appears to deviate markedly from other members of the sample in which it occurs." <ref type="bibr" target="#b27">[26]</ref> "An observation (or subset of observations) which appears to be inconsistent with the remainder of that set of data" <ref type="bibr" target="#b9">[8]</ref> The point of all these definitions is the idea that any process, whether it is a traffic network, web server traffic, credit card data, sensor data in some scientific experiment, or the human metabolism, offers characteristic observations that could even be predicted if the process was well-understood. Any unpredicted observation indicates a lack of understanding of the particular process, or is produced by a different process (such as a traffic accident, a network intrusion attack, credit card fraud, sensor failure, or a disease affecting human health), and therefore probably is worth further investigation.</p><p>Outlier detection algorithms aim to automatically identify those valuable or disturbing observations in large collections of data. Because there is no rigid definition of which observation exactly is an outlier, every algorithm is based on a model that is relying on certain assumptions of what qualifies as an outlier. Clearly, the applicability of each model depends on the nature of the data. Sophisticated algorithms do not only label observations as outlier or inlier, but assign scores to observations, representing degrees or probabilities of outlierness. Some popular models are based on the distance between objects <ref type="bibr">[37; 60; 4; 74]</ref>, or on the density of the neighborhood of an object <ref type="bibr">[9; 56; 34; 38; 42]</ref>, or based on the variance of angles between object vectors <ref type="bibr">[42; 58]</ref>, or on other principles of outlierness in various domains <ref type="bibr">[12; 13; 3]</ref>. These methods represent different attempts to make the rather vague intuition about what outliers are more concrete, typically in an implicit, procedural way <ref type="bibr" target="#b66">[65]</ref>. Because every model is specialized for different characteristics of observations and therefore fits only to some aspects of the "whole truth", it might be a good idea to integrate various different outlier detection results, producing a consensus of judgements. The key idea of such an approach, which is called an "ensemble", is that the combination of individual judgements, or outlier detection results, is beneficial if those judgements do not contain all the same errors. One might think of it as a majority vote of a jury (as in Condorcet's Jury theorem <ref type="bibr" target="#b48">[47]</ref>): One or another judgement about an observation might be wrong, but the majority might still be right, as long as the judgements are, overall, somewhat reliable and every member decides independently from the others. Aggarwal <ref type="bibr" target="#b2">[2]</ref> recently proposed a categorization of ensemble approaches to outlier detection by algorithmic patterns or strategies. He distinguishes "sequential ensembles" vs. "independent ensembles", and "model-centered ensembles" vs. "data-centered ensembles". This is helpful for identifying aspects of the ensemble approach in the literature. Accordingly, he points out that before the first paper was explicitly talking about "outlier ensembles" <ref type="bibr" target="#b46">[45]</ref>, traces of the very idea of combining different models have appeared earlier in the literature, and also several times later without discussing a potential relationship to ensemble techniques explicitly. When reading the literature through these glasses of ensembles, we can undoubtedly find many hints on the ensemble idea without explicit discussion. However, not everybody has to wear these glasses. To discuss the problem of, e.g., subspace outlier detection based on the combination of several models <ref type="bibr">[36; 51; 52]</ref> without discussing ensemble techniques is perfectly fine. In fact, the subspace outlier problem is a hard problem in its own right and the typical conference paper cannot accommodate a broader discussion for reasons of space restrictions. Furthermore, the subspace outlier problem could be seen as a problem analogous to the multiview or alternative clustering problem <ref type="bibr" target="#b78">[77]</ref> where it is not intended to find the consensus clustering; instead, different clustering solutions in different subspaces can each be interesting, valid solutions. Likewise, different outliers in different subspaces could each be meaningfully reported. This is reflected in recent research addressing the explanation of subspace outliers <ref type="bibr" target="#b15">[14]</ref>. Seen this way, subspace outlier detection would even be orthogonal to the "ensemble" or "consensus" idea. Nevertheless, discussing the subspace outlier problem while taking into account reasoning on ensemble techniques would seem promising of finding more principled solutions to the subspace outlier problem <ref type="bibr" target="#b77">[76]</ref>. Likewise, it would seem that ensemble techniques such as feature bagging <ref type="bibr" target="#b46">[45]</ref>, i.e., using different subspaces as a means to learn diverse models, could also benefit from insights in the area of subspace outlier detection. Complementary to Aggarwal <ref type="bibr" target="#b2">[2]</ref>, we would like to discuss here the specific challenges, the first steps taken so far in the literature, and overall the important questions in research regarding ensembles for outlier detection. Transferring basic principles from supervised learning, the two key principles of ensemble construction would be accuracy and diversity. Casting outlier detection as an unsupervised problem, however, there is nothing known about the accuracy of individual outlier detectors during learning. This is a very fundamental problem and, as Aggarwal <ref type="bibr" target="#b2">[2]</ref> pointed out, probably one of the main reasons why the state of the art in research on ensembles for unsupervised outlier detection is not very advanced. But obviously this problem would also affect ensemble clustering where we have a lot more of research presented in the literature. Therefore, we should have a closer look on the differences between ensemble clustering and ensemble outlier detection beyond their common characteristic of being unsupervised ensembles. How to assess the diversity of outlier detection results does not have a straightforward answer either, but at least it found some attention recently. In the remainder of this paper, we will first have a look at the research area of ensemble clustering in Section 2, detailing why ensembles for outlier detection are quite a different issue. We will discuss the crucial research questions for outlier detection ensembles, reflecting the literature as sparse as it is so far, in Section 3, Section 4, and Section 5. Common approaches to assess the accuracy of outlier detection results are far from satisfying. We sketch the problem in Section 3. The diversity of models, besides their accuracy, is the most important ingredient for ensemble construction. We will discuss the issue of diversity of models for outlier detection in Section 4. Another central question is how to actually construct the ensemble, i.e., how to combine the models. The challenges in combining different models and preliminary findings in the literature will be discussed in Section 5. Finally, we summarize our positions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">ENSEMBLE CLUSTERING, ENSEMBLE OUTLIER DETECTION -WHAT IS THE DIFFERENCE?</head><p>Using ensemble techniques to improve classification is based on a sound theory <ref type="bibr">[16; 70; 10; 44; 62]</ref>. In the unsupervised area of clustering, using ensemble techniques has at least a history of many empirical studies <ref type="bibr">[67; 25; 55; 24; 33]</ref>. Furthermore, the idea of using several different clustering results is important not only in ensemble clustering as an explicit technique but also in related approaches such as multi-view clustering, subspace clustering, and alternative clustering <ref type="bibr">[11; 59; 31; 50; 77]</ref>. The ensemble idea has also been used when clustering evaluation measures are combined <ref type="bibr" target="#b73">[72]</ref>. By a simple transfer of ideas from these research results in the area of ensemble clustering (and related areas), we can assume that a combination of outlier detection models would also show potential to improve considerably over the combined individual models. Also, we can assume, by analogy, that diversity of models would be helpful in outlier detection as it is in clustering or classification. Surprisingly, for outlier detection there have not been many attempts to use ensemble techniques for improvement in a principled way, let alone investigations of the theoretical basis of doing so. When comparing the tasks of outlier detection and clustering, we can name several reasons for this surprising fact -reasons, that, at the same time, highlight the research issues that are different for the design of ensemble methods for outlier detection than for ensemble clustering.</p><p>1. The first issue is the question of how to measure accuracy (or some other index of quality) of the result of an unsupervised data mining task. In the case of clustering, we distinguish external and internal validity measures.</p><p>• External measures would assess how well some clustering reflects an externally given ground truth (gold standard) partition, using similarity measures such as the Rand-index <ref type="bibr" target="#b62">[61]</ref> or the adjusted Rand-index (ARI) <ref type="bibr" target="#b33">[32]</ref>, or other pair counting approaches <ref type="bibr" target="#b58">[57]</ref>, essentially counting the number of agreements and disagreements regarding the membership of pairs of objects to clusters in the ground truth and the clustering solution. Other similarity measures compare partitions by mapping sets, important examples being entropy-based measures such as (normalized) mutual information <ref type="bibr">[67; 48]</ref>. Although the approach to assess clustering quality by comparison with some given ground truth of known classes is debatable <ref type="bibr" target="#b23">[22]</ref>, there is probably no better approach available to assess clustering quality w.r.t. external knowledge.</p><p>• Internal measures evaluate the quality of some clustering result according to certain assumptions on what constitutes a good clustering, for example, compactness and separation of clusters as, e.g., in the Silhouette coefficient <ref type="bibr" target="#b36">[35]</ref>, or densityconnectivity within and density-separation between clusters as, e.g., in DBCV <ref type="bibr" target="#b50">[49]</ref>. Many of these internal measures can also be used to rank different solutions relatively to each other and are therefore also called "relative validity measures" <ref type="bibr" target="#b72">[71]</ref>. This way, potential members for a clustering ensemble could be selected based on their relative quality, regardless of any information on the ground truth <ref type="bibr">[20; 53]</ref>.</p><p>Quality assessment for outlier detection models is quite different since outlier detection models are not partitioning but ranking the data. We will elaborate on variants of quality assessment in outlier detection in Section 3.</p><p>2. The second issue that is important for building good ensembles but, at the same time, is quite different for outlier detection and for clustering, is the diversity of models. For clustering, assessment of diversity again can make use of numerous similarity measures such as external validity measures. The effect of diversity of models, and different ways of designing better ensembles making use of diverse components, has been studied extensively in the literature on ensemble clustering <ref type="bibr">[43; 28; 27; 20; 6]</ref>.</p><p>The similarity of outlier detection models, again, not being partitions but rankings of the data, cannot rely on the same means. We will discuss first approaches addressing this aspect of ensembles for outlier detection in Section 4.</p><p>3. The third issue, when given individual models (that are, hopefully, accurate and diverse), is how to combine these models. For ensemble clustering, this requires some matching of partitions, e.g., using similarity measures (again, as those available from external validity measures) or more refined methods of deriving some consensus partition <ref type="bibr">[67; 19; 5; 69; 68; 21; 25; 55]</ref>.</p><p>The combination of outlier detection results, i.e., rankings, requires different techniques than the combination of partitions studied in ensemble clustering. We discuss the issues particularly involved in combining outlier detection models and the approaches presented so far in the literature in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ACCURACY (QUALITY) OF RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">External Evaluation</head><p>If given a ground truth dataset where we know, for each object, whether it actually is an outlier or not, two ways of measuring the quality of the outlier detection result are commonly used in the literature <ref type="bibr" target="#b77">[76]</ref>.</p><p>The first, more widely used measure of success is based on receiver operating characteristic (ROC) curves. ROC curves plot the true positive rate against the false positive rate. The resulting, monotone curves are usually turned into a measure by computing the area under this curve (AUC). This allows to display several results in a single graph and to compare the results numerically.</p><p>For a random ranking result, both rates (true positive rate and false positive rate) will grow at the same rate, resulting in an area that approximately fills half of the space. For a perfect result, returning all outliers first and only then returning the inliers (i.e., we have 100% true positives before we even get the first false positive), the area under the corresponding curve will cover the available space completely, i.e., the maximal ROC AUC value is 1.0. Intuitively, the ROC AUC value can be seen as the probability that a pair of two randomly chosen objects, one positive example (outlier) and one negative example (inlier), is sorted correctly (i.e., the outlier is ranked before the inlier) <ref type="bibr" target="#b30">[29]</ref>. ROC curves and ROC AUC analysis inherently treat the class imbalance problem by using the relative frequencies which makes them particularly popular for evaluation of outlier detection. Sometimes, additionally or alternatively to ROC analysis, the precision of the result is assessed for a given number k of top outliers: How many of the top k ranked data objects are actually outliers? This is known as "precision at k". As an evaluation measure, this is a bit more problematic, as it involves a parameter. Both quality measures require data with known, annotated outliers, or, to put it in terms of classification, a binary, yet typically highly imbalanced classification task (very few outliers vs. many inliers).</p><p>Although the task of outlier detection is practically ubiquitous, these practical tasks are tasks because the ground truth is unknown. There is nothing like established benchmark data sets in this field, required to study and compare the behavior of algorithms for outlier detection. What people do, for example, is using classification data sets such as available in the UCI repository <ref type="bibr">[7]</ref>. To prepare an outlier detection task from such classification tasks, one can, e.g., pick some class as outlying and keep only a small sample of this outlier class while the other classes remain complete and are treated as inliers. This procedure is sometimes called "down sampling" and has been used, with different variants, in many studies designing new outlier detection methods <ref type="bibr">[1; 73; 42; 74; 36; 15; 14]</ref>. A recent study is dedicated to develop a more systematic approach <ref type="bibr" target="#b19">[18]</ref>, but this is also merely a wider step in the same direction -a direction that probably is debatable. Let as note, however, that all these problems regarding external evaluation are not specific for outlier detection ensembles but are inflicting the research on outlier detection in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Internal Evaluation</head><p>To the best of our knowledge, there are no insights whatsoever in the literature on outlier detection regarding internal validation measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Challenges</head><p>As challenges for future research on the aspect of quality assessment of outlier detection results, we see the following issues and questions for research:</p><p>• Defining useful, publicly available benchmark data in a principled way for outlier detection tasks would allow for a more objective study of progress in the field. This is, however, a general challenge in outlier detection not restricted to improving the field on ensemble methods for outlier detection.</p><p>• It will be very useful to identify meaningful criteria of internal evaluation of outlier detection rankings. Again, this is important for the progress of research on outlier detection in general. But internal evaluation criteria can be expected to have significant impact in particular on the research in ensemble methods for outlier detection, as this might allow to develop similar ideas for outlier detection ensembles as mentioned above for better clustering ensembles based on relative validity criteria.</p><p>Actually, since the effectiveness of internal criteria themselves will need to be evaluated, the first challenge posed above, namely, to provide better, more principled and objective possibilities for external evaluation of results, will be an important prerequisite for the second challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DIVERSITY OF MODELS</head><p>Typical unsupervised methods for outlier detection return a score of "outlierness" for each object. When assuming a fixed order of the objects in the dataset, an outlier detection result can be thought of as a vector consisting of the outlier scores for each object <ref type="bibr" target="#b64">[63]</ref>. This way, we can define the space of all possible outlier detection results for a given dataset, where each dimension represents the possible outlier scores of a particular observation. Let us, for the sake of simplicity, consider some outcomes for two objects, resulting in a two-dimensional plot as illustrated in Figure <ref type="figure" target="#fig_0">1</ref> (for n objects, the space would be n-dimensional and not suitable for visualization). The green circle represents the (usually unknown) ground truth, while the red crosses are individual results generated by somehow diverse outlier models. Figure <ref type="figure" target="#fig_0">1</ref>(a) shows how the combination of the six individual result vectors by the simple component-wise mean produces another result, represented by the blue X. This combined result is, in this case, a better approximation of the ground truth (green circle). All individual solutions are already quite accurate, that is, they are close to the ground truth. This is a necessary condition for assembling these individual solutions to make a good ensemble, which can be illustrated by the following reasoning: It is known that the ground truth is located somewhere in the result space, but it could be anywhere. The generation of multiple individual, more or less accurate (i.e., at least better than random) results restricts the space of where the true result most probably lies: if they are accurate to some extent, the true result will be close to them. The motivation for combining the individual results by, for example, computing the mean score for each observation is the expectation that the true result will be somewhere between them. In fact, for combination techniques like the mean, the convex hull of the individual results already restricts the result space to an area where the true result is expected to be, and where ensembles generate their integrating results. Figure <ref type="figure" target="#fig_0">1</ref>(b) illustrates the limited effects of accuracy when diversity is missing. It can easily be seen that, again, the individual results are quite accurate. However, the combined result gets rather attracted towards the majority of the single results. If the upper right, rather deviating, result would not exist, the combined result would lie completely inside the tight cluster of remaining results and would be even more distant to the true result. This is the effect of missing diversity. All single results of that tight cluster make the same error: They underestimate the outlier score for the object that is represented by the x-axis. In comparison, Figure <ref type="figure" target="#fig_0">1</ref>(a) shows results which make different errors, each of them over-and underestimating a score, resulting in an accurate ensemble result. Of course, diversity is not the only criterion. Ignoring accuracy and maximizing diversity would scatter the individual results all across the result space without any restriction. Both the true result and a combined result could reside anywhere in the complete result space, not necessarily being close to each other.</p><p>Seeing the outlier detection results as vectors in a vector space, spanned by the observations of a given dataset, as depicted in Figure <ref type="figure" target="#fig_0">1</ref>, allows us to see both components, accuracy and diversity: accuracy of individual ensemble members (red crosses) is represented by the absolute distances from the true result (green circle), while the diversity is reflected in the relative distances, taking into account also the direction of deviation, from the true result. Clearly, both criteria, accuracy and diversity, are antagonistic to a certain degree. The more accurate the individual results are, the tighter they are packed and therefore the less diverse they are. And the more diverse the individual results are, the less accurate most of them can possibly be. If we just transfer the intuition on ensemble learning from supervised ensembles, the essential requirement is that individual ensemble members would commit errors different from the other ensemble members whenever they are committing errors at all. As long as they are correct they also should be in accordance with the other ensemble members. Let us note that, interestingly, the vector space intuition of outlier detection results would also allow us to talk about subspaces (i.e., subsets of objects) where result vectors would cluster. So maybe it is possible to transfer insights from subspace clustering <ref type="bibr">[41; 66; 77]</ref> to the area of outlier ensembles. So far, this is an intuition basically transferred from supervised ensemble learning without any further theoretical understanding. Questions tackled in the literature are how to induce diversity among models (Section 4.1) and how to assess diversity along with the impact of diversity on the ensemble performance (Section 4.2). If we are given diverse models, another interesting question is if we can select some of them to build better ensembles than if we selected all of them. We sketch a greedy approach to this problem (Section 4.3) and suggest challenges and issues for future research w.r.t. to the diversity of models (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Inducing Diversity</head><p>Mostly in analogy to methods for inducing diversity in classification ensembles <ref type="bibr" target="#b11">[10]</ref> or clustering ensembles <ref type="bibr" target="#b25">[24]</ref>, there have been studies on combining outlier scores (or rankings) (1) learned in different subsets of attributes (i.e., different subspaces), (2) learned on different subsets of objects, (3) learned by randomized methods, (4) learned by the same method but using different parametrization, and (5) learned by different models.</p><p>1. Combining outlier scores or rankings learned on different subsets of attributes, the so-called "feature bagging" was the first paper to explicitly discuss building ensembles for outlier detection <ref type="bibr" target="#b46">[45]</ref>.</p><p>Some meta methods that specialize on subspace outlier detection, such as HiCS <ref type="bibr" target="#b37">[36]</ref> or OutRank <ref type="bibr" target="#b52">[51]</ref>, do in fact also combine models learned in different subspaces. However, their subspaces are not selected randomly but from the point of view of detecting subspace outliers. From an ensemble point of view this restriction could be a disadvantage by introducing a bias. This bias is meaningful and of course intended under the assumption of noisy subspaces that ought to be excluded from the feature bagging procedure. Although these subspace methods are not discussed as an ensemble framework, in effect they could be understood and probably discussed more deeply in an ensemble context, as pointed out earlier <ref type="bibr">[76; 2]</ref>.</p><p>2. The orthogonal approach, combining models learned on different subsets of objects <ref type="bibr" target="#b76">[75]</ref>, has the advantage of a considerable speed-up as it works well in particular with small sample rates, e.g., using only 10% of the objects for the density estimates. The typical complexity of outlier detection methods is in O(n 2 ) due to kNN queries. Hence a common ensemble, such as feature bagging, would be in O(s•n 2 ) for s ensemble members. The subsampling ensemble, however, has to perform, for each data object (n), a kNN query on a subsample only (i.e., m • n for sample rate 0 &lt; m &lt; 1). Repeated on s subsamples, this results in O(n • mn • s). For example, with a sample rate of 10% and an ensemble size of 10 members, the ensemble requires roughly the same runtime as a single base learner on the full data set while the runtime of a standard ensemble (combining models learned on the complete dataset) would be roughly 10 times the base learner's runtime.</p><p>3. The approach of "isolation forests" <ref type="bibr" target="#b47">[46]</ref> designs a randomized method leading to diversity. The effect of randomized methods is, however, complemented in this method by the effect of random subsamples of the dataset. On each subsample, a binary tree (called "isolation tree") is built splitting randomly selected attributes at randomly selected split points up to a specified depth or until a given subset at some node cannot be split (because it has only one element). The path length for an object in the tree is expected to be shorter in areas of lower density. Hence, the ensemble (the forest) is essentially an aggregate of randomized density estimates.</p><p>The speed-up effect of the subsampling is not as prominent in the approach of isolation forests as in the more general approach for methods based on kNN queries <ref type="bibr" target="#b76">[75]</ref> since no kNN queries are required for building the binary trees anyway. A possible effect of using subsamples here is that the trees, because these subsamples are unlikely to contain many outliers, are built faster and describe the dataset in a more concise way.</p><p>The effect of inducing diversity by drawing subsamples appears to be less important for the success of this method than the effect of the randomization of attribute and split point selection <ref type="bibr" target="#b47">[46,</ref><ref type="bibr">Fig. 18</ref>].</p><p>4. Combining models learned using different parameters has been proposed as an ensemble method by Gao and Tan <ref type="bibr" target="#b24">[23]</ref>, although Aggarwal <ref type="bibr" target="#b2">[2]</ref> identified traces of this idea in earlier papers without an explicit discussion of the ensemble idea. For example, for LOF <ref type="bibr" target="#b10">[9]</ref> as well as for LOCI <ref type="bibr" target="#b57">[56]</ref>, the authors suggested to try different parameters (controlling the granularity of neighborhood analysis; in LOCI, the combination of different granularity is even inherent to the method) and to use the granularity that optimally enhances the outlierness. Following this model, a recent generalized KDE-based method <ref type="bibr" target="#b65">[64]</ref> also combines models learned for different parameters to an ensemble approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Combining outlier scores of different algorithms (i.e., combinations of different models of what constitutes</head><p>an outlier) has been explored in several studies <ref type="bibr">[54; 40; 63]</ref>.</p><p>When combining scores from different models, normalization and unification of the scores that can scale very differently and sometimes are even inverted (i.e., some methods represent outliers by large scores, some methods represent outliers by small scores) becomes essential (although normalization should be considered for combination of scores from different subspaces or different parameters as well, depending on the properties of the model).</p><p>The first of these studies <ref type="bibr" target="#b55">[54]</ref> used a generic normalization, the second <ref type="bibr" target="#b41">[40]</ref> studied the properties of distributions of scores for different methods and, thus, was able to use specialized normalization procedures. The third <ref type="bibr" target="#b64">[63]</ref> proposed a greedy combination procedure based on an assessment of diversity of models.</p><p>Overall, these studies highlight three important aspects for outlier ensembles: assessment of diversity, normalization of scores, and combination procedures, which we discuss in Sections 4.2, 5.1, and 5.2, respectively. The greedy combination strategy <ref type="bibr" target="#b64">[63]</ref> also raises an interesting challenge for outlier ensembles: how to choose good ensemble members or how to train improved ensemble members based on previously learned and evaluated models in the absence of a ground truth for evaluation. This challenge has also been noted by Aggarwal <ref type="bibr" target="#b2">[2]</ref>. The heuristic of the greedy ensemble will be discussed in Section 4.3. At first sight, thinking about the transfer of techniques from classification or clustering ensembles, it may seem that with the five mentioned categories of heuristics for inducing diversity the obvious opportunities have been studied in the literature. However, all these studies leave room for deeper understanding of these heuristics and there are probably more methods for inducing diversity waiting to be explored that perhaps do not have a counterpart in classification or clustering ensembles. For example, diverse models could be learned by using different distance measures. This has only been studied partly <ref type="bibr" target="#b64">[63]</ref>, assessing the resulting diversity of models but not the quality of ensembles combining these models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Assessing Diversity</head><p>Having seen different methods for inducing diversity that are known from classification or clustering ensembles, the question arises how well these methods work in the context of outlier detection. This question was addressed by a recent study <ref type="bibr" target="#b64">[63]</ref>, proposing the vector space of outlier scores that we sketched above and weighted Pearson correlation as a similarity measure for these score vectors. This study discussed two use cases of such an assessment of diversity: (1) studying the suitability of methods for inducing diversity and (2) selecting the most diverse models for combination. The latter we discuss in Section 4.3, as mentioned earlier.</p><p>Let us discuss the first aspect now. The idea of using a weighted similarity measure, such as weighted Pearson, to compare score vectors, is motivated by the relative importance of outlier scores while differences in inlier scores should not matter that much. Given a ground truth (i.e., using some dataset with known outliers), the weights for the similarity measure comparing score vectors can be adjusted to this ground truth. Studying some methods, some distance measures, and some datasets using such a weighted similarity measure, the findings reported by Schubert et al. <ref type="bibr" target="#b64">[63]</ref> are:</p><p>• Outlier score vectors are usually similar (strongly correlated) between the same model just using different parameters (e.g., different values of k for the neighborhood size, i.e., different granularity). Hence, this method of inducing diversity is probably not a good idea for building ensembles as long as the model used is not known to be an "unstable learner" w.r.t. its parameter. The classic models LOF <ref type="bibr" target="#b10">[9]</ref>, kNN outlier <ref type="bibr" target="#b61">[60]</ref>, and kNN weight <ref type="bibr" target="#b5">[4]</ref>, among others, are shown experimentally to be rather stable w.r.t. neighborhood size.</p><p>• Different distance measures can have a stronger impact on diversity on some datasets. But there are also examples where all L p norms result in strongly correlated results while results based on vector-length invariant distance measures (such as the cosine distance and other correlation measures) again are correlated strongly with each other but not with the Lp-normbased results. Using different distance measures hence seems to be promising although the suitability of some distance measure is highly dataset dependent.</p><p>• Different models (algorithms) fall into families that learn similar results. For example, the results of LOF <ref type="bibr" target="#b10">[9]</ref> and of the LOF variant LoOP <ref type="bibr" target="#b39">[38]</ref> seem highly correlated, and the results of the kNN model <ref type="bibr" target="#b61">[60]</ref> and the kNN weight model <ref type="bibr" target="#b5">[4]</ref> are strongly correlated as well (on the datasets studied), but LOF or LoOP (both being local methods) and kNN or kNN weight (both being global methods <ref type="bibr" target="#b66">[65]</ref>) are not strongly correlated.</p><p>Combining models from different families might have a large potential to lead to improved ensembles.</p><p>• Feature bagging <ref type="bibr" target="#b46">[45]</ref> apparently has the potential to lead to very uncorrelated results and, thus, to improved ensembles.</p><p>The finding of weakly correlated results by feature bagging is also reflected in the finding of feature bagging being rather unstable <ref type="bibr" target="#b76">[75]</ref>. From the perspective of building ensembles, instability is not necessarily a bad thing although the combination of very different models is not bound to lead to a good ensemble. Diversity, after all, is only one aspect besides accuracy and too much of diversity is bound to limit accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Selection</head><p>Aggarwal <ref type="bibr" target="#b2">[2]</ref> pointed out that analogues of "boosting" or "bucket of models" -established concepts for supervised ensemble learning -are unlikely to be developed for unsupervised outlier detection. We pointed out (Section 3), that internal validity measures for outlier detection results are still missing in the literature and would be very important. Yet this does not mean that model selection is impossible: at least a greedy heuristic, optimizing diversity in an ensemble, has been discussed recently <ref type="bibr" target="#b64">[63]</ref>. This rather crude heuristic (see a sketch in Algorithm 1) relies on an accuracy estimate based on all learned potential ensemble members. The method first takes the union of the top k points of all results as preliminary outliers for determining weights for the similarity measure (weighted Pearson), assessing the diversity between results. Then the ensemble is composed, starting with the result that is closest to this consensus result. Next the remaining outlier detectors are sorted by the lowest correlation to the result of the current ensemble (initially, the ensemble consists only of one outlier detector) and test if including the next detector would improve the correlation of the ensemble result with the (preliminary) target vector (i.e., the estimated ground truth). If yes, this detector is included in the ensemble and the list of remaining detectors is reordered. If no, the detector is discarded and the algorithm continues with the next detector. Note that the whole process works in a completely unsupervised manner in that no actual ground truth is used. This heuristic is based on the assumption that the union of the complete set of individual outlier detectors is somehow accurate but can be improved by dropping those detectors that are strongly correlated with others. This assumption serves to overcome the limitations of unsupervised ensemble learning by unavailability of training data. Although we cannot see -so far -analogues of boosting for unsupervised learning either, very likely better heuristics than this greedy model selection are possible. In terms of the issue of accuracy (Section 3), this heuristic is using internally constructed means of validation as if it were externally available ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Challenges</head><p>As challenges for future research on the aspect of diversity for outlier ensembles, we see the following research questions:</p><p>• A thorough study of the heuristics to induce diversity proposed so far, in more detail and in comparison with each other, would be very interesting. As the heuristics are rather different from each other, a decent and fair comparison study is far from trivial. One could study the diversity actually achieved by the methods for inducing diversity, and the impact of diversity on the performance of an ensemble.</p><p>• To identify yet other methods for inducing diversity would probably lead to broader applicability and deeper understanding of the impact of diversity and of the stability of base methods.</p><p>• To develop better measures of diversity of outlier score vectors in the absence of ground truth would also be crucial to help us understand the issues of diversity and stability.</p><p>• Effective methods of choosing appropriate ensemble members (i.e., those that are different from other ensemble members) would also be desirable. Answers to the previous issues would allow progress here as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">COMBINATION OF MODELS</head><p>Having derived a couple of outlier detection results, or vectors of outlier scores, that are -ideally -diverse and accurate to some extent, the third central question is how to combine them to derive a consensus or ensemble result.</p><p>The two issues we discuss here in particular are the requirement of score normalization for a meaningful combination of scores (Section 5.1) and the different possibilities to combine (normalized) score vectors (Section 5.2). Some prefer to combine the rankings instead of the score vectors which we will touch upon (Section 5.3). We suggest challenges and issues for future research w.r.t. the combination of models (Section 5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Normalization of Scores</head><p>Any meaningful combination of score vectors relies heavily on the scores provided by the individual outlier detectors being comparable. This problem practically rules out the combination of different base methods or, for many methods, different parametrizations of the same method (e.g., different k for a kNN-distance-based method, as the result with the largest k would dominate the distance values). Even when using the same method as base outlier detector and identical parametrization, outlier scores obtained from different subspaces could vary considerably, if some subspaces have largely different scales. The ensemble could then be dominated by just one of the feature bags. Several of the papers discussing outlier detection ensembles focused on the issue of comparability of scores for score combinations. The first approach was to use sigmoid functions and mixture modeling to fit outlier scores, provided by different detectors, into comparable probability values <ref type="bibr" target="#b24">[23]</ref>. The second approach was scaling by standard deviation <ref type="bibr" target="#b55">[54]</ref>. Finally, statistical reasoning about typical score distributions by different methods enabled normalizations tailored to particular properties of different methods <ref type="bibr" target="#b41">[40]</ref>.</p><p>Although the solutions provided so far probably leave room for improvements, the important thing is to realize the problem and to use some normalization when combining outlier scores. To provide a good estimate of the actual probability of some object being an outlier is something valuable for supporting the user in the interpretation of the individual outlier detection result. For combination of several results into an ensemble, this calibration is perhaps not equally important. But normalization of scores is important, to avoid a bias of the decision to the individual result with the largest scale. This distinction is somewhat analogous to the distinction between class probability estimates and classification decisions based on these probability estimates that has been emphasized for the understanding of the performance of the naïve Bayes classifier <ref type="bibr" target="#b18">[17]</ref>: the outlier scores need not be good absolute outlier "probabilities" in order to make sense for a combination but their relative scale needs to reflect the actual ratio of outlierness for compared objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Combination of Score Vectors</head><p>Let us assume we are provided with accurate, diverse, and normalized outlier scores, where normalization includes regularization <ref type="bibr" target="#b41">[40]</ref>, i.e., without loss of generality we can assume that the larger score denotes "more" outlierness while inliers should have been assigned small score values. Now the question remains how to combine the scores. Aggarwal [2, Section 4.2] discusses this issue as well, mentioning several interesting possibilities. As the most commonly used methods he names the maximum and the average function but which combination function is best remains an open question. We do not intend to answer this question, but rather to contribute to the debate. In our opinion, from the point of view of ensembles, using the maximum of scores has some decisive disadvantages whereas the average does seem to make more sense.</p><p>To understand the disadvantage of using the maximum score, consider Figure <ref type="figure" target="#fig_2">2</ref>, depicting the result of the maximum function (blue X) as combination of the individual score vectors (red crosses), in comparison to the average in Figure <ref type="figure" target="#fig_0">1</ref>. The maximum as a combination function results in the upper bound of all individual scores and, hence, has a tendency to overestimate the outlierness. This also means that a single result that is far off, overestimating the scores for some objects, will determine the ensemble result (e.g., Figure <ref type="figure" target="#fig_2">2(b)</ref>). Errors for different objects, contributed by different individual outlier score vectors, can lead the maximum combination actually more off while all individual outlier scores are not too bad overall (e.g., Figure <ref type="figure" target="#fig_2">2</ref>(a)) -remember that this is a toy example for the rankings of two objects only. For a realistic scenario with n 2 objects, it would be even more likely that some individual score vector is off for some single object (i.e., in a one-dimensional subspace) and all the other score vectors would not matter at all for this object. This contradicts the very intuition of building ensembles. Errors of each individual score vector for single objects are strongly emphasized, and an error of a single ensemble member assigning a high outlier score to some object cannot be compensated for, even if all other detectors would be correct. This drawback counteracts one of the most fundamental benefits that one can expect from using an ensemble method: the correction of errors committed by single ensemble members. Let us note that keeping the maximum scores from different outlier models, if these models are learned in different subspaces, could be an approach to the problem of "multiview" outliers that we mentioned in the introduction -and that is somehow orthogonal to the ensemble or consensus idea. On the other hand, using the average of scores has been theoretically advocated <ref type="bibr" target="#b76">[75]</ref> for the combination of outlier scores based on (local) density estimates (as used by many classic methods such as LOF and its variants <ref type="bibr">[9; 56; 38; 39]</ref> or the kNN outlier model and its variants <ref type="bibr">[60; 4; 74]</ref>). 1 Building the average of different density estimates allows to abstract from the individual errors of these density estimates and, instead, to reason about the expected error. This reasoning 1 Note that the set of methods using local density estimates is not restricted to the so-called local outlier detection methods. These are two different notions of "local", as elaborated by Schubert et al. <ref type="bibr" target="#b66">[65]</ref>. might open up possibilities to improve our theoretic understanding of the benefit of ensembles for outlier detection. However, the choice of a particular combination function will also remain application dependent. If the cost of missing a single outlier is much higher than the cost for a high false alarm rate, using the maximum combination is certainly worth considering. On the other hand, in an application scenario where the cost for false negatives is very high but missing some outliers might not hurt too much, maybe even the minimum as a combination method for score methods may be a good choice. This would mean that all individual methods would have to assign a high outlier score to an object in order to actually count this object as an outlier.</p><p>If just one of the ensemble members assigns a small outlier score, the minimum ensemble would use this smallest score for this object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Combination of Rankings</head><p>Combining rankings provided by outlier methods, ignoring the actual outlier scores, could be seen as a particular way of normalization. But there is a considerable amount of literature in databases and in information retrieval on the combination of rankings that opens up possibilities for transferring known results from these areas to the particular problem of outlier detection. The feature bagging method <ref type="bibr" target="#b46">[45]</ref>, for example, was discussed in combination with a breadth-first traversal rank combination, i.e., taking the top ranked object from each individual ranking, then the second rank and so on. This is almost equivalent to using the maximum as score combination function<ref type="foot" target="#foot_0">2</ref> and, thus, has the same pros and cons. Most methods, however, use the outlier scores and not only the rankings. This might be motivated by the assumption that the scores and their relative differences have at least some meaning (an assumption that actually might be debatable, in particular for high dimensional data due to an effect analogous to the concentration of distances <ref type="bibr" target="#b77">[76]</ref>). See also the discussion of normalization issues by Aggarwal [2, Section 4.1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Challenges</head><p>As challenges for future research on the aspect of combining several outlier detection results to a consensus or ensemble ranking or score vector, we see the following issues and questions for research:</p><p>• Improved normalizations of outlier scores via a better understanding of score distributions can possibly improve interpretability of individual scores and, as a consequence, can lead to a smoother combination of outlier scores to an ensemble.</p><p>• Can scores actually be converted into "outlier probabilities" <ref type="bibr">[23; 40]</ref>? How would the success of such a conversion be evaluated (the problem of "calibration")?</p><p>• Should the calibration of outlier scores depend on the application? With different costs of false negatives or false positives, maybe the outlier scores should also get a bias in the more important direction. This question might have parallels in cost sensitive learning and the application of problem dependent loss functions.</p><p>• What are the effects of different combination functions? Which combination function is suitable for which application scenario?</p><p>• How to transfer rank accumulation procedures known in different areas such as databases and information retrieval to outlier ranking with its particular requirements?</p><p>• Can we improve our theoretical understanding of why unsupervised ensembles actually work?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>Aggarwal <ref type="bibr" target="#b2">[2]</ref> discussed algorithmic patterns, identified traces of the ensemble idea in the literature, and touched upon more or less likely options for future transfer of concepts from supervised ensembles for classification to ensembles for unsupervised outlier detection. Complementing his overview, we focused on the fundamental ingredients for success in building ensembles for unsupervised outlier detection. These are (1) learning accurate but (2) diverse models and (3) combining these models (or a selection thereof). For all these aspects, the literature provides not more than some first steps and insights which we sketched in this paper. As we point out, there are many opportunities to improve, for all aspects, we listed some challenges and issues for future research. It is our hope to stimulate research on the surprisingly neglected but very interesting and promising topic of ensembles for outlier detection. VantagePoint Student Edition is a one-year license available to students and faculty of accredited academic institutions in Canada, USA, and Europe.</p><p>For more information or to purchase visit www.vpinstitute.org</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Diverse and clustered outlier detection results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 : 1 2|K| (outliers), 1 2</head><label>111</label><figDesc>Greedy Model Selection /* individual outlier detectors: */ I := list of individual outlier detectors; K := union of top-k outliers ∀I; /* K are the preliminary 'outliers' */ v := target vector; /* (vi = 1 if object i ∈ K, vi = 0, otherwise) */ E := ∅ ensemble; sort I by weighted Pearson correlation to v; /* weights: (n-|K|) (inliers) */ E := E getFirst(I); p := current prediction of E; sort I by weighted Pearson to p (decreasing order); while I = ∅ do i = getFirst(I); if weightedPearson(E i, v) &gt; weightedPearson(E, v) then E := E i; p := current prediction of E; sort I by weighted Pearson to p (decreasing order); end end return E ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The maximum for score combination results in an upper bound of the result vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>VantagePoint</head><label></label><figDesc>Student Edition is a powerful text-mining and visualization tool for discovering knowledge in search results from scientific, technical, patent, and other field-structured text databases. VantagePoint Student Edition can analyze content from a variety of databases including CSA, Ebscohost, EiVillage, ISI WoK, Ovid, PubMed, ScopusNSF awards, or your own Excel or Access databases.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Different from the maximum score combination, this breadth-first rank combination introduces a discretization and the resulting ranking depends on the order of the individual rankings for the traversal.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DEALING WITH BIG DATA?</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Outlier detection by active learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zadrozny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 12th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="504" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Outlier ensembles</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>position paper</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<title level="m">Outlier Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast outlier detection in high dimensional spaces</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pizzuti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th European Conference on Principles of Data Mining and Knowledge Discoverys (PKDD)</title>
		<meeting>the 6th European Conference on Principles of Data Mining and Knowledge Discoverys (PKDD)<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finding natural clusters using multi-clusterer combiner based on shared nearest neighbors</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ayad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Workshop on Multiple Classifier Systems (MCS)</title>
		<meeting><address><addrLine>Guildford, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="166" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive cluster ensemble selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 21st International Joint Conference on Artificial Intelligence (IJCAI)<address><addrLine>Pasadena, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="992" to="997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<author>
			<persName><forename type="first">V</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Outliers in Statistical Data</title>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LOF: Identifying density-based local outliers</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Management of Data (SIGMOD)</title>
		<meeting>the ACM International Conference on Management of Data (SIGMOD)<address><addrLine>Dallas, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Diversity creation methods: a survey and categorisation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Meta clustering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elhawary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 6th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="58" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Article</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Anomaly detection for discrete sequences: A survey</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="823" to="839" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discriminative features for identifying and interpreting outliers</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">H</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Data Engineering (ICDE)</title>
		<meeting>the 30th International Conference on Data Engineering (ICDE)<address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Outlier detection with space transformation and spectral analysis</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">H</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Micenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th SIAM International Conference on Data Mining (SDM)</title>
		<meeting>the 13th SIAM International Conference on Data Mining (SDM)<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="225" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First International Workshop on Multiple Classifier Systems (MCS)</title>
		<meeting><address><addrLine>Cagliari, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Beyond independence: Conditions for the optimality of the simple bayesian classifier</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Machine Learning (ICML)</title>
		<meeting>the 13th International Conference on Machine Learning (ICML)<address><addrLine>Bari, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Systematic construction of anomaly detection benchmarks from real data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Emmott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Outlier Detection and Description, held in conjunction with the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting><address><addrLine>Chicago; USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Illinois</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Random projection for high dimensional data clustering: A cluster ensemble approach</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Z</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Machine Learning (ICML)</title>
		<meeting>the 20th International Conference on Machine Learning (ICML)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="186" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Z</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<title level="m">Cluster ensemble selection. Statistical Analysis and Data Mining</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="128" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Combining multiple clusterings using evidence accumulation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L N</forename><surname>Fred</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="835" to="850" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On using class-labels in evaluation of clusterings</title>
		<author>
			<persName><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mul-tiClust: 1st International Workshop on Discovering, Summarizing and Using Multiple Clusterings Held in Conjunction with KDD 2010</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Converting output scores from outlier detection algorithms into probability estimates</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-N</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 6th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="212" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cluster ensembles</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="315" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Clustering aggregation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mannila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tsaparas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Procedures for detecting outlying observations in samples</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Grubbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Selecting diversifying heuristics for cluster ensembles</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Hadjitodorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Workshop on Multiple Classifier Systems (MCS)</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Moderate diversity for better cluster ensembles</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Hadjitodorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Todorova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="275" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The meaning and use of the area under a receiver operating characteristic (roc) curve</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Mcneil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="29" to="36" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Identification of Outliers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hawkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Chapman and Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unifying dependent clustering and disparate clustering for nonhomogeneous data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tadepalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Helm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 16th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="593" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Arabie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Classification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Comparative study of matrix refinement approaches for ensemble clustering</title>
		<author>
			<persName><forename type="first">N</forename><surname>Iam-On</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boongoen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ranking outliers using symmetric neighborhood relationship</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K H</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), Singapore</title>
		<meeting>the 10th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), Singapore</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="577" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Finding Groups in Data: An Introduction to Cluster Analyis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">John Wi-ley&amp;Sons</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">HiCS: high contrast subspaces for density-based outlier ranking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Böhm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Data Engineering (ICDE)</title>
		<meeting>the 28th International Conference on Data Engineering (ICDE)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A unified notion of outliers: Properties and computation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Knorr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd ACM International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the 3rd ACM International Conference on Knowledge Discovery and Data Mining (KDD)<address><addrLine>Newport Beach, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="219" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">LoOP: local outlier probabilities</title>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the 18th ACM Conference on Information and Knowledge Management (CIKM)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1649" to="1652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Outlier detection in axis-parallel subspaces of high dimensional data</title>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</title>
		<meeting>the 13th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Interpreting and unifying outlier scores</title>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th SIAM International Conference on Data Mining (SDM)</title>
		<meeting>the 11th SIAM International Conference on Data Mining (SDM)<address><addrLine>Mesa, AZ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Subspace clustering</title>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="351" to="364" />
			<date type="published" when="2012">2012</date>
			<publisher>Wiley Interdisciplinary Reviews</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Angle-based outlier detection in high-dimensional data</title>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 14th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="444" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Using diversity in cluster ensembles</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Hadjitodorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 IEEE International Conference on Systems, Man, and Cybernetics (ICSMC)</title>
		<meeting>the 2004 IEEE International Conference on Systems, Man, and Cybernetics (ICSMC)<address><addrLine>The Hague, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1214" to="1219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="181" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Feature bagging for outlier detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lazarevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 11th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Isolation-based anomaly detection</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Essai sur l&apos;application de l&apos;analyse à la probabilité des décisions rendues à la pluralité des voix</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J A N C</forename><surname>Marquis De Condorcet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">L&apos;Imprimerie Royale</title>
		<imprint>
			<biblScope unit="page">1785</biblScope>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Comparing clusterings -an axiomatic view</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 22nd International Conference on Machine Learning (ICML)<address><addrLine>Bonn, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Density-based clustering validation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moulavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Jaskowiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th SIAM International Conference on Data Mining (SDM)</title>
		<meeting>the 14th SIAM International Conference on Data Mining (SDM)<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Discovering multiple clustering solutions: Grouping objects in different views of the data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 10th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">1220</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Outlier ranking via subspace analysis in multiple views of the data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mülle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Böhm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 12th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="529" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Statistical selection of relevant subspace projections for outlier ranking</title>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Data Engineering (ICDE)</title>
		<meeting>the 27th International Conference on Data Engineering (ICDE)<address><addrLine>Hannover, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="434" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Cluster ensemble selection based on relative validity indexes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Naldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C P L F</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="289" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Mining outliers with ensemble of heterogeneous detectors on random subspaces</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gopalkrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Database Systems for Advanced Applications (DASFAA)</title>
		<meeting>the 15th International Conference on Database Systems for Advanced Applications (DASFAA)<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="368" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Consensus clusterings</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 7th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Omaha, NE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="607" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">LOCI: Fast outlier detection using the local correlation integral</title>
		<author>
			<persName><forename type="first">S</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kitagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Data Engineering (ICDE)</title>
		<meeting>the 19th International Conference on Data Engineering (ICDE)<address><addrLine>Bangalore, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="315" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Characterization and evaluation of similarity measures for pairs of clusterings</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pfitzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leibbrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems (KAIS)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="361" to="394" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A near-linear time approximation algorithm for angle-based outlier detection in high-dimensional data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 18th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A principled and flexible framework for finding alternative clusterings</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 15th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="717" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Efficient algorithms for mining outliers from large data sets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Management of Data (SIGMOD)</title>
		<meeting>the ACM International Conference on Management of Data (SIGMOD)<address><addrLine>Dallas, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="427" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">336</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Ensemble-based classifiers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rokach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">On evaluation of outlier rankings and outlier scores</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wojdanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th SIAM International Conference on Data Mining (SDM)</title>
		<meeting>the 12th SIAM International Conference on Data Mining (SDM)<address><addrLine>Anaheim, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1047" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Generalized outlier detection with flexible kernel density estimates</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th SIAM International Conference on Data Mining (SDM)</title>
		<meeting>the 14th SIAM International Conference on Data Mining (SDM)<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Local outlier detection reconsidered: a generalized view on locality with applications to spatial, video, and network outlier detection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="190" to="237" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A survey on enhanced subspace clustering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gopalkrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="332" to="397" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Cluster ensembles -a knowledge reuse framework for combining multiple partitions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="583" to="617" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Clustering ensembles: Models of concensus and weak partitions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Topchy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Punch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1866" to="1881" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Analysis of consensus partition in cluster ensemble</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Topchy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H C</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Fred</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 4th IEEE International Conference on Data Mining (ICDM)<address><addrLine>Brighton, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Ensembles of learning machines</title>
		<author>
			<persName><forename type="first">G</forename><surname>Valentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Masulli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Italian Workshop on Neural Nets</title>
		<meeting>the 13th Italian Workshop on Neural Nets<address><addrLine>Vietri, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="3" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Relative clustering validity criteria: A comparative overview</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vendramin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Analysis and Data Mining</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="209" to="235" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">On the combination of relative clustering validity criteria</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vendramin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Jaskowiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Scientific and Statistical Database Management (SSDBM)</title>
		<meeting>the 25th International Conference on Scientific and Statistical Database Management (SSDBM)<address><addrLine>Baltimore, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Local peculiarity factor and its application in outlier detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 14th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="776" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A new local distancebased outlier detection approach for scattered realworld data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</title>
		<meeting>the 13th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Subsampling for efficient and effective unsupervised outlier detection ensembles</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gaudet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J G B</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<meeting>the 19th ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)<address><addrLine>Chicago, IL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A survey on unsupervised outlier detection in high-dimensional numerical data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Analysis and Data Mining</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="363" to="387" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The blind men and the elephant: On meeting the problem of multiple truths in data from clustering and pattern mining perspectives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vreeken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
