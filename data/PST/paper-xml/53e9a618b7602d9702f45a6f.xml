<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Goal-directed imitation for robots: A bio-inspired approach to action understanding and skill learning $</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-03-30">30 March 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">W</forename><surname>Erlhagen</surname></persName>
							<email>wolfram.erlhagen@mct.uminho.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics for Science and Technology</orgName>
								<orgName type="institution">University of Minho</orgName>
								<address>
									<postCode>4800-058</postCode>
									<settlement>Guimaraes</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">A</forename><surname>Mukovskiy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics for Science and Technology</orgName>
								<orgName type="institution">University of Minho</orgName>
								<address>
									<postCode>4800-058</postCode>
									<settlement>Guimaraes</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">E</forename><surname>Bicho</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Industrial Electronics</orgName>
								<orgName type="institution">University of Minho</orgName>
								<address>
									<postCode>4800-058</postCode>
									<settlement>Guimaraes</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><surname>Panin</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Informatics</orgName>
								<orgName type="department" key="dep2">Chair for Robotics and Embedded Systems</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<postCode>85748</postCode>
									<settlement>Garching</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">C</forename><surname>Kiss</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Informatics</orgName>
								<orgName type="department" key="dep2">Chair for Robotics and Embedded Systems</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<postCode>85748</postCode>
									<settlement>Garching</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">A</forename><surname>Knoll</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Informatics</orgName>
								<orgName type="department" key="dep2">Chair for Robotics and Embedded Systems</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<postCode>85748</postCode>
									<settlement>Garching</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><surname>Van Schie</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Nijmegen Institute for Cognition and Information</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
								<address>
									<postCode>6500 HE</postCode>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">H</forename><surname>Bekkering</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Nijmegen Institute for Cognition and Information</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
								<address>
									<postCode>6500 HE</postCode>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Goal-directed imitation for robots: A bio-inspired approach to action understanding and skill learning $</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2006-03-30">30 March 2006</date>
						</imprint>
					</monogr>
					<idno type="MD5">D39E24A98789901A0522CDB383B6BA1C</idno>
					<idno type="DOI">10.1016/j.robot.2006.01.004</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Imitation learning</term>
					<term>Dynamic field</term>
					<term>Mirror neurons</term>
					<term>Action sequence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present a robot control architecture for learning by imitation which takes inspiration from recent discoveries in action observation/execution experiments with humans and other primates. The architecture implements two basic processing principles: (1) imitation is primarily directed toward reproducing the outcome of an observed action sequence rather than reproducing the exact action means, and (2) the required capacity to understand the motor intention of another agent is based on motor simulation. The control architecture is validated in a robot system imitating in a goal-directed manner a grasping and placing sequence displayed by a human model. During imitation, skill transfer occurs by learning and representing appropriate goal-directed sequences of motor primitives. The robustness of the goal-directed organization of the controller is tested in the presence of incomplete visual information and changes in environmental constraints.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There has been a growing interest in creating autonomous robots which are capable of developing motor and cognitive skills through real-time interactions with their environment. Recent research in movement learning suggests that trying to imitate an experienced teacher (e.g., a human) is a powerful means of speeding up the learning process (for reviews see <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>). This form of social learning in robots is not restricted to movements. It may be complemented by acquiring more abstract knowledge such as, for instance, structurally new motor behaviors composed of a set of parameterized motor primitives.</p><p>In this paper we summarize results of an interdisciplinary project which aimed at exploring new ways of imitation and imitation learning in artefacts based on recent discoveries in cognitive psychology and neuroscience. The basic idea was to get new insights into the relevant functional mechanisms underlying imitation from behavioral and neuronal data. Central questions for robot imitation that we have addressed in our work concern "what to imitate" and how to solve the correspondence problem across dissimilar embodiments and task constraints <ref type="bibr" target="#b2">[3]</ref>. Very often these differences simply do not allow for a matching on the level of movement trajectory or path. In the goal-directed theory of imitation proposed by Bekkering and colleagues <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> imitative behavior can be considered successful whenever the goal of an action in terms of the desired outcome of the movement is reproduced. The action means, on the other hand, may or may not coincide with the observed ones. The focus on the consequences of the movement requires that the imitator understands the demonstrator's behavior as an intentional motor act directed at a specific goal (e.g., placing an object at a certain position). The "matching hypothesis" forwarded by Rizzolatti and colleagues <ref type="bibr" target="#b5">[6]</ref> based on their discovery of the mirror system states that an action is understood if its observation activates the motor representations controlling the execution of a similar goal-directed action ("motor simulation"). The proposed controller implements action understanding and goaldirected imitation as a continuous process which combines sensory evidence, contextual information, and a goal-directed mapping of action observation onto action execution. As a theoretical framework, we base our implementation work on dynamic fields <ref type="bibr" target="#b6">[7]</ref> previously used to endow autonomous robots with certain cognitive capabilities (e.g., memory, decision making, <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>).</p><p>The complete control architecture including vision, cognition and path planning is validated in variations of a paradigm in which the robot system learns to imitate a grasping and placing sequence displayed by a human model. The learning is accompanied by structural changes in the controller representing knowledge transferred from the human to the robot during imitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Experimental paradigm</head><p>To test the idea of a goal-directed organization of imitative behavior in a robot-human task we adopted a paradigm which has been originally developed for experiments with human subjects (van Schie and Bekkering, submitted for publication <ref type="bibr" target="#b21">[22]</ref>). The paradigm contains an object that must be grasped and then placed at one of two laterally presented targets that differ in height. Importantly, the grasping and transporting behaviors are constrained by an obstacle in form of a bridge (see Fig. <ref type="figure" target="#fig_0">1</ref>). Depending on the height of the bridge, the lower target may only be reached by grasping the object with a full grip and transporting it below the bridge. Placing the object at the higher target, on the other hand, may require combining a precision grip and a hand trajectory above the bridge.</p><p>The robot had to reproduce the observed or inferred action consequence (placed object). The work was conducted on a robot platform consisting of an industrial 6-degrees-offreedom robot arm (KUKA, Germany) on which a four-fingered anthropomorphic robot hand (GRAALTECH, University of Genova, Italy) was mounted. A real-time vision system provided the information about the scene parameters and the human hand motion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The control architecture</head><p>Three interconnected modules (vision, cognition, path planning) define the robot control architecture (see Fig. <ref type="figure" target="#fig_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Vision module</head><p>The vision module provides the environmental variables of the task setting (Cartesian position of bridge, object and goals) by means of a semi-automatic calibrated stereo camera system. All outputs are stored in the general configuration structure, globally available for the other modules of the controller. The demonstrator's hand and the object are identified and tracked in real time on the basis of a chroma-space blob segmentation in the YUV color space using a monocular camera view. The hand tracking algorithm is based on a mutual information optimization approach <ref type="bibr" target="#b10">[11]</ref> which maximizes the consistency between an observed image and postures of a hypothetic hand model (26-degrees-of-freedom). The hand trajectory (above or below the bridge) and the placing goal (high or low) are classified on the basis of a distance measure relative to the respective object. The categorization of the grasping behavior (full or precision) is essentially based on the orientation of the palm relative to the object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Cognitive module</head><p>In the cognitive module decisions about the action goal and the means to achieve that goal are made. Its layered architecture is biologically inspired, as it represents the basic functionality of neuronal populations in interconnected brain areas known to be involved in action observation/execution tasks (for details see <ref type="bibr" target="#b11">[12]</ref>). The STS-PF-F5 pathway is believed to represent the neural basis for a matching between the visual description of an action in area STS and its motor representation in area F5. Direct physiological evidence for this hypothesis comes from the existence of "mirror neurons" in F5 that become active both when the animal makes a particular action and when it observes another individual making a similar action. The fundamental idea we adopt for the robotics work is that the matching takes place on the level of motor primitives that represent complete goal-directed motor behaviors such as, for instance, "grasping an object with a full grip"( <ref type="bibr" target="#b5">[6]</ref>, see also <ref type="bibr" target="#b0">[1]</ref> for an excellent overview in the context of robotics research). Motor primitives do not encode the fine details of the movement and thus provide a sufficiently abstract level of description for imitation learning across dissimilar embodiments. Concretely for the bridge paradigm, we distinguish two types of grasping primitives (precision grip (PG) and full grip (FG)) and two types of transporting primitives for avoiding the obstacle (below (BT) or above (AT) the bridge).</p><p>The representations in the intermediate layer PF reflect recent neurophysiological findings in brain area PF that suggest a goal-directed organization of action means. Using a grasping-placing task, Fogassi and colleagues <ref type="bibr" target="#b12">[13]</ref> described a population of grasping mirror neurons which showed a selective response in dependence of the final goal of the action (placing vs. eating) to which the grasping act belongs. For the bridge paradigm, we abstract this finding by assuming representations of specific combinations of primitives (e.g., PG-AT) which allow achieving a specific placing goal. Possible goals parameterized by their height relative to the bridge (spatial gap, Fig. <ref type="figure" target="#fig_0">1</ref>), are assumed to be encoded in neuronal populations of the "prefrontal area" PFC. The reciprocal connections between PFC and PF are learned during the imitation experiments. Functionally, they allow one to override a direct matching between primitives in STS and F5 if necessary. Beside the direct stimulation by the vision system (placed object), the goal representations in PFC may be influenced by two additional information sources: (i) the task input represents memorized information about the number, identity (height) and probability of goals (for details of a computational implementation see <ref type="bibr" target="#b13">[14]</ref>). It reflects the fact that in a known task setting the robot may engage in partial motor preparation even before the observation of the human model. (ii) The second input represents object cues (e.g. color) which may become associated with the goal during imitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">The dynamics of decision making and learning</head><p>Each individual layer of the cognitive module is formalized by a dynamic field. The particular form we employed was originally introduced by Amari <ref type="bibr" target="#b6">[7]</ref> as a mathematical model for the dynamics of pattern formation in neuronal tissue. The main idea is that the interplay between excitatory and inhibitory interactions in local populations of neurons may sustain the population activity for extended periods of time. The buildup of self-sustained activity patterns in populations encoding action goal and means may thus be seen as the process of stabilizing and maintaining the task relevant information.</p><p>In the Amari model, the activity u(x, t) of a neuron at field location x at time t is governed by the following integrodifferential equation:</p><formula xml:id="formula_0">τ δ δt u(x, t) = -u(x, t) + h + i S i (x, t) + f 1 (u(x, t)) w(x -x ) f 2 (u(x , t)) dx -w inhib f 2 (u(x , t)) dx<label>(1)</label></formula><p>where τ &gt; 0 defines the time scale of the dynamics and h &lt; 0 the resting level to which the field activity relaxes without external stimulation. The non-linear functions f i (u), i = 1, 2; are of sigmoid shape,</p><formula xml:id="formula_1">f i (u) = 1 1 + exp(-β i (u -θ i ))<label>(2)</label></formula><p>with threshold θ 1 &gt; θ 2 and slope parameter</p><formula xml:id="formula_2">β 1 = β 2 .</formula><p>The strength of the excitatory connections w to field neighbors is expressed in terms of the distance between locations, that is, w(x, x ) = w(xx ). We used gaussian profiles with standard deviation σ s and amplitude A s . The feedback inhibition depends on the overall activity in the field and is controlled by the constant w inhib &gt; 0. Since the excitatory process is spatially restricted, the globally inhibitory process dominates at larger distances. Finally, the term i S i (x, t) represents the summed external input to the field which consists of excitation from connected layers and input from the vision module. The latter is modelled as gaussian functions of adequate intensity.</p><p>For the present work, we have adapted the model parameters to guarantee a bistable regime of the dynamics in which a transient input may act as a switch between a homogeneous rest state and a localized activity profile <ref type="bibr" target="#b6">[7]</ref>. In Fig. <ref type="figure" target="#fig_2">3</ref>, Panel A, we exemplify the evolution of such a profile in response to an input to a neuronal population representing the precision grip (PG). The build-up of excitation is accompanied by an increase in lateral inhibition which causes a suppression of activation in the population representing the grip alternative (FG). There is a threshold, u TH = 0, for triggering a self-sustained pattern. Weak external inputs (e.g., task input) may only bring the activation close to that threshold. As shown in Panel B, this "preshaping" mechanism may nevertheless drastically alter the time course of the suprathreshold response triggered by a sufficiently strong input <ref type="bibr" target="#b13">[14]</ref>. The observed speed-up of processing may, in turn, affect the decision processes in connected layers.</p><p>Crucial for our approach to learning by imitation is that the control architecture may autonomously evolve during practice by developing new task-relevant representations. We apply a correlation based learning rule for the synaptic connections, a(x, y), between any two neurons x and y in any two model layers that is compatible with the field format <ref type="bibr" target="#b14">[15]</ref>:</p><formula xml:id="formula_3">τ s δ δt a(x, y, t) = -a(x, y, t) + η f 2 ( ū1 (x)) f 2 ( ū2 (y))<label>(3)</label></formula><p>where η &gt; 0, τ τ s and ū1 , ū2 denote the equilibrium solutions of the relaxation phase in layer 1 and layer 2, respectively. Note that a transient phase of the dynamics could have been chosen as well without changing the results of the present study. Important for establishing a goal-directed organization of the control architecture is that an internally generated reinforcement signal representing a successful path planning toward the desired goal posture (see below) defines the time window for the learning. For simplicity, we have chosen a function which takes on the value 1 during the learning period and 0 otherwise. As a result, the metric for the learning appears to be defined by the similarity in the end state of the action <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Path planning</head><p>For generating overt behavior, the abstract motor primitives represented in layer F5 have to be translated into the right kinematics. We employ a global planning method in posture space which is inspired by Mel's biologically plausible network model <ref type="bibr" target="#b16">[17]</ref>. In the network, each of the locally interconnected nodes represents a stored posture, that is, a n-dimensional array of joint angles Θ i = (θ i1 , . . . , θ in ) T , i = 1, . . . , N , where N represents the number of network nodes covering the workspace W . It is assumed that a model for the forward kinematics of the arm/hand system exists, that is, the nodes are associated with the arm/hand location in Cartesian space. Each node Θ i is connected with its k nearest neighbors Θ j , j = 1, . . . , k defined by the euclidean metric d(i, j) = Θ i -Θ j 2 . The connection weights w i j = w(Θ i , Θ j ) are assumed to decrease exponentially with euclidean distance, w(i, j) = exp(-d(i, j)). Starting with an external activation of a set of goal postures P G , activation spreads in each time step to inactive nodes by summing the excitation, v j from the active neighbors multiplied by the respective connection weight, v i (t) = k j=1 v j (t -1) * w(i, j) and v P G (0) = 1 (there is no interaction between already activated units). When the wavefront reaches the node corresponding to the initial posture, the activation dynamics is stopped. The sequence of postures defining a suitable path from the initial state to the goal state is then found by back propagation in time along the maximally excited nodes. Inverse kinematics is used to define three distinct sets of goal postures P G i , i = 1, 2, 3, associated with the Cartesian location of the object to be grasped, X 1 , and location of the two placing targets, X 2 and X 3 , respectively. Moreover, additional information from the vision and the cognitive module of the control architecture is integrated before starting the wavefront operations <ref type="bibr" target="#b17">[18]</ref>. Posture nodes which are impossible due to the obstacles are inhibited. The forbidden set P O of all inhibited nodes is found by explicitly testing for spatial overlap in Cartesian space between the to-be-assumed posture and the bridge obstacle using forward kinematics. Moreover, the ensemble of nodes which can become part of the wavefront is further constrained by the motor primitives in F5. For instance, we use again forward kinematics to check whether a particular node Θ j represents "all links of the robot arm in a high position" as required by a trajectory above the bridge. This pre-selection of a set of compatible postures, P F5 , restrict the global planning process to the subset P F5 ∩ P O = ∅.</p><p>A real-time path planning for artefacts with higher degrees of freedom is possible due to a technique known in the literature as refinement procedure (e.g., <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>). Starting with a distribution of posture nodes covering only sparsely the whole work space, new nodes are successively introduced whenever needed. This refinement procedure and the successive re-planning may be necessary, for instance, around an obstacle or in the vicinity of nodes already defining a possible (albeit not smooth) path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>A set of imitation experiments within the bridge paradigm has been performed which differ in the amount of visual information available to the robot and in task constraints. The aims were <ref type="bibr" target="#b0">(1)</ref> to exemplify what kind of knowledge may be transferred from the human to the robot by autonomously developing new representations, and (2) to illustrate the advantages of a goal-directed organization of the control architecture in terms of robustness, compared to more traditional via-point matching models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Copying the means</head><p>In the first set of experiment, a complete visual description of the teacher's actions in terms of the grasping and transporting behavior exists and the vision system identifies the placing goal. Although the robot has the knowledge how to grasp, transport and place objects in its motor repertoire, it does not know how to combine under the constraints of the bridge paradigm the specific motor primitives to achieve the same end state. One strategy could be trying to copy the primitives displayed by the human demonstrator. The visual description of the observed motions in layer STS resonates via the matching mechanism in the mirror circuit with the congruent motor representations of the robot. If the covert path planning toward the desired posture necessary to achieve the action goal turns out to be successful, the observed action sequence becomes associated with the goal representation in layer PFC by the learning procedure described above. Fig. <ref type="figure" target="#fig_3">4</ref> illustrates the result of this learning by imitation in an example in which the robot copies the demonstrated precision grip and the trajectory above the bridge to place the object at the higher goal. In the various layers of the neural field model, the task specific information is encoded by activity profiles representing a steady state of the dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Discerning motor intention</head><p>The second set of experiments has been designed to reflect a major challenge for all robotics systems cooperating in cluttered environments with other agents. Due to occluding surfaces, for instance, only partial visual information about the action displayed by the partner may be available and the observing robot has to infer the action goal. The proposed control architecture implements the idea that a goal-directed motor simulation together with the integration of prior task knowledge underlies the capacity of discerning motor intention. Consistent with this view, it has been recently reported that mirror neurons may fire under appropriate experimental conditions (e.g., with additional contextual cues) even if the goal of the motor act is hidden from view <ref type="bibr" target="#b5">[6]</ref>. In the concrete example shown in Fig. <ref type="figure" target="#fig_4">5</ref>, only the demonstrator's grasping of the object with a full grip was observable. However since the robot is familiar with the task, links between goal representations and associated goal-directed sequences have been established in previous trials. In addition, the constant task input results in a pre-activation below threshold, u TH , of all task-relevant representations. As a result of the robot's "expectation" about possible goals and means, the evolving activation in STS encoding the observed FG-grip is sufficient to trigger first the sequence FG-BT and subsequently the representation of the associated lower goal (Panel B in Fig. <ref type="figure" target="#fig_4">5</ref>). As depicted in Panel C, the robot shows its action understanding by combining a full grip and a trajectory below the bridge to reproduce the inferred action effect. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Goal directed imitation</head><p>The third set of experiments illustrates that the learned link from the mirror circuit to the goal representation is crucial. The bar of the bridge is removed for the human but not for the robot (Panel A in Fig. <ref type="figure" target="#fig_5">6</ref>). Because of this change in the environmental constraints, the demonstrator now uses a full grip for placing the object at the higher target. For the robot, a direct matching on the level of motor primitives would result in a collision with the bridge. As shown in the snapshot of the field model in Panel B of Fig. <ref type="figure" target="#fig_5">6</ref>, the decisions in layer F5 represent the motor primitives PG and AT previously associated with the higher goal (compare Fig. <ref type="figure" target="#fig_3">4</ref>). This choice is the result of the primacy of the goals over the means implemented in the control architecture. The goal representation is triggered by direct input from the vision system. Through the learned links to layer PF, it biases the decision processes in the mirror circuit, thus overriding the direct mappings from the visual motion description in STS. Technically, we exploit here differences in time course with the goal representation being processed faster in a known task setting compared to the representations in STS (for a detailed discussion of the biological context see <ref type="bibr" target="#b11">[12]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>We have presented a control architecture for imitation and learning by imitation which is strongly inspired by recent insights about the processing principles underlying these capabilities in humans and other primates. In general, our approach emphasizes the role of factors in imitation which are usually considered cognitive such as goal inference or decision making. The experiments with the robot system illustrate that an organization of imitative behavior toward reproducing the goal of an observed action complements purely motor approaches which focus on a matching on the trajectory or path level <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref>. The primacy of the goal over the action means allows coping with differences in embodiment and task constraints known as the correspondence problem in robot imitation <ref type="bibr" target="#b2">[3]</ref>. The emphasis on "end state granularity" <ref type="bibr" target="#b2">[3]</ref> as a measure to classify successful imitative behavior does not exclude, however, that the transfer of knowledge on the level of action means may also be essential (compare Fig. <ref type="figure" target="#fig_3">4</ref>). Most importantly, learning to understand an observed behavior as a goal-directed action enables the robot to reuse the stored information in new contexts and to acquire more abstract knowledge associated with that action. For instance, association between specific object properties (e.g., color) and where to place an object of a particular category may be learned within the proposed control architecture (see Fig. <ref type="figure" target="#fig_1">2</ref>).</p><p>The idea that the movement production system is essentially involved in action understanding has been proposed in the context of robotics research before (for a review see <ref type="bibr" target="#b1">[2]</ref>). For instance, Demiris and Hayes <ref type="bibr" target="#b20">[21]</ref> used internal forward models known from motor control theory to predict the sensory consequences of observed actions in an imitation task. However, the questions how to cope with differences in embodiment, task constraints or even motor skills have not been systematically addressed. In principle, the control architecture proposed here allows for learning to understand the purpose of a hand movement not strictly in the repertoire of the imitator. The only condition is that the observed action effect may be achieved using proper action means <ref type="bibr" target="#b11">[12]</ref>.</p><p>In the present imitation paradigm, the goal-directed sequence is still relatively simple as it combines only four motor primitives. In a joint effort with our experimental colleagues we are currently testing the learning of more complex sequences composed of a richer set of existing movement primitives (e.g., a sequence composed of two grasping and placing behaviors). Conceptually, the implementation work does not require any changes in the overall control architecture. However, some modifications in the field dynamics (Eq. ( <ref type="formula" target="#formula_0">1</ref>)) and the learning dynamics (Eq. ( <ref type="formula" target="#formula_3">3</ref>)) have to be introduced. First, to prevent a competition between motor primitives belonging to the same category (e.g., grasping) but to different parts of the sequence, the representations should be transient in nature. A straightforward solution is to add a "forgetting dynamics" which results in a destabilization of the self-sustained activation profiles <ref type="bibr" target="#b8">[9]</ref>. Second, to allow for an explicit representation of the temporal order of primitives in layer PF a predictive Hebbian learning rule <ref type="bibr" target="#b14">[15]</ref> should be used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Bridge paradigm. The robot has to imitate a human grasping an object and placing it at one of the two targets behind the bridge obstacle.</figDesc><graphic coords="2,37.78,66.76,241.16,98.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Schematic diagram of the control architecture. The central part responsible for the selection of means and goals in the imitation task reflects recent neurophysiological findings in 4 interconnected brain areas. The functionality of the STS-PF-F5 pathway is to match action observation and action execution. The matching is controlled by the goal representations in area PFC.</figDesc><graphic coords="2,336.22,67.16,182.09,319.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Panel A: The temporal evolution of a self-stabilized activation pattern representing a decision for a PG-grip is shown. Note that at the time of stimulus onset, t = 0, the field appears to be already pre-activated by the constant input from the task layer in PFC. Panel B: The time course of the maximally excited field element is compared for the case with pre-activation (solid line) and without pre-activation (dashed line).</figDesc><graphic coords="4,38.74,66.48,238.96,105.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Copying the means. Panel A: The teacher shows a complete grasping-placing sequence, here precision grip (PG), followed by a transport above the bridge (AT). Panel B: Cognitive module. The peaks of activation in layer F5 represent the means (motor primitives) selected by the robot to reproduce the same goal. Panel C: The robot reproduces the observed placing at the lower target using the same means.</figDesc><graphic coords="5,47.55,66.87,241.17,428.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Inference task. Panel A: Only the grasping behavior is observable. Panel B: The stable state in layer PFC of the field model represents the inferred (lower) goal. Panel C: To reproduce the inferred action effect the robot combines a full grip (FG) followed by a trajectory below (BT) the bridge as represented in the motor layer F5 in Panel B.</figDesc><graphic coords="5,316.54,67.11,241.17,312.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Goal directed imitation. Panel A: Conflict in the grasping behavior, i.e. the teacher uses a full grip for placing the object at the higher goal. Panel B: As shown in layer F5 of the field model, the robot decides to use a precision grip to reproduce the observed action effect.</figDesc><graphic coords="6,41.73,66.57,233.20,197.19" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Leonardo Fogassi and Giacomo Rizzolatti for numerous discussions about this work.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>$ This work was supported by the European grants ArteSImit (IST-2000-29686) and JAST(IST-2-003747-IP).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Is imitation learning the route to humanoid robots?</title>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="233" to="242" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Computational approaches to motor learning by imitation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ijspeert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Billard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of Royal Society of London B</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="537" to="547" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The correspondance problem</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Nehaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Imitation in Animals and Artifacts</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Nehaniv</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="41" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imitation of gestures in children is goal-directed</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bekkering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wohlschläger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gattis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="153" to="164" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Action generation and action perception in imitation: An instantiation of the ideomotor principle</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wohlschäger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gattis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bekkering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of Royal Society of London B</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="501" to="515" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neurophysiological mechanisms underlying the understanding and imitation of action</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fogassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gallese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="661" to="670" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamics of pattern formation in lateral-inhibitory type neural fields</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamic fields endow behavior-based robots with representations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Engels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schöner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="55" to="77" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Target representation on an autonomous vehicle with low-level sensors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bicho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schöner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="424" to="447" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamical neural networks for planning and low-level robot control</title>
		<author>
			<persName><forename type="first">M</forename><surname>Quoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="532" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Alignment by Maximization of Mutual Information</title>
		<author>
			<persName><forename type="first">A</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A dynamic model for action understanding and goal-directed imitation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Erlhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mukovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bicho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Research</title>
		<imprint>
			<biblScope unit="volume">1083</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="175" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parietal lobe: From action organization to intention understanding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fogassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gesierich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="page" from="662" to="667" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dynamic field theory of movement preparation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Erlhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schöner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="545" to="572" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
		<title level="m">Theoretical Neuroscience</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discovering optimal imitation strategies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Billard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Epars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Calinon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Mel</surname></persName>
		</author>
		<title level="m">Connectionist Robot Planning: A Neurally-Inspired Approach to Visually-Guided Reaching</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Planning motions with intentions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kuffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Latombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques</title>
		<meeting>the 21st Annual Conference on Computer Graphics and Interactive Techniques</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="395" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Randomized preprocessing of configuration space for path planning: Articulated robots</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kavraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">- C</forename><surname>Latombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="764" to="1771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Motion Planning through Policy Search</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imitation as a dual-route process featuring predictive and learning components: A biologically plausible computational model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demiris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Imitation in Animals and Artifacts</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Nehaniv</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="327" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Van Schie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bekkering</surname></persName>
		</author>
		<title level="m">Neural mechanisms for goal-directed actions reflected by slow wave brain potentials</title>
		<imprint/>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
