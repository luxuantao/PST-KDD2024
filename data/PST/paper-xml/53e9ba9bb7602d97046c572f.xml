<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scale-Invariant Contour Completion using Conditional Random Fields</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaofeng</forename><surname>Ren</surname></persName>
							<email>xren@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Charless</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
							<email>fowlkes@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
							<email>malik@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scale-Invariant Contour Completion using Conditional Random Fields</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8391375DB7D600547070DFE414FAFC03</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a model of curvilinear grouping using piecewise linear representations of contours and a conditional random field to capture continuity and the frequency of different junction types. Potential completions are generated by building a constrained Delaunay triangulation (CDT) over the set of contours found by a local edge detector.</p><p>Maximum likelihood parameters for the model are learned from human labeled groundtruth. Using held out test data, we measure how the model, by incorporating continuity structure, improves boundary detection over the local edge detector. We also compare performance with a baseline local classifier that operates on pairs of edgels.</p><p>Both algorithms consistently dominate the low-level boundary detector at all thresholds. To our knowledge, this is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images. Better boundary detection has immediate application in the problem of object detection and recognition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Finding the boundaries of objects and surfaces in a scene is a problem of fundamental importance for computer vision. There is a large body of work on object recognition which relies on bottom-up boundary detection to provide information about object shape (e.g. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b2">3]</ref>). Even in cases where simple intensity features are sufficient for object detection, e.g. faces, it is still desirable to incorporate bottomup boundary detection in order to provide precise object segmentation (e.g. <ref type="bibr" target="#b24">[25]</ref>). The availability of high quality boundary location estimates will ultimately govern whether these algorithms are successful in real-world scenes where clutter and texture abound.</p><p>Boundaries are typically detected using some local operator. For example, the recent work by <ref type="bibr" target="#b14">[15]</ref> trains a classifier that predicts the probability of boundary, P b, at each pixel location using local brightness, texture and color gradient cues as features. Training data comes from a set of images where boundaries have been marked by human subjects.</p><p>Unfortunately, this algorithm still misses many true boundaries and falsely detects others. The authors argue that detection failures are primarily due to lack of context since human observers presented with only local image patches perform no better than the classifier <ref type="bibr" target="#b15">[16]</ref>. How can we model this missing context?</p><p>One well known source of contextual information is that provided by curvilinear continuity, sometimes referred to as "good continuation" or "illusory contour completion". Inspired by Wertheimer and Kanizsa, the study of this phenomenon has a long and influential tradition in psychophysics as well as neurophysiology <ref type="bibr" target="#b18">[19]</ref>. More recently, ecological statistics of contours have confirmed the existence of curvilinear continuity in natural images <ref type="bibr" target="#b7">[8]</ref> and its scale-invariant properties <ref type="bibr" target="#b20">[21]</ref>. In computer vision there exists a rich literature on how to model curvilinear continuity (e.g. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27]</ref>). More recent developments focus on finding closed salient contours <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>The most basic scientific question is whether this type of additional contextual processing improves the accuracy of boundary detection. In particular, any algorithm which boosts low-contrast or illusory boundaries may also find spurious completions in heavily texture regions of a scene. Is the net effect positive or negative? This question can only be answered by quantitative measurements. To the best of our knowledge, no such measurements have been made on a large, diverse set of real-world images.</p><p>The contribution of this paper is a stochastic model of continuity and closure which provides boundary estimates that are quantifiably better at all thresholds than the input provided by a local detector. Our approach starts with locally computed P b which is discretized into a set of piecewise linear segments. Potential completions are generated utilizing the constrained Delaunay triangulation as described in Section 2. We show that this scale-invariant geometric structure captures a vast majority of the true image boundaries, while reducing the complexity from hundreds of thousands of pixels to a thousand candidate line segments.</p><p>In Section 3 we develop two models of curvilinear con- tinuity on this graphical/geometric structure: a simple local model which classifies each pair of edges independently and a global model which uses a conditional random field <ref type="bibr" target="#b12">[13]</ref> in order to enforce both continuity and long-range probabilistic constraints on junctions.</p><p>Quantitative evaluation is made possible by utilizing three existing image collections that have been labeled with ground-truth boundaries: a set of 30 news photos of baseball players <ref type="bibr" target="#b16">[17]</ref>, 344 images of horses <ref type="bibr" target="#b3">[4]</ref> and the BSDS300 <ref type="bibr" target="#b0">[1]</ref>, a boundary detection benchmark based on images of natural scenes. The performance evaluation of the local and global models on these 3 datasets is presented in Section 4 along with exemplary results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Scale-Invariant Completion</head><p>The starting point of our approach is the observation that piecewise linear approximations of contours can be constructed in a scale-invariant way. Using the constrained Delaunay triangulation to complete the piecewise linear approximations preserves this scale-invariance. Figure <ref type="figure" target="#fig_0">1</ref> gives an illustration. The Delaunay triangulation (DT) is the dual of the Voronoi diagram and is the unique triangulation of a set of vertices in the plane such that no vertex is inside the circumcircle of any triangle. The constrained Delaunay triangulation (CDT) is a variant of of the DT in which a set of user-specified edges must lie in the triangulation. The CDT retains many nice properties of DT and is widely used in geometric modeling and finite element analysis. It was also recently applied to image segmentation by <ref type="bibr" target="#b28">[29]</ref>.</p><p>This piecewise linear representation has many advantages over using the pixel grid: (1) by moving from 100,000 pixels to 1000 edges, it achieves high statistical and computational efficiency. <ref type="bibr" target="#b1">(2)</ref> this discrete representation of the image is scale-invariant, independent of the image resolution.</p><p>(3) By restricting completions to the edges in the graph, it partially solves the problem of having too many spurious completions. Moreover, we will show empirically that very little of the true boundary structure is lost in this discretiza- tion process.</p><p>Of particular interest to us is scale invariance. Empirical studies of the ecological statistics of contours <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b5">6]</ref> have revealed one fundamental problem in many existing models: the lack of scale invariance. For example, the stochastic motion model of <ref type="bibr" target="#b26">[27]</ref> predicts that if one breaks contours into segments at high-curvature locations, the distribution of segment length should be exponential. Work by <ref type="bibr" target="#b20">[21]</ref> suggests that the empirical distribution is not exponential; instead it closely follows a power law, a characteristic of scale-invariant phenomena. A related power law is also reported in <ref type="bibr" target="#b5">[6]</ref>. These findings are consistent with the intuition that we see objects at arbitrary scales. Scale invariance is also crucial from a practical point of view, as it is required in many fundamental vision tasks such as object recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Building a piecewise linear representation</head><p>Our discretization step starts with using Canny's hysteresis thresholding to trace the P b contours and then recursively split them until each segment is approximately straight. Figure <ref type="figure" target="#fig_1">2</ref>(a) shows an illustration of this linearization: for a given contour, let θ be the angle between segments ca and cb. Pick the set of points {a, b, c}, in a coarseto-fine search, such that the angle θ is maximized. If θ is below a threshold, split the contour by adding a vertex at c and continue. A heuristic is added to handle T-junctions: when a vertex is very close to another line, we split this line and insert an additional vertex.</p><p>We use the TRIANGLE program <ref type="bibr" target="#b23">[24]</ref> to produce CDTs as shown in Figure <ref type="figure" target="#fig_2">3</ref>. The linearized edges extracted from the P b contours become constrained edges in the triangulation which we refer to as gradient edges or G-edges. The remaining completion edges or C-edges are filled in by the CDT. Of particular interest to us is CDT's ability to complete contours across gaps in the local detector output. A typical scenario of contour completion is one lowcontrast contour segment (missed by P b) in between two high-contrast segments (both detected by P b). If the lowcontrast segment is short in length, it is likely no other vertices lie in the circumcircle and CDT will correctly com- plete the gap by connecting the two high-contrast segments. This is closely related to the ligature analysis used in <ref type="bibr" target="#b1">[2]</ref>.</p><p>In order to establish groundtruth labels on the CDT edge for fitting our models, we need to transfer human marked boundaries from the pixel grid. This is accomplished by running a maximum-cardinality bipartite matching between the human marked boundaries and the CDT edges with a fixed distance threshold. We label a CDT edge as boundary if 75% of the pixels lying under the edge are matched to human boundaries; otherwise we label it as non-boundary.</p><p>Figure <ref type="figure" target="#fig_4">4</ref> shows the performance of the local boundary detector P b as well as the performance when we assign the average underlying P b to each CDT edge. 1 These results clearly show that moving from pixels to the CDT completion seldom gives up any boundaries found by the local measurement. The green curve documents the soft groundtruth labellings of the CDT edges (percentage matched to human marked pixels). This is the target output of the two continuity models we describe next. The gap between the asymptotic recall of P b and the ground-truth shows that the CDT is even completing a few contours which are completely illusory (i.e. contours with no local evidence). 1 Throughout this paper, performance is evaluated with using a precision-recall curve which shows the trade-off between false positives and missed detections. For each given thresholding t of the algorithm output, above threshold boundary points are matched to human-marked boundaries H and the precision P = P (H(x, y) = 1|P b(x, y) &gt; t) and recall R = P (P b(x, y) &gt; t|H(x, y) = 1) are recorded (see <ref type="bibr" target="#b14">[15]</ref> for more discussion).  We have experimented with other alternative schemes of completion. For example, one way to complete potential gaps is to allow each vertex to connect to its k nearest neighbors, subject to visibility. This scheme adds many more completions than the CDT, without achieving any improvement in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Modeling Curvilinear Continuity</head><p>In the previous section we described how to construct a discrete, scale-invariant structure, the CDT graph, from low-level edges. We will associate a random variable X e to every edge e in the CDT graph, where X e = 1 if e corresponds to a true boundary contour and X e = 0 otherwise. The variables {X e } interact with each other through vertices or junctions in the graph. Our goal is to build a probabilistic model of continuity and junction frequency on the CDT graph and make inference about {X e }.</p><p>We will introduce two models: one of local continuity and one of global continuity. The local continuity model considers only the local context of each e; each X e is estimated independently in its local context. This serves as a baseline model and is a convenient place to study the relevant features (which are all defined locally). The global continuity model uses conditional random fields <ref type="bibr" target="#b12">[13]</ref> to build a joint probabilistic model over all edges. We estimate the marginals of X e using loopy belief propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A local continuity model</head><p>Each edge e in a CDT graph is naturally associated with a set of features including the average P b of pixels along the edge e and whether it is a G-edge (detected in P b) or C-edge (completed by the CDT). The local context of e includes these features and those of neighboring edges in the CDT graph.</p><p>Consider the simplest case of context: a pair of connected edges ( Figure <ref type="figure" target="#fig_5">5(a)</ref> ). Each edge can be on or off (being a true boundary or not), hence four possible labelings of this pair. However, the groundtruth contours in our datasets are almost always closed; line endings and junctions are rare. Therefore we make the simplifying assumption that there are only two possible labelings: either both of them are on, or both are off.</p><p>Our best local model uses as features P b, average P b over the pair of edges; G, an indicator variable whether both of the edges are G-edges, and θ, the angle formed at the connection of the pair. We use logistic regression to fit a linear model to these features. We have found that logistic regression performs as well as other classifiers (we also tested support vector machines and hierarchical mixture of experts). It also has the advantage of being computationally efficient and simple to interpret.</p><p>To evaluate the local continuity model, we use the classifier to assign a new "probability of boundary" value to each edge e. Consider Figure <ref type="figure" target="#fig_5">5</ref>(b): evidence of continuity comes from both ends of an edge e 0 , as a contour at e 0 would have to continue in both directions. We assume that these two sources of information are independent and take a product. Recall X e = 1 if the pixels corresponding to e lie on a true boundary and 0 otherwise. The logistic model gives an estimate of P (X e 0 = 1, X e 1 = 1), the posterior probability that the pair of edges (e 0 , e 1 ) are both true. If S 1 and S 2 are the two sets of edges connecting to e 0 at the two ends we define the new boundary operator P b L under the 2-edge product model to be:</p><formula xml:id="formula_0">P b L = max e 1 ∈S 1 P (X e 0 = 1, X e 1 = 1)• max e 2 ∈S 2 P (X e 0 = 1, X e 2 = 1)</formula><p>The quantitative performance evaluation of P b L against P b is shown in Section 4.</p><p>To evaluate relative contribution of each feature, we fit classifiers to subsets of features and compared their performance. The results on the baseball player dataset are shown in Figure <ref type="figure" target="#fig_6">6</ref>. Performance is evaluated with both a precisionrecall curve and a cross-entropy loss L <ref type="bibr" target="#b8">[9]</ref>.</p><p>We observe that P b is the most useful feature with L = 0.418. Angle θ by itself is not as useful; however, when combined with P b, θ helps reduce the loss to 0.385. G by itself is quite informative, as 85% of the positive examples have G = 1 ( both edges being G-edges ). When the three features are combined, the loss is reduced to 0.374. We have experimented with many additional features but they are at most marginally useful, hence not included in the local model. We also considered several variants such as: a secondlayer classifier to combine information from the two ends of e 0 ; a 3-edge classifier which directly takes as input the features from triples of edges; and a full 4-way classification on each pair of edges. The simplest 2-edge product model described above performs as well as any of these variants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A global continuity model</head><p>In order to capture longer range dependencies of boundary presence we also consider a global probabilistic model built on top of the CDT. We utilize the same measurements as in the local-model (P b,G,θ) along with the frequency with which junctions of different degrees appear. To integrate these features across the image, we use a conditional random field (CRF) model as first introduced by <ref type="bibr" target="#b12">[13]</ref>.</p><p>Unlike the MRF models traditionally used in vision which model the joint distribution of image measurements and hidden labels, a CRF focus directly on the conditional distribution of labels given the observations. One key ad- vantage from our perspective is that the observed variables need not be conditionally independent given the hidden variables. This allows much greater freedom in choosing model features.</p><p>Conditional random fields have been proposed as a method for image segmentation by <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b9">10]</ref>, however, the focus is still on pixel-level labeling which is tied to the resolution of the pixel grid. Moving to scale free, mid-level tokens is our key ingredient to handling objects at a continuum of scales. For example, the "multi-scale" approach of <ref type="bibr" target="#b9">[10]</ref> uses features at three different scales relative to the image, but the features are different for each scale. To make such a model scale-invariant requires adding a set of features for every possible object scale and tying the parameters together across scales. In our case, because the CDT structure and input features are scale-invariant a simple random field would suffices.</p><p>We base the independence structure of our hidden variables on the topology of the CDT. Recall the random variable X e whose value is 1 if the pixels corresponding to e lie on a true boundary. Let X V be the collection of variables for all edges which intersect at a vertex V of the CDT. We consider log-linear distributions over the collection of edges of the form</p><formula xml:id="formula_1">P (X|I, Θ) = e { P e φ(Xe|I,Θ)+ P V ψ(X V |I,Θ)} Z(I, Θ)</formula><p>The φ potential function captures the extent to which the image evidence I supports the presence of a boundary under edge e. ψ describes the continuity conditions at a junction between contour segments. Θ is the collection of model parameters.</p><p>Our edge potential is given by</p><formula xml:id="formula_2">φ(X e |I, Θ) = βP b e X e</formula><p>where P b e is the average P b recorded over the pixels corresponding to edge e. The vertex potential is given by</p><formula xml:id="formula_3">ψ(X V |I, Θ) = i,j α i,j 1 {deg g =i,deg c =j} + γ1 {deg g + deg c =2} f (θ)</formula><p>where deg g is the number of G-edges at vertex V for which X e = 1 and similarly deg c is the number of C-edges which are turned on.</p><p>(deg g , deg c ) determines the "junction type" for every possible assignment of X v : for example, a total degree of 1 ((deg g + deg c ) = 1) corresponds to a line ending, 2 a continuation, and 3 a T-junction. The model associates a seperate weight α i,j to each possible type. When the total degree of a vertex is 2, γ weights the continuity of the two edges.</p><p>θ is the angle formed by the two edges turned on, and f is a smooth function which is symmetric around θ = 0, falling off as θ → π. If the angle between the two edges is close to 0, they form a good continuation, γf (θ) is large and they are more likely to both be turned on.</p><p>Our model has the collection of parameters Θ = {α, β, γ}. We fit Θ by maximizing the log likelihood. Since the likelihood is log-linear in the parameters, taking a derivative always yields a difference of two expectations. For example, the derivative with respect to the continuation parameter γ for a single training image/ground truth labeling, (I, X) is:</p><formula xml:id="formula_4">∂ ∂γ log e { P e φ(Xe|I,Θ)+ P V ψ(X V |I,Θ)} Z(I n , Θ) = V ∂ ∂γ {γ1 {deg g + deg c =2} f (θ)} - ∂ ∂γ log Z(I n , Θ) = V 1 {deg g + deg c =2} f (θ) - V 1 {deg g +deg c =2} f (θ) P (X|I,Θ)</formula><p>where we use the fact that derivatives of the log partition function generate the moment sequence of P (X|I, Θ). The first term is the observed sum of f (θ) on degree 2 vertices while the second term which is the expectation under the model given our current setting of the parameters. When the model expectations match those observed in the training data, we have found the maximum likelihood setting of the parameters. Until we reach that point, we take a small step in the gradient direction. Parameters typically converge after a few hundred iterations. Unfortunately, computing the expectations of our features with respect to model parameters is intractable. Unlike the sequence modeling tasks where conditional random fields were first investigated our graph is not tree structured, it contains many triangles (among other loops). We approximate the edge and vertex degree expectations using loopy belief propagation <ref type="bibr" target="#b25">[26]</ref>. Loopy belief propagation has been applied to many vision problems before, typically on the pixel-grid. The connectivity of the CDT graphs we study is more complicated than a regular grid. However, in our experiments belief propagation appears to converge quickly (&lt; 10 iterations) to a reasonable solution.</p><p>We find that the parameters learned from groundtruth boundary data match our intuition well. For example, the weight α 1,0 is much smaller than α 2,0 , indicating that line endings are less common than continuation and reflecting the prevalence of closed contours. For degree 2 vertices, we find α 2,0 &gt; α 1,1 &gt; α 0,2 , indicating that continuation along G-edges is preferable to invoking C-edges.</p><p>Once the model has been trained, we use belief propagation to estimate the marginal distributions {X e } on the edges of the CDT and then project these down to the pixel grid where it can then be compared to both the local model and the raw P b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results: Is curvilinear continuity useful?</head><p>We have described two different algorithms, each which outputs a new estimate of the boundary probability at each pixel: P b L , the local model on the CDT, and P b G , the global random field model. In order to evaluate these, we use three human-segmented datasets: a set of news photos of baseball players <ref type="bibr" target="#b16">[17]</ref>  Performance on these datasets is quantified using the precision-recall framework as in <ref type="bibr" target="#b14">[15]</ref>. Figure <ref type="figure" target="#fig_9">8</ref> shows the precision-recall curves for each data set. These quantitative comparisons clearly demonstrate that mid-level information is useful in a generic setting. Both models of curvilinear continuity outperform P b. The global model, which is able to combine local evidence of continuity and global constraints such as closure, performs the best.</p><p>The improvement is most noticeable in the lowrecall/high-precision range which corresponds to the case of boosting the most prominent boundaries and suppressing background noise. These boundaries are typically smooth; thus continuity helps suppress false positives in the background. This is evident in the examples shown in Figure <ref type="figure" target="#fig_10">9</ref>. We also find that our models push the asymptotic recall rate much closer to 100% (without loss in precision), reflecting their abilities to complete gradient-less gaps.</p><p>We observe that the benefit of continuity on the baseball player and horse dataset is much larger than that on the BSDS dataset. One reason may be that the baseball and horse datasets are harder (note the low precision rates for P b) which makes the role of continuity more important.</p><p>The remaining gap in performance between our model and the upper bound may best be bridged by detecting objects in the scene using the mid-level boundary map and then "cleaning up" the boundaries in a top-down fashion. In the case of general datasets like the BSDS, this will require recognizing thousands of object categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have described two stochastic models of curvilinear continuity which have a verifiably favorable impact on the problem of boundary detection. The local model of curvilinear continuity, though quite simple, yields a significant performance gain. The global model, by making long-range inference over local continuity constraints, is the most successful in utilizing mid-level information.</p><p>The key step in our approach to modeling continuity is moving from pixels to the piecewise linear approximations of contours and the constrained Delaunay triangulation. This provides a scale-invariant geometric representations of images which tends to complete gaps in the lowlevel edge map. Moving from 100,000 pixels to 1000 Delaunay edges is also important as it yields huge gains in both statistical and computational efficiency.</p><p>We have shown that the outputs of our algorithms are quantifiably better than a low-level edge detector on a wide variety of natural images. We feel strongly that continued progress in mid-level vision rests on being able to make quantitative comparisons between algorithms. Many of the latest exciting results in object recognition and stereo reconstruction could not have occurred without the firm grounding in quantitative evaluation. Perceptual organization should be held to the same high standards.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Finding potential completions: (a) an object may appear at any scale in the visual field (b) a piecewise linear curve approximates the boundaries regardless of scale. (c) Constrained Delaunay Triangulation connects the gaps and completes a scale-invariant representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Building a discrete graph. (a) we recursively split a line until the angle θ is below a threshold. (b) an illustration of the process: the input edge map, the linearization, and the Constrained Delaunay Triangulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Examples of the CDT triangulation. G-edges (gradient edges detected by P b) are in black and C-edges (completed by CDT) in green. Note how the CDT manages to complete gaps on the front legs of the elephant (highlighted on the inset at right). These gaps are commonly formed when an object contour passes in front of a background whose appearance (brightness/texture) is similar to that of the object.</figDesc><graphic coords="3,56.09,164.68,115.20,76.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>pb estimate pb averaged over cdt edges groundtruth on cdt edges</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: This Precision-Recall curve verifies that moving from pixels to the CDT completion doesn't give up any boundaries found by the local measurement. For comparison, we show the upper-bound performance given by the training data on the CDT edges. The upper bound curve has a precision near 1 even at high recall and achieves a greater asymptotic recall than the local boundary detector, indicating it is completing some gradientless gaps.</figDesc><graphic coords="3,183.24,68.75,99.30,198.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (a) A simple 2-edge model of local curvilinear continuity. each edge has an associated set of features. continuity is measured by the angle θ. (b) evidences of continuity come from both ends of edge e 0 . The new"probability of boundary" for e 0 is the product of the 2-edge model on both pairs (e 0 , e 1 ) and (e 0 , e 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Evaluating combinations of features with precision-recall curves and cross-entropy loss L on the set of baseball player images. P b is the most powerful single feature. The addition of continuity θ significantly improves the performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The factor graph representing our conditional random field model for global continuity. The CDT provides both the geometric and graphical structure for our model. Each edge in the CDT corresponds to a variable X e (represented by circles) which is 1 if pixels corresponding to edge e constitute a true boundary. Potential functions (squares) consist of a singleton potential for each edge encodes the underlying P b measurement and continuity/closure potentials at the vertices whose values are dependent on both the angles between incoming segments and the numbers of Cand G-edges entering a junction.</figDesc><graphic coords="5,110.64,71.98,115.20,137.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Pixel-based precision-recall evaluations comparing the local classifier (P b L ), global CRF (P b G ) and raw P b. Both techniques improve boundary detection on all three datasets and the overall ordering of the curves is generally preserved.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Example results on the three data sets. The two columns of edge maps show the local boundary detector P b output and the CRF model respectively. The algorithms outputs have been thresholded at a level which yields 2000 boundary pixels for the baseball/BSDS images and 1000 pixels for the smaller horse images.</figDesc><graphic coords="8,55.72,577.91,75.60,57.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>split into 15 training and 15 testing images, images of horses [4] split into 172 training and 172 test images, and the Berkeley Segmentation Dataset [1] (BSDS) which contains 200 training images and 100 test images of various natural scenes.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments.This research was partially supported by ONR grant N00014-01-1-0890 (MURI).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Berkeley segmentation dataset</title>
		<ptr target="http://www.cs.berkeley.edu/projects/vision/bsds" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contour fragment grouping and shared, simple occluders</title>
		<author>
			<persName><forename type="first">J</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Matching shapes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="454" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Class-specific, top-down segmentation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="109" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical chamfer matching: A parametric edge matching algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Borgefors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="849" to="865" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ecological statistics of of gestalt laws for the perceptual organization of contours</title>
		<author>
			<persName><forename type="first">J</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="324" to="353" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computing contour closures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="399" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Edge co-occurrence in natural images predicts contour grouping performance</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Super</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Gallogly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="711" to="724" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning: data mining, inference and prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiscale conditional random fields for image labelling</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carreira-Perpinan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="695" to="702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Comparing images using the Hausdorff distance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Klanderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rucklidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="850" to="863" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Discriminative random fields: A discriminative framework for contextual interaction in classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1150" to="1159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th International Conf. on Machine Learning</title>
		<meeting>18th International Conf. on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Segmentation of multiple salient closed contours from real images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mahamud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thornber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="444" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to detect natural image boundaries using brightness and texture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Local boundary detection in natural images: Matching human and machine performance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Visual Perception</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Perception, 32 supp, p. 55</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recovering human body configurations: Combining segmentation and recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="326" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Elastica and computer vision</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algebraic Geometry and Its Applications</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="491" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Vision Science: Photons to Phenomenology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Trace inference, curvature consistency, and curve detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Parent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="823" to="839" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A probabilistic multi-scale model for contour completion based on image statistics</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="312" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Structural saliency: the detection of globally salient structures using a locally connected network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="321" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning and inferring image segmentations with the gbp typical cut algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shental</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1243" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Triangle: Engineering a 2d quality mesh generator and delaunay triangulator</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shewchuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Workshop on Applied Computational Geometry</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image parsing: segmentation, detection, and recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Correctness of local probability propagation in graphical models with loops</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stochastic completion fields: a neural model of illusory contour shape and salience</title>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="408" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A comparison of measures for detecting natural shapes in cluttered backgrounds</title>
		<author>
			<persName><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thornber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l. Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="81" to="96" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Two-level image segmentation based on region and edge integration</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DICTA</title>
		<meeting>DICTA</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="957" to="966" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
