<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Low-Rank Preserving Projection Via Graph Regularized Reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jie</forename><surname>Wen</surname></persName>
							<email>wenjie@hrbeu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Na</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaozhao</forename><surname>Fang</surname></persName>
							<idno type="ORCID">0000-0001-8440-1765</idno>
						</author>
						<author>
							<persName><forename type="first">Lunke</forename><surname>Fei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shanhua</forename><surname>Zhan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">N</forename><surname>Wen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">X</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">L</forename><surname>Fang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Fei</surname></persName>
						</author>
						<author>
							<persName><surname>Zhan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Bio-Computing Research Center</orgName>
								<orgName type="department" key="dep2">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>518055</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Low-Rank Preserving Projection Via Graph Regularized Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5A2953297457C972C25F96A866BB2A1</idno>
					<idno type="DOI">10.1109/TCYB.2018.2799862</idno>
					<note type="submission">received November 14, 2017; accepted January 26, 2018.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Feature extraction</term>
					<term>feature selection</term>
					<term>graph regularization</term>
					<term>low-rank representation (LRR)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Preserving global and local structures during projection learning is very important for feature extraction. Although various methods have been proposed for this goal, they commonly introduce an extra graph regularization term and the corresponding regularization parameter that needs to be tuned. However, tuning the parameter manually not only is timeconsuming, but also is difficult to find the optimal value to obtain a satisfactory performance. This greatly limits their applications. Besides, projections learned by many methods do not have good interpretability and their performances are commonly sensitive to the value of the selected feature dimension. To solve the above problems, a novel method named low-rank preserving projection via graph regularized reconstruction (LRPP_GRR) is proposed. In particular, LRPP_GRR imposes the graph constraint on the reconstruction error of data instead of introducing the extra regularization term to capture the local structure of data, which can greatly reduce the complexity of the model. Meanwhile, a low-rank reconstruction term is exploited to preserve the global structure of data. To improve the interpretability of the learned projection, a sparse term with l 2,1 norm is imposed on the projection. Furthermore, we introduce an orthogonal reconstruction constraint to make the learned projection hold main energy of data, which enables LRPP_GRR to be more flexible in the selection of feature dimension. Extensive experimental results show the proposed method can obtain competitive performance with other state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>is used or not, i.e., unsupervised, supervised, and semisupervised feature extractions <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b6">[7]</ref>. Due to the convenience in acquiring the unlabeled data, unsupervised feature extraction has been received a great deal of attention in the past decades. In this branch, the representative works include principle component analysis (PCA) <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, locality preserving projections (LPPs) <ref type="bibr" target="#b9">[10]</ref>, neighborhood preserving embedding (NPE) <ref type="bibr" target="#b10">[11]</ref>, sparsity preserving projections (SPPs) <ref type="bibr" target="#b11">[12]</ref>, etc. PCA seeks the projection directions of maximum variance so that the produced low-dimensional representation can best preserve the main information of data. LPP, NPE, and SPP aim to achieve a low-dimensional representation that preserves the local relationships among data points. PCA, LPP, NPE, and SPP can also be viewed as the graph-based feature extraction methods since they can be unified into a common graph embedding framework <ref type="bibr" target="#b12">[13]</ref>.</p><p>In recent years, the low-rank-based feature extraction method has received a lot of attention owning to its robustness to noise and good performance in uncovering the intrinsic global structure of data <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b18">[19]</ref>. However, it is a pity that the original low-rank-based methods such as robust PCA (RPCA) <ref type="bibr" target="#b19">[20]</ref> and low-rank representation (LRR) <ref type="bibr" target="#b20">[21]</ref> cannot deal with new samples which are not involved in the training stage. To address this issue, Bao et al. <ref type="bibr" target="#b21">[22]</ref> proposed an inductive RPCA method, which owns both advantages of PCA and RPCA by learning a low-rank projection. Latent LRR (LatLRR) takes the hidden data into account and learns a low-rank projection to extract salient features for unsupervised classification <ref type="bibr" target="#b22">[23]</ref>. Double LRR (DLRR) is also proposed for projection learning, in which the principle component recovery and salient feature extraction terms of LatLRR are integrated into a term <ref type="bibr" target="#b16">[17]</ref>. Although the above LRR-based methods have shown their robustness in feature extraction, they lose the ability of dimensionality reduction since the obtained projection has the same dimension with the original data. To tackle this problem, similar to the strategy of SPP, low-rank preserving embedding (LRPE) first learns an LRR-graph from the data and then utilizes it to achieve the projection <ref type="bibr" target="#b23">[24]</ref>. Furthermore, Wong et al. <ref type="bibr" target="#b24">[25]</ref> proposed a joint low-rank embedded projection (LREP) learning model, in which the LRR-graph learning and projection learning are integrated into a joint optimization model.</p><p>In fact, the above unsupervised feature extraction methods have a common point, i.e., they all focus on exploiting the intrinsic relationships of data for projection learning. However, many issues still exist in the above methods. First, the above methods only take into account the local or global 2168-2267 c 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.</p><p>See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>geometric relationships of data. For example, NPE, LPP, and SPP only exploit the local geometric relationships of the nearest neighbor samples <ref type="bibr" target="#b23">[24]</ref>. While the above LRR-based feature extraction methods only preserve the global structure of data.</p><p>Global and local structures both reveal the relationships of data and are useful to learn a more compact and discriminative representation for image classification. Therefore only preserving a kind of structure usually cannot obtain the consistent good performance for different datasets. Although many methods try to exploit both two structures simultaneously for projection learning, they at least introduce an extra regularization term and the corresponding regularization parameter needs to be tuned <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b29">[30]</ref>. For example, Lu et al. <ref type="bibr" target="#b25">[26]</ref> introduced a local geometric constraint term, i.e., a nearest neighbor graph regularization term, to the LRR such that the nearest neighbors have similar representations. In <ref type="bibr" target="#b14">[15]</ref>, both sparse constraint and graph regularization are integrated into the LRR to capture the local structure of data. Yin et al. <ref type="bibr" target="#b26">[27]</ref> introduced two graph regularization terms to constrain the representation matrix and projection to preserve local geometric structures of samples and features, respectively. This strategy seems reasonable and has potential to achieve a better performance, but it also arouses the following two issues. 1) Tuning the regularization parameter to find a suitable value for different tasks is time-consuming.</p><p>2) It is unrealistic to find the optimal penalty parameter that can well balance the role of the global and local structures through the manual way. These greatly limit their applications. Second, many feature extraction methods such as SPP, NPE, LPP, etc., are sensitive to the selection of feature dimension. What is more, how to select the suitable dimension adaptively for different tasks is still an open problem. Third, the above feature extraction methods do not have good interpretability since the extracted features are the simply linear combinations of all the original features, such as PCA, LPP, SPP, LRPE, LREP, etc. These methods treat all features equally through the transformation, and thus it is difficult to interpret which features are the most important for the given task. In other words, all original highdimensional features include outliers and noises are regarded as useful features in these methods. This is contradictory with the purpose of the feature extraction which aims to extract useful and discriminative features.</p><p>To solve the problems mentioned above and learn the optimal projection for feature extraction, in this paper we propose a method named low-rank preserving projection via graph regularized reconstruction (LRPP_GRR). Unlike SPP, LPP, NPE, and LRPE which use a two-step approach to learn the projection, LRPP_GRR integrates the graph learning and projection learning into a joint optimization framework which guarantees the global optimum. In particular, LRPP_GRR is based on the following motivations. First, we observe that for some projection learning methods, especially those use a two-step approach to calculate the projection, the discriminability of each derived projection direction is fixed. In this case, selecting a proper number of feature dimensions seems to be very crucial since too less dimensions lead to the loss of discriminability while too much dimensions not only extract many useless and harmful information but also increase the requirement of the storage memory and computational cost. A reasonable approach to address this issue is to adaptively learn a projection that can preserve the structures and hold the main discriminative information of data simultaneously. Inspired by this motivation, LRPP_GRR introduces a data reconstruction term with an orthogonal constraint. In this way, the sensitive problem of feature dimensional selection can be alleviated to some extent. Second, from the sparse representation-based classification <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref> and LRR, we observe that the original samples and the linear reconstructed samples have the same nearest neighbor relationships with those of the original samples. Based on this observation, we directly impose a nearest neighbor graph constraint on the low-rank-based data reconstruction errors to preserve this local structure. Compared with other methods which exploit both global and local structures by introducing at least one extra regularization term and tuned parameter, LRPP_GRR only uses a term to preserve the global and local structures of data simultaneously, which greatly reduces the complexity. To improve the interpretability of projection, the l 2,1 norm is introduced to constrain the projection matrix owning to its good row-sparsity property. In this way, LRPP_GRR can select the most important features from the original data for feature extraction. Extensive experimental results demonstrate the effectiveness of proposed method.</p><p>The proposed method can be also viewed as a method that finely integrates data reconstruction, LRR and graph regularization into a novel framework for feature extraction. In brief, LRPP_GRR has the following contributions.</p><p>1) LRPP_GRR captures the global and local structures of data simultaneously during projection learning so that the intrinsic structure of data can be preserved. 2) LRPP_GRR holds the main energy of data by taking into account the data reconstruction, which makes it more flexible in the selection of the feature dimension. 3) By imposing a row-sparsity, i.e., l 2,1 norm constraint on the projection matrix, LRPP_GRR not only can select the most useful features adaptively from the redundant data for feature extraction, but also has good interpretability. 4) LRPP_GRR does not introduce any extra terms to preserve the local geometric structure, which reduces the complexity greatly and guarantees the efficiency. The rest of this paper is organized as follows. Section II introduces some related works. Section III presents the proposed method and its solution. Section IV mainly analyzes the proposed method. Experiments on several real datasets are conducted in Section V. Section VI offers the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Since the proposed method uses the constraint of LRR and neighbor graph regularization for projection learning, in this section we give a brief introduction to these two methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Low-Rank Representation-Based Feature Extraction</head><p>Based on the hypothesis that data is approximately drawn from a union of multiple independent subspaces, LRR seeks to jointly learn a lowest-rank representation that can uncover the intrinsic subspaces of data accurately <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b32">[33]</ref>. The general model of LRR is formulated as follows:</p><formula xml:id="formula_0">min Z rank(Z) s.t. X = AZ (1)</formula><p>where X = [x 1 , x 2 , . . . , x n ] ∈ R m×n denotes a data matrix and each column</p><formula xml:id="formula_1">x i (i ∈ [1, n]) is a sample. A = [a 1 , a 2 , . . . , a l ] ∈</formula><p>R m×l is the given dictionary or basis. rank(Z) is the rank of matrix Z. Owing to the discreteness of the rank constraint, it is difficult to obtain the analytical low-rank solution to problem (1). To address this issue, some researchers transform (1) into the following convex optimization problem <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_2">min Z Z * s.t. X = AZ (2)</formula><p>where Z * is the nuclear norm of matrix Z and is calculated as the sum of all singular values of matrix Z.</p><p>In most cases, we usually choose the data itself as the dictionary, then (2) can be rewritten as follows:</p><formula xml:id="formula_3">min Z Z * s.t. X = XZ. (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>In this case, each element z ij of representation matrix Z reveals the "similarity" between samples x i and x j . Problem (3) can be solved fast by the linearized alternating direction method with adaptive penalty <ref type="bibr" target="#b33">[34]</ref> and always has feasible solutions whether there are sufficient samples or not <ref type="bibr" target="#b20">[21]</ref>. Since model (3) does not learn a projection matrix for feature extraction and thus LRR cannot deal with new samples, Liu and Yan <ref type="bibr" target="#b22">[23]</ref> further proposed a method named LatLRR to overcome this problem. The objective function of LatLRR is as follows: min</p><formula xml:id="formula_5">Z,L Z * + L * s.t. X = XZ + LX (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where low-rank matrix L ∈ R m×m is used as the projection to deal with new samples. Extensive experiments show that L is able to extract the salient features for image classification <ref type="bibr" target="#b22">[23]</ref>. However, the extracted features, i.e., LX, cannot preserve the global representation structure and main energy of data. To learn a more robust projection, Yin et al. <ref type="bibr" target="#b16">[17]</ref> proposed the following LRR-based feature extraction model: min</p><formula xml:id="formula_7">Z,L Z * + L * s.t. X = LXZ. (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>In this case, the learned projection matrix L is able to hold the main information and capture the global structure of the original data simultaneously. In this paper, we refer to the method proposed by Yin et al. <ref type="bibr" target="#b16">[17]</ref> as DLRR for further analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Neighbor Graph Regularization-Based Manifold Learning</head><p>Neighbor graph is widely utilized in pattern recognition and computer vision owing to its success in revealing the geometric structure of data <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. For a data matrix X = [x 1 , x 2 , . . . , x n ] ∈ R m×n with n samples, neighbor graph regularization-based manifold learning method first constructs a nearest neighbor graph W to represent the local relationship of samples and then performs projection learning by solving the following optimization problem: min P T XX T P=I i,j P T x i -P T x j 2 2 w ij <ref type="bibr" target="#b5">(6)</ref> where P is the projection matrix to be learned. Specially, each element w ij of graph W can be simply defined as follows:</p><formula xml:id="formula_9">w ij = 1, if x i ∈ N k x j or x j ∈ N k (x i ) 0, otherwise<label>(7)</label></formula><p>where N k (x j ) denotes a set of k nearest neighbor samples of sample x j . w ij = 1 means that sample x i is the nearest neighbor of sample x j in the data distribution and also indicates that these two samples are similar and have larger probability to be a class. Thus, the graph W captures the essential local information of data and can be used as a guide to learn an LPP <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>In this section, we present a method named LRPP_GRR to learn the optimal projection for unsupervised classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model of LRPP_GRR</head><p>In LatLRR, only the salient features are extracted for classification while ignoring the principle component information <ref type="bibr" target="#b22">[23]</ref>. Principle component information also contains discriminability and thus is also very useful to the classification tasks. Compared with LatLRR, projection learned by DLRR not only extracts principle component information, but also preserves the global representation structure of data simultaneously <ref type="bibr" target="#b16">[17]</ref>. Based on DLRR, we propose a method to learn a more flexible projection for feature extraction. Instead of using a low-rank matrix L to extract features, LRPP_GRR introduces two matrices to approximate L as follows:</p><formula xml:id="formula_10">min P,Q,Z Z * s.t. X = PQ T XZ (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>where P ∈ R m×d , Q ∈ R m×d , d is the selected number of the projected dimension (d &lt; m). X ∈ R m×n denotes the original data. m and n are the number of original feature dimension and samples, respectively. Obviously, rank(P)</p><formula xml:id="formula_12">≤ d &lt; m, rank(Q) ≤ d &lt; m, rank(PQ T ) ≤ d.</formula><p>This indicates that matrix PQ T is also a low-rank matrix similar to matrix L in model ( <ref type="formula" target="#formula_7">5</ref>), while model ( <ref type="formula" target="#formula_10">8</ref>) is more flexible to select the rank of d. To avoid the trivial solution of ( <ref type="formula" target="#formula_10">8</ref>), motivated by the sparse PCA (SPCA) <ref type="bibr" target="#b36">[37]</ref>, we impose an orthogonal constraint on matrix P as follows:</p><p>min</p><formula xml:id="formula_13">P,Q,Z Z * s.t. X = PQ T XZ, P T P = I. (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>In this case, matrix P can be viewed as the data reconstruction matrix, which enables the learned projection matrix Q to hold the main energy of data. Compared with DLRR which uses matrix L ∈ R m×m to extract features, LRPP_GRR treats matrix Q ∈ R m×d as the projection. It is noted that projection L learned by DLRR does not have the ability of dimensionality reduction since the projected features have the same dimension with the original data. Thus we say projection Q learned from model ( <ref type="formula" target="#formula_13">9</ref>) not only has the advantages of DLRR, but also is more flexible than DLRR in the selection of the feature dimension.</p><p>Considering that in the real world applications, data not only contains large dimensions, but also has many redundant features which are harmful to the classification tasks. Thus it is desirable to select the most useful features from the redundant data to perform feature extraction. Due to the good row-sparsity property of l 2,1 norm <ref type="bibr" target="#b37">[38]</ref>, we impose it on the projection matrix as follows:</p><formula xml:id="formula_15">min P,Q,Z λ 1 Z * + λ 2 Q 2,1 s.t. X = PQ T XZ, P T P = I (10)</formula><p>where λ 1 and λ 2 are the regularization parameters to balance the importance of the corresponding terms. The l 2,1 norm is defined as Q 2,1 = i q i 2 , q i denotes the ith row vector of matrix Q. By imposing the constraint of l 2,1 norm, the learned projection matrix Q is able to select the most useful features for feature extraction and also has good interpretability.</p><p>As introduced in the previous section, LRR can capture the global representation structure of data that drawn from a union of linear subspaces. However, it ignores the local relationships of data and thus cannot obtain a compact representation of data in the low dimensional subspace. In the real world applications, data such as face images are usually sampled from a nonlinear manifold <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b38">[39]</ref>. In this case, learning a projection that can preserve the local manifold structure of data is also necessary in feature extraction. In this paper, we propose a novel strategy for this goal based on the following lemma.</p><p>Lemma 1: Suppose sample x 1 ∈ R m×1 is the nearest neighbor of sample x 2 ∈ R m×1 , and both two samples can be linearly represented by a given basis or dictionary D ∈ R m×n as x 1 = Dα 1 and x 2 = Dα 2 , respectively, where α 1 and α 2 are the representation coefficient vectors of the two samples. Then sample x 1 (x 2 ) and the reconstructed sample Dα 2 (Dα 1 ) have the same nearest neighbor relationship with the two original samples.</p><p>Proof: Given x 1 = Dα 1 and x 2 = Dα 2 , we have</p><formula xml:id="formula_16">x 1 -x 2 = x 1 -Dα 2 = Dα 1 -x 2 , so x 1 -x 2 2 2 = x 1 -Dα 2 2 2 = Dα 1 -x 2 2</formula><p>2 . This demonstrates that the Euclidean distance between the linear reconstructed sample and the original sample is the same with that of the corresponding two original samples. Therefore, if sample x 1 is the nearest neighbor of sample x 2 , then sample Dα 1 (Dα 2 ) is obviously the nearest neighbor of sample x 2 (x 1 ), with respect to the original samples and the linear reconstructed samples have the same nearest neighbor relationships with those of the original samples. Then we complete the proof.</p><p>Based on Lemma 1, we impose a graph constraint on the reconstruction error between the original sample and the reconstructed sample to preserve the local geometric structure as follows:</p><formula xml:id="formula_17">min P,Q,Z n i=1 n j=1 x i -PQ T Xz j 2 2 w ij +λ 1 Z * + λ 2 Q 2,1 s.t. P T P = I (<label>11</label></formula><formula xml:id="formula_18">)</formula><p>where w ij denotes the (i, j)th element of graph W (W is the nearest neighbor graph which has introduced in Section II-B).</p><p>z j is the jth column vector of LRR matrix Z. PQ T Xz j can be viewed as the reconstructed sample of original sample x j . The neighbor graph regularization term is used to preserve the nearest neighbor relationships among the original samples and the reconstructed samples. Compared with the traditional graph regularization methods <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b29">[30]</ref>, LRPP_GRR does not impose any extra regularization terms to exploit the local structure of data for projection learning, which greatly reduces the complexity. LRPP_GRR has many good properties and we will analyze it in detail in the subsequent section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Solution to LRPP_GRR</head><p>In this section, we use the alternating direction method of multipliers (ADMMs) <ref type="bibr" target="#b39">[40]</ref> to solve the optimization problem <ref type="bibr" target="#b10">(11)</ref>. To make objective function <ref type="bibr" target="#b10">(11)</ref> separable, we first convert problem <ref type="bibr" target="#b10">(11)</ref> into the following formula by imposing two auxiliary variables Y, U:</p><formula xml:id="formula_19">min P,Q,Z,U,Y n i=1 n j=1 x i -Py j 2 2 w i,j + λ 1 U * + λ 2 Q 2,1 s.t. P T P = I, Q T XZ = Y, Z = U. (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>Specially, the first term of ( <ref type="formula" target="#formula_19">12</ref>) can be further simplified as </p><formula xml:id="formula_21">Tr XDX T -2XWY T P T + Tr YDY T + λ 1 U * + λ 2 Q 2,1 s.t. P T P = I, Q T XZ = Y, Z = U. (<label>14</label></formula><formula xml:id="formula_22">)</formula><p>Equation ( <ref type="formula" target="#formula_21">14</ref>) can be further transformed into the following augmented Lagrangian function:</p><formula xml:id="formula_23">L(P, Q, Z, U, Y, C 1 , C 2 ) = Tr XDX T -2XWY T P T + Tr YDY T + λ 1 U * + λ 2 Q 2,1 + μ 2 Q T XZ -Y 2 F + Z -U 2 F + C 1 , Q T XZ -Y + C 2 , Z -U (<label>15</label></formula><formula xml:id="formula_24">)</formula><p>where A, B = Tr(A T B). C 1 and C 2 are the Lagrangian multipliers. μ is a positive penalty parameter. • F is the matrix Frobenious norm. By alternately solving <ref type="bibr" target="#b14">(15)</ref>, we can obtain the solutions of all variables P, Q, Z, U, Y, C 1 , and C 2 .</p><p>The detail solution steps are as follows.</p><p>Step 1 (Update Q): Fix P, Z, U, and Y and update Q by minimizing the following problem:</p><formula xml:id="formula_25">L(Q) = λ 2 Q 2,1 + μ 2 Q T XZ -Y + C 1 μ 2 F . (<label>16</label></formula><formula xml:id="formula_26">) Define H = Y -(C 1 /μ), then Q can be calculated by the derivative of L(Q) with respect to Q ∂L(Q) ∂Q = λ 2 GQ + μ XZZ T X T Q -XZH T (<label>17</label></formula><formula xml:id="formula_27">)</formula><p>where</p><formula xml:id="formula_28">G = diag(1/ q 1,• 2 , 1/ q 2,• 2 , . . . , 1/ q n,• 2 ), q i,• is the ith row vector of Q. Let ∂L(Q)/∂Q = 0, then Q is obtained Q = μXZZ T X T + λ 2 G -1 μXZH T . (<label>18</label></formula><formula xml:id="formula_29">)</formula><p>Step 2 (Update Z): Fix variables P, Q, U, and Y, we can obtain Z by minimizing the following problem:</p><formula xml:id="formula_30">L(Z) = Q T XZ -Y + C 1 μ 2 F + Z -U + C 2 μ 2 F . (<label>19</label></formula><formula xml:id="formula_31">)</formula><p>Define</p><formula xml:id="formula_32">M 1 = Y -(C 1 /μ), M 2 = U -(C 2 /μ), then Z can be calculated by the derivative of (19) with respect to Z ∂L(Z) ∂Z = 2X T Q Q T XZ -M 1 + 2(Z -M 2 ). (<label>20</label></formula><formula xml:id="formula_33">)</formula><p>Let ∂L(Z)/∂Z = 0, then Z is updated by the following formula:</p><formula xml:id="formula_34">Z = X T QQ T X + I -1 X T QM 1 + M 2 . (<label>21</label></formula><formula xml:id="formula_35">)</formula><p>Step 3 (Update U): Fix variables P, Q, Z, and Y and update U by solving the following minimization problem:</p><formula xml:id="formula_36">min U λ 1 U * + μ 2 Z -U + C 2 μ 2 F . (<label>22</label></formula><formula xml:id="formula_37">)</formula><p>Then U is obtained by using the singular value thresholding (SVT) shrinkage operator <ref type="bibr" target="#b22">[23]</ref> as follows:</p><formula xml:id="formula_38">U = λ 1/ μ Z + C 2 μ (<label>23</label></formula><formula xml:id="formula_39">)</formula><p>where is the SVT shrinkage operator.</p><p>Step 4 (Update Y): Fix variables P, Q, Z, and U, Y can be obtained by minimizing the following formula:</p><formula xml:id="formula_40">L(Y) = Tr XDX T -2XWY T P T + Tr YDY T + μ 2 Q T XZ -Y + C 1 μ 2 F . (<label>24</label></formula><formula xml:id="formula_41">)</formula><p>Then we calculate Y by the derivative of (24</p><formula xml:id="formula_42">) with respect to Y ∂L(Y) ∂Y = -2P T XW + 2YD + μ(Y -M 3 ) (<label>25</label></formula><formula xml:id="formula_43">)</formula><p>where</p><formula xml:id="formula_44">M 3 = Q T XZ + (C 1 /μ). Let ∂L(Y)/∂Y = 0, we can obtain Y Y = μM 3 + 2P T XW (2D + μI) -1 . (<label>26</label></formula><formula xml:id="formula_45">)</formula><p>Step 5 (Update P): Fix Q, Z, U, and Y and update P by solving the following minimization problem: min</p><formula xml:id="formula_46">P T P=I Tr XDX T -2XWY T P T . (<label>27</label></formula><formula xml:id="formula_47">)</formula><p>Algorithm 1 LRPP_GRR [Solving <ref type="bibr" target="#b10">(11)</ref>]   <ref type="formula">29</ref>), <ref type="bibr" target="#b29">(30)</ref>, and (31), respectively. end while Output: P, Q, Z Minimizing ( <ref type="formula" target="#formula_46">27</ref>) is equivalent to the following maximization problem: max</p><formula xml:id="formula_48">Input: data matrix X,</formula><formula xml:id="formula_49">; Q = P, Z = W, U = Z, Y = Q T XZ, C 1 = C 2 = 0, μ = 0.1, ρ = 1.</formula><formula xml:id="formula_50">P T P=I Tr XWY T P T . (<label>28</label></formula><formula xml:id="formula_51">)</formula><p>Problem ( <ref type="formula" target="#formula_50">28</ref>) is an orthogonal Procrustes problem and can be simply solved. If SVD(XWY T ) = USV T , then P is obtained as P = UV T <ref type="bibr" target="#b36">[37]</ref>, where SVD is the singular value decomposition (SVD) operation.</p><p>Step 6 (Update C 1 , C 2 , μ): Lagrangian multipliers C 1 and C 2 , and penalty parameter μ are updated by using the following formulas:</p><formula xml:id="formula_52">C 1 = C 1 + μ(Q T XZ -Y) (29) C 2 = C 2 + μ(Z -U) (30) μ = min(ρμ, μ max ) (<label>31</label></formula><formula xml:id="formula_53">)</formula><p>where ρ and μ max are constants. The detail procedures of the proposed algorithm are summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. ANALYSIS OF LRPP_GRR</head><p>In the previous section, we have presented the proposed method and its solution. In this section, we mainly analyze the proposed method from the aspects of computational complexity, convergence, and rationale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Computational Complexity</head><p>For LRPP_GRR listed in Algorithm 1, the major computational costs are the inverse operation and the SVD of matrix. It should be noted that we do not consider the computational costs of the matrix multiplication and addition. For a m × m matrix, the computational complexity of the inverse operation is O(m 3 ). For a m×n matrix, the computational complexity of the conventional SVD operation is O(mn 2 ). It should be noted that in step 4, the inverse operation of (2D + μI) -1 can be directly obtained by calculating the reciprocal of its diagonal elements since it is a diagonal matrix. Thus the computational cost of step 4 can be ignored. Therefore, we just need to consider the remaining four steps. The computational complexities of the remaining four steps in Algorithm 1 are about O(m 3 ), O(n 3 ), O(n 3 ), and O(md 2 ), respectively. d denotes the number of the projected dimension. Compared with the other steps, the computational cost of step 5 can be ignored since dimension d is generally much less than the number of samples and the number of features, i.e., d n, d m. Hence, the main computational complexity of the proposed method is about O(τ (m 3 + 2n 3 )), where τ is the iteration number.</p><p>The proposed method has relatively high computational complexity, which may be inefficiency in largescale databases. To solve this problem, we provide three effective schemes to accelerate the proposed method during optimization. For the major computational cost, i.e., inverse operation, which totally has the computational complexity of O(m 3 + n 3 ), we can calculate it by the Sherman-Woodbury-Morrison formula <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> as follows:</p><formula xml:id="formula_54">(P + ST) -1 = P -1 -P -1 S I + TP -1 S -1 TP -1 . (32)</formula><p>According to <ref type="bibr" target="#b31">(32)</ref>, if we define B = X T Q ∈ R n×d , then the inverse operation in (21) of step 2 can be calculated as follows:</p><formula xml:id="formula_55">I + BB T -1 = I -B I + B T B -1 B T . (<label>33</label></formula><formula xml:id="formula_56">)</formula><p>Obviously, by using <ref type="bibr" target="#b32">(33)</ref> to calculate the inverse operation, the computational cost of the step 2 can be greatly decreased from O(n 3 ) to O(d 3 ). For large-scale databases, dimension d of projection is generally much less than the number of samples n, thus the computational cost of step 2 can be ignored in comparison with the other steps.</p><p>Another effective scheme for inverse operation is to compute it the by graphics processing unit (GPU) device rather than central processing unit (CPU) device. On the platform of Windows 10 system and MATLAB 2015a, for a 10 000 × 10 000 matrix with random values, it takes about 28 s to calculate the inverse operation on an Intel i7-CPU while it only takes about 2 s on a GTX-980 GPU. So by using GPU, the training time of the proposed method can be further decreased.</p><p>Then we provide an effective scheme to decrease the other major computational cost, i.e., SVD, in step 3. For the proposed method, it is obvious to see that when other variables are fixed, the subproblem to variable Z can be simply expressed as: min Z λ 1 Z * s.t. Q T XZ = Y. According to <ref type="bibr" target="#b20">[21,</ref><ref type="bibr">Th. 4.3]</ref>, the optimal Z * always lies within the subspace spanned by the rows of Q T X, i.e., Z * ∈ span(Q T X). Then the subproblem to variable Z can be transformed into a simpler problem as follows <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_57">min Z λ 1 Z * s.t. A Z = Y (<label>34</label></formula><formula xml:id="formula_58">)</formula><p>where A = Q T XG * , G * is the orthonormal basis of matrix X T Q. When the optimal Z is obtained by <ref type="bibr" target="#b33">(34)</ref>, then the optimal Z can also be obtained by Z = G * Z. Thus the optimal Z can be indirectly obtained by optimizing problem <ref type="bibr" target="#b33">(34)</ref>. To obtain Z, similar to the optimization scheme presented in Section III-B, we also introduce an auxiliary variable Ũ as follows:</p><p>min</p><formula xml:id="formula_59">Z, Ũ λ 1 Ũ * s.t. A Z = Y, Z = Ũ.<label>(35)</label></formula><p>It is obvious to see that problem <ref type="bibr" target="#b34">(35)</ref> has the same optimization style with the subproblems to variables Z, U.</p><p>And we can replace the subproblems of variables Z and U (steps 2 and 3) with problem <ref type="bibr" target="#b34">(35)</ref> to indirectly calculate variable Z for large-scale databases. Compared with the computational cost of calculating variable U in problem <ref type="bibr" target="#b11">(12)</ref>, calculating variable Ũ has much lower computational cost, which costs at most O(dn 2 ). For large-scale databases, the selected dimension d of projection is generally much less than the number of samples n. Hence, the computational cost of step 3 can be significantly decreased from O(n 3 ) to O(n 2 ) by optimizing problem <ref type="bibr" target="#b33">(34)</ref>. In summary, by using the above accelerate schemes, the computational cost can be greatly decreased such that the efficiency can be greatly improved, which guarantees that the proposed method can be applied to the large-scale database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Convergence Analysis</head><p>Although LRPP_GRR is a nonconvex optimization problem, we can obtain its local optimal solution by using the ADMMstyle algorithm. In <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b42">[43]</ref>, the strong convergence property of ADMM with two blocks has been proved. However, it is difficult to prove the strong convergence of the proposed method since it has five blocks, i.e., Q, Z, U, Y, and P. Fortunately, we can prove that the solution of the proposed method can reach a stationary point that meets the Karush-Kuhn-Tucher (KKT) conditions and thus a weak convergence property of the proposed method is guaranteed <ref type="bibr" target="#b43">[44]</ref>. Specially, we have the following theorem.</p><p>Theorem 1:</p><formula xml:id="formula_60">Let t = (Q t , Z t , U t , Y t , P t , C t 1 , C t 2 )</formula><p>be the solution of the proposed method in the tth iteration step. Assume sequence { t } ∞ t=1 is bounded and satisfies the condition of lim t→∞ ( t+1 -t ) = 0, then the accumulation point of { t } ∞ t=1 is a KKT point of problem <ref type="bibr" target="#b11">(12)</ref>. In addition, whenever { t } ∞ t=1 converges, it converges to a KKT point. Proof: Please see the detailed proof of Theorem 1 in the supplementary material.</p><p>Theorem 1 provides some assurances to the convergence attribute of the proposed method to some extent. In this section, we also use many experiments to verify the convergence property of the proposed method. Fig. <ref type="figure" target="#fig_1">1</ref> shows the relationship of the objective function value, classification accuracy and iterations. The objective function value shown in Fig. <ref type="figure" target="#fig_1">1</ref> is calculated by the formula of Obj = Tr(XDX T -2XWY T P T ) + Tr(YDY T ) + λ 1 Z * + λ 2 Q 2,1 . From Fig. <ref type="figure" target="#fig_1">1</ref>, we can see that with the iterations increase, the objective function value of the proposed method decreases fast and reaches a stable point after a few iterations, while the classification accuracy increases dramatically during the first small number of iterations and then reaches the stable high level for these four benchmark databases. For example, for the extended Yale B database, the proposed method reaches the stable point in terms of the classification accuracy within about 30 iterations. Both theoretical proof and experiments demonstrate that the proposed method can obtain the local optimum quickly and has good convergence property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Connections to Other Methods</head><p>In this section, we mainly show the advantages of the proposed method by analyzing the differences between the proposed method and some related works, such as SPCA <ref type="bibr" target="#b36">[37]</ref>, LatLRR <ref type="bibr" target="#b22">[23]</ref>, and DLRR <ref type="bibr" target="#b16">[17]</ref>. 1) Compared With SPCA <ref type="bibr" target="#b36">[37]</ref>: SPCA aims to learn a sparse projection that can identify important variables so as to improve the interpretability of features. The objective function of SPCA is as follows:</p><formula xml:id="formula_61">min A,B n i=1 x i -AB T x i 2 + λ k j=1 β j 2 + k j=1 λ 1,j β j 1 s.t. A T A = I. (<label>36</label></formula><formula xml:id="formula_62">)</formula><p>From the objective function of ( <ref type="formula" target="#formula_17">11</ref>), if we let the nearest neighbor graph be the identity matrix, i.e., W = I, then the problem <ref type="bibr" target="#b10">(11)</ref> degrades into the similar model as the problem <ref type="bibr" target="#b35">(36)</ref> to some extent. The main differences between the degraded model of LRPP_GRR and SPCA are as follows.</p><p>1) LRPP_GRR imposes a low-rank constraint to exploit the global structure of data for projection learning, while SPCA does not exploit any structure information of data. 2) LRPP_GRR introduces a row-sparsity norm to improve the interpretability while SPCA utilizes the lasso constraint. Owing to the use of lasso constraint, important degrees of features from the same category in different principle components of SPCA are also different. In this case, we still do not know which features are the most important features. Compared with SPCA, the proposed method utilizes the l 2,1 norm to constrain the projection matrix. l 2,1 norm has the row-sparsity property which is widely used for feature selection <ref type="bibr" target="#b37">[38]</ref>. Fig. <ref type="figure" target="#fig_2">2</ref> shows the projections learned by PCA, SPCA and LRPP_GRR. From Fig. <ref type="figure" target="#fig_2">2</ref>, it is obvious that the interpretability of the projection learned by LRPP_GRR is much better than those of SPCA and PCA. Besides, SPCA only focuses on preserving the principle energy of the original data while ignoring the preservation of the local structure. This may destroy the underlying structure of data during projection learning, which leads to a bad performance. Compared with SPCA, the proposed method preserves the intrinsic global and local geometric structures of data simultaneously by finely integrating the LRR constraint and neighbor graph constraint into the projection learning model, which enables the proposed method to obtain a better performance.</p><p>2) Compared With LatLRR <ref type="bibr" target="#b22">[23]</ref> and DLRR <ref type="bibr" target="#b16">[17]</ref>: As introduced in the previous section, LatLRR reconstructs data from column and row directions by using two LRR matrices. The second LRR matrix L is used to extract the salient features and deal with new samples. LatLRR divides the column recovery and row recovery into two independent terms. In this way, the extracted features only preserve the global reconstruction relation of features while failing to capture the intrinsic structure of data. Besides, LatLRR ignores the discriminability of the principle component, which may seriously degrade its classification performance. Compared with LatLRR, DLRR can preserve more energy of data by simultaneously recovering data from row and column spaces in a term, and thus it has potential to perform better than LatLRR. However, both projections learned from DLRR and LatLRR do not have good interpretability and do not have the ability to select the most important features from large scale redundant features as well. Compared with LatLRR and DLRR, the proposed method learns a more explanatory projection by constraining the projection with a row-sparsity norm, i.e., l 2,1 norm. Moreover, both LatLRR and DLRR all just take into account the global reconstruction characteristic of data while ignoring the local intrinsic structure. Compared with these two methods, the proposed method finely overcomes this problem by imposing a neighbor graph regularization term. In this way, projection learned by the proposed method can preserve the global and local intrinsic structures of data simultaneously so as to obtain a more compact and discriminative representation for classification.</p><p>From the above analyses, the proposed method has many differences compared with the previous methods and has many good properties. In summary, projection learned by the proposed method not only can preserve the global and local intrinsic structures of data simultaneously, but also has good interpretability and has the ability to select the most important features for feature extraction as well. Besides, projection learned by the proposed method can hold energy as much as possible owing to the data reconstruction constraint, which has potential to improve the flexibility in the selection of feature dimension. These meaningful factors enable the proposed method to obtain a better performance than other feature extraction methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS AND ANALYSIS</head><p>In this section, we conduct several experiments to further prove the effectiveness of the proposed method. In the experiments, several related unsupervised methods, include PCA <ref type="bibr" target="#b8">[9]</ref>, LPP <ref type="bibr" target="#b9">[10]</ref>, orthogonal LPP (OLPP) <ref type="bibr" target="#b44">[45]</ref>, NPE <ref type="bibr" target="#b10">[11]</ref>, SPP <ref type="bibr" target="#b11">[12]</ref>, SPCA <ref type="bibr" target="#b36">[37]</ref>, LatLRR <ref type="bibr" target="#b22">[23]</ref>, collaborative representation-based projections (CRPs) <ref type="bibr" target="#b45">[46]</ref>, LRPE <ref type="bibr" target="#b23">[24]</ref>, low-rank preserving projection (LRPP) <ref type="bibr" target="#b18">[19]</ref>, and LREP<ref type="foot" target="#foot_0">1</ref> are compared with LRPP_GRR. The above methods are evaluated on four benchmark databases, including an object image database and three face image databases, i.e., Columbia Object Image Library (COIL20) image database<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b46">[47]</ref>, AR face database<ref type="foot" target="#foot_2">3</ref>  <ref type="bibr" target="#b47">[48]</ref>, extended Yale B face database<ref type="foot" target="#foot_3">4</ref>  <ref type="bibr" target="#b48">[49]</ref>, and CMU PIE face database<ref type="foot" target="#foot_4">5</ref>  <ref type="bibr" target="#b49">[50]</ref>. For fairly comparing, we, respectively, perform these methods 20 times in a wide range of projected dimension and report their best mean classification accuracies (%). In each experiment procedure, we randomly select part of samples from each class as the training samples and treat the remaining samples as the test samples. For the above unsupervised projection learning methods, we choose the nearest neighbor classifier to obtain their final classification accuracies. All experiments are performed on the same software and hardware, i.e., MATLAB 2015a and Windows 10 system, Intel Core i7-4970 CPU, and 16-GB RAM. For the proposed method, the number of the nearest neighbor is set to 10 in all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameters Selection of LRPP_GRR</head><p>From the objective function <ref type="bibr" target="#b10">(11)</ref> of the proposed method, we can find that there are only two parameters, i.e., λ 1 and λ 2 need to be set in advance. In this section, we first use some figures to vividly show the classification accuracy with respect to these two parameters, and then present the strategy used in this paper for parameter selection. Fig. <ref type="figure" target="#fig_4">3</ref> shows the relationship of the classification accuracy and the two penalty parameters on four benchmark databases, in which the two parameters are selected from a candidate set {10 -5 , 10 -4 , 10 -3 , 10 -2 , 10 -1 , 1, 10 1 , 10 2 , 10 3 , 10 4 , 10 5 }.</p><p>From Fig. <ref type="figure" target="#fig_4">3</ref>, we can find that the best combinations of parameters λ 1 and λ 2 are 10 -2 and 10 -1 for the COIL20 database, 10 -3 and 10 -1 for the AR database, 10 -3 and 10 -2 for the extended Yale B database, and 10 -3 and 10 -2 for the CMU PIE database, respectively. From Fig. <ref type="figure" target="#fig_4">3</ref>, it is obvious to see that the classification accuracy curve is very smooth in some local areas and reaches a high level when these two penalty parameters are small and located in a feasible range. From the objective function <ref type="bibr" target="#b10">(11)</ref>, it is easy to find that parameter λ 1 constrains the low-rank matrix which is used to preserve the global representation structure of data, and parameter λ 2 constrains the degree of feature selection. These two parameters balance the importance of the corresponding terms and determine the performance of unsupervised classification.</p><p>As far as we know, there are no efficient strategies which can adaptively select these penalty parameters. How to choose the best suitable parameters for different tasks is still an open problem. In the experiments, we use the following strategy to find the suitable parameters for projection training. From Fig. <ref type="figure" target="#fig_4">3</ref>, it is obvious to see that the proposed method obtains a satisfactory performance when these two parameters have small values. Thus we first coarsely define a candidate parameter range {10 -5 , 10 -4 , 10 -3 , 10 -2 , 10 -1 , 1} for parameter selection. Then we select different combinations of values from the coarse candidate range as values of parameters to perform the proposed method. In this way, we can obtain a best combination of parameters in the coarse candidate range. After that, we further define a fine candidate range according to the best combination of parameters achieved from the coarse range. And then we perform the proposed method again to search the optimal combination of parameters. Finally, we perform the proposed method 20 times with the obtained optimal parameters and report the mean accuracy for comparing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments on the COIL20 Image Database</head><p>The COIL20 image database contains 20 objects and 1440 gray-scale images in total. Images of each object are collected at pose intervals of 5 • and thus there are 72 images per object. In the original COIL20 database, images were resized to 128 × 128 and then stretched to the same intensity level. In the experiments, we further resized each image into a 32 × 32 matrix by the down-sampling algorithm in advance. Some typical images of this database are shown in Fig. <ref type="figure" target="#fig_5">4</ref>. Then each image is first transformed into the column vector with 1024-D by simply stacking the columns of the corresponding image matrix. To improve the computational efficiency, we further perform PCA on all samples (the whole database) and reduce their dimensions from 1024 to 175 by preserving 98% energy for fair comparison <ref type="bibr" target="#b50">[51]</ref>. Preserving 98% energy means that only the first d vectors corresponding to the d largest eigenvalues which satisfy d i=1 λ i / m i=1 λ i = 0.98 are selected to form the projection of PCA for dimensionality reduction, where λ i denotes the ith largest eigenvalue of the covariance matrix of the original data. For all compared methods, we then randomly select 10, 15, 20, and 25 samples from each object as training samples and treat the remaining samples as test samples.    Table <ref type="table" target="#tab_2">I</ref> shows the mean classification accuracies (%) of different methods on the COIL20 image database. It is obvious to see that the proposed method obtains competitive performance with PCA and performs much better than those methods which ignore the energy preserving, i.e., LPP, NPE, SPP, CRP, and LRPE. This demonstrates that holding the main energy of data is helpful to obtain a higher performance. method illustrates that the proposed method is more flexible in the selection of feature dimension. This demonstrates the effectiveness of energy preserving in projection learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experiments on the AR Face Database</head><p>The original AR face database contains 126 subjects and more than 4000 color face images. Images of each class have different facial expressions, illuminations, and occlusions (sun glasses and scarf). Fig. <ref type="figure">6</ref> shows some images of the AR face database. In the experiments, we chose a subset that contains 3120 images of 120 subjects to evaluate the above methods. Each color image was transformed into the gray image and then resized to the size of 40 × 50 in advance. Similar to the previous section, we also use PCA to reduce the dimension of all samples from 2000 to 479 by preserving 98% energy for computational efficiency. For each class, we randomly select 4, 6, 8, and 12 samples as training samples and let the remaining samples be test samples.</p><p>Table <ref type="table" target="#tab_3">II</ref> lists the classification accuracies (%) of different methods on the AR face database. From this table, we can find that the proposed method achieves consistent good performance in comparison with other methods. Especially when a few samples such as four samples of each object are chose for training, the accuracy of the proposed method is about 5% and 30% higher than that of SPP and LatLRR, respectively. This also indicates that it is unrealistic to learn  the optimal projection by only utilizing one structure of data. Moreover, it is obvious that the projection learning methods which capture the representation structure, i.e., NPE, SPP, CRP, LRPE, LRPP, LREP, and the proposed method, generally perform much better than those methods that only exploit the distance relationships of data. This proves the importance of the representation relationships of data in projection learning. Fig. <ref type="figure" target="#fig_7">7</ref> shows the classification accuracies of different methods with different feature dimensions on the AR face database, in which four and eight samples per class are randomly selected as the training set and the remaining samples are treated as the test set, respectively. From Fig. <ref type="figure" target="#fig_7">7</ref>, we can find that the proposed method outperforms other methods in all feature dimensions. In addition, with the dimension increases, the classification accuracy of the proposed method increases obviously and then reaches a stable level. The smooth classification curve indicates that the proposed method is insensitive to the selection of number of feature dimension to some extent, which is an excellent property in unsupervised classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experiments on the Extended Yale B Face Database</head><p>The extended Yale B face database contains 2414 face images from 38 subjects. Each subject provides about 59-64 face images acquired under different illuminations with frontal pose. Fig. <ref type="figure">8</ref> shows some typical faces of the extended Yale B face database. All images were cropped and transformed into gray images with the size of 32 × 32 in advance. In this experiment, PCA is also performed to reduce the dimension of all samples from 1024 to 148 by preserving 98% energy for computational efficiency. Then, 10, 15, 20, and 25 samples are randomly selected from each class as training samples and the remaining samples are treated as test samples, respectively. Experimental results of different methods on the extended Yale B database are shown in Table <ref type="table" target="#tab_4">III</ref>. It is obvious that SPP, NPE, CRP, LRPE, LRPP, LRPE, and the proposed method perform much better than PCA, LPP, OLPP, and LatLRR. This demonstrates that the representation-based methods is more robust than the distance-based methods in uncovering the intrinsic structure of data when data are corrupted by various illuminations. Thus exploiting the representation relationships of data is very important in feature extraction. Compared with SPP and NPE, the proposed method achieves the highest accuracy. This proves that preserving the global structure is also very useful and can further improve the classification performance.</p><p>Fig. <ref type="figure">9</ref> shows the classification accuracies of the above projection learning methods with different feature dimensions on the extended Yale B database, in which 10 and 20 samples per subject are randomly selected as training samples, respectively. From Fig. <ref type="figure">9</ref>, it is obvious that with the dimension increases, the proposed method reaches to the stable point quicker than other methods. Compared with OLPP, LPP, and NPE, the accuracy curve of the proposed method is smoother in the dimension range of <ref type="bibr" target="#b49">[50,</ref><ref type="bibr">140]</ref>. This indicates that the proposed method not only achieves consistent good performance in almost every feature dimensions, but also is more flexible in the selection of feature dimension.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experiments on the CMU PIE Face Database</head><p>The CMU PIE face database is composed of 41 368 face images from 68 subjects. Images in this database were acquired with different poses, illumination conditions, and facial appearances. In the experiments, we choose a subset that contains 11 554 images from 68 subjects with near frontal poses (C05, C07, C09, C27, and C29) to evaluate the above methods. Some typical images of this database are shown in Fig. <ref type="figure" target="#fig_9">10</ref>. In the experiment, all images were resized to gray images with the size of 32 × 32, followed by using PCA to preserve 98% energy to improve the computational efficiency. After the process of PCA, the dimension of all samples is reduced from 1024 to 157. Then we randomly select 10, 15, 20, and 25 samples from each class as training samples and treat the remaining samples as test samples.</p><p>Experimental results of the above methods are shown in Table <ref type="table" target="#tab_5">IV</ref>. It is obvious that the proposed method achieves the best performance. From Table <ref type="table" target="#tab_5">IV</ref>, we can find that the methods that preserve the representation structure of data generally perform better than those methods that only preserve local distance relationships. This is mainly because that distance-based measure metric is sensitive to the images with different poses, and thus cannot capture the local structure of data accurately, which leads to a bad performance. Compared with NPE which simply uses k nearest neighbor for representation, the proposed method can adaptively select those nearest neighbors. This is a very good property and greatly improves the adaptability of the method for different tasks.</p><p>Fig. <ref type="figure" target="#fig_10">11</ref> shows the classification accuracies of the above methods on the CMU PIE database with different feature dimensions, in which 10 and 20 samples per class are randomly selected as training samples. From Fig. <ref type="figure" target="#fig_10">11</ref>, we can find the following.</p><p>1) The proposed method achieves the best performance in each dimension. 2) SPCA and PCA have similar classification performance, which indicates that using the lasso constraint only contributes to the interpretability but cannot improve the classification performance. 3) Compared with other methods, the accuracy curves of PCA, SPCA, and the proposed method are smoother, especially in the dimension range of <ref type="bibr" target="#b49">[50,</ref><ref type="bibr">150]</ref>. This demonstrates that preserving the data energy is necessary and is beneficial to improve the flexibility in the selection of the number of feature dimension for projection learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Effectiveness of the Nearest Neighbor Graph</head><p>In this section, we mainly analyze the effectiveness of the regularization of nearest neighbor graph to the proposed method. Experiments on the extended Yale B and CMU PIE databases are conducted, in which the proposed method without the regularization of nearest neighbor graph is compared. By simply defining the nearest neighbor graph as the identity matrix, i.e., W = I, the proposed method is degraded to the method without the regularization of nearest neighbor graph. We refer to the degraded method without the regularization of nearest neighbor graph as LRPP. Similar to the previous experiments, we also perform PCA to preserve 98% energy to improve the efficiency.</p><p>Fig. <ref type="figure" target="#fig_2">12</ref> shows the comparison of the proposed method and LRPP on the extended Yale B and CMU PIE database. It is obvious that LRPP_GRR performs much better than LRPP in both two databases. This proves the effectiveness of the regularization of nearest neighbor graph. This also demonstrates that preserving the locality has potential to learn a more compact and discriminative representation so as to further improve the classification accuracy. Besides, we use some experiments to analyze the sensitivity of LRPP_GRR associated with the nearest neighbor number. Fig. <ref type="figure" target="#fig_4">13</ref> shows the mean classification accuracies (%) of the proposed method with different numbers of nearest neighbor on the extended Yale B and CMU PIE databases, in which 10 and 20 samples per class are randomly selected as the training set and the remaining samples are treated as the test set, respectively. It is obvious that the classification accuracy first increases and then decreases with the increasing of the nearest neighbor number of k. In the number range of <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref>, the classification accuracy curve is very smooth. This indicates that the proposed method is insensitive to the selection of nearest neighbor number to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we propose a novel projection learning method for unsupervised classification, in which an LRR constraint and a neighbor graph regularization term are integrated into a term to capture the global and local structures of data simultaneously during projection learning. Compared with other methods, the proposed method does not introduce any extra regularization terms for structure preserving, which greatly reduces the complexity. Experiments on several databases demonstrate that the proposed method not only achieves a better performance than some state-of-the-art methods, but also is very flexible in the selection of feature dimension to some extent.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>x i -Py j x i -Py j T )w ij = n i=1 n j=1 Tr x i x T i -2x i y T j P T + Tr y j y T j w ij = Tr XDX T -2XWY T P T + Tr YDY T (13) where D = diag(D 11 , D 22 , . . . , D nn ) is a diagonal matrix, and D ii = j w ij . Tr(•) is the trace operator. Then (12) can be rewritten as min P,Q,Z,U,Y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Objective function value and classification accuracy versus the iterations of the proposed method on the (a) extended Yale B face database, (b) CMU PIE face database, (c) AR face database, and (d) COIL20 image database, in which ten samples of each class are randomly selected from the corresponding database as training samples and the remaining samples are treated as test samples, respectively. Note: the objective function value curve from the second point to the 50th point is plotted in the subfigure pointed out by the "black arrow."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Projections learned by PCA, SPCA, and LRPP_GRR on the COIL20 database, in which ten samples of each class are randomly selected as the training set. In these figures, we just show the first 80 rows and 50 columns of the projection. The feature dimension of the above three methods is 150. Note: the above figures are shown with color map of "lines." (a) PCA. (b) SPCA. (c) LRPP_GRR.</figDesc><graphic coords="7,319.91,53.57,234.38,114.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Classification accuracy of the proposed method versus parameters λ 1 and λ 2 on the (a) COIL20 database, (b) AR database, (c) extended Yale B database, and (d) CMU PIE database, respectively. For each database, ten samples of each class are randomly selected as training set and remaining samples are treated as test samples. Note: in this experiment, the used databases are preprocessed by PCA, in which 98% energy is preserved for computational efficiency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Some typical images of the COIL20 image database.</figDesc><graphic coords="9,66.49,458.04,216.24,55.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 Fig. 5 .Fig. 6 .</head><label>556</label><figDesc>Fig. 5. Classification accuracies (%) of different projection learning methods with different feature dimensions on the COIL20 database, in which (a) 10 and (b) 20 samples per class are randomly selected as training samples, respectively. Note: the local area marked by the "red rectangle" is magnified and the corresponding magnified image is pointed out by the "red arrow."</figDesc><graphic coords="9,329.50,318.51,216.24,70.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Classification accuracies (%) of different projection learning methods with different feature dimensions on the AR database, in which (a) four and (b) eight samples per class are randomly selected as the training set, respectively. Note: the local area marked by the red rectangle is magnified and the corresponding magnified image is pointed out by the red arrow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig. 8. Some typical images of the extended Yale B face database.</figDesc><graphic coords="10,329.50,150.55,216.24,61.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Some typical images of the CMU PIE face database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Classification accuracies (%) of different projection learning methods with different feature dimensions on the CMU PIE database, in which (a) 10 and (b) 20 samples per class are randomly selected as training samples, respectively. Note: the local area marked by the red rectangle is magnified and the corresponding magnified image is pointed out by the red arrow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .Fig. 13 .</head><label>1213</label><figDesc>Fig. 12. Comparison of the proposed method with and without the regularization of the nearest neighbor graph on the (a) extended Yale B database and (b) CMU PIE database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>parameters λ 1 , λ 2 , projected dimension d, nearest neighbor graph W obtained by<ref type="bibr" target="#b6">(7)</ref>.</figDesc><table><row><cell>Initialization: P = arg max P T P=I</cell><cell>Tr P T</cell><cell>P , where</cell><cell>is the data</cell></row><row><cell>covariance</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>01, μ max = 10 8 .</figDesc><table><row><cell>while not converged do</cell></row><row><cell>1. Update Q using (18).</cell></row><row><cell>2. Update Z using (21).</cell></row><row><cell>3. Update U by solving (23).</cell></row><row><cell>4. Update Y using (26).</cell></row><row><cell>5. Update P by solving (28).</cell></row><row><cell>6. Update C 1 , C 2 , μ by (</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I CLASSIFICATION</head><label>I</label><figDesc>ACCURACIES (%) OF DIFFERENT METHODS ON THE COIL20 DATABASE. Note: BOLD NUMBERS DENOTE THE BEST RESULT</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II CLASSIFICATION</head><label>II</label><figDesc>ACCURACIES (%) OF DIFFERENT METHODS ON THE AR FACE DATABASE. Note: BOLD NUMBERS DENOTE THE BEST RESULT</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III CLASSIFICATION</head><label>III</label><figDesc>ACCURACIES (%) OF DIFFERENT METHODS ON THE EXTENDED YALE B FACE DATABASE. Note: BOLD NUMBERS DENOTE THE BEST RESULT</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV CLASSIFICATION</head><label>IV</label><figDesc>ACCURACIES (%) OF DIFFERENT METHODS ON THE CMU PIE FACE DATABASE. Note: BOLD NUMBERS DENOTE THE BEST RESULT</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code of LREP is available at: http://www.scholat.com/portalPaperInfo. html?paperID=31982&amp;Entry=laizhihui.,wong2017low.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Available at http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p><ref type="bibr" target="#b2">3</ref> Available at http://www2.ece.ohio-state.edu/∼aleix/ARdatabase.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>.<ref type="bibr" target="#b3">4</ref> Available at http://vision.ucsd.edu/∼iskwak/ExtYaleDatabase/ExtYaleB.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>html.<ref type="bibr" target="#b4">5</ref> Available at http://www.ri.cmu.edu/projects/project_418.html.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 61772141, and in part by the National Natural Science Foundation of China Youth Fund under Grant 61702110. This paper was recommended by Associate Editor S. Cruces.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>His current research interests include pattern recognition and machine learning.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Feature extraction based on semisupervised kernel marginal fisher analysis and its application in bearing fault diagnosis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mech. Syst. Signal Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="126" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Flexible manifold embedding: A framework for semi-supervised and unsupervised dimension reduction</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1921" to="1932" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint tensor feature analysis for visual object recognition</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2425" to="2436" />
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative elastic-net regularized linear regression</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1466" to="1481" />
			<date type="published" when="2017-03">Mar. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised multitask learning for scene recognition</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1967" to="1976" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Low-rank embedding for semisupervised face classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Workshops Autom. Face Gesture Recognit</title>
		<meeting>IEEE Int. Conf. Workshops Autom. Face Gesture Recognit<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdiscipl. Rev. Comput. Stat</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="459" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Eigenfaces for recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cogn. Neurosci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Locality preserving projections</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neighborhood preserving embedding</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1208" to="1213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sparsity preserving projections with applications to face recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="331" to="341" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A deterministic analysis for LRR</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="430" />
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sparse representation-based robust face recognition by graph regularized low-rank sparse representation recovery</title>
		<author>
			<persName><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page" from="220" to="229" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Blessing of dimensionality: Recovering mixture data via dictionary pursuit</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="60" />
			<date type="published" when="2017-01">Jan. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust face recognition via double lowrank matrix recovery for feature extraction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess<address><addrLine>Melbourne, VIC, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3770" to="3774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Low-rank matrix completion in the presence of high coherence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="5623" to="5633" />
			<date type="published" when="2016-11">Nov. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Low-rank preserving projections</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1900" to="1913" />
			<date type="published" when="2016-08">Aug. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust principal component analysis?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="50" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013-01">Jan. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inductive robust principal component analysis</title>
		<author>
			<persName><forename type="first">B.-K</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3794" to="3800" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Latent low-rank representation for subspace segmentation and feature extraction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1615" to="1622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Low-rank preserving embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="112" to="125" />
			<date type="published" when="2017-10">Oct. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Low-rank embedding for robust image feature extraction</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2905" to="2917" />
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graph-regularized low-rank representation for destriping of hyperspectral images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4009" to="4018" />
			<date type="published" when="2013-07">Jul. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dual graph regularized latent low-rank representation for subspace clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4918" to="4933" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Manifold regularized sparse NMF for hyperspectral unmixing</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2815" to="2826" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Laplacian regularized low-rank representation and its applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="504" to="517" />
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A local structural descriptor for image matching via normalized graph Laplacian embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="410" to="420" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sparse representation or collaborative representation: Which helps face recognition?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation via low-rank representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1432" to="1445" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Linearized alternating direction method with adaptive penalty for low-rank representation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="612" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spectral regression: A unified approach for sparse subspace learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Data Min</title>
		<meeting>IEEE Int. Conf. Data Min<address><addrLine>Omaha, NE, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps and spectral techniques for embedding and clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="585" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sparse principal component analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="286" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Discriminative least squares regression for multiclass classification and feature selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1738" to="1754" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Face recognition using Laplacianfaces</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="340" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="122" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
		<title level="m">Matrix Computations, 3rd ed</title>
		<meeting><address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Johns Hopkins Univ. Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Extracting shared subspace for multi-label classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD Int. Conf. Knowl. Disc. Data Min</title>
		<meeting>ACM SIGKDD Int. Conf. Knowl. Disc. Data Min<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="381" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrix</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno>UILU-ENG-09-2215</idno>
	</analytic>
	<monogr>
		<title level="j">UIUC</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2009-10">Oct. 2009</date>
			<pubPlace>Champaign, IL, USA, Rep</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">An Alternating Direction Algorithm for Nonnegative Matrix Factorization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<pubPlace>Houston, TX, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Rice Univ.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Orthogonal locality preserving indexing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Annu. Int. ACM SIGIR Conf</title>
		<meeting>28th Annu. Int. ACM SIGIR Conf<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A collaborative representation based projections method for feature extraction</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="27" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Columbia object image library (COIL-20)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Nene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Murase</surname></persName>
		</author>
		<idno>CUCS-005-96</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Columbia Univ</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>New York, NY, USA, Rep</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Centre de Visió per Computador</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Martinez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">24</biblScope>
			<pubPlace>Barcelona, Spain, Rep</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Universitat Autònoma de Barcelona</orgName>
		</respStmt>
	</monogr>
	<note>The AR face database</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="643" to="660" />
			<date type="published" when="2001-06">Jun. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The CMU pose, illumination, and expression database</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bsat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1615" to="1618" />
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust latent subspace learning for image classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2017.2693221</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst., to be published</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
