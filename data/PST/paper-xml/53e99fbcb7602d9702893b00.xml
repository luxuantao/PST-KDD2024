<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A review of unsupervised feature learning and deep learning for time-series modeling q</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-01-28">28 January 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Martin</forename><surname>L?ngkvist</surname></persName>
							<email>martin.langkvist@oru.se</email>
							<affiliation key="aff0">
								<orgName type="department">School of Science and Technology</orgName>
								<orgName type="laboratory">Applied Autonomous Sensor Systems</orgName>
								<orgName type="institution">?rebro University</orgName>
								<address>
									<postCode>SE-701 82</postCode>
									<settlement>?rebro</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lars</forename><surname>Karlsson</surname></persName>
							<email>lars.karlsson@oru.se</email>
							<affiliation key="aff0">
								<orgName type="department">School of Science and Technology</orgName>
								<orgName type="laboratory">Applied Autonomous Sensor Systems</orgName>
								<orgName type="institution">?rebro University</orgName>
								<address>
									<postCode>SE-701 82</postCode>
									<settlement>?rebro</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Loutfi</surname></persName>
							<email>amy.loutfi@oru.se</email>
							<affiliation key="aff0">
								<orgName type="department">School of Science and Technology</orgName>
								<orgName type="laboratory">Applied Autonomous Sensor Systems</orgName>
								<orgName type="institution">?rebro University</orgName>
								<address>
									<postCode>SE-701 82</postCode>
									<settlement>?rebro</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A review of unsupervised feature learning and deep learning for time-series modeling q</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-01-28">28 January 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.patrec.2014.01.008</idno>
					<note type="submission">Received 16 July 2013</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Time-series Unsupervised feature learning Deep learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems. While these techniques have shown promise for modeling static data, such as computer vision, applying them to time-series data is gaining increasing attention. This paper overviews the particular challenges present in time-series data and provides a review of the works that have either applied time-series data to unsupervised feature learning algorithms or alternatively have contributed to modifications of feature learning algorithms to take into account the challenges present in time-series data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction and background</head><p>Time is a natural element that is always present when the human brain is learning tasks like language, vision and motion. Most real-world data has a temporal component, whether it is measurements of natural processes (weather, sound waves) or man-made (stock market, robotics). Analysis of time-series data has been the subject of active research for decades <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b25">26]</ref> and is considered by Yang and Wu <ref type="bibr" target="#b130">[131]</ref> as one of the top 10 challenging problems in data mining due to its unique properties. Traditional approaches for modeling sequential data include the estimation of parameters from an assumed time-series model, such as autoregressive models <ref type="bibr" target="#b82">[83]</ref> and Linear Dynamical Systems (LDS) <ref type="bibr" target="#b81">[82]</ref>, and the popular Hidden Markov Model (HMM) <ref type="bibr" target="#b102">[103]</ref>. The estimated parameters can then be used as features in a classifier to perform classification. However, more complex, high-dimensional, and noisy real-world time-series data cannot be described with analytical equations with parameters to solve since the dynamics are either too complex or unknown <ref type="bibr" target="#b118">[119]</ref> and traditional shallow methods, which contain only a small number of non-linear operations, do not have the capacity to accurately model such complex data.</p><p>In order to better model complex real-world data, one approach is to develop robust features that capture the relevant information. However, developing domain-specific features for each task is expensive, time-consuming, and requires expertise of the data.</p><p>The alternative is to use unsupervised feature learning <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b28">29]</ref> in order to learn a layer of feature representations from unlabeled data. This has the advantage that the unlabeled data, which is plentiful and easy to obtain, is utilized and that the features are learned from the data instead of being hand-crafted. Another benefit is that these layers of feature representations can be stacked to create deep networks, which are more capable of modeling complex structures in the data. Deep networks have been used to achieve state-of-the-art results on a number of benchmark data sets and for solving difficult AI tasks. However, much focus in the feature learning community has been on developing models for static data and not so much on time-series data.</p><p>In this paper we review the variety of feature learning algorithms that has been developed to explicitly capture temporal relationships as well as the various time-series problems that they have been used on. The properties of time-series data will be discussed in Section 2 followed by an introduction to unsupervised feature learning and deep learning in Section 3. An overview of some common time-series problems and previous work using deep learning is given in Section 4. Finally, conclusions are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Properties of time-series data</head><p>Time-series data consists of sampled data points taken from a continuous, real-valued process over time. There are a number of characteristics of time-series data that make it different from other types of data.</p><p>Firstly, the sampled time-series data often contain much noise and have high dimensionality. To deal with this, signal processing techniques such as dimensionality reduction techniques, wavelet analysis or filtering can be applied to remove some of the noise and reduce the dimensionality. The use of feature extraction has a number of advantages <ref type="bibr" target="#b96">[97]</ref>. However, valuable information could be lost and the choice of features and signal processing techniques may require expertise of the data.</p><p>The second characteristics of time-series data is that it is not certain that there are enough information available to understand the process. For example, in electronic nose data, where an array of sensors with various selectivity for a number of gases are combined to identify a particular smell, there is no guarantee that the selection of sensors actually are able to identify the target odour. In financial data when observing a single stock, which only measures a small aspect of a complex system, there is most likely not enough information in order to predict the future <ref type="bibr" target="#b29">[30]</ref>.</p><p>Further, time-series have an explicit dependency on the time variable. Given an input x?t? at time t, the model predicts y?t?, but an identical input at a later time could be associated with a different prediction. To solve this problem, the model either has to include more data input from the past or must have a memory of past inputs. For long-term dependencies the first approach could make the input size too large for the model to handle. Another challenge is that the length of the time-dependencies could be unknown.</p><p>Many time-series are also non-stationary, meaning that the characteristics of the data, such as mean, variance, and frequency, changes over time. For some time-series data, the change in frequency is so relevant to the task that it is more beneficial to work in the frequency-domain than in the time-domain.</p><p>Finally, there is a difference between time-series data and other types of data when it comes to invariance. In other domains, for example computer vision, it is important to have features that are invariant to translations, rotations, and scale. Most features used for time-series need to be invariant to translations in time.</p><p>In conclusion, time-series data is high-dimensional and complex with unique properties that make them challenging to analyze and model. There is a large interest in representing the time-series data in order to reduce the dimensionality and extract relevant information. The key for any successful application lies in choosing the right representation. Various time-series problems contain different degrees of the properties discussed in this section and prior knowledge or assumptions about these properties is often infused in the chosen model or feature representation. There is an increasing interest in learning the representation from unlabeled data instead of using hand-designed features. Unsupervised feature learning have shown to be successful at learning layers of feature representations for static data sets and can be combined with deep networks to create more powerful learning models. However, the feature learning for time-series data have to be modified in order to adjust for the characteristics of time-series data in order to capture the temporal information as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Unsupervised feature learning and deep learning</head><p>This section presents both models that are used for unsupervised feature learning and models and techniques that are used for modeling temporal relations. The advantage of learning features from unlabeled data is that the plentiful unlabeled data can be utilized and that potentially better features than hand-crafted features can be learned. Both these advantages reduce the need for expertise of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Restricted Boltzmann Machine</head><p>The Restricted Boltzmann Machines (RBM) <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b75">76]</ref> is a generative probabilistic model between input units (visible), x, and latent units (hidden), h, see Fig. <ref type="figure" target="#fig_0">1</ref>. The visible and hidden units are connected with a weight matrix, W and have bias vectors c and b, respectively. There are no connections among the visible and hidden units. The RBM can be used to model static data. The energy function and the joint distribution for a given visible and hidden vector is defined as:</p><formula xml:id="formula_0">E?x; h? ? h T Wx ? b T h ? c T v<label>?1?</label></formula><formula xml:id="formula_1">P?x; h? ? 1 Z exp E?x;h?<label>?2?</label></formula><p>where Z is the partition function that ensures that the distribution is normalized. For binary visible and hidden units, the probability that hidden unit h j is activated given visible vector x and the probability that visible unit x i is activated given hidden vector h are given by:</p><formula xml:id="formula_2">P?h j jx? ? r b j ? X i W ij x i !<label>?3?</label></formula><formula xml:id="formula_3">P?x i jh? ? r c i ? X j W ij h j !<label>?4?</label></formula><p>where r??? is the activation function. The logistic function, r?x? ? 1 1?e ?x , is a common choice for the activation function. The parameters W, b, and v, are trained to minimize the reconstruction error using contrastive divergence <ref type="bibr" target="#b49">[50]</ref>. The learning rule for the RBM is:</p><formula xml:id="formula_4">@ log P?x? @W ij % x i h j data ? x i h j recon<label>?5?</label></formula><p>where ? h i is the average value over all training samples. Several RBMs can be stacked to produce a deep belief network (DBN). In a deep network, the activation of the hidden units in the first layer is the input to the second layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Conditional RBM</head><p>An extension of RBM that models multivariate time-series data is the conditional RBM (cRBM), see Fig. <ref type="figure">2</ref>. A similar model is the Temporal RBM <ref type="bibr" target="#b113">[114]</ref>. The cRBM consists of auto-regressive weights that model short-term temporal structures, and connections between past visible units to the current hidden units. The bias vectors in a cRBM depend on previous visible units and are defined as:</p><formula xml:id="formula_5">b ? j ? b j ? X n i?1 B i x?t ? i? ? 6? c ? i ? c j ? X n i?1 A i x?t ? i? ?<label>7?</label></formula><p>where A i is the auto-regressive connections between visible units at time t ? i and current visible units, B i is the weight matrix connecting visible layer at time t ? i to the current hidden units. The model order is defined by the constant n. The probabilities for going up or down a layer are: P?h</p><formula xml:id="formula_6">j jx? ? r b j ? X i W ij x i ? X k X i B ijk x i ?t ? k? !<label>?8?</label></formula><formula xml:id="formula_7">P?x i jh? ? r c i ? X j W ij h j ? X k X i A ijk x i ?t ? k? !<label>?9?</label></formula><p>The parameters h ? fW; b; c; A; Bg, are trained using contrastive divergence. Just like a RBM, the cRBM can also be used as a module to create deep networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Gated RBM</head><p>The Gated Restricted Boltzmann Machine (GRBM) <ref type="bibr" target="#b87">[88]</ref> is another extension of the RBM that models the transition between two input vectors. The GRBM models a weight tensor, W ijk , between the input, x, the output, y, and latent variables, z. The energy function is defined as:</p><formula xml:id="formula_8">E?y; z; x? ? ? X ijk W ijk x i y j z k ? X k b k z k ? X j c j y j<label>?10?</label></formula><p>where b and c are the bias vectors for x and y, respectively. The conditional probability of the transformation and the output image given the input image is:</p><formula xml:id="formula_9">p?y; zjx? ? 1 Z?x? exp??E?y; z; x??<label>?11?</label></formula><p>where Z?x? is the partition function. Luckily, this quantity does not need to be computed to perform inference or learning. The probability that hidden unit z i is activated given x and y is given by:</p><formula xml:id="formula_10">P?z k ? 1jx; y? ? r X ij W ijk x i y j ? b k !<label>?12?</label></formula><p>Learning the parameters is performed with an approximation method of the gradient called contrastive divergence <ref type="bibr" target="#b49">[50]</ref>. Each latent variable z k learns a simple transformation that together are combined the represent the full transformation. By fixating a learned transformation z and given an input image x, the output image y is the selected transformation applied to the input image. Similarly, for a fixed input image x, a given image y creates a RBM that learns the transformation z by reconstructing y. These properties could not be achieved with a regular RBM with input units simply being the concatenated images x and y since the latent variables would only learn the spatial information for that particular image pair and not the general transformation. The large number of parameters due to the weight tensor makes it impractical for large image sizes. A factored form of the three-way tensor has been proposed to reduce the number of parameters to learn <ref type="bibr" target="#b88">[89]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Auto-encoder</head><p>A model that does not have a partition function is the auto-encoder <ref type="bibr" target="#b106">[107,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b3">4]</ref>, see Fig. <ref type="figure">3</ref>. The auto-encoder was first introduced as a dimensionality reduction algorithm. In fact, a basic linear autoencoder learns essentially the same representation as a Principal Component Analysis (PCA). The layers of visible units, x, hidden units, h, and the reconstruction of the visible units, x, are connected via weight matrices W 1 and W 2 and the hidden layer and reconstruction layer have bias vectors b 1 and b 2 , respectively. It is common in auto-encoders to have tied weights, that is,</p><formula xml:id="formula_11">W 2 ? ?W 1 ? T .</formula><p>This works as a regularizer as it constrains the allowed parameter space and reduces the number of parameters to learn <ref type="bibr" target="#b4">[5]</ref>. The feed-forward activations are calculated as:</p><formula xml:id="formula_12">h j ? r X i W 1 ji x i ? b 1 j ! ?13? xi ? r X j W 2 ij h j ? b 2 i !<label>?14?</label></formula><p>where r??? is the activation function. As with the RBM, a common choice is the logistic activation function. The cost function to be minimized is expressed as:</p><formula xml:id="formula_13">J?h? ? 1 2N X N n X i ?x ?n? i ? xi ?n? ? 2 ? k 2 X l X i X j ?W l ij ? 2 ? b X l X j KL?qjjp l j ?<label>?15?</label></formula><p>Fig. <ref type="figure">2</ref>. A 2-layer conditional RBM for time-series data. The model order for the first and second layer is 3 and 2, respectively.</p><p>Fig. <ref type="figure">3</ref>. A 1-layer auto-encoder for static time-series input. The input is the concatenation of current and past frames of visible data x. The reconstruction of x is denoted x.</p><p>where p l j is the mean activation for unit j in layer l; q is the desired mean activation, and N is the number of training examples. KL is the Kullback-Leibler (KL) divergence which is de-</p><formula xml:id="formula_14">fined as KL?qjjp l j ? ? q log q p l j ? ?1 ? q? log 1?q 1?p l j</formula><p>. The first term is the square root error term that will minimize the reconstruction error. The second term is the L2 weight decay term that will keep the weight matrices close to zero. Finally, the third term is the sparsity penalty term and encourages each unit to only be partially activated as specified by the hyperparameter q. The inclusion of these regularization terms prevents the trivial learning of a 1-to-1 mapping of the input to the hidden units. A difference between auto-encoders and RBMs is that RBMs do not require such regularization because the use of stochastic binary hidden units acts as a very strong regularizer <ref type="bibr" target="#b50">[51]</ref>. However, it is not uncommon to introduce an extra sparsity constraint for RBMs <ref type="bibr" target="#b75">[76]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Recurrent neural network</head><p>A model that have been used for modeling sequential data is the Recurrent Neural Network (RNN) <ref type="bibr" target="#b56">[57]</ref>. Generally, an RNN is obtained from the feedforward network by connecting the neurons' output to their inputs, see Fig. <ref type="figure">4</ref>. The short-term time-dependency is modeled by the hidden-to-hidden connections without using any time delay-taps. They are usually trained iteratively via a procedure known as backpropagation-through-time (BPTT). RNNs can be seen as very deep networks with shared parameters at each layer when unfolded in time. This results in the problem of vanishing gradients <ref type="bibr" target="#b101">[102]</ref> and has motivated the exploration of second-order methods for deep architectures <ref type="bibr" target="#b85">[86]</ref> and unsupervised pre-training. An overview of strategies for training RNNs is provided by Sutskever <ref type="bibr" target="#b112">[113]</ref>. A popular extension is the use of the purpose-built Long-short term memory cell <ref type="bibr" target="#b53">[54]</ref> that better finds long-term dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Deep learning</head><p>The models presented in this section use a non-linear activation function on the hidden units. This non-linearity enables a more expressive model that can learn more abstract representations when multiple modules are stacked on top of each other to form a deep network (if linear features would be stacked the result would still be a linear operation). The goal of a deep network is to build features at the lower layers that will disentangle the factors of variations in the input data and then combine these representations at the higher layers. It has been proposed that a deep network will generalize better because it has a more compact representation <ref type="bibr" target="#b73">[74]</ref>. However, the difficulty with training multiple layers of hidden units lies in the problem of vanishing gradients when the error signal is backpropagated <ref type="bibr" target="#b8">[9]</ref>. This can be solved by doing unsupervised greedy layer-wise pre-training of each layer. This acts as an unusual form of regularization <ref type="bibr" target="#b28">[29]</ref> that avoids poor local minima and gives a better initialization than a random initialization <ref type="bibr" target="#b4">[5]</ref>. However, the importance of parameter initialization is not as crucial as other factors such as input connections and architecture <ref type="bibr" target="#b107">[108]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Convolution and pooling</head><p>A technique that is particularly interesting for high-dimensional data, such as images and time-series data, is convolution. In a convolutional setting, the hidden units are not fully connected to the input but instead divided into locally connected segments, see Fig. <ref type="figure">5</ref>. Convolution has been applied to both RBMs and auto-encoders to create convolutional RBMs (convRBM) <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b76">77]</ref> and convolutional auto-encoders (convAE) <ref type="bibr" target="#b86">[87]</ref>. A Time-Delay Neural Network (TDNN) is a specialization of Artificial Neural Networks (ANN) that exploits the time structure of the input by performing convolutions on overlapping windows.</p><p>A common operator used together with convolution is pooling, which combines nearby values in input or feature space through a max, average or histogram operator. The purpose of pooling is to achieve invariance to small local distortions and reduce the dimensionality of the feature space. The work by Lee et al. <ref type="bibr" target="#b76">[77]</ref> introduces probabilistic max-pooling in the context of convolutional RBMs. The Space-Time DBN (ST-DBN) <ref type="bibr" target="#b12">[13]</ref> uses convolutional RBMs together with a spatial pooling layer and a temporal pooling layer to build invariant features from spatio-temporal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.">Temporal coherence</head><p>There are a number of other ways besides the architectural structure that can be used to capture temporal coherence in data. One way is to introduce a smoothness penalty on the hidden variables in the regularization. This is done by minimizing the changes in the hidden unit activations from one frame to the next by min jh?t? ? h?t ? 1?j. The motivation behind this is that for sequential data the hidden unit activations should not change much if the time-dependent data is fed to the model in a chronological order. Other strategies include penalizing the squared difference, slow feature analysis <ref type="bibr" target="#b127">[128]</ref>, or as a function of other factors, for example the change in the input data in order to adapt to both slow and rapid changing input data. Temporal coherence is related to invariant feature representations since both methods want to achieve small changes in the feature representation for small changes in the input data. It is suggested in <ref type="bibr" target="#b51">[52]</ref> that the pose parameters and affine transformations should be modeled instead of using invariant feature representations. In that case, temporal coherence should be over a group of numbers, such as the position and pose of the object rather than a single scalar. This could for example be achieved using a structured sparsity penalty <ref type="bibr" target="#b64">[65]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9.">Hidden Markov Model</head><p>The Hidden Markov Model (HMM) <ref type="bibr" target="#b102">[103]</ref> is a popular model for modeling sequential data and is defined by two probability distributions. The first one is the transition distribution P?y t jy t?1 ?, which defines the probability of going from one hidden state y to the next hidden state. The second one is the observation distribution P?x t jy t ?, which defines the relation between observed x values and hidden y states. One assumption is that these distributions are stationary. However, the main problem with HMMs are that they require a discrete state space, often have unrealistic independence assumptions, and have a limited representational capacity of their hidden states <ref type="bibr" target="#b93">[94]</ref>. HMMs require 2 N hidden states in order to model N bits of information about the past history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.10.">Summary</head><p>Table <ref type="table" target="#tab_0">1</ref> gives a summary of the briefly presented models in this section. The first column indicates whether the model is capable of capturing temporal relations. A model that captures temporal relations does so by having a memory of past inputs. The memory of a model, indicated in the second column, means how many steps back in time an input have on the current frame. Without the temporal order, any permutation of the feature sequence would yield the same distribution <ref type="bibr" target="#b55">[56]</ref>. The implementation of a memory is performed differently between the models. In a cRBM, delay taps are used to create a short-term dependency on past visible units. The long-term dependency comes from modeling subsequent layers. This means that the length of the memory for a cRBM is increased for each added layer. The model order for a cRBM in one layer is typically below 5 for input sizes around 50. A decrease in the input size would allow a higher model order. In an RNN, hidden units in the current time frame are affected by the state of the hidden units in the previous time frame. This can create a ripple effect with a duration of potentially infinite time frames. On the other hand, this ripple effect can be prevented by using a forget gate <ref type="bibr" target="#b36">[37]</ref>. The use of Long-short term memory <ref type="bibr" target="#b53">[54]</ref> or hessian-free optimizer <ref type="bibr" target="#b85">[86]</ref> can produce recurrent networks that has a memory of over 100 time steps. The Gated RBM and the convolutional GRBM models transitions between pairs of input vectors so the memory for these models is 2. The Space-Time DBN <ref type="bibr" target="#b12">[13]</ref> models 6 sequences of outputs from the spatial pooling layer, which is a longer memory than GRBM, but using a lower input size.</p><p>The last column in Table <ref type="table" target="#tab_0">1</ref> indicates if the model is generative (as opposed to discriminative). A generative model can generate observable data given a hidden representation and this ability is mostly used for generating synthetic data of future time steps. Even though the auto-encoder is not generative, a probabilistic interpretation can be made using auto-encoder scoring <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>For selecting a model for a particular problem, a number of questions should be taken into consideration: (1) Use a generative or discriminative model? <ref type="bibr" target="#b1">(2)</ref> What are the properties of the data? and (3) How large is the input size? A generative model is preferred if the trained model should be used for synthesizing new data or prediction tasks where partial input data (data at t ? 1) need to be reconstructed. If the task is to do classification, a discriminative model is sufficient. A discriminative model will attempt to model the training data even if that data is noisy while a generative model will simply assign a low probability for outliers. This makes a generative model more robust for noisy inputs and a better outlier detector. There is also the factor of training time. Generative models use Gibbs sampling to approximate the derivatives for each parameter update while a discriminative model calculates the exact gradients in one iteration. However, if the simulation time is an issue, it is a good idea to look for hardware solutions or the choice of optimization method before considering which method is the fastest. When the combination of input size, model parameters, and number of training examples in one training batch is large, the training time could be decreased by performing the parameter updates on a GPU instead of the CPU. For large-scale problems, i.e., the number of training examples is large, it is recommended to use stochastic gradient descent instead of L-BFGS or conjugate gradient descent as optimization method <ref type="bibr" target="#b14">[15]</ref>. Furthermore, if the data has a temporal structure it is not recommended to treat the input data as a feature vector since this will discard the temporal information. Instead, a model that inherently models temporal relations or incorporates temporal coherence (by regularization or temporal pooling) in a static model is a better approach. For high-dimensional problems, like images which have a pictorial structure, it may be appropriate to use convolution. The use of pooling further decreases the number of dimensions and introduces invariance for small translations of the input data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Classical time-series problems</head><p>In this section we will highlight some common time-series problems and the models that have been used to address them in the literature. We will focus on complex problems that require the use of models with hidden variables for feature representation and where the representations are fully or partially learned from unlabeled data. A summary of the classical time-series problems that will be presented in this section is given in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Videos</head><p>Video data are series of images over time (spatio-temporal data) and can therefore be viewed as high-dimensional time-series data. Fig. <ref type="figure" target="#fig_2">6</ref> shows a sequence of images from the KTH activity recognition data set. 1 The traditional approach to modeling video streams is to treat each individual static image and detecting interesting points using common feature detectors such as SIFT <ref type="bibr" target="#b80">[81]</ref> or HOG  <ref type="bibr" target="#b23">[24]</ref>. These features are domain-specific for static images and are not easily extended to other domains such as video <ref type="bibr" target="#b72">[73]</ref>.</p><p>The approach taken by Stavens and Thrun <ref type="bibr" target="#b110">[111]</ref> learns its own domain-optimized features instead of using pre-defined features, but still from static images. A better approach to modeling videos is to learn image transitions instead of working with static images. A Gated Restricted Boltzmann Machine (GRBM) <ref type="bibr" target="#b87">[88]</ref> has been used for this purpose where the input, x, of the GRBM is the full image in one time frame and the output y is the full image in the subsequent time frame. However, since the network is fully connected to the image the method does not scale well to larger images and local transformations at multiple locations must be re-learned.</p><p>A convolutional version of the GRBM using probabilistic maxpooling is presented by Taylor et al. <ref type="bibr" target="#b115">[116]</ref>. The use of convolution reduces the number of parameters to learn, allows for larger input sizes, and better handles the local affine transformations that can appear anywhere in the image. The model was validated on synthetic data and a number of benchmark data sets, including the KTH activity recognition data set.</p><p>The work by Le et al. <ref type="bibr" target="#b72">[73]</ref> presents an unsupervised spatio-temporal feature learning method using an extension of Independent Subspace Analysis (ISA) <ref type="bibr" target="#b59">[60]</ref>. The extensions include hierarchical (stacked) convolutional ISA modules together with pooling. A disadvantage of ISA is that it does not scale well to large input sizes. The inclusion of convolution and stacking solves this problem by learning on smaller patches of input data. The method is validated on a number of benchmark sets, including KTH. One advantage of the method is that the use of ISA reduces the need for tweaking many of the hyperparameters seen in RBM-based methods, such as learning rate, weight decay, convergence parameters, etc.</p><p>Modeling temporal relations in video have also been done using temporal pooling. The work by Chen and de Freitas <ref type="bibr" target="#b12">[13]</ref> uses convolutional RBMs as building blocks for spatial pooling and then performs temporal pooling on the spatial pooling units. The method is called Space-Time Deep Belief Network (ST-DBN). The ST-DBN allows for invariance and statistical dependencies in both space and time. The method achieved superior performance on applications such as action recognition and video denoising when compared to a standard convolutional DBN.</p><p>The use of temporal coherence for modeling videos is done by Zou et al. <ref type="bibr" target="#b134">[135]</ref>, where an auto-encoder with a L1-cost on the temporal difference on the pooling units is used to learn features that improve object recognition on still images. The work by Hyv?rinen <ref type="bibr" target="#b57">[58]</ref> also uses temporal information as a criterion for learning representations.</p><p>The use of deep learning, feature learning, and convolution with pooling has propelled the advances in video processing. Modeling streams of video is a natural continuation for deep learning algorithms since they have already been shown to be successful at building useful features from static images. By focusing on learning temporal features in videos, the performance on static images can be improved, which motivates the need for continuing developing deep learning algorithms that capture temporal relations. The early attempts at extending deep learning algorithms to video data was done by modeling the transition between two frames. The use of temporal pooling extends the time-dependencies a model can learn beyond a single frame transition. However, the time-dependency that has been modeled is still just a few frames. A possible future direction for video processing is to look at models that can learn longer time-dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Stock market prediction</head><p>Stock market data are highly complex and difficult to predict, even for human experts, due to a number of external factors, e.g., politics, global economy, and trader expectation. The trends in stock market data tend to be nonlinear, uncertain, and non-stationary. Fig. <ref type="figure" target="#fig_3">7</ref> shows the Dow Jones Industrial Average (DJOI) over a decade. According to the Efficient Market Hypothesis (EMH) <ref type="bibr" target="#b29">[30]</ref>, stock market prices follow a random walk pattern, meaning that a stock has the same probability to go up as it has to go down, resulting in that predictions can not have more than 50% accuracy <ref type="bibr" target="#b120">[121]</ref>. The EMH state that stock prices are largely driven by ''news'' rather than present and past prices. However, it has also been argued that stock market prices do not follow a random walk and that they can be predicted <ref type="bibr" target="#b83">[84]</ref>. The landscape for acquiring both news and stock information looks very different today than it did decades ago. As an example, it has been shown that predicted stock prices can be improved if further information is extracted from online social media, such as Twitter feeds <ref type="bibr" target="#b13">[14]</ref> and online chat activity <ref type="bibr" target="#b42">[43]</ref>.  One model that has emerged and shown to be suitable for stock market prediction is the artificial neural network (ANN) <ref type="bibr" target="#b2">[3]</ref>. This is due to its ability to handle non-linear complex systems. A survey of ANNs applied to stock market prediction is given in <ref type="bibr" target="#b78">[79]</ref>. However, most approaches of ANN applied to stock prediction have given unsatisfactory results <ref type="bibr" target="#b0">[1]</ref>. Neural networks with feedback have also been tried, such as recurrent versions of TDNN <ref type="bibr" target="#b66">[67]</ref>, wavelet transformed features with an RNN <ref type="bibr" target="#b54">[55]</ref>, and echo state networks <ref type="bibr" target="#b79">[80]</ref>. Many of these methods are applied directly on the raw data, while other papers focus more on the feature selection step <ref type="bibr" target="#b120">[121]</ref>.</p><p>In summary, it can be concluded that there is still room to improve existing techniques for making safe and accurate stock prediction systems. If additional information from sources that affect the stock market can be measured and obtained, such as general public opinions from social media <ref type="bibr" target="#b13">[14]</ref>, trading volume <ref type="bibr" target="#b133">[134]</ref>, market specific domain knowledge, and political and economical factors, it can be combined together with the stock price data to achieve higher stock price predictions <ref type="bibr" target="#b0">[1]</ref>. The limited success of applying small, one layer neural networks for stock market prediction and the realization that there is a need to add more information to make better predictions indicate that a future direction for stock market prediction is to apply the combined data to more powerful models that are able to handle such complex, highdimensional data. Deep learning methods for multivariate timeseries fit this description and provide new interesting approach for the financial field and a new challenging application for the deep learning community, which to the authors knowledge has not yet been tried.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Speech recognition</head><p>Speech recognition is one area where deep learning has made significant progress <ref type="bibr" target="#b47">[48]</ref>. The problem of speech recognition can be divided into a variety of sub-problems, such as speaker identification <ref type="bibr" target="#b76">[77]</ref>, gender identification <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b100">101]</ref>, speech-to-text <ref type="bibr" target="#b31">[32]</ref> and acoustic modeling. The raw input data is single channel and highly time and frequency dependent, see Fig. <ref type="figure" target="#fig_4">8</ref>. A common approach is to use pre-set features that are designed for speech processing such as Mel-frequency cepstral coefficients (MFCC).</p><p>For decades, Hidden Markov Models (HMMs) <ref type="bibr" target="#b102">[103]</ref> have been the state-of-the-art technique for speech recognition. A common method for discretization of the input data for speech that is required by the HMM is to use Gaussian mixture models (GMM). More recently however, the Restricted Boltzmann Machines (RBM) have shown to be an adequate alternative for replacing the GMM in the discretization step. A classification error of 20.7% on the TIMIT speech recognition data set 2 was achieved by Mohamed et al. <ref type="bibr" target="#b92">[93]</ref> by training a RBM on MFCC features. A similar setup has been used for large vocabulary speech recognition by Dahl et al. <ref type="bibr" target="#b21">[22]</ref>. A convolutional deep belief networks was applied by Lee et al. <ref type="bibr" target="#b77">[78]</ref> to audio data and evaluated on various audio classification tasks.</p><p>A number of variations on the RBM have also been tried on speech data. The mean-covariance RBM (mcRBM) <ref type="bibr" target="#b104">[105,</ref><ref type="bibr" target="#b105">106]</ref> achieved a classification error of 20.5% on the TIMIT data set by Dahl et al. <ref type="bibr" target="#b22">[23]</ref>. A conditional RBM (cRBM) was modified by Mohamed and Hinton <ref type="bibr" target="#b93">[94]</ref> by including connections from future instead of only having connections from the past, which presumably gave better classification because the near future is more relevant than the more distant past.</p><p>Earlier, a Time-Delay Neural Network (TDNN) has been used for speech recognition <ref type="bibr" target="#b124">[125]</ref> and a review of TDNN architectures for speech recognition is given by Sugiyama et al. <ref type="bibr" target="#b111">[112]</ref>. However, it has been suggested that convolution over the frequency instead of the time is better since the HMM on top models the temporal information.</p><p>The recent work by Graves et al. <ref type="bibr" target="#b40">[41]</ref> uses a deep Long Shortterm Memory Recurrent Neural Network (RNN) <ref type="bibr" target="#b53">[54]</ref> to achieve a classification error of 17.7% on the TIMIT data set, which is the best result to date. One difference between the approaches of RBM-HMM and RNN is that the RNN can be used as an 'end-to-end' model because it replaces a combination of different techniques that are currently used in sequence modeling, such as the HMM. 2 http://www.ldc.upenn.edu/Catalog/ However, both these approaches still rely on pre-defined features as input.</p><p>While using features such as MFCCs that collapse high dimensional speech sound waves into low dimensional encodings have been successful in speech recognition systems, such low dimensional encodings may lose some relevant information. On the other hand, there are approaches that build their own features instead of using pre-defined features. The work by Jaitly and Hinton <ref type="bibr" target="#b60">[61]</ref> used raw speech as input to a RBM and achieved a classification error of 21.8% on the TIMIT data set. Another approach that uses raw data is learning the auditory codes using spiking population code <ref type="bibr" target="#b109">[110]</ref>. In this model, each spike encodes the precise time position and magnitude of a localized, time varying kernel function. The learned representations (basis vectors) show a striking resemblance to the cochlear filters in the auditory cortex.</p><p>Similarly sparse coding for audio classification is used by Grosse et al. <ref type="bibr" target="#b41">[42]</ref>. The authors used features as input and a shift-invariant sparse coding model that reconstructs a time-series input using all the basis functions in all possible shifts. The model was evaluated on speaker identification and music genre classification.</p><p>A multimodal framework was explored by Ngiam et al. <ref type="bibr" target="#b97">[98]</ref> where video data of spoken digits and letters where combined with the audio data to improve the classification.</p><p>In conclusion, there have been a lot of recent improvements to the previous dominance of the features-GMM-HMM structure that has been used in speech recognition. First, there is a trend towards replacing GMM with a feature learning model such as deep belief networks or sparse coding. Second, there is a trend towards replacing HMM with other alternatives. One of them is the conditional random field (CRF) <ref type="bibr" target="#b67">[68]</ref> that have been shown to outperform HMM, see for example the work by van Kasteren et al. <ref type="bibr" target="#b63">[64]</ref> and Bengio and Frasconi <ref type="bibr" target="#b5">[6]</ref>. However, to date, the best reported result is replacing both parts of GMM-HMM with RNN <ref type="bibr" target="#b40">[41]</ref>. A next possible step for speech processing would be to replace the pre-made features with algorithms that build even better features from raw data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Music recognition</head><p>Music recognition is similar to speech recognition with the exception that the data can be multivariate and either presented as raw acoustic signals or by discrete chords. In music recognition, a number of sub-problems are considered, such as music annotation (genre, chord, instrument, mood classification), music retrieval (text-based content search, content-based similarity retrieval, organization), and tempo identification. For music recognition, a commonly used set of features are MFCCs, chroma, constant-Q spectrograms (CQT) <ref type="bibr" target="#b108">[109]</ref>, local contrast normalization (LCN) <ref type="bibr" target="#b74">[75]</ref>, or Compressive Sampling (CS) <ref type="bibr" target="#b17">[18]</ref>. However, there is an increasing interest in learning the features from the data instead of using highly engineered features based on acoustic knowledge. A widely used data set for music genre recognition is GTZAN. <ref type="foot" target="#foot_1">3</ref> Even though it is possible to solve many tasks on text-based meta-data, such as user data (playlists, song history, social structure), there is still a need for content-based analysis. The reasons for this is that manual labeling is inefficient due to the large amount of music content and some tasks require the well-trained ear of an expert, e.g., chord recognition.</p><p>The work by Humphrey et al. <ref type="bibr" target="#b55">[56]</ref> gives a review and future directions for music recognition. In this work, three deficiencies are identified: hand-crafted features are sub-optimal and unsustainable to develop for each task, shallow architectures are fundamentally limited, and short-time analysis cannot encode a musically meaningful structure. To handle these deficiencies it is proposed to learn features automatically, apply deep architectures, and model longer time-dependencies than the current use of data in milliseconds.</p><p>The work by Nam et al. <ref type="bibr" target="#b95">[96]</ref> addresses the first deficiency by presenting a processing pipeline for automatically learning features for music recognition. The model follows the structure of a high-dimensional single layer network with max-pooling separately after learning the features <ref type="bibr" target="#b20">[21]</ref>. The input data is taken from multiple audio frames and fed into three different feature learning algorithms, namely K-means clustering, sparse coding, and RBM. The learned features gave better performance compared to MFCC, regardless of the feature learning algorithm.</p><p>Sparse coding have been used by Grosse et al. <ref type="bibr" target="#b41">[42]</ref> for learning features for music genre recognition. The work by Henaff et al. <ref type="bibr" target="#b45">[46]</ref> used Predictive Sparse Decomposition (PSD), which is similar to sparse coding, and achieved an accuracy of 83.4% on the GTZAN data. In this work, the features are automatically learned from CTQ spectograms in an unsupervised manner. The learned features capture information about which chords are being played in a particular frame and produce comparable results to hand-crafted features for the task of genre recognition. A limitation, however, is that it ignores temporal dependencies between frames. Convolutional DBNs were used by Lee et al. <ref type="bibr" target="#b77">[78]</ref> to learn features from speech and music spectrograms and from engineered features by Dieleman <ref type="bibr" target="#b24">[25]</ref>. The work by Hamel and Eck <ref type="bibr" target="#b44">[45]</ref> also uses convolutional DBN to achieve an accuracy of 84.3% on the GTZAN dataset.</p><p>Self-taught learning have also been used for music genre classification. The self-taught learning framework attempts to use unlabeled data that does not share the labels of the classification task to improve classification performance <ref type="bibr" target="#b103">[104,</ref><ref type="bibr" target="#b61">62]</ref>. Self-taught learning and sparse coding are used by Markov and Matsui <ref type="bibr" target="#b84">[85]</ref> where unlabeled data from other music genres other than in the classification task was used to train the model.</p><p>In conclusion, there are many works that use unsupervised feature learning methods for music recognition. The motivation for using deep networks is that music itself is structured hierarchically by a combination of chords, melodies and rhythms that creates motives, phrases, sections and finally entire pieces <ref type="bibr" target="#b55">[56]</ref>. Just like in speech recognition, the input data is often in some form of spectrograms. Many works leave the natural step of learning features from raw data as future work <ref type="bibr" target="#b94">[95]</ref>. Still, as proposed by Humphrey et al. <ref type="bibr" target="#b55">[56]</ref>, even though convolutional networks have given good results on time-frequency representations of audio, there is room for discovering new and better models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Motion capture data</head><p>Modeling human motion has several applications such as tracking, activity recognition, style and content separation, person identification, computer animation, and synthesis of new motion data. Motion capture data is collected from recordings of movements from several points on the body of a human actor. These points can be captured by cameras that either track the position of strategically placed markers (usually at joint centers) or uses visionbased algorithms for tracking points of interest <ref type="bibr" target="#b37">[38]</ref>. The points are represented as 3D Cartesian coordinates over time and are used to form a skeletal structure with constant limb lengths by translating the points to relative joint angles. The joint angles can be expressed in Euler angles, 4D quaternions, or exponential map parameterization <ref type="bibr" target="#b39">[40]</ref> and can have 1-3 degrees of freedom (DOF) each. The full data set consists of the orientation and translation of the root and all relative joint angles for each time frame as well as the constant skeleton model. The data is noisy, high-dimensional, and multivariate with complex nonlinear relationships. It has a lower frequency compared to speech and music data and some of the signals may be task-redundant. Some of the traditional approaches include the work by Brand and Hertzmann <ref type="bibr" target="#b15">[16]</ref>, which models both the style and content of human motion using Hidden Markov Models (HMMs). The different styles were learned from unlabeled data and the trained model was used to synthesize motion data. A linear dynamical systems was used by Chiappa et al. <ref type="bibr" target="#b19">[20]</ref> to model three different motions of a human performing the task of holding a cup that has a ball attached to it with a string and then try to catch the ball into the cup (game of Balero). A Bayesian mixture of linear Gaussian state-space models (LGSSM) was trained with data from a human learner and used to generate new motions that was clustered and simulated on a robotic manipulator.</p><p>Both HMMs and linear dynamical systems are limited by their ability to model complex full-body motions. The work by Wang et al. <ref type="bibr" target="#b126">[127]</ref> uses Gaussian Processes to model three styles of locomotive motion (walk, run, stride) from the CMU motion capture data set, <ref type="foot" target="#foot_2">4</ref> see Fig. <ref type="figure">9</ref>. The CMU data set have also been used to generate motion capture from just a few initialization frames with a Temporal RBM (TRBM) <ref type="bibr" target="#b113">[114]</ref> and a conditional RBM (cRBM) <ref type="bibr" target="#b117">[118]</ref>. Better modeling and smoother transition between different styles of motions was achieved by adding a second hidden layer to the cRBM, using the Recurrent TRBM <ref type="bibr" target="#b114">[115]</ref>, and using the factored conditional RBM (fcRBM) <ref type="bibr" target="#b116">[117]</ref>. The work by L?ngkvist and Loutfi <ref type="bibr" target="#b71">[72]</ref> restructures an auto-encoder to resemble a cRBM but is used to perform classification on the CMU motion capture data instead of generating new sequences. The drawbacks with general-purpose models such as Gaussian Processes and cRBM are that prior information about motion is not utilized and they have a costly approximation sampling procedure.</p><p>An unsupervised hierarchical model that is specifically designed for modeling locomotion styles was developed by Pan and Torresani <ref type="bibr" target="#b99">[100]</ref> and builds on the Hierarchical Bayesian Continuous Profile Model (HB-CPM). A Dynamic Factor Graph (DFG), which is an extension of factor graphs, was introduced by Mirowski and LeCun <ref type="bibr" target="#b89">[90]</ref> and used on motion capture data to fill in missing data. The advantage of DFG is that it has a constant partition function which avoids the costly approximation sampling procedure that is used in a cRBM.</p><p>In summary, analyzing and synthesizing motion capture data is a challenging task and it encourages researchers to further improve learning algorithms for dealing with complex, multivariate timeseries data. A motivation for using deep learning algorithms for motion capture data is that it has been suggested that human motion is composed of elementary building blocks (motion templates) and any complex motion is constructed from a library of these previously learned motion templates <ref type="bibr" target="#b30">[31]</ref>. Deep networks can, in an unsupervised manner, learn these motion templates from raw data and use them to form complex human motions. Motion capture data also provides an interesting platform for feature learning from raw data since there is no commonly used feature set for motion capture data. Therefore, the success of applying deep learning algorithms to motion data can inspire learning features from raw data in other time-series problems as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Electronic nose data</head><p>Machine olfaction <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b32">33]</ref> is a field that seeks to quantify and analyze odours using an electronic nose (e-nose). An e-nose is composed of an array of selective gas sensors together with pattern recognition techniques. Fig. <ref type="figure" target="#fig_0">10</ref> shows the readings from an e-nose sensor array. The number of sensors in the array typically ranges from 4-30 sensors and are therefore, just like motion capture data, multivariate and may contain redundant signals. The data is also unintuitive and there is a lack of expert knowledge that can guide the design of features. E-noses are mostly used in practice for industrial applications such as measuring food, beverage <ref type="bibr" target="#b34">[35]</ref>, and air quality <ref type="bibr" target="#b131">[132]</ref>, gas identification, and gas source localization <ref type="bibr" target="#b10">[11]</ref>, but also has medical applications such as bacteria identification <ref type="bibr" target="#b27">[28]</ref> and diagnosis <ref type="bibr" target="#b33">[34]</ref>.</p><p>The traditional approach of analyzing e-nose data involves extracting information in the static and dynamic phases of the signals <ref type="bibr" target="#b43">[44]</ref> for the use of static pattern analysis techniques (PCA, discriminant function analysis, cluster analysis and neural networks). Some commonly used features are the static sensor response, transient derivatives <ref type="bibr" target="#b119">[120]</ref>, area under the curve <ref type="bibr" target="#b16">[17]</ref>, model parameter identification <ref type="bibr" target="#b122">[123]</ref>, and dynamic analysis <ref type="bibr" target="#b46">[47]</ref>.</p><p>A popular approach for modeling e-nose data is the Time-Delay Neural Networks (TDNN) <ref type="bibr" target="#b124">[125]</ref>. It has been used for identifying the smell of spices <ref type="bibr" target="#b132">[133]</ref>, ternary mixtures <ref type="bibr" target="#b123">[124]</ref>, optimum fermentation time for black tea <ref type="bibr" target="#b11">[12]</ref>, and vintages of wine <ref type="bibr" target="#b129">[130]</ref>. An RNN have been used for odour localization with a mobile robot <ref type="bibr" target="#b26">[27]</ref>.</p><p>The work by Vembu et al. <ref type="bibr" target="#b122">[123]</ref> compares the gas discrimination and localization between three approaches: SVM on raw data, SVM on features extracted from auto-regressive and linear dynamical systems, and finally a SVMs with kernels specialized for structured data <ref type="bibr" target="#b35">[36]</ref>. The SVM with built-in time-aware kernels performed better than techniques that used feature extraction, even though the features captured temporal information.</p><p>More recently, an auto-encoder, RBM, and cRBM have been used for bacteria identification <ref type="bibr" target="#b70">[71]</ref> and fast classification of meat spoilage markers <ref type="bibr" target="#b68">[69]</ref>.</p><p>E-nose data introduces the challenge of improving models that can deal with redundant signals. It is not feasible to produce tailormade sensors for each possible individual gas and combinations of gases of interest. Therefore the common approach is to use an array of sensors with different properties and leave the discrimination to the pattern analysis software. It is also not desirable to construct new feature sets for each e-nose application so a datadriven feature learning method is useful. The early works on enose data create feature vectors of simple features for each signal such as the static response or the slope of dynamic response and then feed it to a classifier. Recently, the use of dynamic models such as neural networks with tapped delays and SVMs with kernels for structured data have shown to improve the performance over static approaches. The next step is to continue this trend of using dynamical models that constructs robust features that can deal with noisy inputs in order to quantify and classify odors in more challenging open environments with many different simultaneous gas sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Physiological data</head><p>With physiological data we consider recordings such as electroencephalography (EEG), magnetoencephalography (MEG), electrocardiography (ECG), and wearable sensors for health monitoring. Fig. <ref type="figure" target="#fig_6">11</ref> shows an example of how physiological data look like. The data can exist both as singular or multiple channels. The use of a feature learning algorithm is particularly beneficial in medical applications because acquiring a labeled medical data set is expensive since the data sets are often very large and require the labeling of an expert in the field.</p><p>The work by Mirowski et al. <ref type="bibr" target="#b91">[92]</ref> compares convolutional networks with logistic regression and SVMs for epileptic seizure prediction from intracranial EEG signals. The features that are used are hand-engineered bi-variate features between channels that encode relationship between pairs of EEG channels. The result was that convolutional networks achieved only 1 false-alarm prediction from 21 patients while the SVM had 10 false-alarms. TDNN and ICA has also been used for EEG-based prediction of epileptic seizures <ref type="bibr" target="#b90">[91]</ref>. The application of self-organizing maps (SOM) to analyze EMG data is presented by Tucker <ref type="bibr" target="#b121">[122]</ref>.</p><p>A RBM-based method that builds features from raw data for sleep stage classification from 4-channel polysomnography data has been proposed by L?ngkvist et al. <ref type="bibr" target="#b69">[70]</ref>. A similar setup was used by Wulsin et al. <ref type="bibr" target="#b128">[129]</ref> for modeling single channel EEG waveforms used for anomaly detection. A DBN is used by Wang and Shang <ref type="bibr" target="#b125">[126]</ref> to automatically extract features from raw unlabeled physiological data and achieves better classification than a feature-based approach. These recent works show that DBNs can be applied to raw physiological data to effectively learn relevant features.</p><p>A source separation method tailor-made to EEG and MEG signals is proposed by Hyv?rinen et al. <ref type="bibr" target="#b58">[59]</ref>. The data is preprocessed by short-time Fourier transforms and then fed to an ICA. The work shows that temporal correlations are adequately taken into account. Independent Component Analysis (ICA) has provided to be a new tool to analyze time series and is a unifying framework that combines sparseness, temporal coherence, topography and complex cell pooling in a single model <ref type="bibr" target="#b57">[58]</ref>. A method for how to order the independent components for time-series is explored by Cheung and Xu <ref type="bibr" target="#b18">[19]</ref>.</p><p>Self-taught learning has been used with time-series data from wearable hand-motion sensors <ref type="bibr" target="#b1">[2]</ref>.</p><p>The field of physiological data is large and many different methods have been used. The characteristics of physiological data could be particularly interesting for the deep learning community because it can be used to explore the feasibility of learning features from raw data, which hopefully can inspire similar approaches in other time-series domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Summary</head><p>Table <ref type="table" target="#tab_1">2</ref> gives a summary of the time-series problems that have been presented in this section. The first column indicates if the data is multivariate (or only contains one signal, univariate). Stock prediction is often viewed as a single channel problem, which explains the difficulties to produce accurate prediction systems, since stocks depend on a myriad of other factors, and arguably not at all on past values of the stock itself. For speech recognition, the use of multimodal sources can improve performance <ref type="bibr" target="#b97">[98]</ref>.</p><p>The second column shows which problems have attempted to create features purely from raw data. Only a few works have attempted this with speech recognition <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b109">110]</ref> and physiological data <ref type="bibr" target="#b128">[129,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b125">126]</ref>. To the authors knowledge, learning features from raw data has not been attempted in music recognition. The process of constructing features from raw data has been well demonstrated for vision-tasks but is cautiously used for time-series problems. Models such as TDNN, cRBM and convolutional RBMs are well suited for being applied to raw data (or slightly pre-processed data).</p><p>The third column indicates which time-series problems have valuable information in the frequency-domain. For frequency-rich problems, it is uncommon to attempt to learn features from raw data. A reason for this is that current feature learning algorithms are yet not well-suited for learning features in the frequencydomain. The fourth column displays some common features that have been used in the literature. SIFT and HOG have been applied to videos even though those features are developed for static images. Chroma and MFCC have been applied to music recognition, even though they are develop for speech recognition. The e-nose community have tried a plethora of features. E-nose data is a relatively new field where a hand-crafted feature set have not been developed since this kind of data is complex and unintuitive. For physiological data, the used features are often a combination of application-specific features from previous works or hand-crafted features.</p><p>The fifth column reports the most commonly used method (s), or current state-of-the-art, for each time-series problem. For stock prediction, the progress has stopped at classical neural networks. The current state-of-the-art augments additional information beside the stock data. For high-dimensional temporal data such as video and music recognition, the convolutional version of RBM have been successful. In recent years, the RBM have been used for speech recognition but the current state-of-the-art is achieved with an RNN. The cRBM introduced motion capture data to the deep learning community and it is an interesting problem to explore with other methods. Single layer neural networks with temporal capabilities have been used to model e-nose data and the use of deep networks is an interesting future direction for modeling enose data.</p><p>And finally, the last column indicates a typical benchmark set for each problem. There is currently no well-known publicly available benchmark data set for e-nose data. For deep learning to enter the field of e-nose data it requires a large, well-organized data set that would benefit both communities. A data base of physiological data is available from PhysioNET <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Unsupervised feature learning and deep learning techniques have been successfully applied to a variety of domains. While much focus in deep learning and unsupervised feature learning have been in the computer vision domain, this paper has reviewed some of the successful applications of deep learning methods to the time-series domain. Some of these approaches have treated the input as static data but the most successful ones are those that have modified the deep learning models to better handle time-series data.</p><p>The problem with processing time-series data as static input is that the importance of time is not captured. Modeling time-series faces many of the same challenges as modeling static data, such as coping with high-dimensional observations and nonlinear relationships between variables, however, by simply ignoring time and applying models of static data to time series one disregards much of the rich structure present in the data. When taking this approach, the context of the current input frame is lost and the only time-dependencies that are captured is within the input size. In order to capture long-term dependencies, the input size has to be increased, which can be impractical for multivariate signals or if the data has very long-term dependencies. The solution is to use a model that incorporates temporal coherence, performs temporal pooling, or models sequences of hidden unit activations.</p><p>The choice of model and how the data should be presented to the model is highly dependent on the type of data. Within a chosen model there are additional design choices in terms of connectivity, architecture, and hyperparameters. For these reasons, even though many unsupervised feature learning models offer to relieve the user of having to come up with useful features for the current domain, there are still many challenges for applying them to timeseries data. It is also worth noting that many works that construct useful features from the input data actually still use input data from pre-processed features.</p><p>Deep learning methods offer better representation and classification on a multitude of time-series problems compared to shallow approaches when configured and trained properly. There is still room for improving the learning algorithms specifically for timeseries data, e.g., performing signal selection that deals with redundant signals in multivariate input data. Another possible future direction is to develop models that change their internal architecture during learning or use model averaging in order to capture both short and long-term time dependencies. Further research in this area is needed to develop algorithms for time-series modeling that learn even better features and are easier and faster to train. Therefore, there is a need to focus less on the pre-processing pipeline for a specific time-series problem and focus more on learning better feature representations for a general-purpose algorithm for structured data, regardless of the application.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A 2-layer RBM for static data. The visible units x are fully connected to the first hidden layer h 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig.4. A Recurrent Neural Network (RNN). The input x is transformed to the output representation y via the hidden units h. The hidden units have connections from the input values of the current time frame and the hidden units from the previous time frame.Fig.5. A 2-layer convolutional neural network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Four images from the KTH action recognition data set of a person running at frame 100, 105, 110, and 115. The KTH data set also contains videos of walking, jogging, boxing, hand waving, and handclapping.</figDesc><graphic url="image-4.png" coords="6,120.59,188.50,340.71,92.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Dow Jones Industrial Average (DJOI) over a period of 10 years.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Raw acoustic signal of the utterance of the sentence ''The quick brown fox jumps over the lazy dog''.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 Fig. 9 .Fig. 10 .</head><label>2910</label><figDesc>Fig. 9. A sequence of human motion from the CMU motion capture data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Data from EEG (top two signals), EOG (third and fourth signal), and EMG (bottom signal), recorded with a polysomnograph during sleep.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>A summary of commonly used models for feature learning.</figDesc><table><row><cell>Method</cell><cell cols="4">Temporal relation Memory Typical input size Generative</cell></row><row><cell>RBM</cell><cell>-</cell><cell>-</cell><cell>10-1000</cell><cell>U</cell></row><row><cell>AE</cell><cell>-</cell><cell>-</cell><cell>10-1000</cell><cell>-</cell></row><row><cell>RNN</cell><cell>U</cell><cell>1-100</cell><cell>50-1000</cell><cell>U</cell></row><row><cell>cRBM</cell><cell>U</cell><cell>2-5</cell><cell>50</cell><cell>U</cell></row><row><cell>TDNN</cell><cell>U</cell><cell>2-5</cell><cell>5-50</cell><cell>-</cell></row><row><cell>ANN</cell><cell>-</cell><cell>-</cell><cell>10-1000</cell><cell>-</cell></row><row><cell>GRBM</cell><cell>U</cell><cell>2</cell><cell>&lt;64 ? 64</cell><cell>U</cell></row><row><cell cols="2">ConvGRBM U</cell><cell>2</cell><cell>&gt;64 ? 64</cell><cell>U</cell></row><row><cell>ConvRBM</cell><cell>-</cell><cell>-</cell><cell>&gt;64 ? 64</cell><cell>U</cell></row><row><cell>ConvAE</cell><cell>-</cell><cell>-</cell><cell>&gt;64 ? 64</cell><cell>-</cell></row><row><cell>ST-DBN</cell><cell>U</cell><cell>2-6</cell><cell>10 ? 10</cell><cell>U</cell></row></table><note><p><p>1 </p>http://www.nada.kth.se/cvap/actions/</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>A summary of commonly used time-series problems.</figDesc><table><row><cell>Problem</cell><cell>Multi-variate</cell><cell>Raw data</cell><cell>Frequency rich</cell><cell>Common features</cell><cell>Common method</cell><cell>Benchmark set</cell></row><row><cell>Stock prediction</cell><cell>-</cell><cell>U</cell><cell>-</cell><cell>-</cell><cell>ANN</cell><cell>DJIA</cell></row><row><cell>Video</cell><cell>U</cell><cell>U</cell><cell>-</cell><cell>SIFT, HOG</cell><cell>ConvRBM</cell><cell>KTH</cell></row><row><cell>Speech Recognition</cell><cell>-</cell><cell>(U)</cell><cell>U</cell><cell>MFCC</cell><cell>RBM, RNN</cell><cell>TIMIT</cell></row><row><cell>Music recognition</cell><cell>U</cell><cell>-</cell><cell>U</cell><cell>Chroma, MFCC</cell><cell>ConvRBM</cell><cell>GTZAN</cell></row><row><cell>Motion capture</cell><cell>U</cell><cell>U</cell><cell>-</cell><cell>-</cell><cell>cRBM</cell><cell>CMU</cell></row><row><cell>E-nose</cell><cell>U</cell><cell>U</cell><cell>-</cell><cell>Many</cell><cell>TDNN</cell><cell>-</cell></row><row><cell>Physiological data</cell><cell>U</cell><cell>(U)</cell><cell>U</cell><cell>Many, spectogram</cell><cell>RBM, AE</cell><cell>PhysioNET</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>M. L?ngkvist et al. / Pattern Recognition Letters 42 (2014) 11-24</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>http://marsyas.info/download/data_sets</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>http://mocap.cs.cmu.edu/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">State-of-the-art in stock prediction techniques</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Chourasia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mittra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Res. Electr. Electron. Instrum. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1360" to="1366" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Self-taught learning for activity spotting in on-body motion sensor data</title>
		<author>
			<persName><forename type="first">O</forename><surname>Amft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC 2011: Proceedings of the IEEE International Symposium on Wearable Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="83" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Atsalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Valavanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Surveying stock market forecasting techniques l ?c. Part ii: Soft computing methods</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="5932" to="5941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning Deep Architectures for AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>1312. Dept. IRO</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Universite de Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Unsupervised Feature Learning and Deep Learning: A Review and New Perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno>1206.5538</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>U. Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Input-output HMM&apos;s for sequence processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1231" to="1249" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Scaling learning algorithms towards AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Large-Scale Kernel Machines</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Decoste</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning longterm dependencies with gradient descent is difficult</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Generalized denoising auto-encoders as generative models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno>CoRR abs/1305.6663</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Mobile robots for localizing gas emission sources on landfill sites: is bio-inspiration the way to go?</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Bennetts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Lilienthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trincavelli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Front Neuroeng. 4</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Preemptive identification of optimum fermentation time for black tea using electronic nose</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tudu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bandhopadhyaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhuyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="110" to="116" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep learning of invariant spatio-temporal features from video</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jo-Anne</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2010 Deep Learning and Unsupervised Feature Learning Workshop</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Twitter mood predicts the stock market</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Computational Statistics (COMPSTAT&apos;2010)</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lechevallier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Saporta</surname></persName>
		</editor>
		<meeting>the 19th International Conference on Computational Statistics (COMPSTAT&apos;2010)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Style machines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques</title>
		<meeting>the 27th Annual Conference on Computer Graphics and Interactive Techniques<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press/ Addison-Wesley Publishing Co</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analysis of saffron volatile fraction by td-gc-ms and e-nose</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zalacain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Rodriguez-Mendez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>De Saja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Food Res. Technol</title>
		<imprint>
			<biblScope unit="volume">223</biblScope>
			<biblScope unit="page" from="96" to="101" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Music genre classification via compressive sampling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Iliopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Music Information Retrieval (ISMIR)</title>
		<meeting>the 11th International Conference on Music Information Retrieval (ISMIR)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="387" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Independent component ordering in ica time series analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="145" to="152" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using Bayesian dynamical systems for motion template libraries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Phone recognition with the mean-covariance restricted Boltzmann machine</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="469" to="477" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Audio-based music classification with a pretrained convolutional network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Society for Music Information Retrieval (ISMIR)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Machine learning for sequential data: a review</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural, Syntactic, and Statistical Pattern Recognition</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="15" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to locate an odour source with a mobile robot</title>
		<author>
			<persName><forename type="first">T</forename><surname>Duckett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Axelsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2001">2001. 2001. 2001</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="4017" to="4022" />
		</imprint>
	</monogr>
	<note>ICRA</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bacteria classification using cyranose 320 electronic nose</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Boilot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The behavior of stock-market prices</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Fama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bus</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="34" to="105" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Motor primitives in vertebrates and invertebrates</title>
		<author>
			<persName><forename type="first">T</forename><surname>Flash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hochner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="660" to="666" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Speech-to-text and speech-to-speech summarization of spontaneous speech</title>
		<author>
			<persName><forename type="first">S</forename><surname>Furui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kikuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shinnaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Speech Audio Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="401" to="408" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Electronic Noses, Principles and Applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An electronic nose system to diagnose illness</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Hines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="19" to="24" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An electronic nose system for monitoring the quality of potable water</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Dow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="336" to="341" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey of kernels for structured data</title>
		<author>
			<persName><forename type="first">T</forename><surname>G?rtner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newslett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to forget: continual prediction with LSTM</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Animation from observation: motion capture and motion editing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="51" to="54" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
		<ptr target="&lt;http://circ.ahajournals.org/cgi/content/full/101/23/e215&gt;" />
	</analytic>
	<monogr>
		<title level="m">PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="e220" />
		</imprint>
	</monogr>
	<note>Circulation</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Practical parameterization of rotations using the exponential map</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Grassia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Graph. Tools</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="29" to="48" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 38th International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Shift-invariant sparse coding for audio classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The predictive power of online chatter</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gruhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining</title>
		<meeting>the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Pattern analysis for machine olfaction: a review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gutierrez-Osuna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sens. J</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="189" to="202" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning features from music audio with deep belief networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Society for Music Information Retrieval Conference (ISMIR)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised learning of sparse features for scalable audio classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Music</title>
		<meeting>International Symposium on Music</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Information Retrieval (ISMIR&apos;11</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Electronic noses: a review of signal processing techniques</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Llobet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE Proc. Circuits Devices Syst</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="297" to="310" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Proc. Mag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A practical guide to training restricted boltzmann machines</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">7700</biblScope>
			<biblScope unit="page" from="599" to="619" />
		</imprint>
	</monogr>
	<note>Neural Networks: Tricks of the Trade</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th International Conference on Artificial Neural Networks</title>
		<meeting>the 21th International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Forecasting stock markets using wavelet transforms and recurrent neural networks: an integrated system based on artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2510" to="2525" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Feature learning and deep architectures: new directions for music informatics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Humphrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="461" to="481" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for time series classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>H?sken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stagge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="223" to="235" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bubbles: a unifying framework for lowlevel statistical properties of natural image sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hurri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>V?yrynen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Am. A</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1237" to="1252" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Independent component analysis of short-time Fourier transforms for spontaneous EEG/MEG analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ramkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Parkkonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Hyv?arinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hurri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Image Statistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning a better representation of speech soundwaves using restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="5884" to="5887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">56</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">On autoencoder scoring</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kamyshanska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML-13)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML-13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="720" to="728" />
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Conditional random fields versus hidden markov models for activity recognition in temporal sensor data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Van Kasteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Noulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kr?se</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Conference of the Advanced School for Computing and Imaging (ASCI&apos;08)</title>
		<meeting>the 14th Annual Conference of the Advanced School for Computing and Imaging (ASCI&apos;08)<address><addrLine>The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning invariant features through topographic filter maps</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Le-Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009. 2009</date>
			<biblScope unit="page" from="1605" to="1612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">On the need for time series data mining benchmarks: a survey and empirical demonstration</title>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kasetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Time-delay recurrent neural network for temporal correlations and prediction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="253" to="263" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Conditional random fields: probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Machine Learning</title>
		<meeting>the 18th International Conference on Machine Learning<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Fast classification of meat spoilage markers using nanostructured ZnO thin films and unsupervised feature learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>L?ngkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coradeschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B B</forename><surname>Rayappan</surname></persName>
		</author>
		<idno type="DOI">10.3390/s130201578</idno>
		<ptr target="http://dx.doi.org/10.3390/s130201578" />
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1578" to="1592" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Sleep stage classification using unsupervised feature learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>L?ngkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
		<idno type="DOI">10.1155/2012/107046</idno>
		<ptr target="http://dx.doi.org/10.1155/2012/107046" />
	</analytic>
	<monogr>
		<title level="j">Adv. Artif. Neural Syst</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for electronic nose data applied to bacteria identification in blood</title>
		<author>
			<persName><forename type="first">M</forename><surname>L?ngkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Not all signals are created equal: dynamic objective auto-encoder for multivariate data</title>
		<author>
			<persName><forename type="first">M</forename><surname>L?ngkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning hierarchical invariant spatiotemporal features for action recognition with independent subspace analysis</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Representational power of restricted Boltzmann machines and deep belief networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Le Roux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1631" to="1649" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Convolutional networks and applications in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukvuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings International Symposium on Circuits and Systems (ISCASa ?r ?10)</title>
		<meeting>International Symposium on Circuits and Systems (ISCASa ?r ?10)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ekanadham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sparse deep belief net model for visual area V2</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for audio classification using convolutional deep belief networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Largman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1096" to="1104" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Applications of artificial neural networks in financial economics: a survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 International Symposium on Computational Intelligence and Design</title>
		<meeting>the 2010 International Symposium on Computational Intelligence and Design</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page" from="211" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Short-term stock price prediction based on echo state networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="7313" to="7317" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
		<editor>ICCV</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Luenberger</surname></persName>
		</author>
		<title level="m">Introduction to Dynamic Systems: Theory, Models, and Applications</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>L?tkepohl</surname></persName>
		</author>
		<title level="m">New Introduction to Multiple Time Series Analysis</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">The efficient market hypothesis and its critics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Malkiel</surname></persName>
		</author>
		<idno type="DOI">10.2307/3216840</idno>
		<ptr target="http://dx.doi.org/10.2307/3216840" />
	</analytic>
	<monogr>
		<title level="j">J. Econ. Perspect</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Music genre classification using self-taught learning via sparse coding</title>
		<author>
			<persName><forename type="first">K</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Matsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1929" to="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Training deep and recurrent neural networks with hessian-free optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7700</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Stacked convolutional autoencoders for hierarchical feature extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cires ?an</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th International Conference on Artificial Neural Networks</title>
		<meeting>the 21th International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Unsupervised learning of image transformations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Learning to represent spatial transformations with factored higher-order Boltzmann machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1473" to="1492" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Dynamic factor graphs for time series modeling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn. Knowl. Discovery Databases</title>
		<imprint>
			<biblScope unit="page" from="128" to="143" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Time-delay neural networks and independent component analysis for eeg-based prediction of epileptic seizures propagation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence Conference</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Mirowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuzniecky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Machine Learning for Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008. 2008</date>
			<biblScope unit="page" from="244" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Acoustic modeling using deep belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio Speech Lang. Process. Arch</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="22" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Phone recognition using restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="4354" to="4357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Learning feature representations for music classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Learning sparse feature representations for music annotation and retrieval</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">The International Society for Music Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="565" to="570" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Feature-based classification of time-series data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="49" to="61" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Signal Conditioning and Preprocessing, HandBook of Machine Olfaction, Electronic Nose Technology</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Osuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Nagle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kermani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Schiffman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Wiley-Vch Verlag GmbH &amp; Co. KGaA</publisher>
			<biblScope unit="page" from="105" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Unsupervised hierarchical modeling of locomotion styles</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="785" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Language independent gender identification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Parris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1996">1996. 1996. 1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="685" to="688" />
		</imprint>
	</monogr>
	<note>ICASSP-96</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Understanding the exploding gradient problem</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>CoRR) abs/1211.5063</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">An introduction to hidden Markov models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ASSP Mag</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="16" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Self-taught learning: transfer learning from unlabeled data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning</title>
		<meeting>the 24th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Modeling pixel means and covariances using factorized third-order Boltzmann machines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Computer Vision and Pattern Recognition Conference (CVPR 2010)</title>
		<meeting>Computer Vision and Pattern Recognition Conference (CVPR 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Factored 3-way restricted Boltzmann machines for modeling natural images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poultney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS 2006)</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">On random weights and unsupervised feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Constant-q transform toolbox for music processing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schoerkhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klapuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh Sound and Music Computing Conference</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Learning efficient auditory codes using spikes predicts cochlear filters</title>
		<author>
			<persName><forename type="first">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lewicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Unsupervised learning of invariant features using video</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stavens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1649" to="1656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Review of tdnn (time delay neural network) architectures for speech recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sawai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Sympoisum on Circuits and Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="582" to="585" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m">Training recurrent neural networks</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Learning multilevel distributed representations for high-dimensional sequences</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">The recurrent temporal restricted Boltzmann machine</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="page" from="1601" to="1608" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Convolutional learning of spatiotemporal features</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings European Conference on Computer Vision (ECCV&apos;10)</title>
		<meeting>European Conference on Computer Vision (ECCV&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Factored conditional restricted Boltzmann machines for modeling motion style</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Machine Learning (ICML)</title>
		<meeting>the 26th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Modeling human motion using binary latent variables</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">Composable, distributed-state models for high-dimensional time series</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Direct identification of bacteria in blood culture samples using an electronic nose</title>
		<author>
			<persName><forename type="first">M</forename><surname>Trincavelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coradeschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>S?derquist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thunberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="2884" to="2890" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Combining multiple feature selection methods for stock prediction: union, intersection, and multi-intersection approaches</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Hsiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decis. Support Syst</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="258" to="269" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Self-organizing maps for time series analysis of electromyographic data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks, 1999. IJCNN &apos;99</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="3577" to="3580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">On time series features and kernels for machine olfaction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vembu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vergara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Muezzinoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huerta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="535" to="546" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Gas concentration estimation in ternary mixtures with room temperature operating sensor array using tapped delay architectures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Vito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Castaldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Loffredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Massera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Polichetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nasti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vacca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Quercia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Francia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="309" to="316" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hanazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoust. Speech Signal Process</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="328" to="339" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Modeling physiological data with deep belief networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Inf. Educ. Technol</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Multi-factor Gaussian process models for style-content separation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="975" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Slow feature analysis: unsupervised learning of invariances</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wiskott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="715" to="770" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Modeling electroencephalography waveforms with semi-supervised deep belief nets: faster classification and anomaly measurement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wulsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Litt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neural Eng</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1741" to="2552" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Classification of vintages of wine by artificial nose using time delay neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yamazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ludermir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C P</forename><surname>De Souto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Lett</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1466" to="1467" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">10 Challenging problems in data mining research</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Inf. Technol. Decis. Making</title>
		<imprint>
			<biblScope unit="volume">05</biblScope>
			<biblScope unit="page" from="597" to="604" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">An electronic nose based on solid state sensor arrays for low-cost indoor air quality monitoring applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zampolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Elmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Passini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cardinali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nicoletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Improving pattern recognition of electronic nose data with time-delay neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Balaban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Principe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sens. Actuators B: Chem</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="385" to="389" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Predicting stock index increments by neural networks: the role of trading volume under different horizons</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3043" to="3054" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual invariance with temporal coherence</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2011 Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
