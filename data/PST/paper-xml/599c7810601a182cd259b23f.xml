<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ultrasonic signal classification and imaging system for composite materials via deep convolutional neural networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-02-06">February 6, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Min</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Mechanical and Aeronautical Engineering</orgName>
								<orgName type="institution">Singapore Polytechnic</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiting</forename><forename type="middle">Jacqueline</forename><surname>Chua</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Mechanical and Aeronautical Engineering</orgName>
								<orgName type="institution">Singapore Polytechnic</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Erwin</forename><surname>Wouterson</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Mechanical and Aeronautical Engineering</orgName>
								<orgName type="institution">Singapore Polytechnic</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chin</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kelvin</forename><surname>Ong</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Mechanical and Aeronautical Engineering</orgName>
								<orgName type="institution">Singapore Polytechnic</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ultrasonic signal classification and imaging system for composite materials via deep convolutional neural networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-02-06">February 6, 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">A1F9720EB92289A79CC039903ABAA131</idno>
					<idno type="DOI">10.1016/j.neucom.2016.11.066</idno>
					<note type="submission">Received date: 31 May 2016 Revised date: 11 November 2016 Accepted date: 16 November 2016 Preprint submitted to Neurocomputing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ultrasonic signal classification</term>
					<term>feature extraction</term>
					<term>wavelet transform</term>
					<term>deep convolutional neural networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated ultrasonic signal classification systems are finding increasing use in many applications for the recognition of large volumes of inspection signals.</p><p>Wavelet transform is a well-known signal processing technique in fault signal diagnosis system. Most of the proposed approaches have mainly used lowlevel handcraft features based on wavelet transform to encode the information for different defect classes. In this paper, we proposed a deep learning based framework to classify ultrasonic signals from carbon fiber reinforced polymer (CFRP) specimens with void and delamination. In our proposed algorithm, deep Convolutional Neural Networks (CNNs) are used to learn a compact and effective representation for each signal from wavelet coefficients. To yield superior results, we proposed to use a linear SVM top layer in the training process of signal classification task. The experimental results demonstrated the excellent performance of our proposed algorithm against the classical classifier with manually generated attributes. In addition, a post processing scheme is developed to interpret the classifier outputs with a C-scan imaging process and visualize the locations of defects using a 3D model representation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Ultrasonic methods are the most successful non-destructive testing (NDT) technique for quality assessment and detection of flaws in engineering materials and the pulse-echo is the most commonly used for its simplicity and efficiency <ref type="bibr" target="#b0">[1]</ref>. In this technique, a piezoelectric ultrasonic transducer is used to generate ultrasonic waves which propagate through metal plate. Thus, they are reflected by defect and return back to transducer surface. The same ultrasonic transducer receives the reflected waves and converts them to electrical signals. These signals, called A-scan signals, contain information about the type, size and orientation of the defect <ref type="bibr" target="#b1">[2]</ref>.</p><p>The identification of defects on A-scan signal is not a trivial task and usually called ultrasonic pattern recognition <ref type="bibr" target="#b2">[3]</ref>. The results usually depend on the experience and knowledge of the experts. To minimize errors due to human subjectivity, automatic signal classification system (ASCS) is becoming increasing important and has the advantage of detecting flaws and interpreting ultrasonic signals consistently and accurately <ref type="bibr" target="#b3">[4]</ref>. Some researchers <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref> define three major tasks to such systems: preprocessing raw data, feature extraction and classification. The preprocessing task normalizes the raw data signals values to a suitable range for other tasks. The feature extraction task is responsible to obtain attributes from normalized A-scan signals.</p><p>The obtained attributes must be able to characterize the flaws. Finally the classification task aims to analyze the attributes from an A-scan signal and indicates one from a known set of flaws. The algorithm that implements a classification task is called classifier. Several approaches have been proposed to build a classifier, such as traditional statistical classifiers, rule-base classifiers and learning-base classifiers <ref type="bibr" target="#b6">[7]</ref>, which typical examples are artificial neural network (ANN) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> and support vector machine (SVM) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>As one of the most important techniques, feature extraction will directly affect the accuracy and reliability of signal classification. Deep learning using neural networks develop rapidly recently and have achieved success in a wide range of tasks. We propose to use deep learning to extract powerful representations from the input signals. Instead of low-level handcraft features, we train Convolutional Neural Networks (CNNs) to get high-level features to improve the performance for signal classification. Wavelet transformation can divide the signal gradually in multi-scale by means of dilation and translation. Inspired by <ref type="bibr" target="#b12">[13]</ref>, the wavelet transform coefficients are re-organized into a 2D feature matrix which is taken as the input to the CNNs to facilitate</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T</formula><p>the training process and utilize the convolutional characteristics of CNNs. the deep CNNs is devoted to learn a compact and effective representation for each signal from wavelet coefficients in our framework. In this manner, the proposed deep CNNs is trained as a multi-class classifier to predict the class of the input signals.</p><p>As an alternative to softmax, support vector machine (SVM) is widely used for classification. In <ref type="bibr" target="#b13">[14]</ref>, the L2-SVM objective was used for the output layer of a deep Convolutional Neural Network to obtain more discrimination power of classification. This kind of output layer for classification using the hinge loss as cost function is also proposed in <ref type="bibr" target="#b14">[15]</ref> to make comparison with the commonly applied softmax. Smoother learning curve and slightly increased accuracy are obtained when using this objective in our deep architecture. Thus a linear SVM top layer instead of softmax is proposed to train the networks to yield superior results for signal classification task.</p><p>For defect determination, it is usually beneficial to obtain a two-dimensional representation through a C-scan imaging process <ref type="bibr" target="#b15">[16]</ref>. Other than the C-scan image obtained purely depending on the signal amplitude, we propose a post processing scheme to compute the C-scan image which takes the classifier outputs as input and further create the three-dimensional (3D) model representation to visualize the locations of defects. To our knowledge, it is the first attempt to present the defects in 3D view which provides new potential ways to localize and characterize the defect for ultrasound testing in the future.</p><p>This work conducts a study on ultrasonic signals very similar to each other obtained from artificial inserts in a carbon fiber reinforced polymer (CFRP) plate. Firstly, A process was developed to produce CFRP laminates and artificial defects with void, delamination were collected for our experiments. Then we present an automated signal classification system based on the deep convolutional neural networks to process A-scan signals acquired with the ultrasound transducer. To complement the system, an additional post processing is developed to interpret the classification results with a Cscan imaging process and visualize the locations of defects using a 3D model representation. The flowchart of our proposed approach is shown in 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Contributions</head><p>The main contribution of this work is three-fold:</p><p>• A deep learning based framework is proposed to classify ultrasonic signals from carbon fiber reinforced polymer specimens in an automated signal classification system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T • A linear SVM top layer is used in the training process of signal classification task to yield superior results.</p><p>• A post-processing scheme is developed to interpret the classifier outputs and present the defects in 3D view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Related work</head><p>In the last years, various efforts have been made in devising an automated signal classifications system such that we restrict the discussion to the most important aspects including feature selection techniques and classification algorithms.</p><p>Simone et al. <ref type="bibr" target="#b8">[9]</ref> presented serval techniques including discrete Gabor transform, discrete wavelet transform (DWT) and clustered DWT methods for ultrasonic signals classification. ANN are trained based on the these features and the results demonstrated the effectiveness of the clustered DWT method for feature extraction. Matz et al. <ref type="bibr" target="#b9">[10]</ref> used the DWT based method for filtering of ultrasonic signal in combination with SVM to automatically classify ultrasonic signals of in the form of different fault echoes. Cacciola et al. <ref type="bibr" target="#b10">[11]</ref> proposed an heuristic approaches based on the use of DWT and PCA in feature extraction and selection. The SVM classifier trained on these features has good performance for classifying the ultrasonic echoes measured on defective CFRP specimen. Wang <ref type="bibr" target="#b4">[5]</ref> utilized the DWT and wavelet packet transform (WPT) for feature extraction. ANNs and SVMs are trained to validate the effectiveness of different wavelet transform based features for classifying the ultrasonic flaw signals from CFRP specimens. Like most of the methods mentioned above, we adopted wavelet transform based methods for feature extraction in this paper due to the non-stationary characteristics of ultrasonic flaw signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>For the classification purposes, the classifiers of choices are mainly learningbased classifier, which typical examples are ANN and SVM. recently as a subfield of machine learning, deep learning have been widely applied in traditional artificial intelligence domains such as natural language processing <ref type="bibr" target="#b16">[17]</ref>, transfer learning <ref type="bibr" target="#b17">[18]</ref> and computer vision <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> and many more. we refer the reader to a recent more complete survey <ref type="bibr" target="#b20">[21]</ref>. Hong et al. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> proposed hypergraph regularized autoencoder for feature extraction with deep learning for image-based human pose recovery. Yu et al. <ref type="bibr" target="#b23">[24]</ref> developed a deep multi-modal distance metric learning method based on the click and visual features for image ranking. It is worth noting that A-scan signals are very similar to each other and only have subtle variances that are very difficult to classify. In our study, we firstly attempt to use deep learning to process A-scan signals for ultrasonic flaw classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Outline</head><p>This paper is organized as follows. Section 2 gives a brief introduction to the wavelet transform. Section 3 demonstrates the experimental procedure. The deep learning architectures are described in Section 4. Experimental results are presented in Section 5. Section 6 introduces a post processing algorithm to localize and characterize defect information followed by conclusions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Wavelet transform</head><p>The Wavelet Transform is a windowing technique with variable-sized regions, which allows the use of long time intervals to obtain more precise low frequency information and shorter regions where high frequency information is required <ref type="bibr" target="#b24">[25]</ref>. The structure of wavelet packet transform (WPT) is similar to discrete wavelet transform (DWT) <ref type="bibr" target="#b25">[26]</ref>. The main difference in these two techniques is, the WPT can simultaneously break up detail and approximation versions but DWT only breaks up as an approximation version. Therefore, the WPT have the same frequency bandwidths in each resolution and DWT does not have this property. The WPT suits signal processing, especially non stationary signals because the same frequency bandwidths can provide good resolution regardless of high and low frequencies. The principle of WPT is described as follows <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>The wavelet packet function can be defined as</p><formula xml:id="formula_1">W n j,k (t) = 2 j 2 W n (2 j t -k),<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>where j and k are the index of scale and translation operations and n is an operation modulation parameter or oscillation parameter. The first two wavelet packet functions are the scaling and mother wavelet functions: W 0 0,0 (t) = φ(t), W 1 0,0 (t) = ψ(t). When n = 2, 3, • • • , the functions can be defined recursively by the relationship:</p><formula xml:id="formula_2">W 2n 0,0 (t) = √ 2 k h(k)W n 1,k (2t -k), W 2n+1 0,0 (t) = √ 2 k g(k)W n 1,k (2t -k),<label>(2)</label></formula><p>where h(.) and g(.) are the half-band low-pass and high-pass filter associated with the predefined scaling function and mother wavelet function. The coefficients resulting from the decomposition of a signal x(t) can be computed as</p><formula xml:id="formula_3">d n j,k = x(t), W n j,k (t) .<label>(3)</label></formula><p>The framework of WPT algorithm broken up to three resolution levels for signal x(t) is shown in 2. In the figure, D n j represents the symbol for a subspace that stands for the jth resolution and the nth subspace. In the present study, the ultrasonic signals will be broken up to the fourth level j = 4 and Daubechiess wavelet of order 5 is used for filtering. As a result,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>sixteen subspaces (2 j = 2 4 = 16) will be produced for four resolutions and wavelet frequency intervals of each subspace can be computed by</p><formula xml:id="formula_4">((n -1)2 -j-1 f s , n2 -j-1 f s ], n = 1, 2, • • • , 16,<label>(4)</label></formula><p>where f s is sampling frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental procedure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Specimen preparation</head><p>Carbon fibers are increasingly used in the aerospace and automotive industries. Common techniques adopted to manufacture composite structures include conventional hand lay-up method, resin infusion and recently there is a shift towards (tailored) fiber placement and tape laying. All these methods aim to produce composite laminates of good quality with minimum amount of defects, i.e. dry spots, causing delamination in the structures <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>, which could eventually lead to failure. Besides delamination, voids and micro-cracks are commonly found in defects in composite structures.</p><p>A process was developed to produce carbon fiber reinforced plastics (CFRP) with minimum amount of defects. TORAY 12K twill weave carbon fiber fabrics were cut to a length of 310mm and a width of 310mm. Fifteen layers of carbon fabrics were impregnated with two part epoxy resin, Epikote 1006A using hand lay-up method. The layers were placed in between two glass molds to give smooth surfaces, enhancing ultrasonic scanning. The layup was cured under vacuum at room temperature for 24 hours. The average thickness of the CFRP laminates was measured to be 3.6mm. A water-jet cutter was used to cut the laminates to a length of 210mm and a width of 210mm for NDT measurements.</p><p>A similar process was used to produce the CFRP laminates with defects. The type, position and size of each inserted defects were recorded during the fabrication process. Figure <ref type="figure" target="#fig_2">3</ref> shows a sample containing delamination defects of 20mm in size, placed at different depths (i.e. 3rd, 6th, 9th and 12th layer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Signal acquisition and selection</head><p>Olympus Omniscan MX2 was used to scan composite structures for defects. For the CFRP laminates, a 5 MHz near -wall probe with 64 elements and a wedge (SNW1 -0L -AQ25) were used. In order to reduce the noise signals, the CFRP laminates were submerged in water. The A-scan signal was digitized at a sample length of 512. In this study, the inspection was performed on ten specimens of CFRP laminates and artificial defects with void, delamination were collected for our experiments. The database was created consisting of a total number of 6, 000 ultrasonic A-scan signals which were equally divided into the 12 classes: ten delamination classes with layer number 3-7 and 9-13, one void class and one class of signals showing absence of defect. It's noteworthy that, A-scans from delamination defects of neighboring layers are very similar to each other and only have subtle variances that are very difficult to classify using the manually generated attributes from normalized signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Deep learning approach</head><p>In this section, the deep learning approach developed will be introduced. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Signal processing</head><p>After signal processing by using wavelet packet decomposition, the original time domain signal was transformed into the coefficients d n j,k . At four resolutions level, a time series signal with 512 sample points will have 16 subspaces with 32 samples per subband. These coefficients have a defined ordering and therefore can be thought of as information within the original signal in different frequency band. To facilitate the training process of CNNs similar to <ref type="bibr" target="#b12">[13]</ref>, we re-organize the coefficients into a 2D feature matrix with dimensions 32 × 16. Treating the wavelet transform coefficients in this way allows to utilize the capabilities of CNNs to get high-level features which combines signal information from all frequency intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Structure of Deep CNNs</head><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the structure of the deep CNNs in our proposed algorithm. As we can see, 2 convolutional layers, one fully connected layers and one output layer are contained in the deep learning architecture.</p><p>In the first convolutional layer, sixteen 7 × 5 kernel filters are applied to the input coefficient matrix. After the convolution, a non-linearity module with a sigmoid activation function (i.e.sigmoid(x) = (1 + exp(-x)) -1 ) is applied to generate the feature maps. We down-sample the feature maps by a factor of 2 for each dimension to generate sixteen 6 × 13 feature maps.</p><p>In the second convolutional layer, we generate 32 new feature maps by applying 5 × 3 kernel filters to the input feature maps obtained above. The non-linearity mapping followed by sub-sampling are carried out to generate 32 down-sampled 2 × 5 feature maps. In this manner, the coefficients</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>can be non-linearly combined and hierarchically compressed through various convolutional operations in the proposed networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Loss function of signal classification</head><p>For classification problems using deep learning techniques, the standard choice for the activation function at the top layer of a network is the sof tmax function defined by</p><formula xml:id="formula_5">sof tmax(x i ) = e x i j e x j<label>(5)</label></formula><p>with x i and x j being the value of dimension i and j of a vector x. The sof tmax(x i ) specifies a discrete probability distribution and sum up to one by definition. Instead of minimizing the cross-entropy or maximizing the log-likelihood by sof tmax function, the L2-SVM training objective given by min</p><formula xml:id="formula_6">x 1 2 w T w + C n max(0, 1 -y n (w T x n + b)) 2<label>(6)</label></formula><p>is proposed in <ref type="bibr" target="#b13">[14]</ref>. Every output neuron is treated as a linear SVM in this approach. In this way, the output layer of the network becomes a multi-class SVM-predictor, which is trying to find the maximum margin between signal points of different classes. The main difference to a normal linear multi-class SVM-predictor is that, the inputs to the SVMs are heavily transformed by previous layers of the network. In this paper, we use L2-SVM's objective as the loss function to train deep CNNs for signal classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Manually generated features</head><p>To investigate how well deep CNNs would perform on hand-crafted features, we also implement two exemplary ways of hand-crafting features for comparison.</p><p>Statistical parameters: A feature vector S of eight informative features were extracted from the WPT coefficients representation of each signal <ref type="bibr" target="#b4">[5]</ref>: Shannon entropy: Entropy is a measure of uncertainty that is used in various fault conditions. For ultrasonic signals with different flaws, the entropy at given scales are always varied and can be considered as an important feature for classification. By using WPT decomposition, the wavelet entropy is applied to wavelet coefficients and can be calculated as <ref type="bibr" target="#b31">[32]</ref>:</p><formula xml:id="formula_7">1. Mean value: M = 1 N N i=1 x i 2. Standard deviation: V = 1 N -1 N i=1 (x i -m) 2</formula><formula xml:id="formula_8">E j,i = k d n2 j,k log(d n2 j,k ), (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>where d n j,k is the WPT coefficients of the subspace after wavelet packet decomposition. Let E 4,i (i = 0, 1, • • • , 15) denote the sequence of the entropy of WPT decomposition at the fourth level, then a feature vector T can be expressed as</p><formula xml:id="formula_10">T = [E 4,0 , E 4,1 , • • • , E 4,14 , E 4,15 ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and discussion</head><p>The performance of the proposed approach was tested on a test data set consisting of A-scan signals collected from ten specimens. As described in Section 3, the signals consist of 10 classes of delamination (3th-7th layers and 9th-13th), one class of void and one class of signals presenting no defect. The number of experimental data is 6,000 in total, consisting of 500 sets per class. The 5,000 data sets are used to training and the rest 1,000 data sets are used to test the recognition rate of the proposed network.</p><p>Table <ref type="table" target="#tab_0">1</ref> summarized the recognition rate of the proposed approach. We can observed that the proposed approach produces consistent classification results. The recognition rates for all classes are consistently above 95%. Typically, A-scan signals from delamination defects of neighboring layers only have subtle variance in their echo peak positions that are very difficult to separate from each other. To overcome this problem, our method hierarchically combines the wavelet transform coefficients by learning a set of weights in different layers of CNNs. In this way, the coefficients can be non-linearly combined and hierarchically compressed through various convolutional operations in CNNs that can be used to effectively discriminate between different classes. Fig. <ref type="figure" target="#fig_5">5</ref> shows the convergency curve of the propose method. Our method can achieve convergency through a few of iterations.</p><formula xml:id="formula_11">A C C E P T E D M A N U S C R I P T</formula><p>To understand the effectiveness of the proposed system, various tests were performed to evaluate the overall approach in the choice of feature extraction and classifier's objective functions in particular. Table <ref type="table" target="#tab_2">2</ref> shows the overall classification results for the proposed classifier with different feature extraction methods. Compared with ours, the other two methods perform poorly for the classification results. The shannon entropy is better than the statistical parameters. Obviously, the statistical and entropy features of WPT coefficients can not effectively describe the characteristics of ultrasonic signals for different flaws because it is hard to select the features with the best discrimination power. The proposed network performs much better than hand-crafting features owing to its ability to learn powerful representation from input signals.</p><p>Table <ref type="table" target="#tab_4">3</ref> shows a comparison of classification accuracies for the proposed network using different loss functions at the top. Overall the L2-SVM outperforms the sof tmax due to its higher generalization capability for classification problem. Therefore, the L2-SVM's objective provides a better classification and has been selected as the performing scheme for our classification task.</p><p>As described in subsection 1.2, wavelet transform based methods are   mostly adopted for feature extraction. For the purpose of comparison with the state-of-the-arts, we performed signals classification task with different learning-based classifiers using the features represented by WPT coefficients. Table <ref type="table" target="#tab_5">4</ref> summarized the classification accuracies using our algorithm and the algorithm proposed in <ref type="bibr" target="#b4">[5]</ref> where we chose the best feature extraction strategy for the two classifiers ANN and SVM. The experimental results show that, although all three classifiers achieved effectiveness in the recognition, however, the deep learning based classifier proposed in our approach outperforms the other two popular classifiers.</p><formula xml:id="formula_12">A C C E P T E D M A N U S C R I P T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Post processing for defect determination</head><p>In this section, we developed a post processing scheme to localize and characterize defect information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Representation of ultrasound signals</head><p>The ultrasonic signals can be represented in different ways for defect determination, as shown in Figure <ref type="figure" target="#fig_7">6</ref>. The A-scan shows the amplitude of the signals acquired with ultrasound sensors. Despite A-scan is the common representation used in non-destructive testing, it is usually beneficial to obtain a two-dimensional representation through a C-scan imaging process for defect determination <ref type="bibr" target="#b15">[16]</ref>. The C-scan shows the top view of the sample parallel to the scanning surface. By the means of integrating amplitudes of A-scan signals within a time range over the surface, the C-scan image is able to confirm the presence of a defect in the sample according to the changes in amplitude.</p><p>While moving the probe on the surface of the sample, it was observed that the A-scan signal kept varying in amplitude, suggesting it to be a good indicator for the presence of defects however maybe too sensitive to the random noise during the scanning procedure. This will influence the C-scan imaging process and the C-scan image purely depending on the amplitude is not reliable for defect determination. Thus a C-scan imaging process that  relies on the signal classification is required to provide a high confidence of C-scan representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">C-scan imaging process</head><p>Experiments on the proposed classifier have shown its performance in ultrasonic signal classification and can be utilized as the input to the C-scan imaging process to further characterize the detection area.</p><p>As an alternative for traditional C-scan imaging process, our C-scan image is produced according to the following steps:</p><p>• With the proposed classifier, A-scan signal is indicated as a known type of defect classes which are provided as input for the C-scan imaging of the sample</p><p>• For signal points in each defect class, a connect component labeling is performed on the C-scan image to further determine the defect area on the sample.</p><p>• We retain the points with neighbors belonging to the same class on the image and eliminate the others from C-scan image as random noise Figure <ref type="figure">7</ref> shows an example for the C-scan imaging process. Figure <ref type="figure">7a</ref> is naive C-scan image produced purely depending on the amplitude of raw</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>A-scan signals. The different color-coding of the defects indicates the various depths at which the defects are located. Despite naive C-scan image roughly confirms the presence of the defects, the imaging process seems too sensitive to the amplitude change of A-scan signal and contains signal points which should be treated as random noise. Instead of traditional C-scan imaging process, we utilize the classification of A-scan with the classifier to determine whether the signals indicated as defect in naive C-scan actually indicate the presence of a defect or not. Compared with the naive C-scan, we can provide a high confidence of C-scan representation to ensure the reliability of defect determination. In Figure <ref type="figure">7b</ref>, A-scan signal classification by the proposed classifier are used as input for the C-scan imaging process and the obtained C-scan image shows a clear view of defects parallel to the scanning surface, which are perfectly match with the defects placed during the fabrication of the specimen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">3D visualization of defect</head><p>Although the C-scan representation confirms the presence of defects through showing a clear top view of the sample parallel to the scanning surface, it lacks the locations information of the defects. Thus it would be very helpful if we can visualize the locations of defects in 3D model representation. In this study, we further reconstruct the defects in 3D model showing a clear visualization of the locations of various defects.</p><p>The reconstruction of defects is described as follows:</p><p>• For signal point in each defect class, the location is indicated as the peak position of A-scan amplitude which is nearest to the layer location of the defect class it belongs to</p><p>• According to the estimated locations, the 3D model representation is crated through a smooth surface fitting for each defect class Figure <ref type="figure">8</ref> shows another example for CFRP laminates with defects of various sizes at various depths. All four defects of various size are visible in the C-scan image shown in Figure <ref type="figure">8a</ref>. However, we cannot see any differences or trends of the defect locations for signal points within each defect class from the top view of sample. To overcome this problem, the defects are reconstructed in 3D representation model showing a clear visualization of the locations of defects. A 3D model representation that displays the locations of various defects at various depths is shown in Figure <ref type="figure">8b</ref>. we can observe that,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T the 3D locations of defects are varied for signal points within the same defect class which maybe caused by the fabrication of the sample. Compared with the C-scan, 3D visualization of defects is capable of providing richer information for defect locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper, we propose an automatic ultrasonic signal classification system using deep convolutional neural networks and signal processing techniques. A digital flaw detector is first used to acquire the signals of defective CFRP specimens with void and delamination. The networks are trained by signal classification task based on wavelet transform coefficients. Compared to the hand-crated features, the network trained is capable of learning informative features that could discriminate the defect classes consistently. To further improve the classification rate, we use a deep linear SVM at the top layer to find the maximum margin between signals of different classes. In the classification, the experimental results show that the algorithm developed was effective in classifying the defect signals obtained through ultrasonic testing. For defect determination, a post processing scheme is developed to interpret the classifier outputs with a C-scan imaging process and visualize the locations of defects using a 3D model representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgements</head><p>We would like to thank the anonymous reviewers for their detailed comments and valuable suggestions. This project was supported by MOE2013-TIF-2-G-003. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Flowchart of our proposed approach. (a) Data collection including specimen preparation, ultrasound scanning and signal selection is carried out during the experimental procedure; (b) Signal classification tasks are completed through signal processing, deep architecture construction and training/testing. (c) Defect determination is performed through C-scan imaging and 3D visualization representation.</figDesc><graphic coords="5,95.73,152.20,377.93,52.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Tree structures of wavelet packet transform.</figDesc><graphic coords="7,114.63,434.75,340.13,170.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Locations of the delamination defects in CFRP laminate at various depths, i.e. 3rd, 6th, 9th and 12th layer. Four defects of 20mm in size are placed at each depth, color scale for depth goes from red to blue.</figDesc><graphic coords="9,133.52,152.20,302.37,271.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Architecture of the proposed deep CNNs. Here conv, subs, fc stand for convolutional, sub-sampling, fully-connected layers respectively.</figDesc><graphic coords="10,114.63,152.20,340.15,122.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3 .(x i ) 4 .(x i ) 5 .</head><label>345</label><figDesc>Maximum amplitude: M ax = max 1≤i≤N Minimum amplitude: M in = min 1≤i≤N Maximum energy: max 2 (|M ax|, |M in|) A C C E P T E D M A N U S C R I P T 6. Average frequency 7. Frequency of minimum energy samples 8. Half point (HaPo): the frequency that divides up the spectrum into two parts of same area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Training error convergence curve. One iteration error is obtained by averaging the errors of all the training signals.</figDesc><graphic coords="14,133.52,152.20,302.34,182.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Ultrasound signal representation.</figDesc><graphic coords="16,114.63,152.20,340.13,184.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="20,114.63,394.07,340.13,172.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Recognition rate of our proposed approach.</figDesc><table><row><cell></cell><cell>Recognition rate (%)</cell><cell></cell></row><row><cell></cell><cell>Training data</cell><cell>Test data</cell></row><row><cell>Delamination (layer)</cell><cell></cell><cell></cell></row><row><cell>3rd</cell><cell>99.67</cell><cell>98.34</cell></row><row><cell>4th</cell><cell>100</cell><cell>99.41</cell></row><row><cell>5th</cell><cell>99.86</cell><cell>99.17</cell></row><row><cell>6th</cell><cell>99.67</cell><cell>97.26</cell></row><row><cell>7th</cell><cell>99.69</cell><cell>95.75</cell></row><row><cell>9th</cell><cell>99.76</cell><cell>95.4</cell></row><row><cell>10th</cell><cell>100</cell><cell>97.73</cell></row><row><cell>11th</cell><cell>99.94</cell><cell>97.39</cell></row><row><cell>12th</cell><cell>100</cell><cell>98.75</cell></row><row><cell>13th</cell><cell>99.95</cell><cell>98.6</cell></row><row><cell>Void</cell><cell>100</cell><cell>100</cell></row><row><cell>Non defect</cell><cell>100</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overall classification results for the proposed classifier with different feature extraction methods.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Overall classification results for the proposed network using different loss functions at the top.</figDesc><table><row><cell>Recognition rate (%)</cell><cell></cell></row><row><cell>Training data</cell><cell>Test data</cell></row><row><cell>ANN 98.18</cell><cell>95.25</cell></row><row><cell>SVM 98.51</cell><cell>97.63</cell></row><row><cell>CNN 99.87</cell><cell>98.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Overall classification results for different classifiers by using the features represented by WPT coefficients.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biography of the authors</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The use of artificial neural network in the classification of pulse-echo and TOFD ultra-sonic signals</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L B C</forename><surname>Veiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A D</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C D</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M A</forename><surname>Rebello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Brazilian Society of Mechanical Sciences and Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="394" to="398" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic defect classification in ultrasonic ndt using artificial intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sambath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nagaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Selvakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of nondestructive evaluation</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Development of an intelligent system for ultrasonic flaw classification in weldments</title>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nuclear Engineering and Design</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="307" to="320" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ultrasonic signal processing methods for detection of defects in concrete pipes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Tittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Pedrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in Construction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="135" to="148" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wavelet transform based feature extraction for ultrasonic flaw signal classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computers</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="725" to="732" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-time fault diagnosis for gas turbine generator systems using extreme learning machine</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="249" to="257" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Click prediction for web image reranking using multimodal sparse coding, Image Processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2019" to="2032" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A framework for classification of non-linear loads in smart grids using artificial neural networks and multi-agent systems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D O</forename><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Bernardes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Asada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="page" from="328" to="338" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Feature extraction techniques for ultrasonic signal classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Simone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morabito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Polikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ramuhalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Udpa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Udpa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Electromagnetics and Mechanics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Classification of ultrasonic signals</title>
		<author>
			<persName><forename type="first">V</forename><surname>Matz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kreidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Smid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Materials and Product Technology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="145" to="155" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Computational intelligence aspects for defect classification in aeronautic composites by using ultrasonic pulses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cacciola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Calcagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Morabito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Versaci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on ultrasonics, ferroelectrics, and frequency control</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="870" to="878" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recent advances on svm based fault diagnosis and process monitoring in complicated industrial processes</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="643" to="650" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3d mesh labeling via deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep learning using linear support vector machines</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Challenges in Representation Learning, ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepfish: Accurate underwater live fish recognition with a deep architecture</title>
		<author>
			<persName><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluation of ultrasonic inspection and imaging systems for concrete pipes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Pedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Tittmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in construction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="149" to="164" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups, Signal Processing Magazine</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>-R. Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A unified approach to transfer learning of deep neural networks with applications to speaker adaptation in automatic speech recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<pubPlace>Neurocomputing</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pedestrian detection with unsupervised multi-stage feature learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3626" to="3633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">High-order distance-based multiview stochastic learning in image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cybernetics, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2431" to="2442" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning for visual understanding: A review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oerlemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="27" to="48" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multimodal deep autoencoder for human pose recovery</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5659" to="5670" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hypergraph regularized autoencoder for image-based 3d human pose recovery</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="132" to="140" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep multimodal distance metric learning using click constraints for image ranking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ultrasound image segmentation by using wavelet transform and self organizing neural network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>İşcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Kurnaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dokur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ölmez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Information Processing-Letters and Reviews</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="8" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic frequency-domain discrete wavelet transform for better detection of bearing faults in induction motors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="page" from="206" to="216" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wavelet packet feature extraction for vibration monitoring, Industrial Electronics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="650" to="667" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Support vector machines and wavelet packet analysis for fault detection and identification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Syrmos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3449" to="3456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A novel intelligent method for mechanical fault diagnosis based on dual-tree complex wavelet packet transform and multiple classifier fusion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="837" to="853" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nondestructive inspection of composite structures: methods and practice</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th World Conf. Nondestruct. Test</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Application of ultrasonic c-scan techniques for tracing defects in laminated composite materials, Strojniški vestnik</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Badogiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Tsouvalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mechanical Engineering</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="192" to="203" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An expert system for fault diagnosis in internal combustion engines using wavelet packet transform and neural network</title>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert systems with applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="4278" to="4286" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
