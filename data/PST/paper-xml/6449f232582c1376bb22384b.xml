<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fair Graph Representation Learning via Diverse Mixture-of-Experts</title>
				<funder ref="#_8EW3adS">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Brandeis University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zheyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brandeis University</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brandeis University</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yijun</forename><surname>Tian</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Notre Dame</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Erchi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brandeis University</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
							<email>chuang@cs.hku.hk</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Notre Dame</orgName>
								<address>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
							<email>chuxuzhang@brandeis.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Brandeis University</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">Fair Graph Representation Learning via Diverse Mixture-of-Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3543507.3583207</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph Representation Learning</term>
					<term>Mixture-of-Experts</term>
					<term>Fairness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Neural Networks (GNNs) have demonstrated a great representation learning capability on graph data and have been utilized in various downstream applications. However, real-world data in web-based applications (e.g., recommendation and advertising) always contains bias, preventing GNNs from learning fair representations. Although many works were proposed to address the fairness issue, they suffer from the significant problem of insufficient learnable knowledge with limited attributes after debiasing. To address this problem, we develop Graph-Fairness Mixture of Experts (G-Fame), a novel plug-and-play method to assist any GNNs to learn distinguishable representations with unbiased attributes. Furthermore, based on G-Fame, we propose G-Fame++, which introduces three novel strategies to improve the representation fairness from node representations, model layer, and parameter redundancy perspectives. In particular, we first present the embedding diversified method to learn distinguishable node representations. Second, we design the layer diversified strategy to maximize the output difference of distinct model layers. Third, we introduce the expert diversified method to minimize expert parameter similarities to learn diverse and complementary representations. Extensive experiments demonstrate the superiority of G-Fame and G-Fame++ in both accuracy and fairness, compared to state-of-the-art methods across multiple graph datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, GNNs have gained a significant of attentions on various web-based applications, including node classification <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b43">44]</ref>, link prediction <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>, scene graph reasoning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b52">53]</ref>, and recommendation system <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>. Most GNNs leverage message passing, a fundamental technique introduced by <ref type="bibr" target="#b15">[16]</ref>, to perform calculations and make predictions. However, message passing-based GNNs are vulnerable to sensitive attributes (e.g. race, gender, and nationality) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b21">22]</ref>, which leads to unfair graph representations. Furthermore, message passing exacerbates the unfair learning given nodes aggregate sensitive attributes from their neighbors. Hence, it is necessary to come up with effective graph fairness algorithms to overcome the vulnerability issue and fairness problem in graph representation learning <ref type="bibr" target="#b7">[8]</ref> .</p><p>Numerous works have been proposed to address the fairness problem on GNNs, where the concentrations can be mainly divided into two categories: individual fairness <ref type="bibr" target="#b13">[14]</ref> and group fairness <ref type="bibr" target="#b2">[3]</ref>. Individual fairness methods ensure to generate similar predictions to similar nodes <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33]</ref>, while group fairness approaches assign equal weights to different groups so that no group receives any preference <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref>. Later, some studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b48">49]</ref> have been proposed to solve the graph fairness problem via a dyadic approach, which requires the prediction of two groups to be completely independent of their sensitive attributes. Most of the existing algorithms construct an augmented graph by deleting biased attributes or removing prejudiced information <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b38">39]</ref>, resulting in limited learnable knowledge and discouraging GNNs from learning more distinguishable representations.</p><p>For investigating the limited learnable knowledge, we begin by comparing the statistical distributions between the latent node representations on the standard graph and the fairness-aware augmented graph. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, the statistical distributions of the input graph under standard and fairness settings are quite similar. In addition, the running variables generated by the model during fairness training are grouped together (i.e., the points are overlapped) while more diverse on standard training (i.e., points are well dispersed). Compared to the distribution of the standard setting, the batch normalization distribution under the fairness setting lacks representation diversity across different model layers, providing deficient learnable knowledge. Therefore, it is challenging to maintain the performance of graph fairness training with limited knowledge on fairness augmented graphs, compared to the standard training.</p><p>To address the challenge of the limited learnable knowledge on fairness training, we develop Graph-Fairness Mixture of Experts (G-Fame), a novel plug-and-play method to assist any GNNs learn distinguishable representations with unbiased attributes. In particular, G-Fame is composed of multiple expert neural networks that each contains its own parameters to learn different knowledge for diversifying node representations. In addition, to improve the and figure (c), as the model becomes more complex, the differences between the two distributions grow.</p><p>model resistance against deficiency of learnable knowledge, we propose G-Fame++, in which we design three different strategies from different perspectives: (1) from node representation perspective, we introduce embedding diversity regularization to enable nodes to capture more different information from their neighbors during the message passing process; (2) from layer perspective, we design layer diversity regularization to diversify the outputs of different layers so that the shallow layers and deeper layers can obtain disparate representations;</p><p>(3) from the parameter weight redundancy perspective, we present expert weight regularization to diversify the weight parameters of experts so that each of them can capture different information. To summarize, our contributions lie in the following aspects:</p><p>? To the best of our knowledge, this paper is the first attempt to study the deficiency of learnable information under the fairness setting. We discover that the standard and fairness-aware augmented graphs contain different statistical distributions, making it challenging for current GNNs to learn. ? To address the problem, we propose G-Fame, a novel plug-andplay method to assist any GNNs learn distinguishable representations. In addition, we propose G-Fame++ to further improve the diversity by designing three regularization methods from perspectives of node representations, model layer, and parameter redundancy.</p><p>? Extensive experiments on multiple datasets demonstrate the superiority of G-Fame and G-Fame++ over state-of-the-art methods across different AUC/accuracy and fairness metrics on fairness graph learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Graph Neural Networks. In recent years, numerous GNNs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b53">54]</ref> were proposed to encode complicated graphstructured data, which utilize the message-passing mechanism to learn node representations. For instance, GAT <ref type="bibr" target="#b42">[43]</ref> develops an attention mechanism to aggregate features from nodes with different weights. GraphSAGE <ref type="bibr" target="#b18">[19]</ref> is a framework for inductive learning that implements an efficient aggregation function to learn node representations from neighbor nodes. DeepGCNs <ref type="bibr" target="#b27">[28]</ref> and GCNII <ref type="bibr" target="#b4">[5]</ref> try to alleviate the over-smoothing problem by aggregating adjacent nodes from multi-hop via residual connections. This message passing paradigm relies on node features and graph structures to learn expressive representations <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>. Recently, Mixture-of-Experts is also introduced into GNN for more robust graph representation <ref type="bibr" target="#b54">[55]</ref>. However, in situations where node features contain sensitive attributes, the performance of GNNs is jeopardized by unfair predictions based on biased inputs. In this paper, we propose to enhance the model capacity in handling sensitive node attributes and producing fair predictions.</p><p>Fair Graph Representation Learning. Though fairness representation has become increasingly popular in recent years, studies under fair graphs learning are still underdeveloped <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b44">45]</ref>. The majority of contemporary works attempt to resolve fairness issues on graphs via fairness-aware augmentations or adversarial training. In particular, <ref type="bibr" target="#b35">[36]</ref> proposed Fairwalk, a random walk-based algorithm that aims to address the fairness issues in graph node embedding method node2vec <ref type="bibr" target="#b17">[18]</ref>. <ref type="bibr" target="#b30">[31]</ref> utilized adversarial training to minimize the marginal difference between vertex representations. Followed by that, <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11]</ref> focused on using GANs <ref type="bibr" target="#b16">[17]</ref> to learn fair graph embeddings and encourage classifier assigning unbiased weight to different groups <ref type="bibr" target="#b34">[35]</ref>. In addition, multiple fairness methods have been designed and applied to various graph applications such as fair private learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref> and fair recommendation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b49">50]</ref>. However, none of those fairness algorithms has been considered to address the insufficient learnable knowledge of graphs. Hence, we propose to enrich the learnable information from fair graph representation learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>Fairness-Based Graph Augmentation. Let ? denote a mask for the adjacency matrix. We define each element ? ? ? ? ? as follows:</p><formula xml:id="formula_0">? ? ? = 1 ? ? ? ? ? ??, ? ? N 0 otherwise ,<label>(1)</label></formula><p>where ? ? ? = 1 represents that two nodes with different sensitive attributes are connected, whereas ? ? ? = 0 represents that two nodes sharing the same sensitive attributes are disconnected. ? is utilized to mask the original adjacency matrix and encourages message passing between different minority and majority groups. As a result, GNNs trained on the modified ? are able to produce more diverse and fair representations than standard graphs that are not modified. Based on the fairness-aware mask ?, a randomized response component ?? (?) is utilized to adjust the strength of the fairness-aware adjacency modification, which can be integrated as follows:</p><formula xml:id="formula_1">?? (? ? ? ) = ? ? ? with probability: ? (? ? ? ) = 1 2 + ? 1 -? ? ? with probability: ? (1 -? ? ? ) = 1 2 -? ,<label>(2)</label></formula><p>where ? ? [0, 1  2 ]. Lastly, the unfair connections (i.e., connecting nodes with the same sensitive attributes) are dropped from the original adjacency matrix:</p><formula xml:id="formula_2">? ? ??? = ? ? ?? (?),<label>(3)</label></formula><p>where ? ? ??? denotes the resulting matrix after dropping the unfair edges and ? indicates the Hadamard product between the original matrix ? and the fairness-aware mask ?. Specifically, with ?? (?), the algorithm promotes fairness by dropping edges between nodes with the same sensitive attributes (i.e., ? ? = ? ? ). When ? = 1 2 , the probability of ? ? ? is 1, which means removing all unfair connections (i.e., those connecting nodes with the same sensitive attributes) from the original graph. Consequently, regardless of the value of ?, the total amount of information in the graph is always decreasing after the mask's modification. </p><p>where L (D; ? ) represents the loss of any downstream tasks (e.g., the link prediction for recommendation systems), ?? ? 2 2 denotes ? 2 regularizer, and ? is a coefficient to adjust its importance. In addition, the fairness constraint ?(?) is often defined as the covariance between sensitive attributes and the signed distance of the feature vectors to the decision boundary <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>Mixture of Experts. Mixture of Experts <ref type="bibr" target="#b37">[38]</ref> uses a gating network that decomposes a dense layer into a list of expert subnetworks, ? 1 , ? 2 , ..., ? ? , which are trained to process each corresponding task under individual subset. A gating network is developed to select an optimal combination of the expert subnetworks based on the output of each expert. Given the input ?, we denote the output of the gating network as ? (?) = {? ? (?)} ? ?=1 and the ?-th expert output as ? ? (?). The output of the MoE module ? can be formulated as:</p><formula xml:id="formula_4">? = ?? ? ? A ? ? (?)? ? (?),<label>(5)</label></formula><p>where ? denotes the number of experts and A indicates the set of activated top-? expert subnetworks. The gating network ? (?) enables the activated experts to have the same size as the normal network, hence promoting the efficient learning of a large network.</p><p>In particular, we calculate the gate value for ?-th expert as follows:</p><formula xml:id="formula_5">? ? (?) = exp(? (?) ? ) ? ?=0 exp(? (?) ? ) ,<label>(6)</label></formula><p>where ? (?) denotes a function to compute the weight of each expert given the current input ?, and ? (?) ? , ? (?) ? indicate the ?-th and ?-th value of the obtained weight of the corresponding expert in the current layer, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY</head><p>In order to address the fairness training problem mentioned in the introduction, we first present G-Fame, a novel mechanism that can aid any GNNs in learning distinguishable representations under the fairness setting (Figure <ref type="figure" target="#fig_3">2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">G-Fame: Graph-Fairness Mixture of Experts</head><p>The pipeline of G-Fame is shown in Figure <ref type="figure" target="#fig_3">2</ref> (a). G-Fame can be applied to any GNNs by substituting each GNN layer with a plug and play G-Fame layer, in order to learn distinct representations. Each G-Fame layer introduces multiple expert networks and only activates a subset of them for each input, while each expert is able to capture different aspects of knowledge and learn distinguishable representations. Specifically, given a graph ? = (? , ?), where ? is the node set and ? is the edge set, we extract the node feature vector ? ? for each node ? ? ? . We initialize the input feature ?</p><p>? = ? ? . Subsequently, in order to obtain the learned node representations, G-Fame combines the features of neighboring nodes and then aggregates them to the target node via message passing. This learning procedure can be formulated as follows:</p><formula xml:id="formula_7">? (? ) ? = COMBINE G-FAME (? ) (? (? -1) ? ), ? (? ) ? ) ,<label>(7)</label></formula><formula xml:id="formula_8">? (? ) ? = AGGREGATE G-FAME (? ) (? (? -1) ? ), ?? ? ? (?) ,<label>(8)</label></formula><p>where ?</p><p>(? )</p><p>? represent the feature vectors of node ? at ?-th layer, ? (? ) ?</p><p>indicates the message aggregated to node ? at ?-th layer, N ? is the set of neighbouring nodes for node ?. AGGREGATE(?), COMBINE(?) are the aggregation and combination functions, respectively. In detail, the ?-th G-Fame layer is consist of a set of ? expert fullyconnected networks</p><formula xml:id="formula_9">W (? ) = {? (? ) ? (?)} ? ?=0 and a gating network ? (? ) (?) = {? (? ) ? (?)} ? ?=1</formula><p>. Then, we formulate the ?-th G-Fame layer as follows:</p><formula xml:id="formula_10">G-FAME (? ) (? (? -1) ? ) = ?? ? ? A (? ) ? (? ) ? (? (? -1) ? )? (? ) ? (? (? -1) ? ),<label>(9)</label></formula><p>where A (? ) indicates the set of activated top-? expert networks at ?-th G-Fame layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">G-Fame++: Diversifying Representations From All Levels</head><p>To further enhance the representation diversity of G-Fame, we introduce G-Fame++ with three novel regularization-based strategies including embedding diversity regularization, layer diversity regularization, and expert diversity regularization. Embedding diversity regularization. To enrich the diversity of learned node embeddings, we aim to maximize the agreement between nodes that are proximate to each other (i.e., within ? -hop neighborhood) while pushing away the irrelevant nodes that are far away. In particular, given a node ? ? ? ? and a node ? ? ? N (? ? ), where N (? ? ) is a set of r-hop neighbor nodes of node ? ? , we denote the representations of node ? ? and ? ? as positive pair {? ? , ? ? }. In addition, we randomly select a different node ? ? such that ? is not within the ? -hop neighborhood of node ? ? , i.e., ? ? ? and ? ? ? N (? ? ). Next, we consider the representations of node ? ? and ? ? as negative pair {? ? , ? ? }. Then, we bring positive pairs together while maximizing the distance between negative pairs. The procedure is formulated as follows: ). Layer diversity regularization. Due to the deficiency of learnable knowledge in fairness-aware augmentations caused by high crosslayer similarities, we design a layer diversity regularizer to diversify each layer. In particular, layer diversity regularizer maximizes the output difference across distinct layers and enlarges the discrepancy of learned information between layers:</p><formula xml:id="formula_11">L ?? = -log ? ? ?? exp(sim(? ? , ? ? )/?)</formula><formula xml:id="formula_12">? ?????? (? ? ? , ? ? ? ) = 1 |? | ?? ? ? ?? |? ? ? ? ? ? ? ? ? | ||? ? ? ? || 2 ||? ? ? ? || 2 ,<label>(11)</label></formula><p>where ? ?????? (? ? ? , ? ? ? ) denotes the obtained cosine similarity, ? is the total number of nodes, and ? ? ? , ? ? ? are the learned embeddings from layer ? ? and layer ? ? , respectively. Intuitively, similar crosslayer embeddings indicate that the model cannot diversify different layers and learn distinctive representations for each layer, resulting in poor performance. Therefore, we introduce the contrastive regularization to boost the diversity of cross-layer embeddings and further improve the model learning capability. The regularization term can be defined as follows:</p><formula xml:id="formula_13">? ???????? (? ? ? , ? ? ? ) = - 1 |? | ?? ? ? ?? log exp(? ? ? ? ? ? ? ? ? ) exp(? ? ? ? ? ? ? ? ? ) + exp(? ? ? ? ? ( ? ?? ? ? ? ? ?-1 )) ,<label>(12)</label></formula><p>where ? ???????? (? ? ? , ? ? ? ) is the calculated cross-layer embedding diversity. The rationale behind the contrastive regularization is that it increases the discrepancy between different layers and enforces each layer to learn unique representations. In addition, it improves the learning capacity of each layer by pulling the same node embeddings across layers together while pushing away the embeddings of different nodes. The overall objective function of the all-layer diversity regularization L ?? is defined as:</p><formula xml:id="formula_14">L ?? = ?? ? ? ,? ? ?? | ??? ? ?????? (? ? ? , ? ? ? ) + ? ???????? (? ? ? , ? ? ? ),<label>(13)</label></formula><p>where ? denotes a set of all layers in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expert diversity regularization.</head><p>Although G-Fame is able to learn fairness information via a large number of experts, redundant parameters naturally exist among different experts, preventing the model from obtaining further diversified learnable information. Even worse, the limited learnable knowledge in fairness based augmented graphs induces each expert to obtain similar representations. Hence, to reduce the expert parameter redundancy, we present expert diversity regularization to maximize the difference among experts and obtain expert-wise diversified representations. Specifically, we introduce minimum hyperspherical separation (MHS) <ref type="bibr" target="#b31">[32]</ref> to maximize the separation distance among expert weight vectors:</p><formula xml:id="formula_15">max { ?1 ,..., ?? } ?S ? -1 {L MHS ( ?) := min ??? ? ( ?? , ?? )},<label>(14)</label></formula><p>where L MHS (?) is the separation distance between each weight vector in</p><formula xml:id="formula_16">W = [? 1 ,? 2 , ...,? ? ]. We define ?? = vec(? ? ) | |vec(? ? ) | | 2</formula><p>which means vectorizing one expert weight matrix ? ? then project it onto a unit hypersphere S ? -1 := { ? ? R| || ? || 2 = 1}, and ? (?, ?) represents the shortest distance between two vertices. Accordingly, MHS benefits G-Fame from the following two aspects: 1) reducing the parameter redundancy of experts and facilitating the model to learn diversified learnable information; 2) empowering the model with better optimization and generalization ability (as shown in Figure <ref type="figure">5</ref>). The overall loss function L G-Fame++ for G-Fame++ is the summation of the ground truth cross-entropy loss L ?? , node embedding diversity regularization L ?? , layer-wise diversity regularization L ?? , and expert weight diversity regularization L ??? :</p><formula xml:id="formula_17">L G-Fame++ = L ?? + L ?? + L ?? + L ??? .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>In this section, we conduct extensive experiments to validate the effectiveness of G-Fame and G-Fame++. In addition, we show the ablation study, expressivity analysis, representation diversity analysis, and optimization landscape visualization to demonstrate the superiority of the proposed models in the fairness setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head><p>Datasets and Baseline Models. We test the performance of our methods on three benchmark graph datasets, i.e., ????, ???????? and ??????. The details of the datasets is shown in Appendix C.3.</p><p>For baselines, we compare with general GNN models GCN <ref type="bibr" target="#b26">[27]</ref>, GAT <ref type="bibr" target="#b42">[43]</ref>, GIN <ref type="bibr" target="#b47">[48]</ref>, GraphSAGE <ref type="bibr" target="#b18">[19]</ref> as well as graph fairness learning methods DropEdge <ref type="bibr" target="#b36">[37]</ref> and FairDrop <ref type="bibr" target="#b38">[39]</ref>. Besides, we apply two data augmentation techniques on general GNN models, i.e., node feature masking and edge drop.</p><p>Evaluations Metrics. We utilize AUC/accuracy and fairness metrics to evaluate our models. For AUC/accuracy metrics, we leverage accuracy and area under curve (AUC). For fairness metrics, we use Demographic Parity (DP) <ref type="bibr" target="#b20">[21]</ref> and Equalized Odds (EO) <ref type="bibr" target="#b19">[20]</ref>. Specifically, DP determines the dependency of model predictions on sensitive attributes. EO evaluates whether the subjects have the same true positive rates and false positive rates across protected and unprotected groups. Additional details of evaluation metrics are illustrated in Appendix B.</p><p>Implementation Details. We report the mean and standard deviation of ten independent runs with different data splits and random seeds. We use three experts in each layer and incorporate two G-Fame layers for our model design. In addition, we set learning rate to 0.01, epoches to 1000, and noisy gate rate to 0.01. We use Adam <ref type="bibr" target="#b24">[25]</ref> to optimize the model. Both G-Fame and G-Fame++ are implemented in PyTorch and trained on NVIDIA V100 GPUs. Detailed hyperparameters are shown in Table <ref type="table" target="#tab_3">3</ref> of Appendix A due to the limited space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall Result Comparison</head><p>We conduct link prediction experiments to evaluate the AUC/accuracy and fairness of the proposed methods, which are reported in Table <ref type="table" target="#tab_1">1</ref>). According to the table, we can find that general GNNs (i.e., GCN, GAT) cannot perform well in both standard and fairness settings, with a lower ranking in AUC/accuracy and fairness metrics.</p><p>GNNs with EdgeDrop have a large improvement in performance across all datasets but still fall behind in fairness metrics. On the other hand, fairness algorithms (e.g., FairAdj and GNNs + FairDrop) generally achieve better fairness than AUC and accuracy results. For example, FairAdj with ? 2 = 20 achieves satisfactory results under ?? ? metric. However, the decent fairness obtained by these fairness algorithms comes with a large sacrifice on AUC/accuracy, with poor ranking compared to other baselines. Finally, we observe that G-Fame can outperform other baselines by remarkable margins, which demonstrates the effectiveness of the MoE mechanism.</p><p>In addition, by incorporating the three proposed regularization strategies, G-Fame++ achieves the best overall AUC/accuracy and fairness under eight evaluation metrics, with average rankings of 1, 1, and 1.5 for ????, ???????? , and ??????, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study</head><p>Since we propose G-Fame to learn distinguishable representations and present G-Fame++ with different regularization strategies to further improve the diversity, we conduct the ablation study to validate their effectiveness by answering the following questions: 1) Does G-Fame layer learn more fair features than baselines? and 2) Does G-Fame++ benefit from the proposed three regularizations?</p><p>The associated results are shown in Table <ref type="table" target="#tab_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does G-Fame layer learn more fair features than baselines?</head><p>To answer this question, we replace all G-Fame layers with standard GCNConv layers taken from the backbone, disabling the usage of the MoE mechanism in our model. As shown in Table <ref type="table" target="#tab_2">2</ref>, the absence of G-Fame layer causes the model to lose a significant amount of accuracy (i.e., 5.5% on ????, 12.5% on ???????? , and 4% on ??????), which demonstrates the effectiveness of MoE mechanism in our model. In addition, replacing G-Fame layer leads to worse AUC/accuracy and fairness results, which further indicates the importance of G-Fame layer in facilitating the model's ability to diversify learned fair representations. Does G-Fame++ benefit from the proposed three regularizations? Since G-Fame++ contains different regularization strategies, we analyze their effectiveness by removing each of them individually and then comparing the results. From Table <ref type="table" target="#tab_2">2</ref>, first, we discover that the removal of node diversity regularization negatively impacts not only the AUC/accuracy but also the fairness of the G-Fame++ model, causing a 0.9% loss of accuracy and 2.4 loss of AUC. In addition, from the fairness perspective, this removal drops the average ranking of the model from 1 to 4 when applied to a variety of datasets. This indicates the effectiveness of our node diversity regularization strategy. Second, removing the layer diversity regularization results in a high similarity between different layer outputs.</p><p>As a consequence, it degrades the ranking of the model from 1, 1, 1.5 to ranking 3, 2, and 3.5 on the datasets ????, ???????? , and ??????, respectively. This demonstrates the effectiveness of layer diversity regularization in facilitating distinct layers to produce diversified outputs. Third, the removal of expert diversity regularization results in expert weight parameter redundancy, which inhibits the experts from capturing different aspects of knowledge as well as generating fair predictions. As a result, the G-Fame model's fairness drops from ranking 1, 1, 1.5 to 3.5, 3.5, 4 on the datasets ????, ???????? , and ??????, respectively. This shows the efficacy of expert diversity regularization in enabling the model for learning fair representations. In general, the above comparisons about all three regularizations for different perspectives show that G-Fame++ improves the accuracy and fairness metrics of GNNs against limited learnable information by generating diverse yet useful representations. This is also compatible with the subsequent additional studies in Section 5.4-5.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Expressivity Analysis w.r.t. Fairness</head><p>We compare the expressivity of G-Fame++ and vanilla GCN by showing the distributions of node representations under fairness setting in Figure <ref type="figure">3</ref>. Specifically, we visualize the distributions of node representations from the input, the first Batch Normalization (BN) layer, and the last BN layer. The subfigure 3a shows the distributions of the same input data for both GCN and G-Fame++, with uniform distributions to ensure fair comparison. According to subfigure 3b and subfigure 3c, we observe that GCN and G-Fame++ learn divergent node representation distributions during training. Specifically, in the first BN layer, GCN learns grouped node representation distribution, while the distribution is more scattered and spread out for G-Fame++. As the layer grows deeper, GCN generates a more diversified representation distribution in the last BN layer, but still performs much worse compared to G-Fame++. Generally, G-Fame++ can well capture the limited knowledge and obtain distinguishable representation distributions across layers.</p><p>This phenomenon is further validated by comparing GCN with G-Fame, as shown in Figure <ref type="figure" target="#fig_5">6</ref> in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Representation Diversity Analysis</head><p>For a better understanding and comparison, we visualize the learned node representations of GCN under standard setting, GCN under fairness setting, G-Fame, and G-Fame++ via t-SNE <ref type="bibr" target="#b41">[42]</ref>. As can be seen in Figure <ref type="figure">4</ref>, GCN under standard setting can roughly cluster nodes from different categories while the boundaries between categories are vague. Compared to the standard setting, GCN under the fair setting shows a poor performance on node clustering (i.e., nodes are mixed and unorganized). This demonstrates that GCN cannot fully capture the knowledge from the fairness-aware augmented graph and obtain distinguishable node representations. However, both of our models G-Fame and G-Fame++ are able to distinguish and separate nodes of different categories as well as maintain a clear boundary between each category. Furthermore, nodes within the same category can form a condensed cluster instead of splitting into different small groups. This again shows the effectiveness of G-Fame and G-Fame++ on learning distinguishable node representations under the fairness setting. This observation across different layers is further discussed in Appendix A.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Optimization Landscape Visualization</head><p>To further show the effectiveness of our models, we visualize the 3D loss landscapes <ref type="bibr" target="#b28">[29]</ref> of G-Fame, G-Fame++, and GCN under two settings (i.e., standard and fairness). According to Figure <ref type="figure">5</ref>, we observe that the loss landscape for GCN under the standard setting is more smooth than it under the fairness setting, which shows the difficulty of optimizing the model under the fairness setting. On the other hand, the loss landscape for G-Fame is steeper than GCN under both settings. We ascribe the reason to the large volume of parameters contained in each expert, which significantly increases the difficulty of optimizing the model. However, G-Fame++ can learn a much more smooth landscape compared to G-Fame, thanks to the proposed three regularization strategies. This reveals that our regularizations can alleviate the optimization difficulty induced by fairness-aware augmented graphs, which further demonstrates the efficacy of our overall framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we identify the problem of limited learnable information problem in graph fairness learning. To address this problem, we present G-Fame, a novel plug-and-play method for assisting any GNNs to learn distinguishable representations. Specifically, G-Fame introduces an MoE mechanism that utilizes multiple expert neural networks to capture different aspects of knowledge in the fairness setting. In addition, we propose G-Fame++ with three innovative regularization strategies to further increase the diversity from perspectives of node representations, layers, and experts. Extensive experiments and in-depth studies demonstrate the superiority of G-Fame and G-Fame++ across a variety of accuracy and fairness metrics on multiple benchmark datasets.     ? DropEdge <ref type="bibr" target="#b36">[37]</ref>: a data-augmented technique that alleviates over-fitting problems and reduces the information loss caused by over-smoothing during the training process. It randomly removes a number of edges from the input graph during each training epoch (code). ? FairDrop <ref type="bibr" target="#b38">[39]</ref>: improve fairness in graph representation learning via dropping biased edges. It can also be considered a biased data augmentation technique that can be applied to various datasets and models. The fairness of the algorithm is evaluated based on two tasks: the end-to-end link prediction task and the capability of removing the effect of sensitive attributes from node representations (code).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Hyperparameters</head><p>The hyper-parameters of G-Fame and G-Fame++ are listed in Table <ref type="table" target="#tab_3">3</ref>. Due to the limitation of GPU memory, the output and hidden dimensions for both models on the PubMed dataset are restricted to 128. Similarly, the gating module assigns no more than two experts (? ? 2) in each layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Dataset Details</head><p>We evaluate our proposed G-Fame++ and G-Fame++ under graph fairness learning settings on three real-world citation networks. The data statistics are displayed in Table <ref type="table" target="#tab_4">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Efficiency Analysis</head><p>The efficiency of G-FAME++ is comparable to regular GNN. The complexity of G-FAME++ relies on the activated part, which is a relatively small number, thus the computation complexity of G-FAME++ will not grow rapidly like regular GNN as the hidden dimension increases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Parameter Comparison</head><p>The parameters amount for G-FAME++ (expertnum=4) and existing GCN baseline is 12.0M and 2.2M, respectively. However, during the real training and inference phase, G-FAME++ activates the same number of parameters as the GCN baseline.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distributions of node representations generated by two GNNs trained on standard graphs and fairness-aware augmented graphs. These two distributions are remarkably similar in figure (a). However, as layer grows deeper and deeper, in figure (b) and figure (c), as the model becomes more complex, the differences between the two distributions grow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fairness Training.</head><label></label><figDesc>Given a training dataset D and a model ? ? (?) where ? denotes the model parameters. Fairness training tries to learn distinguishable fair representations under fairness constraints, which can be expressed as the following constraint optimization problem: min ? L (D; ? ) + ??? ? 2 2 , s.t. ?(D; ? ) &lt; 0,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a)). Based on G-Fame, we then design G-Fame++ to comprehensively alleviate the deficiency of learnable information caused by fairness-aware augmented graphs via three regularizers, including i) an embedding diversity regularization to learn distinguishable node representations (Figure2(b)); ii) a layer diversity regularization to minimize the similarity between different layers (Figure 2 (c)); and iii) an expert diversity regularization to reduce expert parameter redundancy (Figure 2 (d)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall framework of proposed methods. In (a) G-Fame++ pipeline, the graph is preprocessed with fairness-aware augmentation to drop the unfair edges and then proceeds to G-Fame layers while partial experts are activated. Then, the final output is regularized towards more diversity from three levels: In (b) embedding diversity regularization, the nodes with similar features are brought closer, whereas the nodes with different features are pulled away. (c) Layer diversity regularization maximizes the difference of different G-Fame layer output to diversify the information. Lastly, (d) expert diversity regularization enriches the weight diversity of each activated expert by maximizing the distance between each weight matrix projected in a hypersphere. The overall loss is consist of original downstream task loss regularized by (b), (c), (d) three components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :Figure 4 :Figure 5 :</head><label>345</label><figDesc>Figure 3: The distributions of node representations in both GCN and our G-Fame++: input layer (figure (a)), after first layer (figure (b)), and after the last layer (figure (c)). Both models have the same input. Red color indicates the GCN under fairness setting, while green color indicates the GCN with G-Fame++ setting. The ? and ? axes represent the running mean and running variance of a channel, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The statistics of the channel-based batch normalization (BN) layer: before transformed by the very first GCN as shown in Figure (a), after the first layer as in Figure (b) shown, and after the last layer as Figure (c) shown. Red color indicates the GCN under fairness setting, while green color indicates the GCN with G-Fame setting. The ? and ? axes represent the running mean and running variance of a channel, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The t-SNE visualization of node embeddings in layer 1 and 2 on fairness-aware augmented ????. Different colors denotes different node category labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>For example, on Cora, the training time of GCN (dim=32 | dim=256) is (5.2 | 8.5) minutes; meanwhile, G-FAME++ (dim=32 and expertnum=4 | dim=32 and expertnum=8) costs (5.5 | 6) minutes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>? ? ?? exp(sim(? ? , ? ? )/?) ? is the temperature parameter, and ? ? , ? ? are node representations of nodes ? ? and ? ? , respectively. The function sim(?) calculates the similarity between two node feature vectors, i.e., sim(? ? , ? ? ) = ? ? ? ? ? /(||? ? || 2 ||? ? || 2</figDesc><table><row><cell>,</cell><cell>(10)</cell></row><row><cell cols="2">where L ?? denotes the obtained embedding diversity regulariza-</cell></row><row><cell>tion loss,</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Overall results of our proposed G-Fame, G-Fame++ with a number of baselines. Bold indicates the best performance and underline indicates the runner-up. ??? ? ??????? and ? . denote the performance of accuracy and AUC. ???????? and ? . denote the fairness metric of ??? ? , ??? ? , ??? ? , ??? ? , ??? ? , and ??? ? . ???. of ??????? denote the average of the overall performance ranking and overall fairness ranking. ??? ? ? ??? ? ? ??? ? ? ??? ? ? ??? ? ? ??? ? ? ? .</figDesc><table><row><cell>Method</cell><cell cols="8">??? ? ??????? Acc. ? AUC ? ? . ???????? ???????</cell><cell>???.</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Link prediction on ????</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GCN [27]</cell><cell>81.0?1.1 88.0?1.0</cell><cell>53.5?2.4</cell><cell>34.8?5.0</cell><cell cols="4">13.6?3.2 17.7?4.1 88.3?3.3 100.0?0.0 6</cell><cell>6</cell><cell>6</cell></row><row><cell>GAT [43]</cell><cell>80.2?1.4 88.3?1.1</cell><cell>54.9?2.9</cell><cell>39.6?4.1</cell><cell cols="4">12.2?2.5 16.5?3.4 90.9?3.5 100.0?0.0 7</cell><cell>9</cell><cell>8</cell></row><row><cell cols="2">GCN+EdgeDrop [37] 82.4?0.9 90.1?0.7</cell><cell>56.4?2.4</cell><cell>36.5?4.3</cell><cell cols="4">12.3?2.6 15.4?3.3 90.2?2.7 100.0?0.0 3</cell><cell>8</cell><cell>5.5</cell></row><row><cell cols="2">GAT+EdgeDrop [37] 80.5?1.2 88.3?0.8</cell><cell>53.7?2.5</cell><cell>37.1?3.2</cell><cell cols="4">18.8?3.6 22.5?4.2 93.6?2.9 100.0?0.0 5</cell><cell>10</cell><cell>7.5</cell></row><row><cell>FairAdj ? 2=5 [30]</cell><cell>75.9?1.6 83.0?2.2</cell><cell>40.7?4.1</cell><cell>20.9?4.3</cell><cell cols="3">18.4?2.8 31.9?7.1 83.8?4.9 98.3?7.2</cell><cell>9</cell><cell>4</cell><cell>6.5</cell></row><row><cell>FairAdj ? 2=20 [30]</cell><cell cols="7">71.8?1.6 79.0?1.9 32.3?2.8 15.8?4.3 23.0?4.2 41.4?5.9 78.3?6.8 98.3?7.2 10</cell><cell>3</cell><cell>6.5</cell></row><row><cell>GCN+FairDrop [39]</cell><cell>82.4?0.9 90.1?0.7</cell><cell>52.9?2.5</cell><cell>31.0?4.9</cell><cell cols="4">11.8?3.2 14.9?3.7 89.4?3.4 100.0?0.0 3</cell><cell>5</cell><cell>4</cell></row><row><cell>GAT+FairDrop [39]</cell><cell>79.2?1.2 87.8?1.0</cell><cell>48.9?2.8</cell><cell>31.9?4.3</cell><cell cols="4">15.3?3.2 18.1?3.5 94.5?2.0 100.0?0.0 8</cell><cell>7</cell><cell>7.5</cell></row><row><cell>G-Fame</cell><cell>82.6?0.7 90.2?1.2</cell><cell>48.8?2.0</cell><cell cols="5">19.5?0.5 10.8?0.7 13.0?0.8 83.3?2.3 100.0?0.0 2</cell><cell>2</cell><cell>2</cell></row><row><cell>G-Fame++</cell><cell cols="2">84.1?2.0 93.8?0.8 44.1?3.6</cell><cell cols="2">15.8?3.7 12.9?2.8</cell><cell cols="3">7.5?2.3 76.7?2.5 100.0?0.0 1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell cols="4">Link prediction on ????????</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GCN [27]</cell><cell>76.7?1.3 86.7?1.3</cell><cell>42.6?3.7</cell><cell>27.9?4.7</cell><cell cols="3">20.6?4.1 22.2?4.6 68.1?3.7 71.4?9.1</cell><cell>7</cell><cell>6</cell><cell>6.5</cell></row><row><cell>GAT [43]</cell><cell>76.3?1.4 85.6?1.9</cell><cell>42.4?2.8</cell><cell>26.4?4.1</cell><cell cols="3">21.1?3.8 25.4?5.6 71.3?5.7 73.4?9.9</cell><cell>8</cell><cell>8</cell><cell>8</cell></row><row><cell cols="2">GCN+EdgeDrop [37] 78.9?1.3 88.0?1.3</cell><cell>44.9?2.5</cell><cell>27.5?4.1</cell><cell cols="3">20.1?2.9 21.6?5.0 71.0?3.4 73.2?9.5</cell><cell>4</cell><cell>7</cell><cell>5.5</cell></row><row><cell cols="2">GAT+EdgeDrop [37] 76.3?0.9 85.6?1.0</cell><cell>42.6?2.5</cell><cell>28.4?5.0</cell><cell cols="3">22.2?5.1 27.6?6.3 76.7?3.0 77.5?8.8</cell><cell>8</cell><cell>10</cell><cell>9</cell></row><row><cell>FairAdj ? 2=5 [30]</cell><cell>78.5?2.2 86.7?2.2</cell><cell>39.2?3.2</cell><cell>19.0?3.9</cell><cell cols="3">17.3?4.4 18.2?5.8 62.6?4.1 47.6?8.8</cell><cell>6</cell><cell>4</cell><cell>5</cell></row><row><cell>FairAdj ? 2=20 [30]</cell><cell cols="2">74.4?2.5 82.5?2.7 31.0?3.1</cell><cell>15.6?3.0</cell><cell>8.8?3.2</cell><cell cols="3">19.7?6.9 56.1?3.8 43.1?7.4 10</cell><cell>2</cell><cell>6</cell></row><row><cell>GCN+FairDrop [39]</cell><cell>79.2?1.4 88.4?1.4</cell><cell>42.6?2.5</cell><cell>26.5?4.2</cell><cell cols="3">18.7?4.0 17.6?5.5 67.7?3.5 64.3?9.5</cell><cell>3</cell><cell>5</cell><cell>3</cell></row><row><cell>GAT+FairDrop [39]</cell><cell>78.2?1.1 87.1?1.1</cell><cell>42.9?2.2</cell><cell>28.3?4.3</cell><cell cols="3">22.5?3.4 25.9?5.2 75.3?3.2 73.4?9.1</cell><cell>5</cell><cell>9</cell><cell>7</cell></row><row><cell>G-Fame</cell><cell>79.8?2.3 89.4?1.7</cell><cell>38.6?3.1</cell><cell>13.5?2.4</cell><cell>11.6?2.2</cell><cell>9.4?2.7</cell><cell>59.1?0.7 47.8?8.6</cell><cell>2</cell><cell>3</cell><cell>2.5</cell></row><row><cell>G-Fame++</cell><cell cols="2">81.5?0.6 91.9?0.1 38.6?0.5</cell><cell cols="2">13.0?1.7 13.6?0.2</cell><cell cols="3">8.5?1.1 55.1?3.4 42.0?1.1 1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell cols="4">Link prediction on ??????</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GCN [27]</cell><cell>88.0?0.4 94.5?0.2</cell><cell>43.9?1.2</cell><cell>13.2?1.4</cell><cell>5.0?1.7</cell><cell>4.9?1.7</cell><cell>57.3?2.0 26.2?3.6</cell><cell>5</cell><cell>4</cell><cell>4.5</cell></row><row><cell>GAT [43]</cell><cell>80.8?0.4 89.4?0.3</cell><cell>42.3?1.7</cell><cell>23.2?1.9</cell><cell>2.3?1.2</cell><cell>5.3?1.2</cell><cell>59.0?1.7 49.7?3.4</cell><cell>6</cell><cell>9</cell><cell>7.5</cell></row><row><cell cols="2">GCN+EdgeDrop [37] 88.0?0.5 94.6?0.3</cell><cell>43.7?1.0</cell><cell>12.8?0.8</cell><cell>6.3?0.7</cell><cell>6.0?1.1</cell><cell>57.5?1.4 26.3?2.3</cell><cell>4</cell><cell>5</cell><cell>4.5</cell></row><row><cell cols="2">GAT+EdgeDrop [37] 80.6?0.9 88.8?0.7</cell><cell>43.5?1.1</cell><cell>24.5?1.9</cell><cell>4.8?1.6</cell><cell>7.5?1.5</cell><cell>60.1?1.9 49.3?3.6</cell><cell>7</cell><cell>10</cell><cell>8.5</cell></row><row><cell>FairAdj ? 2=5 [30]</cell><cell>75.5?2.5 84.1?2.2</cell><cell>32.3?4.7</cell><cell>15.9?4.7</cell><cell>7.3?3.0</cell><cell cols="2">13.8?6.2 53.4?9.9 43.2?9.5</cell><cell>9</cell><cell>7</cell><cell>8</cell></row><row><cell>FairAdj ? 2=20 [30]</cell><cell cols="2">73.8?2.4 82.1?2.0 28.9?4.2</cell><cell>14.0?4.0</cell><cell>7.8?4.0</cell><cell cols="3">16.5?6.7 52.5?9.7 43.5?9.8 10</cell><cell>6</cell><cell>8</cell></row><row><cell>GCN+FairDrop [39]</cell><cell>88.4?0.4 94.8?0.2</cell><cell>42.5?0.5</cell><cell>12.2?0.7</cell><cell>5.6?1.8</cell><cell>5.1?0.9</cell><cell>55.7?1.5 26.6?2.6</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell>GAT+FairDrop [39]</cell><cell>79.0?0.8 87.6?0.7</cell><cell>37.4?0.9</cell><cell>19.7?1.1</cell><cell>2.0?1.0</cell><cell>6.4?1.4</cell><cell>56.8?2.1 47.3?4.1</cell><cell>8</cell><cell>8</cell><cell>8</cell></row><row><cell>G-Fame</cell><cell cols="2">89.4?0.7 95.9?0.2 40.7?0.3</cell><cell>11.7?0.6</cell><cell>4.8?0.9</cell><cell>4.2?1.2</cell><cell>53.0?1.2 26.1?1.0</cell><cell>1</cell><cell>2</cell><cell>1.5</cell></row><row><cell>G-Fame++</cell><cell cols="3">89.2?0.4 95.6?0.07 35.9?0.03 11.0?0.6</cell><cell>2.3?0.2</cell><cell cols="3">1.5?0.04 51.0?0.6 25.8?0.2 2</cell><cell>1</cell><cell>1.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Ablation study results on Graph Fairness Learning Benchmark (i.e ????, ???????? , and ??????). For each dataset, we iteratively remove the three novel components contained in G-Fame and G-Fame++. Bolden represents the best performance and underline indicates the runner-up. ??? ? ??????? and ? . denote the performance of accuracy and AUC. ???????? and ? . denote the fairness metric of ??? ? , ??? ? , ??? ? , ??? ? , ??? ? , and ??? ? . ???. of ??????? denotes the average of the overall performance ranking and overall fairness ranking. ??? ? ? ??? ? ? ??? ? ? ??? ? ? ??? ? ? ??? ? ? ? .</figDesc><table><row><cell>Method</cell><cell cols="9">??? ? ??????? Acc. ? AUC ? ? . ???????? ???????</cell><cell>???.</cell></row><row><cell></cell><cell></cell><cell cols="3">Link prediction on ????</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>G-Fame++</cell><cell>84.1?2.0 93.8?0.8</cell><cell>44.1?3.6</cell><cell cols="6">15.8?3.7 12.9?2.8 7.5?2.3 76.7?2.5 100.0?0.0 1</cell><cell>1</cell><cell>1</cell></row><row><cell>-w/o node diversity</cell><cell>83.2?1.2 91.4?0.7</cell><cell>52.0?2.5</cell><cell>20.0?5.3</cell><cell cols="5">12.2?2.1 12.4?0.6 86.4?0.6 100.0?0.0 3</cell><cell>4</cell><cell>3.5</cell></row><row><cell>-w/o layer diversity</cell><cell cols="2">83.2?1.0 91.3?0.8 43.0?1.5</cell><cell cols="6">16.0?3.9 10.4?2.5 7.5?1.0 80.3?0.8 100.0?0.0 4</cell><cell>2</cell><cell>3</cell></row><row><cell cols="2">-w/o expert diversity 83.5?0.4 93.4?0.4</cell><cell>50.0?1.0</cell><cell>19.3?2.9</cell><cell cols="5">13.4?1.0 14.1?1.5 87.7?1.7 100.0?0.0 2</cell><cell>5</cell><cell>3.5</cell></row><row><cell>G-Fame</cell><cell>82.6?0.7 90.2?1.2</cell><cell>48.8?2.0</cell><cell cols="6">19.5?0.5 10.8?0.7 13.0?0.8 83.3?2.3 100.0 ?0.0 5</cell><cell>3</cell><cell>4</cell></row><row><cell>-w/o G-Fame layer</cell><cell>81.0?1.1 88.0?1.0</cell><cell>53.5?2.4</cell><cell>34.8?5.0</cell><cell cols="5">13.6?3.2 17.7?4.1 88.3?3.3 100.0?0.0 6</cell><cell>6</cell><cell>6</cell></row><row><cell></cell><cell></cell><cell cols="4">Link prediction on ????????</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>G-Fame++</cell><cell>81.5?0.6 91.9?0.1</cell><cell>38.6?0.5</cell><cell cols="2">13.0?1.7 13.6?0.2</cell><cell cols="3">8.5?1.1 55.1?3.4 42.0?1.1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>-w/o node diversity</cell><cell>80.2?0.2 90.3?0.3</cell><cell>40.2?1.0</cell><cell>13.9?0.6</cell><cell cols="4">15.8?1.8 10.5?1.5 62.8?2.0 45.2?15.8</cell><cell>3</cell><cell>4</cell><cell>3.5</cell></row><row><cell>-w/o layer diversity</cell><cell cols="2">80.0?0.4 89.6?0.4 37.9?0.7</cell><cell>14.2?0.8</cell><cell>13.7?1.1</cell><cell>8.7?0.6</cell><cell>55.6?2.7</cell><cell>45.4?4.4</cell><cell>4</cell><cell>2</cell><cell>2</cell></row><row><cell cols="2">-w/o expert diversity 81.0?0.7 91.1?0.3</cell><cell>39.9?0.2</cell><cell>18.5?2.7</cell><cell cols="3">14.3?1.4 11.0?0.6 62.1?2.1</cell><cell>49.0?0.0</cell><cell>2</cell><cell>5</cell><cell>3.5</cell></row><row><cell>G-Fame</cell><cell>79.8?2.3 89.4?1.7</cell><cell>38.6?3.1</cell><cell cols="3">13.5?2.4 11.6?2.2 9.4?2.7</cell><cell>59.1?0.7</cell><cell>47.8?8.6</cell><cell>5</cell><cell>3</cell><cell>4</cell></row><row><cell>-w/o G-Fame layer</cell><cell>76.7?1.3 86.7?1.3</cell><cell>42.6?3.7</cell><cell>27.9?4.7</cell><cell cols="3">20.6?4.1 22.2?4.6 68.1?3.7</cell><cell>71.4?9.1</cell><cell>6</cell><cell>6</cell><cell>6</cell></row><row><cell></cell><cell></cell><cell cols="4">Link prediction on ??????</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>G-Fame++</cell><cell cols="3">89.2?0.4 95.6?0.07 35.9?0.03 11.0?0.6</cell><cell>2.3?0.2</cell><cell cols="3">1.5?0.04 51.0?0.6 25.8?0.2</cell><cell>2</cell><cell>1</cell><cell>1.5</cell></row><row><cell>-w/o node diversity</cell><cell>87.4?0.1 94.2?0.1</cell><cell>50.1?0.4</cell><cell>16.1?0.4</cell><cell>8.6?0.1</cell><cell>7.5?0.3</cell><cell>63.0?0.3</cell><cell>37.2?2.5</cell><cell>5</cell><cell>4</cell><cell>4.5</cell></row><row><cell>-w/o layer diversity</cell><cell>87.5?0.4 94.1?0.1</cell><cell>41.3?0.6</cell><cell>12.4?0.3</cell><cell>4.6?0.3</cell><cell>4.8?0.3</cell><cell>55.1?1.2</cell><cell>28.3?0.4</cell><cell>5</cell><cell>2</cell><cell>3.5</cell></row><row><cell cols="2">-w/o expert diversity 88.8?0.03 95.3?0.1</cell><cell>45.5?0.2</cell><cell>15.7?0.9</cell><cell>6.3?0.9</cell><cell>6.4?0.4</cell><cell>60.2?1.4</cell><cell>36.6?3.5</cell><cell>3</cell><cell>5</cell><cell>4</cell></row><row><cell>G-Fame</cell><cell cols="2">89.4?0.7 95.9?0.2 40.7?0.3</cell><cell>11.7?0.6</cell><cell>4.8?0.9</cell><cell>4.2?1.2</cell><cell>53.0?1.2</cell><cell>26.1?1.0</cell><cell>1</cell><cell>3</cell><cell>1.5</cell></row><row><cell>-w/o G-Fame layer</cell><cell>88.0?0.4 94.5?0.2</cell><cell>43.9?1.2</cell><cell>13.2?1.4</cell><cell>5.0?1.7</cell><cell>4.9?1.7</cell><cell>57.3?2.0</cell><cell>26.2?3.6</cell><cell>4</cell><cell>6</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Hyper-parameters of G-Fame and G-Fame++ for cora, citeseer and pubmed datasets. The ? and ? indicate the number of total experts and activated experts in each layer, respectively. The noisy rate controls the randomness when some expert is activated by the gate module. ? regulates the level of fairness in our model during the training process.</figDesc><table><row><cell>Model</cell><cell></cell><cell>G-Fame</cell><cell></cell><cell></cell><cell>G-Fame++</cell><cell></cell></row><row><cell>Dataset</cell><cell cols="6">Cora CiteSeer PubMed Cora CiteSeer PubMed</cell></row><row><cell>Iteration</cell><cell>500</cell><cell>500</cell><cell>200</cell><cell>500</cell><cell>500</cell><cell>200</cell></row><row><cell>Learning Rate</cell><cell>1e-3</cell><cell>1e-3</cell><cell>1e-3</cell><cell>1e-3</cell><cell>1e-3</cell><cell>1e-3</cell></row><row><cell>Output Dimension</cell><cell>256</cell><cell>256</cell><cell>128</cell><cell>256</cell><cell>256</cell><cell>128</cell></row><row><cell>Hiddent Dimension</cell><cell>256</cell><cell>256</cell><cell>128</cell><cell>256</cell><cell>256</cell><cell>128</cell></row><row><cell>Optimizer</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>n</cell><cell>3</cell><cell>3</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>2</cell></row><row><cell>k</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Dropout</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell><cell>0.5</cell></row><row><cell>Noisy Rate</cell><cell>1e-2</cell><cell>1e-2</cell><cell>1e-2</cell><cell>1e-2</cell><cell>1e-2</cell><cell>1e-2</cell></row><row><cell>?</cell><cell>0.46</cell><cell>0.50</cell><cell>0.46</cell><cell>0.46</cell><cell>0.46</cell><cell>0.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Statistics of three academic network datasets</figDesc><table><row><cell cols="6">Dataset #Nodes #Edges #Feat. #Classes #Avg. Degree</cell><cell>Feat. Range (original)</cell><cell>Download links</cell></row><row><cell>Cora</cell><cell>2,708</cell><cell cols="2">10,556 1,433</cell><cell>7</cell><cell>3.88</cell><cell cols="2">[-2.30, 2.40] https://shorturl.at/bhoY4</cell></row><row><cell>Citeseer</cell><cell>3,327</cell><cell>9,104</cell><cell>3,703</cell><cell>6</cell><cell>2.84</cell><cell cols="2">[-4.55, 1.67] https://shorturl.at/bGTZ6</cell></row><row><cell cols="2">PubMed 19,717</cell><cell>88,648</cell><cell>500</cell><cell>3</cell><cell>4.50</cell><cell cols="2">[-4.55, 1.67] https://shorturl.at/cnEN8</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work is partially supported by the <rs type="funder">NSF</rs> under grants <rs type="grantNumber">CMMI-2146076</rs> and <rs type="funder">Brandeis University</rs>. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of any funding agencies.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8EW3adS">
					<idno type="grant-number">CMMI-2146076</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A ADDITIONAL EXPERIMENTS A.1 Expressivity of G-Fame w.r.t Fairness</head><p>The statistics of the batch normalization layer for G-Fame are shown in Figure <ref type="figure">6</ref>. Here we compare the representations of G-Fame and vanilla GCN under the fairness setting as a complementary for experiments. Specifically, we visualize the distributions of node representations from the input, the first Batch Normalization (BN) layer, and the last BN layer. Subfigure 6a demonstrates the distributions of the uniform input data for both GCN and G-Fame, with same distributions to guarantee the fair comparison. Figure <ref type="figure">6</ref> shows a divergent distribution between G-Fame, and GCN under fairness setting. According to Subfigure 6b and Subfigure 6c, we find out that GCN and G-Fame learn disparate node representation distributions during training. In particular, in the first BN layer, GCN learns mixed node representation distribution, while the BN distribution is more scattered and spread out for G-Fame. As the layer depth increases, GCN produces a more diversified representation distribution in the last BN layer, but still performs not as good as G-Fame. Generally, G-Fame can still maintain an outstanding ability to produce distinguishable representations across layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Representation Diversity across Layers</head><p>We visualize the performance of G-Fame, G-Fame++, and vanilla GCN under the fairness setting via the t-SNE visualization <ref type="bibr" target="#b41">[42]</ref>, which is demonstrated in Figure <ref type="figure">7</ref>. In particular, we show the visualizations of two layers for each model, where layer 1 is the beginning input layer and layer 2 indicates the next proceeding layer after layer 1. According to Figure <ref type="figure">7</ref>, vanilla GCN under fairness setting illustrates a poor performance on node classification tasks due to its mixed and clustered nodes. In addition, GCN under the fairness setting is having a hard time congregating nodes from different categories while the boundary between each category is pretty vague. This phenomenon is alleviated as the layer depth increases but still not satisfying enough. On the other hand, both of our models G-Fame and G-Fame++ are able to distinguish and separate nodes of different categories while maintaining a clear boundary between each category as layer depth increases, which can also be validated in previous experiment 4. Furthermore, nodes under the same category can form a condensed group instead of splitting into different small clusters. This again shows the effectiveness of G-Fame and G-Fame++ on learning distinguishable node representations under the fairness setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B EVALUATION METRICS</head><p>In section 5.1, we briefly demonstrate the general fairness metrics we used in this paper to evaluate and compare the performance of G-Fame and G-Fame++ with other baselines. Let us denote ? ? [0, 1] as a binary target variable and ? = ? (?) as a predictor. Next, we pair each ? with a categorical sensitive attribute ?. Two often used metrics under a such case are Demographic Parity (DP) <ref type="bibr" target="#b20">[21]</ref> and Equalized Odds (EO) <ref type="bibr" target="#b19">[20]</ref>. Demographic Parity (DP): ? satisfies DP if the positive outcome is independent of the value of the sensitive attribute ?, such that:</p><p>If this is shown on a confusion matrix, it requires the positive rate of every part of the protected group to be the same.</p><p>Equalized Odds (EO): ? satisfies EO if the true positive rates and false positive rates between two groups match with each other with different values of sensitive attribute ?:</p><p>For the link prediction task, we focus more on the dyadic fairness metric such that it requires model predictions to be statistically independent of sensitive attributes corresponding to the edges. In <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b38">39]</ref>, the authors proposed three dyadic criteria: mixed dyadic-level protection, group dyadic-level protection, and subgroup dyadic-level protection. Specifically, the fairness in mixed dyadic is determined based on the homophily of the nodes interconnected by each link; the fairness in subgroup dyadic ensures that no subgroups gain unfair advantages in the formation of links. Group dyadic ensures that every node is involved in link creation regardless of the value of their sensitive attributes. Here, we provide more detailed explanations for these metrics:</p><p>? Mixed dyadic <ref type="bibr" target="#b33">[34]</ref>: the fairness is evaluated based on the homogeneity of nodes involved in each edge. In particular, the edge is considered to be an intra-group link if it interconnects a pair of nodes with the same sensitive attribute. Otherwise, it is regarded as an inter-group link. This evaluation metric usually appears in the recommender system to prevent segregation of the users. ? Sub-group dyadic <ref type="bibr" target="#b33">[34]</ref>: the fairness is evaluated based on how representative a subgroup is in the creation of the links (i.e., intra-group and inter-group). In other words, the subgroup dyadic fairness metric aims to protect the balance between all possible intra-group links and inter-group links.</p><p>It makes sure that no certain subgroup is favored over other subgroups. ? Group dyadic <ref type="bibr" target="#b38">[39]</ref>: there is an injective mapping between the node-level and dyadic groups. The group dyadic metric ensures that each node gets involved in the links' creation process whether the value of their sensitive attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C IMPLEMENTATION DETAILS C.1 Baseline Descriptions</head><p>To evaluate the performance of our pipelines on the link prediction task, we compare our models with multiple general GNNs and fairness algorithms to further display their effectiveness:</p><p>? GCN <ref type="bibr" target="#b26">[27]</ref>: a neural network model that implements with layer-wise propagation rule based on a first-order approximation of spectral graph convolutions. (code). ? GAT <ref type="bibr" target="#b42">[43]</ref>: a convolution-style neural network that leverages masked self-attentional layers to assign importance to different nodes within a neighborhood without depending on the entire graph structure (code). ? FairAdj <ref type="bibr" target="#b29">[30]</ref>: learns a fair adjacency matrix during the link prediction task. The algorithm implements a graph variational autoencoder <ref type="bibr" target="#b25">[26]</ref> and two distinct optimization methods to reach a more favorable fairness-utility tradeoff. In particular, one optimization process is for obtaining a fair version of the adjacency matrix while the other one is for an end-to-end link prediction task (code.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Metric-free individual fairness in online learning</title>
		<author>
			<persName><forename type="first">Yahav</forename><surname>Bechavod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">Z</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00075</idno>
		<title level="m">Data decisions and theoretical implications when adversarially learning fair representations</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">On the apparent conflict between individual and group fairness</title>
		<author>
			<persName><forename type="first">Reuben</forename><surname>Binns</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In FAccT</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multisided fairness for recommendation</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00093</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple and deep graph convolutional networks</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhewei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zengfeng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaliang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Say as you wish: Finegrained control of image caption generation with abstract scene graphs</title>
		<author>
			<persName><forename type="first">Shizhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9962" to="9971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Sean</forename><surname>Current</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saket</forename><surname>Gurukar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.11596</idno>
		<title level="m">FairMod: Fair Link Prediction and Recommendation via Graph Modification</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Say no to the discrimination: Learning fair graph neural networks with limited sensitive attribute information</title>
		<author>
			<persName><forename type="first">Enyan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On Structural Explanation of Bias in Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Yushun</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Derr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fairness through awareness</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toniann</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>In ITCS</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05897</idno>
		<title level="m">Censoring representations with an adversary</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Graph neural networks for social recommendation</title>
		<author>
			<persName><forename type="first">Wenqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Heterogeneous temporal graph neural network</title>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>In SDM</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">What&apos;s Fair about Individual Fairness?</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Fleisher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In AAAI</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Arpita</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kleinberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01508</idno>
		<title level="m">Inferential privacy guarantees for differentially private mechanisms</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nati</forename><surname>Srebro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized Demographic Parity for Group Fairness</title>
		<author>
			<persName><forename type="first">Zhimeng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Mostafavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fair graph mining</title>
		<author>
			<persName><forename type="first">Jian</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Jian</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiankai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11069</idno>
		<title level="m">MultiFair: Multi-Group Fairness in Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Shima</forename><surname>Khoshraftar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aijun</forename><surname>An</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.01855</idno>
		<title level="m">A Survey on Graph Representation Learning Methods</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<title level="m">Variational graph auto-encoders</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deepgcns: Can gcns go as deep as cnns?</title>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Visualizing the loss landscape of neural nets</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gavin</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On dyadic fairness: Exploring and mitigating bias in graph connections</title>
		<author>
			<persName><forename type="first">Peizhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengyu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongfu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Information obfuscation of graph neural networks</title>
		<author>
			<persName><forename type="first">Peiyuan</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning with hyperspherical uniformity</title>
		<author>
			<persName><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongmei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Individual fairness for k-clustering</title>
		<author>
			<persName><forename type="first">Sepideh</forename><surname>Mahabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Vakilian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bursting the filter bubble: Fairness-aware network link prediction</title>
		<author>
			<persName><forename type="first">Farzan</forename><surname>Masrour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tyler</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Pang-Ning Tan, and Abdol Esfahanian</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Dana</forename><surname>Pessach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erez</forename><surname>Shmueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">A Review on Fairness in Machine Learning. Comput. Surveys</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fairwalk: Towards fair graph embedding</title>
		<author>
			<persName><forename type="first">Tahleen</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bartlomiej</forename><surname>Surma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DropEdge: Towards Deep Graph Convolutional Networks on Node Classification</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename><surname>Krzysztof Maziarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fairdrop: Biased edge dropout for enhancing fairness in graph representation learning</title>
		<author>
			<persName><forename type="first">Indro</forename><surname>Spinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Scardapane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelio</forename><surname>Uncini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Masked Autoencoders</title>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiwen</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency</title>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Graph Attention Networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deep Graph Infomax. In ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning fair representations for recommendation: A graph-based perspective</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengyang</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Graph neural networks in recommender systems: a survey</title>
		<author>
			<persName><forename type="first">Shiwen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Surveys</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Self-supervised hypergraph transformer for recommender systems</title>
		<author>
			<persName><forename type="first">Lianghao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">How Powerful are Graph Neural Networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Moyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.04520</idno>
		<title level="m">Obtaining Dyadic Fairness by Optimal Transport</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Beyond parity: Fairness objectives for collaborative filtering</title>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bert</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Fairness beyond disparate treatment &amp; disparate impact: Learning classification without disparate mistreatment</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Bilal Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><forename type="middle">Gomez</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Fairness constraints: A flexible approach for fair classification</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Bilal Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Gomez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Look Twice as Much as You Say: Scene Graph Contrastive Learning for Self-Supervised Image Caption Generation</title>
		<author>
			<persName><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youhuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Heterogeneous graph neural network</title>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh V</forename><surname>Chawla</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In KDD</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization</title>
		<author>
			<persName><forename type="first">Chunhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxuan</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanfang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Few-shot knowledge graph completion</title>
		<author>
			<persName><forename type="first">Chuxu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitesh V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
