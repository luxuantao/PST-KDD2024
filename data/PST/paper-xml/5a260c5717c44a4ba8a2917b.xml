<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zeroing neural networks: A survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-06-29">June 29, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Long</forename><surname>Jin</surname></persName>
							<email>longjin@polyu.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Lanzhou University</orgName>
								<address>
									<postCode>730000</postCode>
									<settlement>Lanzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<addrLine>Hung Hom</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shuai</forename><surname>Li</surname></persName>
							<email>shuaili@polyu.edu.hk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<addrLine>Hung Hom</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bolin</forename><surname>Liao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">College of Information Science and Engineering</orgName>
								<orgName type="institution">Jishou University</orgName>
								<address>
									<postCode>416000</postCode>
									<settlement>Jishou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhijun</forename><surname>Zhang</surname></persName>
							<email>auzjzhang@scut.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department">School of Automation Science and Engineering</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510640</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Departmental General Research Fund of Hong</orgName>
								<orgName type="institution">Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Zeroing neural networks: A survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-06-29">June 29, 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">C76482CE02A803559BE67563D30450CA</idno>
					<idno type="DOI">10.1016/j.neucom.2017.06.030</idno>
					<note type="submission">Received date: 7 April 2017 Revised date: 27 May 2017 Accepted date: 16 June 2017 Preprint submitted to Neurocomputing</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Zeroing neural network</term>
					<term>recurrent neural network</term>
					<term>stability</term>
					<term>numerical algorithms</term>
					<term>redundant manipulators</term>
					<term>robust stability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Using neural networks to handle intractability problems and solve complex computation equations is becoming common practices in academia and industry. It has been shown that, although complicated, these problems can be formulated as a set of equations and the key is to find the zeros of them. Zeroing neural networks (ZNN), as a class of neural networks particularly dedicated to find zeros of equations, have played an indispensable role in the online solution of time-varying problem in the past years and many fruitful research outcomes have been reported in the literatures. The aim of this paper is to provide a comprehensive survey of the research on ZNNs, including continuous-time and discrete-time ZNN models for various problems solving as well as their applications in motion planning and control of redundant manipulators, tracking control of chaotic systems, or even populations control in mathematical biosciences. By considering the fact that real-time performance is highly demanded for time-varying problems in practice, stability and convergence analyses of different continuous-time ZNN models are</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Approaches based on neural network for solving various knotty problems have attracted considerable attention in many fields <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3,</ref><ref type="bibr" target="#b0">4,</ref><ref type="bibr" target="#b1">5,</ref><ref type="bibr" target="#b2">6,</ref><ref type="bibr" target="#b3">7,</ref><ref type="bibr" target="#b4">8,</ref><ref type="bibr" target="#b5">9,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11,</ref><ref type="bibr" target="#b8">12,</ref><ref type="bibr" target="#b9">13,</ref><ref type="bibr" target="#b10">14]</ref>. For example, an adaptive fuzzy controller based on neural network is constructed for a class of nonlinear discrete-time systems with discrete-time dead zone in <ref type="bibr">[1]</ref>. An adaptive decentralized scheme based on neural network is presented for multiple-input and multiple-output (MIMO) nonlinear systems with the aid of back-stepping techniques in <ref type="bibr" target="#b10">[14]</ref>. Such a scheme guarantees the uniform ultimate boundedness of all signals in the closed-loop system with respect to mean square. To overcome the design difficulty of nonstrict-feedback structure, Reference [3] uses variable separation technique to decompose the unknown functions of all state variables into a sum of smooth functions of each error dynamic. With the aid of radial basis function neural networks' universal approximation capability, an adaptive neural control algorithm is proposed in <ref type="bibr">[3]</ref>. Authors in <ref type="bibr" target="#b4">[8]</ref> propose a neural network model to generate winner-take-all competition, which has an explicit explanation of the competition mechanism. As a branch of artificial intelligence, recurrent neural network (RNN) models have received considerable investigation in many scientific and engineering fields, which is often exploited for computational problems <ref type="bibr" target="#b11">[15,</ref><ref type="bibr" target="#b12">16,</ref><ref type="bibr" target="#b13">17,</ref><ref type="bibr" target="#b14">18,</ref><ref type="bibr" target="#b15">19,</ref><ref type="bibr" target="#b16">20,</ref><ref type="bibr" target="#b17">21,</ref><ref type="bibr" target="#b18">22]</ref> and nonlinear optimizations are solved by many methods <ref type="bibr" target="#b19">[23,</ref><ref type="bibr" target="#b20">24]</ref> A gradient-based RNN model is presented in <ref type="bibr" target="#b21">[25]</ref> for computing the inversion of a matrix online with guaranteed convergence, which can be deemed as a seminal work in this field. A simplified neural network model is presented in <ref type="bibr" target="#b22">[26]</ref> to solve a class of linear matrix inequality problems, of which the stability and solvability are analyzed theoretically. In general, recurrent neural networks can be divided into two classes: 1) the continuous-time RNNs and 2) the discretetime RNNs. By exploiting a numerical differential formula, a continuous-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>time RNN model can be discretized into a discrete-time one. However, a numerical differentiation rule does not necessarily generate a convergent and stable discrete-time RNN model even though the original continuous-time RNN model is convergent. In addition, if the discrete-time RNN model is coded as a serial-processing program and performed on the digital computer, it can be considered as a numerical algorithm <ref type="bibr" target="#b23">[27]</ref>. As a novel type of RNN specifically designed for solving time-varying problems, zeroing neural network (ZNN) is able to perfectly track time-varying solution by exploiting the time derivative of time-varying parameters. Then, many researchers make progresses along this direction by proposing various kinds of ZNN models for solving problems with different highlights. A detailed survey and summary are necessary for understanding the development of ZNN models as well as their applications. This paper is organized as follows. In Section 2, the descriptions and continuous-time ZNN models are presented, which include the evolution of models, activation functions, finite-time convergence, and integration-enhanced ZNN models. In Section 3, a brief review on the discrete-time ZNN models is presented. In Section 4, the applications of ZNN techniques are also analyzed. Section 5 concludes this paper with finial remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Design Formulas and Various Continuous-Time Models</head><p>Prior to the proposal of ZNN approach, many gradient-related methods had been reported on the solutions of algebraic equations and optimizations, i.e., zero-finding problems <ref type="bibr" target="#b24">[28,</ref><ref type="bibr" target="#b25">29,</ref><ref type="bibr" target="#b26">30,</ref><ref type="bibr" target="#b27">31]</ref>. By constructing a performance index whose minimal point is identical to the solution to the task problem, a typical approach is to design a recurrent neural network evolving along the negative gradient descent to achieve a minimum of the performance index. However, these methods may fail to work well when exploited to the online solution of dynamic problems with time-varying coefficients, which is intrinsically due to the lacking of the compensation to the velocity components of the time-varying coefficients. Therefore, in view of the variability of coefficients, any method designed intrinsically for computing the static problem can no longer guarantee the decrease of the performance index of a time-varying problem, thereby possibly leading to a failure of the task with large residual error. For example, it is observed, investigated and analyzed in <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33,</ref><ref type="bibr" target="#b30">34]</ref> that the residual error of gradient-based neural network (GNN) for solving a time-varying problem can not be eliminated and remains at a <ref type="bibr" target="#b23">[27,</ref><ref type="bibr" target="#b31">35,</ref><ref type="bibr" target="#b32">36]</ref> further point out that, when exploited to solve a time-varying problem, any traditional method that does not exploit the time-derivative information of time-varying coefficients can not converge to the theoretic solution with the residual error proportional to the value of the sampling gap.</p><formula xml:id="formula_0">A C C E P T E D M A N U S C R I P T relative high level. References</formula><p>To solve a time-varying problem in an error-free manner, Zhang et al. present a recurrent neural network for solving the time-varying Sylvester equation, which is depicted in an implicit dynamical system and can be deemed as the seminal work on ZNN <ref type="bibr" target="#b33">[37]</ref>. They further generalize and summarize the design procedures of such a methodology, and analyze the convergence and stability of the corresponding ZNN model for time-varying matrix inversion in <ref type="bibr" target="#b34">[38]</ref>. Specifically, for solving a time-varying matrix inversion problem depicted in the form of</p><formula xml:id="formula_1">A(t)X(t) = I,<label>(1)</label></formula><p>where A(t) ∈ R (n×n) is a smooth matrix with its derivative assumed to be known, I ∈ R (n×n) is the identity matrix, X(t) ∈ R (n×n) is the unknown matrix to be obtained. The core in the design of ZNN model is to construct an error function E(t) = A(t)X(t) -I, which is evidently different from the performance index of gradient-related methods. Then, the ZNN design formula is used to enforce the corresponding E(t) to converge to zero:</p><formula xml:id="formula_2">Ė(t) = -γΦ(E(t)),<label>(2)</label></formula><p>where γ &gt; 0 and Φ(•) is a matrix array of activation function φ(•). Similarly, for the vector-valued time-varying problems <ref type="bibr" target="#b35">[39]</ref>, e.g., the system of linear equation A(t)x(t) = b(t), with A(t) ∈ R (m×n) , x(t) ∈ R n , and b(t) ∈ R m , the error function can be designed as e(t) = A(t)x(t)b(t). Even for the scalarvalued time-varying problems <ref type="bibr" target="#b36">[40,</ref><ref type="bibr" target="#b37">41,</ref><ref type="bibr" target="#b38">42,</ref><ref type="bibr" target="#b39">43]</ref>, e.g., the time-varying 4th root finding problem x 4 (t) = a(t), with a(t) ∈ R and x(t) ∈ R, the error function can be designed as e(t) = x 4 (t)a(t). Note that the matrix-valued (or vector-valued) error function is a decoupled system and thus its ijth (or ith) subsystem, i.e., the scale-valued dynamical system ė(t) = -γφ(e(t)), can be used to analyze the corresponding convergence and stability. By exploiting ZNN design formula to solve different time-varying problems, various ZNN models that exploit the time-derivative information of coefficients can be constructed with their formulations shown in Table <ref type="table" target="#tab_0">1</ref>. In short, any ZNN Dynamic problem Error function ZNN model <ref type="bibr" target="#b37">[41]</ref> 4th root finding e(t) = x 4 (t) ẋ(t) = ȧ(t)-γφ(x 4 (t)-a(t)) 4x 3 (t)</p><formula xml:id="formula_3">A C C E P T E D M A N U S C R I P T</formula><p>x 4 (t) = a(t) -a(t) <ref type="bibr" target="#b40">[44]</ref> Linear system e(t) = A(t)x(t)</p><formula xml:id="formula_4">A(t) ẋ(t) = -Ȧ(t)x(t) A(t)x(t) = b(t) -b(t) + ḃ(t) -γΦ(A(t)x(t) -b(t)) [38] Matrix inversion E(t) = A(t)X(t) A(t) Ẋ(t) = -Ȧ(t)X(t) A(t)X(t) = I -I -γΦ(A(t)X(t) -I) [45] Matrix square E(t) = X(t) Ẋ(t) + Ẋ(t)X(t) = roots finding X 2 (t) -A(t) -γΦ(X 2 (t) -A(t)) -Ȧ(t) X 2 (t) = A(t) [46] Nonlinear e(t) = ẋ(t) = -J -1 (x(t), t) equations f (x(t), t) γΦ(f (x(t), t)) + ∂f (x(t),t) ∂t f (x(t), t) = 0</formula><p>model for solving any time-varying problem can be deemed as an equivalently expansion of the ZNN design formula. Since Zhang et al proposed ZNN models in the 2000s, modified models have been frequently proposed by considering different internal and external factors. Especially, when nonlinear activation functions are incorporated into the network models, stability research has gained significant progress. A brief review on the design of continuous-time ZNN models for various problems solving is presented in <ref type="bibr" target="#b43">[47]</ref>. However, with the rapid development of the theory on ZNN, new variations have taken place <ref type="bibr" target="#b44">[48]</ref> and in the ensuing part, we will briefly review some basic models of ZNN from different perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Convergence and stability</head><p>In the research of neural networks, the key issues are convergence and stability. Broadly speaking, there are three ways for proving the convergence of ZNN models, i.e., proof based on Lyapunov theory, ordinary differential equation (ODE), or Laplace transform. 1) Proof based on Lyapunov theory <ref type="bibr" target="#b45">[49]</ref>. For example, for the time-varying nonlinear minimization problem solving with the task function being f (x(t), t) ∈ R and x(t) ∈ R n in <ref type="bibr" target="#b32">[36]</ref>, the error function can be designed</p><formula xml:id="formula_5">A C C E P T E D M A N U S C R I P T as e(t) = ∂f (x(t), t) ∂x(t) .</formula><p>By constructing a Lyapunov function candidate :</p><formula xml:id="formula_6">V (t) = 1 2 e T (t)e(t),</formula><p>it can be concluded that V (t) is evidently of the positive-definiteness. Then, computing its time derivative leads to</p><formula xml:id="formula_7">V (t) = -γe T (t)e(t),</formula><p>which is of negative-definiteness and we draw the conclusion that the residual error of the corresponding ZNN model globally converges to zero. It is worth noting that, by replacing the definition of error function e(t), the global convergence of all the existing continuous-time ZNN models can be analyzed from the similar way. This way is the dominant approach in the analysis of continuous-time ZNN models and has been widely studied in <ref type="bibr" target="#b46">[50,</ref><ref type="bibr" target="#b47">51,</ref><ref type="bibr" target="#b48">52,</ref><ref type="bibr" target="#b32">36]</ref>.</p><p>2) Proof based on ODE. In addition to the convergent range, ODE-based approach can be used to prove the convergent speed of linear function activated ZNN models. For example, for the same problem shown in <ref type="bibr" target="#b32">[36]</ref>, by solving the ith subsystem of design formula, i.e., ė(t) = -γe(t), one can readily have</p><formula xml:id="formula_8">e(t) = e(0) exp(-γt),</formula><p>where e(0) is the initial value of e(t). Then, we have the conclusion that the residual error of the ZNN model globally and exponentially to zero. This way has been widely studied in <ref type="bibr" target="#b32">[36,</ref><ref type="bibr" target="#b34">38,</ref><ref type="bibr" target="#b35">39]</ref>.</p><p>3) Proof based on Laplace transform. Using Laplace transform to ė(t) = -γe(t) produces se(s)e(0) = -γe(s), and we further have</p><formula xml:id="formula_9">e(s) = e(0) s + γ . (<label>3</label></formula><formula xml:id="formula_10">) A C C E P T E D M A N U S C R I P T</formula><p>In view of γ &gt; 0, it can be readily concluded that the final value theorem applies. Based on the final value theorem, we have</p><formula xml:id="formula_11">lim t→∞ e(t) = lim s→0 se(s) = lim s→0 se(0) s + γ = 0,</formula><p>which completes the proof. This way is a new approach and has been preliminarily studied in <ref type="bibr" target="#b49">[53,</ref><ref type="bibr" target="#b50">54,</ref><ref type="bibr" target="#b51">55,</ref><ref type="bibr" target="#b52">56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Nonlinear activation functions</head><p>In the design and construction of ZNN models, nonlinear activation functions are used to accelerate the convergent speed. Typically, the following ones are often employed to construct ZNN models <ref type="bibr" target="#b41">[45,</ref><ref type="bibr" target="#b53">57,</ref><ref type="bibr" target="#b54">58]</ref>:</p><p>-the power-sum activation function:</p><formula xml:id="formula_12">φ(e i ) = N 0 e 2N -1 i ,</formula><p>where N &gt; 1.</p><p>-the power-sigmoid activation function:</p><formula xml:id="formula_13">φ(e i ) = 1+exp(-ξ) 1-exp(-ξ) 1-exp(-ξe i ) 1+exp(-ξe i ) , if |e i | &lt; 1, e p i , if |e i | 1,</formula><p>where p is an odd integer and ξ &gt; 0.</p><p>-and the hyperbolic sine activation function:</p><formula xml:id="formula_14">φ(e i ) = exp(e i m) 2 - exp(-e i m) 2 ,</formula><p>where m is an odd integer.</p><p>It is worth noting that, to prove the convergence of these nonlinear function activated ZNN models, a common approach is to construct a Lyapunov function candidate V (t) = e T (t)e(t)/2, and then compute its time derivative V (t), which is smaller than that of linear function activated ZNN model. Then, we draw the conclusion that nonlinear activation function can be used to accelerate the convergence speed. Many existing results on the ZNN concern the case that activation functions should be continuous, and strictly monotonically increasing, which is a limitation and should be remedied in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Finite-time convergence</head><p>Due to in-depth research on the ZNN model and inspired by the study on finite-time convergence in continuous autonomous system <ref type="bibr" target="#b55">[59,</ref><ref type="bibr" target="#b56">60,</ref><ref type="bibr" target="#b57">61]</ref>, Li et al. present a nonlinear function to accelerate the continuous-time ZNN to finite-time convergence for solving time-varying Sylvester equation in <ref type="bibr" target="#b58">[62]</ref> and then extend to the online solution of dual neural networks for solving quadratic programming problems in <ref type="bibr" target="#b59">[63]</ref>. After that, many different finitetime activation functions have been proposed and employed to various ZNN models, e.g, time-varying matrix pseudoinversion in complex domain <ref type="bibr" target="#b60">[64]</ref>, Lyapunov equation <ref type="bibr" target="#b61">[65]</ref>, equality-constrained quadratic optimization <ref type="bibr" target="#b62">[66]</ref>, linear complex matrix equation <ref type="bibr" target="#b63">[67]</ref> and so on <ref type="bibr" target="#b64">[68,</ref><ref type="bibr" target="#b65">69,</ref><ref type="bibr" target="#b39">43,</ref><ref type="bibr" target="#b66">70]</ref>. Note that the residual error of a traditional ZNN model exponentially converges to zero, which means that the smaller the residual error is, the slower the convergent speed is. Therefore, for achieving finite-time convergence, an effective is to amplify the value of ė(t)/e(t) to large enough when e(t) approaches to zero. In addition, it is investigated in <ref type="bibr" target="#b68">[71]</ref> that various ZNN models can be designed by exploiting different error functions for a time-varying problem solving, which can be accelerated to finite-time convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Complex-valued ZNN models</head><p>In the past years, different ZNN models have received considerable studies in many scientific and engineering fields, which successfully tackles the estimation error problem in the real domain. In contrast to these ZNN models defined in the real domain, the research on complex-valued ZNN models shows advantage over conventional real-valued neural networks in complex problems solving. The first complex-valued ZNN model is proposed to solve the time-varying matrix-inversion problems in complex domain in <ref type="bibr" target="#b48">[52]</ref>. To guarantee the global convergence of the neural network, only linear activation functions are considered in it. As pointed previously, many nonlinear function can be used to accelerate the convergence speed of ZNN model, which inspires Li et al to explore nonlinear complex-valued activation functions to accelerate the convergence of ZNN with guaranteed global convergence in <ref type="bibr" target="#b69">[72]</ref>. They find two classes of activation functions to achieve the global convergence of the complex-valued ZNN for solving the complex-valued timevarying Sylvester equation and then accelerate it to finite-time convergence. Liao et al propose five ZNN models by exploiting different techniques to compute the time-varying complex-valued pseudoinversion problem in <ref type="bibr" target="#b70">[73]</ref>, which is further generalized to complex-valued matrix inversion in <ref type="bibr" target="#b71">[74]</ref>. Qiao </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dynamic problem</head><p>Noise-tolerant ZNN model 4th root finding</p><formula xml:id="formula_15">ẋ(t) = ȧ(t) -γ(x 4 (t) -a(t)) x 4 (t) = a(t) -λ t 0 (x 4 (δ) -a(δ)dδ/(4x 3 (t)) Linear system A(t) ẋ(t) = -Ȧ(t)x(t) + ḃ(t) -γ(A(t)x(t) -b(t)) A(t)x(t) = b(t) -λ t 0 (A(δ)x(δ) -b(δ))dδ Matrix inversion A(t) Ẋ(t) = -Ȧ(t)X(t) -γ(A(t)X(t) -I) A(t)X(t) = I -λ t 0 (A(δ)X(δ) -I)dδ Matrix square roots X(t) Ẋ(t) + Ẋ(t)X(t) = -γ(X 2 (t) -A(t)) -Ȧ(t) finding X 2 (t) = A(t) -λ t 0 (X 2 (δ) -A(δ))dδ Nonlinear equations ẋ(t) = -J -1 (x(t), t) γΦ(f (x(t), t)) + ∂f (x(t),t) ∂t f (x(t), t) = 0 λ t 0 (f (x(δ), δ))dδ</formula><p>et al present two complex-valued ZNN models for computing the Drazin inverse, which is accelerated to finite-time with proven upper bounds of the convergence time in <ref type="bibr" target="#b65">[69]</ref>. In addition, as a comparison, online solution of complex-valued systems of linear equations is investigated in the complex domain via a GNN model in <ref type="bibr" target="#b72">[75]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Noise-tolerant ZNN models</head><p>Many computational models for solving time-varying problems (including the conventional ZNN models) usually assume that the solving task is free of noises or that the noise reduction operation has been completed before the computation <ref type="bibr" target="#b73">[76]</ref>. Note that, for the online computation of timevarying problems, time is precious and the preprocessing for denoising may consume extra time, thereby breaking the requirement for online computation. Therefore, an integration-enhanced ZNN design formula is proposed in <ref type="bibr" target="#b51">[55]</ref> for time-varying matrix inversion, which leverages the integrationcontrol technique in control theoretical and is able to handle simultaneously the noises. Then, such a noise-tolerant ZNN design formula is used to construct continuous-time ZNN model in <ref type="bibr" target="#b52">[56]</ref> with nonlinear activation function exploited for accelerating the noise-tolerant model. In <ref type="bibr" target="#b50">[54]</ref>, the authors analyze and design different ZNN models via a systematic approach from the control perspective for solving time-varying problems. The essence of the noise-tolerant ZNN models is to leverage the error integration information</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>to eliminate the constant bias errors. A challenging topic existing in this approach is how to determine the suitable activation functions for accelerating its convergence. By exploiting noise-tolerant ZNN design formula to solve different time-varying problems, various noise-tolerant ZNN models that exploit the time-derivative information of coefficients as well as the error integration can be constructed with their formulations shown in Table <ref type="table" target="#tab_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Numerical Formulas and Various Discrete-Time Models</head><p>As reviewed previously, various continuous-time ZNN models have been presented for solving different problems. However, due to the fact that step size in simulating continuous-time systems is variable and that digital computer often requires constant time step, it is different for digital computer to implement continuous-time ZNN models directly <ref type="bibr" target="#b74">[77,</ref><ref type="bibr" target="#b75">78,</ref><ref type="bibr" target="#b76">79,</ref><ref type="bibr" target="#b77">80]</ref>. In addition, for continuous-time ZNN models, it is always assumed that neurons communicated and responded instantaneously and without any delay. However, in digital circuits, time delay is unavoidable due to the existing of the sampling gap. Thus, researchers devote their effects to propose and investigate discrete-time ZNN models for online time-varying problems solving. In addition, some challenges of developing the discrete-time ZNN models from the continuous-time ones for the time-varying problems solving are listed as follows.</p><p>1. From the perspective of time, any time-varying problem can be deemed as a causal system and thus, the related computation should be conducted based on the existing data, i.e., the present and/or previous data, due to the unavailability of future data but for computing the future solution. For example, for solving the time-varying matrix inversion problem 1 in a discrete manner, at the time instant t k , we can use the known information, e.g., A(t k ) and Ȧ(t k ), not the unknown information, e.g., A(t k+1 ) and Ȧ(t k+1 ) for computing the inverse of A(t k+1 ), i.e., X(t k+1 ). Thus, a fundamental requirement for constructing the discrete-time ZNN model is that we can not use future data. 2. Accordingly, A feasible numerical differentiation formula for discretizing continuous-time ZNN model should have and only have one point ahead of the target point. Consequently, when the numerical differentiation formula is used to discretize the continuous-time ZNN model, the constructed discrete-time ZNN model has one and only one unknown point X(t k+1 ) to be computed via the known data (e.g., A(t k )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M A N U S C R I P T</head><p>and Ȧ(t k ). Therefore, the backward and multiple-point central differentiation rules can not be used to construct discrete-time ZNN models, no matter how tiny the truncation error of each formula is. Moreover, only the forward differentiation formulas with one step ahead can be considered for the discretization of ZNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Computation consumes time inevitably at each time instant and time is</head><p>precious for the time-varying problems solving in practice. So, how to design a very simple discrete-time ZNN model with less calculation time is important. In other words, as Leonardo da Vinci said, 'simplicity is the ultimate sophistication'.</p><p>The first discrete-time ZNN model is proposed in <ref type="bibr" target="#b78">[81]</ref> for constant matrix inversion, which bridges the gap between discrete-time ZNN model and the traditional Newton iteration. At the early stage, Euler forward difference is used to construct the discretize the continuous-time ZNN model <ref type="bibr" target="#b79">[82,</ref><ref type="bibr" target="#b80">83]</ref>.</p><p>The discrete-time ZNN models generated by Euler forward difference are of the error pattern of O(τ<ref type="foot" target="#foot_0">2</ref> ), where τ denotes the sampling gap. For example, the Euler-type discrete-time ZNN model for time-varying matrix inversion is directly given as <ref type="bibr" target="#b81">[84]</ref>:</p><formula xml:id="formula_16">X k+1 = X k -τ X k Ȧk X k -hX k (A k X k -I),<label>(4)</label></formula><p>where k denotes the iteration index and h = τ γ &gt; 0. In addition, by omitting the term τ X k Ȧk X k and letting h = 1, the Euler-type discrete-time ZNN model (4) reduces to</p><formula xml:id="formula_17">X k+1 = X k -X k (A k X k -I),<label>(5)</label></formula><p>which is the Newton iteration. In other words, the traditional Newton iteration can be deemed as a special case of Euler-type discrete-time ZNN model <ref type="bibr" target="#b0">(4)</ref>. Meanwhile, the link between Getz-Marsden dynamic system and discrete-time ZNN models is found in <ref type="bibr" target="#b82">[85]</ref>. To achieving high accuracy in the discretization of ZNN models, a Taylor-type numerical differentiation formula is proposed in <ref type="bibr" target="#b81">[84]</ref> for the first-order derivative approximation, which has a truncation error of O(τ 2 ) and formulated as</p><formula xml:id="formula_18">f (t k ) = 2f (t k+1 ) -3f (t k ) + 2f (t k-1 ) -f (t k-2 ) 2τ + O(τ 2 ).<label>(6)</label></formula><p>A new Taylor-type discrete-time ZNN model can be developed for timevarying matrix inversion as</p><formula xml:id="formula_19">X k+1 = -τ X k Ȧk X k -hX k (A k X k -I) + A C C E P T E D M A N U S C R I P T</formula><p>The above Taylor-type discrete-time ZNN model converges to the theoretical solution of the time-varying problem with the residual error being O(τ 3 ). Recently, a numerical difference rule is established in <ref type="bibr" target="#b83">[86]</ref> for first-order derivative approximation with the truncation error of O(τ 3 ). Based on such a new foumula, a five-step discrete-time ZNN model is proposed for time-varying matrix inversion, of which the residual error is O(τ 4 ). Note that, the discretetime ZNN models can be deemed as time delay systems, and thus, a large value of h may lead the model to oscillate. To remedy the instability, a direct way is to lessen the value of h. However, lessening the value of h would significantly slow the convergence of discrete-time ZNN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Applications</head><p>As a systematic approach for solving time-varying zero-finding problems, ZNN design formula as well as the derived models has been applied to the motion generation and control of redundant manipulators, the tracking control of chaotic systems or even the population control in biosciences. Along the above lines, we will give a detailed review on the application research of ZNN in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Robotic Applications</head><p>The joint-drift problem existing in the motion generation and control of redundant manipulators is that, after completing a closed path in the workspace, the joint variables do not go back to their initial values <ref type="bibr" target="#b84">[87]</ref>. Researchers exploit the ZNN approach to remedy such a weakness. For a redundant robot manipulator, we have <ref type="bibr" target="#b85">[88,</ref><ref type="bibr" target="#b86">89,</ref><ref type="bibr" target="#b87">90,</ref><ref type="bibr" target="#b88">91,</ref><ref type="bibr" target="#b89">92]</ref>:</p><formula xml:id="formula_20">f (θ) = r,<label>(8)</label></formula><formula xml:id="formula_21">J(θ) θ = ṙ,<label>(9)</label></formula><p>where r ∈ R m is the orientation vector to be achieved; f (θ) denotes the endeffector position; Differentiating Equation ( <ref type="formula" target="#formula_21">9</ref>) with respect to time t leads to <ref type="bibr" target="#b4">(8)</ref>. To eliminate the joint displacement θ(T )θ(0), where θ(T ) and θ(0) denote the values of joint variables at the final state and initial state, respectively, a direction based on ZNN design formula is to construct an error function (t) = θ(t)θ(0) and then employ the ZNN design formula to force (t) converging to zero. Then, we have θ(t) = -γ(θ(t)θ(0)). For considering the equality and inequality constraints, it is better to minimize</p><formula xml:id="formula_22">A C C E P T E D M A N U S C R I P T</formula><p>the performance index θ(t) + γ(θ(t)θ(0)) 2 2 /2, rather than using θ(t) + γ(θ(t)θ(0)) = 0 directly. Thus, the repetitive motion generation scheme based on ZNN method can be formulated as minimize θ(t) + γ(θ(t)θ(0)) 2 2 /2 (10) subject to</p><formula xml:id="formula_23">J(θ) θ = ṙ,<label>(11) θ</label></formula><formula xml:id="formula_24">- l θ l θ + l ,<label>(12) θl</label></formula><formula xml:id="formula_25">- θl θl + . (<label>13</label></formula><formula xml:id="formula_26">)</formula><p>It is investigated in <ref type="bibr" target="#b90">[93]</ref> that the above scheme is reformulated as a quadratic programming problem. Moreover, different RNN models are investigated comparatively for solving such a problem. In general, the redundancyresolution problem arising in the motion planning and control of redundant manipulators can be solved at the joint-velocity level or at the jointacceleration level, resulting in the corresponding velocity-level and accelerationlevel redundancy-resolution schemes. Then, to solve the joint-angle drift problems in repetitive motion control of redundant robot manipulators at the level of acceleration, a scheme called acceleration-level drift-free (ALDF) scheme subject to a linear equality constraint is presented in <ref type="bibr" target="#b91">[94]</ref> with guaranteed effectiveness. Reference <ref type="bibr" target="#b92">[95]</ref> point out that there existing equivalent relationship between joint-velocity level and joint-acceleration level via the ZNN-related techniques. Miao et al present ZNN models for solving time-varying quadratic program problems and applied to robot tracking <ref type="bibr" target="#b93">[96]</ref>,</p><p>where the models are of finite-time convergence. A noise-tolerant ZNN model is designed and presented in <ref type="bibr" target="#b94">[97]</ref> for the motion generation of multiple redundant robot manipulators in a distributed manner, which can be deemed as a seminal work on ZNN with application to distributed systems. The Jacobian equality constraints for multiple manipulators in <ref type="bibr" target="#b94">[97]</ref> are compacted into an equality based on consensus with limited communications, and the scheme could coordinately control all manipulators involved to complete a given task with the aid of ZNN, as long as the communication topological graph is connected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Chaos Applications</head><p>For the tracking-control problems of two chaotic systems, many methods fail to solve it due to the existence of singularities. For demonstration, the Lu system equipped with a single control input u is presented. Let us consider</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T the following chaotic system with input u:</p><formula xml:id="formula_27">     ẋ = a(y -x), ẏ = -xz + cy + u, ż = xy -bz,<label>(14)</label></formula><p>where a = 36, b = 3 and c = 20; ϑ = z denotes the output of system <ref type="bibr" target="#b10">(14)</ref>.</p><p>The aim is to construct a controller such that ϑ tracks time-varying desired path ϑ d , with e = ϑϑ d approaching zero.</p><p>To adopt ZNN design formula, the first error function is designed as</p><formula xml:id="formula_28">e 1 = ϑ -ϑ d = z -ϑ d ,</formula><p>where ϑ d denotes the desired trajectory. In addition, the following ZNN design formula is provided:</p><formula xml:id="formula_29">ė1 = -γe 1 .<label>(15)</label></formula><p>Expanding the above design formula leads to</p><formula xml:id="formula_30">xy + (γ -b)z -θd -γϑ d = 0. (<label>16</label></formula><formula xml:id="formula_31">)</formula><p>To get an expression of u in (16) explicitly, the following second error function is constructed: e 2 = xy + (γb)z -θdγϑ d . Then, we have</p><formula xml:id="formula_32">ẋy + x ẏ + (γ -b) ż -θd -γ θd = -γ(xy + (γ -b)z -θd -γϑ d ).<label>(17)</label></formula><p>With the aid of ( <ref type="formula" target="#formula_27">14</ref>), we have</p><formula xml:id="formula_33">x 2 z + (a + b -c -2γ)xy -ay 2 -xu + g 2 = 0,<label>(18)</label></formula><p>where g 2 = (2γbb 2γ 2 )z + θd + 2γ θd + γ 2 ϑ d . Thus, a controller based on ZNN design formula is obtained:</p><formula xml:id="formula_34">u = 1 x x 2 z + (a + b -c -2γ)xy -ay 2 + g 2 ,<label>(19)</label></formula><p>which has a singularity plane x = 0. To conquer it, the idea based on ZNNrelated approach is to eliminate the division operation by transforming the direct control <ref type="bibr" target="#b15">(19)</ref>  </p><p>which is free of division operation. In view of the fact that such a controllerdesign method is consisted of ZNN method and GNN method, it is termed ZG neural dynamics in <ref type="bibr" target="#b95">[98]</ref>. Such a method is extended to the singularityconquering of inverted pendulum on a cart system in <ref type="bibr" target="#b96">[99]</ref>, the tracking control of chaotic systems with the mixture of additive and multiplicative inputs <ref type="bibr" target="#b97">[100]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Other Applications</head><p>In addition to the robotics as well as chaos, ZNN is also applied to the multi-dimensional spectral estimation. For avoiding the computation of direct inverse of covariance matrix, Benchabane et al use discrete-time ZNN models to compute the inverse of covariance matrix online in <ref type="bibr" target="#b76">[79]</ref>. To handle the output tracking control of general-form single-input single-output nonlinear system, controllers based on ZNN are designed in <ref type="bibr" target="#b98">[101]</ref>, which can avoid the division-by-zero problem. In <ref type="bibr" target="#b99">[102]</ref>, discrete-time ZNN models are used for motion estimation for computing 2D optical flow. In addition, new fractals are yielded by using the discrete-time complex-valued ZNN for solving time-varying nonlinear equations in the complex domain in <ref type="bibr" target="#b100">[103,</ref><ref type="bibr" target="#b101">104,</ref><ref type="bibr" target="#b102">105]</ref>. The population control of the Lotka-Volterra model in mathematical ecology based on the ZNN-related techniques is investigated in <ref type="bibr">[106]</ref>. The presented controller is able to drive the prey population and/or predator population to a desired state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In summary, the studies for ZNN have achieved a great deal in the last 16 years. However, there are still many new problems to be solved. For future directions of the study on zeroing neural networks as well as their applications, we now provide some prospective suggestions.</p><p>1. Continue to apply and find some useful one-step ahead numerical differential formulas to discretize the continuous-time ZNN models, especially to further expand the step-size in the existing discrete ZNN results while keeping a high computational accuracy. This direction is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C C E P T E D M</head><p>A N U S C R I P T closely related to the development of applied mathematics and computational mathematics. 2. How to construct nonlinear activation functions to accelerate the convergence speed of zeroing neural networks for solving complex-valued problems is still an open problem. For the case of real-valued problems, a great deal of nonlinear activations have been proposed and investigated. Moreover, how to obtain the convergence conditions is also meaningful in the development of zeroing neural networks. 3. In addition to the global stability property, how to construct and analyze the stability criteria for noise-tolerant and nonconvex-allowed zeroing neural networks still needs more efforts. In general, these modified zeroing neural networks are highly related to the control techniques.</p><p>All these future developments will accompany the development of mathematical theory, especially applied mathematics and computational mathematics. For example, new models should be derived for solving the inequality constraint in time-varying optimization problems. All these future developments will accompany the development of the computational mathematics for constructing and developing neural networks as well as the techniques for various kinds of robot manipulators. Keeping in mind, different kinds of neural networks e.g., discrete-time ZNN models or even the gradient neural network models, have their own feasible ranges, and one cannot expect that only a few existing results on neural networks can tackle all the computational problems. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>into a minimization problem. By defining h = x 2 z + (a + A C C E P T E D M A N U S C R I P T bc -2µ)xyay 2xu + g 2 and based on the gradient method, a tracking controller in the form of u can be designed as u = γxh,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>[1] Y.-J.Liu, S. Tong, D.-J. Li, Y. Gao, Fuzzy adaptive control with state observer for a class of nonlinear discrete-time systems with input constraint, IEEE Transactions on Fuzzy Systems 24 (2016) 1147-1158. [2] Y.-J. Liu, S. Tong, Adaptive fuzzy identification and control for a class of nonlinear pure-feedback mimo systems with unknown dead zones, IEEE Transactions on Fuzzy Systems 23 (2015) 1387-1398. [3] H. Wang, B. Chen, K. Liu, X. Liu, C. Lin, Adaptive neural tracking control for a class of nonstrict-feedback stochastic nonlinear systems with unknown backlash-like hysteresis, IEEE Transactions on Neural Networks and Learning Systems 25 (2014) 947-958.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Continuous-time ZNN models constructed for solving time-varying problems.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Continuous-time noise-tolerant ZNN models constructed for solving time-varying problems.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>X k -X k-1 + 1 2 X k-2 . (7)</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>$ This work is supported by the National Natural Science Foundation of China (with numbers 61401385 and 61563017), by Hong Kong Research Grants Council Early Career Scheme (with number 25214015), and also by</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimal control-based adaptive nn design for a class of nonlinear discrete-time block-triangular systems</title>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="2670" to="2680" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural network control-based adaptive learning design for nonlinear systems with full-state constraints</title>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1562" to="1571" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Distributed recurrent neural networks for cooperative control of manipulators: A game-theoretic perspective</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Rafique</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="415" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Decentralized kinematic control of a class of collaborative redundant manipulators via recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Selective positive-negative feedback produces the winner-take-all competition in recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="301" to="309" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cp-activated wasd neuronet approach to asian population prediction with abundant experimental verification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient extraction of non-negative latent factors from high-dimensional and sparse matrices in industrial applications</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="311" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Construction of reliable protein-protein interaction networks using weighted sparse representation based classifier with pseudo substitution matrix representation features</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="131" to="138" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Regularizaed extraction of non-negative latent factors from high-dimensional sparse matrices</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1221" to="001226" />
		</imprint>
	</monogr>
	<note>Systems, Man, and Cybernetics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive neural synchronization control for bilateral teleoperation systems with time delay and backlash-like hysteresis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adaptive fuzzy decentralized control for a class of interconnected nonlinear system with unmodeled dynamics and dead zones</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="page" from="972" to="980" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recurrent neural network approach based on the integral representation of the drazin inverse</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Stanimirović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Živković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2107" to="2131" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent neural network for computing outer inverse</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Živković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Stanimirović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="970" to="998" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nonlinearly activated recurrent neural network for computing the drazin inverse</title>
		<author>
			<persName><forename type="first">X.-Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Stanimirović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simulink comparison of varying-parameter convergent-differential neural-network and gradient neural network for solving online linear time-varying equations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Control and Automation (WCICA), 2016 12th World Congress on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="887" to="894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discontinuous neural networks for finite-time solution of time-dependent linear equations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Di</forename><surname>Marco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nistri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pancioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="2509" to="2520" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recurrent neural network for computation of generalized eigenvalue problem with real diagonalizable matrix pair and its applications</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="page" from="230" to="241" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A nonnegative latent factor model for large-scale sparse matrices in recommender systems via alternating direction method</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="579" to="592" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Three recurrent neural networks and three numerical methods for solving repetitive motion planning scheme of redundant robot manipulators</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ASME Transactions on Mechatronics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Incorporation of efficient second-order solvers into latent factor models for accurate prediction of missing qos data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An efficient second-order approach to factorize sparse matrices in recommender systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="946" to="956" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A recurrent neural network for real-time matrix inversion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="89" to="100" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A simplified neural network for linear matrix inequality problems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-G</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural processing letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="213" to="230" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Neural network-based discrete-time Z-type model of high accuracy in noisy environments for solving dynamic system of linear equations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Neural Computing and Applications</publisher>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for synthesizing linear control systems via pole placement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Systems Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2369" to="2382" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for nonlinear output regulation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1161" to="1173" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Global exponential convergence and stability of gradient-based neural network for online matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="page" from="1301" to="1306" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An improved recurrent network for online equalityconstrained quadratic programming</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Brain Inspired Cognitive Systems: 8th International Conference</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-11-28">2016. November 28-30, 2016. 2016</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>BICS</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Performance analysis of gradient neural network exploited for online time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Z</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1940" to="1945" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Performance analysis of gradient neural network exploited for online time-varying quadratic minimization and equality-constrained quadratic programming</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ruan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1710" to="1719" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Convergence properties analysis of gradient neural network for solving online linear equations</title>
		<author>
			<persName><forename type="first">Y.-N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng-Hai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Automatica Sinica</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1136" to="1139" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Discrete-time Zhang neural network of O(τ 3 ) pattern for time-varying matrix pseudoinversion with application to manipulator motion generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="165" to="173" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Continuous and discrete Zhang dynamics for realtime varying nonlinear optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerical Algorithms</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="115" to="140" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A recurrent neural network for solving Sylvester equation with time-varying coefficients</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1053" to="1063" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Design and analysis of a general recurrent neural network model for time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1477" to="1490" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Zhang neural network versus gradient-based neural network for time-varying linear matrix equation solving</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="3708" to="3712" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Time-varying square roots finding via Zhang dynamics versus gradient dynamics and the former&apos;s link and new explanation to Newton-Raphson iteration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="1103" to="1109" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Continuous and discrete time Zhang dynamics for time-varying 4th root finding</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="35" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Simulation and verification of zhang neural networks and gradient neural networks for time-varying stein equation A</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang ; C C E P T E D M A N U S C R I P T Solving</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="385" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Online solution of time-varying lyapunov matrix equation by zhang neural networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Recent Patents on Computer Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Different ZFs leading to various ZNN models illustrated via online solution of time-varying underdetermined systems of linear equations with robotic application</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="481" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Superior performance of using hyperbolic sine activation functions in ZNN illustrated via time-varying matrix square roots finding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science and Information Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1603" to="1625" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Comparison on Zhang neural dynamics and gradient-based neural dynamics for online solution of nonlinear time-varying equation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Novel recurrent neural network for time-varying problems solving</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="61" to="65" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>research frontier</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Zhang neural network versus gradient neural network for solving time-varying linear inequalities</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1676" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Zhang neural network for online solution of timevarying convex quadratic program subject to time-varying linearequality constraints</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Letters A</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="page" from="1639" to="1643" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Three new ZNN models with economical dimension and exponential convergence for realtime solution of moore-penrose pseudoinverse</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks (IJCNN), 2014 International Joint Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2788" to="2793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Different ZFs lead to different nets: examples of Zhang generalized inverse</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="453" to="458" />
		</imprint>
	</monogr>
	<note>Chinese Automation Congress (CAC)</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Complex-valued Zhang neural network for online complex-valued time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="page" from="10066" to="10073" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Performance analyses of recurrent neural network models exploited for online time-varying nonlinear optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science and Information Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="691" to="705" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Noise-tolerant ZNN models for solving time-varying zero-finding problems: A control-theoretic approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="992" to="997" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Integration-enhanced Zhang neural network for real-time-varying matrix inversion in the presence of various kinds of noises</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2615" to="2627" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Modified ZNN for time-varying quadratic programming with inherent tolerance to noises and its application to kinematic redundancy resolution of robot manipulators</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="6978" to="6988" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Superior robustness of power-sum activation functions in zhang neural networks for time-varying quadratic programs perturbed with large implementation errors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Comparison on neural solvers for the lyapunov matrix equation with stationary &amp; nonstationary coefficients</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematical Modelling</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="2495" to="2502" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Finite-time stability of continuous autonomous systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="751" to="766" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Robustness of convergence in finite time for linear programming neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Marco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grazzini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of circuit theory and applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="307" to="316" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Finite time dual neural networks with a tunable activation function for solving quadratic programming problems and its application</title>
		<author>
			<persName><forename type="first">P</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="80" to="89" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Accelerating a recurrent neural network to finite-time convergence for solving time-varying sylvester equation by using a sign-bi-power activation function</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural processing letters</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="189" to="205" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A class of finite-time dual neural networks for solving quadratic programming problems and its k-winners-take-all application</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">From different zfs to different znn models accelerated via li activation functions to finite-time convergence for timevarying matrix pseudoinversion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="512" to="522" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A convergence-accelerated zhang neural network and its solution application to lyapunov equation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="213" to="218" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A nonlinearly-activated neurodynamic model and its finitetime solution to equality-constrained quadratic optimization with nonstationary coefficients</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="252" to="259" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A finite-time convergent neural dynamics for online solution of time-varying linear complex matrix equation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page" from="254" to="259" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Finite-time stability and its application for solving time-varying sylvester equation by recurrent neural network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="763" to="784" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Two finite-time convergent zhang neural network models for time-varying complex matrix drazin inverse</title>
		<author>
			<persName><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra and its Applications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The application of lifunction activated rnn to acceleration-level robots&apos; kinematic control via time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Control and Decision Conference</title>
		<imprint>
			<publisher>CCDC</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ieee</forename><surname>Chinese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3455" to="3460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">From different zhang functions to various znn models accelerated to finite-time convergence for time-varying linear matrix equation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural processing letters</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="309" to="326" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Nonlinearly activated neural network for solving timevarying complex sylvester equation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1397" to="1407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Different complex zfs leading to different complex znn models for time-varying complex generalized inverse matrices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1621" to="1631" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Novel complex-valued neural network for dynamic complex-valued matrix inversion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JACIII</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="132" to="138" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A fully complexvalued neural network for rapid solution of complex-valued systems of linear equations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="444" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Robustness analysis of a hybrid of recursive neural dynamics for online matrix inversion</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="969" to="975" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Three nonlinearly-activated discretetime znn models for time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="163" to="167" />
		</imprint>
	</monogr>
	<note>Natural Computation (ICNC)</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<title level="m">Zeroing Dynamics, Gradient Dynamics, and Newton Iterations</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Multidimensional capon spectral estimation using discrete zhang neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Benchabane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bennia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Charif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taleb-Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multidimensional Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">From davidenko method to zhang dynamics for nonlinear equation systems solving</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">On the variable step-size of discrete-time zhang neural network and newton iteration for constant matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information Technology Application, 2008. IITA&apos;08. Second International Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="34" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">From zhang neural network to newton iteration for matrix inversion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems I: Regular Papers</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1405" to="1415" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Enhanced discrete-time zhang neural network for time-variant matrix inversion in the presence of bias noises</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="220" to="230" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Taylor-type 1-step-ahead numerical differentiation rule for first-order derivative approximation and znn discretization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="29" to="40" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Zhang neural network, getz-marsden dynamic system, and discrete-time algorithms for time-varying matrix inversion with application to robots&apos; kinematic control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="22" to="32" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Novel discrete-time zhang neural network for time-varying matrix inversion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Remedy scheme and theoretical analysis of joint-angle drift phenomenon for redundant robot manipulators</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Computer-Integrated Manufacturing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="860" to="869" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Acceleration-level cyclic-motion generation of constrained redundant robots tracking different paths</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</title>
		<imprint>
			<biblScope unit="page" from="1257" to="1269" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Manipulability optimization of redundant manipulators using dynamic neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>La</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">G2-type srmpc scheme for synchronous manipulation of two redundant robot arms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="153" to="164" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Distributed task allocation of multiple robots: A control perspective</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Kinematic control of redundant manipulators using neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Repetitive motion of redundant robots planned by three kinds of recurrent neural networks and illustrated with a four-link planar manipulators straight-line example</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="645" to="651" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Design and experimentation of acceleration-level drift-free scheme aided by two recurrent neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="25" to="42" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Different-level redundancy-resolution and its equivalent relationship analysis for robot manipulators using gradient-descent and zhang&apos;s neural-dynamic methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="3146" to="3155" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Solving time-varying quadratic programs based on finite-time zhang neural networks and their application to robot tracking</title>
		<author>
			<persName><forename type="first">P</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="693" to="703" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Cooperative motion generation in a distributed network of redundant robot manipulators with noises</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Singularity-conquering tracking control of a class of chaotic systems using zhang-gradient dynamics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Control Theory &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="871" to="881" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Singularity-conquering zg controllers of z2g1 type for tracking control of the ipc system</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Control</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1729" to="1746" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Tracking control of modified lorenz nonlinear system using zg neural dynamics with additive input or mixed inputs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="page" from="82" to="94" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">zg and iol controllers and comparisons for nonlinear system output tracking with dbz problem conquered in different relative-degree cases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zd</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Asian Journal of Control</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Horn &amp; schunck meets a discrete zhang neural networks for computing 2d optical flow</title>
		<author>
			<persName><forename type="first">F</forename><surname>Charif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benchabane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Djedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taleb-Ahmed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Zhang fractals yielded via solving nonlinear equations by discrete-time complex-valued zd</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
			<affiliation>
				<orgName type="collaboration">ICAL</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
			<affiliation>
				<orgName type="collaboration">ICAL</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
			<affiliation>
				<orgName type="collaboration">ICAL</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
			<affiliation>
				<orgName type="collaboration">ICAL</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Automation and Logistics</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Zhang fractals yielded via solving time-varying nonlinear complex equations by discrete-time complex-valued zd</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Computational Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="596" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">From newton fractals to gradient fractals in addition to zhang fractals</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Science and Engineering (CSE)</title>
		<imprint>
			<biblScope unit="page" from="1237" to="1242" />
			<date type="published" when="2014">2014. 2014</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">His current research interests include dynamic neural networks, wireless sensor networks, robotic networks, machine learning, and other dynamic problems defined on a graph. Bolin Liao received the B.S. degree in Electronic Information Engineering from Jishou University</title>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">;</forename><surname>A C C E P T E D M A N U S C R I P T Long</surname></persName>
		</author>
		<author>
			<persName><surname>Hom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Kowloon</surname></persName>
		</author>
		<author>
			<persName><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">China in 2005, the M.E. degree in Automatic Control Engineering from University of Science and Technology of China, China in 2008, and the Ph.D. degree in Electrical and Computer Engineering from Stevens Institute of Technology, USA in 2014. He is currently a research assistant professor with Department of Computing</title>
		<meeting><address><addrLine>Guangzhou, China; Kowloon, Hong Kong; Jishou, China; Anshan, China; Guangzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2011. 2016. 2003. 2006. 2015</date>
		</imprint>
		<respStmt>
			<orgName>Sun Yat-sen University ; The Hong Kong Polytechnic University ; The Hong Kong Polytechnic University ; Anshan University of Science and Technology ; Communication and Information Systems from Sun Yat-Sen University</orgName>
		</respStmt>
	</monogr>
	<note>He also works in Lanzhou University. His main research interests include neural networks, robotics and intelligent information processing. He is currently an associate professor with the College of Information Science and Engineering, Jishou University. His main research interests include neural networks, robotics, and process control</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
