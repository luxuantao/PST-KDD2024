<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Factorized Latent Spaces with Structured Sparsity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley EECS</orgName>
								<orgName type="institution" key="instit2">ICSI</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
							<email>salzmann@ttic.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley EECS</orgName>
								<orgName type="institution" key="instit2">ICSI</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">TTI-Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
							<email>trevor@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UC Berkeley EECS</orgName>
								<orgName type="institution" key="instit2">ICSI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Factorized Latent Spaces with Structured Sparsity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A702BC61F1278446B36A0F85CCAB1CDF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent approaches to multi-view learning have shown that factorizing the information into parts that are shared across all views and parts that are private to each view could effectively account for the dependencies and independencies between the different input modalities. Unfortunately, these approaches involve minimizing non-convex objective functions. In this paper, we propose an approach to learning such factorized representations inspired by sparse coding techniques. In particular, we show that structured sparsity allows us to address the multiview learning problem by alternately solving two convex optimization problems. Furthermore, the resulting factorized latent spaces generalize over existing approaches in that they allow having latent dimensions shared between any subset of the views instead of between all the views only. We show that our approach outperforms state-of-the-art methods on the task of human pose estimation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many computer vision problems inherently involve data that is represented by multiple modalities such as different types of image features, or images and surrounding text. Exploiting these multiple sources of information has proven beneficial for many computer vision tasks. Given these multiple views, an important problem therefore is that of learning a latent representation of the data that best leverages the information contained in each input view.</p><p>Several approaches to addressing this problem have been proposed in the recent years. Multiple kernel learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24]</ref> methods have proven successful under the assumption that the views are independent. In contrast, techniques that learn a latent space shared across the views (Fig. <ref type="figure" target="#fig_0">1(a</ref>)), such as Canonical Correlation Analysis (CCA) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b2">3]</ref>, the shared Kernel Information Embedding model (sKIE) <ref type="bibr" target="#b22">[23]</ref>, and the shared Gaussian Process Latent Variable Model (shared GPLVM) <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b14">15]</ref>, have shown particularly effective to model the dependencies between the modalities. However, they do not account for the independent parts of the views, and therefore either totally fail to represent them, or mix them with the information shared by all views.</p><p>To generalize over the above-mentioned approaches, methods have been proposed to explicitly account for the dependencies and independencies of the different input modalities. To this end, these methods factorize the latent space into a shared part common to all views and a private part for each modality (Fig. <ref type="figure" target="#fig_0">1(b)</ref>). This has been shown for linear mappings <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11]</ref>, as well as for non-linear ones <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20]</ref>. In particular, <ref type="bibr" target="#b19">[20]</ref> proposed to encourage the shared-private factorization to be nonredundant while simultaneously discovering the dimensionality of the latent space. The resulting FOLS models were shown to yield more accurate results in the context of human pose estimation. This, however, came at the price of solving a complicated, non-convex optimization problem. FOLS also lacks an efficient inference method, and extension from two views to multiple views is not straightforward since the number of shared/latent spaces that need to be explicitly modeled grows exponentially with the number of views.</p><p>In this paper, we propose a novel approach to finding a latent space in which the information is correctly factorized into shared and private parts, while avoiding the computational burden of previous techniques <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20]</ref>. Furthermore, our formulation has the advantage over existing shared-private factorizations of allowing shared information between any subset of the views, instead of only be-Z X (1)  X (2)   (a)</p><formula xml:id="formula_0">X (1) X (2) Z s Z 1 Z 2 (b) X (1) X (2)</formula><p>D (1)   α D (2)   (c)</p><formula xml:id="formula_1">X (1) X (2) α Πs α Π 1 α Π 2 D (2) Π2 D (2) Πs D (1) Πs D (1) Π1 (d)</formula><p>Figure <ref type="figure" target="#fig_0">1</ref>: Graphical models for the two-view case of (a) shared latent space models <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b14">15]</ref>, (b) shared-private factorizations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20]</ref>, (c) the global view of our model, where the sharedprivate factorization is automatically learned instead of explicitly separated, and (d) an equivalent shared-private spaces interpretation of our model. Due to structured sparsity, rows Π s of α are shared across the views, whereas rows Π 1 and Π 2 are private to view 1 and 2, respectively. tween all views. In particular, we represent each view as a linear combination of view-dependent dictionary entries. While the dictionaries are specific to each view, the weights of these dictionaries act as latent variables and are the same for all the views. Thus, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>(c), the data is embedded in a latent space that generates all the views. By exploiting the idea of structured sparsity <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b8">9]</ref>, we encourage each view to only use a subset of the latent variables, and at the same time encourage the whole latent space to be low-dimensional. As a consequence, and as depicted in Fig. We demonstrate the effectiveness of our approach on the problem of human pose estimation where the existence of shared and private spaces has been shown <ref type="bibr" target="#b6">[7]</ref>. We show that our approach correctly factorizes the latent space and outperforms state-of-the-art techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Learning a Latent Space with Structured Sparsity</head><p>In this section, we first formulate the problem of learning a latent space for multi-view modeling.</p><p>We then briefly review the concepts of sparse coding and structured sparsity, and finally introduce our approach within this framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Statement and Notations</head><p>Let X = {X (1) , X (2) , • • • , X (V ) } be a set of N observations obtained from V views, where X (v) ∈ Pv×N contains the feature vectors for the v th view. We aim to find an embedding α ∈ N d ×N of the data into an N d -dimensional latent space and a set of dictionaries D = {D (1) , D (2) , • • • , D (V ) }, with D (v) ∈ Pv×N d the dictionary entries for view v, such that X (v) is generated by D (v) α, as depicted in Fig. <ref type="figure" target="#fig_0">1(c</ref>). More specifically, we seek the latent embedding α and the dictionaries that best reconstruct the data in the least square sense by solving the optimization problem</p><formula xml:id="formula_2">min D,α V v=1 X (v) -D (v) α 2 Fro .<label>(1)</label></formula><p>Furthermore, as explained in Section 1, we aim to find a latent space that naturally separates the information shared among several views from the information private to each view. Our approach to addressing this problem is inspired by structured sparsity, which we briefly review below.</p><p>Throughout this paper, given a matrix A, we will use the term A i to denote its i th column vector, A i,• to denote its i th row vector, and A •,Ω (A Ω,• ) to denote the submatrix formed by taking a subset of its columns (rows), where the set Ω contains the indices of the chosen columns (rows).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sparse Coding and Structured Sparsity</head><p>In the single-view case, sparse coding techniques <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b12">13]</ref> have been proposed to represent the observed data (e.g., image features) as a linear combination of dictionary entries, while encouraging each observation vector to only employ a subset of all the available dictionary entries. More formally, let X ∈ P ×N be the matrix of training examples. Sparse coding aims to find a set of dictionary entries D ∈ P ×N d and the corresponding linear combination weights α ∈ N d ×N by solving the optimization problem</p><formula xml:id="formula_3">min D,α 1 N ||X -Dα|| 2 Fro + λφ(α)<label>(2)</label></formula><formula xml:id="formula_4">s.t. ||D i || ≤ 1 , 1 ≤ i ≤ N d ,</formula><p>where φ is a regularizer that encourages sparsity of its input, and λ is the weight that sets the relative influence of both terms. In practice, when φ is a convex function, problem (2) is convex in D for a fixed α and vice-versa. Typically, the L 1 norm is used to encourage sparsity, which yields</p><formula xml:id="formula_5">φ(α) = N j=1 α j 1 = N j=1 N d i=1 |α i,j | .<label>(3)</label></formula><p>While sparse coding has proven effective in many domains, it fails to account for any structure in the observed data. For instance, in classification tasks, one would expect the observations belonging to the same class to depend on the same subset of dictionary entries. This problem has been addressed by structured sparse coding techniques <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9]</ref>, which encode the structure of the problem in the regularizer. Typically, these methods rely on the notion of groups among the training examples to encourage members of the same group to rely on the same dictionary entries. This can simply be done by re-writing problem (2) as</p><formula xml:id="formula_6">min D,α 1 N ||X -Dα|| 2 Fro + λ Ng g=1 ψ(α •,Ωg )<label>(4)</label></formula><formula xml:id="formula_7">s.t. ||D i || ≤ 1 , 1 ≤ i ≤ N d ,</formula><p>where N g is the total number of groups, Ω g represents the indices of the examples that belong to group g, and α •,Ωg is the matrix containing the weights associated to these examples. To keep the problem convex in α, ψ is usually taken either as the L 1,2 norm, or as the L 1,∞ norm, which yield</p><formula xml:id="formula_8">ψ(α •,Ωg ) = N d i=1 ||α i,Ωg || 2 , or ψ(α •,Ωg ) = N d i=1 ||α i,Ωg || ∞ = N d i=1 max k∈Ωg |α i,k | .<label>(5)</label></formula><p>In general, structured sparsity can lead to more meaningful latent embeddings than sparse coding. For example, <ref type="bibr" target="#b3">[4]</ref> showed that the dictionary learned by grouping local image descriptors into images or classes achieved better accuracy than sparse coding for small dictionary sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multi-view Learning with Structured Sparsity</head><p>While the previous framework has proven successful for many tasks, it has only been applied to the single-view case. Here, we propose an approach to multi-view learning inspired by structured sparse coding techniques. To correctly account for the dependencies and independencies of the views, we cast the problem as that of finding a factorization of the latent space into subspaces that are shared across several views and subspaces that are private to the individual views. In essence, this can be seen as having each view exploiting only a subset of the dimensions of the global latent space, as depicted by Fig. <ref type="figure" target="#fig_0">1(d</ref>). Note that this definition is in fact more general than the usual definition of shared-private factorizations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20]</ref>, since it allows latent dimensions to be shared across any subset of the views rather than across all views only.</p><p>More formally, to find a shared-private factorization of the latent embedding α that represents the multiple input modalities, we adopt the idea of structured sparsity and aim to find a set of dictionaries D = {D (1) , D (2) , • • • , D (V ) }, each of which uses only a subspace of the latent space. This can be achieved by re-formulating problem (1) as</p><formula xml:id="formula_9">min D,α 1 N V v=1 X (v) -D (v) α 2 Fro + λ V v=1 ψ((D (v) ) T )<label>(6)</label></formula><formula xml:id="formula_10">s.t. ||α •,i || ≤ 1 , 1 ≤ i ≤ N d .</formula><p>where the regularizer ψ((D (v) ) T ) can be defined using the L 1,2 or L 1,∞ norm. In practice, we chose the L 1,∞ norm regularizer which has proven more effective than the L 1,2 <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b16">17]</ref>. Note that, here, we enforce structured sparsity on the dictionary entries instead of on the weights α. Furthermore, note that this sparsity encourages the columns of the individual D (v) to be zeroed-out instead of the rows in the usual formulation. The intuition behind this is that we expect each view X (v) to only depend on a subset of the latent dimensions. Since X (v) is generated by D (v) α, having zero-valued columns of D (v) removes the influence of the corresponding latent dimensions on the reconstruction.</p><p>While the formulation in Eq. 6 encourages each view to only use a limited number of latent dimensions, it doesn't guarantee that parts of the latent space will be shared across the views. With a sufficiently large number N d of dictionary entries, the same information can be represented in several parts of the dictionary. This issue is directly related to the standard problem of finding the correct dictionary size. A simple approach would be to manually choose the dimension of the latent space, but this introduces an additional hyperparameter to tune. Instead, we propose to address this issue by trying to find the smallest size of dictionary that still allows us to reconstruct the data well. In spirit, the motivation is similar to <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20]</ref> that use a relaxation of rank constraints to discover the dimensionality of the latent space. Here, we further exploit structured sparsity and re-write problem <ref type="bibr" target="#b5">(6)</ref> as</p><formula xml:id="formula_11">min D,α 1 N V v=1 X (v) -D (v) α 2 Fro + λ V v=1 ψ((D (v) ) T ) + γψ(α) ,<label>(7)</label></formula><p>where we replaced the constraints on α by an L 1,∞ norm regularizer that encourages rows of α to be zeroed-out. This lets us automatically discover the dimensonality of the latent space α. Furthermore, if there is shared information between several views, this regularizer will favor representing it in a single latent dimension, instead of having redundant parts of the latent space.</p><p>The optimization problem ( <ref type="formula" target="#formula_11">7</ref>) is convex in D for a fixed α and vice versa. Thus, in practice, we alternate between optimizing D with a fixed α and the opposite. Furthermore, to speed up the process, after each iteration, we remove the latent dimensions whose norm is less than a pre-defined threshold. Note that efficient optimization techniques for the L 1,∞ norm have been proposed in the literature <ref type="bibr" target="#b16">[17]</ref>, enabling efficient optimization algorithms for the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Inference</head><p>At inference, given a new observation {x </p><formula xml:id="formula_12">min α * V v=1 x (v) * -D (v) α * 2 2 + γ α * 1 ,<label>(8)</label></formula><p>where the regularizer lets us deal with noise in the observations.</p><p>Another advantage of our model is that it easily allows us to address the case where only a subset of the views are observed at test time. This scenario arises, for example, in human pose estimation, where view X (1) corresponds to image features and view X (2) contains the 3D poses. At inference, the goal is to estimate the pose x</p><p>(2) * given new image features x</p><p>(1) * . To this end, we seek to estimate the latent variables α * , as well as the unknown views from the available views. This is equivalent to first solving the convex problem</p><formula xml:id="formula_13">min α * v∈Va x (v) * -D (v) α * 2 2 + γ α * 1 ,<label>(9)</label></formula><p>where V a is the set of indices of available views. The remaining unobserved views x</p><formula xml:id="formula_14">(v) * , v / ∈ V a are then estimated as x (v) * = D (v) α * .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>While our method is closely related to the shared-private factorization algorithms which we discussed in Section 1, it was inspired by the existing sparse coding literature and therefore is also Method <ref type="bibr" target="#b25">[26]</ref> none</p><formula xml:id="formula_15">ψ(D) φ(α) C D or Cα PCA none none {D|D T D = I} SC (e.g. [25]) none α T 1,1 {D| Di 2 ≤ 1 ∀i ≤ N d } Group SC [4] D T 1,2 Ωg α•,Ω g 1,2 none SSPCA [9] Ωg D•,Ω g ξ,2 † none {α| αi,• 2 ≤ 1 ∀i ≤ N d } Group Lasso</formula><formula xml:id="formula_16">Ωg (αΩ g ,•) T 1,2 {D|D T D = I} Our Method Ωg (DΩ g ,•) T 1,∞</formula><p>α 1,∞ none † Here ξ denotes the vector lα/l1 quasi-norm. See <ref type="bibr" target="#b8">[9]</ref> for details.</p><p>Table <ref type="table">1</ref>: Properties of the different algorithms that can be viewed as special cases of RMF. related to it. In this section, we first show that many existing techniques can be considered as special cases of a general regularized matrix factorization (RMF) framework, and then discuss the relationships and differences between our method and the existing ones.</p><p>In general, the RMF problem can be defined as that of factorizing a P ×N matrix X into the product of a P × M matrix D and an M × N matrix α so that the residual error is minimized. Furthermore, RMF exploits structured or unstructured regularizers to constrain the forms of D and α. This can be expressed as the optimization problem</p><formula xml:id="formula_17">min D,α 1 N X -Dα 2 Fro + λψ(D) + γφ(α)<label>(10)</label></formula><formula xml:id="formula_18">s.t. D ∈ C D , α ∈ C α ,</formula><p>where C D and C α are the domains of the dictionary D and of latent embedding α, respectively. These domains allow to enforce additional constraints on those matrices. Several existing algorithms, such as PCA, sparse coding (SC), group SC, structured sparse PCA (SSPCA) and group Lasso, can be considered as special cases of this general framework. Table <ref type="table">1</ref> lists the regularization terms and constraints used by these different algorithms.</p><p>Algorithms relying on structured sparsity exploit different types of matrix norm<ref type="foot" target="#foot_0">1</ref> to impose sparsity and different ways of grouping the rows or columns of D and α using algorithm-specific knowledge. Group sparse coding <ref type="bibr" target="#b3">[4]</ref> relies on supervised information such as class labels to define the groups, while in our case, we exploit the natural separation provided by the multiple views. As a result, while group sparse coding finds dictionary entries that encode class-related information, our method finds latent spaces factorized into subspaces shared among different views and subspaces private to the individual views.</p><p>Furthermore, while structured sparsity is typically enforced on α, our method employs it on the dictionary. This also is the case of <ref type="bibr" target="#b8">[9]</ref> in their SSPCA algorithm. However, while in our approach the groups are taken as subsets of the rows of D, their method follows the more usual approach of defining the groups as subsets of its columns. Their intuition for doing so was to encourage dictionary entries to represent the variability of parts of the observation space, such as the variability of the eyes in the context of face images.</p><p>Finally, it is worth noting that imposing structured sparsity regularization on both D and α naturally yields a multi-view, multi-class latent space learning algorithm that can be deemed as a generalization of several algorithms summarized here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head><p>In this section, we show the results of our approach on learning factorized latent spaces from multiview inputs. We compare our results against those obtained with state-of-the-art techniques on the task of human pose estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Toy Example</head><p>First, we evaluated our approach on the same toy case used by <ref type="bibr" target="#b19">[20]</ref>. This shows our method's ability to correctly factorize a latent space into shared and private parts. This toy example consists of two 3-dimensional latent space recovered with our method. Note that, as opposed to CCA, our approach correctly recovered the generative signals and discarded the noise. (f) Dictionaries learned by our algorithm for each view. Fully white columns correspond to zero-valued vectors; note that the dictionary for each view uses only the shared dimension and its own private dimension. views generated from one shared signal and one private signal per view depicted by Fig. <ref type="figure" target="#fig_1">2(a,</ref><ref type="figure">b</ref>). In particular, we used sinusoidal signals at different frequencies such that</p><formula xml:id="formula_19">α (1) = [sin(2πt); cos(π 2 t))], α (2) = [sin(2πt); cos( √ 5πt))] ,<label>(11)</label></formula><p>where t was sampled from a uniform distribution in the interval (-1, 1). This yields a 3-dimensional ground-truth latent space, with 1 shared dimension and 2 private dimensions. The observations X (v)  were generated by randomly projecting the α (v) into 20-dimensional spaces and adding Gaussian noise with variance 0.01. Finally, we added noise of the form y noise = 0.02 sin(3.6πt) to both views to simulate highly correlated noise. The input views are depicted in Fig. <ref type="figure" target="#fig_1">2(c</ref>)</p><p>To initialize our method, we first applied PCA separately on both views, as well as on the concatenation of the views, and in each case, kept the components representing 95% of the variance. We took α as the concatenation of the corresponding weights. Note that the fact that this latent space is redundant is dealt with by our regularization on α. We then alternately optimized D and α, and let the algorithm determine the optimal latent dimensionality. Fig. <ref type="figure" target="#fig_1">2(e,</ref><ref type="figure">f</ref>) depicts the reconstructed latent spaces for both views, as well as the learned dictionaries, which clearly show the shared-private factorization. In Fig. <ref type="figure" target="#fig_1">2</ref>(d), we show the results obtained with CCA. Note that our approach correctly discovered the original generative signals and discarded the noise, whereas CCA recovered the shared signal, but also the correlated noise and an additional noise. This confirms that our approach is well-suited to learn shared-private factorizations, and shows that CCA-based approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11]</ref> tend to be sensitive to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Human Pose Estimation</head><p>We then applied our method to the problem of human pose estimation, in which the task is to recover 3D poses from 2D image features. It has been shown that this problem is ambiguous, and that sharedprivate factorizations helped accounting for these ambiguities. Here, we used the HumanEva dataset <ref type="bibr" target="#b21">[22]</ref> which consists of synchronized images and motion capture data describing the 3D locations of the 19 joints of a human skeleton. These two types of observations can be seen as two views of the same problem from which we can learn a latent space.</p><p>In our experiments, we compare our results with those of several regression methods that directly learn a mapping from image features to 3D poses. In particular, we used linear regression (Lin-Reg), Gaussian Process regression with a linear kernel (GP-lin) and with an RBF kernel (GP-rbf), and nearest-neighbor in the feature space (NN). We also compare our results with those obtained with the FOLS-GPLVM <ref type="bibr" target="#b19">[20]</ref>, which also proposes a shared-private factorization of the latent space. Note that we did not compare against other shared-private factorizations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>, or purely shared   models <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b22">23]</ref>, since they were shown to be outperformed by the FOLS-GPLVM <ref type="bibr" target="#b19">[20]</ref> for human pose estimation.</p><p>To initialize the latent spaces for our model and for the FOLS-GPLVM, we proceeded similarly as for the toy example; We applied PCA on both views separately, as well as on the concatenated views, and retained the components representing 95% of the variance. In our case, we set α to be the concatenation of the corresponding PCA weights. For the FOLS-GPLVM, we initialized the shared latent space with the coefficients of the joint PCA, and the private spaces with those of the individual PCAs. We performed cross validation on the jogging data, and the optimal setting λ = 0.01 and γ = 0.1 was then fixed for all experiments.</p><p>At inference for human pose estimation, only one of the views (i.e., the images) is available. As shown in Section 2.4, our model provides a natural way to deal with this case by computing the latent variables from the image features first, and then recovering the 3D coordinates using the learned dictionary. For the FOLS-GPLVM, we followed the same strategy as in <ref type="bibr" target="#b19">[20]</ref>; we computed the nearest-neighbor among the training examples in image feature space and took the corresponding shared and private latent variables that we mapped to the pose. No special care was required for the other baselines, since they explicitly take the images as inputs and the poses as outputs.</p><p>As a first case, we used hierarchical features <ref type="bibr" target="#b9">[10]</ref> computed on the walking and jogging video sequences of the first subject seen from a single camera. As the subject moves in circles, we used the first loop to train our model, and the remaining ones for testing. Table <ref type="table" target="#tab_2">2</ref> summarizes the mean squared reconstruction error for all the methods. Note that our approach yields a smaller error than the other methods. In Fig. <ref type="figure" target="#fig_2">3(a,</ref><ref type="figure">b</ref>), we show the factorization of the latent space obtained by our approach by displaying the learned dictionaries<ref type="foot" target="#foot_1">2</ref> . For the jogging case our algorithm automatically found a low-dimensional latent space of 10 dimensions, with a 4D private space for the image features, a 4D shared space, and a 2D private space for the 3D pose <ref type="foot" target="#foot_2">3</ref> . For the walking case, the  private space for the image features was found to be higher-dimensional. This can partially explain why the other methods did not perform as well as in the jogging case.</p><p>Next, we evaluated the performance of the same algorithms for different image features. In particular, we used randomized tree (RT) features generated by <ref type="bibr" target="#b18">[19]</ref>, and PHOG features <ref type="bibr" target="#b4">[5]</ref>. For this case, we only considered the walking sequence and similarly trained the different methods using the first cycle and tested on the rest of the sequence. The top two rows of Table <ref type="table" target="#tab_3">3</ref> show the results of the different approaches for the individual features. Note that, with the RT features that were designed to eliminate the ambiguities in pose estimation, GP regression with an RBF kernel performs slightly better than us. However, this result is outperformed by our model with PHOG features.</p><p>To show the ability of our method to model more than two views, we learned a latent space by simultaneously using RT features, PHOG features and 3D poses. The last row of Table <ref type="table" target="#tab_3">3</ref> shows the corresponding reconstruction errors. In this case, we used the concatenated features as input to Lin-Reg, GP-lin and NN. For GP-rbf, we relied on kernel combination to predict the pose from multiple features. For the FOLS model, we applied the following inference strategy. We computed the NN in feature space for both features individually and took the mean of the corresponding shared latent variables. We then obtained the private part by computing the NN in shared space and taking the corresponding private variables. Note that this proved more accurate than using NN on a single view, or on the concatenated views. Also, notice in Table <ref type="table" target="#tab_3">3</ref> that the performance drops when structured sparsity is only imposed on either D's or α, showing the advantage of our model over simple structured sparsity approaches. Fig. <ref type="figure" target="#fig_2">3(c</ref>) depicts the dictionary found by our method. Note that our approach allowed us to find latent dimensions shared among all views, as well as shared among the image features only.</p><p>Finally, we studied the influence of the number of training examples on the performance of the different approaches. To this end, we varied the training set size from 5 to 100, and, for each size, randomly sampled 10 different training sets on the first walking cycle. In all cases, we kept the same test set as before. Fig. <ref type="figure" target="#fig_3">4</ref> shows the mean squared errors averaged over the 10 different sets as a function of the number of training examples. Note that, with small training sets, our method yields more accurate results than the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have proposed an approach to learning a latent space factorized into dimensions shared across subsets of the views and dimensions private to each individual view. To this end, we have proposed to exploit the notion of structured sparsity, and have shown that multi-view learning could be addressed by alternately solving two convex optimization problems. We have demonstrated the effectiveness of our approach on the task of estimating 3D human pose from image features. In the future, we intend to study the use of our model to other tasks, such as classification. To this end, we would extend our approach to incorporating an additional group sparsity regularizer on the latent variables to encode class membership.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 1 )</head><label>1</label><figDesc>* , • • • , x (V ) * }, the corresponding latent embedding α * can be obtained by solving the convex problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Latent spaces recovered on a toy example. (a,b) Generative signals for the two views. (c) Correlated noise and the two 20D input views. (d) First 3 dimensions recovered by CCA. (e)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Dictionaries learned from the HumanEva data. Each column corresponds to a dictionary entry. (a) and (b) show the 2-view case, and (c) shows a three-view case. Note that in (c) our model found latent dimensions shared among all views, but also shared between the image features only.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Mean squared error as a function of the number of training examples using PHOG features only, RT features only, or both feature types simultaneously.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Mean squared errors between the ground truth and the reconstructions obtained by different methods.</figDesc><table><row><cell>Image Features</cell><cell>5 10 15</cell><cell></cell><cell></cell><cell></cell><cell>Image Features</cell><cell>5 10 15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12</cell><cell>14</cell></row><row><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3D Pose</cell><cell>20 30 40</cell><cell></cell><cell></cell><cell></cell><cell>3D Pose</cell><cell>20 30 40</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12</cell><cell>14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Mean squared errors for different choices of image features. The last two columns show the result of our method while forcing one regularization term to be zero. See text for details.</figDesc><table><row><cell>Feature</cell><cell cols="3">Lin-Reg GP-lin GP-rbf</cell><cell>NN</cell><cell cols="4">FOLS Our Method λ = 0 γ = 0</cell></row><row><cell>PHOG</cell><cell>1.190</cell><cell>1.167</cell><cell>0.839</cell><cell cols="2">1.279 1.277</cell><cell>0.778</cell><cell>2.886</cell><cell>0.863</cell></row><row><cell>RT</cell><cell>1.345</cell><cell>1.272</cell><cell>0.827</cell><cell cols="2">1.067 1.068</cell><cell>1.141</cell><cell>3.962</cell><cell>1.235</cell></row><row><cell>PHOG+RT</cell><cell>1.159</cell><cell>1.042</cell><cell>0.727</cell><cell cols="2">1.090 1.015</cell><cell>0.769</cell><cell>1.306</cell><cell>0.794</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In our paper, we define the Lp,q norm of a matrix A to be the p-norm of the vector containing of the q-norms of the matrix rows, i.e., A p,q = ( A1,• q , A2,• q , • • • , An,• q ) p .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note that the latent space per se is a dense, low-dimensional space, and whether a dimension is private or shared among multiple views is determined by the corresponding dictionary entries.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>A latent dimension is considered private if the norm of the corresponding dictionary entry in the other view is smaller than 10% of the average norm of the dictionary entries for that view.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sparse probabilistic projections</title>
		<author>
			<persName><forename type="first">C</forename><surname>Archambeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiple kernel learning, conic duality, and the SMO algorithm</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A probabilistic interpretation of canonical correlation analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno>688</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strelow</surname></persName>
		</author>
		<title level="m">Group sparse coding. Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image classification using random forests and ferns</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Munoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gaussian process latent variable models for human pose estimation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Ek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Workshop on Machine Learning and Multimodal Interaction</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ambiguity modeling in latent spaces</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Ek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Workshop on Machine Learning and Multimodal Interaction</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rank priors for continuous non-linear dimensionality reduction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Structured sparse principal component analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<meeting><address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semi-supervised hierarchical models for 3d human pose reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Probabilistic approach to detecting dependencies between data sets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The geometry of kernel canonical correlation analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<idno>TR-108</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Tübingen, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Max Planck Institute for Biological Cybernetics</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient sparse coding algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Context assisted information extraction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Leen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>High Street, Paisley PA1 2BE, Scotland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University the of West of Scotland, University of the West of Scotland</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Joint Manifold Model for Semi-supervised Multivalued Regression</title>
		<author>
			<persName><forename type="first">R</forename><surname>Navaratnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<meeting><address><addrLine>Rio, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-10">October 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An efficient projection for l1,infinity regularization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transfer learning for image classification with sparse prototype representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Randomized Trees for Human Pose Detection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rihan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Orrite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Factorized orthogonal latent spaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Ek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<meeting><address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning shared latent structure for image synthesis and robotic imitation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Shon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grochow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1233" to="1240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Humaneva: Synchronized video and motion capture dataset for evaluation of articulated human motion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno>CS-06-08</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Brown University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Shared kernel information embedding for discriminative inference</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large scale multiple kernel learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1531" to="1565" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Model selection and estimation in regression with grouped variables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="49" to="67" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
