<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Augury: Using Data Memory-Dependent Prefetchers to Leak Data at Rest</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jose</forename><forename type="middle">Rodrigo</forename><surname>Sanchez Vicarte</surname></persName>
							<email>josers2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign, ‡ Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Flanders</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Riccardo</forename><surname>Paccagnella</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign, ‡ Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Grant</forename><surname>Garrett-Grossman</surname></persName>
							<email>grantlg2@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign, ‡ Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Morrison</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
							<email>cwfletch@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois Urbana-Champaign, ‡ Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Kohlbrenner</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Augury: Using Data Memory-Dependent Prefetchers to Leak Data at Rest</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/SP46214.2022.00089</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Microarchitectural side-channel attacks are enjoying a time of explosive growth, mostly fueled by novel transient execution vulnerabilities. These attacks are capable of leaking arbitrary data, as long as it is possible for the adversary to read that data into the processor core using transient instructions.</p><p>In this paper, we present the first microarchitectural attack that leaks data at rest in the memory system, i.e., never directly read into the core speculatively or non-speculatively. This technique is enabled by a previously unreported class of prefetcher: a data memory-dependent prefetcher (DMP). These prefetchers are designed to allow prefetching of irregular address patterns such as pointer chases. As such, DMPs examine and use the contents of memory directly to determine which addresses to prefetch.</p><p>Our experiments demonstrate the existence of a pointerchasing DMP on recent Apple processors, including the A14 and M1. We then reverse engineer the details of this DMP to determine the opportunities for and restrictions it places on attackers using it. Finally, we demonstrate several basic attack primitives capable of leaking pointer values using the DMP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>As the demand for performance gains in general purpose CPUs continues and the gains from Moore's scaling dwindle, microarchitects have consistently delivered surprising and powerful optimizations. However, these optimizations come with drawbacks, notably in how they inadvertently leak information via microarchitectural side channels.</p><p>Today's microarchitectural side channels are only capable of leaking data in use. That is, data is speculatively or nonspeculatively architecturally accessed and then transmitted through an "unsafe instruction". For example, data might be read into an architectural register and then acted on by an instruction that changes hardware resource usage in an operand-dependent fashion <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b28">30]</ref>. This restriction to data in use limits attacks in situations where victim programs lack access or transmit gadgets or when the programs are specifically written to not contain such gadgets as in constanttime programming <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b47">49]</ref>.</p><p>Yet, there has recently been speculation that we are standing on a precipice, about to face an even more insidious threat: microarchitectural side channels that leak data at rest <ref type="bibr" target="#b42">[44,</ref><ref type="bibr" target="#b43">45]</ref>. These attacks are brought on by exotic microarchitectural optimizations such as silent stores <ref type="bibr" target="#b30">[32]</ref>, cache compression <ref type="bibr" target="#b35">[37]</ref> and data memory-dependent prefetchers <ref type="bibr" target="#b48">[50]</ref> all of which can leak data even if it is never brought into the processor core. Consider for example a processor that implements a data 1 The two first authors contributed equally to the paper. memory-dependent prefetcher (DMP). Unlike well-known and widely implemented prefetchers whose behavior is "just" a function of a program's address pattern (limiting their leakage to program address pattern/control flow <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b40">42]</ref>), DMPs read and initiate cache fills based on the contents of program data memory directly.</p><p>This immediately puts all of program memory at risk. For example, Vicarte et al. <ref type="bibr" target="#b43">[45]</ref> point out how a specific proposed DMP called the indirect-memory prefetcher <ref type="bibr" target="#b48">[50,</ref><ref type="bibr" target="#b49">51]</ref> can be coerced into leaking all of program memory, similar to Spectre/Meltdown but without relying on transient instruction execution. Making matters worse, as the DMP lives in the memory system, it accomplishes this without the secret data ever being read from the cache into the processor core, rendering current constant-time programming techniques ineffective.</p><p>Fortunately for defenders, data-at-rest attacks have been purely theoretical. While there is a rich literature on DMPs, there has been no evidence to suggest they have ever been implemented in commercial processors.</p><p>In this paper, we demonstrate for the first time the existence, and resulting security implications, of a DMP in the wild. By extension, this shows that microarchitecture leaking data at rest is real. We refer to our techniques as Augury due to their reliance on interpreting what the prefetcher believes about the future.</p><p>Specifically, we found that the Apple M1, M1 Max, M1 Pro, and A14 processors possess an Array-of-Pointers (AoP) prefetcher that recognizes streaming and striding reads and dereferences over an array of pointers, and then prefetches the result of dereferencing future pointers. To see the difference from conventional prefetchers, suppose a program is looping from i=0...N and has allocated an array A which is indexed by i. A conventional prefetcher would prefetch an access pattern such as A As the AoP DMP operates only on a stream of memory accesses, and does not have any concept of array bounds, this prefetcher can overshoot the legal set of pointers to access and attempt a prefetch of unrelated memory addresses up to its prefetch depth. This act of dereferencing the out-of-bounds pointer (potentially even if it is not actually a pointer!) creates a memory side channel that an attacker can use to learn the pointer. In fact, we show that this pattern recognition is relatively robust, can operate at large strides, and can trigger even if all memory accesses are speculative and eventually squashed. Together, these capabilities enable the attacker to target and leak pointer values across much of memory.</p><p>There have been many proposed DMP patterns, and since none have previously been found, there is little in the way of guideposts for understanding DMP behaviors. As there is no documentation for even the existence of the M1 AoP DMP, simply finding the activation pattern is a non-trivial matter. 1  Even then, knowing that an AoP DMP exists does not clearly lay out a plan for attack primitives or for software mitigations. To aid in this, we present a detailed analysis of the AoP DMP behavior and we also provide guidance for the reverse engineering and security analysis of any DMP system.</p><p>For attackers, this prefetcher opens up new, previously unconsidered exploitation scenarios. For defenders, the existence of this prefetcher, and the attacks it enables, is a call to action for developing new approaches for programming techniques that can protect data not even being operated on.</p><p>Contributions. Our major contributions are:</p><p>• We analyze the security relevant design factors for DMPs.</p><p>• We demonstrate the existence of the first known datamemory prefetcher in a commercial processor family. • We reverse-engineer the activation criteria, depth of prefetch, and other features of the M1 DMP. • We demonstrate that this prefetcher can be used to cause unexpected pointer de-references, putting data at risk. • We demonstrate the first microarchitectural attacks on data at rest by using the M1 DMP to construct exploit primitives that leak pointer values. Disclosure. We coordinated with Apple on disclosure and mitigation prior to publication.</p><p>Release of tools. Following disclosure, we have made our tools for investigating DMP behavior on ARM and x86 chips, as well as our proof-of-concept attack primitives available at: https://github.com/FPSG-UIUC/augury.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND AND MOTIVATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Classical prefetchers</head><p>We now review how hardware prefetchers work, and their status from a security perspective. Fig. <ref type="figure" target="#fig_4">1</ref>: A high-level architecture for classical prefetchers/PFs (left) and data memory-dependent prefetchers/DMPs (right). 1 We thank Anandtech for their analysis of the A14 processor that speculated a "pointer-chase prefetch mechanism" <ref type="bibr" target="#b20">[22]</ref> might exist in that processor.</p><p>To start, we review what we call classical prefetchers (prefetchers for short). These are widely deployed in commercial processors. For example, both Intel and AMD report multiple distinct prefetchers in their recent processors <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>Like prefetchers, caches are present in multiple forms and levels on nearly all modern processors. Generally, each processor core will have at least 1 level of private cache, split into an instruction and data cache. Below this, there is at least one level of shared cross-core cache, generally storing both data and instructions. By default, caches will exploit temporal locality to hide the latency of repeated accesses to memory by storing data recently used by the core.</p><p>Prefetchers are next-in-sequence address predictors that proactively fetch data into the cache to help hide memory latency. Figure <ref type="figure" target="#fig_4">1</ref> (left) gives a high-level overview. In Step (training), the prefetcher records whether the address sequence coming from the core matches a specific pattern. In Step (prefetching), if a pattern was recognized with sufficient confidence, the prefetcher autonomously makes accesses to memory to fill the cache with cache lines that it thinks will be requested in the near future. In Step (validation), the prefetcher checks whether its predictions were correct by checking the core's subsequent requests. Note, we separate the above steps to ease explanation; similar to a branch predictor, train/prefetch/validate all occur concurrently and continuously.</p><p>For example, a typical address pattern that can be captured by a prefetcher is a stride through an array, e.g., int A[M]; ... // e.g., initialize A for (i = 0 ... M) A[k * i]; for some constant stride k. Upon observing the core request addresses &amp;A[0], &amp;A[k], ..., &amp;A[k * N], the prefetcher predicts that the core will request &amp;A[k * (N+1)], ..., &amp;A[k * (N+delta)] in the near future and proactively issues cache fills for those cache lines. Here, N is the confidence threshold: how many accesses must be seen before the prefetcher activates. delta is the depth: how far ahead the prefetcher prefetches once it activates. Depth is often directly correlated to the confidence: As more accesses are made, the prefetcher will fetch proportionally farther ahead.</p><p>Importantly, prefetchers live in the memory system and are software transparent. For example, they might live between the core and level 1 (L1) cache, or between two lowerlevels (L2+) of cache. As such, they are unaware of program semantics: they only see the program address pattern and try to predict the next address. In the above code snippet, the prefetcher is unaware of the array A, its base or its bound. Thus, the prefetcher will prefetch data out of bounds of A, i.e., up to address &amp;A[M+k * delta], before it realizes through subsequent failed validations that the program doesn't intend to access beyond the array bounds. This will have important security implications later on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Classical prefetcher security implications</head><p>Several recent papers have studied prefetchers in a security context <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b40">42]</ref>. We also note Gruss et al.'s <ref type="bibr" target="#b23">[25]</ref> work on vulnerabilities in software prefetch instructions, which we consider out of scope. At a high level, prefetcher attacks work in a similar fashion to branch predictor-and cachebased attacks <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b33">35]</ref>. Specifically, when a victim program unknowingly interacts with a prefetcher, these interactions create microarchitectural persistent state changes such as in the cache or the prefetcher's internal state. An attacker (receiver) can use techniques like cache-based side-channels to measure these changes. Interestingly, prior work has shown how this can increase leakage beyond normal cache attacks. For example, many cache attacks leak the address pattern at a coarse, e.g., cache line-or page-granularity <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b45">47]</ref>. The prefetcher, however, stores address pattern information at a finer, e.g., byte, granularity.</p><p>Despite the above, leakage through the prefetcher is limited to the victim's address pattern. This means that prefetcher attacks can be mitigated through constant-time programming practices that ensure that the memory address pattern is completely independent of secret data <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b47">49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Data memory-dependent prefetchers (DMPs)</head><p>Beyond classical prefetchers, there is significant work in the computer architecture literature <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b48">50]</ref> and several industry patents <ref type="bibr" target="#b39">[41,</ref><ref type="bibr" target="#b49">51]</ref> on what we refer to as data memory-dependent prefetchers (DMPs). These are designed to prefetch irregular address patterns such as pointer chases or indirections that cannot be predicted without understanding dependencies between the address pattern and the contents of memory itself <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b48">50]</ref>.</p><p>See Figure <ref type="figure" target="#fig_4">1</ref> (right) for an overview. Similar to a classical prefetcher, a DMP trains , prefetches , and validates its predictions . During the train phase, the DMP monitors the data returned to the core as well as subsequent addresses and tries to determine whether the address stream is a specific function of the data returned. For example, in a pointer chase data will be directly used as an address. In the prefetch phase, the prefetcher will initiate reads to memory that follow the predicted pattern. This, crucially, requires the prefetcher to examine and act on the contents of data memory directly. For a pointer chase, the prefetcher will read a cache line that it believes contains a pointer and then dereference the pointer.</p><p>Depending on the address pattern, this can be a complex multi-interactive procedure. The common proposed patterns are shown in Figure <ref type="figure" target="#fig_2">2</ref>, and discussed in more detail in Section IV-B. For example, the DMP in <ref type="bibr" target="#b48">[50]</ref> patented by Intel <ref type="bibr" target="#b49">[51]</ref> is capable of prefetching through address patterns such as shown in Figure <ref type="figure" target="#fig_2">2d</ref> with L = 2. This requires that the DMP not only perform multiple levels of indirection autonomously-each of which may require virtual-to-physical address translations/direct interactions with the TLB-but also infer each array's base address through relations between data and subsequent accesses. Recall, the DMP only sees data returned to the core and subsequent addresses sent by the core. Specifically, the DMP only sees physical (post-translation) addresses. In this example, the data returned to the core in the first stage of the indirection is A[k * i] -an offset into array B -and the subsequent address sent back to the memory system is &amp;B[A[k * i]]. Thus, to predict the indirection into  B for future k * (i+delta), the DMP must use the data and addresses it has seen so far to infer &amp;B[0]. Note, A[k * i] is an offset into an array in the program's virtual address space, whereas &amp;B[A[k * i]] is likely a physical address. So, the DMP must autonomously perform virtual to physical address translations to identify data-address correspondences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. DMP security implications</head><p>To our knowledge, prior to this paper, there has been no evidence to suggest that any DMP is implemented in any commercial processor. Nor (by extension) has there been analysis of the security implications of DMPs in the wild. Vicarte et al. <ref type="bibr" target="#b43">[45]</ref> did recently perform an analysis of the security implications of proposed microarchitecture, including DMPs, but these were not known to be implemented. While their work was theoretical, it points out how DMPs have potentially disastrous security implications. For example, consider an indirection-based DMP that prefetches the pattern C[B[A[k * i]] similar to the one in Figure <ref type="figure" target="#fig_2">2d</ref>. Misused, this DMP can be coerced to leak all of program memory, similar to Spectre and Meltdown <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b31">33]</ref>. To see this, suppose that the DMP was used in a sandbox setting. In that case, the attacker controls the program and can therefore easily force the DMP to activate. The attack proceeds as follows. 1) the attacker specifies a value (call it j) stored off the end of array A. j will correspond to the address of the value in memory the attacker wants to learn. 2) the DMP erroneously reads j and accesses memory to read C[B[j]]. Recall from Section II-A, prefetchers do not know array bounds. Thus, B[j] can refer to the data at any memory location. Finally, C[B[j]] serves as the transmitter in a memory side channel: B[j] is a secret and C[B[j]] turns that secret into an address to memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Apple Silicon</head><p>Modern Macs no longer use Intel processors, but instead use the new (ARM) M1 line. As the M1 is very similar to previous Apple processors, vulnerabilities in it may affect millions of consumers. We have confirmed that our findings apply to the A14 (iPhone 12) and the new M1 Max at a minimum.</p><p>The M1 has eight cores: four high-performance Firestorm and four energy-efficient Icestorm cores <ref type="bibr" target="#b10">[12]</ref>. As we find the DMP to only be present on the Firestorm cores, we focus on the relevant Firestorm details. Each core has a private L1 cache, and there are two large L2 caches shared between cores of the same type. The four Firestorm cores share a 12 MiB L2, and the Icestorm cores share 4 MiB. Each Firestorm core has a private 192 KiB L1 instruction cache and 128 KiB L1 data cache <ref type="bibr" target="#b9">[11]</ref>. While there is no official information on the associativity or cacheline size, we found that L2 lines are 128 bytes, and L1 lines are 64 bytes.</p><p>When filling L1d lines, two adjacent L1d lines are brought in at a time, and both are independently evictable. We also believe that the L1 is 8-way associative and the L2 is 16-way associative from our experience building eviction sets (Section VII-C).</p><p>A major complication for reverse engineering is reports that the M1 DRAM controller performs frequency scaling <ref type="bibr" target="#b32">[34]</ref>. This matches our observations that a cache miss to DRAM can return in a wide range of times. We find that increasing the pressure on DRAM can reduce the average access time more than amortizing measurement costs would anticipate. The net effect is that we observe otherwise inexplicable decreases in memory access times for longer experiments.</p><p>Other relevant aspects of the M1 include that it can have an unusually large number of instructions in flight to exploit instruction level parallelism <ref type="bibr" target="#b26">[28]</ref>, and does not support any form of Simultaneous Multi-Threading (SMT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THREAT MODEL AND ATTACKER OBJECTIVES</head><p>There are two main threat models we consider for the M1 DMP: adversarial unprivileged (or sandboxed) code, and latent gadgets in benign code. This is similar to prior microarchitectural vulnerability research that exploits unprivileged attacker code as well as cases of privileged programs containing speculative gadgets <ref type="bibr" target="#b28">[30]</ref>. The M1 does not support any form of simultaneous multithreading and so it is not considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Sandboxed Adversarial Code</head><p>In this model, we assume a standard microarchitectural sandboxed attacker: the adversary is able to run arbitrary sandboxed code on a system that does not trust the sandboxed code. The adversary is attempting to perform memory reads outside the sandbox and will leverage microarchitectural details of the processor to achieve this. This is a scenario commonly seen with JavaScript sandboxes in browsers, the kernel sandbox for eBPF code, NaCl modules, and more.</p><p>As we assume the sandbox model, the adversary will control the training pattern that will eventually activate the DMP. The training pattern is the series of legal, in-sandbox memory accesses made by the adversary that will cause the DMP to activate and fetch data based on the predicted next accesses after the training pattern. The adversary leverages this behavior to cause the DMP to read outside of the sandbox, and then leak that information back to the adversary.</p><p>We additionally assume that the adversary can use standard cache side channels to retrieve information about the cache state. We demonstrate specifically using Prime+Probe on the M1 in Section VII-C, but these include Prime+Probe <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b36">38]</ref>, Flush+Reload <ref type="bibr" target="#b46">[48]</ref>, and other similar styles of attack. The attacker will use these techniques to receive the secrets transmitted via cache state by the DMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Latent DMP Gadgets</head><p>Like with other microarchitectural attacks, it may be the case that a victim program already contains the necessary code patterns an adversary can use to induce an adversarial training pattern. This is not unlikely, as during our reverse engineering we found it easy to unintentionally activate the DMP by accessing stack variables that are pointers and causing the DMP to prefetch other pointers on the stack.</p><p>In this model, we assume the adversary at most has control over a set of inputs to the program, and must leverage an existing set of memory operations. This model can facilitate an attack, e.g., if the memory operations' access pattern is a function of the attacker input. It is also possible for a program to, without any adversarial interaction, cause a DMP to activate and leak information.</p><p>One possible example of the former would be a syscall that dereferences userspace-defined pointers, such as readv or writev. In these situations, the adversary may be able to induce activation of the DMP during kernel execution and cause the DMP to leak data near the kernel buffer containing data copied from userspace.</p><p>For the latter, consider a program that accesses (unconditionally) addresses X, A, B, and C, where X is the address of an attacker controlled string buffer. If the buffer contains the values "A,B,C,Z" then it is possible the DMP will interpret X as an Array-of-Pointers currently being iterated over and dereferenced, and then (attempt) to prefetch Z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. THE DANGERS OF DMPS</head><p>As part of our study of the DMP present in Apple CPUs, we first had to consider the possible design dimensions of a DMP, and the relevant security impact of each. While any DMP will have security implications, understanding the implementation of a specific DMP is necessary for making definite claims about the vulnerability of real programs and to formulate platform-specific software defenses. For example, a DMP using a prefetch buffer (see Section IV-D) may not even provide an advantage over standard cache side channels! A DMP performs several important actions during operation that allow for the use of side channels to determine secrets. We will use the terminology of access-transmit-receive for discussing the leakage of secrets <ref type="bibr" target="#b27">[29]</ref>. After activating, any data read by the DMP to determine addresses for prefetching is considered accessed. The DMP is then considered to have transmitted that data when it performs a prefetch to an address which is a function of the data. Finally, the adversary uses some side-channel attack (cache occupancy, cache contention, etc.) to receive that data.</p><p>Below, we explore the possible design space for a DMP through a security lens. This analysis is driven by our survey of existing DMP and prefetcher literature, existing prefetcher reverse engineering, and questions that arose while working on this paper. As real DMPs have not previously been evaluated for security impact, this is an unexplored area useful for framing both the M1's DMP as well as any future DMP analysis. Relevant axes of interest are:</p><p>• What are the preconditions for DMP activation?</p><p>• What memory is accessed to inform prefetching?</p><p>• What function of memory values is transmitted?</p><p>• How can the adversary receive the transmitted values?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preconditions for a DMP to activate</head><p>Like classical prefetchers, a DMP must track memory accesses made by programs and decide when to activate. Based on previous prefetcher designs, we know that this may track only address suffixes, may organize tracking entries by PID, may organize memory accesses by the instruction address they originate from, and may rely on another non-DMP prefetcher to retrieve data. Each of these possibilities has significant impact on what an attacker can do with that DMP.</p><p>If, like the Intel L1i prefetcher <ref type="bibr" target="#b15">[17]</ref>, the DMP only tracks address suffixes, then it is vulnerable to aliasing attacks. This allows an adversary to train the prefetcher using noncontiguous memory accesses that only appear to be contiguous when the upper bits of the address are ignored. For example, an adversary could train a DMP over a sandboxed memory region but a safe access outside of the sandbox that aliases to the same pattern could activate prefetches outside the sandbox.</p><p>Instruction-pointer (IP) tagged pattern tracking on the other hand limits attacker capabilities by restricting the code performing dereferences to loops. Without IP tagging, the memory access pattern can originate from any series of instructions that perform memory accesses. These instructions may not even intentionally be referencing related memory, and may simply appear to the DMP to be a contiguous streaming access.</p><p>Like general DMP address tracking, IP tagging may only track address suffixes <ref type="bibr" target="#b29">[31]</ref>. Once again, this will allow an adversary to perform aliasing attacks where two distinct instructions that share an address suffix will be conflated by the DMP as the same originating address.</p><p>Process ID (PID) tagging, like IP tagging, limits the adversary by forcing all accesses and prefetches to occur in the same process. Without PID tagging an adversary may be able to train the DMP on one process, and then allow the unrelated victim accesses to cause DMP prefetches.</p><p>Finally, it may be the case that the DMP follows some classical prefetcher on the system. This would mean that the DMP's top-level activation criteria and restrictions are the same as that classical prefetcher's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data access patterns for DMPs</head><p>The most important feature to the attacker is which values the DMP will access to inform prefetching.</p><p>The first concern is if the DMP is single or multi-layer (see Figure <ref type="figure" target="#fig_2">2</ref>). A single layer DMP performs only one (effective) memory dereference per-prefetch. An N-layer DMP will perform N dereferences per-prefetch. As an example, a prefetcher that simply prefetches the memory backing all pointers in an array-of-pointers ( * arr[n+1]) is a single-layer DMP. A prefetcher that fetches not only the data backing a pointer in memory, but also interprets that data as a pointer and dereferences again ( ** arr[n+1]) is a two-layer prefetcher.</p><p>Multi-layer DMPs are exceptionally powerful for an attacker and most other design decisions become irrelevant if the DMP is multi-layer. The reason is that the attacker can precondition the first value being accessed (e.g., arr[n+1]) to refer to an arbitrary memory location, meaning the DMP can subsequently access arbitrary program memory. This is well demonstrated in Vicarte et al. <ref type="bibr" target="#b43">[45]</ref> which shows how to use the 2-level Indirect Memory Prefetcher (IMP) <ref type="bibr" target="#b48">[50]</ref> to construct a Universal Read Gadget and transmit the contents of all of virtual memory. For the rest of this section we assume a single-layer DMP.</p><p>As with classical prefetchers, a DMP is likely capable of detecting a stride pattern where the access pattern touches non-adjacent items in memory. Stride detection will have some maximum distance within which sequential accesses are considered part of the pattern. This maximum stride will determine the maximum distance from the end of the training pattern that the DMP will prefetch from.</p><p>Any prefetcher will also have a maximum number of elements that it is willing to prefetch, generally increasing with higher confidence. This is the effective depth of the prefetcher. Fundamentally, the furthest value that can be targeted by a DMP is (max stride × depth) + end o f training address. We will refer to max stride × depth as the maximum prefetch distance (in bytes).</p><p>As we will see with the M1 AoP DMP, there can be other unusual restrictions on what memory the DMP can access. These don't follow any particular set of rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Function of data transmitted by a DMP</head><p>A DMP can be either a pointer-chasing prefetcher or it can be an indirection based prefetcher (see Figure <ref type="figure" target="#fig_2">2</ref>).</p><p>A pointer-chasing DMP dereferences pointers in memory and prefetches the cache lines found there. Thus, an attacker that controls the train pattern can trick the DMP into dereferencing a secret value as if it were a pointer. These DMPs allow an adversary in control of the training pattern to cause a secret memory location to be treated as an address, and to attempt a load of that address. If the secret value is a valid pointer, this will transmit the pointer value through standard cache side-channels. If it is not an address, it may still be possible for the adversary to monitor the (failed) page-walk or use TLB side-channels <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b41">43]</ref> to learn the upper bits of the secret.</p><p>Indirection DMPs dynamically determine the base address of some array(s) and prefetches portions of it based on a series of index values in memory. These are more powerful transmitters than pointer-chasing DMPs as they easily transmit values that are not valid virtual addresses. Specifically, an attacker that controls the train pattern can trick the DMP into treating a secret as an offset in a base-plus-offset calculation. Suppose the attacker additionally controls the base address (which is the case, if the attacker controls the training pattern). Then the indirection-based DMP avoids the previouslydiscussed issue in the pointer-chasing prefetcher: the attacker can arrange for the base-plus-offset to fall within a mapped memory region that is accessible to the attacker. This allows both for simpler transmission and straight-forward cacheoccupancy side-channels for reception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Receiving data transmitted by a DMP</head><p>Once a DMP has accessed and transmitted a secret, the adversary must now receive that secret. In the simplest case of an indirection prefetcher this would involve checking the access time (cache occupancy status) of every entry in the base array. For pointer-chasing prefetchers this would mean running a cache contention side-channel to detect what address was brought into the cache.</p><p>A DMP may alternatively prefetch to a prefetch buffer rather than directly to the cache. A prefetch buffer is a small, typically fully associative, cache which only holds prefetched data. Only prefetched data can induce contention on this buffer, making it significantly harder for the adversary to observe the effect of the prefetch. Then, there must be an actual access to the address corresponding to the transmitted value to observe a timing difference or affect cache state.</p><p>Since the value being transmitted is the address in question for single-layer DMPs, it may not be possible for the adversary to directly access this address at all. This would occur because it is unlikely that a secret address is mapped into the adversary's virtual address space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXISTENCE OF THE M1 DMP</head><p>In this section, we provide a detailed walkthrough of our initial experiments confirming the existence of a specific DMP while ruling out the existence of several other DMPs. We also describe the steps we took to determine that the root cause of our observations was, in fact, a DMP as opposed to other microarchitectural features (like speculative execution).</p><p>We tested for the existence of four DMPs: both single-and two-level versions of pointer-chasing and indirection-based DMPs (Section IV). Our findings show the existence of a single-level pointer-chasing DMP, so our focus below is on how we setup the experiment for that variant. We discuss other variants (negative results) at the end of the section (V-F).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment overview</head><p>To confirm the existence of the single-level pointer-chasing DMP (referred to as the DMP for short), we compare the execution time of two different methods for accessing the same randomly generated sparse series of memory addresses. The first method-the AoP DMP pattern-pre-computes all memory addresses and stores them sequentially in an array-of-pointers (AoP). The addresses are then accessed by streaming over the AoP and dereferencing each pointer. The second method-the baseline-accesses the same series of addresses by computing them on the fly. Computing the addresses ensures they cannot be prefetched by either a DMP or a classical prefetcher. Both experiments generate addresses using the same PRNG seed.</p><p>All experiments insert dependencies between operations such as loads and PRNG calls. This action prevents out-oforder execution from issuing multiple operations simultaneously and makes overall execution time strongly correlated to the average memory access time.</p><p>Finally, the cache is flushed between experiments to remove inter-experiment interference. We discuss this and other methodological details, e.g., ensuring that both experiments run the same instruction sequences, in Section V-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Setting up the sequence of memory accesses</head><p>We set up the experiment by allocating two large buffers as shown in Figure <ref type="figure" target="#fig_3">3</ref>. One of the buffers, the data buffer, is filled with random data, and the other buffer, the AoP, is filled with unique pointers to disjoint and non-consecutive 128-byte chunks of the data buffer.</p><p>These constraints are not necessary to activate the DMP but will amplify the signal to noise ratio of DMP-caused speed ups and minimize any affects from noise or other microarchitectural optimizations. In particular, uniqueness and 128-byte aligned accesses ensure that data backed by pointers is not already cached from being accessed earlier in the experiment. Recall from Section II-E, the M1 has 128 byte (L2) cache lines. Using pointers to non-consecutive chunks improves the likelihood that a classical prefetcher (Section II-A) will not activate from data buffer accesses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Access patterns and other considerations</head><p>After setting up the data buffer and the AoP, there are still some precautions that must be taken when accessing the pointers to ensure a speedup can only be caused by a DMP.</p><p>If we were to just measure the execution time of two different loops-one baseline access pattern loop and one AoP access pattern loop-then we would be comparing the execution time of two different instruction sequences. The AoP access pattern has an extra memory access per loop iteration since it must: 1) indirect by some offset into the AoP and 2) dereference the pointer stored in the AoP. Whereas the baseline must 1) make a single memory access and 2) use a PRNG to compute the next data buffer address on each iteration. Thus, seeing different runtimes for the two loops would not be surprising, and not necessarily be due to the presence of a DMP. MEM BARRIER is an instruction/data serialization instruction. PRNG is a C macro that expands into a Lehmer random number generator, i.e., is not implemented as a syscall. The code is compiled with compiler optimizations turned off, and the assembly code was manually inspected to ensure intended behavior.</p><p>To address these discrepancies, we ensure that both the baseline and AoP experiments execute the same instructions, while taking care to ensure that the baseline does not activate a DMP. The code used for both experiments is shown in Algorithm 1. For the baseline, we add an access and dereference the pointer at index 0 of the AoP during each iteration (Line 16). For the AoP case, we compute the address on the fly as in the baseline (Line 19) but use the pointer read from the AoP to lookup the data buffer (Line 17). With both experiments executing the same instructions, we expect the baseline to run slightly faster than the AoP pattern due to occasional cache misses from AoP traversal.</p><p>It is also necessary during baseline runs to set all pointers in the AoP to point to the first element in the data buffer: otherwise the DMP activates during the baseline run due to the single AoP access combined with the computed pattern being similar to the AoP case pattern. This is an instance of the pattern described in III-B where a single read of a cacheline containing pointers is misinterpreted as the source of multiple pointer dereferences.</p><p>Finally, we add dependencies between operations to ensure that speedups are not due to out-of-order execution. Specifically, dep val in Algorithm 1 ensures that all loads are executed serially and between the timer start and stop operations. Note that the first load in each iteration, which looks up data bu f , depends on both the previous load into the AoP and the PRNG computation-regardless of whether the baseline or AoP-based experiment is being run. This, coupled with the fact that both the AoP lookup and PRNG operation are expected to be relatively fast, implies that the loop's performance will be strongly correlated to the data bu f access latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Other Notes on Methodology</head><p>We find the DMP to be present solely on Firestorm cores. To improve consistency, we core pin our experiments by setting the thread quality of service, as described in <ref type="bibr" target="#b0">[1]</ref>. We do not perform any kind of frequency pinning (for the Firestorm cores or for DRAM) throughout our experiments.</p><p>Our experiments make use of two different timers: the M1's performance monitoring counter (PMC) <ref type="bibr" target="#b25">[27]</ref> and the mach_absolute_time macOS syscall <ref type="bibr" target="#b2">[3]</ref>. The PMC can measure time at cycle-granularity with Apple reporting a maximum clock speed of 3.2 GHz for the Firestorm cores whereas mach_absolute_time can measure time at a granularity of (on average) 42 ns per 'tick'. Despite the coarser-grain measurement, we use the mach_absolute_time timer in many situations since we found it easier to work with (e.g., accessible from userspace, accessible across cores) and sufficient to distinguish between cache hit vs. DRAM access events. We use the PMC in select experiments to distinguish between finer-grain events (e.g., an L1 cache vs. L2 cache hit).</p><p>For all experiments with either timer, we first measure the timer's overhead by running a start timer-stop timer pair back to back in an empty loop. This overhead is subtracted from all points on graphs that use that timer. For mach_absolute_time, we found the overhead to be ∼ 42 ns and convert measurements using that timer to ns using that conversion rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results</head><p>Figure <ref type="figure">4</ref> reports the time elapsed (stop timestart time) for the baseline and DMP variants tested in Algorithm 1, for different length sequences of pointers (AoPs). The main takeaway is that the "Array of Pointers" variant (testing the presence of a single-level pointer-chasing DMP) sees significant speedup (3 − 8X) on medium to large AoPs compared to the baseline ("Computed") access times.</p><p>We note that, while the AoP variant always sees speedup relative to the baseline, the speedup varies as a function of NUM PTRS. To break this down, we divide Figure <ref type="figure">4</ref> into three regimes (1), ( <ref type="formula">2</ref>) and (3) demarcated with vertical dashed lines. In regime (1)-small NUM PTRS-the speedup is initially zero and increases quickly with NUM PTRS. This is due to timer granularity: for small NUM PTRS, timer overhead dominates. In regime (2)-medium NUM PTRS-the speedup converges given sufficiently large NUM PTRS. We attribute this to the DMP improving the average memory access time in the AoP-based experiment. Finally, in regime (3)large NUM PTRS-the speedup decreases with NUM PTRS. Fig. <ref type="figure">4</ref>: Execution times for the single-level pointer-chasing DMP ("Array of Pointers"), single-level indirection-based DMP ("Indirections"; c.f. Section V-F3), and Baseline/pointers computed on the fly ("Computed") patterns, using the setup in Algorithm 1. We measure access time using on-chip timers according to Algorithm 1 (stop timestart time). Times are obtained using mach_absolute_time and converted to nanoseconds as described in Section V-D. For the indirection-based access pattern, the AoP dereference is replaced with an indirection. Each point represents average pointer dereference time (averaged across 2560 runs and the number of accesses in the train loop) with error bars representing standard deviation.</p><p>We attribute this to the DRAM frequency scaling discussed in Section II-E. From the core's perspective, an increase in DRAM frequency will appear as a decrease in access times.</p><p>These results provide evidence that the speedups are not the result of speculative execution. First, speculation would not cause such a large and consistent speedup for the AoP while leaving the baseline-which executes the same (serialized) instruction sequence in the same loop-unaffected. <ref type="foot" target="#foot_1">2</ref> Second, these speedups vanish when we run the same experiment on the M1's Icestorm cores, which still feature speculative execution but (presumably) lack other high-performance microarchitectural features such as the DMP.</p><p>The results are consistent with the behavior of a DMP (Section II-A). When iterating through smaller AoPs (regimes (1) and (2) in Figure <ref type="figure">4</ref>), the DMP is less confident and dereferences fewer pointers. When iterating through larger AoPs (regime (2)), the DMP is more confident and aggressively dereferences more pointers resulting in larger speed ups <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b48">50]</ref>.</p><p>1) Testing for prefetches+dereferences of unaccessed AoP entries: We also tested the existence of the DMP with a second methodology. Shown in Figure <ref type="figure" target="#fig_3">3</ref>, the idea is to have the test program stop iterating through the AoP without accessing all of the pointers and to then test whether the next unaccessed AoP entries have been prefetched and dereferenced. If the AoP stores M pointers, we have the test program access N pointers for N &lt; M. We then perform what we call a test access, and measure the time to load the cache line at the address given by aop[M]. <ref type="foot" target="#foot_2">3</ref> Critically, we avoid interaction with the DMP by not accessing the aop during the test access. That is, by computing and accessing the address pointed to by aop[M] in the same manner as in the baseline case.</p><p>Figure <ref type="figure">5</ref> shows the time to perform one of these test accesses for N = 256 pointers and M = 259 as well as measured access latencies to various memory levels (L1, L2, DRAM). Lower latency test accesses indicate the DMP prefetched and dereferenced data. The figure shows that test accesses for the DMP configuration track closely with the L2 cache hit latency. From this, we conclude that the DMP prefetches into the L2 cache and is likely built alongside the L2. Fig. <ref type="figure">5</ref>: Test access latency, relative to the baseline (computing pointers on the fly) and measured access latencies to different level memories. Time is measured using the fine-grain performance monitoring counter from Section V-D. The label 'Fastest main memory times' refers to the fastest main memory time we observed with DRAM frequency scaling (Section II-E).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Testing for the existence of other prefetchers</head><p>So far we have only discussed the existence of a singlelevel, pointer-chasing DMP. We also tested whether the M1 contained other classical prefetchers and other data memorydependent prefetchers. We found the M1 does feature at least one other classical prefetcher but does not contain the other data memory-dependent prefetchers described in Section IV.</p><p>1) Testing for classical (stride) prefetchers: We confirmed through a separate analysis that the M1 contains a separate classical (stride) prefetcher that prefetches data into the L1 cache. Based on our analysis, this prefetcher seems to be completely separate from the DMP-i.e., has different depth, confidence, etc., parameters-and thus does not impact what data the DMP can access (Section IV-B). Thus, we do not study it further in this paper.</p><p>2) Testing for multi-level pointer-chasing DMPs: Next, we tested whether the pointer-chasing DMP we had been focusing on was multi-level. Confirming whether such a prefetcher is present is very important since having more than one level dramatically increases the scope of data that the DMP can access (Section IV-B).</p><p>For this experiment, we added another level to the AoP and reran the previous experiments. Specifically, we allocate an additional array which holds pointers to random 128-byte chunks of the original AoP. We call this additional array the outer AoP and the original AoP the inner AoP. The pointers in the outer AoP are again spaced out so that there is only one pointer at the start of every 128-byte chunk with the rest of the chunk zero-padded. We ensured that the pointers chosen for the outer AoP would not cause the DMP to activate for the inner AoP and data buffer, which would create false positives. The access pattern and training loop is then the same as the AoP DMP (Algorithm 1), but this time we double dereference the pointer at the current index of the AoP.</p><p>3) Testing for single-level indirection-based DMPs: Next, we tested for the existence of a single-level indirectionbased prefetcher such as the indirect memory prefetcher (i.e., B[A[i]] <ref type="bibr" target="#b48">[50]</ref>). Such prefetchers also have interesting (and different) security implications due to their ease of leaking nonpointer data (Section IV-C). For this experiment, we changed the single-level AoP-style code in Algorithm 1 so that the AoP would store offsets into a second array, as opposed to direct pointers into memory.</p><p>4) Results: Both of the above experiments did not indicate the presence of other styles of DMP. Figure <ref type="figure">4</ref> "Indirections" shows the performance of the indirection-based experiment relative to the pointer-chasing variants. We did not try to equalize the instruction sequences between this variant and the pointer-chasing variants. Yet, the Indirections variant results in performance that is very similar to the pointer-chasing variant. This is expected assuming no such indirection-based DMP exists: both codes are memory bound (hence, performance is largely a function of the average memory access time) and exhibit the same memory system performance.</p><p>Since the single-level indirection-based prefetcher experiment returned a negative result, we did not directly test the existence of a multi-level indirection-based prefetcher.</p><p>5) Other microarchitectures: We also ran existence tests for indirection-based DMPs (Section V-F3) and the singlelevel, pointer-chasing DMP (Algorithm 1) on more than 5 Intel and 3 AMD processor families, more than 50 machines in total. In none of these systems did we observe test pointers being prefetched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. REVERSE ENGINEERING THE M1 DMP</head><p>After confirming that there is a DMP on the M1, we now turn to reverse engineering the parameters of the M1 DMP so that we can exploit it. Recall from Section IV that we need to answer the following questions to understand how to exploit or mitigate a DMP:</p><p>• What are the preconditions for DMP activation?</p><p>• What memory regions can a DMP access?</p><p>• What function of memory values is transmitted?</p><p>• How can the adversary receive the transmitted values? These questions are discussed below and summarized in Table <ref type="table" target="#tab_3">II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. What are the preconditions for activating the M1 DMP?</head><p>We identified four conditions necessary to activate the M1's DMP.</p><p>1) Fire vs. Icestorm cores: Any thread interacting with the must be running on a Firestorm core (Section II-E). Developers and MacOS users can specify whether a program should run on an Icestorm or Firestorm core by modifying a process's quality of service (QoS) bits. For example, setting a process's QoS to 'user interactive' will cause the process to be scheduled only on Firestorm cores <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b24">26]</ref>.</p><p>2) DMP "noise" tolerance: There are restrictions on operations between sequential accesses of the AoP. We examined four types of noise: serialization, system calls, other spurious operations, and time. We found that system calls and serialization such as instruction and data synchronization barriers <ref type="foot" target="#foot_3">4</ref>placed between accesses to pointers in the AoP prevents the DMP from activating. On the other hand, we found that the DMP is generally tolerant of time-based delays between memory accesses and the insertion of unrelated arithmetic (e.g., incrementing a counter variable from 1 to 1000) or memory operations between accesses.</p><p>3) DMP minimum confidence threshold: For the DMP to activate, the program needs to dereference at least 3 pointers in the AoP. That is, the DMP has a minimum confidence threshold of 3 accesses to activate at all (Section II-A). We determined this threshold by running the Section V-E1 experiment with various lengths of training loop (N). We then find the smallest N at which we observe cache hits on dereferencing the (un-touched) test pointers. On the M1, this occurs after 3 AoP pattern accesses. This is consistent with Figure <ref type="figure">4</ref>, which shows the AoP and baseline patterns diverging for train lengths between 2 and 4.</p><p>4) AoP alignment requirements: The M1 DMP will not build confidence if the addresses of the pointers in the AoP are not aligned to eight-byte boundaries. This is easily observed by offsetting the start of the AoP by any amount that is not a multiple of 8, and running any of the previous experiments. This is slightly disappointing for attackers, as it precludes a sliding-window style attack where the attacker learns a secret byte-by-byte through repeated experiments with differentlyaligned AoPs. <ref type="foot" target="#foot_4">5</ref>We also make several observations that weaken assumptions needed to activate the DMP.</p><p>5) The DMP is not IP indexed: We observed that the M1 DMP is not IP indexed. That is, the instructions that cause the memory accesses matching the AoP pattern need not be related in any way. We tested this by unrolling the training loop from Algorithm 1 into straight-line memory accesses without branches and observing that both of the experiments from Section V still show the DMP activating.</p><p>6) The DMP can be activated using only speculative accesses: We found that the DMP can be activated using only speculative memory accesses that are eventually squashed. We demonstrate this by adapting a Spectre attack example [5] to run on the M1, and using it to activate the DMP on branch mispredictions (Algorithm 6). Instead of tricking the branch predictor into reading out of bounds, the experiment will read the first three elements in the DMP AoP pattern when it mispredicts and speculatively executes. Since DMP activation is slightly noisy for an AoP with 3 pointers (Figure <ref type="figure" target="#fig_2">2</ref>), the experiment performs this branch-predictor training and misprediction loop many times (lines 7-16) to raise confidence in whether target ptr was dereferenced or not. If the DMP can be triggered via speculation only, then the target pointer should be dereferenced and it will be a cache hit which is tested for on line 17. Algorithm 2: Pseudocode of experiment for determining whether the DMP will activate when all memory accesses are speculative and eventually squashed. This code will also be used in our ASLR break (Section VII-D). p1, p2, p3 are unique random pointers to a data buffer. The cache line storing the value 0 used in the conditional check is evicted on each iteration. Figure <ref type="figure" target="#fig_6">6</ref> shows the dereference times of the target ptr (line 17) across 1530 experiment runs. The baseline shows dereference times for the target pointer without the three speculative accesses on each 6th train loop iteration-i.e., it never mispredicts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. What memory regions can the M1 DMP access?</head><p>There are two main considerations for whether or not the M1 DMP can leak a secret at a given address: 1) how far the secret is located from an adversary-interactable AoP and 2) whether the DMP is willing to prefetch memory located at any reachable address.</p><p>Recall from Section IV-B that the location of the furthest pointer past the end of an AoP that a singlelevel DMP can dereference is (max stride × depth) + end o f training address where the maximum prefetch distance is max stride × depth in bytes. In the case of the M1, we found that the DMP will also activate when traversing an AoP backwards.</p><p>1) Determining maximum prefetch distance (as a function of confidence, stride and depth): We found there to be a non-trivial relationship between DMP confidence (the number of training accesses touching the AoP) and stride (distance between pointers) in determining the M1 DMP's maximum prefetch depth. This is shown in Figure <ref type="figure" target="#fig_1">7</ref> and Table <ref type="table" target="#tab_1">I</ref>. The high-order bit is that a stride of 64 cache lines (8 KiB) enables the DMP to reach (access and dereference) a pointer 64 KiB (i.e., 8 pointers deep) away from either end of the AoP.</p><p>To start, Figure <ref type="figure" target="#fig_1">7</ref> shows that the number of entries the DMP is willing to prefetch and dereference (depth) is clearly proportional to the number of accesses the program makes that match the DMP's target pattern (confidence). This is consistent with expected DMP behavior (Section V-E). Note, consistent with Section VI-A3, the AoP DMP plot only shows low latency test accesses for train sizes 4 and larger. We note two other features in the data. First, when more than 2048 accesses are performed, either the first eight or sixteen accesses are not prefetched. This behavior is caused by a 16 KiB page boundary, and is further studied in Section VI-B2. Second, for both the AoP and baseline patterns, as the number of accesses increases, the access time for misses decreases. We propose an explanation for this in Section V-E.</p><p>Table <ref type="table" target="#tab_1">I</ref> reports the maximum distance in bytes we can prefetch/dereference a pointer. We run this experiment with a training loop that is large enough to maximize confidence (and therefore depth, see previous paragraph). Our experiments show that the maximum distance is not monotonically increasing with stride, but larger strides do tend to enable larger maximum prefetch distances, as expected. To summarize, up to a stride of 8 KiB, the maximum distance increases (up to a maximum distance of 64 KiB). We did not see the DMP activate for strides larger than 8 KiB (1024 pointers).</p><p>Finally, we observed that the DMP does not activate when the stride, at cache line granularity, is not a power of two. This is shown in Figure <ref type="figure" target="#fig_8">8</ref>. We confirmed that low measurements on the y-axis (faster times) occur iff test accesses are dereferenced, i.e., indicate that the DMP activated.   <ref type="figure" target="#fig_1">7</ref>) while avoiding the page boundary interaction described in Section VI-B. All memory in the AoP in between touched pointers (for a given stride) is zeroed.</p><p>2) Unprefetchable virtual address regions: Unexpectedly, we found that the M1 DMP behavior is affected by the virtual address of the AoP itself and the virtual addresses of pointers contained in the AoP. We found that the M1   <ref type="table" target="#tab_1">I</ref>. All memory in the AoP in between touched pointers (for a given stride) is zeroed. Times are measured using mach_absolute_time and converted to nanoseconds as described in Section V-D.</p><p>DMP does not dereference pointers located in the cacheline immediately after 16 KiB or 2 MiB virtual address boundaries of the AoP and has additional odd behavior depending on which boundary (16 KiB or 2 MiB) we try to get it to cross. We illustrate this behavior with a dense AoP in Figure <ref type="figure" target="#fig_9">9</ref>. We see that the DMP does not dereference pointers located in the 128 bytes immediately after the 16 KiB page boundary (y-axis value 4096), but it does dereference the pointers before and after this 'dead zone'. However, if the last training access of the AoP occurs after the 16 KiB page boundary (x-axis values 4096-4103, then the DMP only refuses to dereference the pointers in the second 64 byte chunk after the 16 KiB boundary until train accesses touch this 64 byte chunk (xaxis value 4104). Notably, this behavior is independent of AoP sparsity. Though a sparse AoP will naturally have fewer pointers within these 128 byte regions.</p><p>We observed a more aggressive behavior at 2 MiB address boundaries of the AoP. This behavior is, once again, independent of AoP sparsity. The DMP will not dereference any pointers past a 2 MiB boundary of the AoP. When a training loop crosses this boundary, the DMP's confidence resets and must retrain based on pointers accessed after the boundary.</p><p>These interactions are difficult to explain because: 1) the L1 stride prefetcher (Section V-F1) prefetches AoP lines across the 16 KiB boundary, and 2) the DMP induces page walks that populate the TLB entries for both the AoP and the pointers in the AoP (Section VI-C). We observed similar results running this experiment on Asahi Linux.This means that the reluctance of the DMP to cross these boundaries is not due to any safeguards against address translation.</p><p>We additionally observed that on MacOS, the DMP will not dereference pointers contained in the AoP which have a virtual address between 0x280000000 and 0x7fe840004000-the end of mappable user-space addresses. On Asahi Linux, which allows us to map virtual addresses above 0x7fe840004000, we found the DMP to activate and dereference pointers above 0xffff3f2b0000, but then addresses below 0x280000000 are not dereferenceable. At this time, we do not have an explanation for why there are restrictions on the virtual addresses the M1 DMP will dereference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. What function of memory values is transmitted?</head><p>The M1 AoP DMP makes prefetches based on memory content as if it were pointer values. This, naively, places a major restriction on the function of values transmitted. Only the top 57 bits of the address/value (i.e., L2 cacheline granularity) is transmitted, and only if they are a valid virtual address. As pointers must be placed at 8-byte alignments (Section VI-A), we cannot read partial values. (Section VI-A4).</p><p>We did, however, find that the M1 DMP fills entries in the TLB for the pointers in the AoP. To test this we set up an AoP in the usual way but made each 'test pointer' after the end of the AoP a pointer to a unique page. We can then use the mprotect system call to change the protection bits of pages associated with the test pointers to invalidate their TLB entries. We now set up two experiments: 1) where we mprotect the test pointers before streaming through the AoP and 2) where we mprotect the test pointers after streaming through the AoP. <ref type="foot" target="#foot_5">6</ref> If the DMP fills TLB entries, then the test pointer access  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. How can an adversary receive the transmitted values?</head><p>We found three attacker visible ways that the M1 DMP affects microarchitectural state: it prefetches to the L2 cache, it fills TLB entries, and it has internal state (e.g., confidence).</p><p>To receive changes to L2 cache state, the adversary may use directly timed accesses to the cache, use a cache side channel like Prime+Probe <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b36">38]</ref>, or alternatively use an interconnect side channel <ref type="bibr" target="#b34">[36]</ref>. The TLB entries may also be attacked directly using a TLB side channel <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b41">43]</ref>.</p><p>So far, the retrieval methods have had secrets or pointers of interest after the end of the AoP, but attackers can also learn about pointers contained in the AoP by using the DMP's confidence metrics as an indicator. We showed earlier in Figure <ref type="figure" target="#fig_1">7</ref> that higher confidences result in deeper prefetching, and frome Section VI-A3 that the DMP needs 3 AoP patterned accesses to then prefetch the "4th" (next) pointer. We can use these effects to determine the validity of pointers under the right circumstances. We later show in Section VII-D how one can use the DMP's confidence to break ASLR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXAMPLES OF AUGURY TECHNIQUES</head><p>In this section, we cover four scenarios where the M1 DMP can be used in attacks: performing out-of-bounds reads, beating speculative load hardening, retrieving leaked addresses via Prime+Probe, and breaking ASLR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Out-of-Bounds Reads</head><p>Algorithm 3 shows a proof-of-concept (PoC) which uses the DMP to read past the end of a buffer. We start by picking three random pointers (test p 1, test p 2, and test p 3) that point to different cachelines of memory. Although in this example these pointers are accessible to the attacker, we know that the DMP alters the L2 cache and TLB, so an attacker could instead conduct an attack like Prime+Probe if they did not have access to these pointers <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b36">38]</ref>. The user then picks one of the pointers on line 2, and we will use the DMP to determine which pointer the user picked without reading it. To activate the DMP, we first create an AoP filled with AOP SIZE random pointers to disjoint 128-byte chunks of memory. This AoP is placed immediately before the memory location containing the user-chosen pointer. AOP SIZE must be at least 3 to activate the DMP, with larger sizes increasing the DMP's confidence and the clarity of the signal. Next, we flush the entire cache state by reading in several MB of unrelated data on line 3. We do this to ensure that the only test pointer that has a cache hit will be the pointer off the end of the AoP, assuming it is prefetched. We now stream through the AoP, accessing and dereferencing each pointer in it, and not the test pointer outside the AoP (see lines 4-6.) We have unrolled the loop for two reasons: it makes it clear that this is not a speculative execution effect, and it also demonstrates that attackers only need to induce an access pattern that looks like the cache misses caused by streaming through an AoP.</p><p>After training the DMP, we measure the access time to each of the 3 test pointers. Since only the the user selected pointer should be prefetched into L2, it will be the fastest to access</p><p>We ran this PoC 500 times using an AoP of size 64, selecting a different test pointer number each time, and measuring its accuracy in distinguishing pointers. For the first 250 runs, we used the M1's PMC (see Section V-D) which can very accurately distinguish between L2 and main memory access times. For the latter 250 runs, we used mach_absolute_time which is noisier than the PMC. The with the PMC the PoC had a 92.0% average accuracy-i.e., number of times the PoC correctly picked the pointer. With mach_absolute_time, the PoC had a 70.2% average accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Beating Speculative Load Hardening</head><p>Speculative load hardening (SLH) is a defense against conditional branch-based speculative execution attacks, known by the name of Spectre Variant #1 <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b28">30]</ref>. Some pseudocode with and without SLH applied is shown in Algorithm 4.</p><p>SLH prevents Spectre Variant #1 by adding a branchless recheck of each branch condition within each conditional's Algorithm 4: Example of gcc and clang's SLH hardened AoP iteration loop <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b13">15]</ref>. We apply SLH by providing clang with the -mspeculative-load-hardening flag <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b5">7]</ref>. This option for AArch64 masks only the loaded value, and this is the only SLH option for AArch64 when using LLVM 14 (the current latest version). Note that there are additional speculative-execution-specific instructions inserted in the final compiler output.</p><p>body to apply an all-ones or all-zeroes bitmask to a data load. This results in the load working as expected when the branch predictor is correct and only loading from offset 0 when the branch predictor guesses incorrectly. In the case of the SLH train loop in Algorithm 4, the hardening of loaded values also applies to the index into the array of pointers; this should prevent the accesses from speculatively reading past the bounds of the array of pointers.</p><p>Since the DMP only ever sees cache misses, the (nonspeculative) access pattern caused by both loops in Algorithm 4 will be the same. SLH provides no protection against using the DMP to bypass the bounds check. We reran our existence experiments from Section V with the SLH compiler flag enabled and confirmed that they still work. We also reran the PoC from Algorithm 3 getting an accuracy of 88.0% with the AoP accesses turned back into a loop, SLH enabled, and using the PMC. Indeed, the exploits should still work since to the memory system, the memory accesses caused by both loops in Algorithm 4 will be the same, and the additional instructions inserted from SLH do not prevent DMP activation.</p><p>While it is unsurprising that SLH does not protect against DMP leakage, it is important to note that some code vulnerable to Spectre V1, but protected by SLH, will continue to be vulnerable to the same receive side-channel as before. As such, a developer applying SLH to attacker submitted code or code containing latent DMP gadgets (such Algorithm 4) gains almost no defensive advantage. However, unlike the Spectre attacks that SLH was designed to prevent, the M1 DMP has a maximum stride and depth which constrains the furthest value past the end of a buffer that can be prefetched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Retrieving leaked pointers via Prime+Probe</head><p>The previous example primitives rely on the adversary being able to directly time accesses to the targeted pointers to determine their cache state. This is often not possible, and we can instead use cache side-channels like Prime+Probe to determine if a given pointer was prefetched.</p><p>We set up this experiment identically to the basic out-ofbounds read in Section VII-A. However, we use only two test pointers (test p 0 and test p 1) and build eviction sets of size 24 for each (ev 0 and ev 1 ) using the baseline algorithm from Vila et al <ref type="bibr" target="#b44">[46]</ref>. Each run of the experiment randomly chooses either test p 0 or test p 1 as the test pointer.</p><p>After the training accesses are complete, we time an access to each eviction set (ev 0 and ev 1 ) independently. The eviction set with a longer access time corresponds to the pointer we guess as the test pointer. In general this manifested as one eviction set taking around 100 PMC cycles longer to access than the other. Across 4300 runs, this resulted in a correct guess in 60.0% of runs. However, if we remove runs where the Probe step failed, and did not result in ev 0 or ev 1 being significantly slower, the accuracy rises to 84.8%. The net effect is that Prime+Probe, while effective, adds another layer of noise to the recovery of pointer values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Breaking ASLR by testing virtual addresses</head><p>Address space layout randomization (ASLR) is a widely deployed defense that prevents attackers from knowing a priori where important parts of a program live in memory. It does this by randomizing the memory locations of portions of a program such as the stack, heap, code, and libraries.</p><p>Breaking ASLR (that is, discovering the virtual addresses of code and data pages) is a core step in a larger exploit. We show how the DMP can be used to check whether arbitrary pointers are valid mapped virtual memory addresses and thus aid in breaking ASLR. Using the DMP rather than a cache sidechannel removes the need for knowledge of the cache system, or creating eviction sets, and is significantly less noisy.</p><p>We set up an experiment similar to Algorithm 2, with the third pointer (p3) replaced with the address we wish to test validity of. Since the DMP requires 3 accesses (see Section VI-A) that match the AoP pattern to activate, we can use the DMP's confidence threshold as a metric for the validity of p3. Since the test address may not be readable and reading it would cause a segfault, ensure that all three training accesses are only speculative, and eventually squashed. Since Section VI-A showed that the DMP can be activated in these conditions, the fourth pointer (p4, the target pointer) will be prefetched if and only if the p3 (the test address) was valid.</p><p>Using our experiment code from Algorithm 2 written in C (and using mach_absolute_time), we can test a virtual address for validity on average every 24.91 ms with standard deviation 0.79 ms. This long duration is due to an unoptimized implementation that uses cache thrashing rather than targeted eviction sets. The attacker can repeat this per-pointer validity test to sweep across the address space, trying each virtual memory page and determining which are mapped. This will, at the least, reveal the location and size of memory regions that are mapped for use by the program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. MITIGATING THE THREAT OF DMPS</head><p>Unfortunately, the AoP DMP is already widely deployed on at least the A14 and M1 family of processors. This DMP, to our knowledge, cannot be disabled via software updates. Given that our experiments show the DMP is not present on Icestorm cores (See Section V-E), the only dependable mitigation is to execute sensitive software on the Icestorm cores at a significant performance cost. For sensitive software running on Firestorm cores, our remaining option is to modify the software to besteffort avoid DMP-caused data leakage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Removing secrets</head><p>If we assume a sandboxed threat model, our most straight forward solution is similar to the one adopted by most Spectre defenses: do not keep secret data in the same virtual address space as the adversary sandbox or user-space program. This is only applicable to cases where secret data and attacker code are co-located, and is not relevant to other situations.</p><p>Since Spectre vulnerabilities have put all of a process' virtual memory space at risk of being leaked, we have seen widescale deployment of policies like Chrome's Site Isolation <ref type="bibr" target="#b37">[39]</ref>. These policies segment untrusted code (like sandboxed JavaScript) from sensitive data (such as the rendering data from another web origin) by placing them into entirely separate virtual address spaces. Similarly, KPTI/KAISER <ref type="bibr" target="#b22">[24]</ref> removed virtual address mappings for the kernel from userspace processes. The net effect of these changes was the removal of valuable targets from the virtual address space of highly attacker-influenceable code. Thankfully, these partitioning efforts have removed most of the obvious sandbox or userspace to kernel attack surfaces for the M1 DMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Preventing M1 DMP interaction</head><p>For both the sandbox and latent gadget cases, we can use any features or implementation quirks that cause the DMP to ignore values or never activate. We consider this as preventing the DMP from ever accessing and transmitting a secret bit.</p><p>In Section VI-B2 we found that the M1's DMP is unwilling to prefetch pointers to specific virtual address regions. As the DMP will skip pointers that are in this address range even after it begins fetching nearby pointers, we can put all data in this region and prevent pointers to it from leaking. We caution that there is no known explanation for why this region exists, and leveraging it should not be considered a complete mitigation.</p><p>We also found that the DMP requires pointers to be aligned on 8-byte boundaries. If all pointers in the program are non-8-byte aligned, the prefetcher cannot to prefetch them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Protecting non-pointer values from the M1 DMP</head><p>Both of the above approaches assume that the DMP leaks only pointer values. We believe that this is not a fundamental limitation of the M1 DMP, and that by observing changes to the cache caused by page walks and the TLB an adversary may be able to receive information about a failed (invalid pointer) prefetch. If this is the case, we must consider any page walk that varies based on secret bits to be leaking information <ref type="bibr" target="#b21">[23]</ref>. One possible defense would be to only store secret data in the bottom N-bits of every 64-bit aligned chunk, and ensure that the top N-bits are never a valid virtual address prefix. Any attempted prefetch of a 64-bit chunk containing secrets would then fail before the pagewalk encountered secret related bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. General DMP mitigations</head><p>The only generalized, but incomplete, mitigation to all DMPs is to remove secrets from the virtual address spaces accessible to adversaries, similar to many Spectre mitigations. Unfortunately there is no guarantee that all DMP implementations will happen to reach a subset of the memory reachable by Spectre. As we outlined in Section IV there are many possible design possibilities like aliasing or cross-PID training that would reach beyond what a Spectre attack can.</p><p>Orthogonal to removal of secrets, we should also consider cases where a privileged non-malicious program contains latent DMP gadgets that must be detected and removed. In our experiments we repeatedly unintentionally activated the AoP DMP by storing pointers on the stack. With a DMP this aggressive, it is possible for a program to be accidentally leaking secret values without any intervention by an adversary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. CONCLUSIONS</head><p>Exotic microarchitectural optimizations that leak data never accessed by the core have arrived in mainstream processors and are unlikely to disappear any time soon. The M1 has been rightfully lauded for performance and efficiency, and the recent M1 Pro and Max continue to drive excitement for novel microarchitectural approaches. While exceptional now, we expect that this AoP DMP is only the first of many DMPs to be deployed across all architectures and manufacturers.</p><p>Here, we've demonstrated that, while difficult to wield, the M1's DMP is capable of being abused by an adversary. It can read and transmit some types of memory values outside of sandboxes or test the validity of pointers controlled by an attacker. This is despite a single-level pointer-chasing DMP being nearly the worst-case DMP for an attacker, leaking only pointers and only under restricted situations. Thankfully, many particularly worrying scenarios like JavaScript sandboxes already assume that an adversary can leak any value in the virtual address space. These systems are unlikely to have significant security impacts from the M1 DMP. However, given the ease with which the DMP can be activated, it is likely that existing programs and kernels contain latent DMP gadgets that can be leveraged to leak data in their own address spaces.</p><p>As with timing attacks, Spectre attacks, and others, we emphasize the need for compiler and program transformation tools to adapt to mitigate data at rest leakage. The M1 DMP is an opportunity to prepare our defensive software techniques for the next generation of microarchitectural attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. ACKNOWLEDGMENTS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[i] or A[stride * i]. The M1's AoP DMP prefetches access patterns such as * A[i] or * A[stride * i].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>7 Z</head><label>7</label><figDesc>= 0; i &lt; len(A); i++) [Y [(...) A[k * i ]]]; (d) L-level indirection-based.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Examples of types of DMP expected access patterns. k is the constant stride. L is the number of pointer dereferences that occur ignoring streaming over A. The left column is the explicit L = 1 case. L is a DMP design decision. We discovered a 1-Level Pointer Chasing DMP (a) on the Apple M1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Memory layout of the DMP AoP and data buffer. Black arrows illustrate memory accesses due to aop dereferences (Line 17) in Algorithm 1.Baseline accesses (Line 16) directly load the same entries in the data bu f without dereferencing from the aop. The AoP shown contains pointers which are consecutive in memory (unit stride). Each pointer points to disjoint and non-consecutive 128-byte chunks of the data buffer. If we access the AoP from index 1 through N and the DMP activates, the contents of the data buffer at aop[M] for M &gt; N may be brought into the cache.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 :</head><label>1</label><figDesc>dep val = MSB(data bu f [rand idx * (1 − aop mode) * CL SIZE | dep val]) /* AoP Access */ 17 dep val = MSB( * aop[aop idx | dep val]) 18 aop idx = aop idx + aop mode 19 rand idx = PRNG(rand idx) 20 end 21 MEM BARRIER 22 stop time = READ TIMER(dep val) Pseudocode for the baseline experiment (which computes pointers on the fly) and the experiment testing for the presence of a single-level pointer-chasing DMP and baseline. READ TIMER calls mach absolute time which returns time in ticks. CL SIZE stands for the (128 byte) cache line size. Dependencies are guaranteed to resolve to zero by using only their Most Significant Bit; denoted by MSB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1</head><label></label><figDesc>aop[0 * 128] = p1 2 aop[1 * 128] = p2 3 aop[2 * 128] = p3 4 aop[3 * 128] = target ptr 5 aop[4 * 128] = target ptr 6 FLUSH CACHE 7 for train iter in 1...30 do 8 idx1 = 0 /* Branchless if-then-elses */ 9 idx2 = if (train iter%6) then 0 else 1 10 idx3 = if (train iter%6) then 0 else 2 11 if idx3 == access evicted memory containing(0) 12 * aop[idx1 * 128] 13 * aop[idx2 * 128] 14 * aop[idx3 * 128] 15 end 16 end 17 result = was l2 timing(target ptr)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Speculative accesses in an AoP pattern causes the DMP to activate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: DMP prefetch depth is a function of train loop size (NUM PTRS in Algorithm 1). The left/right graphs show results for the single-level AoP/baseline experiments in Algorithm 1. Each column (along the x-axis) represents a single training loop size. Each row in a given column (along the y-axis) corresponds to a test access latency into data bu f (Section V-E1) that far away from the last pointer touched in the training loop. Times are measured using mach_absolute_time and converted to nanoseconds as described in Section V-D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: DMP training loop performance as a function of stride. All experiments use a large training loop size, similar to TableI. All memory in the AoP in between touched pointers (for a given stride) is zeroed. Times are measured using mach_absolute_time and converted to nanoseconds as described in Section V-D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: For different training AoP lengths N (x-axis), what is the access latency for values in data bu f corresponding to pointers in the AoP at offsets N + M (y-axis). The dashed lines indicate cacheline boundaries in the AoP. A 16 KiB Boundary occurs at aop[4096]. Times are measured using mach_absolute_time and converted to nanoseconds (Section V-D.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>The maximum distance ahead in memory prefetched is a function of stride. All experiments are performed using 4144 training accesses. This number of accesses achieves the maximum prefetch depth (Figure</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc>Summary of the M1 DMPtimes for experiment 1 should be faster than experiment 2, and if it does not fill TLB entries, then the access times should be the same. Across 250 runs of each experiment, we found that the average test pointer access time and standard deviation for experiment 1 was 27.95 cycles and 2.8 cycles respectively (using the PMC), and the times for experiment 2 were 110.83 cycles and 49.87 cycles respectively. From this, we conclude that the DMP does fill TLB entries which transmits the page bits of the value through another channel.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>/* Stick the user chosen pointer after the filled AoP */ 1 aop[0 : AOP SIZE − 1] = ... /* Random, unique ptrs */ 2 test p = user choice(test p 1,test p 2,test p 3) Algorithm 3: PoC using straight-line memory accesses to activate the DMP and distinguish between three pointers.</figDesc><table><row><cell>3 thrash cache()/* Evict test pointers */</cell></row><row><cell>/* Train the DMP by streaming through the AoP */</cell></row><row><cell>4  * aop[0]</cell></row><row><cell>5 . . .</cell></row><row><cell>6  * aop[AOP SIZE − 1]</cell></row><row><cell>/* Find the fastest test pointer access time */</cell></row><row><cell>7 time( * test p 1)</cell></row><row><cell>8 time( * test p 2)</cell></row><row><cell>9 time( * test p 3)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 14:41:02 UTC from IEEE Xplore. Restrictions apply.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Subsequent results in Section VI are also inconsistent with speculative execution but consistent with prefetchers.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">This assumes M ≤ N + where is the prefetcher depth (Section II-A). In this experiment, we assume that this holds and that is known. Analyzing what is the depth in different situations is a subject in Section II-A.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://developer.arm.com/documentation/100941/0100/Barriers.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">Recall from Section IV-C, the attacker may be able to learn high-order bits of a secret (even if it is not a virtual address) by monitoring TLB and related MMU state. A sliding-window attack can amplify this leakage by tricking the DMP into interpreting different secret bytes as high-order address bits.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">We also pad the mprotect syscalls with 10,000 cycle delays on both sides of the call and again add data dependencies.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We thank our anonymous reviewers for their valuable feedback to this paper. We thank Andrei Frumusanu for their exceptionally insightful remark "[...] we might believe they're using some sort of pointer-chase prefetching mechanism." <ref type="bibr" target="#b20">[22]</ref>. We thank Dean Tullsen for seeding this idea. This work was funded partially by NSF grants 1954521 and 1942888, as well as by an Intel RARE grant.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 14:41:02 UTC from IEEE Xplore. Restrictions apply. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://developer.apple.com/library/archive/documentation/Performance/Conceptual/powerefficiencyguidelinesosx/PrioritizeWorkAtTheTaskLevel.html" />
		<title level="m">Energy Efficiency Guide for Mac Apps: Prioritize Work at the Task Level</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://software.intel.com/en-us/articles/intel-sdm" />
		<title level="m">Intel x86 64 and ia32 developers manual</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="https://developer.apple.com/documentation/kernel/1462446-machabsolutetime" />
		<title level="m">Mach absolute timer</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Software optimization guide for amd epyc 7003 processors</title>
		<ptr target="tps://www.amd.com/system/files/TechDocs/56665.zip" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="https://lwn.net/Articles/759423/" />
		<title level="m">Spectre V1 defense in GCC</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="https://llvm.org/docs/SpeculativeLoadHardening.html" />
		<title level="m">Speculative load hardening</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Predicting secret keys via branch prediction</title>
		<author>
			<persName><forename type="first">Onur</forename><surname>Aciicmez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Pierre</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cetin</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koc</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>IACR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Graph prefetching using data structure knowledge</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ainsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An event-triggered programmable prefetcher for irregular workloads</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ainsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASPLOS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Apple event -november 10</title>
		<author>
			<persName><surname>Apple</surname></persName>
		</author>
		<ptr target="https://www.apple.com/apple-events/" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Optimize for apple silicon with performance and efficiency cores</title>
		<author>
			<persName><surname>Apple</surname></persName>
		</author>
		<ptr target="https://developer.apple.com/news/?id=vk3m204o" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
		<title level="m">The Poly1305-AES Message-Authentication Code. FSE</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Curve25519: New diffie-hellman speed records</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>PKC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Chandler</forename><surname>Carruth</surname></persName>
		</author>
		<ptr target="https://docs.google.com/document/d/1wwcfv3UV9ZnZVcGiGuoITT61eKo3TmoCS3uXLcJR0/edit#" />
		<title level="m">Speculative load hardening</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fact: A flexible, constant-time programming language</title>
		<author>
			<persName><forename type="first">Sunjay</forename><surname>Cauligi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Soeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Johannesmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunlu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranjit</forename><surname>Jhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deian</forename><surname>Stefan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Leaking control flow information via the hardware prefetcher</title>
		<author>
			<persName><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingfeng</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A stateless, content-directed data prefetching mechanism</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cooksey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Jourdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Practical mitigations for timing-based sidechannel attacks on modern x86 processors</title>
		<author>
			<persName><forename type="first">Bart</forename><surname>Coppens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingrid</forename><surname>Verbauwhede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koen</forename><surname>De Bosschere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjorn</forename><forename type="middle">De</forename><surname>Sutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">S&amp;P</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A fetching tale: Covert communication with the hardware prefetcher</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Cronin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengmo</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>HOST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A primer on hardware prefetching</title>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synth. Lect. Comput. Archit</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Apple announces the Apple Silicon M1: Ditching x86 -What to Expect, Based on A14</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Frumusanu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-11">Nov 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Translation Leak-aside Buffer: Defeating Cache Side-channel Protections with TLB Attacks</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Gras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristiano</forename><surname>Giuffrida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Kaslr is dead: Long live kaslr</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Lipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Fellner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clémentine</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>ESSOS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clémentine</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Fogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Lipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
		<title level="m">Prefetch Side-Channel Attacks: Bypassing SMAP and Kernel ASLR. CCS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Cores shouldn&apos;t all be the same: M1 Macs do better</title>
		<imprint>
			<date type="published" when="2021-05">May 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Dougall</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cpu</forename><surname>Apple</surname></persName>
		</author>
		<ptr target="https://github.com/dougallj/applecpu" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Apple M1 Microarchitecture Research</title>
		<author>
			<persName><forename type="first">Johnson</forename><surname>Dougall</surname></persName>
		</author>
		<ptr target="https://dougallj.github.io/applecpu/firestorm.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dawg: A defense against cache timing attacks in speculative execution processors</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Kiriansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilia</forename><forename type="middle">A</forename><surname>Lebedev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Devadas</surname></persName>
		</author>
		<author>
			<persName><surname>Emer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MI-CRO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Spectre attacks: Exploiting speculative execution</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Hamburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Lipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Prescher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Yarom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>S&amp;P</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Inferring fine-grained control flow inside SGX enclaves with branch shadowing</title>
		<author>
			<persName><forename type="first">Sangho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasun</forename><surname>Gera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taesoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyesoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Peinado</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the value locality of store instructions</title>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">M</forename><surname>Lepak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikko</forename><forename type="middle">H</forename><surname>Lipasti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISCA</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Meltdown: Reading kernel memory from user space</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Lipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gruss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Prescher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Werner</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mangard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Hamburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Hector</forename><surname>Martin</surname></persName>
		</author>
		<ptr target="https://twitter.com/marcan42/status/1450364369519276032" />
		<title level="m">M1 dram scaling observed</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cache attacks and countermeasures: The case of aes</title>
		<author>
			<persName><forename type="first">Arne</forename><surname>Dag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adi</forename><surname>Osvik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eran</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><surname>Tromer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CT-RSA&apos;06</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Lord of the ring(s): Side channel attacks on the CPU on-chip ring interconnect are practical</title>
		<author>
			<persName><forename type="first">Riccardo</forename><surname>Paccagnella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Licheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Base-deltaimmediate compression: Practical data compression for on-chip caches</title>
		<author>
			<persName><forename type="first">Gennady</forename><surname>Pekhimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Kozuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>PACT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cache missing for fun and profit</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Percival</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of BSDCan</title>
				<meeting>of BSDCan</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Site isolation: Process separation for web sites within the browser</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Moshchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasko</forename><surname>Oskov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dependence based prefetching for linked data structures</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurindar</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">System, method, and apparatus for enhanced pointer identification and prefetching</title>
		<imprint>
			<date type="published" when="2021-08">August 2021</date>
		</imprint>
		<respStmt>
			<orgName>Sreenivas Subramoneyand Stanislav Shwartsmanand Anant Noriand Shankar Balachandranand Elad Shtiegmannand Vineeth Mekkatand Manjunath Shevgoor and Sourabh Alurkar</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Unveiling hardware-based data prefetcher, a hidden source of information leakage</title>
		<author>
			<persName><forename type="first">Youngjoo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename><surname>Hyung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dokeun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Hoon</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbeom</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><surname>Hur</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CCS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">TLB;DR: Enhancing TLB-based attacks with TLB desynchronized reverse engineering</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Tatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniël</forename><surname>Trujillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristiano</forename><surname>Giuffrida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herbert</forename><surname>Bos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Safecracker: Leaking Secrets through Compressed Caches</title>
		<author>
			<persName><forename type="first">Po-An</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andres</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASPLOS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Opening Pandora&apos;s Box: A Systematic Study of New Ways Microarchitecture Can Leak Private Data</title>
		<author>
			<persName><forename type="first">Jose</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanchez</forename><surname>Vicarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradyumna</forename><surname>Shome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nandeeka</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Trippel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kohlbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>ISCA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Theory and practice of finding eviction sets</title>
		<author>
			<persName><forename type="first">Pepe</forename><surname>Vila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Köpf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">José</forename><forename type="middle">F</forename><surname>Morales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">S&amp;P</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Controlledchannel attacks: Deterministic side channels for untrusted operating systems</title>
		<author>
			<persName><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weidong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Peinado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">S&amp;P</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Flush+Reload: A high resolution, low noise, L3 cache side-channel attack</title>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Yarom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrina</forename><surname>Falkner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>Sec</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Data oblivious isa extensions for side channelresistant and high performance computing</title>
		<author>
			<persName><forename type="first">Jiyong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Hsiung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamad</forename><forename type="middle">El</forename><surname>Hajj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NDSS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Imp: Indirect memory prefetcher</title>
		<author>
			<persName><forename type="first">Xiangyao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadathur</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><surname>Devadas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>MICRO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Hardware prefetcher for indirect access patterns</title>
		<author>
			<persName><forename type="first">Xiangyao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadathur Rajagopalan</forename><surname>Satish</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-02">February 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
