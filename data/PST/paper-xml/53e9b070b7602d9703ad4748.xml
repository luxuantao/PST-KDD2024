<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving drag-and-drop on wall-size displays</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Maxime</forename><surname>Collomb</surname></persName>
							<email>collomb@lirmm.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 5506</orgName>
								<orgName type="institution" key="instit1">LIRMM</orgName>
								<orgName type="institution" key="instit2">CNRS Univ. Montpellier II</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mountaz</forename><surname>Hascoët</surname></persName>
							<email>mountaz@lirmm.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR 5506</orgName>
								<orgName type="institution" key="instit1">LIRMM</orgName>
								<orgName type="institution" key="instit2">CNRS Univ. Montpellier II</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Baudisch</surname></persName>
							<email>.baudisch@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<postCode>98102</postCode>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><surname>Lee</surname></persName>
							<email>balee@graphics.stanford.edu</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Stanford Computer Graphics Laboratory</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<region>California</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving drag-and-drop on wall-size displays</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3C362E7F17F6CBB048279CA26E28E6E4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>drag-and-pop</term>
					<term>push-and-throw</term>
					<term>wall-size display</term>
					<term>drag-and-drop</term>
					<term>pen input</term>
					<term>touch-screen</term>
					<term>interaction technique</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>On wall-size displays with pen or touch input, users can have difficulties reaching display contents located too high, too low, or too far away. Drag-and-drop interactions can be further complicated by bezels separating individual display units. Researchers have proposed a variety of interaction techniques to address this issue, such as extending the user's reach (e.g., push-andthrow) and bringing potential targets to the user (dragand-pop). In this paper, we introduce a new technique called push-and-pop that combines the strengths of push-and-throw and drag-and-pop. We present two user studies comparing six different techniques designed for extending drag-and-drop to wall-size displays. In both studies, participants were able to file icons on a wallsize display fastest when using the push-and-pop interface.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the emergence of wall-size displays (e.g., Liveboard <ref type="bibr" target="#b5">[6]</ref> and SMART Board TM ), touch and pen input have regained popularity. Over the past years, more complex display systems have been created by combining multiple display units into wall-size display walls, such as the DynaWall <ref type="bibr" target="#b24">[25]</ref>, the iRoom SMART Board wall (iWall <ref type="bibr" target="#b13">[14]</ref>, shown in Figure <ref type="figure" target="#fig_3">4</ref>), as well as display systems based on stitched projection, such as the Information Mural <ref type="bibr" target="#b10">[11]</ref>.</p><p>Touch/pen input requires users to physically display content in order to interact with it. This can become a problem when targets are out of reach, e.g., because they are located too high or too low or on a display unit that does not support touch/pen input <ref type="bibr" target="#b2">[3]</ref>. Accessing icons located far away from the user may require users to physically walk over, requiring a target acquisition time roughly linear to distance <ref type="bibr" target="#b8">[9]</ref>. Interactions that involve dragging objects tend to be particularly errorprone <ref type="bibr" target="#b21">[22]</ref> and can be complicated further by the bezels separating screen units <ref type="bibr" target="#b2">[3]</ref>. Researchers have proposed a variety of interaction techniques that simplify drag-and-drop from and to inaccessible screen locations, across long distances, and across display unit borders. Approaches include extending the user's reach (e.g., push-and-throw <ref type="bibr" target="#b11">[12]</ref>) and bringing potential targets to the user (drag-and-pop <ref type="bibr" target="#b2">[3]</ref>, shown in Figure <ref type="figure" target="#fig_3">4</ref>). Both techniques have their particular strengths, while facing their particular limitations, as we will discuss in detail in sections 3 and 4. We also present improvements addressing some of these limitations.</p><p>We then present a novel technique we call pushand-pop (Figure <ref type="figure" target="#fig_0">1</ref>) that combines the world-inminiature aspect from push-and-throw with the targetto-pointer approach of drag-and-pop. In two experimental comparisons with five competing drag-and-drop extension techniques, participants performed tasks fastest when using the push-and-pop interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Drag-and-drop is a well-known interaction technique for transferring or copying information using a pointing device, while avoiding the use of a hidden clipboard <ref type="bibr" target="#b25">[26]</ref>. Several techniques have been proposed to adapt drag-and-drop, initially invented for use with a desktopsized computer screen, to large screens.</p><p>The majority of work so far has focused on dragand-drop with direct input devices, such as the mouse. Hyperdragging <ref type="bibr" target="#b20">[21]</ref> allows extending drag-and-drop across physically separate displays. Manual And Gaze Input Cascaded (MAGIC) pointing <ref type="bibr" target="#b26">[27]</ref> helps overcoming long distances by combining mouse input with gaze input. High-density cursors help users keep track of the mouse pointer during long-distance traversals <ref type="bibr" target="#b1">[2]</ref>. Semantic pointing <ref type="bibr" target="#b3">[4]</ref> and vector pointing <ref type="bibr" target="#b8">[9]</ref> use a multiscale navigation approach to allow users to cross very long distances with logarithmic access time <ref type="bibr" target="#b9">[10]</ref>.</p><p>Laser pointers <ref type="bibr" target="#b18">[19]</ref> have been discussed for input on wall-size displays, but were found to be slower than touch input <ref type="bibr" target="#b17">[18]</ref>.</p><p>Techniques compatible with pen usage are based on a variety of different approaches. Pick-and-drop <ref type="bibr" target="#b21">[22]</ref> and take-and-put <ref type="bibr" target="#b24">[25]</ref> are based on point-and-click, but, unlike traditional drag-and-drop, they do not require users to maintain contact with the screen. The Frisbee technique by Kahn et al. <ref type="bibr" target="#b6">[7]</ref> allows users to create a local view into a distant area of the screen, thereby allowing users to drag objects to arbitrary targets. These techniques also help users overcome obstacles, such as bezels separating display units. Marking menus <ref type="bibr" target="#b14">[15]</ref> allow a user to perform a menu selection by either popping-up a radial (or pie) menu, or, for an experienced user, by making a straight mark in the direction of the desired menu item without popping-up the menu.</p><p>Other techniques offer additional functionality for interacting with targets that are out of reach. Throwing, for example, allows users to accelerate an object with a small gesture; the object then continues its trajectory based on its inertia <ref type="bibr" target="#b7">[8]</ref>. The imprecision of human motor skills has prevented throwing from being used for reliable target acquisition.</p><p>Push-and-throw <ref type="bibr" target="#b11">[12]</ref> and drag-and-pop <ref type="bibr" target="#b2">[3]</ref> also fall into this category. In this paper, we focus on these two techniques and present extensions and design improvements. We describe these techniques in detail in the following section.</p><p>3 Push-and-throw and drag-and-pop</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1</head><p>Drag-and-throw &amp; push-and-throw Drag-and-throw <ref type="bibr" target="#b11">[12]</ref> was designed to address the limitations of throwing <ref type="bibr" target="#b7">[8]</ref> by providing users with a realtime preview of where the dragged object will come down if thrown. This way, drag-and-throw allows users to tweak the throwing trajectory in order to assure that the right target is hit. Snap-to-target helps increase users' accuracy.</p><p>Push-and-throw <ref type="bibr" target="#b11">[12]</ref> is a follow-up version of dragand-throw. By letting users drag towards the target rather than away from it, push-and-throw was found to offer better affordance <ref type="bibr" target="#b11">[12]</ref>. Figure <ref type="figure" target="#fig_1">2</ref> shows a walkthrough of push-and-throw. (1→2) Tapping the pen onto an icon causes the pushand-throw visuals to appear. The translucent rectangle, called the take-off area, represents a miniature of the desktop space. A translucent copy of the icon (the "tip icon") appears. It is connected to the cursor using a rubber band, which may be thought of as preview of the trajectory along which the icon will be "thrown" when released. Dragging the pen inside the take-off area causes the tip icon to move to the respective location on the real desktop. (3) As the user moves the tip icon over a target icon, such as a folder, the target icon provides the usual visual feedback, i.e., it changes its color. (4) When lifting the pen, the icon is filed.</p><p>Push-and-throw, originally inspired by the metaphor of the pantograph <ref type="bibr" target="#b4">[5]</ref> is a combination of a go-go <ref type="bibr" target="#b19">[20]</ref> and a world in miniature technique <ref type="bibr" target="#b23">[24]</ref>. The main idea behind push-and-throw is to temporarily turn the pen/touch input, inherently a direct pointing device, into an indirect pointing device in order to traverse distances faster and to be able to reach locations further away or on a different screen unit. On the downside, it also leads to reduced resolution and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design improvements: rubber bands &amp; acceleration</head><p>While the original version of push-and-throw <ref type="bibr" target="#b11">[12]</ref> used simple lines to connect pointer and dragged icon, we created an improved version that uses a tapered rubber band inspired by drag-and-pop <ref type="bibr" target="#b2">[3]</ref> as shown in Figure <ref type="figure" target="#fig_1">2</ref>. As Baudisch et al. discuss, the shape of this type of rubber band provides users with an additional visual cue about distance. Unlike the rubber bands proposed by Baudisch et al., we used an asymmetric rubber band for push-and-throw, which looked more consistent when linking the pointer (1 pixel wide) to an icon (32 pixels wide). This improved design was one of the interfaces compared in our user studies presented in Section 6 and 7.</p><p>One of the main limitations of the original pushand-throw is its lack of precision due to the size reduction that occurs when mapping the desktop to the takeoff area. We address this issue by introducing nonlinear acceleration, as it is common with indirect input devices, to push-and-throw. In accelerated push-andthrow, moving the pointer slowly results in a much slower motion of the dragged icon, helping users acquire small targets. In addition, the acceleration factor is reduced when the dragged icon is close to a target (similar to semantic pointing <ref type="bibr" target="#b3">[4]</ref>). Accelerated pushand-throw also allows clutching, i.e., lifting and repositioning the pen/finger within a drag interaction. This allows users to reach very distant targets.</p><p>With acceleration, there is no more immediate correspondence between physical pointer location and the location of the dragged icon. As a consequence, the technique does not have a clearly defined take-off area anymore and we cannot provide a preview of it. Since accelerated push-and-throw therefore does not completely subsume tradition push-and-throw, we decided to include both designs in our user study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head><p>Drag-and-pop Drag-and-pop <ref type="bibr" target="#b2">[3]</ref> uses the opposite approach to dragand-throw. Rather than sending the dragged object to the periphery, it allows users to bring a selection of likely candidates to the user. This allows users to complete drag interactions in a convenient screen location. There is no scaling of pointer motion, so users can make use of the full resolution of their motor skills.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows a walkthrough of drag-and-pop. (1) The user intends to delete a web page by dragging it into the recycle bin. (2) As the user starts dragging the web pages icon towards the recycle bin, icons that are of compatible type and located in the direction of the user's drag motion "pop up". This means that each of these icons produces a "tip icon" that appears in front of the user's pen. Tip icons are connected to the respective original icon using a rubber band. (3) The user drags the web page over the recycle bin and releases the mouse button. The recycle bin accepts the web page. Alternatively, the user could have dropped the web page over the word processor or the web browser icon, which would have launched the respective application with the memo. (4) When the user drops the icon, all tip icons disappear instantly.</p><p>In order to reduce clutter, drag-and-pop creates tip icons only for icons that are of matching file type, located far enough away from the dragged icon, and lo-cated within a certain angle from the user's initial drag direction. Drag-and-pop compacts the layout of all tip icons by placing tip icons on a denser grid and by eliminating empty rows and columns from that grid <ref type="bibr" target="#b2">[3]</ref>. Users can abort drag-and-pop interactions at any time by moving the pen away from the tip icon cluster. This allows users to rearrange icons on the desktop. The rubber bands connecting tip icons with their original are designed to help users follow the transition when the tip icons appear and to re-identify the desired targets among the other tip icons. Drag-and-pop can be extended to allow users to access content in the periphery (drag-and-pick <ref type="bibr" target="#b2">[3]</ref>). The main limitation of drag-and-pop is that imprecise invocation gestures can cause the wrong tip icons to appear. In particular, Baudisch et al. found <ref type="bibr" target="#b2">[3]</ref> that the arc-shaped full-arm drag motions users performed caused drag-and-pop to bring icons located in the extension of the first segment of that arc-this was typically not the direction to the target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design improvements: target sector and positioning</head><p>In order to address the limitations identified by Baudisch et al., we adjusted our version of drag-and-pop in two ways. First, we increased the size of the target sector and added extra tolerance for movements towards the top of the screen.</p><p>Second, in its original version, dragging towards another display unit sometimes makes the tip icon cluster appear fully or partially on that other screen unit.</p><p>The version of drag-and-pop used in our user study avoids this-it always places tip icon clusters in the display unit where the drag interaction was initiated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis and comparison of approaches</head><p>As listed in the previous section, push-and-throw and drag-and-pop have different strengths, but they also have different limitations. In order to allow creating a new technique that overcomes the limitations of both approaches, we take a closer look at these limitations and at the responsible design dimensions (Table <ref type="table">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Index of difficulty</head><p>All other factors kept constant, users can acquire closer targets faster than more distant targets (Fitts' law <ref type="bibr" target="#b16">[17]</ref>). Push-and-throw and drag-and-pop both reduce the distance to the target in motor space. Push-and-throw amplifies pointer speed by a constant factor, but at the same time scales targets in motor space, so the only aspect that has an effect on the index of difficulty are snapping and acceleration. Drag-and-pop, in contrast, leaves target size unchanged. Packing targets more tightly therefore reduces the index of difficulty.</p><p>While index of difficulty does play a role in target acquisition in general, on wall-size displays the main factors are whether the target is in reach and how many bezels need to be crossed. In comparison to these factors, the impact of actual distance was found to be minor <ref type="bibr" target="#b2">[3]</ref> and should therefore be expected to have only minor impact on the relative performance of push-andthrow with regard to drag-and-pop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2</head><p>Need for reorientation Push-and-throw-based techniques move the pointer all the way to the target, while drag-and-pop first moves potential targets to the pointer (Table <ref type="table">1</ref>). The difference, however, is merely a matter of the applied visuals. The underlying mechanism is similar: in motor space the user moves the pointer to a target that is within reach. In the case of push-and-throw the visuals appear in the target space, i.e., all over the wall-size display. In the case of drag-and-pop the visuals appear in the motor space, i.e., in the space reachable by the user.</p><p>The different visuals, however, have an impact on the interaction. Drag-and-pop involves a single fairly dramatic movement on the screen that requires users to reorient themselves. Drag-and-pop uses the rubber bands to minimize that impact, yet since different drag directions cause the tip cluster to be a little different every time, users need to pay attention when picking their target tip icon. Once users have identified the target tip icon, however, they can complete the interaction easily: the target is at a stable location and acquiring it requires only very little attention.</p><p>Push-and-throw, in contrast, requires users to constantly monitor the screen as it is virtually impossible for users to guess upfront where their finger has to be in order to acquire the target.</p><p>In our observation, the single motion caused by drag-and-pop impacts performance less than the continuous monitoring required by push-and-throw. We therefore paid close attention to avoid the need for continuous monitoring when designing push-and-pop. technique approach need to reorient drag-and-drop -never pick-and-drop -never push-and-throw to target constantly accelerated… to target constantly drag-and-pop to pointer once New: push-and-pop to pointer once, later never Table <ref type="table">1</ref> : candidate techniques and design dimensions 5 Push-and-pop Based on our analysis of push-and-throw and drag-andpop, we created a new technique designed to combine the strengths of both techniques. We call this new technique push-and-pop-the name trying to convey that it builds on both push-and-throw and drag-and-pop.</p><p>Figure <ref type="figure">5</ref> shows a walkthrough. In the shown example, the user is dragging a word document into the recycle bin. The interaction proceeds as follows. (1) The user starts dragging the word document icon. (2) As a response, the system surrounds the pointer with a miniature representing the wall-size display-the takeoff area-here containing the icons of the word application, a folder, and the recycle bin. (3) The user drags the word document icon over the recycle bin, which responds by highlighting itself with a rectangular frame. (4) The users lets go of the word document icon and the word document disappears in the recycle bin. The take off area disappears. Figure <ref type="figure" target="#fig_0">1</ref> shows a photo of pushand-pop in use on a wall-size display.</p><p>In case users need to rearrange icons on the desktop, they can switch push-and-pop temporarily into a pushand-throw mode. Users invoke this functionality by moving the pointer back to the location of invocation, marked with a black circle in Figure <ref type="figure">5</ref>.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5: Push-and-pop walkthrough</head><p>The grid-like arrangement of the tip icons in the take-off area is taken directly from the drag-and-pop's layout algorithm <ref type="bibr" target="#b2">[3]</ref>. It is created by placing icons on a small grid and by removing empty rows and columns. Unlike drag-and-pop which creates tip icons only for icons located in the drag direction, however, push-andpop brings all target icons of matching type, independent of where they are located on the screen. This eliminates the risk of users invoking the wrong set of targets and also assures a stable, reproducible layout, thereby overcoming the two main limitations of drag-and-pop. Invocation of push-and-pop over the same icon type always results in the same take-off area, allowing users to perform the actual acquisition task based on muscle memory.</p><p>The resulting rectangular take-off area corresponds to the take-off area in push-and-throw. However, pushand-pop's take-off area offers two major benefits. First, the take-off area shows tip icons. This offers good readability even if the represented target is too far away to be readable. But most importantly it allows users to acquire the desired tip icon without the need for further reorientation. Second, rather than being a geometrically reduced version of the display, the miniature in the take-off is a semantically reduced version of the display in that only valid targets are contained. This allows push-and-pop to use full-size versions of the target icons allowing for an easier acquisition. However, to save space, we removed file names, instead revealing them as tool tips on hover.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">First study: double wall-size screen</head><p>We conducted a user study comparing six drag-anddrop techniques for wall-size displays. The study served two main purposes. First, we wanted to learn more about the relative performance of the different techniques. We had several hypotheses. For sufficiently long distances, we expected all techniques to outperform traditional drag-and-drop. More specifically, we expected the techniques that required no or a one-time reorientation to outperform the techniques that required continuous tracking. Second, we wanted to validate the design of push-and-pop. Would it really outperform push-and-throw and drag-and-pop?</p><p>In order to extend our findings to longer distances, we later replicated the study on a three-unit display wall, as we report in Section 7. We will hold off with our discussion until after the second study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.1</head><p>Task Participants' task was to perform drag-and-drop operations on a simulated Windows desktop. The task details corresponded largely to the original drag-and-pop user study reported in <ref type="bibr" target="#b2">[3]</ref>. Figure <ref type="figure" target="#fig_4">6</ref> shows the icon layout used in the study. The icons to be filed appeared at the bottom right of the screen (the cluster of 10 icons at the bottom right of Figure <ref type="figure" target="#fig_4">6</ref>). The target was successively displayed in one of 12 positions, which allowed us to obtain uniformly distributed indexes of difficulty. Unlike the original drag-and-pop study, we simplified the participants' task by always using the recycle bin icon as the target. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Apparatus &amp; interfaces</head><p>The study was conducted on a combination of a wallsize back-projected display and a front-projected SMART Board TM . Each of the two displays measured 5'/1.7m across and ran at 1024*768 pixel resolution. Pen input on the back-projected display was supported by a Mimio TM capture bar and a specialized pen. The Wall-screens were connected to a PC with a Pentium4 1.5GHz processor and 512MB of RAM.</p><p>Participants used six different interfaces: drag-anddrop, pick-and-drop, push-and-throw, accelerated pushand-throw, drag-and-pop, and push-and-pop. The pickand-drop interface corresponded to <ref type="bibr" target="#b21">[22]</ref> (A first click selects the object that has to be moved and a second one selects the target) with the difference that the interface in the study required users to briefly drag an icon in order to pick it up. This allowed differentiating drag operations from object selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.3</head><p>Participants Twelve participants (all male, one left-handed, students and researchers) were recruited internally. All participants but one had little or none experience with using wall-size displays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.4</head><p>Experimental design We used a within-subjects design. Each participant performed 36 trials per interface, resulting in a total of 216 trials. The 36 trials were grouped in three blocks of 12 trials, with each trial corresponding to a different target positions. A Latin square was used to counterbalance order of interfaces and order of presentation. Target positions within each block were randomized. Participants received up to 5 minutes of training per interface before beginning the timed tasks.</p><p>We measured Movement Time, i.e., the time from the moment the participant tapped onto the icon to be filed to the moment the participant lifted the pen. We also measured Error Rate, i.e., the percentage of cases where the user released the dragged icon over the wrong target. In cases where participants accidentally released the dragged object over empty space, they had to pick it up again and complete the trial. We kept track of that as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.5</head><p>Results Task completion time: An ANOVA on median values for time showed significant differences with the type of technique (p&lt;0.001). A Dunn's pair-to-pair comparison showed that all comparisons were significant except the comparison of accelerated push-and-throw and pickand-drop.</p><p>Overall, participants performed the task fastest when using the push-and-pop interface, confirming our hypothesis. Drag-and-pop was only slightly slower. Next came accelerated push-and-throw and pick-anddrop. Participants performed worse when using pushand-throw. Confirming the findings by Baudisch et al. <ref type="bibr" target="#b2">[3]</ref>, drag-and-drop worked well as long as the target was located within the same display unit, but performed poorly when the task required participants to cross the bezel between screens. Averaged across distance, traditional drag-and-drop performed worst.  Errors rates: Figure <ref type="figure" target="#fig_7">8a</ref> shows error rates. The number of cases where participants dropped an icon into the wrong target was generally low (less than two cases out of 36 trials per interface). The number of cases where participants temporarily dropped an icon, but then successfully filed it was much higher for push-and-throw and drag-and-pop (between 9% and 12%). Pick-anddrop, push-and-pop and accelerated push-and-throw offered much better results here (below 2%). Drag-anddrop does not count here, because participants had to temporarily drop the icon whenever crossing the bezel.</p><p>Subjective satisfaction: At the end of the experiment, participants ranked all six techniques by preference. Figure <ref type="figure" target="#fig_7">8b</ref> shows a summary created by assigning 5 points for each first ranks, down to 0 points for last rank and averaging the results. In particular, 9 of the 12 participants ranked push-and-pop first. We replicated the study on a corresponding three-unit display wall in order to extend our findings to longer distances.</p><p>The second study was run on the iWall <ref type="bibr" target="#b13">[14]</ref>, a three back-projection SMART Board TM displays, each with resolution 1024x768 (Figure <ref type="figure" target="#fig_3">4</ref>). Participants interacted with the board via touch, either using their fingers directly or holding a pen. The display was driven by a Pentium® II 500MHz with 256MB of RAM.</p><p>Six volunteers (4 females, 2 left-handed) participated in this study. All participants but one had very little experience with using wall-size displays.</p><p>The experimental design was identical to the first study, but instead of 3 blocks of 12 trials, participants performed 4 blocks or 12 trials per interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.1</head><p>Results Task completion time: An ANOVA on median task times showed significant differences with the type of technique (p&lt;0.001). A Dunn's pair-to-pair comparison found all differences significant except the comparison of push-and-throw and accelerated push-and-throw.</p><p>Figure <ref type="figure" target="#fig_9">9</ref> shows the results. The resulting ranking corresponds largely with the first study. Participants were fastest when using push-and-pop, followed by drag-and-pop, pick-and-drop, and drag-and-drop. In this study participants performed worst when using pushand-throw/accelerated push-and-throw. Only for very long distances did these techniques perform better than traditional drag-and-drop. Note drag-and-drop and pickand-drop performance depended on the target distance, while the performance all other techniques is largely distance independent.  Error rates: Error rates corresponded to the first study with the exception that this time participants using accelerated push-and-throw performed a higher number of accidental drops (Figure <ref type="figure" target="#fig_10">10a</ref>). Subjective satisfaction: This time pick-and-drop scored slightly higher that push-and-pop (Figure <ref type="figure" target="#fig_10">10b</ref>). The push-and-throw techniques scored last.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>The two user studies presented above provide some supporting evidence for the claims made earlier in this paper.</p><p>Confirming findings by Baudisch et al. <ref type="bibr" target="#b2">[3]</ref> dragand-drop performed well as long as source and target icons were situated in the same display unit, but failed quickly when long distances and bezels were involved. In addition, we found that pick-and-drop is affected by distance in a similar way, though to a lesser extent.</p><p>For all other evaluated techniques, target distance had comparably little impact on task performances. However, our studies seem to indicate a performance benefit of acquisition techniques that require a one-time reorientation over techniques that require continuous tracking. The two techniques that required only require a one-time reorientation (drag-and-pop and push-andpop) achieved the best task times.</p><p>Overall, the study indicates that push-and-pop is indeed a useful technique. Push-and-pop outperformed all other techniques, including its ancestors, drag-andpop and push-and-throw. Participants' subjective preference reflected this. Push-and-pop also offered a very low error rate, which is one possible explanation for the performance benefit in comparison with drag-and-pop. While participants using drag-and-pop needed to pay close attention to the directionality of their invocation gesture in order to avoid error, push-and-pop avoided this additional burden on users by always displaying all possible tip icons.</p><p>Among pointer-to-target techniques, accelerated push-and-throw performed significantly better than traditional push-and-throw. Despite the unexceptional performance of both techniques, this indicates that our design improvements were beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We presented an experimental comparison of six dragand-drop techniques for wall-size displays and found significant performance benefits for techniques that do not require users to continuously track their interaction, in particular the push-and-pop technique introduced in this paper.</p><p>We have focused on icon displacements. As future work, we plan to optimize the design of push-and-pop (e.g., by reintroducing rubber bands and solving scalability problems, such as those presented by desktops with numerous folders) and extending the presented techniques to other types of interactions, such as activation of menus and buttons.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A user is dragging a web page icon into the recycle bin on a wall-size display. The proposed push-and-pop interaction technique has created a world-in-miniature around the user's finger that contains all valid target icons.</figDesc><graphic coords="1,314.30,198.60,226.68,149.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Push-and-throw walkthrough: the user is dropping the image icon located in the bottom left into the "My Pictures" folder located at the top right.</figDesc><graphic coords="2,315.00,71.88,229.92,192.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Drag-and-pop: Here the user drops the word file located at the right into the recycle bin.</figDesc><graphic coords="3,315.00,223.44,228.60,245.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Moving an object using the drag-and-pop technique on the iWall wall-size display.</figDesc><graphic coords="4,72.24,113.40,224.52,149.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The icon layouts used in the study.</figDesc><graphic coords="5,315.00,514.92,225.60,169.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Mean task completion time for each technique depending of the ID of the task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: (a) Error rates for each technique. (b) Subjective preferences (higher is better)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Mean task completion time for each technique depending of the ID of the task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: (a) Error rates for each technique. (b) User's subjective preferences (higher is better)</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank the participants in our experiments, who spent significant amounts of time testing the interaction models.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Beyond Fitts&apos; law: models for trajectory-based HCI tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Accot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc.CHI&apos;97</title>
		<meeting>.CHI&apos;97</meeting>
		<imprint>
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">High-Density Cursor: A Visualization Technique that Helps Users Keep Track of Fast-Moving Mouse Cursors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cutrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interact&apos;03</title>
		<meeting>Interact&apos;03</meeting>
		<imprint>
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Drag-and-Pop and Drag-and-Pick: Techniques for Accessing Remote Screen Content on Touch and Penoperated Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cutrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Czerwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zierlinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Interact&apos;03</title>
		<meeting>Interact&apos;03</meeting>
		<imprint>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic pointing: improving target acquisition with control-display ratio adaptation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blanch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guiard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;04</title>
		<meeting>CHI&apos;04</meeting>
		<imprint>
			<biblScope unit="page" from="519" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Introduction to Geometry</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S M</forename><surname>Coxeter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<publisher>Wiley</publisher>
			<biblScope unit="page" from="69" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Liveboard: a large interactive display supporting group meetings, presentations, and remote collaboration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Elrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;92</title>
		<meeting>CHI&apos;92</meeting>
		<imprint>
			<biblScope unit="page" from="599" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A remote control interface for large displays</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burtnyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST&apos;04</title>
		<meeting>UIST&apos;04</meeting>
		<imprint>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Throw or Take It! Working Efficiently with an Interactive Wall</title>
		<author>
			<persName><forename type="first">J</forename><surname>Geißler</surname></persName>
		</author>
		<author>
			<persName><surname>Shuffle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;98 Late-Breaking Results</title>
		<imprint>
			<biblScope unit="page" from="265" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vector Pointing: Object vs. Pixel Selection in Graphical User Interfaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guiard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Blanch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GI&apos;04</title>
		<meeting>GI&apos;04</meeting>
		<imprint>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">View size and pointing difficulty in multi-scale navigation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guiard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bastin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pasveer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AVI&apos;04</title>
		<meeting>AVI&apos;04</meeting>
		<imprint>
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fluid interaction with High Resolution Wall-Size Displays</title>
		<author>
			<persName><forename type="first">F</forename><surname>Guimbretiere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST&apos;01</title>
		<meeting>UIST&apos;01</meeting>
		<imprint>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Throwing models for large displays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hascoët</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HCI&apos;03</title>
		<meeting>HCI&apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="73" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Experience with Flexible Input Redirection in Interactive Workspaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Johanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><surname>Pointright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST&apos;02</title>
		<meeting>UIST&apos;02</meeting>
		<imprint>
			<biblScope unit="page" from="227" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Interactive Workspaces Project: Experiences with Ubiquitous Computing Rooms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Johanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">User learning and performance with marking menus</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;94</title>
		<meeting>CHI&apos;94</meeting>
		<imprint>
			<biblScope unit="page" from="258" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An evaluation of two input devices for remote pointing</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jusoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EHCI&apos;01</title>
		<meeting>EHCI&apos;01</meeting>
		<imprint>
			<biblScope unit="page" from="235" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fitts&apos; law as a research and design tool in human-computer interaction</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Mackenzie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="91" to="139" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interacting At a Distance: Measuring the Performance of Laser Pointers and Other Devices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc CHI&apos;02</title>
		<meeting>CHI&apos;02</meeting>
		<imprint>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Laser pointer interaction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;01</title>
		<meeting>CHI&apos;01</meeting>
		<imprint>
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Go-Go Interaction Technique: Non-Linear Mapping for Direct Manipulation in VR</title>
		<author>
			<persName><forename type="first">I</forename><surname>Poupyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Billinghurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weghorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ichikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST&apos;96</title>
		<meeting>UIST&apos;96</meeting>
		<imprint>
			<biblScope unit="page" from="79" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Augmented Surfaces: A Spatially Continuous Work Space for Hybrid Computing Environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saitoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI&apos;99</title>
		<imprint>
			<biblScope unit="page" from="378" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Direct Manipulation Technique for Multiple Computer Environments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
		<author>
			<persName><surname>Pick-And-Drop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST&apos;97</title>
		<meeting>UIST&apos;97</meeting>
		<imprint>
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Designing the Star user interface</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Irby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Verplank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harslem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Byte</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="242" to="282" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Virtual Reality on a WIM: Interactive Worlds in Miniature</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stoakley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pausch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI&apos;95</title>
		<meeting>CHI&apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Human-Computer Interaction in the New Millennium</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Streitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Müller-Tomfelde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Konomi</surname></persName>
		</author>
		<author>
			<persName><surname>Roomware</surname></persName>
		</author>
		<editor>Carroll, J.A.</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Addison Wesley</publisher>
			<biblScope unit="page" from="553" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Drag me, drop me, treat me like an object</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>O'brien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc CHI &apos;95</title>
		<meeting>CHI &apos;95</meeting>
		<imprint>
			<biblScope unit="page" from="525" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Manual And Gaze Input Cascaded (MAGIC) Pointing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ihde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;99</title>
		<meeting>CHI &apos;99</meeting>
		<imprint>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
