<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Huanfeng</forename><surname>Shen</surname></persName>
							<email>shenhf@whu.edu.cn</email>
						</author>
						<author>
							<persName><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Resources and Environmental Sciences</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of Geographic Information System</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Geospatial Technology</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing and the Collaborative Innovation Center for Geospatial Technology</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">156B8B0D0682488158E68876EA40487B</idno>
					<idno type="DOI">10.1109/TGRS.2016.2596290</idno>
					<note type="submission">received March 24, 2016; revised June 22, 2016; accepted July 23, 2016.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An Integrated Framework for the Spatio-Temporal-Spectral Fusion of Remote Sensing Images Huanfeng Shen, Senior Member, IEEE, Xiangchao Meng, and Liangpei Zhang, Senior Member, IEEE Abstract-Remote sensing satellite sensors feature a tradeoff between the spatial, temporal, and spectral resolutions. In this paper, we propose an integrated framework for the spatio-temporalspectral fusion of remote sensing images. There are two main advantages of the proposed integrated fusion framework: it can accomplish different kinds of fusion tasks, such as multiview spatial fusion, spatio-spectral fusion, and spatio-temporal fusion, based on a single unified model, and it can achieve the integrated fusion of multisource observations to obtain high spatiotemporal-spectral resolution images, without limitations on the number of remote sensing sensors. The proposed integrated fusion framework was comprehensively tested and verified in a variety of image fusion experiments. In the experiments, a number of different remote sensing satellites were utilized, including IKONOS, the Enhanced Thematic Mapper Plus (ETM+), the Moderate Resolution Imaging Spectroradiometer (MODIS), the Hyperspectral Digital Imagery Collection Experiment (HYDICE), and Système Pour l' Observation de la Terre-5 (SPOT-5). The experimental results confirm the effectiveness of the proposed method.</p><p>Index Terms-Image fusion, integrated framework, remote sensing, spatial resolution, spectral resolution, temporal resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>W ITH the rapid development of remote sensing sensor networks, massive volumes of remote sensing images can be now obtained every day. However, due to the technical limitations of the sensors and other factors, the existing optical remote sensing sensors have to make a fundamental tradeoff between the spatial, temporal, and spectral resolutions, which greatly limits the potential applications of remote sensing images <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. Fortunately, remote sensing image fusion is an effective way to obtain superior high spatio-temporal-spectral resolution images by merging the complementary information.</p><p>It is defined as the synergic combination of two or more image data sets, which is aimed at producing a knowledge of phenomena under investigation better than the knowledge achievable from individual data sets <ref type="bibr" target="#b3">[4]</ref>.</p><p>To date, a variety of remote sensing image fusion methods <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b9">[10]</ref> have been proposed. In general, the existing image fusion methods are performed at three different processing levels, i.e., data level, feature level, and decision level <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b10">[11]</ref>. In this paper, we focus on the data-level fusion of remote sensing images. According to the different aims, there are several categories of remote sensing image fusion, such as multiview spatial fusion, spatio-spectral fusion, and spatio-temporal fusion. However, on one hand, most of the existing methods have been developed independently, and few studies have been dedicated to studying the relationships between them, and thus, the fusion frameworks lack versatility. On the other hand, most of the existing fusion methods can be only applied to integrate two of the spatial, temporal, and spectral resolution indexes, and thus, they cannot obtain the highest spatio-temporal-spectral resolution fused images. In addition, they are designed to merge the complementary information from one or two sensors, and thus, they cannot take full advantage of the useful complementary information from more sensor observations. Therefore, in this paper, we propose an integrated framework for the spatio-temporal-spectral fusion of remote sensing images. In the proposed fusion framework, the maximum a posteriori (MAP) theory is utilized to describe the inverse fusion problem. The spatial, temporal, and spectral relationships between the desired image and the multisource remote sensing observations are then thoroughly analyzed to construct an integrated relationship model. Finally, the fused image is solved by the classical conjugate gradient optimization algorithm. The proposed integrated fusion framework can simultaneously accomplish multiview spatial fusion, spatio-spectral fusion, spatio-temporal fusion, etc., based on a single unified model. In addition, it can obtain high spatio-temporal-spectral resolution fused images by taking full advantage of the useful complementary information from multisource observations. Furthermore, it does not have any limitation on the number of sensors.</p><p>The rest of this paper is organized as follows. Section II presents the related work about the existing remote sensing image fusion methods. Section III presents the proposed integrated fusion framework. The optimization solution and the parameter determination are presented in Section IV. In Section V, the experimental results and analysis are provided. Finally, the conclusion is drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multiview Spatial Fusion</head><p>Multiview spatial fusion refers to the process of combining a sequence of multiview low-spatial-resolution remote sensing images, generally acquired by one imaging system, to produce a higher spatial resolution image. It is also known as multiframe superresolution reconstruction <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b14">[15]</ref>. Multiview spatial fusion was first proposed by Tsai and Huang <ref type="bibr" target="#b15">[16]</ref> in the frequency domain, and it has since been successfully applied to improve the hardware performance of remote sensing sensors. For example, it has been successfully applied to the Système Pour l' Observation de la Terre-5 (SPOT-5) satellite system to produce a 2.5-m "THR" (a French acronym that stands for "very high resolution") panchromatic (PAN) image with two 5-m halfpixel shift images delivered by the double charge-coupled device linear array <ref type="bibr" target="#b16">[17]</ref>. To date, multiview spatial fusion has been focused on the fusion of multitemporal and multiangle image sequences <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. To the best of our knowledge, Shen et al. <ref type="bibr" target="#b19">[20]</ref> and Merino and Nunez <ref type="bibr" target="#b20">[21]</ref> earlier proposed multiview spatial fusion methods for multitemporal images. Li et al. <ref type="bibr" target="#b21">[22]</ref> subsequently presented a MAP-based method with a universal hidden Markov tree model for use with Landsat-7 PAN images of different dates. Dually, Zhang et al. <ref type="bibr" target="#b18">[19]</ref> and Ma et al. <ref type="bibr" target="#b22">[23]</ref> proposed fusion methods for multiangle remote sensing data sets. It is noteworthy that most of the existing multiview spatial fusion methods are based on an observation model considering the imaging process of the remote sensing sensors. In addition, a notable feature is that they take advantage of the complementary information of multiframe degraded observations to improve the spatial resolution. However, due to the lack of auxiliary higher spatial resolution images, the effect of the spatial resolution improvement is not significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spatio-Spectral Fusion</head><p>Spatio-spectral fusion <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b8">[9]</ref> is an important approach in remote sensing image fusion. It is aimed at obtaining a fused image with both high spatial and spectral resolutions. The classical spatio-spectral fusion methods include PAN/multispectral (MS) fusion <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, PAN/hyperspectral (HS) fusion <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b23">[24]</ref>, and MS/HS fusion <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b24">[25]</ref>.</p><p>PAN/MS fusion, which is popularly referred to as "pansharpening," is a particular case of the spatio-spectral fusion methods. It is used to fuse the high-spatial-resolution PAN image (a single band) and several bands of the low-spatialresolution MS image simultaneously acquired over the same area <ref type="bibr" target="#b7">[8]</ref>. PAN/MS fusion originated in the 1980s <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref>; since 1986, the Système Pour l' Observation de la Terre-1 (SPOT-1) system has provided two MS images together with one PAN image; thus, PAN/MS fusion methods have got rapid development over a period of nearly 30 years. In general, most of the existing PAN/MS fusion methods can be grouped into four categories: 1) component substitution (CS)based approaches; 2) multiresolution analysis (MRA)-based approaches; 3) model-based optimization (MBO) approaches; and 4) sparse reconstruction (SR)-based approaches. Among them, the CS-based <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b30">[31]</ref> and MRA-based <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref> fusion methods are the most popular due to their simplicity and high efficiency, and they have been formulated as general image fusion frameworks <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b34">[35]</ref>. The MBO fusion approach <ref type="bibr" target="#b35">[36]</ref> is another important category. These methods regard the solution of the fused image as an ill-posed problem, and they mainly rely on constructing a relationship model between the desired fused image and the observed PAN/MS images. In general, the MBO fusion method has higher precision than the CS-based and MRA-based fusion methods; however, it is a relatively complex and time-consuming approach. The SR-based PAN/MS fusion approaches <ref type="bibr" target="#b36">[37]</ref>- <ref type="bibr" target="#b39">[40]</ref> have attracted increasing attention in recent years, and they are considered to be a promising new generation of fusion methods <ref type="bibr" target="#b40">[41]</ref>. Their basic idea is that the reconstructed signal is sparse and it can be represented as a linear combination of a few base elements. This category of fusion methods mainly relies on dictionary construction. More detailed comparisons and discussions of the pansharpening methods can be found in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, and <ref type="bibr" target="#b41">[42]</ref>- <ref type="bibr" target="#b43">[44]</ref>.</p><p>In addition to PAN/MS fusion, PAN/HS fusion and MS/HS fusion are another two essential spatio-spectral fusion categories. To date, many different PAN/MS fusion methods have been applied and extended to PAN/HS fusion <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b23">[24]</ref> and MS/HS fusion <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. In addition, a large number of model-based or unmixing-based PAN/HS <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref> and MS/HS fusion methods <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b48">[49]</ref>- <ref type="bibr" target="#b50">[51]</ref> have been developed. On the whole, PAN/HS fusion and MS/HS fusion are more challenging than PAN/MS fusion because of the increased number of spectral bands and the more extensive spectral wavelength <ref type="bibr" target="#b51">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Spatio-Temporal Fusion</head><p>Spatio-temporal fusion is another fundamental approach to remote sensing image fusion. It can make use of the complementary spatial and temporal information of multisource remote sensing observations to obtain a fused image with both a high spatial resolution and a frequent temporal coverage <ref type="bibr" target="#b52">[53]</ref>. Most of the spatio-temporal fusion methods can be classified into three categories: 1) filter-based methods; 2) unmixing-based methods; and 3) learning-based methods. Among them, the filter-based methods <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b52">[53]</ref>- <ref type="bibr" target="#b55">[56]</ref> are the most popular. This category of methods utilizes the weighted sum of the neighboring similar pixels of the input observations to reconstruct the fused image <ref type="bibr" target="#b9">[10]</ref>. Gao et al. <ref type="bibr" target="#b52">[53]</ref> proposed the spatial and temporal adaptive reflectance fusion model (STARFM) to fuse Landsat and Moderate Resolution Imaging Spectroradiometer (MODIS) observations. Subsequently, a number of popular spatio-temporal fusion methods have been further developed, including the enhanced STARFM <ref type="bibr" target="#b55">[56]</ref> and the extended spatio-temporal fusion method considering sensor observation differences <ref type="bibr" target="#b53">[54]</ref>. In addition, the unmixing-based methods <ref type="bibr" target="#b56">[57]</ref>, <ref type="bibr" target="#b57">[58]</ref> and the learning-based methods <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b59">[60]</ref> have been attracting ever-increasing attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Integrated Fusion Framework</head><p>Although many different kinds of image fusion methods have been proposed, they have all been developed independently, and there have been few studies exploring the relationships between them. In addition, the aforementioned fusion methods are dedicated to fusing two of the spatial, temporal, and spectral resolution indexes, and they are also only focused on one or two sensors. Therefore, in this paper, we propose an integrated fusion framework.</p><p>In this paper, we define the integrated fusion framework as taking full advantage of the multicomplementary spatial, temporal, and spectral information to obtain superior fused images, such as images with high spatial, high temporal, and high spectral resolutions. In general, it has two meanings. On one hand, it is dedicated to explore the relationship among different types of image fusion methods to formulate the unified fusion framework. On the other hand, it aims at fusing more complementary information from multisensor observations to obtain better fused results than one-sensor or two-sensor fusion. To the best of our knowledge, Shen <ref type="bibr" target="#b60">[61]</ref> was the first to attempt to formulate an integrated fusion framework for multiple spatiotemporal-spectral remote sensing images; however, the method was only tested on simulated data sets. Huang et al. <ref type="bibr" target="#b61">[62]</ref> proposed an extended version of the model in <ref type="bibr" target="#b60">[61]</ref> by exploring the relationship between the spatio-spectral and spatio-temporal fusion methods. This method was tested in real-data experiments; however, it was only performed on two sensors. Wu et al. <ref type="bibr" target="#b2">[3]</ref> and Meng et al. <ref type="bibr" target="#b62">[63]</ref> proposed integrated fusion frameworks for multiple sensors, but they did not consider the simultaneous fusion of multiple spatial, temporal, and spectral features. Therefore, as an extension of <ref type="bibr" target="#b63">[64]</ref>, this paper presents a unified framework for the integrated fusion of complementary spatial, temporal, and spectral information in multisource observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED FUSION FRAMEWORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Framework Description</head><p>In this paper, we propose an integrated framework for the spatio-temporal-spectral fusion of remote sensing images. It aims to obtain fused images with the highest spatial, temporal, and spectral resolutions among the input multisource remote sensing observations. In ideal conditions, it is expected to produce time series of high spatio-spectral resolution images simultaneously. However, difficulties in model establishment and computation load make this infeasible. Therefore, the proposed fusion framework is designed to obtain a fused image with high spatial and spectral resolutions for a specific time k, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The prerequisite for the fusion process is that there is an observation y k at the given time k. The multiview (multitemporal or multiangle) images Y = {y 1 , . . . , y k , . . . , y K } of y k may be also used in the fusion process, with k being the total number of images. In general, the images Y have higher spectral and temporal resolutions, but with a lower spatial resolution. Therefore, we regard Y as the spatially degraded images. As the enhanced counterpart of y k by the fusion process, x is the desired image with the higher spatial resolution. For a better solution of x, auxiliary multisource observations Z = {z 1 , . . . , z n , . . . , z N } are often necessary. Here, z n represents the nth image, and it is generally a PAN or an MS image with a higher spatial resolution, but with a lower spectral or temporal resolution. N is the total number of auxiliary images. As aforementioned, the proposed integrated fusion framework can accomplish different kinds of fusion tasks, including multiview spatial fusion, spatio-spectral fusion, spatio-temporal fusion, and spatio-temporal-spectral fusion, based on a single unified model. Table <ref type="table" target="#tab_0">I</ref> shows the different input requirements of the different fusion tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relationship Model</head><p>The integrated relationship model is constructed to build the relationship between the desired image x and the multisource remote sensing observations Y, Z. It includes the spatial degradation model and the spatio-temporal-spectral relationship model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Spatial Degradation Model:</head><p>The construction of the relationship between the desired image x and the observed degraded observations Y requires a comprehensive analysis of the integrated fusion problem to formulate a suitable spatial degradation model. It is assumed that the observed degraded images can be obtained by warping, blurring, downsampling, and noise operators performed on the desired image <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b64">[65]</ref>, and it is denoted by the following expression:</p><formula xml:id="formula_0">y k,b = DS k,b M k x b + v k,b (1 ≤ k ≤ K) (1)</formula><p>where y k,b denotes the bth band of the kth image in the collection of degraded observed images Y. x b represents the bth band of the desired fused image x, M k denotes the motion matrix, S k,b represents the point spread function blurring <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b47">[48]</ref>, D is the downsampling matrix, and v k,b is the zero-mean Gaussian noise <ref type="bibr" target="#b8">[9]</ref>, which is caused by sensors and the external environment. For convenience, (1) can be expressed as</p><formula xml:id="formula_1">y k,b = A y,k,b x b + v k,b (1 ≤ k ≤ K) (2)</formula><p>where</p><formula xml:id="formula_2">A y,k,b = DS k,b M k .</formula><p>2) Spatio-Temporal-Spectral Relationship Model: The spatio-temporal-spectral relationship model relates the desired image x to the multisource high-spatial-resolution observations Z. The multisource images in the collection Z may have different spatial scales, different spectral resolutions and spectral ranges, and different temporal resolutions and imaging times. Therefore, the relationship between x and Z should be comprehensively analyzed to construct the spatio-temporal-spectral relationship model. For convenience, the model in terms of z n,q is represented as follows:</p><formula xml:id="formula_3">z n,q = Ψ n,q C n,q A z,n,q x + τ n,q + υ n,q (1 ≤ q ≤ B z,n , 0 ≤ n ≤ N ) (3)</formula><p>where z n,q denotes the qth band of the nth image z n in the collection of multisource high-spatial-resolution observations Z, the total number of spectral bands of z n is B z,n , and A z,n,q denotes the spatial degradation matrix between the desired image and the multiscale high-spatial-resolution images; it is similar to A y,k,b in (2). C n,q denotes the spectral correlation matrix, Ψ n,q is the temporal correlation matrix considering the temporal features between the desired image and z n,q , τ n,q is the offset, and υ n,q denotes the noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Integrated Fusion Model 1) MAP Formulation:</head><p>The MAP theory has been widely applied in the description of ill-posed inverse problems such as denoising <ref type="bibr" target="#b65">[66]</ref>, destriping and inpainting <ref type="bibr" target="#b66">[67]</ref>, and image fusion <ref type="bibr" target="#b67">[68]</ref>. In this paper, the MAP theory is used to describe the proposed integrated fusion problem, and the aim is to estimate the desired image x based on the multisource observed images Y and Z. We can write this as</p><formula xml:id="formula_4">x = arg max x p(x|Y, Z).<label>(4)</label></formula><p>Applying Bayes' rules, (4) becomes</p><formula xml:id="formula_5">x = arg max x p(Y, Z|x)p(x) p(Y, Z) . (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>Since p(Y, Z) is independent of x, it can be thus considered as a constant to be removed in <ref type="bibr" target="#b4">(5)</ref>, and hence, we can write (5) as</p><formula xml:id="formula_7">x = arg max x p(Y, Z|x)p(x) = arg max x p(Y|x)p(Z|x, Y)p(x) = arg max x p(Y|x)p(Z|x)p(x). (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>Since Y and Z are known quantities, it is therefore tenable that p(Z|x, Y) = p(Z|x) in ( <ref type="formula" target="#formula_7">6</ref>).</p><p>2) Fusion Model: It can be seen that there are three probability density functions involved in <ref type="bibr" target="#b5">(6)</ref>. The first function p(Y|x) provides a measure of the coherence between the desired image x and the degraded observed images Y, as given by the spatial degradation model ( <ref type="formula">2</ref>), and it is determined by the probability density function of the noise in <ref type="bibr" target="#b1">(2)</ref>. The noise is assumed to be Gaussian, independent and identically distributed <ref type="bibr" target="#b68">[69]</ref>, <ref type="bibr" target="#b69">[70]</ref>; hence, p(Y|x) can be written as</p><formula xml:id="formula_9">p(Y|x) = K k=1 B x b=1 p(y k,b |x b ) (7) p(y k,b |x b ) = 1 (2πa y,k,b ) Φ 1 Φ 2 /2 exp -y k,b -A y,k,b x b 2 2 /2a y,k,b<label>(8)</label></formula><p>where a y,k,b is the variance of the noise v k,b , B x is the number of spectral bands, Φ 1 Φ 2 denotes the spatial dimension of y k,b , and || • || 2 denotes the 2 -norm.</p><p>The second probability density function p(Z|x) provides a measure of the accordance of Z and x to the spatio-temporal-spectral relationship model <ref type="bibr" target="#b2">(3)</ref>. It is determined by the probability distribution of the noise in (3), and we can argue the expression in</p><formula xml:id="formula_10">p(Z|x) = N n B z,n q=1 p(z n, q |x) (9) p(z n, q |x) = 1 (2πα z,n,q ) H n,1 H n,2 /2 exp{-z n,q -Ψ n,q C n,q A z,n,q x-τ n,q 2 2 /2α z,n,q } (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where a z,n,q denotes the variance of the noise, and H n,1 H n,2 denotes the spatial dimension of z n,q</p><p>The third probability density function p(x) is the image prior term. Inspired by <ref type="bibr" target="#b70">[71]</ref>, an adaptive weighted 3-D spatiospectral Laplacian prior is introduced, which is represented as</p><formula xml:id="formula_12">p(x) = B x b=1 1 (2πa x,b ) L 1 L 2 /2 exp -Qx b 2 2 /2a x,b (<label>11</label></formula><formula xml:id="formula_13">)</formula><formula xml:id="formula_14">θ d = B x b=1 [∇F (x b ) d ] T [∇F (x b ) d ] B x b=1 [e b,d ] T K k=1 A T y,k,b A y,k,b + λ 1 N n B z,n q=1 w n,q A T z,n,q C T n,q,b Ψ T n,q Ψ n,q C n,q A z,n,q + λ 2 Q T Q [e b,d ]<label>(18)</label></formula><p>where α x,b is the variance of the noise, L 1 L 2 denotes the spatial dimension of x, and Q indicates the adaptive weighted 3-D Laplacian matrix. For convenience, we write this as the expression</p><formula xml:id="formula_15">Qx b (i, j) = Q spa x b (i, j) + βQ spe x b (i, j) = x b (i + 1, j) + x b (i -1, j) + x b (i, j + 1) + x b (i, j -1) -4x b (i, j) + β xb || 2 xb+1 || 2</formula><p>x b+1 (i, j)</p><formula xml:id="formula_16">+ xb || 2 xb-1 || 2 x b-1 (i, j) -2x b (i, j) (<label>12</label></formula><formula xml:id="formula_17">)</formula><p>where x is the initial estimate of the fused image obtained by resampling of the corresponding observation, and β is the parameter, which is adaptively determined as</p><formula xml:id="formula_18">β = ⎧ ⎨ ⎩ exp -1 B x B x b=1 ∇x b || 2 /L 1 L 2 B x , B x &gt; u 0, B x ≤ u (<label>13</label></formula><formula xml:id="formula_19">)</formula><p>where u is the threshold parameter. It is assumed that, when the desired image has only a few spectral bands, their spectral curves are discontinuous; therefore, it is tenable and more robust to set β = 0. Conversely, if the desired image is a hyperspectral image, the spectral curve can be assumed to be approximately continuous, and thus, the adaptive weighted prior term can effectively preserve the shape of the spectral curve to decrease the spectral distortion. It is assumed that the smaller the difference between spectral bands, the stronger the spectral constraints. ∇x b denotes the gradient in the spectral dimension of the bth band. Here, the parameter u is set to 8, with the spectral band number of WorldView-2 multispectral images as a reference. Substituting ( <ref type="formula">7</ref>)-( <ref type="formula" target="#formula_12">11</ref>) into ( <ref type="formula" target="#formula_7">6</ref>), through the implementation of the monotonic logarithm function and the simplification, many parameters can be safely dropped, and the final energy function can be expressed as the regularized minimization problem in</p><formula xml:id="formula_20">x = arg min x [F (x)]<label>(14)</label></formula><formula xml:id="formula_21">F (x) = 1 2 K k=1 B x b=1 y k,b -A y,k,b x b 2 2 + λ 1 2 N n B z,n q=1</formula><p>w n,q z n,q -Ψ n,q C n,q A z,n,q x-τ n,q</p><formula xml:id="formula_22">2 2 + λ 2 2 B x b=1 Qx b 2 2 (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>where the first term denotes the coherence between x and Y, the second term represents the relationship between x and Z, and the third term denotes the image prior. w n,q denotes the relative contribution of z n,q to the desired image x, and it is adaptively calculated as w n,q = λ n,q U n . U n is calculated by the correlation <ref type="bibr" target="#b71">[72]</ref> between the degraded version of z n and the observed image corresponding to x, and it is assumed that the greater the correlation, the greater the contribution of the observation z n . The auxiliary parameter λ n,q is used to adaptively adjust the balance of the spatial details to each band of the fused image, and it is expressed as</p><formula xml:id="formula_24">λ n,q = f (z n,q , x)/min[f (z 1,1 , x), . . . , f(z 1,q , x), . . . , f(z n,q , x), . . .],</formula><p>where f (z n,q , x) denotes the number of spectral bands to be fused by z n,q . λ 1 and λ 2 , which are related to the variance of the noise, are the parameters used to control the relative contribution of the three terms. Because there are parameters in the second and third terms, there is no need to add extra parameters in the first term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. OPTIMIZATION SOLUTION AND PARAMETER DETERMINATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimization Procedure</head><p>The fused image is solved by the conjugate gradient algorithm <ref type="bibr" target="#b72">[73]</ref>, differentiating the energy function <ref type="bibr" target="#b14">(15)</ref> with respect to x b , as</p><formula xml:id="formula_25">∇F (x b ) = - K k=1 A T y,k,b (y k,b -A y,k,b x b ) -λ 1 N n B z,n q=1 w n,q A T z,n,q C T n,q,b Ψ T n,q (z n,q -Ψ n,q C n,q A z,n,q x-τ n,q )+λ 2 Q T Qx b . (<label>16</label></formula><formula xml:id="formula_26">)</formula><p>The desired fused image can be then solved by successive approximation iterations, i.e.,</p><formula xml:id="formula_27">x b,d+1 = x b,d + θ d e b,d<label>(17)</label></formula><p>where e b,d denotes the search direction of the dth iteration, and the initial value is negative of the gradient ∇F (x b ), i.e., e b,1 = -∇F (x b ) 1 . θ d is the step size of the dth iteration, as in ( <ref type="formula" target="#formula_14">18</ref>), shown at the top of the page. The next search direction is then relevant to the current iteration and the previous search direction and is represented as</p><formula xml:id="formula_28">e b,d+1 = -∇F (x b ) d+1 + γ d e b, d<label>(19)</label></formula><p>with ( <ref type="formula">20</ref>) and ( <ref type="formula" target="#formula_34">21</ref>), shown at the bottom of the next page.</p><p>The fused image is updated in each iteration, and it is terminated when</p><formula xml:id="formula_29">xd+1 -xd 2 2 / xd 2 2 ≤ ς (<label>22</label></formula><formula xml:id="formula_30">)</formula><p>where ς is a predetermined threshold value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Determination of the Spectral and Temporal Correlations</head><p>The spatial, temporal, and spectral relationships between the desired image and the multisource remote sensing observations are comprehensively considered in the integrated relationship model. In the model, two issues need to be solved, i.e., the determination of the spectral correlation matrix and the temporal correlation matrix in (3).</p><p>1) Spectral Correlation C: The spectral correlation matrix plays an important role in the integrated relationship model. In general, the images in the collection of multisource highspatial-resolution observations Z have a relatively wider bandwidth than the desired image x. Therefore, a popular approach is to relate x and the images in Z by linear band combinations <ref type="bibr" target="#b35">[36]</ref>- <ref type="bibr" target="#b37">[38]</ref> , <ref type="bibr" target="#b60">[61]</ref>- <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b67">[68]</ref>. For convenience, we take PAN/MS fusion <ref type="bibr" target="#b67">[68]</ref> as an example, which is written as</p><formula xml:id="formula_31">z(i, j) = B x b=1 c b x b (i, j) + τ + υ(i, j)<label>(23)</label></formula><p>where z(i, j) is the brightness value of the wideband PAN image, with (i, j) being the pixel position, and {c b } is the linear combination coefficients.</p><p>To date, a variety of fusion methods have been involved in searching for the solution of the linear combination coefficients {c b }, and most of them employ the spectral response functions of the sensors to calculate the linear coefficients <ref type="bibr" target="#b67">[68]</ref>, <ref type="bibr" target="#b73">[74]</ref>. However, in fact, the spectral response functions of the sensors may differ from the responses of the observed data sets due to the atmospheric effects, illumination conditions, etc. <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b74">[75]</ref>. Furthermore, if we cannot easily obtain the spectral response functions, then the image fusion methods will not work. In this paper, it is assumed that the linear coefficients {c b } are not only about the fitting between z and x; furthermore, they also play an important role in assigning the relative weight of the spatial structure information to each band of the fused image. Inspired by this idea, a novel and simple solution for {c b } is proposed by considering the internal correlation between the spectral bands. This is represented as</p><formula xml:id="formula_32">c b = cov(x b , I syn ) var(I syn )<label>(24)</label></formula><p>where cov(•) denotes the covariance, and var(•) denotes the variance. xb is the resampled bth band of the observed narrowband image, and I syn denotes the intensity by the generalized intensity-hue-saturation <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b75">[76]</ref> transformation of the corresponding spectral bands. Finally, the linear combination coefficients are obtained by normalization as c b /sum({c b }).</p><p>2) Temporal Correlation Ψ: It is assumed that the relationship between the multitemporal scenes can be expressed by a linear model <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b76">[77]</ref>- <ref type="bibr" target="#b78">[79]</ref>. To improve the robustness, a space-varying multitemporal linear relationship model is adopted by comprehensively analyzing the integrated fusion problem. The schematic for the determination of the temporal relationship is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. It is shown that the temporal relationship Ψ can be approximately obtained by the corresponding multitemporal low-spatial-resolution remote sensing images ỹt1 , ỹt2 <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b78">[79]</ref>. To ensure the effectiveness of the relationship mapping, the spectral range of ỹt1 , ỹt2 should be consistent with z; for example, in the case of spatio-temporalspectral fusion, ỹt1 , ỹt2 should be first obtained by band combination of the corresponding observations. Here, x has the same spatial scale and spectral range as z, and it can be approximately represented as x = CAx, where A denotes the spatial degraded matrix, and C represents the spectral correlation matrix, as shown in <ref type="bibr" target="#b2">(3)</ref>, and when it is a case of spatiotemporal fusion, A and C are generally the identity matrices. <ref type="bibr" target="#b19">(20)</ref>  The space-varying temporal relationship is solved with the aid of neighboring similar pixels. The initial similar pixel locations are determined in the high-spatial-resolution image z, and they are selected based on a nonlocal strategy <ref type="bibr" target="#b79">[80]</ref>. The selection rule is</p><formula xml:id="formula_33">∇F (x b ) d+1 = ∇F (x b ) d + θ d ⎡ ⎣ K k=1 A T y,k,b A y,k,b + λ 1 N n B z,n q=1 w n,q A T z,n,q C T n,q,b Ψ T n,q Ψ n,q C n,q A z,n,q + λ 2 Q T Q ⎤ ⎦ e b,d</formula><formula xml:id="formula_34">γ d = B x b=1 [∇F (x b ) d+1 ] T [∇F (x b ) d+1 ] B x b=1 [∇F (x b ) d ] T [∇F (x b ) d ]<label>(21)</label></formula><formula xml:id="formula_35">exp -G(O z (i) -O z (j)) 2 2 h 2 ≥ η, j ∈ W i (<label>25</label></formula><formula xml:id="formula_36">)</formula><p>where O z (i) denotes the 3-D at the central pixel position i, and O z (j) denotes the 3-D neighboring patch at pixel position j within a W i . G is the kernel function with inverse distance weighting, h is the standard of the central pixel patch, and η is the threshold value.</p><p>After the initial similar pixel locations are determined, an additional filtering process is applied to the candidates to improve the accuracy. The basic rule is that the more consistent the temporal change between the similar pixels and the central pixel, the greater the probability of the similar pixels' selection. This is expressed as</p><formula xml:id="formula_37">E = {ỹ t1 j -ỹt2 j |j ∈ Ω i },⇒ abs(E j -E i ) ≤ δ E j ∈ Ω i (<label>26</label></formula><formula xml:id="formula_38">)</formula><p>where E denotes the temporal change of the similar pixels, Ω i denotes the collection of initial similar pixel locations for the central pixel position i, abs(•) represents the absolute value function, and σ E is the standard variation of E.</p><p>After the similar pixels are finally selected in ỹt1 , ỹt2 , robust regression analysis using iteratively reweighted least squares with a Huber weighting function <ref type="bibr" target="#b80">[81]</ref> is utilized to solve the multitemporal correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Sets and Experimental Settings</head><p>To comprehensively test the performance of the proposed integrated fusion framework, a variety of image fusion experiments were implemented with both simulated and real data. The experiments consisted of the following: 1) multiview spatial fusion experiments; 2) spatio-spectral fusion experiments; 3) spatio-temporal fusion experiments; and 4) spatio-temporalspectral fusion experiments. Furthermore, the proposed method was comprehensively tested and verified using data from multiple different remote sensing satellites, including IKONOS, Landsat Enhanced Thematic Mapper Plus (ETM+), MODIS, Hyperspectral Digital Imagery Collection Experiment (HYDICE), and SPOT-5.</p><p>There are several parameters in the experiments. However, it is noteworthy that most of the parameters are not sensitive to the fusion model for different fusion tasks, and hence, most of them were empirically set to be fixed values. The parameter λ 1 was the sole tunable parameter in the experiments. Unless otherwise specified, the parameter λ 2 was empirically set to 0.001, and the iterative threshold value ς was empirically set to 1e-7. In the spatio-temporal and spatio-temporal-spectral fusion experiments, the patch size in <ref type="bibr" target="#b24">(25)</ref> was set to 7 × 7, the window size of W was set to 23 × 23, and the threshold value η was set to 1e-3 empirically. In addition, the motion and the blurring of (3) have little influence to the experiments, considering the efficiency and effectiveness; they are hence set to be identity matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results and Analysis 1) Multiview Spatial Fusion Experiments:</head><p>The multiview spatial fusion experiments were implemented with simulated data, and a 256 × 256 pixel subarray of the blue band of the original IKONOS MS image [see Fig. <ref type="figure" target="#fig_2">3(d)]</ref>, which was acquired in Hubei Province, China, on September 4, 2009, was used to generate four simulated low-spatial-resolution images with subpixel displacements. The subpixel shifts were (0, 0), (0.5, 0), (0, 0.5), and (0.5, 0.5), respectively; and the spatial dimension size of each degraded image was 64 × 64. The popular quantitative indexes of the correlation coefficient (CC) <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b67">[68]</ref>, the structural similarity index (SSIM) <ref type="bibr" target="#b81">[82]</ref>, <ref type="bibr" target="#b82">[83]</ref>, the peak signal-tonoise ratio (PSNR) <ref type="bibr" target="#b81">[82]</ref>, <ref type="bibr" target="#b83">[84]</ref>, and the root-mean-square error (RMSE) <ref type="bibr" target="#b67">[68]</ref> were utilized to evaluate the fused results. Fig. <ref type="figure" target="#fig_2">3</ref>(c) shows the fused result obtained by the proposed integrated fusion framework with λ 1 = 0. Fig. <ref type="figure" target="#fig_2">3(a)</ref> and<ref type="figure">(b)</ref> shows the results of the nearest neighbor and bilinear interpolation algorithms, respectively, for comparison. It can be observed that the result of the proposed fusion framework has more detailed information and a better visual quality than the traditional interpolation methods. A more detailed visual comparison can be made from the subregions of the images. The quantitative evaluation results in Table II also show that the proposed fusion framework produces results that are superior to the results of the traditional methods. Therefore, it is demonstrated that the proposed integrated fusion framework can make full use of the redundancy and complementary information to improve the spatial resolution of the degraded images.  2) Spatio-Spectral Fusion Experiments: In the spatiospectral fusion experiments, three fusion cases were implemented by the proposed integrated fusion framework: 1) PAN/ HS fusion; 2) MS/HS fusion; and 3) PAN/MS/HS fusion.</p><p>The experiments were performed on the simulated data sets based on an original HYDICE HS image <ref type="bibr" target="#b84">[85]</ref> acquired over the Washington DC Mall. The simulated HS image was obtained by low-pass filtering using Gaussian modulation transfer function blurring and downsampling by a factor of 4 in the spatial domain. The spatial resolution of the simulated degraded HS image was 4 m, and it had 79 bands with the spectral range of 450-1750 nm. The MS image was obtained by degradation in both the spatial and spectral domains. In the spatial dimension, it was downsampled by a factor of 2, and its spatial resolution was 2 m; in the spectral dimension, it was produced according to the spectral characteristics of Landsat-7 ETM+ bands 1-5, which cover the 450-to 515-nm, 525-to 605-nm, 630-to 690-nm, 750-to 900-nm, and 1550-to 1750-nm regions, respectively. The PAN image with a 1-m spatial resolution was degraded in the spectral dimension, and it was produced according to the spectral characteristics of a Landsat-7 PAN image covering 520-900 nm. In the experiments, several widely used quality indexes were applied for the quantitative evaluation: CC, SSIM, PSNR, the dimensionless global error in synthesis (ERGAS) <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b67">[68]</ref>, the spectral angle mapper (SAM) <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b67">[68]</ref>, and Q -avg <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b71">[72]</ref>.   <ref type="figure" target="#fig_4">5</ref>. It is noteworthy that we set the same parameter λ 1 = 1 for all three fusion cases, for a fair comparison. It can be seen that all three fusion cases can improve the spatial resolution of the HS image. However, there is still a distinct difference between the three fusion results. On one hand, in the aspect of spatial resolution enhancement, the MS/HS fusion can only improve the spatial resolution of the HS image from 4 to 2 m, whereas the PAN/HS and PAN/MS/HS fusion cases can improve the spatial resolution of the HS image from 4 to 1 m. Relatively speaking, the PAN/MS/HS fusion result has slightly better spatial details than the PAN/HS fusion result because of the incorporation of the MS images. On the other hand, in the aspect of spectral fidelity, the PAN/MS/HS fusion and the MS/HS fusion can effectively enhance all the spectral bands of the HS image; however, the PAN/HS fusion with a single PAN image cannot enhance all the spectral bands due to the incomplete spectral coverage between the PAN (520-900 nm) and HS (450-1320 nm) images. In addition, the PAN/MS/HS fusion result shows better spectral information preservation than the other two fusion cases. Table <ref type="table" target="#tab_2">III</ref> shows the quantitative evaluation results. It should be noted that the MS/HS fusion was evaluated by bilinear resampling to the spatial scale of the original HS image, for a fair comparison. It can be seen that most of the evaluation indexes of the PAN/MS/HS fusion result are the best. On the whole, the PAN/MS/HS fusion result is the best in terms of both the spatial enhancement and the spectral fidelity. This is because the PAN/MS/HS fusion can make full use of the complementary spatial and spectral information of the PAN and MS groups.</p><p>3) Spatio-Temporal Fusion Experiments: The spatiotemporal fusion experiments were implemented on Landsat-7 ETM+ and MODIS terra MOD09GA image pairs <ref type="bibr" target="#b85">[86]</ref>, with spatial resolutions of 25 and 500 m, respectively. The images were from southern New South Wales (NSW, Australia; 34.0034 • E, 145.0675 • S). Fig. <ref type="figure" target="#fig_6">6</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Spatio-Temporal-Spectral Fusion Experiments:</head><p>In the spatio-temporal-spectral fusion experiments, a SPOT-5 PAN image (5 m), a SPOT-5 MS image (10 m, band numbers: 1-4), an ETM+ PAN image (15 m), an ETM+ MS image (30 m, band numbers: 1-5, 7), and MODIS images (MOD02 1 km, band numbers: 1-12, 17-19, 26) were used. The spectral bands of the MODIS images were arranged according to the spectra of the SPOT-5 and ETM+ images. Fig. <ref type="figure" target="#fig_8">7(a)-(g)</ref> shows the experimental data sets with multiple spatial, temporal, and spectral features. The main task of these spatio-temporal-spectral fusion experiments was to obtain high spatial-spectral resolution images on October 6, 2011. To comprehensively test the performance of the proposed integrated fusion framework, three groups of fusion experiments were implemented: 1) twosensor fusion; 2) three-sensor fusion; and 3) five-sensor fusion. Table <ref type="table">V</ref> shows the input data sets of the three experimental groups. The parameter λ 1 was set to 1 for all three cases.</p><p>The experimental results of the two-sensor fusion, the three-sensor fusion, and the five-sensor fusion are shown in Fig. <ref type="figure" target="#fig_8">7</ref>(h)-(j), respectively. For a detailed comparison, local zoomed-in areas are shown. It can be clearly seen that all three fusion cases can effectively predict the result on October 6, 2011. In comparison, the five-sensor fusion result has the highest spatial resolution of 5 m, the three-sensor fusion result has a spatial resolution of 15 m, and the two-sensor fusion result has a spatial resolution of 30 m. Furthermore, although </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE V THREE GROUPS OF SPATIO-TEMPORAL-SPECTRAL FUSION EXPERIMENTS</head><p>the spatial resolution of the five-sensor fusion result has been greatly improved, the spectral information is preserved very well, which can be clearly seen in the local zoomed-in areas in Fig. <ref type="figure" target="#fig_8">7</ref>. In addition, this can be also seen in the spectral profiles in Fig. <ref type="figure" target="#fig_9">8</ref>. On the whole, all the spectral profiles of the three fusion cases are consistent with the MODIS observations. However, there is a slight difference in the spectral profiles of the 13th and 14th bands between the fusion results and the MODIS observations. This is because the wavelength of the 13th spectral band is far from the relevant spectral bands of the SPOT-5 and ETM+ images. Thus, it causes slight spectral distortion of the 13th and 14th bands. To further verify the effectiveness of the multisensor fusion, a two-sensor fusion experiment with only the highest and lowest spatial resolution observations was implemented, i.e., the observations in Fig. <ref type="figure" target="#fig_8">7</ref>(b), (c), and (g). A comparison between the two-sensor and five-sensor fusion results [i.e., Fig. <ref type="figure" target="#fig_8">7</ref>(j)] is shown in Fig. <ref type="figure" target="#fig_10">9</ref>. The bilinear interpolated ETM+ MS image with consistent spectra on the same day, i.e., October 6, 2011, is shown in Fig. <ref type="figure" target="#fig_10">9</ref>(c) for the identification of the spectral features. Visually, it can be clearly seen that both the two-sensor and five-sensor fusion results have promoted the spatial structure; however, some regions of the two-sensor fusion result are too homogenized. In addition, the two-sensor fusion result shows a serious loss of spectral information. This can be clearly seen by a comparison with Fig. <ref type="figure" target="#fig_10">9</ref>(c), and it can be also seen in the spectral profiles in Fig. <ref type="figure" target="#fig_11">10</ref>. This is because the difference in spatial resolution between the SPOT-5 PAN (5 m) and MODIS observations (1000 m) is too great, and the complementary information is not enough for such a challenging fusion process. Conversely, the fivesensor fusion can make full use of the complementary information of the multisource observations, which fully demonstrates the advantage of the proposed integrated fusion framework. However, this does not mean that more sensors will always lead to better fusion results. Several factors are involved, including the redundancy, the complementarity, and the image quality. In conclusion, there are two main advantages of the proposed integrated fusion framework. First, the proposed integrated fusion framework can accomplish different kinds of image fusion tasks based on a single unified model, including multiview spatial fusion, spatio-spectral fusion (PAN/MS fusion, PAN/HS fusion, and MS/HS fusion), and spatio-temporal fusion. Second, the proposed integrated fusion framework can obtain promising high spatio-temporal-spectral resolution fused images by taking full advantage of the complementary information from multisource observations. Furthermore, it does not have limitations on the number of remote sensing sensors.</p><p>However, it is noteworthy that there is still room for the proposed fusion framework to be further improved. The first limitation is the efficiency of the algorithm, particularly when there are quite a few sensor images to be fused. Therefore, a faster optimization algorithm and acceleration strategies such as parallel computing could be incorporated into the integrated fusion framework. Second, the proposed integrated fusion framework can be only used for homogenous optical remote sensing images. Fusion of multisource heterogeneous data (optical, thermal infrared, radar, etc.) is a more challenging task. Furthermore, new computation frameworks, including sparse representation, low-rank approximation, and tensor analysis, could be considered to further improve the robustness of the proposed fusion framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic of the proposed integrated fusion framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Schematic for determination of the temporal correlation.</figDesc><graphic coords="6,343.07,81.41,174.82,151.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Experimental results in multiview spatial fusion. (a) Nearest neighbor interpolation. (b) Bilinear interpolation. (c) Result of the proposed method. (d) Original image.</figDesc><graphic coords="7,340.55,160.01,79.70,79.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Experimental results in spatio-spectral fusion (displayed as false color: near infrared, green, and blue). (a) HS image. (b) MS image. (c) PAN image. (d) MS/HS fusion result. (e) PAN/HS fusion result. (f) PAN/MS/HS fusion result. (g) Original HS image.</figDesc><graphic coords="8,307.79,333.77,246.08,89.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Local zoomed-in areas of the fusion results. (a) Resampled HS image with bilinear interpolation to the spatial scale of the original HS image. (b) Resampled MS/HS fusion result with bilinear interpolation to the spatial scale of the original HS image. (c) PAN/HS fusion result. (d) PAN/MS/HS fusion result. (e) Original HS image.</figDesc><graphic coords="8,52.31,213.29,68.19,68.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4</head><label>4</label><figDesc>Fig.4shows the experimental results. The PAN/MS/HS fusion result is shown in Fig.4(f), and the MS/HS and PAN/HS fusion results are shown in Fig.4(d) and (e), respectively. For a more detailed comparison, local zoomed-in areas are shown in Fig.5. It is noteworthy that we set the same parameter λ 1 = 1 for all three fusion cases, for a fair comparison. It can be seen that all three fusion cases can improve the spatial resolution of the HS image. However, there is still a distinct difference between the three fusion results. On one hand, in the aspect of spatial resolution enhancement, the MS/HS fusion can only improve the spatial resolution of the HS image from 4 to 2 m, whereas the PAN/HS and PAN/MS/HS fusion cases can improve the spatial resolution of the HS image from 4 to 1 m. Relatively speaking, the PAN/MS/HS fusion result has slightly better spatial details than the PAN/HS fusion result because of the incorporation of the MS images. On the other hand, in the aspect of spectral fidelity, the PAN/MS/HS fusion and the MS/HS fusion can effectively enhance all the spectral bands of the HS image; however, the PAN/HS fusion with a single PAN image cannot enhance all the spectral bands due to the incomplete spectral coverage between the PAN (520-900 nm) and HS (450-1320 nm) images. In addition, the PAN/MS/HS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Experimental results in spatio-temporal fusion (displayed as band combination: red, green, blue). (a) MODIS image on October 8, 2001. (b) ETM+ image on October 8, 2001. (c) MODIS image on November 2, 2001. (d) ETM+ image on November 2, 2001. (e) MODIS image on October 17, 2001. (f) Predicted result on October 17, 2001 by the STARFM method. (g) Predicted result on October 17, 2001 by the SPSTFM method. (h) Predicted result on October 17, 2001 by the EBSPTF method. (i) Predicted result on October 17, 2001 by the proposed fusion framework. (j) Observed ETM+ image on October 17, 2001.</figDesc><graphic coords="9,93.59,177.77,400.30,90.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(a)-(d) shows two pairs of ETM+/MODIS observations on October 8, 2001 and November 2, 2001, respectively. Fig. 6(e) shows the MODIS image on October 17, 2001. The task of the fusion was to predict a Landsat-like image on October 17, 2001 by making use of Fig. 6(a)-(e). The observed ETM+ image shown in Fig. 6(j) is for reference. Fig. 6(i) shows the result of the proposed fusion framework with λ 1 = 3, and Fig. 6(f)-(h) shows the fusion results of the popular STARFM method [53], the SParserepresentation-based SpatioTemporal reflectance Fusion Model (SPSTFM) [59], and the error-bound-regularized sparse coding (EBSPTM) [87] method, respectively, for comparison. Here, the default parameters consistent to the original published papers are used. For a more detailed comparison, local zoomedin areas are shown. It can be observed that the proposed fusion framework can effectively predict the ETM+ image on October 17, 2001, and it is competitive compared with other methods. The quantitative results are shown in Table IV. It also demonstrates the good performance of the proposed fusion framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Experiments in spatio-temporal-spectral fusion (displayed as false color). (a) MODIS image on September 4, 2011. (b) MODIS image on October 6, 2011. (c) MODIS image on September 22, 2011. (d) ETM+ MS image on September 4, 2011. (e) ETM+ PAN image on September 4, 2011. (f) SPOT-5 MS image on September 22, 2011. (g) SPOT-5 PAN image on September 22, 2011. (h) Fusion result on October 6, 2011 by two sensors, where the inputs are observations (a), (b), and (d). (i) Fusion result on October 6, 2011 by three sensors, where the inputs are observations (a), (b), (d), and (e). (j) Fusion result on October 6, 2011 by five sensors, where the inputs are all the observations (a)-(g).</figDesc><graphic coords="10,266.63,176.93,98.91,295.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Spectral profiles of the original MODIS observation on October 6, 2011 and the fusion results of the three experimental groups, i.e., two-sensor fusion, three-sensor fusion, and five-sensor fusion.</figDesc><graphic coords="10,337.32,540.42,186.96,124.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Performance verification of multisensor fusion. (a) Fusion result on October 6, 2011 by two sensors with only the highest and lowest spatial resolution observations, i.e., Fig. 7(b), (c), and (g). (b) Fusion result on October 6, 2011 by five sensors using Fig. 7(a)-(g). (c) Bilinear interpolated ETM+ MS on October 6, 2011 with the consistent spectral display for the spectral feature validation.</figDesc><graphic coords="11,63.12,69.18,462.24,312.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Spectral profiles of the two-sensor fusion result with only the highest and lowest spatial resolution observations, the five-sensor fusion result, and the original MODIS observation on October 6, 2011. VI. CONCLUSION This paper has presented an integrated framework for the spatio-temporal-spectral fusion of remote sensing images. The proposed integrated fusion framework was comprehensively tested and verified by a variety of image fusion experiments involving multiple remote sensing satellites, including IKONOS,</figDesc><graphic coords="11,300.12,452.10,252.00,180.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PROPOSED</head><label>I</label><figDesc></figDesc><table /><note><p>FUSION FRAMEWORK AS A UNIFIED MODEL FOR DIFFERENT KINDS OF FUSION TASKS</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II QUANTITATIVE</head><label>II</label><figDesc>EVALUATION RESULTS OF THE MULTIVIEW SPATIAL FUSION EXPERIMENTS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III QUANTITATIVE</head><label>III</label><figDesc></figDesc><table /><note><p>EVALUATION RESULTS OF THE SPATIO-SPECTRAL EXPERIMENTS</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV QUANTITATIVE</head><label>IV</label><figDesc>EVALUATION RESULTS OF THE SPATIO-TEMPORAL FUSION EXPERIMENTS</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the anonymous reviewers for their careful reading and valuable comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Natural Science Foundation of China under Grant 41271376 and Grant 41422108 and in part by the Cross-Disciplinary Collaborative Teams Program for Science, Technology and Innovation of the Chinese Academy of Sciences, Wuhan Science and Technology Program under Grant 2013072304010825.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding image fusion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="657" to="661" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving the spatial resolution of Landsat TM/ETM+ through fusion with SPOT5 images via learning-based super-resolution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1195" to="1204" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Integrated fusion of multiscale polar-orbiting and geostationary satellite observations for the mapping of high spatial and temporal resolution land surface temperature</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-M</forename><surname>Göttsche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="169" to="181" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Remote Sensing Image Fusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garzelli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hyperspectral remote sensing data analysis and future challenges</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scheunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Mag</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="6" to="36" />
			<date type="published" when="2013-06">Jun. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multisensor image fusion in remote, sensing: Concepts, methods, application</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Van Genderenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="823" to="854" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Synthesis of multispectral images to high spatial resolution: A critical review of fusion methods based on remote sensing physics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ranchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1301" to="1312" />
			<date type="published" when="2008-05">May 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A critical comparison among pansharpening algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2565" to="2586" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hyperspectral pansharpening: A review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Loncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Mag</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="27" to="46" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparison of spatiotemporal fusion models: A review</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1798" to="1835" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-source remote sensing data fusion: Status and trends</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Image Data Fusion</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="24" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Super-resolution image reconstruction: A technical overview</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="21" to="36" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multiframe super-resolution employing a spatially weighted total variation model</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="392" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image superresolution: The techniques, applications, and future</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="389" to="408" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adaptive norm selection for regularized image restoration and super-resolution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1388" to="1399" />
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiframe image restoration and registration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Comput. Vis. Image Process</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="317" to="339" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Super resolution: Quincunx sampling and fusion processing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Latry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rougé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE IGARSS</title>
		<meeting>IEEE IGARSS<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="315" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An operational superresolution approach for multi-temporal and multi-angle remotely sensed imagery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>-W. Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Canters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="110" to="124" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Super-resolution reconstruction for multi-angle remote sensing images considering resolution differences</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="637" to="657" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Super-resolution reconstruction algorithm to MODIS remote sensing images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. J</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="100" />
			<date type="published" when="2007">2009. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Super-resolution of remotely sensed images with variable-pixel linear reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Merino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nunez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1446" to="1457" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Super resolution for remote sensing images based on a universal hidden Markov tree model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1270" to="1278" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust locally weighted regression for superresolution enhancement of multi-angle remote sensing imagery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>-W. Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Canters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1357" to="1371" />
			<date type="published" when="2014-04">Apr. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Merging hyperspectral and panchromatic image data: Qualitative and quantitative analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cetin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Musaoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1779" to="1804" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Coupled nonnegative matrix factorization unmixing for hyperspectral and multispectral data fusion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iwasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="528" to="537" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reconstruction of multispatial, multispectral image data using spatial frequency content</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Schowengerdt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1325" to="1334" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Integration of the SPOT panchromatic channel into its multispectral mode for image sharpness enhancement</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cliche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bonn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Teillet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogramm. Eng. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="316" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image sharpening for mixed spatial and spectral resolution satellite systems</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Hallada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium Remote Sensing Environment</title>
		<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983">May 9-13, 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A new look at IHS-like image fusion methods</title>
		<author>
			<persName><forename type="first">T.-M</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. fusion</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="177" to="186" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Color enhancement of highly correlated images. II. Channel ratio and &quot;chromaticity&quot; transformation techniques</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Gillespie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Kahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="365" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Process for enhancing the spatial resolution of multispectral imagery using pan-sharpening</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Brower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Laben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">U.S. Patent</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2000-04">Jan. 4, 2000</date>
		</imprint>
	</monogr>
	<note>875 A</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Introduction of sensor spectral response into image fusion methods. Application to wavelet-based methods</title>
		<author>
			<persName><forename type="first">X</forename><surname>Otazu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>González-Audícana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Fors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Núñez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garzelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2300" to="2312" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pansharpening with a guided filter based on three-layer decomposition</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Art. no. E1068</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A comparative analysis of image fusion methods</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ziou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Armenakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1391" to="1402" />
			<date type="published" when="2005-06">Jun. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A variational model for P+ XS image fusion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Igual</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verdera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rougé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="58" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A new pan-sharpening method using a compressed sensing technique</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="738" to="746" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A practical compressed sensing-based pan-sharpening method</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="633" />
			<date type="published" when="2012-07">Jul. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Two-step sparse coding for the pan-sharpening of remote sensing images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1792" to="1805" />
			<date type="published" when="2014-05">May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Remote sensing image fusion via sparse representations over learned dictionaries</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4779" to="4789" />
			<date type="published" when="2013-09">Sep. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Full-scale assessment of pansharpening through polynomial fitting of multiscale measurements</title>
		<author>
			<persName><forename type="first">R</forename><surname>Carla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Santurri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6344" to="6355" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Comparison of pansharpening algorithms: Outcome of the 2006 GRS-S data-fusion contest</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gamba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3012" to="3021" />
			<date type="published" when="2007-10">Oct. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Twentyfive years of pansharpening: A critical review and new developments</title>
		<author>
			<persName><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alparone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garzelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Selva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal and Image Processing for Remote Sensing</title>
		<editor>
			<persName><forename type="first">C.-H</forename><surname>Chen</surname></persName>
		</editor>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="533" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multispectral and hyperspectral pansharpening: A critical examination and new developments</title>
		<author>
			<persName><forename type="first">G</forename><surname>Vivone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ph.D. dissertation, Dept. Inf. Eng., Electr. Eng. Appl., Univ. Salerno</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>Fisciano, Italy</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A variational approach to hyperspectral image fusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wittman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Defense</title>
		<meeting>SPIE Defense<address><addrLine>Security, Sens</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fusion of hyperspectral and multispectral images: A novel framework based on generalization of pan-sharpening methods</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-M</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1418" to="1422" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Physics-based resolution enhancement of hyperspectral data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Algorithms Technol. Multispectr., Hyperspectr., Ultraspectr. Imagery VIII</title>
		<meeting>SPIE Algorithms Technol. Multispectr., Hyperspectr., Ultraspectr. Imagery VIII</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">MAP estimation for hyperspectral image resolution enhancement using an auxiliary sensor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Eismann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1174" to="1184" />
			<date type="published" when="2004-09">Sep. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hyperspectral resolution enhancement using high-resolution multispectral imagery with arbitrary response functions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Eismann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="465" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hyperspectral and multispectral image fusion based on a sparse representation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dobigeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Tourneret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3658" to="3668" />
			<date type="published" when="2015-07">Jul. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A convex formulation for hyperspectral image superresolution via subspacebased regularization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simões</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3373" to="3388" />
			<date type="published" when="2015-06">Jun. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Recent advances in techniques for hyperspectral image processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
		<idno>pp. S110-S122</idno>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On the blending of the Landsat and MODIS surface reflectance: Predicting daily Landsat surface reflectance</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schwaller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2207" to="2218" />
			<date type="published" when="2006-08">Aug. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A spatial and temporal reflectance fusion model considering sensor observation differences</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4367" to="4383" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Long-term and finescale satellite monitoring of the urban heat island effect by the fusion of multi-temporal and multi-sensor remote sensed data: A 26-year case study of the city of Wuhan in China</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">An enhanced spatial and temporal adaptive reflectance fusion model for complex heterogeneous regions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Masek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2610" to="2623" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A comparison of STARFM and an unmixing-based algorithm for Landsat and MODIS data fusion</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Gevaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>García-Haro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="34" to="44" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Multitemporal fusion of Landsat/TM and ENVISAT/MERIS for crop monitoring</title>
		<author>
			<persName><forename type="first">J</forename><surname>Amorós-López</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Appl. Earth Observ. Geoinf</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="132" to="141" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Spatiotemporal reflectance fusion via sparse representation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3707" to="3716" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Spatiotemporal satellite image fusion through one-pair image learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1883" to="1896" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Integrated fusion method for multiple temporal-spatial-spectral images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Congr</title>
		<meeting>22nd Congr<address><addrLine>Melbourne, Vic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="407" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Unified fusion of remote-sensing imagery: Generating simultaneously high-resolution synthetic spatial-temporal-spectral earth observations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="561" to="569" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Improving the spatial resolution of hyperspectral image using panchromatic and multispectral images: An integrated method</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 7th WHISPERS</title>
		<meeting>7th WHISPERS<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A unified framework for spatio-temporal-spectral fusion of remote sensing images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE IGARSS</title>
		<meeting>IEEE IGARSS<address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2584" to="2587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A MAP approach for joint motion estimation, segmentation, and super resolution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="479" to="490" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Hyperspectral image denoising employing a spectral-spatial adaptive total variation model</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3660" to="3677" />
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A MAP-based algorithm for destriping and inpainting of remotely sensed images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1492" to="1502" />
			<date type="published" when="2009-05">May 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Adjustable model-based fusion method for multispectral and panchromatic images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1693" to="1704" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">MAP estimation for multiresolution fusion in remotely sensed images using an IGMRF prior model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jalobeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1245" to="1255" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A model-based approach to multiresolution fusion in remotely sensed images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2549" to="2562" />
			<date type="published" when="2006-09">Sep. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A fast algorithm for highresolution color image reconstruction with multisensors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Numerical Analysis and Its Applications</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="615" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A universal image quality index</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="81" to="84" />
			<date type="published" when="2002-03">Mar. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Function minimization by conjugate gradients</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Reeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. J</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="154" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Fusion of multispectral and panchromatic images using a restoration-based method</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1482" to="1491" />
			<date type="published" when="2009-05">May 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Cross-calibration for data fusion of EO-1/Hyperion and Terra/ASTER</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mayumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iwasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="419" to="426" />
			<date type="published" when="2013-04">Apr. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Improving component substitution pansharpening through multivariate regression of MS+ PAN data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Aiazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baronti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Selva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3230" to="3239" />
			<date type="published" when="2007-10">Oct. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Recovering missing pixels for Landsat ETM+ SLC-off imagery using multi-temporal regression analysis and a regularization method</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="182" to="194" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Missing information reconstruction of remote sensing data: A technical review</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Mag</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="61" to="85" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Bayesian data fusion: Spatial and temporal applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fasbender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Obsomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Radoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bogaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Defourny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Anal. Multi-Temporal Remote Sens</title>
		<meeting>Int. Workshop Anal. Multi-Temporal Remote Sens<address><addrLine>Leuven, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Robust estimation of a location parameter</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="101" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Multivariate statistical analysis of measures for assessing the quality of image fusion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Image Data Fusion</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="66" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Mean squared error: Love it or leave it? A new look at signal fidelity measures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="117" />
			<date type="published" when="2009-01">Jan. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">HYDICE system: Implementation and performance</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Basedow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Carmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Symp. OE/Aerosp. Sens. Dual Use Photon</title>
		<meeting>SPIE Symp. OE/Aerosp. Sens. Dual Use Photon</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="258" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Assessing the accuracy of blending Landsat-MODIS surface reflectances in two landscapes with contrasting spatial and temporal dynamics: A framework for algorithm selection</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Emelyanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Mcvicar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Van Niel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Environ</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="193" to="209" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">An error-bound-regularized sparse coding for spatiotemporal reflectance fusion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6791" to="6803" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
