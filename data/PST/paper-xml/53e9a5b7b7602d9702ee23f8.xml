<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Succinct Indexable Dictionaries with Applications to Encoding k-ary Trees, Prefix Sums and Multisets *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-05-04">4 May 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rajeev</forename><surname>Raman</surname></persName>
							<email>r.raman@mcs.le.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Leicester</orgName>
								<address>
									<postCode>LE1 7RH</postCode>
									<settlement>Leicester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Venkatesh</forename><surname>Raman</surname></persName>
							<email>vraman@imsc.res.in</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Mathematical Sciences</orgName>
								<address>
									<postCode>600 113</postCode>
									<region>Chennai</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">S</forename><forename type="middle">Srinivasa</forename><surname>Rao</surname></persName>
							<email>ssrao@uwaterloo.ca</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<postCode>N2L 3G1</postCode>
									<settlement>Waterloo</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Succinct Indexable Dictionaries with Applications to Encoding k-ary Trees, Prefix Sums and Multisets *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-05-04">4 May 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">A4A6D57CB0A90B696C371D022E5D2CCD</idno>
					<idno type="arXiv">arXiv:0705.0552v1[cs.DS]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the indexable dictionary problem, which consists of storing a set S ⊆ {0, . . . , m -1} for some integer m, while supporting the operations of rank(x), which returns the number of elements in S that are less than x if x ∈ S, and -1 otherwise; and select(i) which returns the i-th smallest element in S. We give a data structure that supports both operations in O( <ref type="formula">1</ref>) time on the RAM model and requires B(n, m) + o(n) + O(lg lg m) bits to store a set of size n, where B(n, m) = lg m n is the minimum number of bits required to store any n-element subset from a universe of size m. Previous dictionaries taking this space only supported (yes/no) membership queries in O(1) time. In the cell probe model we can remove the O(lg lg m) additive term in the space bound, answering a question raised by Fich and Miltersen, and Pagh.</p><p>We present extensions and applications of our indexable dictionary data structure, including:</p><p>• an information-theoretically optimal representation of a k-ary cardinal tree that supports standard operations in constant time,</p><p>• a representation of a multiset of size n from {0, . . . , m -1} in B(n, m + n) + o(n) bits that supports (appropriate generalizations of) rank and select operations in constant time, and</p><p>• a representation of a sequence of n non-negative integers summing up to m in B(n, m + n) + o(n) bits that supports prefix sum queries in constant time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Given a set S of n distinct keys from the universe {0, . . . , m -1}, possibly the most fundamental data structuring problem that can be defined for S is the dictionary problem: to store S so that membership queries of the form "Is x in S?" can be answered quickly. In his influential paper <ref type="bibr" target="#b28">[29]</ref>, Yao considered the complexity of this problem and showed that the sorted array representation of S is the best possible for this problem, if one considers a suitably restricted class of representations. Since membership queries take Ω(lg n) time to answer using a sorted array<ref type="foot" target="#foot_0">1</ref> , a number of researchers have developed representations based on hashing that answer membership queries in constant time (see e.g. <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b23">24]</ref>).</p><p>However, one extremely useful feature present in the sorted array representation of S is that, given an index i, the i-th smallest element in S can be retrieved in constant time. Also, when the presence of an element x has been established in a sorted array, we know the rank of x, i.e., the number of elements in S that are less than x. Schemes based on hashing work by "randomly scattering" keys, and do not intrinsically support such operations. It is natural to ask whether one can represent S in a way that combines the speed of hash tables with the additional functionality of sorted arrays. We therefore consider the problem of representing S to support the following operations in constant time: rank(x, S) Given x ∈ {0, . . . , m -1}, return -1 if x ∈ S and |{y ∈ S|y &lt; x}| otherwise, and select(i, S) Given i ∈ {1, . . . , n}, return the i-th smallest element in S.</p><p>When there is no confusion, we will omit the set S from the description of these operations. We call this the indexable dictionary problem, and a representation for S where both these operations can be supported in constant time an indexable dictionary representation.</p><p>Our interest lies in succinct representations of S, whose space usage is close to the information-theoretic lower bound. Motivated by applications to very large data sets, as well as by applications to low-resource systems such as handheld and embedded computers, smart cards etc., there has been a renewal of interest in succinct representations of data <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27]</ref>. In the context of this paper, the information-theoretic lower bound is obtained by noting that as there are m n subsets of size n from {0, . . . , m -1}, one cannot represent an arbitrary set of n keys from {0, . . . , m -1} in fewer than B(n, m) = lg m n bits, and we seek representations that use space close to B(n, m). As B(n, m) = n lg(em/n) -O(lg n) -Θ(n<ref type="foot" target="#foot_1">2</ref> /m) <ref type="bibr" target="#b23">[24]</ref>, a sorted array representation of S, which takes n ⌈lg m⌉ bits, can be significantly larger than the information-theoretic lower bound. Brodnik and Munro <ref type="bibr" target="#b5">[6]</ref> were the first to give a succinct representation that supported constant-time membership queries. Pagh <ref type="bibr" target="#b23">[24]</ref> improved the space bound to B(n, m) + o(n) + O(lg lg m) bits, while continuing to support membership queries in constant time. Raman and Rao <ref type="bibr" target="#b25">[26]</ref> considered dictionaries with rank, which support constant-time rank queries and gave a representation requiring n ⌈lg m⌉ + O(lg lg m) bits of space; this is better than augmenting Pagh's data structure with n ⌈lg n⌉ bits of explicit rank information. Raman and Rao's data structure can also support select queries using n(⌈lg m⌉ + ⌈lg n⌉) + O(lg lg m) bits, but this is nearly 2n lg n bits more than necessary. All the above papers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26]</ref> assume the standard word RAM model with word size Θ(lg m) bits <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref>; unless specified otherwise this is our default model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Our results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.1">Indexable dictionaries</head><p>We give an indexable dictionary representation that requires B(n, m) + o(n) + O(lg lg m) bits to store a set of size n from {0, . . . , m -1}. Modifying this data structure, we get an indexable dictionary representation that requires B(n, m)+o(n) bits and supports operations in O(1) time in the cell probe model <ref type="bibr" target="#b28">[29]</ref> with word size Θ(lg m). The significance of this modest improvement in space usage is as follows. Since B(n, m) + o(n) ≤ n ⌈lg m⌉ for all n larger than a sufficiently large constant, this result shows that n words of ⌈lg m⌉ bits suffice to answer membership queries in constant time on a set of size n, and answers a question raised by Fich and Miltersen <ref type="bibr" target="#b11">[12]</ref> and Pagh <ref type="bibr" target="#b23">[24]</ref>. By contrast, Yao showed that if the n words must contain a permutation of S, then membership queries cannot be answered in constant time <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.2">Applications of indexable dictionaries</head><p>Using the indexable dictionaries, we obtain the following results:</p><p>• A k-ary cardinal tree is a rooted tree, each node of which has k positions labeled 0, . . . , k -1, which can contain edges to children. The space lower bound for representing a k-ary cardinal tree with n nodes is C(n, k) = lg 1 kn+1 kn+1 n <ref type="bibr" target="#b15">[16]</ref>. Note that C(n, k) = (k lg k -(k -1) lg(k -1))n -O(lg(kn)), which is close to n(lg k + lg e), as k grows. Benoit et al. <ref type="bibr" target="#b4">[5]</ref> gave a cardinal tree data structure that takes (⌈lg k⌉ + 2)n + o(n) + O(lg lg k) = C(n, k) + Ω(n) bits and answers queries asking for parent, i-th child, child with label i, degree and subtree size in constant time. We obtain an encoding for k-ary cardinal trees taking C(n, k) + o(n) + O(lg lg k) bits, in which all the above operations, except the subtree size at a node, can be supported in constant time. Both the above results on cardinal trees use the word RAM model with a word size of Θ(lg(k + n)) bits.</p><p>• Let M be a multiset of n numbers from {0, . . . , m -1}. We consider the problem of representing M to support the following operations:</p><formula xml:id="formula_0">rankm(x, M) Given x ∈ U, return -1 if x ∈ M and |{y ∈ M|y &lt; x}| otherwise,<label>and</label></formula><formula xml:id="formula_1">selectm(i, M) Given i ∈ {1, . . . , n}, return the largest element x ∈ M such that rankm(x) ≤ i -1.</formula><p>rankm and selectm are natural generalisations of rank and select to multisets. It is easy to see that B(n, m + n) is a lower bound on the number of bits needed to represent such a multiset, as there is a 1 -1 mapping between such multisets and sets of n elements from {0, . . . , m + n -1} <ref type="bibr" target="#b10">[11]</ref>. However, if we transform a multiset into a set by this mapping, then rankm and selectm do not appear to translate into rank and select operations on the transformed set. Using some additional ideas, we obtain a multiset representation that takes B(n, m + n) + o(n) + O(lg lg m) bits, and supports rankm and selectm in constant time. This result assumes a word size of Θ(lg(m + n)) bits.</p><p>Elias <ref type="bibr" target="#b10">[11]</ref> previously considered the problem of representing multisets succinctly while supporting selectm and the following generalization of rankm: fullrankm(x) Given x ∈ U, return |{y ∈ M|y &lt; x}|.</p><p>He considered the bit-probe model rather than the word RAM model, and was concerned with average-case behaviour over all possible operations. Our results on FIDs (see below) have consequences for this version of the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.3">Fully indexable dictionaries and prefix sums</head><p>We also give a subroutine that appears to be of independent interest. Given a sequence σ of m bits, define the following operations, for b ∈ {0, 1}: (a) rank b (i) -count the number of b's before the position i in σ, and (b) select b (i) -find the position of the i-th b in σ. It is shown in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> how to represent σ in m + o(m) bits and support these four queries in constant time. This data structure is a fundamental building block in a large number of succinct data structures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>One can also view σ as the characteristic vector of a subset S of n keys from U = {0, . . . , m -1}, and define a fully indexable dictionary (FID) representation of S to be one that supports the operations rank(x, S), select(i, S), rank(x, S) and select(i, S) all in constant time, where S = U \ S is the complement of the set S. It is easy to see that an FID representation is functionally equivalent to a bit-vector supporting rank 0/1 and select 0/1 . Extending a result due to Pagh <ref type="bibr" target="#b23">[24]</ref>, we give an FID representation for S that takes B(n, m)+ O((m lg lg m)/ lg m) bits. This is always at most m + o(m) bits, but it may be substantially less: for example, whenever m/ <ref type="formula">1</ref>))B(n, m) bits. We give the following application of this result:</p><formula xml:id="formula_2">√ lg m ≤ n ≤ m(1 -1/ √ lg m), the space usage is at most B(n, m) + o(n) = (1 + o(</formula><p>• We can store a multiset M of n values from {0, . . . , m -1} to support selectm (but not rankm) in constant time using B(n, m + n) + o(n) bits. Another way of stating this result is that we can represent a sequence of n non-negative integers X = x 1 , . . . , x n , such that n j=1 x j = m, so that the query sum(i, X), which returns i j=1 x j , can be answered in constant time using</p><formula xml:id="formula_3">B(n, m + n) + o(n) bits.</formula><p>The problem of representing integers compactly so that their prefix sums can be computed efficiently has been studied by a number of researchers including <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref>. Our solution is more space-efficient than all of these. The result of Grossi and Vitter [17, <ref type="bibr">Lemma 2]</ref>, which is based on Elias's ideas, is the previously most space-efficient one and requires n(⌈lg m⌉ -⌊lg n⌋ + 2) + o(n) bits to represent n non-negative integers adding up to m, where m ≥ n. In most cases, this will be Θ(n) bits more than optimal. When n and m are not powers of 2, the ceilings and floors are a source of non-optimality; for example, take m = n with m not a power of 2; Grossi and Vitter's method requires 3n + o(n) bits in the worst case, as opposed to the lower bound of B(n, 2n) = 2n -O(lg n) bits. Another source of non-optimality is that the constant 2 is not optimal; for example, take m = cn where n and m are powers of 2 and c &gt; 1. Grossi and Vitter's method requires (2 + lg c)n + o(n) bits in the worst case, which can be easily shown to be at least (2 -(1 + c) lg((1 + c)/c))n = Ω(n) bits more than optimal (the difference tends to (2 -lg e)n as c increases). On the other hand, our representation is always within o(n) bits of optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.4">Lower bounds</head><p>It is important to note that, appearances notwithstanding, some of the space bounds above may actually be much larger than the information-theoretic lower bound of B(n, m). For example, consider the space bound of B(n, m) + o(n) + O(lg lg m) bits for storing a set S of size n from {0, . . . , m -1} in an indexable dictionary representation. If n ≤ m/2, B = B(n, m) ≥ max{n, lg m} and this space bound is indeed B plus lower-order terms. However, as n gets very close to m, B can be much smaller than the o(n) term. If we only want to answer membership queries, we can assume n ≤ m/2 without loss of generality: if S has more than m/2 elements then we store its complement and invert the answers. However, in the indexable dictionary problem, it is not clear how answering rank and select queries on a set could help us to answer these queries on its complement in constant time. In fact, we note that if we could store a set S in B O (1) bits for all n and m, and support select (or rank) in constant time, then we could also support fullrank queries on S in constant time using B O (1) bits. Here fullrank(x, S) returns the rank of x in S for any x ∈ U. It is known that in general, fullrank queries cannot be answered in constant time in the RAM model (or even in the cell probe model) while using n O (1) words of (lg m) O (1) bits each <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">Corollary 3.10]</ref>. Thus, many of our space bounds are of necessity not information-theoretically optimal in some cases; one exception is the space bound for k-ary trees, which is optimal for all k ≥ 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Techniques used</head><p>The main ingredient in our indexable dictionary representation is most-significant-bit first (MSB) bucketing. The idea is to apply a trivial top-level hash function to the keys in S, which simply takes the value of the t most significant bits of a key. As we can omit the t most significant bits of all keys that "hash" to the same bucket, space savings is possible. A similar idea was used by Brodnik and Munro <ref type="bibr" target="#b5">[6]</ref> in their succinct representation of sets. A major difference between our approach and theirs is that they store explicit pointers to refer to the representation of buckets, which uses more space than necessary (and hence constrains the number of buckets). Instead, we use a succinct representation of the prefix sums of bucket sizes that not only provides the extra functionality needed for supporting rank and select, but also uses significantly less space. The related technique of quotienting <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b8">9]</ref> stores only the "quotients" of keys that are mapped to a bucket by a standard hash function (e.g. those of <ref type="bibr" target="#b12">[13]</ref>). The crucial difference is that MSB bucketing preserves enough information about the ordering of keys to allow us to maintain most of the rank information using negligible extra space.</p><p>Other ideas relevant to the indexable dictionary representation are range reduction ( <ref type="bibr" target="#b12">[13]</ref> and others), distinguishing bits ( <ref type="bibr" target="#b1">[2]</ref> and others) and techniques for compactly representing hash functions for several subsets of a common universe developed in <ref type="bibr" target="#b4">[5]</ref>. Our k-ary tree representation does not encode the tree structure explicitly, a feature shared with the representation of <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Organization of the paper</head><p>The remainder of this paper is organized as follows. In Section 2, we give some building blocks that will later be used in our main results. Extending the dictionary with rank of <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b4">5]</ref>, we first give a simple indexable dictionary that uses about 2n lg n bits more than necessary. Then we show the connection between fully indexable dictionaries and prefix sum data structures and give some simple representations for both. These are then used in Section 3, coupled with MSB bucketing, to obtain an improved result on indexable dictionaries, which reduces the space wastage to about O(n) bits.</p><p>In Section 4, we first develop a B(n, m) + O((m lg lg m)/ lg m)-bit fully indexable dictionary representation, extending a result of Pagh <ref type="bibr" target="#b23">[24]</ref>. Using this and our result from Section 3, we obtain our main result: an indexable dictionary taking B(n, m) + o(n) + O(lg lg m) bits. In Section 5, we remove the O(lg lg m) term in the space bound by moving to the cell probe model, giving a representation that takes B(n, m) + o(n) bits. Section 6 gives some applications of our succinct dictionaries to representations of multiple dictionaries, k-ary trees, multisets and prefix sums. Section 7 makes some observations about the difficulty of achieving optimal space for all values of the input parameters. Section 8 recapitulates the main results and gives some open problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section, we first establish connections between FIDs and prefix sums, and we end with simple representations of multiple indexable dictionaries and prefix sums.</p><p>In what follows, if f is a function defined from a finite set X to a finite totally ordered set Y , by ||f ||, we mean max{f (x) : x ∈ X}. We use the notation [m] to denote the set {0, 1, . . . , m -1}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Fully Indexable Dictionaries and Searchable Prefix Sums</head><p>Given a set S ⊆ U, recall that a fully indexable dictionary (FID) representation for S supports rank and select operations on both S and its complement S = U \ S in O(1) time. FIDs are essential to our data structure as they are intimately related to operations on prefix sums, as we note below.</p><p>Given a sequence X of n non-negative integers x 1 , . . . , x n such that n i=1 x i = m, the searchable prefix sum problem is to find a representation of this sequence that supports the following operations in constant time:</p><formula xml:id="formula_4">sum(i, X) Given i ∈ {1, . . . , n}, return i j=1 x j pred(x, X) Given x ∈ [m], return max{i ≤ n| i j=1 x j &lt; x}.</formula><p>We call a data structure that stores the sequence X to support the queries in constant time an (n, m)-searchable prefix sum data structure. We now make the connection between FIDs and the searchable prefix sums problem <ref type="bibr" target="#b10">[11]</ref>.</p><p>Lemma 2.1 Suppose that there is an FID representation for a given set S ⊆ U that uses f (|S|, |U|) bits. Then given a sequence X of non-negative integers x 1 , x 2 , . . . , x n , such that n i=1 x i = m there is an (n, m)-searchable prefix sum data structure for X using f (n, m + n) bits.</p><p>Proof: Consider the following m + n bit representation of the sequence X. For i = 1 to n, represent x i by x i 0s followed by a 1. Clearly this representation takes m + n bits since it has m 0s and n 1s. View this bit sequence as the characteristic vector of a set S of n elements from the universe [m + n]. Represent S as an FID using f (n, m + n) bits. It is easy to verify that pred(x, X) = select(x, S) -x + 1 and sum(i,</p><formula xml:id="formula_5">X) = select(i, S) -i + 1. (Recall that [m + n] begins with 0.) 2 Lemma 2.2 Given a set S ⊆ [m],</formula><p>there is an FID for S taking m + o(m) bits.</p><p>Proof: Consider the characteristic vector of S, which is a bit-vector of length m. It is shown in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref> how to represent this bit-vector using m + o(m) bits, to support the queries rank b (i) and select b (i) in constant time, for b ∈ {0, 1}. It is easy to verify that these operations on the characteristic vector suffice to support FID operations on S: for example, rank 1 (j) is given by rank(j, S) if the j-th bit is a 1, and by jrank(j, S) -1 otherwise. 2</p><p>The following lemma is an immediate consequence of Lemma 2.1 and Lemma 2.2:</p><p>Lemma 2.3 A sequence S of n non-negative numbers whose total sum is m can be represented using m + n + o(m + n) bits to support sum and pred operations in constant time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A Simple Indexable Dictionary</head><p>We now give a simple indexable dictionary representation for a set S ⊆ [m * ], based on perfect hashing schemes for membership <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b23">24]</ref>. These perfect hashing schemes begin with finding a universe reduction</p><formula xml:id="formula_6">function f : [m * ] → [|S| 2 ] such that f is 1 -1 on S.</formula><p>A problem with such an approach is that f requires Ω(lg lg m * ) bits to represent, which can be a significant overhead for sets which are very small but nonetheless not constant-sized. This overhead becomes significant if we need to store several sets in the data structure, as we pay the overhead repeatedly for each set. To reduce this overhead we use the idea of <ref type="bibr" target="#b4">[5]</ref>, which is to note that we do not need f to bring the universe size as far down as |S| 2 for small sets, thereby allowing the same f to be used for several (small) sets. Thus, it makes sense to talk about representing the set S, but excluding the space cost of representing a universe-reduction function. In the following lemma, which is a simplification and extension of a scheme from <ref type="bibr" target="#b4">[5]</ref>, we use this approach. Here h S is the universe-reduction function and q S is a "quotient" function, which gives the information thrown away during the universe reduction and is used to recover x given h S (x).</p><p>Lemma 2.4 Let m * , n * ≥ 1 be two given integers, and let S ⊆ [m * ] be a set of size at most n * . Suppose that we have access to two functions h S and q S , defined on [m * ], satisfying the following conditions:</p><formula xml:id="formula_7">1. h S is 1-1 on S.</formula><p>2. h S and q S can be evaluated in O(1) time, and from h S (x) and q S (x) one can uniquely reconstruct x in O(1) time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">||h</head><formula xml:id="formula_8">S || = O((n * ) 2 ) if |S| &gt; √ lg n * and ||h S || = O((lg n * ) c ) for some constant c &gt; 0 otherwise. 4. ⌈lg ||h S ||⌉ + ⌈lg ||q S ||⌉ = lg m * + O(1).</formula><p>Then we can represent S using |S|(lg m * + lg |S| + O(1)) bits and support rank and select in O(1) time. This assumes a word size of at least lg max{m * , n * } bits, and access to a pre-computed table of o(n * ) bits and a constant of O(lg n * ) bits that depends only on ||h S ||, and that m * and n * are known to the data structure.</p><p>Proof: Let l = |S| and suppose that S contains the elements</p><formula xml:id="formula_9">x 1 &lt; x 2 &lt; . . . &lt; x l .</formula><p>If l ≤ √ lg n * then we write down h S (x 1 ), . . . , h S (x l ) in fields of b = ⌈lg ||h S ||⌉ bits each, followed by q S (x 1 ), . . . , q S (x l ) in fields of ⌈lg ||q S ||⌉ bits each. This requires |S|(lg m * + O(1)) bits. To compute rank(x) we calculate h S (x) and look for a match in h S (x 1 ), . . . , h S (x l ). This can be done in O(1) time using standard techniques <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b2">3]</ref>, provided we have available the integer constant k that contains 1s in bit positions 0, b, 2b, . . . , b • ⌊(lg n * )/b⌋, as well as tables that enable us to compute, for every integer x of lg n * or fewer bits, the index of the most significant bit that is set to 1 (or, equivalently to compute ⌊lg x⌋). If we are unable to find an index i such that h S (x) = h S (x i ), we return -1, otherwise we verify whether q S (x) = q S (x i ). If so, return i -1, otherwise return -1. To compute select(i), reconstruct x i from the values h S (x i ) and q S (x i ) and return it. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b17">18]</ref>, there exists such a function f that can be evaluated in O(1) time and that can be represented in O(l + lg lg ||h S ||) = O(l + lg lg n * ) = O(l) bits. We also store two tables of size l. In the first table R, for 1 ≤ i ≤ l, we store the value i in the location f (h S (x i )) using a total of l ⌈lg l⌉ bits. In the second table X, we store the elements of S in sorted order. Now to answer rank(x), we calculate j = R[f (h S (x))] and check if x = x j : if so, then rank(x) is j -1, and is -1 otherwise. Supporting select is trivial since we have stored the x i s in sorted order in X. 2</p><formula xml:id="formula_10">If l &gt; √ lg n * , then let S ′ = {h S (x)|x ∈ S}. We create a minimal perfect hash function f : [||h S ||] → [l] that is 1 -1 on S ′ . As shown in</formula><p>The following lemma from <ref type="bibr" target="#b4">[5]</ref> gives the space savings obtained by combining universe reduction functions for different sets: </p><formula xml:id="formula_11">≤ i 1 &lt; i 2 &lt; . . . &lt; i s &lt; n * be a sequence of integers. Let S i 1 , S i 2 , . . . , S is be subsets of [m * ] such that s j=1 |S i j | ≤ n * .</formula><p>Then there exist functions h S i j and q S i j for j = 1, . . . , s that satisfy the conditions of Lemma 2.4, which can be represented in o(n * ) + O(lg lg m * ) bits in such a way that given i j we can access h S i j and q S i j in constant time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Saving n lg n bits using MSB bucketing</head><p>In this section, we first give a representation that takes about n⌈lg m⌉ bits to represent a set of size n from a universe of size m, and supports rank and select operations in O(1) time (Theorem 3.1). We then use this representation to store multiple independent (but not necessarily disjoint) dictionaries efficiently (Lemma 3.1). Theorem 3.1 There is an indexable dictionary for a set S ⊆ [m], |S| = n, that uses at most n ⌈lg m⌉ + o(n) + O(lg lg m) bits of space.</p><p>Proof: Our construction algorithm partitions S using MSB bucketing, recursing on large partitions. The base case of the recursion is handled using Lemma 2.4. We get an overall space bound of n ⌈lg m⌉ assuming the hypothesis of Lemma 2.4 for each application of this lemma. We then show how to support rank and select in O(1) time. Finally, we sketch how to use Lemma 2.5 to represent all functions used in applications of Lemma 2.4 using o(n) + O(lg lg m) bits.</p><p>Let t = ⌈lg m⌉-⌈lg n⌉, and let c and d be two constants whose values are to be determined later. If n ≤ d, then we store the elements of S explicitly, using n ⌈lg m⌉ bits, and we are done.</p><p>Otherwise, if n &gt; d, we partition the elements of S according to their top ⌈lg n⌉ bits. This partitions S into y = 2 ⌈lg n⌉ ≤ 2n sets denoted by S 0 , . . . , S y-1 , where S i consists of the last t bits of all keys in S whose most significant ⌈lg n⌉ bits have value i, for i ∈ [y]. We store a representation of the sizes of these y sets which takes n + y + o(n + y) ≤ 3n + o(n) &lt; 4n bits (for sufficiently large n) using Lemma 2.3 and pad this out to 4n bits. The representation of S is obtained by concatenating these 4n bits with the representations of each of the S i 's, for i ∈ [y].</p><p>The representation of S i , for i ∈ [y], is obtained as follows. Let n i = |S i |. If n i ≤ d, we write down the elements of S i using n i t bits, and pad this out to n i (t+ 4 + c) bits. Otherwise, we again partition the elements of S i into z = 2 ⌈lg n i ⌉ sets according to their top ⌈lg n i ⌉ bits, denoted as T 0 i , . . . , T z-1 i (see Fig. <ref type="figure" target="#fig_0">1</ref>). We store a representation of the sizes of these z sets and pad this out to 4n i bits. Again, the representation of S i is the concatenation of these 4n i bits with the representations of each of the T j i s, for j ∈ [z]. The representation of T j i , for j ∈ [z], is obtained as follows. If |T j i | ≤ d, then we write down its elements using |T j i |(t -⌈lg n i ⌉) bits, and pad this out to |T j i |(t + c) bits. Otherwise, we store it using the representation of Lemma 2.4 (with m * = 2 t-⌈lg n i ⌉ and n * = n), padding this out to |T j i |(t + c) bits if necessary. (Note that the representation of T j i using Lemma 2.4 takes</p><formula xml:id="formula_12">|T j i |(t -⌈lg n i ⌉ + lg |T j i | + O(1)</formula><p>) bits. Thus it is enough to choose c to be equal to the constant in the O(1) term to guarantee that this is at most</p><formula xml:id="formula_13">|T j i |(t + c) bits.) When S i is partitioned, its representation takes 4n i + z-1 j=0 |T j i |(t + c) = 4n i + n i (t + c) = n i (t + 4 + c) bits.</formula><p>Thus the representation of S i takes n i (t + 4 + c) in either case. Hence the length of the representation of S, when it is partitioned, is 4n + y-1 i=0 n i (t + 4 + c) = 4n + n(t + 4 + c) = n(t + 8 + c) bits. Thus, in either case, S takes n(t + 8 + c) bits. This is at most n ⌈lg m⌉ bits, for sufficiently large d (since t = ⌈lg m⌉ -⌈lg n⌉).</p><p>We now describe how the computation of rank proceeds; select works in a similar way. If n ≤ d, we apply the trivial algorithm and return. Otherwise, we consider the first 4n bits of the representation of S, which contains the representation of the sequence σ of the sizes of the buckets S i , i ∈ [y]. We extract the the top ⌈lg n⌉ bits of the current key<ref type="foot" target="#foot_2">2</ref> ; suppose that these bits have value i. Using Lemma 2.3, we calculate ρ = sum(i -1, σ) and ρ ′ = sum(i, σ) in O(1) time; note that ρ ′ -ρ is the size of the set S i to which the current key belongs. The start of the representation of S i is also easy to compute: it starts 4n + ρ(t + 4 + c) bits from the start of the representation of S. We then remove the top ⌈lg |T |⌉ bits from the query key, add the rank of the resulting key in the set S i to ρ and return. Thus the problem reduces to finding the rank of a key in some set S i .</p><p>If |S i | ≤ d, then we apply the trivial algorithm to find the rank of a key in S i . Otherwise, we apply a similar algorithm as above to reduce the problem to finding the rank of a key in some set T j i . Again, if |T j i | ≤ d, then we apply the trivial algorithm to find the rank. Otherwise, since T j i is stored using the representation of Lemma 2.4, we can support rank in constant time. The overall computation is clearly constant-time.</p><p>It is easily verified that n * = n is an appropriate choice for all applications of Lemma 2.4 above. We now verify that the additional space required (in terms of the pre-computed table and constants) is not excessive. Firstly, the pre-computed table is of size o(n * ) = o(n) bits and is common to all applications of Lemma 2.4. At most O(lg n) constants are required, one for each possible value of b = ⌈lg ||h S ||⌉, which require negligible space.</p><p>We now discuss the use of Lemma 2.5 to represent the functions for all the base-case sets. The lemma requires that there is a numbering of the sets using integers from [n], but we can simply take the number of a set to be the sums of the cardinalities of the sets whose indices are less than its own index. This information must be computed anyway during rank and select. Finally, the space required for representing the functions is o(n) + O(lg lg m) bits. This completes the proof of Theorem 3.1. 2 The following lemma is an easy extension of Theorem 3.1. Lemma 3.1 Let S 1 , S 2 , . . . , S s all contained in [m] be given sets with S i containing n i elements, such that s i=1 n i = n. Then this collection of sets can be represented using n ⌈lg m⌉ + o(n) + O(lg lg m) bits where the operations rank(x, S i ) and select(j, S i ) can be supported in constant time for any x ∈ [m], 1 ≤ j ≤ n and 1 ≤ i ≤ s. This requires that we have access to a constant-time oracle which returns the prefix sums of the n i values.</p><p>Proof: If we apply Theorem 3.1 directly to each set S i we get a representation taking</p><formula xml:id="formula_14">s i=1 (n i ⌈lg m⌉ + o(n i ) + O(lg lg m)) = n ⌈lg m⌉ + o(n) + O(</formula><p>s lg lg m) bits, that supports rank and select on each set in O(1) time. The beginning of the representation of each set can be calculated using the oracle supporting the prefix sum queries in constant time. To get the claimed space bound, we apply Theorem 3.1 to represent each S i , but with the modification that Lemma 2.5 is used only once across all applications of Theorem 3.1. The only change this causes is that we need a global numbering (using indices bounded by n) of all base-case sets created when applying Theorem 3.1 to the S i 's. Recall that when applying Theorem 3.1 to a particular set S i , we give each base-case set that is created a 'local' number bounded by n i . Thus, an appropriate global number for a base-level set created when applying Theorem 3.1 to S i is just its local number plus i-1 j=1 n j . This gives the claimed bound. 2</p><p>4 Obtaining a sublinear lower-order term</p><p>In this section, we develop the main result of the paper, namely, a representation for an indexable dictionary taking B(n, m) + o(n) + O(lg lg m) bits of space. We begin by observing that the bound of Theorem 3.1 is better than claimed: it is actually B(n, m) + O(n + lg lg m) bits. The constant factor in the O(n) term can be improved by means of one more level of MSB bucketing, as follows. We place the keys into 2 ⌊lg n⌋ buckets based upon the first ⌊lg n⌋ bits of each element. We represent the sizes of these buckets using at most 2n + o(n) bits via Lemma 2.3. This partitions the given set into multiple (up to n) sets which contain keys of ⌈lg m⌉ -⌊lg n⌋ bits each; the collection of sets is then represented using the data structure of Lemma 3.1. The resulting dictionary takes at most n(⌈lg m⌉ -⌊lg n⌋ + 2) + o(n) + O(lg lg m) bits and supports rank and select in constant time.</p><p>Recalling the discussion on representing prefix sums in the introduction, this bound is also non-optimal by Θ(n) bits in many cases. In addition to redundancy caused when m and n are not powers of 2, the constant 2 is not optimal. For example, when m = cn for some constant c &gt; 2, the disparity in this case is (2 -c lg(c/(c -1)))n bits, which tends again to about (2 -lg e)n bits for large c. To bring the linear term of the space bound closer to optimal, we place the keys into Θ(n √ lg n) buckets; this will also enable us to 'remove' the ceilings and floors in the bound. However, using a super-linear number of buckets uses too much space if we use Lemma 2.3 to represent their sizes. Hence, we now develop a much more space-efficient alternative to Lemma 2.3, by giving more space-efficient FIDs. In particular, we show the following lemma which is an extension of [24, Proposition 4.3]. Proof: Take u = 1  2 lg m and divide the universe [m] into p = ⌈m/u⌉ blocks of u numbers each, with the i-th block U i = {(i -1)u, . . . , iu -1}, for 1 ≤ i ≤ p -1, and U p = {(p -1)u, . . . , m-1}. Let S i = S∩U i and n i = |S i |. Clearly, we can view S i as a subset of [u], which we now do for convenience. The set S i is represented implicitly by a string of B(n i , u) bits by storing an index into a table containing the characteristic bit vectors of all possible subsets of size n i from a universe of size u. S is represented by concatenating the representations of the S i 's; the length of this representation of S is at most B(n, m) + O(m/ lg m) bits, as shown in <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fully Indexable Dictionaries for Dense Sets</head><p>To enable fast access to the representations of the S i s, we store two arrays of size p. The first array A stores the numbers n i in equal-sized fields of ⌈lg u⌉ bits each. The second array B stores the quantities B(n i , u); since B(n i , u) ≤ u these numbers can also be stored in equal sized fields of ⌈lg u⌉ bits each. This requires O(m lg lg m/ lg m) bits of space. We also store the prefix sums of the two arrays, as described in [24, Proposition 4.2] or <ref type="bibr" target="#b27">[28]</ref>, in O(m lg lg m/ lg m) bits, such that the i-th prefix sum is calculated in O(1) time. We also store precomputed tables to support rank and select queries on an arbitrary set S i given its size and its implicit representation. These tables require O(m 1-ǫ ) bits of space for some fixed positive constant ǫ &lt; 1.</p><p>To find rank(x) we proceed as in <ref type="bibr" target="#b23">[24]</ref>: first compute i = ⌊x/u⌋, find the number of elements in S 0 ∪ . . . ∪ S i-1 using the partial sum data structure for the array A, index into the string for S to get the representation of S i using the partial sum data structure for the array B, and find the rank of x within the set S i using a table lookup.</p><p>To support select we do the following. We let v = ⌊(lg p) 2 ⌋ and q = ⌊n/v⌋. We store an array C of size q + 2 such that C[0] = 0, C[q + 1] = p, and for j = 1, . . . , q, C[j] stores the index l ≤ p such that Σ l-1 i=1 n i &lt; jv ≤ Σ l i=1 n i . The array C takes O(n/ lg p) = O(n/ lg m) bits and allows select(jv) for j = 1, . . . , q to be answered in O(1) time, as follows. Letting k = C[j], we use the partial sums of B to extract the representation of S k , use the partial sums of A to calculate s = k-1 i=1 n i , and use table lookup to return the (jv -s)-th element from S k as the final answer.</p><p>To support select for arbitrary positions, we follow the ideas of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>. For i = 1, . . . , q+1, we define the i-th segment as ∪</p><formula xml:id="formula_15">C[i]</formula><p>j=C[i-1]+1 U j ; i.e., the part of the universe that lies between two successive indices from C. As v &gt; u for sufficiently large m, C[i] &gt; C[i -1] for all 1 ≤ i ≤ q, and all segments (except perhaps the last) are nonempty. We call a segment dense if its size is at most (lg p) 4 and sparse otherwise.</p><p>For each sparse segment, we explicitly list (in sorted order) the elements of S that lie in that segment. The space required to represent the elements of S that lie in a sparse segment is therefore O((lg p) 2 • lg m), but since there are at most m/(lg p) 4 sparse segments, this adds up to O(m/ lg m) bits overall. For a dense segment, we construct a complete tree with branching factor √ lg p , whose leaves are the blocks that constitute this segment. Since the number of leaves is O((lg p) 3 ), the depth of this tree is constant. At each node of this tree, we store an array containing the number of elements of S in each of its child subtrees. If the tree for a dense segment has k leaves, the space usage for this tree is O(k lg lg p) bits. As segments are disjoint and the total number of blocks is O(m/ lg m), this adds up to O(m lg lg m/ lg m) bits overall. We store explicit pointers to the beginning of the representation of each segment, which takes O(m/ lg m) bits as there are only O(m/(lg m) 2 ) segments.</p><p>The representations of all sparse segments are stored consecutively, as are the representations of all dense segments. A bit-sequence of length q + 1, where the i-th bit of the sequence is 1 if the i-th segment is sparse and 0 otherwise, is used to distinguish between the two cases; this bit sequence is stored as a FID using Lemma 2.2. Using rank operations on this FID, we can access the representation of the i-th segment, be it sparse or dense.</p><p>To compute select(i) we first identify the segment in which the i-th element can be found. Letting k 1 = C[⌊i/v⌋], by inspecting the prefix sums of A at positions k 1 and k 1 + 1 one can determine whether the i-th element belongs to the segment ending at k 1 or the one beginning at k 1 + 1. Suppose it belongs to the segment σ. Using the prefix sums of A, we determine the rank of the element to be selected in σ. If σ is sparse we read the required element directly from a sorted array. Otherwise, if σ is dense, we start at the root of the tree corresponding to σ and do a predecessor search among the numbers stored in the array stored at that node to find the subtree to which the required element belongs. This can be done in constant time via table lookup using tables of negligible size, as the array at each node takes O( √ lg p lg lg p) = o(lg m) bits. Thus, in constant time we reach a leaf that corresponds to some block S j which is known to contain the element sought. We find the number of elements s in S 0 ∪ . . . ∪ S j-1 using the partial sum data structure for the array A, index into the string for S to get the representation of S j using the prefix sum data structure for the array B, and find the position l of the (i -s)-th element in the representation of S i using a table lookup. Now we consider supporting rank and select operations on S. Again letting Si = S∩U i and ni = | Si |, we observe that ni = u-n i , and so the prefix sums of A suffice to answer prefix sum queries on the ni s. Likewise, the implicit representation of S i is also an implicit representation of Si and the concatenated representations of the S i s is also an implicit representation of S that takes only B(n, m) + O(m/ lg m) bits, from which the representation of a single Si can be retrieved in O(1) time using the array B. Thus, answering rank queries on S requires no additional information except new tables (of negligible size) for performing rank and select on the implicit representations of the Si s.</p><p>To answer select queries on S, we create an array C which is analogous to the array C, and which partitions the universe anew into segments. Selecting elements from S in these segments is done as before, with trees for dense segments and sorted arrays for sparse segments. This requires O(m lg lg m/ lg m) additional auxiliary space.</p><p>2 Remark: By replacing the implicit representations of the S i 's with the characteristic vector of set S, we get a representation of a bit-vector of length m that takes m+ O(m lg lg m/ lg m) bits and supports rank b and select b queries, for b ∈ {0, 1} (defined in Section 1.1), in constant time. This improves the lower-order term in space of the earlier known data structures <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> from O(m/ lg lg m) to O(m lg lg m/ lg m).</p><p>2 As an immediate consequence of Lemma 4.1 we get: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimal Bucketing for Sparse Sets</head><p>In this section we prove our main result. A key idea will be to use MSB bucketing to place keys into ω(n) buckets, and the following proposition will be used to bound the increase in space usage: √ lg n, we choose an integer l &gt; 0 such that n √ lg n ≤ ⌊m/2 l ⌋ &lt; 2n √ lg n. We now group the keys based upon the mapping g(x) = ⌊x/2 l ⌋. Let r = ⌊(m-1)/2 l ⌋. We "partition" S into sets B i , for i = 0, . . . , r, where </p><formula xml:id="formula_16">B i = {x mod 2 l | x ∈ S and g(x) = i}. Let b i = |B i |, for i = 0, . . . ,</formula><formula xml:id="formula_17">+ n + 1) -B(n, r) = O(n 2 /r + lg n) = o(n) as r = Θ(n √ lg n).</formula><p>Thus, the space usage is B(n, r) + o(n) bits. The overall representation is the following. First we represent B top as above. Then we represent each of the B i 's using the data structure of Lemma 3.1. The total space used will be nl + B(n, r)</p><formula xml:id="formula_18">+ o(n) + O(lg lg m) bits. Note that B(n, r) = n lg(er/n) + o(n) as r = Θ(n √ lg n), and so nl + B(n, r) = nl + n lg(me/(2 l n)) + o(n) = B(n, m) + o(n).</formula><p>Thus, the overall space bound is as claimed. The computations of rank and select proceed essentially as in Theorem 3.1, except that we use Corollary 4.2, instead of Lemma 2.3, to represent B top . 2 5 An indexable dictionary in the cell probe model</p><p>In this section we give an indexable dictionary representation for a set S of size n from a universe of size m that uses B(n, m) + o(n) bits of space in the cell probe model <ref type="bibr" target="#b28">[29]</ref>. Recall that in this model, time is measured as just the number of words (cells) accessed during an operation. All other computations are free. We first prove a lemma which is analogous to Lemma 2.4, but which does not assume access to the functions h S and q S . Lemma 5.1 There is an indexable dictionary for a set S ⊆ [m] of size n that uses n(lg m + lg n + O(1)) bits in the cell probe model.</p><p>Proof: Let x 1 &lt; x 2 &lt; . . . &lt; x n be the elements of S.</p><p>If n ≥ √ lg m, then we first store the given set S in an array A in increasing order, which takes n lg m + O(n) bits of space. As in Lemma 2.4, we find a minimal perfect hash function f for S and store it using</p><formula xml:id="formula_19">O(n + lg lg m) = O(n) bits (since n ≥ √ lg m). We then store a table T with T [f (x i )] = i. This requires n lg n + O(n) bits.</formula><p>To answer rank(x), we calculate j = T [f (x)] and check if x = x j ; if so we return j -1, otherwise return -1. Supporting select is straightforward, as we store the elements in sorted order in A.</p><formula xml:id="formula_20">Otherwise, if n &lt; √ lg m, let s = lg m n 2</formula><p>and r = ⌈(lg m)/s⌉, and note that r = O(n 2 ). We divide the ⌈lg m⌉-bit representation of each x ∈ S into r contiguous pieces, where each piece has size exactly s bits, except for one piece (consisting, say, of the most significant bits of x) which has size s ′ bits, 1 ≤ s ′ ≤ s. We number the parts 0, . . . , r -1 with 0 being the most significant. Since n &lt; √ lg m, s ≥ 1, and this is possible. Then there exists a set R ⊆ [r], |R| = n, such that if we consider only the bits in the parts that belong to R, all keys in S are still distinct <ref type="bibr" target="#b1">[2]</ref>. Let h(x, R) be the number obtained by extracting the bits in x's representation from parts that belong to R, and concatenating them from most significant to least significant. Then for any distinct x, y ∈ S, h(x, R) = h(y, R). Similarly let q(x, R) be the number obtained by extracting the bits in x's representation from parts that do not belong to R, and concatenating them from most significant to least significant. <ref type="foot" target="#foot_3">3</ref> The set S is represented as follows.</p><p>First, we store an implicit representation of R; this takes lg r n = n lg n + O(n) bits. Then, we store the sequences h(x 1 , R), h(x 2 , R), . . . , h(x n , R) and q(x 1 , R), q(x 2 , R), . . . , q(x n , R) in that order. Clearly, this representation takes n lg m + n lg n + O(n) bits.</p><p>To answer rank(x), we read R first; as n lg n = o(lg m) this can be done in O(1) time. Then we compute h(x, R) in O(1) time. We then read h(x 1 , R), . . . , h(x n , R); since h(x i , R) is O((lg m)/n) bits long, all these values can be read in O(1) time. We then find an i such that h(x i , R) = h(x, R); if such an i exists, we verify the match by reading q(x i , R) and comparing it with q(x, R), and return i -1 or -1 as appropriate. If such an i does not exist then x ∈ S. It is easy to see that select can also be supported in constant time using this representation.</p><p>2 Using the representation of Lemma 5.1 instead of Lemma 2.4 for representing the sets at the bottom level in the proof of Theorem 3.1, we get an indexable dictionary data structure that takes n ⌈lg m⌉ + o(n) bits. One can use this data structure to get a result similar to Lemma 3.1, but without the additive O(lg lg m) term in the space complexity. Thus we have: Lemma 5.2 Let S 1 , S 2 , . . . , S s all contained in [m] be given sets with S i containing n i elements, such that s i=1 n i = n. Then this collection of sets can be represented using n ⌈lg m⌉ + o(n) bits where the operations rank(x, S i ) and select(j, S i ) can be supported in constant time in the cell probe model, for any x ∈ [m], 1 ≤ j ≤ n and 1 ≤ i ≤ s. This requires that we have access to a constant-time oracle which returns the prefix sums of the n i values.</p><p>Using Lemma 5.2 in place of Lemma 3.1 in Theorem 4.1, we get the following result for the cell probe model: Theorem 5.1 There is an indexable dictionary for a set S ⊆ [m] of size n using B(n, m) + o(n) bits in the cell probe model.</p><p>As an immediate corollary we get: Corollary 5.1 There is an indexable dictionary for a set S ⊆ [m] of size n using at most n ⌈lg m⌉ bits in the cell probe model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Extensions and applications</head><p>In this section, we give some extensions and applications of our succinct indexable dictionary (Theorem 4.1) as well as our fully indexable dictionary for dense sets (Corollary 4.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Multiple Indexable Dictionaries</head><p>Here, using our succinct indexable dictionary, we will give a better representation for multiple indexable dictionaries, improving on Lemma 3.1.</p><p>Let S 0 , S 1 , . . . , S s-1 all contained in [m] be a given sequence of dictionaries with S i containing n i elements, such that s-1 i=0 n i = n. Note that the representation in Lemma 3.1 of these multiple dictionaries requires an oracle to specify the starting point of each dictionary in the sequence. The representation we develop here does not make use of this assumption, but instead requires that s = O(n). Define the set S as follows:</p><formula xml:id="formula_21">S = { i, j : i ∈ [s], j ∈ [m] and j ∈ S i }.</formula><p>We map the pairs i, j , i ∈ [s], j ∈ [m] to integers in the range [ms] using the obvious mapping i, j → i • m + j. We represent the n-element set S using our indexable dictionary representation of Theorem 4.1, which takes B(n, ms) + o(n) + O(lg lg ms) bits. As any nelement subset of [ms] corresponds to a unique sequence of s sets (using the inverse of the above mapping), the first term B(n, ms) is the minimum number of bits required to represent such a sequence of multiple dictionaries. Now to support the multiple dictionary operations rank(x, S i ) and select(j, S i ), we need to find the rank of i, 0 in S even if i, 0 ∈ S. We can do this by a more detailed inspection of the proof of Theorem 4.1, and potentially modifying S slightly.</p><p>If ms ≤ 4n √ lg n, then the set S is dense and so this follows from Lemma 4.1. If ms &gt; 4n</p><p>√ lg n then we alter m to a new and carefully-chosen value m ′ , and redefine S with the new value of m ′ ; more precisely the pairs in S stay the same, but we change the mapping that takes pairs to integers as i, j → i • m ′ + j . By doing this, we ensure that no bucket at the top level of Theorem 4.1 contains elements of the form x, y and x ′ , y ′ for x = x ′ (i.e., all elements in a bucket have the same first co-ordinate). Thus, answering rank queries for x, 0 only requires summing up the sizes of a number of top-level buckets, which is supported by the top level representation. We now discuss the choice of m ′ . Recall that if we apply Theorem 4.1 directly to S, we would choose an integer l such that n √ lg n ≤ ⌊ms/2 l ⌋ &lt; 2n √ lg n and place x in the bucket ⌊x/2 l ⌋. Let l be this integer, and let m ′ = 2 l • ⌈m/2 l ⌉, i.e., round the value of m to the next higher multiple of 2 l . Now it is easy to verify that ⌊(x • m ′ + y)/2 l ⌋ = ⌊(x ′ • m ′ + y ′ )/2 l ⌋ for x = x ′ , and thus keys belonging to distinct dictionaries are mapped to different buckets.</p><p>However, this increases the universe size to m ′ s from ms. Due to this increase, a direct application of Theorem 4.1 may result in the elements being bucketed according to the mapping x → ⌊x/2 l ′ ⌋, for some l ′ ≥ l. This issue is most easily dealt with by noting that as m ′ &lt; m + 2 l , m ′ s &lt; ms(1 + 2 l /m) = ms(1 + Θ(s/(n √ lg n))) = ms(1 + O(1/ √ lg n)) (recall that s = O(n) by assumption). This in particular means that, for n larger than some constant, m ′ s &lt; 2ms, and so retaining the mapping x → ⌊x/2 l ⌋ in the proof of Theorem 4.1 gives at most 4n √ lg n buckets at the top level, which is immaterial. More importantly, since m ′ s = ms(1 + O(1/ √ lg n)), the increase in the space is only in the lower-order terms by Proposition 4.1. With this additional power, we now support the multiple dictionary operations as follows:</p><p>• To find the size of the set S i , we do the following. Find the rank of i + 1, 0 and the rank of i, 0 . The difference gives the size of the set S i .</p><p>• To perform select(i, S j ), find the rank r of j, 0 and then do select(r + i) in S. The second coordinate of the element returned by the select operation is the value of the i-th smallest element of S j .</p><p>• To find rank(x, S j ), find and subtract the rank of j, 0 from rank( j, x ). Return the result if rank( j, x ) ≥ 0 and return -1 otherwise.</p><p>Thus we have: Theorem 6.1 Let S 0 , S 1 , . . . , S s-1 all contained in [m] be a given sequence of s = O(n) sets with S i containing n i elements, such that s i=1 n i = n. Then this collection of sets can be represented using B(n, ms) + o(n) + O(lg lg m) bits and the rank(x, S i ) and select(j, S i ) operations can be supported in constant time for any x ∈ [m], i ∈ [s] and j ∈ {1, . . . , n i }. We can also find n i for each i in constant time. The first term in the space bound is the minimum number of bits required to represent such a sequence of sets.</p><p>We use Theorem 6.1 in the next section to represent k-ary trees. However, Theorem 6.1 has several direct applications. For instance, it can be used to represent an arbitrary directed graph on n nodes, where the vertices are numbered 0 to n -1 and S i ⊆ [n] represents the set of neighbors of vertex i. The space used -B(r, n 2 ) + o(r) bits, where r is the number of edges -is information-theoretically optimal, and the representation supports the union of the operations supported in O(1) time by the standard adjacency list and adjacency matrix representations, such as adjacency testing, or iteration over the list of neighbors of a given vertex. However, it also supports constant-time operations not supported in O(1) time by either of the standard representations, including random access to the i-th neighbor of a vertex and reporting the out-degree of a vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Representing k-ary Cardinal Trees</head><p>Recall that a k-ary cardinal tree is a rooted tree, each node of which has k positions labeled 0, . . . , k-1, which can contain edges to children. As noted in the introduction, the space lower bound for representing a k-ary cardinal tree with n nodes is C(n, k) = lg 1 kn+1 kn+1 n</p><p>. We now give a succinct representation of k-ary cardinal trees that supports a number of operations in O(1) time. Given a node, we can go to its child labelled j (i.e. the child reachable with an edge in the position labelled j), its i-th child or to its parent if these nodes exist. In addition, we can determine the degree of a node as well as the ordinal position of a node among its siblings in constant time. The representation uses C(n, k) + o(n) + O(lg lg k) bits of space; the space usage is therefore information-theoretically optimal up to o(n + lg k) terms, and is more space-efficient than the representation of <ref type="bibr" target="#b4">[5]</ref>. Unfortunately, we are not able to support the subtree size operation in constant time using this representation. Our representation imposes a numbering from 0 to n -1 on the nodes (the representation of <ref type="bibr" target="#b4">[5]</ref> also imposes a numbering, albeit a different one, on the nodes). Theorem 6.2 A k-ary tree on n nodes can be represented using C(n, k) + o(n) + O(lg lg k) bits where given a node of the tree, we can go to its i-th child or to its child labeled j or to its parent if they exist, all in constant time. In addition, we can determine the degree of a node as well as the ordinal position of a node among its siblings in constant time.</p><p>Proof: Consider a level-ordered left-to-right numbering of the tree nodes by numbers from {0, . . . , n -1}, starting from the root with 0. From now on, we refer to the nodes of the tree by these numbers. By a child labeled j of a node x, we mean the child y of x such that the edge (x, y) is labeled j. Let S x be the set of edge labels out of the vertex x. Then the sets S 0 , . . . , S n-1 form a sequence of n sets of total size n -1, each being a subset of <ref type="bibr">[k]</ref>.</p><p>Representing these multiple dictionaries using Theorem 6.1, we get a representation for the k-ary tree using at most B(n-1, kn)+o(n)+O(lg lg(kn)) bits. Since kn</p><formula xml:id="formula_22">n-1 = n kn+1 kn+1 n , B(n -1, kn) + o(n) + O(lg lg(kn)) = B(n, kn + 1) -lg(kn + 1) + o(n) + O(lg lg kn) = C(n, k) + o(n) + O(</formula><p>lg lg k) bits. By Theorem 6.1, we can support the degree of a node x, the i-th child of a node x, and the ordinal position (the local rank) of the child labeled j, if exists, of a node x, all in constant time. However, the basic navigational operations of going to a child or to the parent are not supported. To support these, we re-examine the proof of Theorem 6.1. Note that in applying Theorem 6.1 to represent our tree, the following set S is stored in an indexable dictionary:</p><formula xml:id="formula_23">S = { x, j : x ∈ [n], j ∈ [k]</formula><p>and ∃ an edge labeled j out of node x}.</p><p>The representation supports rank( x, j , S) and select( x, j , S) in O(1) time. It is easy to verify that:</p><p>• rank( x, j , S)+1 gives the label of the child labeled j of node x, if it exists, and returns 0 otherwise.</p><p>• The first component of select(i, S) is the parent of the node i. I.e., if the i-th element in S is x, j , then x is the parent of the node i, for i &gt; 0. We also consider a generalization of the rankm operation: fullrankm(x) Given x ∈ U, return |{y ∈ M|y &lt; x}|.</p><p>There is an intimate connection between FIDs and multisets similar to that in Lemma 2.1 as shown below. Lemma 6.1 Suppose there is an FID representation for any given set T ⊆ U using f (|T |, |U|) bits of space. Then given a multiset M of n elements from the universe [m], there is a data structure to represent M using f (n, m + n) bits of space that supports fullrankm and selectm operations in constant time.</p><p>Lemma 7.4 Given a sequence X = x 1 , . . . , x n of non-negative integers adding up to m, one cannot store this sequence in (B(n, m + n)) O(1) bits of space for all m, n and support the sum query on this sequence in O(1) time in the cell probe model with word size (lg(m + n)) O(1) bits.</p><p>Proof: Suppose that the statement of the lemma is false. Then given S = {s 1 , . . . , s n * } ⊆ [m * ] where s 1 &lt; s 2 &lt; . . . &lt; s n * we could answer fullrank queries on S in O(1) time using (n * ) O (1) words of space as follows, contradicting Lemma 7.1. Create a sequence X which consists of s 1 0s followed by a 1, and for i = 2 to n, s i -s i-1 -1 0s followed by a 1 and finally m * -s n * -1 0s followed by a 1. This is a sequence of n = m * + 1 non-negative integers adding to m = n * . We store this sequence using (B(n, m + n)) O (1) bits, but since B(n, m + n) = B(m, m + n) = B(n * , m * + n * + 1) ≤ B(n * , 2m * + 1), the space usage is (n * ) O (1)  words. It is easy to verify that fullrank(j, S) = sum(j, X). 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We have given a static data structure for storing an n element subset of an m element universe, that takes B(n, m) + o(n) + O(lg lg m) bits of space and supports rank and select operations in constant time (an indexable dictionary) on the RAM model of computation. B(n, m) is the information theoretically optimal number of bits needed to store a subset of size n from an m-element universe. By modifying our indexable dictionary for the RAM model, we obtained an indexable dictionary representation that uses B(n, m) + o(n) bits in the cell probe model. This, in particular, implies that n words (of size ⌈lg m⌉ bits) are sufficient to represent n elements from an m element universe and answer membership queries in O(1) time on the cell probe model, answering a question raised by Fich and Miltersen <ref type="bibr" target="#b11">[12]</ref> and Pagh <ref type="bibr" target="#b23">[24]</ref>. Using the indexable dictionary representation for the RAM model, we have developed improved succinct representations for a number of objects. We have shown that a k-ary tree on n nodes can be represented using C(n, k) + o(n) + O(lg lg k) bits of space and support all the navigational operations, except the subtree size of a given node, in constant time. Here C(n, k) is the information-theoretically optimum number of bits required to represent a k-ary tree on n nodes. We also developed a succinct representation for an indexable multiset of n elements from an m element universe using B(n, m + n) + o(n) + O(lg lg m) bits.</p><p>An important subroutine used by the indexable dictionary is a space-efficient fullyindexable dictionary (FID) which simultaneously supports rank and select on a set and its complement. This data structure, which is functionally equivalent to supporting rank 0/1 and select 0/1 on a bit-vector, occupies B(n, m) + o(m) bits and supports all operations in O(1) time on the RAM model. We gave further applications of this result, most notably, to representing a sequence of non-negative integers in information-theoretically optimal space, while supporting prefix sum queries in O(1) time.</p><p>We have focussed on space utilization and (static) query time, and have not given extensive consideration either to the time and space required for pre-processing, or to dynamizing the data structure. As regards the pre-processing time, we note that an indexable dictionary can be used to sort the input set S, so pre-processing must take at least as much time as the best algorithm for sorting integers. Assuming S is presented in sorted order, however, the main bottleneck is the creation of hash functions as required by Lemma 2.5. The hash functions can be found rapidly using randomization, yielding a linear expected time preprocessing algorithm. As regards dynamization, the work of <ref type="bibr" target="#b13">[14]</ref> gives a lower bound of Ω(lg n/ lg lg n) time for both rank and select, when S is allowed to change by insertions or deletions.</p><p>Some open problems that remain are:</p><p>1. Is there a succinct indexable dictionary taking B(n, m) + o(n) bits in the RAM model?</p><p>2. Is there a representation for k-ary trees taking C(n, k) + o(n) + O(lg lg k) bits that can also support subtree size operation besides the other navigational operations in constant time?</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two level MSB bucketing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Lemma 4 . 1</head><label>41</label><figDesc>Given a set S ⊆ [m], |S| = n, there is an FID on S that requires B(n, m) + O(m lg lg m/ lg m) bits of space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Corollary 4 . 1</head><label>41</label><figDesc>There is a fully indexable dictionary representation for a set S ⊆[m], |S| = n that uses B(n, m) + o(n) bits of space, provided that m is O(n √ lg n).The following corollary is a consequence of Corollary 4.1 and Lemma 2.1. Note that B(n, m + n) is the information theoretic minimum number of bits to represent a multiset of n elements from [m].Corollary 4.2 If m = O(n √ lg n),then a sequence S of n non-negative numbers that sum up to m can be represented using B(n, m + n) + o(n) bits to support sum and pred operations in constant time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Proposition 4 . 1</head><label>41</label><figDesc>For all integers x, y, c ≥ 0, y ≥ x, B(x, y + c) -B(x, y) = O(cx/y + lg x + x 2 /y). Proof: We begin with the estimate B(x, y) = x lg(ey/x) -O(lg x) -Θ(x 2 /y) [24, Equation 1.1]. From this it follows that B(x, y + c) -B(x, y) = O(x lg((y + c)/y) + lg x + x 2 /y) = O(cx/y + lg x + x 2 /y). 2 Now we use Corollary 4.2 to prove our main result: Theorem 4.1 There is an indexable dictionary for a set S ⊆ [m] of size n that uses at most B(n, m) + o(n) + O(lg lg m) bits. Proof: First, if m &lt; 4n √ lg n then we use Corollary 4.1, which establishes the result. If m ≥ 4n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>r. We represent the sequence B top = (b 0 , . . . , b r ) using the data structure of Corollary 4.2 taking B(n, r + n + 1) + o(n) bits, which supports sum and pred on B top in constant time. By Proposition 4.1, B(n, r</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 6. 3 Multisets</head><label>23</label><figDesc>Given a multiset M from U = [m], |M| = n, an indexable multiset representation for M must support the following two operations in constant time: rankm(x, M) Given x ∈ U, return -1 if x ∈ M and |{y ∈ M|y &lt; x}| otherwise, and selectm(i, M) Given i ∈ {1, . . . , n}, return the largest element x ∈ M such that rankm(x) ≤ i -1.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>lg x denotes log</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>x.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>Standard techniques allow us to calculate ⌈lg x⌉ in constant time<ref type="bibr" target="#b14">[15]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>It appears to be difficult to compute h(x, R) and q(x, R) in O(1) time on the RAM model.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We thank the anonymous TALG referee who helped us significantly to improve the presentation of the paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* Research supported by UK-India Science and Technology Research Fund project number 2001.04/IT and EPSRC grant GR L/92150.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Proof: Consider the m + n bit representation of M obtained as follows. For i = 0 to m -1, represent i by a 1 followed by n i 0s where n i is the number of copies of the element i present in the set M. Clearly this representation takes m + n bits since it has m 1s and n 0s.</p><p>View this bit sequence as a characteristic vector of a set T of m elements from the universe [m + n]. Represent T as an FID using f (m, m + n) = f (n, m + n) bits. It is easy to verify that fullrankm(x, M) = select(x, T ) -x + 1 and selectm(i, M) = select(i, T ) -i. (Note that [m + n] starts with element 0.) 2 The following corollary follows from Corollary 4.1 and Lemma 6.1. Corollary 6.1 Given a multiset M of n elements from the universe [m], there is a data structure to represent M and to support fullrankm and selectm operations in constant time using</p><p>We now develop an indexable multiset representation (that supports only rankm and selectm operations) taking B(n, m + n) + o(n) + O(lg lg m) bits for all n. As was alluded to in the introduction (see <ref type="bibr" target="#b10">[11]</ref>), the first term is the minimum number of bits required to store such a multiset.</p><p>If not, then we represent M as follows. First represent the set S of distinct elements present in M using the indexable dictionary data structure of Theorem 4.1 using B(n ′ , m) + o(n) + O(lg lg m) bits where n ′ ≤ n is the number of distinct elements present in M.</p><p>Then represent the rank information separately by representing each element i present in M (in increasing order) by a 1 followed by n i -1 0s where n i is the multiplicity of the element i in M. This representation is a bitstring of length n with n ′ 1's. This bitstring could be considered as a characteristic vector of a set R ⊆</p><p>Now to find rankm(x, M), first find rank(x, S). If the answer is -1, then return -1. Otherwise rankm(x, M) is select(rank(x, S)+1, R). To find selectm(i, M), let r = rank(i, R)+1 if rank(i, R) ≥ 0 and r = irank(i, R) otherwise. The value r is precisely the number of 1's up to and including i in the characteristic vector of R. Then selectm(i, M) = select(r, S).</p><p>To support both rankm(x, M) and selectm(i, M) in constant time in this way, we need a fully indexable dictionary for R.</p><p>Otherwise represent R using the FID representation of Lemma 2.2 which uses n</p><p>, by Proposition 4.1 as n is also sparse in m. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Applications of Succinct FIDs</head><p>Here we give more applications of our FID for dense sets obtained in Corollary 4.1 to represent sets, multisets and prefix sums. Proof: The proof is essentially as in the proof of Theorem 4.1 except that we store each of the B i 's as a sorted list. To perform a select(i) operation, we first perform a pred(i) at the top level prefix sum representation, to find the bucket B j in which the i-th element is present. Then a sum(j) operation at the top level representation gives the prefix sum of the first j -1 bucket sizes. Now isum(j) is the rank of the element in the bucket B j in which we are interested. Since the buckets are sorted, it is easy to find the element of appropriate rank in that bucket. 2 6.4.2 Multiset with selectm and Prefix Sums Theorem 6.5 Given a multiset M of n elements from [m], there is a representation of M that uses B(n, m + n) + o(n) bits that supports selectm operation in constant time.</p><p>Proof: Use the encoding given in the proof of Lemma 6.1 to convert the multiset M into a set T ⊆ [m + n] of size n. Represent T using the representation of Theorem 6.4 which uses B(n, m + n) + o(n) bits and supports select operation on T . From the proof of Lemma 6.1, we know that selectm(i, M) = select(i, T ) -i. The theorem follows.</p><p>2 As an immediate corollary we get: Corollary 6.2 Given a sequence X = x 1 , . . . , x n of non-negative integers such that n i=1 x i = m, the sequence can be represented using B(n, m + n) + o(n) bits to support the partial sum query sum(i, X) in constant time. The first term is the information theoretically minimum number of bits required to represent such a sequence.</p><p>Proof: Consider the multiset M of partial sum values M = { i j=1 x j : 1 ≤ i ≤ n}. As the x i s are non-negative and add up to m, M ⊆ [m]. Represent this multiset using Theorem 6.5 and observe that sum(i, X) = selectm(i, M). Also, as the mapping from X to M is invertible, the information theoretic minimum number of bits required to store the partial sum information is B(n, m + n). The result follows. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Optimality considerations</head><p>As mentioned in the introduction, some of the space bounds we show above may actually be very far from the information-theoretically optimal bound of B(n, m). Recall that, for example, in the context of storing a set of size n from [m], the information-theoretic lower bound of B(n, m) bits may be dwarfed by additive terms of o(n) bits, say when n = m -c for some constant c. We now note that this is unavoidable to some extent, and in particular that achieving a space bound even polynomial in the information-theoretic lower bound and preserving constant query time is impossible for several of the problems that we consider in this paper, namely:</p><p>• Supporting rank queries on a set of integers;</p><p>• Supporting select queries on a set of integers and</p><p>• Supporting sum queries on a sequence of non-negative integers (or equivalently, supporting selectm on a multiset of integers).</p><p>We show that the fullrank problem reduces to all of these. Given a set S of size n from U = [m], recall that fullrank(x, S) returns the rank of x in S for any x ∈ U. words of space and answer rank queries on S in O(1) time. To answer fullrank(x, S) for all x ∈ U, we first compute rank(x, S); if the value returned is not -1 we return it as the answer to fullrank, otherwise we return xrank(x, S) -1 as the answer to fullrank. 2 Proof: Suppose that the statement of the lemma is false. Then given T ⊆ [m * ], where T = {t 1 , . . . , t n * } and t 1 &lt; t 2 &lt; . . . &lt; t n * , we can answer fullrank queries on T in O(1) time using (n * ) O(1) words as follows, contradicting Lemma 7.1. We create a bit-vector by writing down t 1 0s followed by a 1, then (t 2 -t 1 ) 0s followed by a 1, and so on and finally we write (m * -t n ) 0s. This is a bit vector with n * 1s and m * 0s; we view this is as a characteristic vector of a set S of size n = n * from [m] where m = m * + n * . We store S using (B(n, m)) O(1) bits = n O (1) words and compute fullrank(x, T ) as select(x, S) -x in O(1) time. 2</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Data Structures and Algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Addison-Wesley Publishing Company</publisher>
			<pubPlace>Reading, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hash functions for priority queues</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ajtai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komlós</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="217" to="225" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sorting in linear time?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hagerup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="74" to="93" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimal bounds for the predecessor problem and related problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Beame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Fich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="72" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Representing trees of higher degree</title>
		<author>
			<persName><forename type="first">D</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="292" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Membership in constant time and almost minimum space</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brodnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1628" to="1640" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Compact Pat Trees</title>
		<author>
			<persName><forename type="first">D</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient suffix trees on secondary storage</title>
		<author>
			<persName><forename type="first">D</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="383" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compact hash tables using bidirectional linear probing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Cleary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="828" to="834" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Bonsai: A compact representation of trees. Software -Practice and Experience</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Darragh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Cleary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="277" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient storage retrieval by content and address of static files</title>
		<author>
			<persName><forename type="first">P</forename><surname>Elias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="246" to="260" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tables should be sorted (on random access machines)</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Miltersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Algorithms and Data Structures</title>
		<meeting>Workshop on Algorithms and Data Structures</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">955</biblScope>
			<biblScope unit="page" from="482" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Storing a sparse table with O(1) worst case access time</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Komlós</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Szemerédi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="544" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The cell probe complexity of dynamic data structures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Saks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 21st Annual ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="345" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Surpassing the information theoretic bound with fusion trees</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fredman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Willard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="424" to="436" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Knuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Patashnik</surname></persName>
		</author>
		<title level="m">Concrete Mathematics</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Compressed Suffix Arrays and Suffix Trees with Applications to Text Indexing and String Matching</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Vitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="378" to="407" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient minimal perfect hashing in nearly minimal space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hagerup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tholey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Symposium on Theoretical Aspects of Computer Science, volume 2010 of LNCS</title>
		<meeting>Symposium on Theoretical Aspects of Computer Science, volume 2010 of LNCS</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sorting and searching on the word RAM</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hagerup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Symposium on Theoretical Aspects of Computer Science</title>
		<meeting>Symposium on Theoretical Aspects of Computer Science</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1373</biblScope>
			<biblScope unit="page" from="366" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Succinct Static Data Structures</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jacobson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><surname>Tables</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Foundations of Software Technology &amp; Theoretical Computer Science</title>
		<meeting>Foundations of Software Technology &amp; Theoretical Computer Science</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1180</biblScope>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Succinct representation of balanced parentheses and static trees</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="762" to="776" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Space efficient suffix trees</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="222" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Low redundancy in static dictionaries with constant query time</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Decision trees and random access machines</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Logic and Algorithmic</title>
		<meeting>International Symposium on Logic and Algorithmic<address><addrLine>Zürich</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Static dictionaries supporting rank</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Algorithms and Computation, volume 1741 of LNCS</title>
		<meeting>International Symposium on Algorithms and Computation, volume 1741 of LNCS</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="18" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The spatial complexity of oblivious k-probe hash functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Siegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="775" to="786" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Storing a sparse table</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="606" to="611" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Should tables be sorted</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="615" to="628" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
