<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Artificial Intelligence Language Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">L</forename><surname>Waltz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Artificial Intelligence Language Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F593F358289726CD36D8AD614D9CD62C</idno>
					<note type="submission">July 197S Volume 21 Number 7 Received October 1976; revised Ociober 1977</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>question answering</term>
					<term>relational database</term>
					<term>natural language</term>
					<term>database front end</term>
					<term>artificial intelligence</term>
					<term>dialogue</term>
					<term>query generation</term>
					<term>information retrieval</term>
					<term>natural language programming CR Categories: 3.42</term>
					<term>3.60</term>
					<term>3.69</term>
					<term>3.74</term>
					<term>3.79</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>By typing requests in English, casual users will be able to obtain explicit answers from a large relational database of aircraft flight and maintenance data using a system called PLANES. The design and implementation of this system is described and illustrated with detailed examples of the operation of system components and examples of overall system operation. The language processing portion of the system uses a number of augmented transition networks, each of which matches phrases with a specific meaning, along with context registers (history keepers) and concept case frames; these are used for judging meaningfulness of questions, generating dialogue for clarifying partially understood questions, and resolving ellipsis and pronoun reference problems. Other system components construct a formal query for the relational database, and optimize the order of searching relations. Methods are discussed for handling vague or complex questions and for providing browsing ability. Also included are discussions of important issues in programming natural language systems for limited domains, and the relationship of this system to others.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A prime obstacle for nontechnical people who wish lo use computers has been the need to either learn a special language for communicating with the machine or communicate via an intermediary. We feel that the time is ripe for computers to be equipped with natural language systems which can be used by persons who are not extensively trained in a special computer language.</p><p>In order for such systems to be of value to a casual user, the systems must tolerate simple errors, must embody a degree of "common sense." must have a relatively large and complete vocabulary for the subject matter to be treated, must accept a wide range of grammatical constructions, must be able to deal sensibly with partly understood input, and. of course, must be capable of providing the information and computations requested by the user. Recent surveys of the state-of-the-art of natural language systems can be found in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>We are developing such a system called PLANES (for Programmed LANguage-based Enquiry System) at the University of Illinois Coordinated Science Laboratory <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr">28]</ref>. PLANES mcludes an English language front end with the ability to understand and explicitly answer user requests and to carry on clarifying dialogues with him <ref type="bibr" target="#b3">[4]</ref> as well as the ability to answer vague or poorly defmed questions. This work is being carried out using a subset of the U.S. Navy 3-M (Maintenance and Material Management) database of aircraft maintenance and flight data, although the ideas can be directly applied to other nonhierarchic record-based databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The Goals of PLANES</head><p>Our main goal is to allow a nonprogrammer to obtain information from a large database with a minimum amount of prior training or experience. A system to realize this goal <ref type="bibr" target="#b0">(1)</ref> must be able to understand to a substantial degree a user's natural language and (2) must be able to help guide and train the user to frame requests in a form that the system can understand.</p><p>We have formulated a number of subgoals which we feel are important for realizing our main goal;</p><p>(1) The system must accept a user's "natural" English input, possibly including complex syntactic constructions, abbreviations, pronoun reference and ellipsis (i.e. omission of one or more words that can be obviously understood in context); the system should not require complete grammatical sentences.</p><p>(2) The system must provide explicit answers to questions, and not merely retrieve a file which somewhere contains the answer. The system should phrase its answer in a clear manner, including units or dimensions of numerical answers and a description of the answer values. Whenever possible, graphical output is desirable.</p><p>(3) The system must be tolerant of minor errors, e.g. spelling and grammatical errors; it should suggest corrections for user approval whenever possible, and should in general be able to continue processing of the corrected request without requiring a complete retyping of the request.</p><p>(4) The system should use clarifying dialogues for several purposes: (a) To feed back its understanding of the user's request, so that the user can feel confident that the system has understood his request, (b) To ask the user pointed questions about portions of a request which it does not understand, (c) To add new words, phrases, and sentences to the system's knowledge base, (d) To provide appropriate HELP file information in the event of user errors or direct requests for help, (e) To provide information about the system's capabilities, abbreviations it knows, general contents of the database, sample queries, and other such information to help orient a new user. For an excellent discussion on the uses of dialogue, see <ref type="bibr" target="#b3">[4]</ref>.</p><p>(5) Such a system should be convenient to use: (a) It should be interactive and online, fb) It should operate rapidly. If the system responds to the user in a minute or less, he retains a level of involvement and interest in the interactive process; past a minute, interest begins to wane, resulting in boredom or impatience <ref type="bibr" target="#b2">[3]</ref>. Even one minute is too long unless the system continuously provides information about its progress as it proceeds, (c) The system should require a minimum of typing; abbreviations and ellipsis should be routinely handled, (d) While it need not answer every question, a system should answer a substantial percentage (i.e. 75-90 percent or more of a moderately experienced user's questions) without requiring complete rephrasing by the user. <ref type="bibr" target="#b5">(6)</ref> The system should be relatively easy to extend, both within its own world, and to new databases and domains of discourse. ,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Current Assessment of PLANES</head><p>This paper is a report on work in progress. In our current version of PLANES we have worked toward achieving all the subgoals above though we are still short of completely satisfying solutions for many of them. (The numbers below correspond to subgoals from the preceding section.)</p><p>(1) The system accepts a wide range of semantic and syntactic structures including relative clauses, comparatives and exception statements, and can in addition accept "pidgin English" and other nongrammatical requests. Ellipsis and several types of pronoun references are handled routinely. The system knows many abbreviations, and new ones can be added easily by a user.</p><p>(2) Answers are explicit, and graphical output is produced whenever the answer form allows it.</p><p>(3) The system corrects spelling errors and tolerates a wide range of nongrammatical requests.</p><p>(4) The system feeds back to the user a paraphrase of the formal database query it generates. It provides information about words or phrases it does not understand, and will continue to generate a query as long as any portions of a request are understood. Often this query can easily be patched and completed using the ellipsis handling mechanisms. Fairly extensive HELP files are provided, and work is underway on tutoring routines to guide a user through the formation of sample requests. HELP files can be requested directly, und certain files are also printed automatically in response to user errors or problems.</p><p>(5) Operation is fast, requiring typically less than 10 seconds total cpu time per request on a DEC System 10; between one and four seconds of this time is used by the language processing routines, and the rest by database search and answer routines. Obviously, requests requiring extensive search can take much longer. Informative intermediate results can be displayed to let a user know how processing is proceeding. Many major system features are designed to minimize typing. These include ellipsis and abbreviation handling and the handling of nongrammatical or partially understood requests and spelling correction. So far the system has been tested primarily by project members, but we expect to begin tests with Navy personnel during Fall 1977.</p><p>(6) Certain kinds of extensions, such as the addition of new idioms, words, or abbreviations, can be performed online by a user. Most other extensions must be performed by a programmer, but we have provided extensive editing tools to make modification easy within the PLANES domain. Extension to a new domain would require substantial amounts of work, though many routines could be transferred directly, and the extension would be quite straightforward (see <ref type="bibr">Section 3.4 and [28]</ref> for information on the process of writing a natural language front end).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Why Use Natural Language?</head><p>There are good reasons why natural language systems are more desirable than other possible database front ends, such as touch-panel menu-selection schemes or systems using special purpose data languages. Most important, one can phrase and verify complicated questions relatively easily with a natural language system. For example, the question described in Section 4.1. "Did any planes which had engine maintenance in May have 10 or fewer fiight hours in June?", would, to the best of our knowledge, be beyond the capabihty of any current touch-panel menu-selection system; such systems seem best at rapidly selecting specific files to display, either in their entirety or subject to simple restrictions. If one wishes to display only file elements which simultaneously satisfy several predicates or relations which require logical combinations of several files, more extensive programming is required than can be done simply by menu selection. Speeial purpose data languages can deal with, complex searches and combinations or relations, but learning such languages requires extensive training, and even then, input programs may be difficult to formulate, verify, and troubleshoot. The advantage of natural language systems in phrasing questions will become even greater when the ability to handle vague and complex }) How many flights did the A7 with tail number 003 make in January. 1973?</p><formula xml:id="formula_0">(SUM TOTFLTS) = 17,</formula><p>)) How many flights did it make in Feb. 73? (SUM TOTFLTS) = 1,</p><p>)) During April? (SUM TOTFLTS) = 8.</p><p>)) March? (SUM TOTFLTS) = 13.</p><p>)) All of 1973? (SUM TOTFLTS) = 39. Fig. <ref type="figure">3</ref>, PLANES' graphical presentation of an answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>18</head><p>]Z</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Examples of PLANES^ Operation</head><p>All examples in this section are taken from actual transcripts of PLANES' operation on questions we posed. Figure <ref type="figure">1</ref> shows the operation of the current PLANES system on a single question.</p><p>Figure <ref type="figure" target="#fig_0">2</ref> shows an extended session, with all but the question and answer suppressed. Figure <ref type="figure" target="#fig_0">2</ref> illustrates the ability of the system to handle ellipsis (i.e. information omitted which is to be understood in context).</p><p>Figure <ref type="figure">3</ref> shows PLANES' ability to provide answers in a graphical form. NORHRS stands for "Not Operationally Ready HouRS"; ACTDATE stands for "AC-Tion DATE"; 2001 is the first day of the year 1972.</p><p>Figure <ref type="figure">4</ref> shows a short dialogue. PLANES first asks for time period information necessary for performing its database search. It then detects a misspelling and suggest two plausible corrections to the user. Once the user selects the appropriate correction by typing "2," the system is able to continue processing without requiring further typing.</p><p>Figure <ref type="figure">5</ref> shows PLANES' ability to answer general questions about its contents.</p><p>Figure <ref type="figure">6</ref> gives an idea of the variety of requests PLANES can handle; examples illustrate (a) nongrammatical requests, (b) relative clauses, (e) comparatives, (d) compounds, (e) exception statements, and (f) user definitions. We have attempted to build into PLANES as complete a coverage of its domain as possible, includ-528 ing richness of vocabulary, syntactic structures (or lack of syntactic structure), and request meanings.</p><p>Further examples of PLANES" abilities are given in the sections which follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.0">The PLANES World</head><p>This section describes the general environment in which the language-understanding program operates. This environment includes the database, the user, and the user's range of queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The PLANES Database</head><p>We have obtained a database from the Navy 3-M Database for Aircraft, Mechanicsburg, PA., consisting of complete records of aircraft maintenance and flight information for 48 A7 and F4 aircraft, extending over a period of two years. Each time a plane is serviced, a record is made including such information as the time and duration of the maintenance, who performed it, what action was taken, whieh parts were used, the manufacturers of these parts, whether or not the service was scheduled or unscheduled, and so on. Records on the number of flights and the number of hours in the air are also kept for each plane. There are roughly forty different record formats (or tuples in relational database terminology <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref> whieh oecur in the database, each containing between ten and twenty attributes (fields), where each attribute draws its values from one of the 80 underlying domains, such as date of the action, type of aircraft, serial number of the aircraft, type of malfunction, component serviced, the work station performing mainte-  <ref type="formula">6</ref>) PHANTOM (7) SKYHAWK The above planes may be further specified by giving the "tail number" (i.e. BUSER, BUNO, Bureau Serial Number, ete.) along with the name of the series.</p><p>(cpu time was 2.59 seconds, real time was 5.75 seconds. nance, and so on. Our database is described in detail in <ref type="bibr">[28]</ref>.</p><p>The 48 aircraft in our database are divided into three groups: (1) 24 planes whieh crashed or sustained major damage in accidents involving mechanical failures; (2) 12 planes with bad maintenance reeords; and (3) 12 planes with good maintenance records. "Good" and "bad" reeords were judged by comparing the ratio of the number of NOR (Not Operationally Ready) hours to the number of flight hours. A high ratio represents a bad record while a low ratio corresponds to a good record. In addition, we have summaries of maintenance and flight data for all F4 and A7 aircraft for the same two-year period, so that we ean have some basis for classifying events as "normal" or "unusual."</p><p>The PLANES database contains on the order of 10" bits. This database, while quite large, represents only a fraction of the entire 3-M database, which now contains on the order of 10^^ bits (10 years' complete data on all U.S. Navy aircraft, plus summaries).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Helpful Factors in the PLANES World</head><p>A number of factors contribute to making our problem much easier to solve than the general problem of understanding unconstrained natural language. They are: (1) Lack of lexical ambiguity. Relatively few words and virtually no sentences in the PLANES world are ambiguous. Examples of the small number of ambiguous words we have been able to find a "wing" (meaning "a squadron" or "part of a plane") and "flight" (meaning "a flying event" or an adjective, as in "flight computer" or "flight director"). Virtually no words are ambiguous if syntactic information (i.e, part of speech) ean be determined. This suggests that if PLANES can fmd any interpretation at all t^or a word in a request, it is in all hkelihood the correct interpretation.</p><p>(2) Small vocabulary. Our current system has about 900 words.' We estimate that 1200 words will cover 90 percent or more of all requests made by users with at least a little prior experience with PLANES.</p><p>(3) Very few modes. PLANES is usually either answering a question from the database, attempting to help a user express his request in a form PLANES can understand, accepting a new definition, or providing HELP. There is little difficulty in determining the appropriate mode from a user's input.</p><p>(4) People do not type complex sentences. The increasing likelihood of making typing errors in lengthy requests, the increasing likelihood that long requests will baffle a program in some aspect, and general laziness all contribute to keeping input requests short and simple in construction. Malhotra <ref type="bibr" target="#b16">[17]</ref> performed an experiment in which nonprogrammers thought that they were communicating via keyboard with an intelligent program, when in fact they were interacting with another person who would respond appropriately to any input. He found that 10 simple sentence types covered 78 percent of all input requests, and that another 10 would handle all but 10 percent of the requests.</p><p>(5) Less than 100 percent answer rate is acceptable. We feel that a 90 percent answer rate without requiring the user to rephrase would be more than adequate to keep ;i visor's interest and provide a practical and useful system. We plan to lest ihis hypothesis directly.</p><p>((&gt;) We have a good idea of what polenlial users of tliKs dalabiisc would like to know, 1 he Navy has made a study <ref type="bibr" target="#b20">[20]</ref> oral! the requests made to the 3-M database during a otic month period, and the frequency with which various requests were made. We Ihus had a good idea about where lo concentrate our initial efforts, and the order in which to proceed. A summary of this study is given in <ref type="bibr">[28]</ref>,</p><p>While these factors have simplified our (ask in designing and implementing Ihe PLANES system, they of eourse also mean that we have put off solving certain problems important for our long-term goals of more general and robust language understanding systems. PLANES does not attempt to provide a simulation of human language comprehension, but rather, uses a taskoriented engineering approach, 2.3 Nof-so-Helpful Factors 1I) The system must contain a great deal of specialized knowledge. One of our major realizations has been that a small number of general rules cannot suffice to "translate" all natural English requests into database queries. Consider the sentences "Which A7 has the worst maintenance record?"^ or "Find any common factors of plane numbers 37 and 78." Clearly, the system must contain special programs to compile a "maintenance record," and special knowledge to judge its "goodness."</p><p>The system must know that if two aircraft have the same digit as the fourth element of their serial numbers, this does not constitute a "common factor," but that things like similar event sequences are important. Moreover, different users may mean different things by "maintenance record," e.g. a cost analysis, a down time summary, or a list of actions performed.</p><p>(2) Each request may be expressed in a great many different ways. Clearly, if users are encouraged to sit at a console with little or no prior training or instruction, and if the system is expected to understand enough of a user's input to keep his interest and perform useful actions from the beginning, then the system must be able to make some sense of a very large number of types of queries and a wide range of syntactic constructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.0">Operation of PLANES</head><p>The processing of a user's request is divided into four main phases: parsing, query generation, evaluation, and response (see Figure <ref type="figure">1</ref>).</p><p>(1) The first phase, parsing, is aecomphshed by matching the input against subnets (phrase patterns stored as ATN networks <ref type="bibr">[31]</ref>) and concept case frames (semantic sentence patterns). The matched patterns are transformed into unordered sets of semantic constituents for eaeh clause, with canonical phrases substituted for the user's terms, and with pronoun reference and elhpsis g. 7, An .wervicw of the PLANES system. User •* resolved. Clause boundaries are found using a "heuristic parser" (see Section 4.0).</p><p>(2) In the query generation phase, the sets of semantic constituents representing the user's request are translated into a formal query to generate the data to answer the request. A key finding of our research is that an unordered set of semantic constituents usually specifies a formal query uniquely. There are exceptions to this rule, e.g. comparative phrases ("Did plane 3 make more flights than plane 2?" is not the same as "Did plane 2 make more flights than plane 3?" See Section 4.0 for more discussion). This stage contains specific knowledge about the database. It knows, for example, which subparts of the database contain which relations, and whieh codes are used to represent different pieces of information. The program is constructed out of primitives of our query language, an implementation of DSL Alpha <ref type="bibr" target="#b5">[6]</ref>. The query is fed to the paraphrase generator, which in turn presents the paraphrase to the user for his approval.</p><p>(3) The evaluation phase uses the program generated in the previous stage to search the database and construct an answer. This portion is based on Codd's relational data model <ref type="bibr" target="#b4">[5]</ref> and is implemented along lines suggested by <ref type="bibr">Palermo [21]</ref>. This phase contains procedures for optimizing the speed and intermediate storage requirements of the database search.</p><p>(4) The evaluation portion passes the resulting data to the response generator. This module can display the answer in one of three forms: As a simple number or list, as a graph, or as a table. The choice of output form can be determined by the user through a direct request (e.g. "Draw a graph of ...) or by a set of heuristics which attempt to fmd the most "natural" form. A graph, for example, can be generated only if the output data consists of a set of pairs which can be interpreted as a function of one of the variables. Furthermore, the number of tuples must lie within certain bounds, so that the entire result will fit on a CRT screen. At each stage of the process, the results are sent to the context register, which consists of a stack of relevani information. This stack contains semantic/contextual information (e.g. time period and plane type underconsideration, etc). This information is made available for resolving anaphoric references, supplying phrases deleted through ellipsis, and generating responses.</p><p>Each of the main phases is described in detail in the following sections. For greater clarity, we will trace a single simple request through all phases of processing. Assume that the system has already successfully answered the question: "Which A7's logged less than 5 flight hours in February 1973?" We then give PLANES the following request: "Tell me which ones logged betwen 10 and 20 flight hours in Jan." (Note the deliberate misspelling of "between.")</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parsing</head><p>"Parsing" in PLANES involves four operations: (1) putting all words and phrases in canonical form and correcting spelling; (2) matching against prestored phrase patterns {subnets) and setting a context register (history keeper); (3) matching the context register values against concept case frame patterns; and (4) filling in missing contextual information needed to form a meaningful query.</p><p>These operations are explained in more detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Putting Words and Phases in Canonical form</head><p>The parser first checks to make sure that each word of the input is known by the system. Roots and inflection markers are substituted for inflected words, canonical words are substituted for synonyms, and single words are substituted for certain phrases (e.g. "USA" for "the United States of America"). If a given input word cannot be found in the dictionary, the spelling correction module is called. This module attempts to find dictionary entries "close" to the input using methods de.scribed in <ref type="bibr" target="#b25">[25]</ref>; if one or more candidates are found, the user is given an 531 appropriate message, and if one of these candidates is correcl, it is inserted in place of the misspelled word. If no candidate words are found, or if the user rejects all the suggested candidates, the system initiates a dialogue to attempt lo add the user's word to the dictionary." The user can tell the system to ignore the word and continue.</p><p>Example 1. Given our question: Tell me which ones logged betwen 10 and 20 flighl hours in Jan." The parser first notes that "betwen" is not in the dictionary; the spelling corrector finds that "between" is the most similar dictionary entry, and types back: IS BETWEN A MISSPELLING OF BETWEEN? TYPE Y OR NO.</p><p>Once the user types "y," the system substitutes "between" for "betwen", and proceeds, "(fly past)" is substituted for "logged," "flighthours" is substituted for "flight hours," and "January" is substituted for "Jan." Thus the output of this first operation is: Tell me which ones (fly past) between 10 and 20 flighthours in January.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Matching Phrases</head><p>This portion and the next comprise the heart of the language-understanding process. It is here that pronoun reference and ellipsis are resolved, and here too that much of the overall programming effort for the system has been expended. The processing in this portion is handled by subnets.</p><p>Each subnet is an ATN [31] phrase parser which matches only phrases with a specific meaning. There are subnets for each different semantic object in the PLANES world, e.g. plane type, date, time period, malfunction, maintenance type, aircraft component, etc. Some examples of phrases which the subnet for "planetype" would match are: "A7," "phantom," "phantom or skyhawk," "ones" (where some type of aircraft is an appropriate referent of "ones"), "plane number A49732," and "A7's which crashed in May." Most subnets match noun phrases or prepositional phrases. The construction of subnets is based on Winograd's analysis of noun phrases <ref type="bibr" target="#b29">[30]</ref>. Quantifiers (e.g. "first," "rest," "more than," "largest," etc.) are handled by a special subnet as are qualifiers (e.g. the italicized words in the phrase "A7's which crashed in May). Figure <ref type="figure">8</ref> shows the subnet which matches phrases referring to amounts.</p><p>Subnets are applied to the input request one after another. When a subnet matches a phrase, that phrase is saved along with information on which subnet matched it, and attention is shifted to the next portion of the request. Also as part of this phase, "noise words" are matched by a subnet and essentially discarded. "Noise words" refer to phrases Uke "please tell me," "can you tell me," "would you let me know," "could you find," etc. ^This process will ultimately fail unless the user can find a synonymous word or phrase already known to the system. There is however a fair chance that the system will understand to request correctly, even with a missing word, since it has a compendium of wellformed query patterns (the concept case frames). In matching subnets, the system uses a general heuristic: Once a subnet has matched a phrase, keep trying to match more of the input string using the same subnet. Thus, if a prepositional phrase follows a main noun in a noun phrase, PLANES will first assume that the prepositional phrase is a qualifier of the noun (see Section 4.1 for a more detailed treatment of qualifiers). Similarly, the next input portion may be part of a compound noun phrase, as in "..phantoms or skyhawks..." Relative clause boundaries are also found using "heuristic parsing" techniques described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Context Registers, Concept Case Frames, Pronoun Reference and Ellipsis</head><p>Whenever most subnets match a phrase, they push a value in canonical form onto the context register, which acts as a history keeper; there are canonical forms for aircraft type(s), dates, serial numbers, damage types, etc. The context register is used for pronoun reference and ellipsis; if some item(s) in a request have been left unspecified or replaced by pronouns, context register values from previous requests are used to supply the missing information or the referent of a pronoun. There are also context register items stored for the last request, last paraphrase, last query language form, and last answer. The context register is implemented as a stack which is pushed down with each new phrase. Thus, while we have not yet programmed this ability, PLANES could conceivably retrieve an earlier context when given a user statement like "A while ago we were talking about skyhawks," simply by looking back through the context register until it found the planetype value equal to "skyhawk," and then restoring the other context register values current at that time.</p><p>In many cases, the subnets can recognize the type of a phrase, but some information may be missing. As an example, "in January" can be recognized as a time period phrase, but without a year specified the system will be unable to perform a search. As another example. the phrase "ihese planes" can be recognized as referring to a plane type or group of planes, bul exactly which planes are intended is not specified in the request. In such cases, the system selects the missing value (if any) from the previous context register record, and fills in the current context register. Laler when the paraphrase of a request is fed back to a user, he can either verify or modify the values which have been filled in. If the context register is empty, PLANES will ask a user to provide the necessary information as was illustrated in Figure <ref type="figure">4</ref>.</p><p>In other cases of pronoun reference or ellipsis (missing information meant to be understood in context) the system cannol easily decide what information is missing. In these cases, the system consults concept case fiames.</p><p>Concept case frames enumerate the patterns of questions understood by the system (and can also associate database query skeletons with each question type). Our concept case frames are somewhat different from ordinary case frames <ref type="bibr" target="#b1">[2]</ref>; each concept case frame consists of an act (typically related to the verb) and a list of noun phrases (referred to by subnet/context register name) which can occur meaningfully with the act. Unlike ordinary case frames, we do not store information about the role (e.g. agent, patient, instrument) played by the various phrases, and each act covers a number of related verbs (e.g. "fly" covers "fly," "log," and "record"). Furthermore, phrases which occur in every case frame, such as "time period," are omitted from the concept case frames. As a simplified example, concept case frames for acts synonymous with require might be (*require *planetype *maintenancetype), and (*require *component *maintenance-type). Together, the subnets and concept case frames form a "semantic grammar" <ref type="bibr" target="#b0">[1]</ref>.</p><p>Whenever constituents of a sentence are missing (as in an elhpsis) or replaced by pronouns or referential phrases, the system is able to suggest what type of phrase is necessary to complete the concept by finding all the concept case frames which match the rest of the sentence. If only one concept case frame matches, we are done; if more than one matches, then reference to which constituents were present in the previous sentence is usually adequate to decide among candidates.</p><p>In the event that more than one concept case frame still remains, the user can be given a set of possibilities from which to choose the appropriate referents for each phrase.' Furthermore, the system concludes that sentences such as "How many malfunctions logged more than 10 flight hours?" are probably meaningless because all phrases are recognized but no matching concept case frame exists; it is important to note however that the system can and will attempt to generate a query in any case, using the query generator, if the user tells it to do so,' The query generator allows the system to construct 'PLANES has not yet been programmed to return such a set of possibilities to the user.</p><p>' The user is given a "yes" or "no" option on proceeding at this point. queries directly from semantic constituents of a request, even for requests which have no concept case frame matches. The query generator can only handle plane type or date ellipsis, and does not always provide a correct query for novel requests. Example 3. After the subnets have operated on the request (see Example 2), some semantic constituents are complete, and can be used to form canonical values, while other semantic constituents, in this case "(ones pronoun plural)" and "January" are not yet complete. PLANES knows that "January" is a time period, but a year must also be specified. The system looks back to the previous *time-period context register value, which is "February 1973," and adds "1973" to the current context register value.</p><p>The other constituent ("(ones pronoun plural)") is of uncertain semantic class. To handle it, the system consults the concept case frame list, and finds for the act "fly" the following possibilities: The system notes that [PI] is the only appropriate match, and that a value for *planetype must be supplied to make a meaningful request. It consults the earlier context register value for *planetype, finds "A7," and sets the current value of *planetype to "A7." The program furthermore assumes that the pronoun "ones" in the ongina! request referred to *planetype, and thus decides that what is wanted as an answer is a list of planes.</p><p>Some other sentences which also match pattern [PI] are: "Find phantoms which had fewer than 15 flight hours in Feb. 1974," "Please tell me which skyhawks and F4's logged no flight hours," and "Which A7's that crashed in May had 50 or more flight hours in April?"</p><p>The canonical values for each phrase are now stored in the context register, and the information organized to form an interim query, which can be fed back to the user.</p><p>Example 4. In this case, the interim query form is:</p><formula xml:id="formula_1">{(FINDALL) (PLOT NIL) (NP (PLANE (PRONOUN T) (TYPE A7) (BUSER NIL)) (FLIGHTHOURS (QUANT (&gt;IO &lt;20)))) (NEG NIL) {ACT ELY) (TIME (DATE (MONTH (1. 0. 0.)) (DAY NIL) (YEAR 73.))</formula><p>This expression can be read as follows: (I) FINDALL is a search function which means "find all items in the database satisfying the specifications following." It is inserted because the request began with which -f plural.</p><p>(2) (PLOT NIL) means that the user did not specifically request graphical output. (3) The line beginning with 533 "PLANE..." specifies the item to be searched for and returned as a value, in this case planes of type A7. (PRONOUN T) means that pronoun (or phrase) reference occurred for this phrase of the request. "A7" has been inserted for plane type. (BUSER NIL) means that no specific serial number was mentioned. (4) The next line represents the information that to be a "hit," items must have between 10 and 20 flighthours. (5) (NEG NIL) means that the sentence is not negated. (6) The three hnes beginning "(TIME..." specify thai the entire flrst month of 1973 is to be considered. In our current system, this interim query can be fed back to the user or suppressed.</p><p>Extending system competence with the PLANES world is fairly easy, though for the most part it must now be done by a programmer. To add the ability to handle a new type of sentence, one must only add a concept case frame which expresses that sentence, and verify that the query generator produces the appropriate query for the sentence. Variations on the new sentence, including active and passive forms, ellipsis, different phrase orderings and the addition of noise words can all be handled with no additional machinery. If the query generator's output is inappropriate, then special instructions are necessary. These are attached to the concept case frame. A common special instruction specifies the fields which should be returned as answers to a query. For example, the question "Which planes had 20 or more flight hours in May?" returns a list of flight hours as well as planes, even though only the planes are explicitly requested.</p><p>Extending the subnets is also easy; we have written a net editor (described in <ref type="bibr">[28]</ref>) which takes a phrase and adds the states and arcs to match this phrase to a specified subnet, using a minimum number of new arcs and states. Once a phrase has been added lo a subnet's repertoire, the phrase ean of course be matched in any sentence context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">The Query Generator</head><p>The interim query form expression is next translated into a formal query expression for use with our relational database sysiem by the query generator: The translation involves: (1) deciding which relations (files and card types) to look at to retrieve the information necessary for answering the user's request; <ref type="bibr" target="#b1">(2)</ref> deciding what domains (data fields) to return from the relations which are searched. (In general, more fields are returned than are actually asked for. For example, if asked about which planes had engine maintenance during some time period, the system returns not only the plane identification numbers, but also the dates of maintenance and codes for the exact type of maintenance.); (3) deciding which semantic constituents should be represented as predicates, i.e. test conditions to decide whether or not given tuples are "hits"; <ref type="bibr" target="#b3">(4)</ref>  actions) into internal database codes; <ref type="bibr" target="#b5">(6)</ref> deciding how to arrange the output data. Typical orderings are by increasing or decreasing size of some field value (like "number of hours down time") or sequentially by date.</p><p>The query generator makes all these decisions and produces an expression in the relational calculus <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10]</ref> which can be used lo implement the actual database search. Decisions (4), ( <ref type="formula" target="#formula_2">5</ref>), and ( <ref type="formula">6</ref>) are relatively straightforward. ( <ref type="formula">4</ref>) is decided by noting which operations (if any) are associated with each semantic constituent; ( <ref type="formula" target="#formula_2">5</ref>) is done by look-up in a code table; and ( <ref type="formula">6</ref>) is done by a priority scheme (unless a user has specifically requested a particular item to sort on).</p><p>Decisions ( <ref type="formula">1</ref>), (2), and (3) are more interesting, and are considered one at a time below.</p><p>(1) Of particular interest is the method by which relations are selected. The system looks at each semantic constituent separately, and notes which relations it could possibly belong to. Some constituents (like planetype and date) are not very useful for this process, since they appear in most relations, but others (like flighthours or NOR (Not Operationally Ready) hours) appear in only one or two relations. All the relations possible for each phrase constituent of a clause are then intersected, and if a single relation is selected, the process of selecting a relation is complete for the clause. Clauses are then considered in pairs, and so on.</p><p>If more than one relation or a set of relations remains, then the request is ambiguous, and the system uses a priority scheme to pick a relation to search. As an example, if the answer to a request could be obtained from either daily records or monthly summaries, PLANES will choose to look at the summary data for the obvious efficiency advantage.</p><p>If no relations remain at any intersection step, then more than one relation must be searched to answer the request, and the results of these searches musl then be combined via the relational operation csiWed joining (constructing a single relation from two different relations). As an example, the request: "Find all planes which had engine maintenances on the same day as a flight" would require searching the maintenance and flight relations, and then joining these relations via the date and plane domains. Exactly how joining is done is described in Section 4.</p><p>(2) To decide which data fields to return for an answer, the system looks at the nature of each semantic constituent. Semantic constituents may be constants (e.g. "plane 3,'' "May 1, 1973," or "engine maintenance"'), variables (e.g. "planes," "maintenance," or "flights"), or sets of constants'' (e.g. "between 10 and 20 flights," "A7's," "planes 3 and 5" or "less than 20 flighthours"). The query generator puts all variables and sets of constants in the answer.</p><p>(3) In a similar manner, all constants and sets of constants are turned '\n\.o predicates.</p><p>Example 5. In our example, the semantic constituents refer to planetype, date, and flighthours. Planetypes and date appear in most relations, but flighthours appear only in two relations, O(monthly summaries) and /)(dai!y records). O(monlhly summaries) is selected by a priority scheme.</p><p>The query generator notes that of the semantic constituents "A7" refers to a set of constants (all A7 serial numbers); "January 1973" is a constant (it refers lo specific values of fields for month and year),^ and "flighthours, (&gt;10, &lt;20)" is a set of constants.</p><p>Thus all three semantic constituents are used to generate predicates (see below), and A7 serial numbers and number of flighthours are determined to be the items which constitute an answer to the request.</p><p>The query generator combines all this information in a standard template:</p><p>(FIND (quantifier) (variables, relations) (answer form) (predicates) (sort order))</p><p>The result is the query language (relational calculus) expression: The meaning of this expression is as follows: (1) "FIND 'ALL" means that all items satisfying the criteria following should be searched for. In contrast, "FIND 'ONE" would return as soon as any item satisfied the rest of the query expression. Still other forms are possible. (2) Kis a variable name; (3) O specifies the relation O, which is in turn associated with the database files in which monthly flight data summaries are stored; (4) '((V BUSER) ( KTOTHRS)) specifies what is to be returned as output, in this case a table with columns for BUSER (BUreau SERial number-a plane identification number) and for TOTHRS, the total number of flight hours for that plane. <ref type="bibr" target="#b4">(5)</ref> The five lines beginning with '(AND... specify the predicates which must be true of each entry to be returned for the answer table, namely that the year must be <ref type="bibr">3 (1973)</ref>, the month musl be 1 (January), the plane type must be A7, and the total number of flight hours (given in the card field TOTHRS) must be less than 20 but greater than 10. ( <ref type="formula">6</ref> that the output table is to be ordered by BUSER (serial) number, with the smallest serial number first and the largest serial number last.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">The Paraphrase Generator</head><p>An important part of the system's operation is allowing a user to verify whether or not the system has correctly understood his request. To this end, the system feeds back its understanding of the request, with pronoun reference and ellipsis resolved, for the user's approval. The paraphrase is straightforwardly constructed from the formal query.</p><p>The construction involves (1) substituting English words for abbreviations, coded items, compound conzstructions. etc. (2) selection of an appropriate overall paraphrase template, (3) placing words and phrase in the template slots. We will not discuss the details of this process here.</p><p>Example 6. Given the formal query from Example 5, the paraphrase generator constructs the following paraphrase:</p><p>PLANES searches the MONTHLY FLIGHT AND MAINTENANCE SUMMARIES and returns: The value for SERIAL# and HOW MANFUNCTIONED codes for A7 aircraft during January 1973 satisfying TOTAL FLIGHT HOURS &lt;20 and TOTAL FLIGHT HOURS &gt;IO. Should I evaluate the query? Type y or n:» Suppose that the user had actually intended that the time period be January 1974. He can easily modify the query by typing "n" and then when PLANES prints</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please enter your question</head><p>The user can simply type "1974"; the PLANES ellipsis mechanisms repeat the question for 1974. Similarly "A7 and F4" would modify the query to cover both classes of aircraft.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Execution of Query Expression on the Relational Database</head><p>In the relational model <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref> data is viewed as being divided into relations which roughly correspond to nonhierarchic files or sets of files in conventional database terminology. Each relation contains a collection of tuples which cort^espond to records; each tuple contains one or more attributes or fields. A relation can conveniently be thought of as a table, with each row being a tuple and each column an attribute.</p><p>For our purposes the relational approach has two important advantages: (1) The relational approach stresses data independence. This means that the user and front end programs are effectively isolated from the actual database organization. We are now working with only a small subset of the entire 3-M database; if we were to use our front end with the entire 3-M database, the data accessing programs would have to be modified, but. using the relational model, these changes need not 535 affect lhe "data model" seen by users and the natural language front end. (2) The 3-M database is already internally organized in a tabular form, and is thus ideally suited to a relational data model.</p><p>In Section 3.5, we showed the sort of expression generated by the translator. This expression is given in the data sublanguage Alpha <ref type="bibr" target="#b5">[6]</ref>, as implemented in Lisp by Green <ref type="bibr" target="#b12">[13]</ref>. This expression is used by the relational database system to construct the actual program which retrieves the data. In order to construct the search program, the system must: (1) select the files to be searched;</p><p>(2) select an order for searching these flies; (3) generate an expression for testing and selecting tuple values to return while searching; (4) generate a program to combine data, possibly from a number of different relations, so that the proper answer will be returned; (5) decide when to save the results of a search for future use. This is important in interactive querying, since interesting results can evoke follow-up queries from a user, and such queries are likely to reference tuples just retrieved.</p><p>Our database is physically organized into files, where each file contains one type of data (e.g. flight data, failed parts, installed parts, etc.) for a single plane for a oneyear period. Each file also contains statistical information (including the number of unique values of a domain, the range of values for a numerical domain, and the number of tuples in the file) used in planning the order for searching files (step (2) above). Continuing our example should help clarify this portion of the processing.</p><p>Example 7. By looking at the expression given in Example 5, the execution program first finds the files to be searched. In this case the system will select flight data files for all A7's for the year 1973. These are chosen by noting that only relation O (flight data summary) is selected, that only data on PLANETYPE equal to A7 will be returned, and that only ACTDATEYR 3 (1973) should be considered. The system notes that all files belong to the same relation, so search order is irrelevant, since no intermediate results need to be generated and combined. Since it has already guaranteed that the files retrieved will contain only data on A7's during 1973, the program simplifies the predicate portion of the query used to test each tuple to see whether or not it is a "hit" to:</p><p>(AND (EQU(l^ACTDATEMON) I.)</p><p>(LT(KTOTHRS) 20) K TOTHRS) 10.)).</p><p>Since it is only to return a list, and the files already contain summaries of flight hours by month, the returned data form is also particularly simple, requiring no arithmetic operations (any "hits" are merely listed).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Generating an Answer</head><p>Once the data has been retrieved, the results are passed to the output module, which decides on an appropriate display formal for the data. If possible, it attempts to produce a graph. This can only be done if <ref type="bibr" target="#b0">(1)</ref>  number of items reUirned is small enough (but nol too small) lo produce a reasonable graph which will Hi on a CRT screen. If a graph is nol possible, the system will produce a list or table; if there is too much dala to fit on the screen, the results will be automatically output to the line printer.</p><p>Example 8. Suppose that only a very few planes (lew between 10 and 20 hours in January 1973. A typical output would be; If 40 or more items were returned (impossible for this query with our current database, since we have data on only 36 A7's) the results would be output by line printer. The heuristics for selecting output can be easily modified to produce whatever form of output is desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.0">Embedded Clauses, Comparatives, and Multiple Relation Searches</head><p>The example traced in the preceding section was particularly simple. In this section we will treat three complications which can arise fairly frequently in the PLANES world; these are (I) requests with qualifying phrases, (2) comparatives, and (3) requests which require the combining of information from more than one relation.</p><p>Qualifying phrases or qualifiers (see Winograd <ref type="bibr" target="#b29">[30]</ref>), constitute the most common type of dependent clause. Examples of qualifiers are the italicized parts of "planes which crashedin Mav."""md^ini^nanQQ^performed on A7's," and "planes with poor maintenance records," Qualifiers usually appear after the main noun in a noun phrase, and are often introduced by relative pronouns such as "which" or "that," or by verb forms ending in -ed or -ing. Prepositional phrases can also serve as qualifiers.</p><p>Qualifiers can be found by applying a qualifier subnet to the portion of a request following the main noun of a noun phrase. Because qualifier syntax is fairly restrictive, merely examining the single word after the main noun may in many cases suffice to preclude the presence of a qualifier. If a qualifying phrase or clause may be present, the following actions are taken:</p><p>(1) A "heuristic parser" (see below) is invoked to verily that a qualifier is present, and to find its boundaries. Thus, unlike overall sentences in PLANES, qualifiers must be grammatical, at least to a degree.</p><p>(2) If a qualifier is found to be present, processing is suspended on the current clause, and the current context register values are pushed down.</p><p>(3) The main noun from outside the qualifying phrase is substituted for the relative pronoun (if any), or is inserted as a phrase element in the qualifier.</p><p>(4) The qualifying phrase or clause is processed like a normal request, with the main noun from the clause above serving the role of the requested item. Note the verb forms get changed to a root plus an inflection, so that the exact verb form does not affect this processing. Prepositions as well as verbs can refer to certain case frames, so that, for example "planes with poor maintenance records" has the same meaning to the system as "planes having poor maintenance records." <ref type="bibr" target="#b4">(5)</ref> The query corresponding to the qualifier must be integrated with the query corresponding to its surrounding clause to form the overall query. The ordinary meaning of qualifiers seems to suggest that the qualifier query should be evaluated on the database first, and its result should then be used as the scope of search for the other clause. In fact, either search can in general be performed first. Our system estimates temporary storage required for each query, and selects the query with minimum requirements to search first to increase system efficiency. The storage estimates are made on the basis of statistical information stored for each file. Query construction is discussed in more detail in <ref type="bibr" target="#b12">[13]</ref> and [28].</p><p>Comparatives, for example "Did plane 3 have more flight hours in April than in May?," are handled in a manner exactly parallel to qualifiers; the request containing the comparative is broken into two simple queries which are evaluated separately. The only difference is that one query is evaluated first and the results used in forming the second query. Thus for the example request. PLANES would first find the number of flight hours for plane 3 in April (say 48) and then form a second query "Did plane 3 have &gt; 48 flight hours in May?" An example should help clarify both the linguistic processing of qualifiers and the handling of questions where more than one relation must be searched.</p><p>Example 9. Consider the sentence; Did any A7*s which had engine damage in May have 10 or fewer flight hours in June?</p><p>Assume that the year 1973 can be found from the dialogue context. The system proceeds normally until the word A7's has been found as the main noun of the noun phrase "any A7's... ." The system then checks for possible qualifiers, and finds "which" following "A7's," a sure sign of a qualifying phrase. The heuristic parser finds that the complete qualifying clause is "which had engine maintenance in May," and sets as its first subgoal forming a database query for the question; "Which A7's has engine damage in May?" This simple question is given to PLANES recursively, and can be handled straightforwardly by mechanisms discussed earlier in Section 3, yielding the query expression shown in Figure <ref type="figure">8</ref>(a). Similarly, the outer clause, "Did any A7's have 10 or fewer flight hours in June?" presents no problems, and results in the query shown in Figure <ref type="figure">8</ref>(b). These two queries are then joined by noting that the word "A7's" must refer to the same entity in both the inner and outer clauses. Thus the two queries can be joined, with the added condition that the BUSER numbers from each query must be equal, as shown in Figure <ref type="figure">8(c</ref>). This expression can then be operated on by the optimizer to select either the relation M or the relation O to search first, based on file statistics. The prime job of the heuristic parser is to bracket relative clauses so that the request may be broken up into simple queries with no embedded clauses. The left boundary of the embedded clauses is already known^it immediately precedes the main noun of the outer clause-so the problem is to find the right clause boundary. (The main noun is shared by inner and outer clauses.)</p><p>The parser knows a number of general patterns for embedded clauses and simply matches these to the request sentence. Two of these patterns for finding right clause boundaries are: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.0">Discussion</head><p>There are some loose ends which should be treated to give a more complete picture of the scope of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Browsing; Complex and Vague Questions</head><p>This paper has so far described only our work on straightforward questions, ones which are not subject to multiple interpretations. We have also given considerable attention in our research to the problem of answering vague and complex questions. Such questions are intimately related to browsing programs, i.e. programs which can automatically search for "interesting" connections and patterns in a database, given large quantities of computation time (e.g. as a background or off-hours job) and certain broad guidelines about areas of prime concern.</p><p>Examples of the types of difficult questions we have been considering are: Which plane had the worst maintenance record? Is there anything unusual about the history of plane 67? Do planes 67 and 117 have any common factors? Are any A7"s hangar queens?'T o handle such questions, we have developed a number of special functions which are "expert" in narrow areas, such as characterizing maintenance records or comparing histories. These expert functions have specialized knowledge about the relative importance of data items, about alternative interpretations of "goodness" of records (e.g. minimum cost, man-hours, down-time, down-time/flight-hours ratio, etc.), as well as about methods for judging such factors as statistical significance.</p><p>' ^ A "hangar queen" is a plane that serves primarily as a parts source for other planes. Hooks have been provided in the language processing portions of PLANES for attaching those special purpose lunctu^ns as they become available. The work done to dale in lhi,s area is described in more detail in [^' 1 ;ind</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rolutionship to Other Research</head><p>Over the past few years there has been a great deal of interest tn the general areas of natural language question answering, relational databases, and data front ends. A number of complete systems have been developed. Our purpose is not to cover the entire area, but to discuss projects which are similar to PLANES in significant respects or which have been influential in developing PLANES. This is not intended to be a complete overview of the field; no doubt worthy projects have been omitted.</p><p>(1) The LSNLIS (for Lunar Sciences Natural Language Information System) of Woods et al [32], is a system for answering questions about the chemical analyses of moon rock samples. Both PLANES and LSNLIS use ATN's, though Woods' does a complete syntactic parse before performing semantic analysis and is thus probably less tolerant of nongrammatical requests. The PLANES database is considerably larger and more complex, and the vocabulary and semantics of the PLANES world are consequently also somewhat larger than those of the LSNLIS world.</p><p>(2) PLANES owes a substantial debt to the work of Codd, including his ideas on dialogue for his RENDEZ-VOUS system <ref type="bibr" target="#b3">[4]</ref> and his development of relational database systems and concepts <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>. RENDEZ-VOUS uses a self-description of database relations to provide a basis for judging the meaningfulness of request and for generating dialogue; in PLANES the list of concept case frames serves roughly the same function. RENDEZVOUS uses a large number of productions (situation-action pairs) which are repeatedly apphed to transform a request into a formal query. Special attention has been given to generating a "clarifying dialogue" with a user when a query is novel or only partially understood. The PLANES database query language and general organization are fairly direct implementations of Codd's ideas as elaborated and developed by Palermo <ref type="bibr">[21]</ref>. The use of statistics to "optimize" the order of search is novel in PLANES. Another system which also uses an underlying relational database is the TORUS system of Mylopoulos et al. <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b19">19]</ref>.</p><p>(3) Any system for answering questions which is to distinguish meaningful from meaningless requests must store information about which concepts are possible. The same function can be served by different constructs. In PLANES, concept case frames are used; as mentioned above, Codd's RENDEZVOUS work <ref type="bibr" target="#b3">[4]</ref> suggests using relation self-descriptions. Recent work by Sowa <ref type="bibr" target="#b24">[24]</ref> offers a potentially powerful solution using "conceptual graphs" (as well as relational database ideas and operations). His work closely parallels our work on PLANES III many ways, but Sowa has aimed at generality and nialhemalical rigor, whereas our work has been aimed more at practical implementation in a relatively narrow domain. TORUS <ref type="bibr">[IH,</ref><ref type="bibr" target="#b19">19]</ref> and OWL [141 use semantic nets to represent possible meanmgs; other possibilities for representing meanings include verb meaning structures plus .semantic markers as in ease grammars [2, 11], Schank's conceptual dependency diagrams <ref type="bibr" target="#b22">[23]</ref>, and Wilks' preference semantics <ref type="bibr" target="#b28">[29]</ref>.</p><p>(4) The use of phrases with distinct meanings as the basic unit of analysis is akin to and to a degree inspired by Brown and Burton's "semantic grammar" work <ref type="bibr" target="#b0">[1]</ref>. The basic noun phrase analysis and organization of subnet in PLANES draws heavily on the work of Winograd <ref type="bibr" target="#b29">[30]</ref>.</p><p>(5) Work on a question-answering system for the Navy 3-M Ship database is being carried out at SRI <ref type="bibr" target="#b15">[16]</ref>. The SRI work, called LIFER, seems similar in many respects to an earlier version of PLANES <ref type="bibr" target="#b26">[26]</ref>. LIFER is implemented using productions (situation âction pairs). Each situation is an ordered request pattern, and each action is an appropriate search function. Such a system would require several productions for eaeh PLANES query to account for different request orders, and would seem to be unable to do much with a novel query. However, special emphasis has been placed on making it simple to add new queries to the system (or to write new versions of LIFER for novel databases). From examples shown, LIFER seems to have been applied primarily to a database organized as a set of property lists.</p><p>For surveys of other natural language question-answering research, all more or less related to PLANES, see <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.0">Summary</head><p>The PLANES system for natural language access to a large database has been described in detail. Key concepts and novel ideas include;</p><p>(1) The central role of ATN subnets for recognizing phrases with specific meaning; in particular this allows the recognition of semigrammatical requests.</p><p>(2) The use of concept ease frames for checking meaningfulness of requests, for generating dialogue to find missing elements, for aiding in pronoun reference and ellipsis resolution, and for aiding translation into the query language.</p><p>(3) The use of context registers as history keepers for many purposes including especially the resolution of pronoun reference and ellipsis and the efficient answering of follow-up questions.</p><p>(4) The use of relational calculus as a convenient language into which to translate English, and a relational database organization as appropriate to our record-based database.</p><p>( s mciuatng operalmg speed, dialogue and paraphrase generation, spelling correction and error recovery, browsing and answering of vague questions, answer generation, automatic HELP files, etc.</p><p>(6) The use of statistics on the database for "optimizing" search order.</p><p>(7) An approach toward handling dependent clauses and language in general which looks at and attempts to account for every word, while at the same lime not constricting the system by requiring requests to be grammatically correct.</p><p>A cknowledgments. I would especially like to acknowledge the work of Brad Goodman on the language portion of the system and Fred Green on the relational database portion. Others who have played important roles in implementing PLANES include Lois Boggess, Tim Finin, George Hadden, Doug Dankel, Paul Rutter, Tse-Wah Wong, Gene Lewis, Harry Tennant, Forrest Conrad, and Dick Gabriel.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig, 2 ,</head><label>2</label><figDesc>Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Example 2 .</head><label>2</label><figDesc>Let us now (ollow our example through; iho inpul lo the mulching portion from the previous portion is: "Tell me which ones (tly past) between 10 and 20 llighthours in January." In this phase, the noise words "tell me" are dropped and the sentence is analyzed to be of the form:(*qword *nphrl *actl *quant-phrase *nphr2 *timepp)where the starred items have the following values: stands for noun phrase, *qword for question word, *quant-phrase for quantifying phrase, and *timepp for lime period.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>[</head><label></label><figDesc>P\] (*fly *planetype *flighthours) [PI] (*fly *planetype *ship-tlights) [^3] (*fly *planetype *catapult-flights) [PA] (*fly *planetype ^flights)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>) '(BUSER UP) means '' All engine maintenances have the same two-digit prefix for a particular data field (i.e. work unit code). ' • Strictly speaking, .some examples should be called "ranges of constants."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(with) + NP + right boundary I end of sentencej [p5] allows the system to place brackets as shown for: Did any [A7's which had engine damage in May] have 10 or fewer flight hours in June?Notice that a request can involve searching more than one relation, even if there are no quahfiers or dependent clauses, as in the sentence: Did any planes have a flight on the same day as an engine maintenance? In this case the relation for flights and the relation for maintenance must both be searched, and the results joined with respect to plane and date values. The need for a multiple relation search is inferred when no single relation contains all semantic constituents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>) The attack on a broad front of many practical</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>deciding which operations should be performed on the fields returned. Examples of operations include list, count, average, sum, and find largest;<ref type="bibr" target="#b4">(5)</ref> translating field values (e.g. for dates, plane types, or</figDesc><table><row><cell>Communications of</cell><cell>July 1978 Volume 21</cell></row><row><cell>the ACM</cell><cell>Number 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>pairs of items are returned, (2) one item is numerical, and (3) the</figDesc><table><row><cell>Communications</cell><cell>July 1978</cell></row><row><cell>of</cell><cell>Volume 2</cell></row><row><cell>the ACM</cell><cell>Number 7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Fig,8(a), Query corresponding lo "Which A7 aircraft had engine dan\age in May 1973?" IIOWMAL stands tor a "How Malfunclioned" code; "M" specifies that the maintenance relation is lo be searched. Compare with discussion in Section 3. Example 5,</figDesc><table><row><cell>(FIND ALL</cell><cell></cell><cell></cell></row><row><cell>'((VI A/))</cell><cell></cell><cell></cell></row><row><cell>({VI BUSBR))</cell><cell></cell><cell></cell></row><row><cell>'(AND(EQU (VI ACTDATEYR) 3.)</cell><cell></cell><cell></cell></row><row><cell>(EQU(Vi ACTDATEM0)5.)</cell><cell></cell><cell></cell></row><row><cell>(EQU{V1 PLANETYPE)'A7)</cell><cell></cell><cell></cell></row><row><cell>(EQU &lt;Vl HOWMAL)62.)))</cell><cell></cell><cell></cell></row><row><cell>Fig. 8(b). Query corresponding lo "Did any A7 aircraft have 10 or</cell><cell></cell><cell></cell></row><row><cell>fewer (light hours in June 1973?" Compare with Section 3, Example 5.</cell><cell></cell><cell></cell></row><row><cell>(FIND 'ALL</cell><cell></cell><cell></cell></row><row><cell>'{(V2 O))</cell><cell></cell><cell></cell></row><row><cell>'((V2 BUSER) (V2 TOTHRS))</cell><cell></cell><cell></cell></row><row><cell>'(AND '(EQU (V2 ACTDATEYR) 3)</cell><cell></cell><cell></cell></row><row><cell>(EQU (V2 ACTDATEMO) 6)</cell><cell></cell><cell></cell></row><row><cell>(EQU (V2 PLANETYPE) 'A7)</cell><cell></cell><cell></cell></row><row><cell>(LTE(V2 TOTHRS) 10,)))</cell><cell></cell><cell></cell></row><row><cell>Fig, 8(c), Query resulting from combining queries from figures 8(a)</cell><cell></cell><cell></cell></row><row><cell>and 8(b), with added requirement that the answer is lo be a list of</cell><cell></cell><cell></cell></row><row><cell>planes satisfying both queries,</cell><cell></cell><cell></cell></row><row><cell>(FIND ALL</cell><cell></cell><cell></cell></row><row><cell>'((VI A/)(V2 O))</cell><cell></cell><cell></cell></row><row><cell>'((V2 BUSER) (V2 TOTHRS))</cell><cell></cell><cell></cell></row><row><cell>'(AND '(EQU (V2 ACTDATEYR) 3.)</cell><cell></cell><cell></cell></row><row><cell>(EQU (V2 ACTDATEMO) 6.)</cell><cell></cell><cell></cell></row><row><cell>(EQU (V2 PLANETYPE) 'A7)</cell><cell></cell><cell></cell></row><row><cell>(LTE(V2 TOTHRS) 10.)</cell><cell></cell><cell></cell></row><row><cell>(EQU (VI ACTDATEYR) 3 )</cell><cell></cell><cell></cell></row><row><cell>(EQU (VI ACTDATEMO) 5,)</cell><cell></cell><cell></cell></row><row><cell>(EQU (VI PLANETYPE) 'A7)</cell><cell></cell><cell></cell></row><row><cell>(EQU (VI HOWMAL)62)</cell><cell></cell><cell></cell></row><row><cell>(EQU (VI BUSER) (V2 BUSER))))</cell><cell></cell><cell></cell></row><row><cell>536</cell><cell>Communications of</cell><cell>July 1978 Volume 21</cell></row><row><cell></cell><cell>the ACM</cell><cell>Number 7</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_0"><p>I X X X X X X X X X X X X X X X X X X X X X X X X X X X X y X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X K K X X X X X X20032004 aO05 zoos 2007 2008 2009 ZOIO ZOIl 2012 questions, as discussed in Section 5.1, is more fully developed.For a discussion of other pros and cons of natural language systems, see<ref type="bibr" target="#b21">[22]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>' The numbers listed include abbreviations and Irregular verb conjugations. Regular verbs and plural forms are computed from dictionary entries. Many idioms are not in the dictionary, but are encoded implicitly in the subnets (see Sections 3,2 and 3.3), Communications of the ACM July 1978 Volume 2 Number 7</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="534" xml:id="foot_2"><p>' Under certain circumstances, the same constituents may be treated differently. For example, if a phrase like "when during January 1973" or a structure like "when ±...+January 1973" occurs, then days is an implicit variable. Communications of the ACM July 1978 Volume 2 Number 7</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_3"><p>K X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The research described in this paper was supported by the Office of Naval Research under Contract Number NOOO14-67-A-0305-0026.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple representations of knowledge for tutorial reasoning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Representation and Understanding</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bobrow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ed</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="311" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">systems for natural language</title>
		<author>
			<persName><forename type="first">Case</forename><forename type="middle">B</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="327" to="360" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On Ihe psychological importance of time in a time-sharing system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="142" />
			<date type="published" when="1968-04">April 1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scven steps to RENDEZVOUS with the casual user</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Codd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc, IFIP TC-2 Working Conf. on Daia Base Management Systems</title>
		<meeting>IFIP TC-2 Working Conf. on Daia Base Management Systems<address><addrLine>Co., Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland Publ</publisher>
			<date type="published" when="1974-04">April 1974. 1974</date>
			<biblScope unit="page" from="179" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A relational model of data for large shared data banks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Codd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">311</biblScope>
			<date type="published" when="1970-06">June 1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A data base sublanguage founded on the relational calculus</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Codd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc, ACM-SIGFIDET Workshop on Data Description, Access and Control</title>
		<imprint>
			<biblScope unit="page" from="35" to="68" />
			<date type="published" when="1971-11">Nov, 1971</date>
			<publisher>ACM</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Relational completeness of data base sublanguages</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Codd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Base Systems</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="33" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Normalized data base structure: a brief tutorial</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Codd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM-SIGFIDET Workshop on Data Description, Access, and Control</title>
		<meeting>ACM-SIGFIDET Workshop on Data Description, Access, and Control<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1971-11">Nov. 1971. 1971</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">BROWSER: a user oriented information retrieval system</title>
		<author>
			<persName><forename type="first">F</forename><surname>Conrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>Depl, of Computer Science, U-of lilinois</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">An Introduction to Database Systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Date</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The case for case</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fillmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Univer.mls in Linguistic Theory</title>
		<editor>
			<persName><forename type="first">Harms</forename><surname>Bach</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ed</surname></persName>
		</editor>
		<editor>
			<persName><surname>Holt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Winston</forename><surname>Rinehart</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Natural language based information retrieval</title>
		<author>
			<persName><forename type="first">R-P</forename><surname>Cabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Waltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th Allerton Conf. on Circuit and Sys. Theory, U, of Illinois</title>
		<meeting>12th Allerton Conf. on Circuit and Sys. Theory, U, of Illinois<address><addrLine>Urbana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1974-10">Oct. 1974</date>
			<biblScope unit="page" from="875" to="S84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Implementation of a query language based on the relational calculus. M,S, thesis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1976-10">Oct, 1976</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, U, of Illinois. Urbana. II!,</orgName>
		</respStmt>
	</monogr>
	<note>to be issued as Coordinated Science Lab. tech. rpt</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The representation of concepts in OWL</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hawkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. papers 4th Intl, Joint Conf, on Artificial Intelligence</title>
		<meeting><address><addrLine>Tbilisi, U,S.S.R, Sept; Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="107" to="114" />
		</imprint>
		<respStmt>
			<orgName>MIT Al Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic programming through natural language dialogue: a survey</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Heidorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Develop. It)</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="302" to="313" />
			<date type="published" when="1976-07">July 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Human engineering for applied natural language processing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Hendrix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc, Fifth Intl. Joint Conf. on Artificial Intelligence, MIT</title>
		<meeting>Fifth Intl. Joint Conf. on Artificial Intelligence, MIT<address><addrLine>Cambridge, Mass.; Pittsburgh, PA.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1977-08">Aug. 1977</date>
			<biblScope unit="page" from="183" to="191" />
		</imprint>
		<respStmt>
			<orgName>Available through Comp, Sci, Dept, Carnegie-Mellon Univ</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Knowledge-based English language systems for management support: an analy,sis of requirements</title>
		<author>
			<persName><forename type="first">A</forename><surname>Malhotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Papers</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">th</biblScope>
		</imprint>
	</monogr>
	<note>Adv</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Joint</forename><surname>Intl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Conf ; S</surname></persName>
		</author>
		<title level="m">on Artificial Intelligence</title>
		<meeting><address><addrLine>Tbilisi, U.S,; Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">Sept, 1975, M2-S47</date>
		</imprint>
		<respStmt>
			<orgName>MIT Al Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic networks and the generation of context-Adv</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mylopoutos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borgida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sugar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Papers 4th Intl, Joint Conf. on Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="134" to="142" />
			<date type="published" when="1975-09">Sept. 1975</date>
			<pubPlace>Tbilisi, USSR</pubPlace>
		</imprint>
		<respStmt>
			<orgName>MIT Al Lab-, Cambridge. Mass-)</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">TORUS-a natural language understanding system for data management</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mylopoulos</surname></persName>
		</author>
		<author>
			<persName><surname>Borgida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roussopoulos</forename><forename type="middle">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-</forename><surname>Tsotsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H ;</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Sept</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Papers 4th Intl. Joint Conf. on Artificial Intelligence</title>
		<meeting><address><addrLine>Tbilisi, U,S; Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="414" to="421" />
		</imprint>
		<respStmt>
			<orgName>MIT Al Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Naval Air Logistics Data Analysis) system data requirements determination report. Naval Aviation Integrated Logistics Support Center</title>
		<author>
			<persName><surname>Nalda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">data base search problem, 4th Intl, Symp. on Computer and Info</title>
		<meeting><address><addrLine>Patuxent River, MD, 21. Palermo, F, P, A; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Plenum Press</publisher>
			<date type="published" when="1972-12">Dec. 1972. 1972</date>
			<biblScope unit="page" from="67" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On natural language based computer systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Pelrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Develop</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="314" to="325" />
			<date type="published" when="1976-07">July 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Identification of conceptualizations underlying natural language</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Models of Thought and Language</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Colby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">-</forename><surname>Ed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freeman</forename><surname>Wott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="187" to="247" />
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conceptual graphs for a data base interface</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Sowa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Develop</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="336" to="357" />
			<date type="published" when="1976-07">July 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Spelling, word, and concept recognition. Rep, Computer-based Education Research Lab</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tenczar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Golden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<pubPlace>Urbana</pubPlace>
		</imprint>
		<respStmt>
			<orgName>U-of Illinois</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Natural language access to a large database: an engineering approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Waltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Papers 4th Intl. Joint Conf, on Artificial Intelligence. Tbilisi</title>
		<imprint>
			<date type="published" when="1975">Sept-1975. 868-872</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
		<respStmt>
			<orgName>MIT Ai Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Writing a natural language database system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Waltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>Fifth International Joint Conference on Artificial Intelligence<address><addrLine>Cambridge, Mass; Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1976-01">Jan, 1976. April 1976. Aug. 1977</date>
			<biblScope unit="volume">XXIX</biblScope>
			<biblScope unit="page" from="144" to="150" />
		</imprint>
		<respStmt>
			<orgName>CS Dept., Carnegie-Mellon Univ</orgName>
		</respStmt>
	</monogr>
	<note>MIT</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A preferential, pattern-seeking, semantics for natural language inference</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="74" />
			<date type="published" when="1975">Spring 1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Transition network grammars for natural language analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M-</forename><surname>Nash-Webber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The lunar sciences natural language system: final report-Rep</title>
		<meeting><address><addrLine>New York; Cambridge. Mass</addrLine></address></meeting>
		<imprint>
			<publisher>Bolt Beranek and Newman Inc</publisher>
			<date type="published" when="1970">1972. Oct, 1970. 2378. 1972</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="591" to="606" />
		</imprint>
	</monogr>
	<note>Understanding Natural Language</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
