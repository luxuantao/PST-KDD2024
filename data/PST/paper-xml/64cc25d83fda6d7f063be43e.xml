<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Practical 128-bit General Purpose Microarchitectures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chandana</forename><forename type="middle">S</forename><surname>Deshpande</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arthur</forename><surname>Perais</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fr?d?ric</forename><surname>P?trot</surname></persName>
						</author>
						<title level="a" type="main">Toward Practical 128-bit General Purpose Microarchitectures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/LCA.2023.3287762</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>128-bit microprocessors</term>
					<term>microarchitecture</term>
					<term>clustered microarchitectures</term>
					<term>region based compression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Intel introduced 5-level paging mode to support 57bit virtual address space in 2017. This, coupled to paradigms where backup storage can be accessed through load and store instructions (e.g., non volatile memories), lets us envision a future in which a 64-bit address space has become insufficient. In that event, the straightforward solution would be to adopt a flat 128bit address space. In this early stage letter, we conduct highlevel experiments that lead us to suggest a possible generalpurpose processor micro-architecture providing 128-bit support with limited hardware cost.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE virtual address (VA) space has steadily grown over the past decades. For instance, x86 extended VA width from 48 to 57 bits in 2017 <ref type="bibr" target="#b0">[1]</ref>. Moreover, there is already a signal from industry that we may run out of 64-bit addresses within two decades in specific use cases (e.g., 8 EiB -2 63 -files by 2040 <ref type="bibr" target="#b1">[2]</ref>). In that event, the most straightforward strategy would be to double the VA width again, to 128 bits <ref type="bibr" target="#b2">[3]</ref>. Such a change would impact the whole stack, from compilers and operating systems to processor cores. In this context, it is necessary to start stirring the pot as early as possible, as the band-aids (e.g., Physical Address Extensions) that were added during the 32-to 64-bit transition phase turned out to be burdens that disappeared as soon as it became possible to remove them. In this letter, we focus on microarchitecture and propose a 128-bit processor microarchitecture, in a context where Dennard scaling and Moore's Law cannot be entirely trusted to absorb hardware cost <ref type="bibr" target="#b3">[4]</ref>. In particular, naively scaling datapaths and structures is bound to increase area, latency, and power consumption. A "business as usual" approach to 128bit microarchitecture is therefore likely to incur a performance penalty. Under the high-level assumption that integer width used in programs need not increase with the width of VAs, we propose to divide and conquer hardware complexity using clustering. Specifically, we architect the processor back-end around a 128-bit cluster mostly dedicated to address computations, while general purpose integer computations remain performed on a distinct 64-bit cluster.</p><p>Manuscript received 16 May 2023; revised 7 June 2023; accepted 15 June 2023. This work was supported by ANR project Maplurinum under Grant ANR21-CE25-0016. Chandana S. Deshpande, Arthur Perais and Fr?d?ric P?trot are with the TIMA, CNRS, Grenoble INP, University Grenoble Alpes, 38000 Grenoble, France (e-mail: chandana.deshpande@univ-grenoble-alpes.fr; arthur. perais@univ-grenoblealpes.fr; frederic.petrot@univ-grenoble-alpes.fr). Digital Object Identifier 10.1109/LCA.2023.3287762</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. NAIVE 128-BIT MICROARCHITECTURE</head><p>Despite opening access to more memory, naively supporting 128-bit VAs in a modern microarchitecture <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> by doubling datapath width and the size of specific structures will incur significant area, power and latency costs.</p><p>In Fetch, the iTLB tags (virtual page number, VPN) and data (physical page number, PPN) as well as I-Cache tags (PPN or VPN for VI* and PI* caches respectively) almost double in size. The BTB and indirect branch predictor data (VAs) suffer the same increase. BTB, direction and indirect branch predictor tags may not grow as full tags are not required. Nonetheless, iTLB, I-Cache, BTB and predictors area, power, and latency are impacted. In Decode, the predicted targets of direct branches are checked against the targets computed from the instruction bytes. Both comparison and computation now require 128-bit operators, whose latency scales logarithmically with operand width. Register Rename is not affected as the stage only manipulates register names, whose width depends on the number of registers, not their width. Dispatch is similarly not affected, as no operand value or address is manipulated. The exception is instruction PCs that are inserted in the Reorder Buffer (ROB) or a microarchitecturespecific FIFO to handle pipeline flushes. From the Scheduler, instructions are scheduled for execution if operands and a functional unit (FU) are available. Since operand values are not stored in the scheduler, the stage is not affected. However, once scheduled, the instructions read operands from either the Physical Register File (PRF) or bypass network. Their area, power and latency increase as 128-bit values are now stored and routed. The logic determining whether a value should be taken from the bypass network or the PRF is unchanged (comparison on the register name), and the muxes depth does not change, although the muxes are now wider. Broadly speaking, the latency of common functional units (ALU, shift, multiplication, division) grows linearly or better with operand width, while the area grows linearly or worse. Finally, on the data access side, dTLB and D-Cache suffer the same area, power and latency increase as the iTLB and I-Cache. Moreover, the Load/Store Queue area, power and latency increase as the structure is responsible for determining memory readafter-write hazards by comparing physical addresses (PAs) of incoming load/stores with PAs stored in LSQ entries. Since modern LSQ support 128-bit accesses for SIMD instructions, the data fields of LSQ entries remain unchanged.</p><p>To summarize, in the front-end, the transition to 128-bit mostly impacts caching structures, as the front-end does not deal with actual operand values. The exception is any control flow speculation or checking logic (e.g., next PC selection, direct target check in Decode). In the back-end, both storage (e.g., PRF, D-Cache) and logic (e.g., functional units, bypass network) are affected. Depending on the specific design, this could impact frequency, e.g., if the PRF read is the critical path. Combined with the increased footprint of pointers in memory, this transition will probably decrease overall performance.</p><p>The virtual memory paging structures may also be impacted. However, this would not impact first level TLBs who would still map a VPN to a PPN regardless of the page table structure. As a result, this letter does not discuss changes to the virtual memory structures themselves. Rather, our objective is to address part of the hardware overhead incurred by a 128-bit transition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. A PRACTICAL 128-BIT MICROARCHITECTURE</head><p>Implemented VA width will not initially be 128-bit, just as currently implemented VAs are not yet 64-bit <ref type="bibr" target="#b0">[1]</ref>. This significantly limits the increase in tag size in, e.g. TLBs. Moreover, techniques such as region-based compression <ref type="bibr" target="#b6">[7]</ref> can be leveraged to mitigate the increase in tag and/or data arrays of relevant structures. The idea is to map high-order bits to region identifiers (RIDs) such that structures store the lower bits and an RID, while a small table stores the higher bits mapped to each identifier. Since the tags (caches, TLBs, BTB, predictors) and -part of the-data (TLBs, BTB, LSQ, ROB) of the structures are addresses, they exhibit high locality. Therefore, given a sufficiently large region size, only a handful of RIDs (i.e., mapping table entries) are necessary to minimize RID reclamation, which is a costly operation. In the backend, the same scheme can be applied to the PRF, with lower efficiency. Indeed, the PRF contains both addresses and plain integers, which increases value entropy and implies more RIDs to minimize RID reclamations. Nevertheless, we note that despite the transition from 32-to 64-bit, some computations are still performed on 32-bit in current programs. In fact, the typical width of a C int is 32-bit. Moreover, although a 32-bit unsigned loop counter might not be enough to walk through a large structure, a 64-bit counter can cover any structure up to 16 Ei-entries. As a result, we hypothesize that future 128-bit programs will only use 128-bit instructions for address manipulation, as would be the case if an existing code source were taken and compiled for a 128-bit machine today. Under that assumption, we propose to divide and conquer the microarchitecture complexity using clustering.</p><p>In a nutshell, clustering partitions critical parts of the microarchitecture (scheduler, PRF, FUs, bypass network) into clusters and steers instructions to respective clusters using specific criteria. A steering mechanism is responsible for distributing instructions <ref type="bibr" target="#b7">[8]</ref>. Modern processors already implement integer and floating point clusters <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> and naturally steer instructions to clusters based on their type. However, address calculation is performed in the integer cluster: Addresses are treated as integers.</p><p>In this letter, we propose to implement a 128-bit cluster dedicated to executing instructions that manipulate addresses (loads, stores, indirect branches and all producers), and a 64bit cluster for other integer instructions. As a result, most values in the 128-bit PRF will be addresses, enabling highly efficient region-based compression of the structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. A Clustered 128-bit Address/Value Microarchitecture</head><p>This microarchitecture implements three clusters with dynamic steering: Address (A, 128 bits), integer (I, 64 bits), and FP/SIMD (FP, implementation dependent). The A and I clusters each maintain their own PRFs (128-and 64-bit respectively), and communication is transparent to the programmer. Each integer rename map table entry is augmented with a bit to determine if a value resides in the A or I cluster. If the steering policy finds that an instruction it is sending to the A cluster requires a value currently living in the I cluster, it will inject a copy ?-op in the pipeline to perform the copy, using an execution unit in the I cluster and dedicated cluster-to-cluster wires, incurring latency <ref type="bibr" target="#b8">[9]</ref>. Note that steering only applies to instructions that are not explicitly 128-bit (e.g., 64-bit or 32-bit arithmetic operations). Instructions that are explicitly 128-bit (e.g., 128-bit arithmetic operations) are trivially steered towards the 128-bit cluster. Depending on the percentage of instructions to steer to the 128-bit cluster as well as their nature (e.g., addition vs. multiplication), the hardware footprint of the A cluster may vary.</p><p>In the next section, we quantify the number of instructions that would be steered to the A cluster. We further highlight that region-based compression is indeed an adapted tool to mitigate the area increase of microarchitectural structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Framework</head><p>As RISC-V already features material for a 128-bit extension <ref type="bibr" target="#b2">[3]</ref>, we use the functional simulator Spike <ref type="bibr" target="#b9">[10]</ref> to study metrics in Polybench <ref type="bibr" target="#b10">[11]</ref> (standard inputs) and SPEC CPU 2017 speed <ref type="bibr" target="#b11">[12]</ref> (ref inputs). omnetpp, xalancbmk, pop2 and fotonik3d are excluded due to lack of system support by the proxy kernel provided with Spike.</p><p>For SPEC CPU 2017, we skip the first 100 B instructions to avoid the initialization phase of the workload, then run 10 B instructions. For Polybench, we run the first 10 B instructions. We analyze only 10 B because our first experiment maintains an arbitrarily large dependency graph of the execution in memory to gather statistics of interest. We assume that the current benchmarks are representative enough to draw meaningful conclusions for our experiments, as the nature of the future 128-bit workloads is still hypothetical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Quantifying Address Calculating Instructions:</head><p>The backward address slice (BAS) of address generating (AGEN) instructions (loads, stores, and indirect branches) is a directed graph with instruction nodes and register data dependency edges. The last node is the AGEN instruction, and all previous nodes are direct or indirect producers. To identify instructions on BASes, which would be steered to the address cluster, we build the dynamic register data dependency graph at runtime Fig. <ref type="figure">1</ref>: Percentage of dynamic instructions on (at least) a BAS. and walk it backwards for each AGEN instruction. The walk stops when an instruction does not have producers (e.g., load immediate) or when another load instruction is reached, as we separately build its own BAS. A comparable algorithm can be implemented in hardware to iteratively build BASes and drive the steering decision for instructions that are not explicitly 128-bit but are indirect or direct producers of AGEN instructions <ref type="bibr" target="#b12">[13]</ref>. Figure <ref type="figure">1</ref> shows that around 55% (INPSpeed), 58%(FPSpeed) and 63% (Polybench) of the dynamic instructions are on a BAS for a global average of 59%. Figure <ref type="figure">2</ref> further depicts that most non AGEN instructions on BASes are ALU or shift instructions. The number of div instructions on BASes is negligible, suggesting that a microcoded or purely software implementation of 128-bit division may be acceptable. The number of mul instructions is significant in a handful of cases: deriche, deepsjeng, exchange2 and nab. For instance, 79 M dynamic mul instructions are on a BAS in deepsjeng, with 43% of them in a single function, FindFirstRemove (deepsjeng/bits.cpp:49-53). As a result, a hardware 128-bit multiplier may be required to guarantee good performance in the address cluster. We also found that on average, 45%, 17% and 1% of the dynamic instructions are on load, store and indirect branches BASes. However, the ratio of the sum of dynamic instructions on the different BAS types to the number of dynamic instructions on BASes is on average 1.11, indicating that a moderate amount of dynamic instructions are on two or more BAS types. Despite implementing vastly different algorithms (especially SPEC), most workloads have a reasonably balanced utilization of the address and integer clusters. As a consequence, the address cluster will in fact require enough resources and especially functional units to deliver high throughput, although complex operations can be pushed to software to save area.</p><p>2) Region-based Compression: In addition to functional units, the address cluster will require a large enough instruction window to allow many instructions in flight in the cluster. This includes physical registers, which have now doubled in area, increasing access time as a side effect.</p><p>Fortunately, most values in the address cluster registers will be addresses. As a result, and as discussed in Section III, we can leverage region-based compression to not only compress tags and or data in caches, predictors and TLBs, but also greatly reduce the size of the physical registers in the address cluster.</p><p>For the PRF, a 128-bit datum is compressed before being written back to the PRF by matching the upper bits to an RID in the mapping table (associative search) and concatenating it with the lower bits. A compressed value is uncompressed after being read from the PRF by retrieving the upper bits corresponding to the RID in the mapping table (indexed read) and concatenating them to the lower bits of the compressed value.</p><p>For caches, BTB and predictors, similar operations are needed. For tag matches, the tag array is read in parallel to the mapping table being associatively searched with the VPN or PPN of the address of interest, and only the lower bits of the tag and RIDs are actually compared. Writing a new tag to the array also requires an associative search. For (VI/PI)PT instruction and data caches, a single mapping table associative search is needed to perform the TLB tag match followed by the cache tag match since the PPN is already compressed in the TLB data array. However, it is likely that two mapping tables will be required, one for PAs and one for VAs. Each compressed structure may implement its own table.</p><p>For the PRF, however, enough RIDs must be available to represent a valid architectural state. This means that we need at least 32 RIDs in case i) All architectural registers are currently in the address cluster PRF and ii) All architectural registers have different upper bits. This requirement will impact the timing of the mapping table, which is on the critical path of register reads (indexed read) and writes (associative search). An RID is reclaimed from the mapping table when a value that cannot be compressed using existing mappings is written to the PRF (or another structure that uses that mapping table). Reclaiming an RID requires ensuring that all the physical registers using that RID are unreachable. This can be done non-speculatively by waiting for the problematic instruction to reach Commit, flushing the pipeline, then reclaiming any RID not currently used by architectural registers living in the address cluster. If all RIDs are used, then each architectural register uses its own RID. Thus, the RID used by the architectural register being written can be reclaimed safely. While slow, this process is straightforward and the region size can be chosen such that reclamation is rare, at the cost of slightly less efficient compression. RID reclamation caused by ROB (PCs) and LSQ (PAs) would be handled similarly by waiting for the pipeline to drain and reclaiming an RID. For other structures (caches, TLBs, BTB), reclaiming an RID implies invalidating all the tags or data using that RID, which can be done non speculatively in an iterative fashion.</p><p>To determine what a good region size would be, we sample the number of unique regions being accessed every 40 M instructions (1 IPC @ 4GHz during 10 ms) for region sizes from 116 bits (4 KB region offset) to 92 bits (64 GB region offset), using only SPEC CPU 2017. We excluded Polybench from this experiment because the control flow is highly regular and prevents access to many unique memory regions within a sample. Figure <ref type="figure">3</ref>   regions for INTSpeed and FPSpeed). Using this region size would save 66% of the PRF storage if a 256-entry 128-bit PRF and a 32-entry RID table are considered. Nevertheless, future machines running workloads with large datasets could want to consider smaller regions to ensure region identifier reclamation remains rare. For instance, using a region size of 94 upper bits (16 GB region offset) would still save 60% of the PRF storage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RELATED WORK</head><p>State of the art clustered microarchitectures can be categorised as homogeneous or heterogeneous. In the former, an instruction may be executed by multiple identical clusters <ref type="bibr" target="#b13">[14]</ref>, and each cluster maintains a copy of the physical register file. Conversely, in heterogeneous clustering, instructions have to be executed in a specific cluster <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, each featuring their own disjoint register files. Our proposal is a form of heterogeneous clustering, although some instructions can technically be executed on both A and I clusters (e.g. 64-bit add initially executing on I cluster before it is determined to belong to a BAS). However, in existing heterogeneous designs, transferring values between clusters is done through memory using loads and stores or directly using dedicated instructions <ref type="bibr" target="#b2">[3]</ref>, as the clusters usually own different portion of the architectural registers (e.g., integer vs. FP). Since both A and I clusters own the integer architectural registers, value transfer between clusters is done implicitly by the hardware. Steering can be performed dynamically in hardware or statically by the compiler. The former does not require ISA change and generally performs better as the compiler does not have all the dynamic latency information that hardware does <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Since out-of-order machines are notorious for their latency variability, dynamic steering appears the natural choice. Regarding 128-bit machines, only RISC-V defines a flat 128-bit general purpose extension <ref type="bibr" target="#b2">[3]</ref>. However, no actual 128-bit microarchitectures implementing this extension ISA have been proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION AND FUTURE WORK</head><p>This letter proposes an efficient 128-bit microarchitecture. Instructions are steered to the dedicated 128-bit address cluster by iteratively learning <ref type="bibr" target="#b12">[13]</ref> the backward address slices (BAS) of address generating instructions. Other 64-and 32-bit instructions are steered to the cheaper 64-bit cluster. This letter showed that this would allow around 41% of the dynamic instructions to not consume 128-bit resources, on average, under the hypothesis that non address related integer computations would remain performed on 32 or 64 bits when compiling for a 128-bit machine. We further suggest to leverage an existing region-based compression scheme to significantly reduce the footprint of many common structures, including the 128-bit physical register file in the address cluster.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>depicts the average number of accessed regions per sample, across all 40 M samples, for each region size, for each workload. The Figure confirms the intuition that as the region size grows, the number of regions accessed within an epoch increases. In this experiment, using a region size of 102 upper bits (64 MB region offset) yields fewer than 32 regions tracked within an epoch, on average (19 and 13</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :Fig. 3 :</head><label>23</label><figDesc>Fig. 2: Dynamic distribution of instruction type on BAS (Groups from L to R: Polybench, INTSpeed, FPSpeed)</figDesc><graphic url="image-7.png" coords="5,75.33,202.00,198.34,118.78" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.intel.com/content/www/us/en/content-details/671442/5-level-paging-and-5-level-ept-white-paper.html" />
		<title level="m">5-Level Paging and 5-Level EPT</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="31" />
		</imprint>
		<respStmt>
			<orgName>Intel Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Zettalinux: It&apos;s not too late to start</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wilcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linux Plumbers Conference</title>
		<imprint>
			<date type="published" when="2022-09">Sep. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Volume I: User-Level ISA, Document Version 2.2</title>
		<author>
			<persName><forename type="first">Risc-V</forename><surname>Foundation</surname></persName>
		</author>
		<ptr target="https://riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf" />
	</analytic>
	<monogr>
		<title level="m">The RISC-V Instruction Set Manual</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A New Golden Age for Computer Architecture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. of the ACM</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="60" />
			<date type="published" when="2019-01">Jan. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The amd &quot;zen 2&quot; processor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Suggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subramony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bouvier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>IEEE Micro</publisher>
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Intel Alder Lake CPU Architectures</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yoaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Mandelblat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gihon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weissmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chabukswar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Basin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yasin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>IEEE Micro</publisher>
			<biblScope unit="page" from="13" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Don&apos;t use the page number, but a pointer to it</title>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Symp. on Computer Architecture</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="104" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Revisiting clustered microarchitecture for future superscalar cores: A case for wide issue clusters</title>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mondelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Arch. and Code Optim</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic cluster assignment mechanisms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Canal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parcerisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Symp. on High-Performance Computer Architecture</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">"</forename><surname>Risc-V Foundation</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Risc-V Isa</forename><surname>Spike</surname></persName>
		</author>
		<author>
			<persName><surname>Simulator</surname></persName>
		</author>
		<ptr target="https://github.com/riscv-software-src/riscv-isa-sim/tree/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>a0298a33e7b2091ba8d9f3a20838d96dc1164cac</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Polybench: The polyhedral benchmark suite</title>
		<author>
			<persName><forename type="first">L.-N</forename><surname>Pouchet</surname></persName>
		</author>
		<ptr target="http://www.cs.ucla.edu/pouchet/software/polybench" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Standard Performance Evaluation Corporation</title>
		<ptr target="https://www.spec.org/cpu" />
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>SPEC CPU</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The load slice core microarchitecture</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Allam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. Symp. on Computer Architecture</title>
		<imprint>
			<biblScope unit="page" from="272" to="284" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The alpha 21264 microprocessor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE micro</title>
		<imprint>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
