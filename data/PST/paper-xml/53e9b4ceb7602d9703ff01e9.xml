<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">U NIMODAL biometric systems rely on a single source of information such as a single iris or fingerprint or face for authentication [1]. Unfortunately, these systems have to deal with some of the following inevitable problems [2]</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-06-10">10 June 2013.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">V</forename><forename type="middle">S M</forename><surname>Shekhar</surname></persName>
							<email>sshekha@umiacs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Center for Automation Research</orgName>
								<orgName type="institution" key="instit1">UMIACS</orgName>
								<orgName type="institution" key="instit2">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">R</forename><surname>Patel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Center for Automation Research</orgName>
								<orgName type="institution" key="instit1">UMIACS</orgName>
								<orgName type="institution" key="instit2">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Chellappa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Center for Automation Research</orgName>
								<orgName type="institution" key="instit1">UMIACS</orgName>
								<orgName type="institution" key="instit2">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="middle">N M</forename><surname>Nasrabadi</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Army Research Lab</orgName>
								<orgName type="institution">U.S</orgName>
								<address>
									<postCode>20783</postCode>
									<settlement>Adelphi</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">U NIMODAL biometric systems rely on a single source of information such as a single iris or fingerprint or face for authentication [1]. Unfortunately, these systems have to deal with some of the following inevitable problems [2]</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-06-10">10 June 2013.</date>
						</imprint>
					</monogr>
					<idno type="MD5">3864A47ABA554810365980F3029A0F5F</idno>
					<idno type="DOI">10.1109/TPAMI.2013.109</idno>
					<note type="submission">received 27 Aug. 2012; revised 11 Mar. 2013; accepted 28 May 2013;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multimodal biometrics</term>
					<term>feature fusion</term>
					<term>sparse representation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditional biometric recognition systems rely on a single biometric signature for authentication. While the advantage of using multiple sources of information for establishing the identity has been widely recognized, computational models for multimodal biometrics recognition have only recently received attention. We propose a multimodal sparse representation method, which represents the test data by a sparse linear combination of training data, while constraining the observations from different modalities of the test subject to share their sparse representations. Thus, we simultaneously take into account correlations as well as coupling information among biometric modalities. A multimodal quality measure is also proposed to weigh each modality as it gets fused. Furthermore, we also kernelize the algorithm to handle nonlinearity in data. The optimization problem is solved using an efficient alternative direction method. Various experiments show that the proposed method compares favorably with competing fusion-based methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. Noisy data. Poor lighting on a user's face or occlusion are examples of noisy data. 2. Nonuniversality. The biometric system based on a single source of evidence may not be able to capture meaningful data from some users. For instance, an iris biometric system may extract incorrect texture patterns from the iris of certain users due to the presence of contact lenses. 3. Intraclass variations. In the case of fingerprint recognition, the presence of wrinkles due to wetness <ref type="bibr" target="#b2">[3]</ref> can cause these variations. These types of variations often occur when a user incorrectly interacts with the sensor. 4. Spoof attack. Hand signature forgery is an example of this type of attack. It has been observed that some of the limitations of unimodal biometric systems can be addressed by deploying multimodal biometric systems that essentially integrate the evidence presented by multiple sources of information such as iris, fingerprints, and face. Such systems are less vulnerable to spoof attacks, as it would be difficult for an imposter to simultaneously spoof multiple biometric traits of a genuine user. Due to sufficient population coverage, these systems are able to address the problem of nonuniversality.</p><p>Classification in multibiometric systems is done by fusing information from different biometric modalities. Information fusion can be done at different levels, broadly divided into feature-level, score-level, and rank-/decisionlevel fusion. Due to preservation of raw information, feature-level fusion can be more discriminative than scoreor decision-level fusion <ref type="bibr" target="#b3">[4]</ref>. But, feature-level fusion methods have been explored in the biometric community only recently. This is because of the differences in features extracted from different sensors in terms of types and dimensions. Often features have large dimensions, and fusion becomes difficult at the feature level. The prevalent method is feature concatenation, which has been used for different multibiometric settings <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. However, for high-dimensional feature vectors, simple feature concatenation may be inefficient and nonrobust. A related work in the machine learning literature is multiple kernel learning (MKL), which aims to integrate information from different features by learning a weighted combination of respective kernels. A detailed survey of MKL-based methods can be found in <ref type="bibr" target="#b7">[8]</ref>. However, for multimodal systems, weight determination during testing is important, based on the quality of modalities. Also, a corrupted test sample from a modality must be rejected by the algorithm. Such a framework is not yet feasible in the MKL settings. Methods like those given in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> try to exploit information from data from a different view to improve classifier performance. However, <ref type="bibr" target="#b8">[9]</ref> being an unsupervised technique, is not suited for classification tasks, and <ref type="bibr" target="#b9">[10]</ref> reduces to the MKL framework in a supervised setting. Similarly, SVM-2k <ref type="bibr" target="#b10">[11]</ref> jointly learns SVM for two views, while maximizing the agreement between the projections of data from the two views . It is, however, not clear how this can be extended to multiple views, which is common in multimodal biometrics. A Fisher-discriminant-analysis-based method has also been proposed for integrating multiple views in <ref type="bibr" target="#b11">[12]</ref>, but it is also similar to MKL with kernel Fisher discriminant analysis as the base learner <ref type="bibr" target="#b12">[13]</ref>.</p><p>In recent years, theories of sparse representation (SR) and compressed sensing (CS) have emerged as powerful tools for efficient processing of data in nontraditional ways <ref type="bibr" target="#b13">[14]</ref>. This has led to a resurgence in interest in the principles of SR and CS for biometrics recognition <ref type="bibr" target="#b14">[15]</ref>. Wright et al. <ref type="bibr" target="#b15">[16]</ref> proposed the seminal sparse representation-based classification (SRC) algorithm for face recognition. It was shown that by exploiting the inherent sparsity of data, one can obtain improved recognition performance over traditional methods especially when data are contaminated by various artifacts such as illumination variations, disguise, occlusion, and random pixel corruption. Pillai et al. <ref type="bibr" target="#b16">[17]</ref> extended this work for robust cancelable iris recognition. Nagesh and Li <ref type="bibr" target="#b17">[18]</ref> presented an expression-invariant face recognition method using distributed CS and joint sparsity models. Patel et al. <ref type="bibr" target="#b18">[19]</ref> proposed a dictionary-based method for face recognition under varying pose and illumination. A discriminative dictionary learning method for face recognition was also proposed by Zhang and Li <ref type="bibr" target="#b19">[20]</ref>. For a survey of applications of SR and CS algorithms to biometric recognition, see <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> and the references therein.</p><p>Motivated by the success of SR in unimodal biometric recognition, we propose a joint sparsity-based algorithm for multimodal biometrics recognition. Fig. <ref type="figure" target="#fig_0">1</ref> presents an overview of our framework. It is based on the well-known regularized regression method, multitask multivariate Lasso <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. The proposed method imposes common sparsities both within each biometric modality and across different modalities. The idea of joint sparsity has been explored recently for image classification <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> and segmentation <ref type="bibr" target="#b27">[28]</ref>. However, our method is different from these previously proposed algorithms based on joint sparse representation for classification. For example, Yuan and Yan <ref type="bibr" target="#b26">[27]</ref> proposed a multitask sparse linear regression model for image classification. This method uses group sparsity to combine different features of an object for classification. Zhang et al. <ref type="bibr" target="#b25">[26]</ref> proposed a joint dynamic sparse representation model for object recognition. Their essential goal was to recognize the same object viewed from multiple observations, i.e., different poses. Our method is more general in that it can deal with both multimodal as well as multivariate sparse representations.</p><p>This paper makes the following contributions:</p><p>. We present a robust feature level fusion algorithm for multibiometric recognition. Through the proposed joint sparse framework, we can easily handle unequal dimensions from different modalities by forcing the different features to interact through their sparse coefficients. Furthermore, the proposed algorithm can efficiently handle large-dimensional feature vectors. . We make the classification robust to occlusion and noise by introducing an error term in the optimization framework. . The algorithm is easily generalizable to handle multiple test inputs from a modality. . We introduce a quality measure for multimodal fusion based on the joint sparse representation. . Last, we kernelize the algorithm to handle nonlinearity in the data samples. A preliminary version of this work appeared in <ref type="bibr" target="#b28">[29]</ref>, which describes just the linear version of the algorithm, robust to noise and occlusion. Furthermore, extensive experimental evaluations are presented here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Paper Organization</head><p>The paper is organized as follows: In Section 2, we describe the proposed sparsity-based multimodal recognition algorithm, which is kernelized in Section 4. The quality measure is described in Section 3. Experimental evaluations on a comprehensive multimodal data set and a face database are described in Section 5. Finally, in Section 6, we discuss the computational complexity of the method. Concluding remarks are presented in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">JOINT SPARSITY-BASED MULTIMODAL BIOMETRICS RECOGNITION</head><p>Consider a multimodal C-class classification problem with D different biometric traits. Suppose there are p ¼ P C j¼1 p j training samples in each biometric trait, where p j is the number of training samples in class j. For each biometric trait i ¼ 1; . . . ; D, we denote  <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b29">[30]</ref>.</p><formula xml:id="formula_0">X i ¼ Â X i 1 ; X i 2 ; . . . ; X i C Ã as an n i Â p dictionary of training samples consisting of C subdictionaries X i k corresponding to C different classes. Each subdictionary X i j ¼ Â x i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multimodal Multivariate Sparse Representation</head><p>We propose to exploit the joint sparsity of coefficients from different biometric modalities to make a joint decision. To simplify this model, let us consider a bimodal classification problem where the test sample Y ¼ ½Y 1 ; Y 2 consists of two different modalities such as iris and face. Suppose that Y 1 belongs to the jth class. Then, it can be reconstructed by a linear combination of the atoms in the subdictionary</p><formula xml:id="formula_1">X 1 j . That is, Y 1 ¼ X 1 À 1 þ N 1 ,</formula><p>where À 1 is a sparse matrix with only p j nonzero rows associated with the jth class and N 1 is the noise matrix. Similarly, since Y 2 represents the same subject, it belongs to the same class and can be represented by training samples in X 2 j with different sets of coefficients À 2 j . Thus, we can write</p><formula xml:id="formula_2">Y 2 ¼ X 2 À 2 þ N 2</formula><p>, where À 2 is a sparse matrix that has the same sparsity pattern as À 1 . If we let À ¼ ½À 1 ; À 2 , then À is a sparse matrix with only p j nonzero rows, as both Y 1 and Y 2 are represented by samples of the jth class.</p><p>In the more general case where we have D modalities, if we denote fY i g D i¼1 as a set of D observations each consisting of d i samples from each modality and let À ¼ ½À 1 ; À 2 ; . . . ; À D 2 IR pÂd be the matrix formed by concatenating the coefficient matrices with d ¼ P D i¼1 d i , then we can determine the row-sparse matrix À by solving the following ' 1 =' q -regularized least-squares problem:</p><formula xml:id="formula_3">À ¼ arg min À 1 2 X D i¼1 kY i À X i À i k 2 F þ kÀk 1;q ;<label>ð1Þ</label></formula><p>where is a positive parameter and q is set greater than 1 to make the optimization problem convex. Here, kÀk 1;q is a norm defined as kÀk 1;q ¼ P p k¼1 k k k q , where k s are the row vectors of À and kYk F is the Frobenius norm of the matrix Y defined as kYk F ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P i;j Y 2 i;j q . The ' 1 =' q regularization seeks a solution with sparse nonzero rows; hence, we get a representation consistent across all the modalities. Once À is obtained, the class label associated with an observed vector is then declared as the one that produces the smallest approximation error:</p><formula xml:id="formula_4">ĵ ¼ arg min j X D i¼1 Y i À X i i j ðÀ i Þ 2 F ;<label>ð2Þ</label></formula><p>where i j is the matrix indicator function defined by keeping rows corresponding to the jth class and setting all other rows equal to zero. Note that the optimization problem (1) reduces to the conventional Lasso <ref type="bibr" target="#b30">[31]</ref> when D ¼ 1 and d ¼ 1. In the case when D ¼ 1, (1) is referred to as multivariate Lasso <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Robust Multimodal Multivariate Sparse Representation</head><p>In this section, we consider a more general problem where the data are contaminated by noise. In this case, the observation model can be modeled as</p><formula xml:id="formula_5">Y i ¼ X i À i þ Z i þ N i ; i ¼ 1; . . . ; D;<label>ð3Þ</label></formula><p>where N i is a small dense additive noise and Z i 2 IR n i Âd i is a matrix of background noise (occlusion) with arbitrarily large magnitude. One can assume that each Z i is sparsely represented in some basis</p><formula xml:id="formula_6">B i 2 IR n i Âm i . That is, Z i ¼ B i Ã i for some sparse matrices Ã i 2 IR miÂdi .</formula><p>For simplicity, we assume B i to be orthonormal in this paper. Hence, (3) can be rewritten as</p><formula xml:id="formula_7">Y i ¼ X i À i þ B i Ã i þ N i ; i ¼ 1; . . . ; D:<label>ð4Þ</label></formula><p>With this model, one can simultaneously recover the coefficients À i and Ã i by taking advantage of the fact that Ã i are sparse:</p><formula xml:id="formula_8">À; Ã ¼ arg min À;Ã 1 2 X D i¼1 kY i À X i À i À B i Ã i k 2 F þ 1 kÀk 1;q þ 2 kÃk 1 ;<label>ð5Þ</label></formula><p>where 1 and 2 are positive parameters and Ã ¼ ½Ã 1 ; Ã 2 ; . . . ; Ã D is the sparse coefficient matrix corresponding to occlusion. The ' 1 -norm of matrix Ã is defined as kÃk 1 ¼ P i;j jÃ i;j j. Note that the idea of exploiting the sparsity of occlusion term has been studied by Wright et al. <ref type="bibr" target="#b15">[16]</ref> and Candes et al. <ref type="bibr" target="#b31">[32]</ref>.</p><p>Once À; Ã are computed, the effect of occlusion can be removed by setting Ỹi ¼ Y i À B i Ã i . One can then declare the class label associated with an observed vector as</p><formula xml:id="formula_9">ĵ ¼ arg min j X D i¼1 Y i À X i i j ðÀ i Þ À B i Ã i 2 F :<label>ð6Þ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Optimization Algorithm</head><p>The optimization problem ( <ref type="formula" target="#formula_8">5</ref>) is convex but difficult to solve due to the joint sparsity constraint. In this section, we present an approach based on the classical alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> to solve <ref type="bibr" target="#b4">(5)</ref>. Note that the optimization problem (1) can be solved by setting 2 equal to infinity. Let</p><formula xml:id="formula_10">CðÀ; ÃÞ ¼ 1 2 X D i¼1 Y i À X i À i À B i Ã i 2 F :</formula><p>Then, our goal is to solve the following optimization problem:</p><formula xml:id="formula_11">min À;Ã CðÀ; ÃÞ þ 1 kÀk 1;q þ 2 kÃk 1 :<label>ð7Þ</label></formula><p>In ADMM, the idea is to decouple CðÀ; ÃÞ, kÀk 1;q , and kÃk 1 by introducing auxiliary variables to reformulate the problem into a constrained optimization problem</p><formula xml:id="formula_12">min À;Ã;U;V CðÀ; ÃÞ þ 1 kVk 1;q þ 2 kU Uk 1 s:t: À ¼ V; Ã ¼ U:<label>ð8Þ</label></formula><p>Since ( <ref type="formula" target="#formula_12">8</ref>) is an equally constrained problem, the augmented Lagrangian method (ALM) <ref type="bibr" target="#b32">[33]</ref> can be used to solve the problem. This can be done by minimizing the augmented Lagrangian function f À; Ã ðÀ; Ã; V; U; A Ã ; A À Þ defined as</p><formula xml:id="formula_13">CðÀ; ÃÞ þ 2 kUk 1 þ hA Ã ; Ã À Ui þ Ã 2 kÃ À Uk 2 F þ 1 kVk 1;q þ hA À ; À À Vi þ À 2 kÀ À Vk 2 F ;<label>ð9Þ</label></formula><p>where A Ã and A À are the multipliers of the two linear constraints, and Ã ; À are the positive penalty parameters.</p><p>The ALM algorithm solves f À; Ã ðÀ; Ã; V; U; A Ã ; A À Þ with respect to À, Ã, U, and V jointly, keeping A À and A Ã fixed and then updating A À and A Ã keeping the remaining variables fixed. Due to the separable structure of the objective function f À; Ã , one can further simplify the problem by minimizing f À ; Ã with respect to variables À, Ã, U, and V, separately. Different steps of the algorithm are given in Algorithm 1. In what follows, we describe each of the suboptimization problems in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Alternating Direction Method of Multipliers (ADMM).</head><p>Initialize:</p><formula xml:id="formula_14">À 0 ; U 0 ; V 0 ; A Ã;0 ; A À;0 ; À ; Ã While not converged do 1. À tþ1 ¼ arg min À f À ; Ã ðÀ; Ã t ; U t ; V t ; A À;t ; A Ã;t Þ 2. Ã tþ1 ¼ arg min Ã f À ; Ã ðÀ tþ1 ; Ã; U t ; V t ; A À;t ; A Ã;t Þ 3. U tþ1 ¼ arg min U f À ; Ã ðÀ tþ1 ; Ã tþ1 ; U; V t ; A À;t ; A Ã;t Þ 4. V tþ1 ¼ arg min V f À ; Ã ðÀ tþ1 ; Ã tþ1 ; U tþ1 ; V; A À;t ; A Ã;t Þ 5. A À;tþ1 ¼ : A À;t þ À ðÀ tþ1 À V tþ1 Þ 6. A Ã;tþ1 ¼ : A Ã;t þ Ã ðÃ tþ1 À U tþ1 Þ 2.3.1 Update Step for À</formula><p>The first suboptimization problem involves the minimization of f À ; Ã ðÀ; Ã; V; U; A Ã ; A À Þ with respect to À. It has the quadratic structure, which is easy to solve by setting the first-order derivative equal to zero. Furthermore, the loss function CðÀ; ÃÞ is a sum of convex functions associated with sub-matrices À i , one can seek for À i tþ1 , i ¼ 1; . . . ; D, which has the following solution:</p><formula xml:id="formula_15">À i tþ1 ¼ À X i T X i þ À I Á À1 À X i T À Y i À B i À i t Á þ À V i t À A i À;t Á ;</formula><p>where I is the p Â p identity matrix and Ã i t , À i t , and A i À;t are submatrices of Ã t , À t , and A À;t , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Update Step for Ã</head><p>The second suboptimization problem is similar in nature; its solution is given below:</p><formula xml:id="formula_16">Ã i tþ1 ¼ À B i T B i þ Ã I Á À1 À B i T À Y i À X i À i tþ1 Á þ Ã U i t À A i Ã;t Á ;</formula><p>where U i t and A i Ã;t are submatrices of U t and A Ã;t , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Update Step for U</head><p>The third suboptimization problem is with respect to U, which is the standard ' 1 minimization problem that can be recast as</p><formula xml:id="formula_17">min U 1 2 Ã tþ1 þ À1 Ã A Ã;t À U 2 F þ 2 Ã kUk 1 :<label>ð10Þ</label></formula><p>Equation ( <ref type="formula" target="#formula_17">10</ref>) is the well-known shrinkage problem whose solution is given by</p><formula xml:id="formula_18">U tþ1 ¼ S Ã tþ1 þ À1 Ã A Ã;t ; 2 Ã ;</formula><p>where Sða; bÞ ¼ sgnðaÞðjaj À bÞ for jaj ! b and zero otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Update Step for V</head><p>The final suboptimization problem is with respect to V, which can be reformulated as</p><formula xml:id="formula_19">min V 1 2 À tþ1 þ À1 À A À;t À V 2 F þ 1 À kVk 1;q :<label>ð11Þ</label></formula><p>Due to the separable structure of <ref type="bibr" target="#b10">(11)</ref>, it can be solved by minimizing with respect to each row of V separately. Let i;tþ1 , a À;i;t , and v i;tþ1 be rows of matrices À tþ1 , A À;t and V tþ1 , respectively. Then for each i ¼ 1; . . . ; p, we solve the following subproblem:</p><formula xml:id="formula_20">v i;tþ1 ¼ arg min v 1 2 kz À vk 2 2 þ kvk q ;<label>ð12Þ</label></formula><p>where z ¼ i;tþ1 þ a À;i;t À1 À and ¼ 1 À . One can derive the solution for <ref type="bibr" target="#b11">(12)</ref> for any q. In this paper, we only focus on the case when q ¼ 2. The solution of (12) has the following form:</p><formula xml:id="formula_21">v i;tþ1 ¼ 1 À kzk 2 þ z;</formula><p>where ðcÞ þ is a vector with entries receiving values maxðc i ; 0Þ.</p><p>Our proposed sparse multimodal biometrics recognition (SMBR) method is summarized in Algorithm 2. We refer to the robust method that takes sparse error into account as SMBR-E (SMBR with error), and the initial case where it is not taken into account as SMBR-WE (SMBR without error).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2. Sparse Multimodal Biometrics Recognition (SMBR).</head><p>Input: Training samples fX i g D i¼1 , test sample fY i g D i¼1 , Occlusion basis fBg D i¼1 Procedure: Obtain À and Ã by solving</p><formula xml:id="formula_22">À; Ã ¼ arg min À;Ã 1 2 X D i¼1 kY i À X i À i À B i Ã i k 2 F þ 1 kÀk 1;q þ 2 kÃk 1 Output: identityðYÞ ¼ arg min j P D i¼1 kY i À X i i j ð Ài Þ À B i Ãi k 2 F 3 QUALITY-BASED FUSION</formula><p>Ideally, a fusion mechanism should give more weights to the more reliable modalities. Hence, the concept of quality is important in multimodal fusion. A quality measure based on sparse representation was introduced for faces in <ref type="bibr" target="#b15">[16]</ref>. To decide whether a given test sample has good quality or not, its sparsity concentration index (SCI) was calculated. Given a coefficient vector 2 IR p , the SCI is given as</p><formula xml:id="formula_23">SCIð Þ ¼ C:max j2f1;...;Cg kjð Þk1 k k 1 À 1 C À 1 ;</formula><p>where j is the indicator function keeping the coefficients corresponding to the jth class and setting others to zero. SCI values close to 1 correspond to the case where the test sample can be represented well using the samples of a single class, hence are of high quality. On the other hand, samples with SCI close to 0 are not similar to any of the classes, and hence are of poor quality. This can be easily extended to the multimodal case using the joint sparse representation matrix À À. In this case, we can define the quality, q i j , for sample y i j as</p><formula xml:id="formula_24">q i j ¼ SCIð Ài j Þ;</formula><p>where Ài j is the jth column of Ài . Given this quality measure, the classification rule (2) can be modified to include the quality measure:</p><formula xml:id="formula_25">ĵ ¼ arg min j X D i¼1 X d i k¼1 q i k ky i k À X i j ðÀ i k Þk 2 F ;<label>ð13Þ</label></formula><p>where j is the indicator function retaining the coefficients corresponding to jth class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">KERNEL SPACE MULTIMODAL BIOMETRICS RECOGNITION</head><p>The class identities in the multibiometric data set may not be linearly separable. Hence, we also extend the sparse multimodal fusion framework to kernel space. The kernel function, : IR n Â IR n , is defined as the inner product</p><formula xml:id="formula_26">ðx i ; x j Þ ¼ hðx i Þ; ðx j Þi;</formula><p>where is an implicit mapping projecting the vector x into a higher dimensional space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multivariate Kernel Sparse Representation</head><p>Considering the general case of D modalities with fY i g D i¼1 as a set of d i observations, the feature space representation can be written as</p><formula xml:id="formula_27">ÈðY i Þ ¼ Â À y i 1 Á ; À y i 2 Á ; . . . ; À y i d ÁÃ :</formula><p>Similarly, the dictionary of training samples for modality i ¼ 1; . . . ; D can be represented in feature space as</p><formula xml:id="formula_28">ÈðX i Þ ¼ Â À X i 1 Á ; À X i 2 Á ; . . . ; À X i C ÁÃ :</formula><p>As in joint linear space representation, we have</p><formula xml:id="formula_29">ÈðY i Þ ¼ ÈðX i ÞÀ i ;</formula><p>where À i is the coefficient matrix associated with modality i.</p><p>Incorporating information from all the sensors, we seek to solve the following optimization problem similar to the linear case:</p><formula xml:id="formula_30">À ¼ arg min À 1<label>2</label></formula><formula xml:id="formula_31">X D i¼1 kÈðY i Þ À ÈðX i ÞÀ i k 2 F þ kÀk 1;q ;<label>ð14Þ</label></formula><p>where À ¼ ½À 1 ; À 2 ; . . . ; À D . It is clear that the information from all modalities is integrated via the shared sparsity pattern of the matrices fÀ i g D i¼1 . This can be reformulated in terms of kernel matrices as</p><formula xml:id="formula_32">À ¼ arg min À 1 2 X D i¼1 À trace À À i T K X i ;X i À i Á À 2trace À K Xi;Yi À i ÁÁ þ kÀk 1;q ;<label>ð15Þ</label></formula><p>where the kernel matrix K A;B is defined as</p><formula xml:id="formula_33">K A;B ði; jÞ ¼ hða i Þ; ðb j Þi;<label>ð16Þ</label></formula><p>a i and b j being ith and jth columns of A and B, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimization Algorithm</head><p>Similarly to the linear fusion method, we apply the alternating direction method to efficiently solve the problem for kernel fusion. This is done by introducing a new variable V and reformulating the problem (15) as</p><formula xml:id="formula_34">arg min À;V 1 2 X D i¼1 À trace À À i T K X i ;X i À i Á À 2trace À K X i ;Y i À i ÁÁ þ kVk 1;q s:t: À ¼ V:<label>ð17Þ</label></formula><p>Rewriting the problem using the Lagrangian multiplier P À , the optimization problem becomes</p><formula xml:id="formula_35">arg min À;V 1 2 X D i¼1 À trace À À i T K X i ;X i À i Á À 2trace À K X i ;Y i À i ÁÁ þ kVk 1;q þ hP À ; À À Vi þ À 2 À À V 2 F ;<label>ð18Þ</label></formula><p>where À is a positive penalty parameter. This upon rearranging reduces to</p><formula xml:id="formula_36">arg min À;V 1 2 X D i¼1 À trace À À i T K X i ;X i À i Á À 2trace À K X i ;Y i À i ÁÁ þ kVk 1;q þ À 2 À À V þ 1 À P À 2 F :<label>ð19Þ</label></formula><p>Now, ( <ref type="formula" target="#formula_36">19</ref>) can be solved in a similar way as the linear fusion problem in <ref type="bibr" target="#b4">(5)</ref>. The optimization method is summarized in Algorithm 3. It should be pointed out that each step has a simple closed-form expression.</p><p>Algorithm 3. Alternating Direction Method of Multipliers (ADMM) in kernel space.</p><formula xml:id="formula_37">Initialize: À 0 ; V 0 ; B 0 ; À While not converged do 1. À tþ1 ¼ arg min À 1 2 P D i¼1 ðtraceðÀ i T K X i ;X i À i Þ À 2traceðK X i ;Y i À i ÞÞ þ kV t k 1;q þ À 2 À À V t þ 1 À P À;t 2 F 2. V tþ1 ¼ arg min V kVk 1;q þ À 2 À tþ1 À V þ 1 À P À;t 2 F 3. P À;tþ1 ¼ P À;t þ À ðÀ tþ1 À V tþ1 Þ 4.</formula><p>2.1 Update Steps for À t À tþ1 is obtained by updating each submatrix À i t , i ¼ 1; . . . ; D, as</p><formula xml:id="formula_38">À i t ¼ ðK X i ;X i þ À IÞ À1 À K X i ;Y i þ À V i t À P i À;t Á ;<label>ð20Þ</label></formula><p>where I is an identity matrix, and V i t and P i À;t are submatrices of V t and P À;t , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Update Steps for V t</head><p>The update equation for V t is the same as in the linear fusion case using <ref type="bibr" target="#b10">(11)</ref> and ( <ref type="formula" target="#formula_20">12</ref>), replacing A À;t and À with P À;t and À , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification</head><p>Once À is obtained, classification can be done by assigning the class label as</p><formula xml:id="formula_39">ĵ ¼ arg min j X D i¼1 ÈðY i Þ À È À X i j Á Ài j 2 F ;</formula><p>or in terms of kernel matrices as</p><formula xml:id="formula_40">ĵ ¼ arg min j X D i¼1 traceðK Y;Y Þ À 2trace Ài T j K X i j ;Y Ài j þ trace Ài T j K X i j ;X i j Ài j :<label>ð21Þ</label></formula><p>Here, X i j is the subdictionary associated with the jth class and Ài j is the coefficient matrix associated with this class. The classification rule can be further extended to include the quality measure as in <ref type="bibr" target="#b12">(13)</ref>. But, we skip this step here as we wish to study the effect of kernel representation and quality separately.</p><p>Multivariate </p><formula xml:id="formula_41">P D i¼1 À traceðÀ i T K X i ;X i À i Þ À 2traceðK X i ;Y i À i Þ Á þ kÀk 1;q Output: identityðYÞ ¼ arg min j P D i¼1 ðtraceðK Y;Y Þ À 2traceð Ài T j K X i j ;Y Ài j Þ þ traceð Ài T j K X i j ;X i j Ài j ÞÞ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We evaluated our algorithm on two publicly available data sets-the WVU multimodal data set <ref type="bibr" target="#b34">[35]</ref> and the AR face data set <ref type="bibr" target="#b35">[36]</ref>. In the first experiment, we tested on the WVU data set, which is one of the few publicly available data sets that allows fusion at the image level. It is a challenging data set consisting of samples from different biometric modalities for each subject.</p><p>In the second experiment, we show the applicability of the proposed approach to fusing information from weak biometrics extracted from face images. In particular, the periocular region has been shown to be a useful biometric <ref type="bibr" target="#b36">[37]</ref>. Similarly, the nose region has also been explored as a biometric <ref type="bibr" target="#b37">[38]</ref>. Sinha et al. <ref type="bibr" target="#b38">[39]</ref> have demonstrated that eyebrows are important for face recognition. However, each of these subregions may not be as discriminative as the whole face. The challenge for fusion algorithms is to be able to combine these weak modalities with a strong modality based on the whole face <ref type="bibr" target="#b39">[40]</ref>. We demonstrate how our framework can be extended to address this problem. Furthermore, we also show the effects of noise and occlusion on the performance of different algorithms. In all the experiments, B i was set to be identity for convenience, i.e., we assume background noise to be sparse in the image domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">WVU Multimodal Data Set</head><p>The WVU multimodal data set is a comprehensive collection of different biometric modalities such as fingerprint, iris, palmprint, hand geometry, and voice from subjects of different age, gender, and ethnicity, as described in Table <ref type="table" target="#tab_2">1</ref>. It is a challenging data set, as many of these samples are corrupted with blur, occlusion, and sensor noise, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Out of these, we chose iris and fingerprint modalities for testing the proposed algorithms. In total, there are two iris (right and left iris) and four fingerprint modalities. Also, the evaluation was done on a subset of 219 subjects having samples in both modalities.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Preprocessing</head><p>Robust preprocessing of images was done before feature extraction. Iris images were segmented using the method proposed in <ref type="bibr" target="#b40">[41]</ref>. Following the segmentation step, 25 Â 240 iris templates were generated by resampling using the publicly available code of Masek and Kovesi <ref type="bibr" target="#b41">[42]</ref>. Fingerprint images were enhanced using the filtering methods described in <ref type="bibr" target="#b42">[43]</ref>, and then the core point was detected from the enhanced images <ref type="bibr" target="#b43">[44]</ref>. Features were then extracted around the detected core point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Feature Extraction</head><p>Gabor features were extracted from the processed images as they have been shown to give good performance on both fingerprints <ref type="bibr" target="#b43">[44]</ref> and iris <ref type="bibr" target="#b44">[45]</ref>. For fingerprint samples, the processed images were convolved with Gabor filters at eight different orientations. Circular tessellations were extracted around the core point for all the filtered images similar to <ref type="bibr" target="#b43">[44]</ref>. The tessellation consisted of 15 concentric bands, each of width 5 pixels and divided into 30 sectors. The mean values for each sector were concatenated to form the feature vector of size 3;600 Â 1. Features for iris images were formed by convolving the templates with a log-Gabor filter at a single scale, and vectorizing the template to give a 6;000 Â 1 dimensional feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Experimental Setup</head><p>The data set was randomly divided into four training samples per class (one sample here is one data sample each from six modalities) and the remaining 519 samples were used for testing. The recognition result was averaged over five runs. The proposed methods were compared with state-of-the-art classification methods such as sparse logistic regression (SLR) <ref type="bibr" target="#b45">[46]</ref> and SVM <ref type="bibr" target="#b46">[47]</ref>. As these methods cannot handle multiple modalities, we explored score-level and decision-level fusion methods for combining the results of individual modalities. For score-level fusion, the probability outputs for the test sample of each modality, fy i g 6 i¼1 , were added together to give the final score vector. Classification was based upon the final score values. For decision-level fusion, the subject chosen by the maximum number of modalities was taken to be from the correct class. We further compared with an efficient multiclass implementation of the MKL algorithm <ref type="bibr" target="#b47">[48]</ref>. The proposed linear and kernel fusion techniques were tested separately and were compared with linear and kernel versions of SLR, SVM, and MKL algorithms. We denote the score-level fusion of these methods as SLR-Sum and SVM-Sum, and the decision-level fusion as SLR-Major and SVM-Major. The MKL-based method is denoted as MKLFusion. We report the mean and standard deviation of rank-one recognition rates for all the methods. We also show the cumulative match curves (CMCs) for all the classifiers. The CMCs provide the performance measure for biometric recognition systems and has been shown to be equivalent to the ROC of the system <ref type="bibr" target="#b48">[49]</ref>.</p><p>Linear Fusion. The recognition performances of SMBR-WE and SMBR-E were compared with linear SVM and linear SLR classification methods. The parameters 1 and 2 were set to 0.01:</p><p>. Comparsion of methods. Fig. <ref type="figure" target="#fig_2">3</ref> and Table <ref type="table" target="#tab_3">2</ref> show the performance on individual modalities. All the classifiers show a similar trend. The performance for all of them are lower on iris images and fingers 1 and 3. The proposed method show superior performance on all the modalities. Fig. <ref type="figure" target="#fig_4">4</ref> and Table <ref type="table" target="#tab_4">3</ref> show the recognition performance for different fusion settings. The proposed SMBR approach outperforms existing classification techniques. Furthermore, the CMC curves of the proposed approaches lie above the other methods for all the fusion settings. Both SMBR-E and SMBR-WE have similar performance, though the latter seems to give a slightly better performance. This may be due to the penalty on the sparse error, though the error may not be sparse in the image domain. Furthermore, sum-based fusion shows a superior performance over voting-based methods. The MKL-based method shows good performance for iris fusion, but the performance drops for other two settings. This may be because by weighing kernels during training, it loses flexibility while testing when number of modalities increase. . Fusion with quality. Clearly, different modalities have different levels of performance. Hence, we studied the effect of the proposed quality measure on the performance of different methods. For a consistent comparison, the quality values produced by the SMBR-E method were used for all the algorithms. Table <ref type="table" target="#tab_5">4</ref> shows the performance for the three fusion settings. The effect of including the quality measure can be studied by comparing with Table <ref type="table" target="#tab_4">3</ref>. Clearly, the recognition rate increases for all the methods across the fusion settings. Again SMBR-E and SMBR-WE give the best performances among all the methods. . Effect of joint sparsity. We also studied the effect of joint sparsity constraint on the recognition performance. For this, the SMBR-WE algorithm was run for different values of 1 . Fig. <ref type="figure" target="#fig_3">5</ref> shows the rank-one   recognition variation across 1 values for different fusion settings. All the curves show a sharp increase in performance around 1 ¼ 0. Furthermore, the increase is more for iris fusion, which shows around 5 percent improvement at 1 ¼ 0:005 over 1 ¼ 0. This shows that imposing joint sparsity constraint is important for fusion. Moreover, it helps in regulating fusion performance, when the reconstruction error alone is not sufficient to distinguish between different classes. The performance is then stable across 1 values, and starts decreasing slowly after reaching the optimum performance. . Variation with number of training samples. We varied the number of training samples and studied the effect on the proposed method along with SLR-Sum and MKLFusion. Fig. <ref type="figure" target="#fig_5">6</ref> shows the variation for fusion of all the modalities. It can be seen that SMBR-WE and SMBR-E are stable across number of training samples, whereas the performances of SLR-Sum-and MKLFusion-based methods fall sharply. The fall in performance of SLR-Sum and MKLFusion can be attributed to the discriminative approaches of these methods, as well as score-based fusion, as the fusion further reduces the recognition performance when individual classifiers are not good. . Comparison with other score-based fusion methods.</p><p>Although sum-based fusion is a popular technique for score fusion, some other techniques have also been proposed. We evaluated the performance of the likelihood-based fusion method proposed in <ref type="bibr" target="#b49">[50]</ref>.</p><p>The results are shown in Table <ref type="table">5</ref>. The method does not show good performance as it models score distribution as a Gaussian mixture model. However, it is difficult to model score distribution due to large variations in data samples. The method is also affected by the curse of dimensionality. Kernel Fusion. We further compared the performances of proposed kerSMBR with kernel SVM, kernel SLR, and MKLFusion methods. In the experiments, we used radial basis function (RBF) as the kernel, given as</p><formula xml:id="formula_42">ðx i ; x j Þ ¼ exp À kx i À x j k 2 2 2 ! ;</formula><p>being a parameter to control the width of the RBF. For MKLFusion, we gave linear, polynomial, and RBF kernels as the base kernels for learning:</p><p>. Hyperparameter tuning. To fix the value of hyperparameter , we iterated over different values of , f2 À3 ; 2 À2 ; . . . ; 2 3 g, for one set of training and test split of the data. The value of giving the maximum performance was fixed for each modality, and the performance was averaged over a few iterations. and À were set to 0.01 and 0.01, respectively. . Comparison of methods. Fig. <ref type="figure" target="#fig_6">7</ref> and Table <ref type="table" target="#tab_6">6</ref> show the performance of different methods on individual modalities, and Fig. <ref type="figure" target="#fig_7">8</ref> and Table <ref type="table" target="#tab_7">7</ref> on different fusion settings. Comparison of performance with linear fusion shows that the proposed kerSMBR significantly improves the performance on individual iris modalities as well as iris fusion. The performance on fingerprint modalities is similar; however, the fusion of all six modalities (two iris + four fingerprints) shows an improvement of 0.4 percent. kerSMBR also achieves the best accuracy among all the methods for different fusion settings. kerSLR scores better than kerSVM in all the cases, and it's accuracy is close to kerSMBR. The performance of kerSLR is better than the linear counterpart; however, kerSVM does not show much improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">AR Face Data Set</head><p>The AR face data set consists of faces with varying illumination, expression, and occlusion conditions, captured in two sessions. We evaluated our algorithms on a set of 100 users. Images from the first session, seven for each subject, were used as training and the images from the second session, again seven per subject, were used for testing. For testing the fusion algorithms, four weak modalities were extracted from the face images: left and right periocular, mouth, and nose regions. This was done by applying   <ref type="bibr" target="#b49">[50]</ref> on WVU Data Set rectangular masks as shown in Fig. <ref type="figure" target="#fig_8">9</ref>, and cropping out the respective regions. These, along with the whole face, were taken for fusion. Simple intensity values were used as features for all of them. The experimental setup was similar to the previous section. The parameter values, 1 and 2 , were set to 0.003 and 0.002, respectively. Furthermore, we also studied the effect of noise and occlusion on recognition performance.   . Comparison of methods: Table <ref type="table">8</ref> shows the performance of different algorithms on the face data set.</p><p>Here, SR shows the classification result using just the whole face. The block sparse method is a recent block sparsity-based face recognition algorithm <ref type="bibr" target="#b22">[23]</ref> and FDDL <ref type="bibr" target="#b50">[51]</ref> is a state-of-the-art discriminative dictionaries-based technique, but using only a single modality. Clearly, the SMBR approach achieves about 4 percent improvement over other techniques. Thus, robust classification using multiple modalities results in a significant improvement over the current benchmark. Furthermore, a comparison with discriminative methods, such as SLR and SVM, shows that they perform poorly compared to the proposed method. This is because weak modalities are hard to discriminate; hence, score-level fusion with strong modality does not improve performance. On the other hand, by appropriately weighing different modalities, MKLFusion achieves better results. However, by imposing reconstruction and joint sparsity simultaneously, the proposed method is able to achieve the best performance. . Effect of noise: In this experiment, test images were corrupted with white Gaussian noise of increasing variance, 2 . Comparisons are shown in Fig. <ref type="figure" target="#fig_10">10</ref>. It can be seen that both SMBR, SR, and block sparse methods are stable with noise. The performance of other algorithms degrade sharply with the noise level. This also highlights the problem with MKLFusion, as it is not robust to degradation during testing. . Effect of occlusion: In this experiment, a randomly chosen block of the test image was occluded. The recognition performance was studied with increasing block size. Fig. <ref type="figure" target="#fig_9">11</ref> shows the performance of various algorithms with block size. SMBR-E is the most stable among all the methods due to robust handling of error. Recognition rates for other methods fall sharply with increasing block size. . Recognition in spite of disguise: We also performed experiment on the rest of the AR face data set, occluded by sun-glass and scarves. Similar to the above experiment, seven frontal nonoccluded images per subject, from the first session, were used for training, and 12 occluded images per person from both the sessions were used for testing. Again the proposed SMBR-WE and SMBR-E methods outperformed the other methods, as shown in Table <ref type="table" target="#tab_8">9</ref>. SMBR-E method gave the best performance, improving by 17.7 percent over the block sparse method.     . Quality-based fusion: Quality determination is an important parameter in fusion here, as strong modality is being combined with weak modalities. We studied the effect of quality measure introduced in Section 3. However, in this case, we fix the quality for strong modality, viz. whole face to be 1, while for the weak modalities, the SCI values were taken. The recognition performance for SMBR-E and SMBR-WE across different noise and occlusion levels was studied. Fig. <ref type="figure" target="#fig_11">12</ref> show the performance comparison with the unweighted methods. Using quality, the recognition performance for SMBR-WE goes up to 97.4 percent from 96.9 percent, whereas for SMBR-WE it increases up to 97 percent from 96 percent. Similarly, results improve across different noise levels for both methods. However, SMBR-WE with quality shows worse performance as block size is increased. This may be because it does not handle sparse error; hence, the quality values are not robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">COMPUTATIONAL COMPLEXITY</head><p>The proposed algorithms are computationally efficient. The main steps of the algorithms are the update steps for À, Ã, U, and V. For linear fusion, the update step for À involves computing ðX i T X i þ À IÞ À1 , and four matrix multiplications. The first term is constant across iterations and can be precomputed. Matrix multiplication for two matrices of sizes m Â n and n Â p can be done in OðmnpÞ time. Hence, for a given training and test data, the computations are linear in feature dimension. Hence, large feature dimensions can be efficiently handled. Similarly, update step for Ã involves matrix multiplication X i À i . Update steps for U and V involve only scalar matrix computations and are very fast. Similarly in the kernel fusion, update for À involves calculating ðK X i ;X i þ À IÞ À1 , which can be precomputed. Other steps are similar to linear fusion. Classification step involves calculating the residual error for each class, and is efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND DISCUSSIONS</head><p>We proposed a novel joint sparsity-based feature level fusion algorithm for multimodal biometrics recognition. The algorithm is robust as it explicitly includes both noise and occlusion terms. An efficient algorithm based on the alternative direction was proposed for solving the optimization problem. We also proposed a multimodal quality measure based on sparse representation. Furthermore, the algorithm was kernelized to handle nonlinear variations.</p><p>Various experiments have shown that the method is robust and significantly improves the overall recognition accuracy. An important question is about the theoretical justification of the proposed approaches through ' 0 =' 1 equivalence. For the special case of D ¼ 1, the theory of sparse representation has been reviewed in <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>. However, it has not been addressed yet for the general multimodal setting. This is a challenging problem, and can be investigated as a future direction to this paper. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of our algorithm. The proposed algorithm represents the test data by a sparse linear combination of training data while constraining the observations from different modalities of the test subject to share their sparse representations. Finally, classification is done by assigning the test data to the class with the lowest reconstruction error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Examples of challenging images from the WVU multimodal data set. The images shown above suffer from various artifacts such as sensor noise, blur, and occlusion.</figDesc><graphic coords="6,293.39,53.21,242.70,55.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. CMCs for individual modalities using (a) SMBR-E, (b) SMBR-WE, (c) SLR, and (d) SVM methods on WVU data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Variation of recognition performance with different values of sparsity constraint, 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. CMCs (Cumulative Match Curve) for multimodal fusion using (a) four fingerprints, (b) two irises, and (c) all modalities on WVU data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Variation of recognition performance with number of training samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. CMCs for individual modalities using (a) kernel SVM, (b) kernel SLR, and (c) kerSMBR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. CMCs for different fusion methods for (a) four fingerprints, (b) two irises, and (c) all modalities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Face mask used to crop out different modalities.</figDesc><graphic coords="11,117.87,430.50,67.69,85.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Effect of occlusion on rank-1 recognition performance for AR face data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Effect of noise on rank-one recognition performance for AR face data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Effect of quality on recognition performance across (a) noise, (b) random blocks on AR face data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>kernel sparse recognition (kerSMBR) algorithm is summarized in Algorithm 4:</figDesc><table><row><cell cols="2">Algorithm 4. Kernel Sparse Multimodal Biometrics</cell></row><row><cell>Recognition (kerSMBR).</cell><cell></cell></row><row><cell cols="2">Input: Training samples fX i g D i¼1 , test sample fY i g D i¼1 Procedure: Obtain À by solving</cell></row><row><cell>À ¼ arg min À</cell><cell>1 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 WVU</head><label>1</label><figDesc>Biometric Data</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 2</head><label>2</label><figDesc>Rank-One Recognition Performance on WVU Data Set for Individual Modalities</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 3 Rank</head><label>3</label><figDesc>-One Recognition Performance on WVU Data Set for Different Fusion Settings</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4</head><label>4</label><figDesc>Rank-One Recognition Performance on WVU Data Set Using the Proposed Quality Measure</figDesc><table><row><cell>TABLE 5</cell></row><row><cell>Rank One Recognition Performance with the</cell></row><row><cell>Likelihood-Based Method</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 6</head><label>6</label><figDesc>Rank-One Recognition Performance on WVU Data Set for Individual Modalities Using Kernel Methods</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 7</head><label>7</label><figDesc>Rank-One Recognition Performance on WVU Data Set for Different Fusion Settings Using Kernel Methods 8 Performance Comparison Different Methods on AR Face Data Set</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 9</head><label>9</label><figDesc>Rank-One Performance Comparison of Different Methods on Images with Disguise in AR Face Data Set</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="122" xml:id="foot_0"><p>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 36, NO. 1, JANUARY 2014</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work of Sumit Shekhar, Vishnal M. Patel, and Rama Chellappa was partially supported by a MURI grant from the US Army Research Office under the Grant W911NF-09-1-0383. (USC). Since 1991, he has been a professor of electrical and computer engineering (ECE) and an affiliate professor of computer science at the University of Maryland (UMD), College Park. He is also affiliated with the Center for Automation Research, the Institute for Advanced Computer Studies (Permanent Member) and is serving as the chair of the Electrical and Computer Engineerintg Department. In 2005, he was named a Minta Martin Professor of Engineering. He received the US National Science Foundation (NSF) Presidential Young Investigator Award, four IBM Faculty Development Awards, an Excellence in Teaching Award from the School of Engineering at USC, and two paper awards from the International Association of Pattern Recognition (IAPR). He received the K.S. Fu Prize from IAPR. He received the Society, Technical Achievement, and Meritorious Service Awards from the IEEE Signal Processing Society. He also received the Technical Achievement and Meritorious Service Awards from the IEEE Computer Society. At UMD, he was elected as a Distinguished Faculty Research fellow, as a Distinguished scholar-teacher, received an Outstanding Innovator Award from the Office of Technology Commercialization, and an Outstanding GEMSTONE Mentor Award from the Honors College. He received the Outstanding Faculty Research Award and the Poole and Kent Teaching Award for Senior Faculty from the College of Engineering. In 2010, he was recognized as an Outstanding ECE by Purdue University. He served as the editor-in-chief of the IEEE Transactions on Pattern Analysis and Machine Intelligence. He has served as a General and Technical Program chair for several IEEE international and national conferences and workshops. He is a Golden Core member of the IEEE Computer Society and served as a Distinguished lecturer of the IEEE Signal Processing Society. Recently, he completed a two-year term as the president of the IEEE Biometrics Council. He holds four patents. He is a fellow of the IEEE, IAPR, OSA, and AAAS.</p><p>. For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nandakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<title level="m">Handbook of Multibiometrics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multimodal Biometrics: An Overview</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Signal Processing Conf</title>
		<meeting>European Signal essing Conf</meeting>
		<imprint>
			<date type="published" when="2004-09">Sept. 2004</date>
			<biblScope unit="page" from="1221" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Wet Fingerprint Recognition: Challenges and Opportunities</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krishnasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Int&apos;l Joint Conf</title>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
	<note>Biometrics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Vehicle Classification on Multi-Sensor Smart Cameras Using Feature-and Decision-Fusion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klausner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tengg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rinner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Distributed Smart Cameras</title>
		<meeting>IEEE Conf. Distributed Smart Cameras</meeting>
		<imprint>
			<date type="published" when="2007-09">Sept. 2007</date>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Feature Level Fusion of Face and Fingerprint Biometrics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rattani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kisku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bicego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Biometrics: Theory, Applications, and Systems</title>
		<meeting>IEEE Int&apos;l Conf. Biometrics: Theory, Applications, and Systems</meeting>
		<imprint>
			<date type="published" when="2007-09">Sept. 2007</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feature Fusion of Face and Gait for Human Recognition at a Distance in Video</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Pattern Recognition</title>
		<meeting>Int&apos;l Conf. Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006-08">Aug. 2006</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="529" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Feature Level Fusion of Hand and Face Biometrics</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2005-03">Mar. 2005</date>
			<biblScope unit="volume">5779</biblScope>
			<biblScope unit="page" from="196" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiple Kernel Learning Algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Go ¨nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alpaydn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2211" to="2268" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-View Regression via Canonical Correlation Analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pro. 20th Int&apos;l Conf. Learning Theory</title>
		<imprint>
			<biblScope unit="page" from="82" to="96" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An RKHS for Multi-View Learning and Manifold Co-Regularization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int&apos;l Conf. Machine learning</title>
		<meeting>25th Int&apos;l Conf. Machine learning</meeting>
		<imprint>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="976" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Two View Learning: SVM-2k, Theory and Practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawetaylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Constructing Nonlinear Discriminants from Multiple Data Views</title>
		<author>
			<persName><forename type="first">T</forename><surname>Diethe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="328" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimal Kernel Selection in Kernel Fisher Discriminant Analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Magnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Int&apos;l Conf. Machine Learning</title>
		<meeting>23rd Int&apos;l Conf. Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="page" from="465" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sparse Representations, Compressive Sensing and Dictionaries for Pattern Recognition</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Asian Conf. Pattern Recognition</title>
		<meeting>Asian Conf. Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="325" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sparse Representations and Random Projections for Robust and Cancelable Biometrics</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tistarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Control, Automation, Robotics, and Vision</title>
		<meeting>Int&apos;l Conf. Control, Automation, Robotics, and Vision</meeting>
		<imprint>
			<date type="published" when="2010-12">Dec. 2010</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust Face Recognition via Sparse Representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Secure and Robust Iris Recognition Using Random Projections and Sparse Representations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ratha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1877" to="1893" />
			<date type="published" when="2011-09">Sept. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Compressive Sensing Approach for Expression-Invariant Face Recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nagesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009-06">June 2009</date>
			<biblScope unit="page" from="1518" to="1525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dictionary-Based Face Recognition under Variable Lighting and Pose</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="954" to="965" />
			<date type="published" when="2012-06">June 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative K-SVD for Dictionary Learning in Face Recognition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
			<biblScope unit="page" from="2691" to="2698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sparse Representation for Computer Vision and Pattern Recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="1031" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards a Practical Face Recognition System: Robust Alignment and Illumination via Sparse Representation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="372" to="386" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust Classification Using Structured Sparse Representation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
			<biblScope unit="page" from="1873" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Model Selection and Estimation in Regression with Grouped Variables</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statistical Soc.: Series B</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="49" to="67" />
			<date type="published" when="2006-02">Feb. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Group Lasso for Logistic Regression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V D</forename><surname>Geer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statistical Soc.: Series B</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="53" to="71" />
			<date type="published" when="2008-02">Feb. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-Observation Visual Recognition via Joint Dynamic Sparse Representation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="595" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual Classification with Multi-Task Joint Sparse Representation</title>
		<author>
			<persName><forename type="first">X.-T</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
			<biblScope unit="page" from="3493" to="3500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-Task Low-Rank Affinity Pursuit for Image Segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="2439" to="2446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Joint Sparsity-Based Robust Multimodal Biometrics Recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV Workshop Information Fusion in Computer Vision for Concept Recognition</title>
		<meeting>ECCV Workshop Information Fusion in Computer Vision for Concept Recognition</meeting>
		<imprint>
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Robust Multi-Sensor Classification via Joint Sparse Representation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Information Fusion</title>
		<meeting>Int&apos;l Conf. Information Fusion</meeting>
		<imprint>
			<date type="published" when="2011-07">July 2011</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Regression Shrinkage and Selection via the Lasso</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statistical Soc.: Series B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust Principal Component Analysis?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Alternating Direction Algorithms for l1 Problems in Compressive Sensing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="250" to="278" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An Augmented Lagrangian Approach to the Constrained Optimization Formulation of Imaging Inverse Problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="681" to="695" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A Protocol for Multibiometric Data Acquisition, Storage and Dissemination</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S S</forename><surname>Crihalmeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hornak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Lane Dept. of Computer Science and Electrical Eng., West Virginia Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">technical report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The AR Face Database</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martnez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benavente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVC technical report</title>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Periocular Biometrics in the Visible Spectrum</title>
		<author>
			<persName><forename type="first">U</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jillela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="106" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The Nose on Your Face May Not Be So Plain: Using the Nose as a Biometric</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moorhouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Crime Detection and Prevention</title>
		<meeting>Int&apos;l Conf. Crime Detection and Prevention</meeting>
		<imprint>
			<date type="published" when="2009-12">Dec. 2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Face Recognition by Humans: Nineteen Results All Computer Vision Researchers Should Know About</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Balas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2006-11">Nov. 2006</date>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="1948" to="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-A</forename><surname>Toh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Advanced Topics In Biometrics</title>
		<imprint>
			<publisher>World Scientific Publishing Co. Pvt. Ltd</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Non-Ideal Iris Segmentation Using Graph Cuts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pundlik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Woodard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Birchfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Computer Vision and Pattern Recognition Workshops</title>
		<meeting>IEEE Conf. Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2008-06">June 2008</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">MATLAB Source Code for Biometric Identification System Based on Iris Patterns</title>
		<author>
			<persName><forename type="first">L</forename><surname>Masek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kovesi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>The Univ. of Western Australia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">technical report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Systematic Approach for Feature Extraction in Fingerprint Images</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W S</forename><surname>Chikkerur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Govindaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Bioinformatics and Its Applications</title>
		<meeting>Int&apos;l Conf. Bioinformatics and Its Applications</meeting>
		<imprint>
			<date type="published" when="2004-12">Dec. 2004</date>
			<biblScope unit="page" from="344" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Filterbank-Based Fingerprint Matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pankanti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="846" to="859" />
			<date type="published" when="2000-05">May 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How Iris Recognition Works</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2004-01">Jan. 2004</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sparse Multinomial Logistic Regression: Fast Algorithms and Generalization Bounds</title>
		<author>
			<persName><forename type="first">B</forename><surname>Krishnapuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hartemink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="957" to="968" />
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A Tutorial on Support Vector Machines for Pattern Recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">SimpleMKL</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2491" to="2521" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The Relation between the ROC Curve and the CMC</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bolle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pankanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ratha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth IEEE Workshop Automatic Identification Advanced Technologies</title>
		<meeting>Fourth IEEE Workshop Automatic Identification Advanced Technologies</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="15" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Likelihood Ratio-Based Biometric Score Fusion</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nandakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="342" to="347" />
			<date type="published" when="2008-02">Feb. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fisher Discrimination Dictionary Learning for Sparse Representation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">F M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<meeting>IEEE Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">From Sparse Solutions of Systems of Equations to Sparse Modeling of Signals and Images</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="81" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Sumit Shekhar received the BTech degree in electrical engineering from the Indian Institute of Technology Bombay in 2009. He is working toward the PhD degree in electrical and computer engineering at the University of Maryland, College Park. He received the University of Maryland James Clarke Graduate Fellowship for 2009-2010</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Redundant</forename><surname>Sparse</surname></persName>
		</author>
		<author>
			<persName><surname>Representations</surname></persName>
		</author>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>He is a student member of the IEEE</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
