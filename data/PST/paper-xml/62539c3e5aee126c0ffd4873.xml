<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wanyu</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Virginia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zae</forename><forename type="middle">Myung</forename><surname>Kim</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vipul</forename><surname>Raheja</surname></persName>
							<email>vipul.raheja@grammarly.com</email>
							<affiliation key="aff2">
								<address>
									<settlement>Grammarly</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dhruv</forename><surname>Kumar</surname></persName>
							<email>dhruv.kumar@grammarly.com</email>
							<affiliation key="aff2">
								<address>
									<settlement>Grammarly</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongyeop</forename><surname>Kang</surname></persName>
							<email>dongyeop@umn.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Revision is an essential part of the human writing process. It tends to be strategic, adaptive, and, more importantly, iterative in nature. Despite the success of large language models on text revision tasks, they are limited to non-iterative, one-shot revisions. Examining and evaluating the capability of large language models for making continuous revisions and collaborating with human writers is a critical step towards building effective writing assistants. In this work, we present a human-inthe-loop iterative text revision system, Read, Revise, Repeat (R3), which aims at achieving high quality text revisions with minimal human efforts by reading model-generated revisions and user feedbacks, revising documents, and repeating human-machine interactions. In R3, a text revision model provides text editing suggestions for human writers, who can accept or reject the suggested edits. The accepted edits are then incorporated into the model for the next iteration of document revision. Writers can therefore revise documents iteratively by interacting with the system and simply accepting/rejecting its suggested edits until the text revision model stops making further revisions or reaches a predefined maximum number of revisions. Empirical experiments show that R3 can generate revisions with comparable acceptance rate to human writers at early revision depths, and the human-machine interaction can get higher quality revisions with fewer iterations and edits. The collected human-model interaction dataset and system code are available at https://github. com/vipulraheja/IteraTeR. Our system demonstration is available at https:// youtu.be/lK08tIpEoaE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text revision is a crucial part of writing. Specifically, text revision involves identifying discrepan- * Equal contributions. cies between intended and instantiated text, deciding what edits to make, and how to make those desired edits <ref type="bibr" target="#b10">(Flower and Hayes, 1981;</ref><ref type="bibr" target="#b5">Faigley and Witte, 1981;</ref><ref type="bibr" target="#b8">Fitzgerald, 1987)</ref>. It enables writers to deliberate over and organize their thoughts, find a better line of argument, learn afresh, and discover what was not known before <ref type="bibr" target="#b20">(Sommers, 1980;</ref><ref type="bibr" target="#b18">Scardamalia, 1986)</ref>. Previous studies <ref type="bibr" target="#b9">(Flower, 1980;</ref><ref type="bibr" target="#b2">Collins and Gentner, 1980;</ref><ref type="bibr" target="#b22">Vaughan and McDonald, 1986)</ref> have shown that text revision is an iterative process since human writers are unable to simultaneously comprehend multiple demands and constraints of the task when producing well-written texts -for instance, covering the content, following linguistic norms and discourse conventions of written prose, etc. Therefore, writers resort to performing text revisions on their drafts iteratively to arXiv:2204.03685v1 [cs.CL] 7 Apr 2022 reduce the number of considerations at each time.</p><p>Computational modeling of the iterative text revision process is essential for building intelligent and interactive writing assistants. Most prior works on the development of neural text revision systems <ref type="bibr" target="#b7">(Faruqui et al., 2018;</ref><ref type="bibr" target="#b0">Botha et al., 2018;</ref><ref type="bibr" target="#b12">Ito et al., 2019;</ref><ref type="bibr" target="#b6">Faltings et al., 2021)</ref> do not take the iterative nature of text revision and human feedback on suggested revisions into consideration. The direct application of such revision systems in an iterative way, however, could generate some "noisy" edits and require much burden on human writers to fix the noise. Therefore, we propose to collect human feedback at each iteration of revision to filter out those harmful noisy edits and produce revised documents of higher quality.</p><p>In this work, we present a novel human-in-theloop iterative text revision system, Read, Revise, Repeat (R3), which reads model-generated revisions and user feedbacks, revises documents, and repeats human-machine interactions in an iterative way, as depicted in Figure <ref type="figure" target="#fig_0">1</ref>. First, users write a document as input to the system or choose one from a candidate document set to edit. Then, the text revision system provides multiple editing suggestions with their edits and intents. Users can accept or reject the editing suggestions in an iterative way and stop revision when no editing suggestions are provided or the model reaches the maximum revision limit. The overall model performance can be estimated by calculating the acceptance rate throughout all editing suggestions. R3 provides numerous benefits over existing writing assistants for text revision. First, R3 improves the overall writing experience for writers by making it more interpretable, controllable, and productive: on the one hand, writers don't have to (re-)read the parts of the text that are already high quality, and this, in turn, helps them focus on larger writing goals ( ?4.2); on the other hand, by showing edit intentions for every suggested edit, which users can further decide to accept or reject, R3 provides them with more fine-grained control over the text revision process compared to other one-shot based text revision systems <ref type="bibr" target="#b13">(Lee et al., 2022)</ref>, and are limited in both interpretability and controllability. Second, R3 improves the revision efficiency. The human-machine interaction can help the system produce higher quality revisions with fewer iterations and edits, and the empirical experiments in ?4.2 validate this claim. To the best of our knowledge, R3 is the first text revision system in literature that can perform iterative text revision in collaboration by human writers and revision models.</p><p>In this paper, we make three major contributions:</p><p>? We present a novel human-in-the-loop text revision system R3 to make text revision models more accessible; and to make the process of iterative text revision efficient, productive, and cognitively less challenging.</p><p>? From an HCI perspective, we conduct experiments to measure the effectiveness of the proposed system for the iterative text revision task. Empirical experiments show that R3 can generate edits with comparable acceptance rate to human writers at early revision depths.</p><p>? We analyze the data collected from humanmodel interactions for text revision and provide insights and future directions for building high-quality and efficient human-in-the-loop text revision systems. We release our code, revision interface, and collected human-model interaction dataset to promote future research on collaborative text revision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Previous works on modeling text revision <ref type="bibr" target="#b7">(Faruqui et al., 2018;</ref><ref type="bibr" target="#b0">Botha et al., 2018;</ref><ref type="bibr" target="#b12">Ito et al., 2019;</ref><ref type="bibr" target="#b6">Faltings et al., 2021)</ref> have ignored the iterative nature of the task, and simplified it into a one-shot "original-to-final" sentence-to-sentence generation task. However, in practice, at every revision step, multiple edits happen at the document-level which also play an important role in text revision. For instance, reordering and deleting sentences to improve the coherence. More importantly, performing multiple highquality edits at once is very challenging. Continuing the previous example, document readability can degrade after reordering sentences, and further adding transitional phrases is often required to make the document more coherent and readable. Therefore, one-shot sentence-to-sentence text revision formulation is not sufficient to deal with real-world challenges in text revision tasks.</p><p>While some prior works on text revision <ref type="bibr" target="#b1">(Coenen et al., 2021;</ref><ref type="bibr" target="#b16">Padmakumar and He, 2021;</ref><ref type="bibr">Gero et al., 2021;</ref><ref type="bibr" target="#b13">Lee et al., 2022)</ref> have proposed humanmachine collaborative writing interfaces, they are mostly focused on collecting human-machine interaction data for training better neural models, rather than understanding the iterative nature of the text revision process, or the model's ability to adjust editing suggestions according to human feedback.</p><p>Another line of work by <ref type="bibr" target="#b21">Sun et al. (2021)</ref>; <ref type="bibr" target="#b19">Singh et al. (2022)</ref> on creative writing designed humanmachine interaction interfaces to encourage new content generation. However, text revision focuses on improving the quality of existing writing and keeping the original content as much as possible. In this work, we provide a human-in-the-loop text revision system to make helpful editing suggestions by interacting with users in an iterative way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Overview</head><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the general pipeline of R3 humanin-the-loop iterative text revision system. In this section, we will describe the development details of the text revision models and demonstrate our user interfaces.</p><p>We first formulate an iterative text revision process: given a source document<ref type="foot" target="#foot_0">1</ref> D t-1 , at each revision depth t, a text revision system will apply a set of edits to get the revised document D t . The system will continue iterating revision until the revised document D t satisfies a set of predefined stopping criteria, such as reaching a predefined maximum revision depth t max , or making no edits between D t-1 and D t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text Revision System</head><p>We follow the prior work of <ref type="bibr" target="#b4">Du et al. (2022)</ref> to build our text revision system. The system is composed of edit intention identification models and a text revision generation model. We follow the same data collection procedure in <ref type="bibr" target="#b4">Du et al. (2022)</ref> to collect the iterative revision data.<ref type="foot" target="#foot_1">2</ref> Then, we train the three models on the collected revision dataset.</p><p>Edit Intention Identification Models. Following <ref type="bibr" target="#b4">Du et al. (2022)</ref>, our edit intentions have four categories: FLUENCY, COHERENCE, CLARITY, and STYLE. We build our edit intention identification models at each sentence of the source document D t-1 to capture the more fine-grained edits. Specifically, given a source sentence, the system will make two-step predictions: (1) whether or not to edit, and (2) which edit intention to apply. The decision whether or not to edit is taken by an edit-prediction classifier that predicts a binary label of whether to edit a sentence or not. The second model, called the edit-intention classifier, predicts which edit intention to apply to the sentence. If the edit-prediction model predicts "not to edit" in the first step, the source sentence will be kept unchanged at the current revision depth.</p><p>Text Revision Generation Model. We fine-tune a large pre-trained language model like PEGA-SUS <ref type="bibr" target="#b25">(Zhang et al., 2020)</ref> on our collected revision dataset to build the text revision generation model. Given a source sentence and its predicted edit intention, the model will generate a revised sentence, conditioned on the predicted edit intention. Then, we concatenate all un-revised and revised sentences to get the model-revised document D t , and extract all its edits using latexdiff<ref type="foot" target="#foot_2">3</ref> and difflib. <ref type="foot" target="#foot_3">4</ref>In summary, at each revision depth t, given a source document D t-1 , the text revision system first predicts the need for revising a sentence, and for the ones that need revision, it predicts the corresponding fine-grained edit intentions -thus, generating the revised document D t based on the source document and the predicted edit decisions and intentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Human-in-the-loop Revision</head><p>In practice, not all model-generated edits are equally impactful towards improving the document quality <ref type="bibr" target="#b4">(Du et al., 2022)</ref>. Therefore, we enable user interaction in the iterative text revision process to achieve high quality of text revisions along with a productive writing experience. At each revision depth t, our system provides the user with suggested edits, and their corresponding edit intentions. The user can interact with the system by choosing to accept or reject the suggested edits.</p><p>Figure <ref type="figure">2</ref> illustrates the details of R3's user interface. First, a user enters their id to login to the web interface as shown in Figure <ref type="figure">2a</ref>. Then, the user is instructed with a few guidelines on how to operate the revision as demonstrated in Figure <ref type="figure">2b</ref>. After getting familiar with the interface, the user can select a source document from the left dropdown menu in Figure <ref type="figure">2c</ref>. By clicking the source document, all the edits predicted by the text re- vision model, as well as their corresponding edit intentions will show up in the main page as illustrated in Figure <ref type="figure">2d</ref> (left panel). The user is guided to go through each suggested edits, and choose to accept or reject the current edit by clicking the Confirm button in Figure <ref type="figure">2d</ref> (right panel). After going through all the suggested edits, the user is guided to click the Submit button to save their decisions on the edits. Then, the user is guided to click the Next Iteration! button to proceed to the next revision depth and check the next round of edits suggested by the system. This interactive process continues until the system does not generate further edits or reaches the maximum revision depth t max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conduct experiments to answer the following research questions: RQ1 How likely are users to accept the editing suggestions predicted by our text revision system? This question is designed to evaluate whether our text revision system can generate high quality edits. RQ2 Which types of edit intentions are more likely to be accepted by users? This question is aimed to identify which types of edits are more favored by users. RQ3 Does user feedback in R3 help produce higher quality of revised documents? This question is proposed to validate the effectiveness of human-in-the-loop component in R3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setups</head><p>Iterative Revision Systems. We prepare three types of iterative revision systems to answer the above questions:</p><p>1. HUMAN-HUMAN: We ask users to accept or reject text revisions made by human writers, which are directly sampled from our collected iterative revision dataset. This serves as the baseline to measure the gap between our text revision system and human writers. 2. SYSTEM-HUMAN: We ask users to accept or reject text revisions made by our system. Then, we incorporate user accepted edits to the system to generate the next iteration of revision. This is the standard human-in-the-loop process of R3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SYSTEM-ONLY:</head><p>We conduct an ablation study by removing user interaction in reviewing the model-generated edits. Then, we compare the overall quality of final revised documents with and without the human-in-the-loop component. In both HUMAN-HUMAN and SYSTEM-HUMAN setups where users interacted with the system, they were not informed whether the revisions were sampled from our collected iterative revision dataset, or generated by the underlying text revision models.</p><p>User Study Design. We hired three linguistic experts (English L1, bachelor's or higher degree in Linguistics) to interact with our text revision system. Each user was presented with a text revision (as shown in Figure <ref type="figure">2d</ref>) and asked to accept or reject each edit in the current revision (users were informed which revision depth they were looking at). For a fair comparison, users were not informed about the source of the edits (human-written vs. model-generated), and the experiments were conducted separately one after the other. Note that the users were only asked to accept or reject edits, and they had control neither over the number of iterations, nor over the stopping criteria. The stopping criteria for the experiment were set by us and designed as: (1) no new edits were made at the following revision depth, or (2) the maximum revision depth t max = 3 was reached. Data Details. We followed the prior work <ref type="bibr" target="#b4">(Du et al., 2022)</ref> to collect the text revision data across three domains: ArXiv, Wikipedia and Wikinews. This data was then used to train both the edit intention identification models and the text revision generation model. We split the data into training, validation and test set according to their document For the human evaluation data, we randomly sampled 10 documents with a maximum revision depth of 3 from each domain in the test set in Table 1. For the evaluation of text revisions made by human writers (HUMAN-HUMAN), we presented the existing ground-truth references from our collected dataset to users. Since we do not hire additional human writers to perform continuous revisions, we just presented the static human revisions from the original test set to users at each revision depth, and collected the user acceptance statistics as a baseline for our system.</p><p>For the evaluation of text revisions made by our system (SYSTEM-HUMAN), we only presented the original source document at the initial revision depth (D 0 ) to our system, and let the system generate edits in the following revision depths, while incorporating the accept/reject decisions on modelgenerated edit suggestions by the users. Note that at each revision depth, the system will only incorporate the edits accepted by users and pass them to the next revision iteration.</p><p>For text revisions made by our system without human-in-the-loop (SYSTEM-ONLY), we let the system generate edits in an iterative way and accepted all model-generated edits at each revision depth.</p><p>Model Details. For both edit intention identification models, we fine-tuned the RoBERTa-large <ref type="bibr" target="#b15">(Liu et al., 2020)</ref> pre-trained checkpoint from Hugging-Face <ref type="bibr" target="#b23">(Wolf et al., 2020)</ref> for 2 epochs with a learning rate of 1 ? 10 -5 and batch size of 16. The edit- For the text revision generation model, we finetuned the PEGASUS-LARGE <ref type="bibr" target="#b25">(Zhang et al., 2020)</ref> pre-trained checkpoint from HuggingFace. We set the edit intentions as new special tokens (e.g., &lt;STYLE&gt;, &lt;FLUENCY&gt;), and concatenated the edit intention and source sentence together as the input to the model. The output of the model is the revised sentence, and we trained the model with cross-entropy loss. We fine-tuned the model for 5 epochs with a learning rate of 3 ? 10 -<ref type="foot" target="#foot_4">5</ref> and batch size of 4. Finally, our text revision generation model achieves 41.78 SARI score <ref type="bibr" target="#b24">(Xu et al., 2016)</ref>, 81.11 BLEU score <ref type="bibr" target="#b17">(Papineni et al., 2002)</ref> and 89.08 ROUGE-L score <ref type="bibr" target="#b14">(Lin, 2004)</ref> on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Result Analysis</head><p>Iterativeness. The human-in-the-loop iterative text revision evaluation results are reported in Table 2. Each document is evaluated by at least 2 users. We find that R3 achieves comparable performances with ground-truth human revisions at revision depth 1 and 2, and tends to generate less favorable edits at revision depth 3. At revision depth 1, R3 is able to generate more edits than ground-truth human edits for each document, and gets more edits accepted by users on average. This shows the potential of R3 in generating appropriate text revisions that are more favorable to users.</p><p>At revision depth 2, while R3 generates less edits than human writers on average, it gets a higher acceptance rate than human writers. This result suggests that for the end users, more edits may not necessarily lead to a higher acceptance ratio, and shows that R3 is able to make high-quality edits for effective iterative text revisions. At revision depth 3, R3 generates even less edits compared both to human writers and its previous revision depths. This result can be attributed to the fact that our models are only trained on static human revision data, while at testing time they have to make predictions conditioned on their revisions generated at the previous depth, which may have a very different distribution of edits than the training data. Table <ref type="table">7</ref> shows an example of iterative text revision in ArXiv domain generated by R3. We also provide some other iterative revision examples generated by R3 in Appendix A.</p><p>Edit Intentions. Table <ref type="table" target="#tab_3">3</ref> demonstrates the distribution of different edit intentions, which can help us further analyze the which type of edits are more likely to be accepted by end users. For humangenerated revisions, we find that FLUENCY edits are most likely to be accepted since they are mainly fixing grammatical errors.</p><p>For system-generated revisions, we observe that CLARITY edits are the most frequent edits but end users only accept 58.73% of them, which suggests that our system needs further improvements in learning CLARITY edits. Another interesting observation is that STYLE edits are rarely generated by human writers (1.2%) and also gets the lowest acceptance rate (33.33%) than other intentions, while they are frequently generated by our system (16.7%) and surprisingly gets the highest acceptance rate (64.6%) than other intentions. This observation indicates that R3 is capable for generating favorable stylistic edits. Table <ref type="table" target="#tab_4">4</ref> shows some examples of edit suggestions generated by R3.</p><p>Role of Human Feedback in Revision Quality.   final revised documents with and without humanin-the-loop for R3. We asked another group of three annotators (English L2, bachelor's or higher degree in Computer Science) to judge whether the overall quality of system-generated final document is better than the ground-truth reference final document. The quality score ranges between 0 and 1. We evaluated 10 unique documents in ArXiv domain, and took the average score from all 3 annotators. As shown in Table <ref type="table" target="#tab_5">5</ref>, SYSTEM-HUMAN produces better overall quality score for the final system-generated documents with fewer iterations of revision and fewer edits, which validates the effectiveness of the human-machine interaction proposed in R3.</p><p>User Feedback. We also collected qualitative feedback about R3 from the linguistic experts through a questionnaire. The first part of our questionnaire asks participants to recall their experience with the system, and evaluate various aspects of the system (in Table <ref type="table">6</ref>). They were asked to rate how easy it was to get onboarded and use the system (convenience), whether they were satisfied with the system (revision quality and usage experience) (satisfaction), whether they felt it improved their productivity for text revision (productivity), and whether they would like to use the system again (retention) for performing revisions on their documents.</p><p>In general, the users gave positive feedback towards the ease of use of the system. However, they were neutral on the potential productivity impact, owing to the lack of domain knowledge of the documents they were evaluating. This issue could be mitigated by asking users to revise their own documents of interest. The retention and satisfaction scores were leaning slightly negative, which was explained as primarily attributed to gaps in the user interface design (eg. improperly aligned diffs, suboptimal presentation of word-level edits, etc.).</p><p>We also asked them to provide detailed comments on their experience, and the potential impact of the system on their text revision experience. Specifically, upon asking the users whether using the system to evaluate the model-suggested edits would be more time-efficient compared to actually revising the document themselves, we received many useful insights that help better design better interfaces and features of our system in future work, as some users noted: I think it would be faster using the system, but I would still be checking the text myself in case edits were missed. The system made some edits where there were letters and parts of words being added/re- Table <ref type="table">6</ref>: User feedback survey ratings. Ratings are on 5-point Likert scale with 5 being strongly positive experience, 3 being neutral, and 1 being strongly negative. However, we'd like to point out that as the number of users (linguists) who participated in the study is small, the statistical significance of the results should be taken lightly.</p><p>moved/replaced, which sometimes took some time to figure out. That wouldn't be the case if I were editing a document.</p><p>Ultimately, I would use the system for grammar/coherence/clarity edits, and then still research (a lot) to ensure that meaning was preserved throughout the document. For topics that I was more familiar with/more general topics, using the system would probably reduce my time by a third or so. For topics that required more in-depth research for me, the time saved by using the system might be minimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Future Directions</head><p>When R3 generates revisions at deeper depths, we observe a decrease in the acceptance ratio by human users. It is crucial to create a text revision system that can learn different revision strategies at each iteration and generate high quality edits at deeper revision levels.</p><p>Editing suggestions provided by our text revision generation models could be improved. Particularly, FLUENCY edits show a huge gap between human and system revisions (45.05% and 82.02%). Future work could focus on developing more powerful text revision generation models.</p><p>In our human-machine interaction, we restrict the users' role to accept or reject the model's predictions. Even with minimal human interaction, our experiment shows comparable or even better revision quality as compared to human writers at early revision depths. A potential future direction for human-machine collaborative text revision would be to develop advanced human-machine interaction interfaces, such as asking users to re-write the machine-revised text. Also, a larger-scale user study could be carried out to derive more meaningful statistics (e.g. optimal number of revision depths and edit suggestions) and investigate if there is any intriguing user behavior in the iterative revision process. For example, as mentioned in the users' feedback, it would be interesting to check if users behave differently when they are asked to accept/reject edit suggestions provided for their own texts as opposed to the texts written by a third party.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we develop an interactive iterative text revision system R3 that is able to effectively assist users to make revisions and improve the quality of existing documents. R3 can generate higher quality revisions while minimizing the human efforts. Users are provided with a reviewing interface to accept or reject system suggesting edits. The user-validated edits are then propagated to the next revision depth to get further improved revisions. Empirical results show that R3 can generate iterative text revisions with acceptance rates comparable or even better than human writers at early revision depths. Here, we develop a novel agent-based epidemiological model for the spread of SARS-CoV-2 in nursing homes to identify optimal preventive testing strategies to curb this spread . The model is microscopically.</p><p>The model is calibrated to high-resolution data from actual nursing homes in Austria, including the detailed networks of social contacts of their residents and information on past outbreaks.</p><p>2 Due to its high lethality amongst the elderly, nursing homes are in the eye of the COVID-19 storm pandemic .</p><p>Emerging new test procedures , such as antigen or RT-LAMP tests, might enable us to protect nursing home residents by means of preventive screening strategies.</p><p>Here, we develop a novel detailed agent-based epidemiological model for the spread of SARS-CoV-2 in nursing homes to identify optimal preventive testing strategiesto curb this spread . The model is microscopically calibrated to high-resolution data from actual nursing homes in Austria, including the detailed networks of social contacts of their resident detailed social contact networks and information on past outbreaks.</p><p>Due to its high lethality amongst the elderly, n N ursing homes are in the eye of the COVID-19 storm. Emerging new test procedures might enable us to protect nursing home residents by means of preventive screening strategies . Here, we develop a novel agent-based epidemiological model for the spread of SARS-CoV-2 in nursing homes to identify optimal preventive testing strategies. The model is calibrated to high-resolution data from actual nursing homes in Austria, including the detailed networks of social contacts of their residents and information on past outbreaks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">-</head><p>Due to its high lethality amongst the elderly, nursing homes are in the eye of the COVID-19 storm. Emerging new test procedures might enable us to protect nursing home residents by means of preventive screening.</p><p>Here, we develop a novel n agent-based epidemiological model for the spread of SARS-CoV-2 in nursing homes to identify optimal preventive testing strategies. The model is calibrated to high-resolution data from actual nursing homes in Austria, including detailed networks of social contacts of their residents and information on past outbreaks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A R3 Iterative Revision Samples</head><p>We present more iterative revision examples generated by R3 in Table <ref type="table" target="#tab_10">8</ref> and<ref type="table">Table 9</ref>. A Reserve soldier serving with Canadian Forces in Afghanistanwas killed on September 24, 2007. Four others were injured in the incident which killed 24-year-old Corporal Nathan Hornburg of Calgary, Alberta.</p><p>A Canadian Forces statement said Cpl. Hornburg was killed during Operation Sadiq Sarbaaz (Honest Soldier) approximately 47 kilometres west of Kandahar City in Panjwaii District , a joint Afghan-NATO mission designed to "set the conditions for a continuous security presence and the establishment of a new police sub-station in the northern part of (Panjwaii)." . Media reports indicated he died from mortar fire at around 4 :30 p.m. local time (12:00 UTC) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad.</p><p>A Canadian soldier serving with the Canadian Forces in Afghanistanwas killed on September 24, 2007. Four others were injured in the incident which killed 24-year-old Corporal Nathan Hornburg of Calgary, Alberta. Nathan Hornburg was killed during Operation Sadiq Sarbaaz (Honest Soldier) , approximately 47 kilometres west of Kandahar City in Panjwaii District. Media reports indicated he died from mortar fire at around 4 :30 p.m. local time (12:00 UTC) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">-</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System overview for R3 human-in-the-loop iterative text revision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2: User interface demonstration for R3. Anonymized version available at https://youtu.be/ lK08tIpEoaE.</figDesc><graphic url="image-12.png" coords="4,366.65,414.96,64.31,69.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics for our collected revision data which has been used to train the edit intention identification model and the text revision generation model. # Docs means the total number of unique documents, Avg.</figDesc><table><row><cell></cell><cell cols="2"># Docs Avg. Depths</cell><cell># Edits</cell></row><row><cell>Training</cell><cell>44,270</cell><cell>6.63</cell><cell>292,929</cell></row><row><cell>Validation</cell><cell>5,152</cell><cell>6.60</cell><cell>34,026</cell></row><row><cell>Test</cell><cell>6,226</cell><cell>6.34</cell><cell>39,511</cell></row><row><cell cols="4">Depths indicates the average revision depth per docu-</cell></row><row><cell cols="4">ment (for the human-generated training data), and # Ed-</cell></row><row><cell cols="4">its stands for the total number of edits (sentence pairs)</cell></row><row><cell>across the corpus.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">ids with a ratio of 8:1:1. The detailed data statistics</cell></row><row><cell cols="4">are included in Table 1. Note that our newly col-</cell></row><row><cell cols="4">lected revision dataset is larger than the previously</cell></row><row><cell cols="4">proposed dataset in Du et al. (2022) with around</cell></row><row><cell cols="4">24K more unique documents and 170K more edits</cell></row><row><cell>(sentence pairs).</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>t # Docs Avg. Edits Avg. Accepts % Accepts # Docs Avg. Edits Avg. Accepts % Accepts Human-in-the-loop iterative text revision evaluation results. t stands for the revision depth, # Docs shows the total number of revised documents at the current revision depth, Avg. Edits indicates the average number of applied edits per document, Avg. Accepts means the average number of edits accepted by users per document, and % Accepts is calculated by dividing the total accepted edits with the total applied edits.prediction classifier is binary classification model that predicts whether to edit a given sentence or not. It achieves an F1 score of 67.33 for the edit label and 79.67 for the not-edit label. The edit-intention classifier predicts the specific intent for a sentence that requires editing. It achieves F1 scores of 67.14, 70.27, 57.0, and 3.21 5 for CLARITY, FLUENCY, COHERENCE and STYLE intent labels respectively.</figDesc><table><row><cell>1</cell><cell>30</cell><cell>5.37</cell><cell>2.77</cell><cell>51.66</cell><cell>30</cell><cell>5.90</cell><cell>2.90</cell><cell>49.15</cell></row><row><cell>2</cell><cell>30</cell><cell>4.83</cell><cell>3.00</cell><cell>62.06</cell><cell>24</cell><cell>3.83</cell><cell>2.57</cell><cell>67.02</cell></row><row><cell>3</cell><cell>20</cell><cell>3.80</cell><cell>2.67</cell><cell>70.39</cell><cell>20</cell><cell>3.43</cell><cell>1.94</cell><cell>56.71</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Table 5 illustrates the quality comparison results of</figDesc><table><row><cell></cell><cell></cell><cell>HUMAN-HUMAN</cell><cell></cell><cell cols="2">SYSTEM-HUMAN (ours)</cell><cell></cell></row><row><cell></cell><cell cols="6"># Edits # Accepts % Accepts # Edits # Accepts % Accepts</cell></row><row><cell>CLARITY</cell><cell>197</cell><cell>119</cell><cell>60.40</cell><cell>332</cell><cell>195</cell><cell>58.73</cell></row><row><cell>FLUENCY</cell><cell>178</cell><cell>146</cell><cell>82.02</cell><cell>91</cell><cell>41</cell><cell>45.05</cell></row><row><cell>COHERENCE</cell><cell>103</cell><cell>41</cell><cell>39.80</cell><cell>141</cell><cell>68</cell><cell>48.22</cell></row><row><cell>STYLE</cell><cell>6</cell><cell>2</cell><cell>33.33</cell><cell>113</cell><cell>73</cell><cell>64.60</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>The distribution of different edit intentions. # Edits indicates the total number of applied edits under the current edit intention, # Accepts means the total number of edits accepted by users under the current edit intention, and % Accepts is calculated by dividing the total accepted edits with the total applied edits.</figDesc><table><row><cell cols="2">Edit Intention Edit Suggestion</cell></row><row><cell>CLARITY</cell><cell>Emerging new test procedures , such</cell></row><row><cell></cell><cell>as antigen or RT-LAMP tests, might en-</cell></row><row><cell></cell><cell>able us to protect nursing home resi-</cell></row><row><cell></cell><cell>dents.</cell></row><row><cell>FLUENCY</cell><cell>For Radar tracking, we show how a</cell></row><row><cell></cell><cell>model can reduce the tracking errors.</cell></row><row><cell>COHERENCE</cell><cell>However, we show that even a small vi-</cell></row><row><cell></cell><cell>olation can significantly modify the ef-</cell></row><row><cell></cell><cell>fective noise.</cell></row><row><cell>STYLE</cell><cell>There has been numerousextensive re-</cell></row><row><cell></cell><cell>search focusing on neural coding.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Edit suggestion examples generated by R3.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Quality comparison results of final revised documents with and without human-in-the-loop. Avg. Depths indicates the average number of iterations conducted by the system, # Edits means the total number of accepted edits by the system, and Quality represents the human judgements of the overall quality of systemrevised final documents.</figDesc><table><row><cell></cell><cell cols="3">Avg. Depths # Edits Quality</cell></row><row><cell>SYSTEM-HUMAN (ours)</cell><cell>2.5</cell><cell>148</cell><cell>0.68</cell></row><row><cell>SYSTEM-ONLY</cell><cell>2.8</cell><cell>175</cell><cell>0.28</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Hornbur was killed during , who was operating as part of Operation Sadiq Sarbaaz (Honest Soldier) approximately 47 kilometres west of Kandahar City in Panjwaii District. Media reports indicated he died from mortar fire at around 4 :30 p.m. local time (12:00 UTC) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad. Corporal Nathan Hornburg. A Reserve A Canadian soldier serving with Canadian Forces in Afghanistanwas killed on September 24, 2007. Four others were injured in the incident which killed 24-yearold Corporal Nathan Hornburg of Calgary, Alberta. A Canadian Forces statement said Cpl. Nathan Hornburg was killed during Operation Sadiq Sarbaaz (Honest Soldier) approximately 47 kilometres west of Kandahar City in Panjwaii District. Media reports indicated he died from mortar fire at around 4 :30 p.m. local time (12:00 UTC) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad. 2 Corporal Nathan Hornburg.</figDesc><table><row><cell cols="3">t HUMAN-HUMAN</cell><cell></cell><cell></cell><cell>SYSTEM-HUMAN(ours)</cell></row><row><cell cols="6">0 Corporal Nathan Hornburg. A Reserve soldier serving with</cell><cell>Corporal Nathan Hornburg. A Reserve soldier serving</cell></row><row><cell></cell><cell cols="5">Canadian Forces in Afghanistanwas killed on September 24,</cell><cell>with Canadian Forces in Afghanistanwas killed on Septem-</cell></row><row><cell></cell><cell cols="5">2007. Four others were injured in the incident which killed</cell><cell>ber 24, 2007. Four others were injured in the incident</cell></row><row><cell></cell><cell cols="5">24-year-old Corporal Nathan Hornburg of Calgary, Alberta. A</cell><cell>which killed 24-year-old Corporal Nathan Hornburg of</cell></row><row><cell></cell><cell cols="5">Canadian Forces statement said Cpl. Hornburg was killed during</cell><cell>Calgary, Alberta. A Canadian Forces statement said Cpl.</cell></row><row><cell></cell><cell cols="5">Operation Sadiq Sarbaaz (Honest Soldier) approximately 47</cell><cell>Hornburg was killed during Operation Sadiq Sarbaaz</cell></row><row><cell></cell><cell cols="5">kilometres west of Kandahar City in Panjwaii District. Media</cell><cell>(Honest Soldier) approximately 47 kilometres west of</cell></row><row><cell></cell><cell cols="5">reports indicated he died from mortar fire at around 4 :30 p.m.</cell><cell>Kandahar City in Panjwaii District. Media reports indi-</cell></row><row><cell></cell><cell cols="5">local time (12:00 UTC) while he was repairing the track on</cell><cell>cated he died from mortar fire at around 4 :30 p.m. local</cell></row><row><cell></cell><cell cols="5">a Canadian Leopard tank near a cluster of villages known as</cell><cell>time (12:00 UTC) while he was repairing the track on a</cell></row><row><cell></cell><cell>Zangabad.</cell><cell></cell><cell></cell><cell></cell><cell>Canadian Leopard tank near a cluster of villages known</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>as Zangabad.</cell></row><row><cell>1</cell><cell cols="5">Corporal Nathan Hornburg. A Reserve soldier serving with</cell></row><row><cell></cell><cell cols="5">Canadian Forces in Afghanistanwas killed on September</cell></row><row><cell></cell><cell cols="5">24, 2007 On MOnday, a 24-year old Calgary Reservist</cell></row><row><cell></cell><cell cols="5">became the 71st Canadian soldier killed in Afghanistan .</cell></row><row><cell></cell><cell cols="5">Four others were injured in the incident which</cell></row><row><cell></cell><cell>killed</cell><cell>24-year-old</cell><cell>Corporal</cell><cell>Nathan</cell><cell>Hornburg</cell></row><row><cell></cell><cell cols="5">of Calgary, Alberta. A Canadian Forces statement said Cpl.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>A Canadian soldier serving with the Canadian Forces in Afghanistan was killed on September 24, 2007. Four others were injured in the incident which killed 24-year-old Corporal Cpl. Nathan Hornburg of Calgary, Alberta. Nathan Hornburg was killed during Operation Sadiq Sarbaaz (Honest Soldier), approximately 47 kilometres west of Kandahar City in the Panjwaii District. Media reports indicated he died from mortar fire at around 4 :30 p.m. local time (12:00 UTC) while he was repairing the track on a Canadian Leopard tank near a cluster of villages known as Zangabad.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>A sample snippet of iterative text revisions in Wikinews domain generated by R3, where t is the revision depth and t = 0 indicates the original input text. Note that text represents user accepted deletions, text represents user accepted insertions, and text represents user rejected edits.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The source document can be chosen by a user in the candidate set of documents or written from scratch by a user.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>See ?4.1 for the detailed data collection.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://ctan.org/pkg/latexdiff</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://docs.python.org/3/library/ difflib.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>We note that the F1 score for STYLE is low as the number of training samples for that intent is particularly small.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank all linguistic expert annotators at Grammarly for participating in the user study and providing us with valuable feedback during the process. We also thank <rs type="person">Karin de Langis</rs> at <rs type="affiliation">University of Minnesota</rs> for narrating the video of our system demonstration. We would like to extend our gratitude to the anonymous reviewers for their helpful comments.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>t HUMAN-HUMAN SYSTEM-HUMAN(ours) 0 Jecon Gregory is or was a nomadic artist, whose autobiographical fragments and poems, dictated to an acquaintance, were published as the book "History of a Nation of One" <ref type="bibr">(Harcourt Brace, New York, 1969, and</ref><ref type="bibr">Michael Joseph, London, 1971)</ref>. Jecon apparently did not know his place, date, language or even name of birth, began his wanderings as a child in Malta; walked through many lands, barefoot, tall and thin, pulling all his possessions in a basket on wheels, sleeping on the ground, and making a living by drawing portraits.</p><p>Jecon Gregory is or was a nomadic artist, whose autobiographical fragments and poems, dictated to an acquaintance, were published as the book "History of a Nation of One" <ref type="bibr">(Harcourt Brace, New York, 1969, and</ref><ref type="bibr">Michael Joseph, London, 1971)</ref>. Jecon apparently did not know his place, date, language or even name of birth, began his wanderings as a child in Malta; walked through many lands, barefoot, tall and thin, pulling all his possessions in a basket on wheels, sleeping on the ground, and making a living by drawing portraits.</p><p>1 Jecon Gregory is or was a nomadic artist, whose autobiographical fragments and poems, dictated to an acquaintance, were published as the book "History of a Nation of One : An Unlikely Memoir " <ref type="bibr">(Harcourt Brace, New York, 1969, and</ref><ref type="bibr">Michael Joseph, London, 1971)</ref>. .. Jecon apparently did not know his place, date, language or even name of birth, began his wanderings as a child in Malta; walked through many lands, barefoot, tall and thin, pulling all his possessions in a basket on wheels, sleeping on the ground, and making a living by drawing portraits.</p><p>Jecon Gregory is or was a nomadic artist, whose autobiographical fragments and poems, dictated to an acquaintance, were published as the book " History of a Nation of One" <ref type="bibr">(Harcourt Brace, New York, 1969, and</ref><ref type="bibr">Michael Joseph, London, 1971)</ref>. Jecon apparently did not know his place, date, language or even name of birth, began his wanderings as a child in Malta; walked through many lands, barefoot, tall and thin, pulling all his possessions in a basket on wheels, sleeping on the ground, and making a living by drawing portraits.</p><p>2 -Jecon Gregory is or was a nomadic artist, whose autobiographical fragments and poems, dictated to an acquaintance, were published as the book "History of a Nation of One" <ref type="bibr">(Harcourt Brace, New York, 1969, and</ref><ref type="bibr">Michael Joseph, London, 1971)</ref>. Jecon apparently did not know his place, date, language or even name of birth, began his wanderings as a child in Malta; walked through many lands, barefoot, tall and thin, pulling all his possessions in a basket on wheels, sleeping on the ground, and making a living by drawing portraits. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">--</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to split and rephrase from Wikipedia edit history</title>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1080</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="732" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Wordcraft: a human-ai collaborative editor for story writing</title>
		<author>
			<persName><forename type="first">Andy</forename><surname>Coenen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.07430</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A framework for a cognitive theory of writing</title>
		<author>
			<persName><forename type="first">Allan</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dedre</forename><surname>Gentner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive processes in writing</title>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="51" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A sample snippet of iterative text revisions in ArXiv domain generated by R3, where t is the revision depth and t = 0 indicates the original input text. Note that text represents user accepted deletions, text represents user accepted insertions</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note>and text represents user rejected edits</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding Iterative Revision from Human-Written Text</title>
		<author>
			<persName><forename type="first">Wanyu</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vipul</forename><surname>Raheja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myung</forename><surname>Zae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melissa</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyeop</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Analyzing revision. College composition and communication</title>
		<author>
			<persName><forename type="first">Lester</forename><surname>Faigley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Witte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="400" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Text editing by command</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Faltings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerold</forename><surname>Hintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.414</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5259" to="5274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">WikiAtomicEdits: A multilingual corpus of Wikipedia edits for modeling language and discourse</title>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1028</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="305" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Research on revision in writing</title>
		<author>
			<persName><forename type="first">Jill</forename><surname>Fitzgerald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of Educational Research</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="481" to="506" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The dynamics of composing: Making plans and juggling constraints. Cognitive processes in writing</title>
		<author>
			<persName><forename type="first">Linda</forename><surname>Flower</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="31" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A cognitive process theory of writing. College Composition and Communication</title>
		<author>
			<persName><forename type="first">Linda</forename><surname>Flower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Hayes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="365" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sparks: Inspiration for science writing using language models</title>
		<author>
			<persName><forename type="first">Katy</forename><surname>Ilonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lydia</forename><forename type="middle">B</forename><surname>Chilton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.07640</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diamonds in the rough: Generating fluent sentences from early-stage drafts for academic writing assistance</title>
		<author>
			<persName><forename type="first">Takumi</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsuki</forename><surname>Kuribayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hayato</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Brassard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masato</forename><surname>Hagiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-8606</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Natural Language Generation</title>
		<meeting>the 12th International Conference on Natural Language Generation<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="40" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Mina</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.06796</idno>
		<title level="m">Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">RoBERTa: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Vishakh</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.04193</idno>
		<title level="m">Machinein-the-loop rewriting for creative image captioning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Research on written composition. Handbook of reserch on teaching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scardamalia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Where to hide a stolen elephant: Leaps in creative writing with multimodal machine intelligence</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillermo</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daria</forename><surname>Savchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><forename type="middle">L</forename><surname>Glassman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3511599</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput.-Hum</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Revision strategies of student writers and experienced adult writers. College composition and communication</title>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Interact</surname></persName>
		</author>
		<author>
			<persName><surname>Sommers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="378" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">IGA: An intent-guided authoring assistant</title>
		<author>
			<persName><forename type="first">Simeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Manjunatha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Vasan Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.483</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5972" to="5985" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A model of revision in natural language generation</title>
		<author>
			<persName><forename type="first">Marie</forename><forename type="middle">M</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">D</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno type="DOI">10.3115/981131.981146</idno>
	</analytic>
	<monogr>
		<title level="m">24th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="90" to="96" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00107</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization</title>
		<author>
			<persName><forename type="first">Jingqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="11328" to="11339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
