<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Filtering for Texture Classification: A Comparative Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Trygve</forename><surname>Randen</surname></persName>
							<email>t.randen@ieee.org</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">John</forename><forename type="middle">Håkon</forename><surname>Husøy</surname></persName>
							<email>john.h.husoy@tn.his.no</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Schlumberger Geco-Prakla</orgName>
								<address>
									<postBox>P.O. Box 330</postBox>
									<postCode>4001</postCode>
									<settlement>Sta-vanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Stavanger College</orgName>
								<address>
									<settlement>Stavanger</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Filtering for Texture Classification: A Comparative Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A7B300558C17B5FDCA48B7B9156F5624</idno>
					<note type="submission">received 13 Feb. 1998; revised 11 Dec. 1998. Recommended for acceptance by K. Bowyer.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T10:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Texture classification</term>
					<term>image processing</term>
					<term>filtering</term>
					<term>survey</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we review most major filtering approaches to texture feature extraction and perform a comparative study. Filtering approaches included are Laws masks, ring/wedge filters, dyadic Gabor filter banks, wavelet transforms, wavelet packets and wavelet frames, quadrature mirror filters, discrete cosine transform, eigenfilters, optimized Gabor filters, linear predictors, and optimized finite impulse response filters. The features are computed as the local energy of the filter responses. The effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches. For reference, comparisons with two classical nonfiltering approaches, co-occurrence (statistical) and autoregressive (model based) features, are given. We present a ranking of the tested approaches based on extensive experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>LASSIFICATION and segmentation of texture content in digital images has received considerable attention during the past decades and numerous approaches have been presented <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Tuceryan and Jain <ref type="bibr" target="#b1">[2]</ref> identifies five major categories of features for texture identification; statistical, geometrical, structural, model-based, and signal processing features. It is our impression that the statistical, model-based, and signal processing techniques are the most commonly used. The focus of this paper will be on signal processing approaches.</p><p>A common denominator for most signal processing approaches is that the textured image is submitted to a linear transform, filter, or filter bank, followed by some energy measure. Due to the inherent similarities between these approaches, they will all be referred to as filtering approaches in this paper.</p><p>Although similar in concept, several quite different filtering schemes have been presented in the literature. One of the pioneering techniques was the approach by Laws <ref type="bibr" target="#b2">[3]</ref>, where a bank of band pass filters was applied. Subsequent works have focused on different filter bank families, different subband decompositions, and on optimization of the filters for texture feature separation. The large number of different test images applied, along with different system setups, have made comparison of the filtering approaches based on published results very difficult.</p><p>A few comparisons between texture feature extraction schemes have been presented. Weszka et al. <ref type="bibr" target="#b3">[4]</ref> compared the Fourier power spectrum, second order gray level statistics, co-occurrence statistics, and gray level run length statistics features. They concluded that the co-occurrence features were the best of these features. The co-occurrence features were also the best features in a study by Conners and Harlow <ref type="bibr" target="#b4">[5]</ref>, when compared with run length difference, gray level difference density, and power spectrum.</p><p>Du Buf et al. <ref type="bibr" target="#b5">[6]</ref>, on the other hand, reported that several features had roughly the same performance. They evaluated co-occurrence features, fractal dimension, transform and filter bank features, dominant local frequency and orientation features, number of gray level extrema per unit area, and curvilinear integration features. Filtering features have been compared to the co-occurrence features in some more studies, with different conclusions. Strand and Taxt <ref type="bibr" target="#b6">[7]</ref> concluded that the co-occurrence features were performing best, while Laws <ref type="bibr" target="#b2">[3]</ref>, Pietikäinen et al. <ref type="bibr" target="#b7">[8]</ref>, and Clausi and Jernigan <ref type="bibr" target="#b8">[9]</ref> had the opposite conclusion. Different setups, different test images, and different filtering methods may be the reasons for the contradicting results. Ojala et al. <ref type="bibr" target="#b9">[10]</ref> compared gray-level difference, Laws filter, covariance, local binary patterns, and complementary feature pairs. They concluded that the gray level difference features were performing best and noted a particularly poor performance of the Laws features.</p><p>We note that no extensive evaluation of the various filtering approaches has been performed. The aim of this paper is to provide such a comparative study. The system setup will be as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. In order to make the results comparable, the focus will be on the filtering part of this system, keeping the other components as similar as possible. For reference, we also compare the filtering approaches with two classes of popular, nonfiltering texture features, model-based and statistical features. In our experiments, we compare the classification results for some images with two to 16 textures with borders ranging from simple to difficult. Special emphasis is put on making the results realistic, thus the design and test data sets are disjoint. Interestingly enough, this is far from always the case in experiments presented in the literature on texture classification. This paper is organized as follows: In Section 2, we give an introduction to how texture features are extracted by filtering, along with a review of the different filtering approaches. In Section 3, we present the experimental results for the test of the various filtering approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FEATURE EXTRACTION APPROACHES AND SYSTEM SETUP</head><p>Before we proceed with the description of the different filtering approaches, we will give a description of the elements of the system in Fig. <ref type="figure" target="#fig_0">1</ref>. Consider the simple synthetic textured image in Fig. <ref type="figure" target="#fig_1">2a</ref>. This image consists of two textures generated by sinusoids. The left half of the image has one low-frequency sinusoid and the right half has a highfrequency sinusoid superimposed on the low frequency one. For illustrational purposes, consider a horizontal line through this image, Fig. <ref type="figure" target="#fig_1">2b</ref>. The first operation of the system illustrated in Fig. <ref type="figure" target="#fig_0">1</ref> is filtering. Assume that the image is filtered with a filter stopping the low frequency sinusoid and passing the high frequency sinusoid. A line in the resulting image is illustrated in Fig. <ref type="figure" target="#fig_1">2c</ref>. In this case, we see that the filter response for the left texture has low energy, and the right texture high. However, we still can not classify the image by its pixel values alone without significant classification errors.</p><p>Next, a local energy function is applied, consisting of a nonlinearity (Fig. <ref type="figure" target="#fig_1">2d</ref>), basically rectifying 1 the filter response and smoothing (Fig. <ref type="figure" target="#fig_1">2e</ref>). The resulting feature image is 1. Rectification here is understood as the operation of transforming negative amplitudes to the corresponding positive amplitudes.</p><p>given in Fig. <ref type="figure" target="#fig_1">2f</ref>, and this feature image can be classified with success. The optional second nonlinearity box in Fig. <ref type="figure" target="#fig_0">1</ref> is not illustrated in this experiment and will be treated later.</p><p>In the literature, different choices for all the elements of Fig. <ref type="figure" target="#fig_0">1</ref> have been reported. In this section, we will review some of the approaches found in the literature. We do, however, believe that the most important element is the filter or filter bank. The scope of this paper is to examine the performance of different choices for the filtering step. In order to isolate this problem to keep the results comparable, we will keep the other elements of the setup as similar as possible.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Local Energy Function and Post Processing</head><p>The objective of the local energy function (see Figs. <ref type="figure" target="#fig_0">1</ref> and<ref type="figure" target="#fig_1">2</ref>) is to estimate the energy in the filter output in a local region. Unfortunately, accurate edge preservation and accurate energy estimation are conflicting goals. For edge localization, high spatial resolution is desired, while for energy estimation, high spatial frequency resolution is desired. These desires need to be balanced in the smoothing filter.</p><p>Commonly applied smoothing filters in the local energy function are rectangular <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> and Gaussian <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Experience has taught us that the Gaussian filter is the far better choice and will consequently be used in our experiments.</p><p>How can the size of the smoothing filter be appropriately determined? If we want to estimate the local energy of low spatial frequencies, the smoothing filter will have to be large, while we can allow smaller smoothing filters for higher frequencies. Hence, for a band-limited filter output, we may set the smoothing filter size as a function of the band center frequency. In our experiments, we compute the radial spatial center frequency, f 0 , for all band pass filters, and apply a separable Gaussian low-pass filter with the unit pulse response,</p><formula xml:id="formula_0">h n e G s n s 0 5 = - 1 2 1 2 2 2 ps s<label>(1)</label></formula><p>in each dimension, where</p><formula xml:id="formula_1">s s f = 1 2 2 0 0 5 .</formula><p>This smoothing function was initially suggested by Jain and Farrokhnia <ref type="bibr" target="#b19">[20]</ref>. For subsampled filter responses, a modification of this scheme described by Randen and Husøy <ref type="bibr" target="#b16">[17]</ref> is used. Another element of the local energy function is the nonlinearity. Commonly applied nonlinearities are the magnitude |¼| <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, the squaring (¼)</p><p>2 <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, and the rectified sigmoid, |tanh(a¼)| <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. The magnitude and squaring nonlinearities are parameter free, whereas the rectified sigmoid nonlinearity requires tuning of the saturation parameter, a. This may be an advantage if it is easy to tune this parameter, or a disadvantage otherwise. An appropriate saturation parameter is dependent on the dynamic range of the input image.</p><p>The second nonlinearity illustrated in Fig. <ref type="figure" target="#fig_0">1</ref> is not commonly used. Unser <ref type="bibr" target="#b26">[27]</ref> proposed and tested several combinations of the first and second nonlinearity for texture segmentation. He concluded that squaring in combination with a logarithmic normalizing nonlinearity was the best combination. This combination will consequently be used in most experiments in this paper. Unser did not test the rectified sigmoid nonlinearity. However, due to the issue of appropriate saturation parameter determination, this nonlinearity will primarily not be used here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification</head><p>The output from the local energy function is a set of images, one image per filter. These images are the feature images that will form the basis for the classification. They are used to form feature vectors, where each feature image corresponds to one element in the feature vectors. Each feature vector corresponds to one or a few image pixels. Classification is the task of assigning class labels to these feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Classification Scheme</head><p>Numerous classification approaches are possible and are described in several text books, e.g., <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. The choice of classifier will not be examined in detail, but classifiers will be used for illustrating the usefulness of the proposed feature extraction schemes. Examples of classification schemes reported in the literature are Bayes classifiers assuming multivariate Gaussian feature distributions <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b22">[23]</ref>, Fisher transformation <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b25">[26]</ref>, nearest neighbor classifiers <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b21">[22]</ref>, classification trees <ref type="bibr" target="#b25">[26]</ref>, feed-forward neural networks <ref type="bibr" target="#b18">[19]</ref>, and the Learning Vector Quantization scheme <ref type="bibr" target="#b16">[17]</ref>. In some cases, even thresholding <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref> and simple extremum picking <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref> are applicable as classification schemes. Yet, other researchers <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b33">[34]</ref> report their results using clustering schemes, i.e., unsupervised schemes. It is beyond the scope of this article to test all these classification schemes. We have chosen to use the "Type One Learning Vector Quantizing" (LVQ) supervised classifier of Kohonen <ref type="bibr" target="#b34">[35]</ref> for most experiments.</p><p>Training and using complex statistical or neural network classifiers like the LVQ is clearly both time consuming and puts heavy requirements on training data quality and size. As will become clear some of the feature extraction schemes are specially designed to avoid this complexity and use maximum picking or thresholding instead. Since these schemes probably will never be used together with a complex statistical or neural network classifier, it would not be appropriate to test them with such classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Training Data</head><p>In order to have a reliable test of the classification, it is necessary to have separate test and training feature vectors. Despite this, it is quite common in texture classification to pick the training feature vectors as a subset of the test vectors <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> or as a not completely disjoint set <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>. This practice has major implications on the performance of the classification system and yields results not attainable in a realistic environment. Farrokhnia <ref type="bibr" target="#b18">[19]</ref> suggests using 6 percent of the feature vectors for classifier training in the supervised experiments. To illustrate the effect of this choice, experiments with the texture image of Fig. <ref type="figure" target="#fig_9">11a</ref> were conducted. In these experiments, the classifiers were trained using two different approaches: Overoptimistic results, however, is not the only problem with a nonseparate training set. The relative performance degradation was very dependent on the method. For example, with co-occurrence features <ref type="bibr" target="#b35">[36]</ref> the error rate was 7.6 percent with a nonseparate training set and 9.7 percent with separate. The results with a dyadic Gabor filter bank <ref type="bibr" target="#b19">[20]</ref> were 3.8 percent and 14.5 percent, respectively. Hence, if we were comparing these methods based on nonseparate training data, the conclusion on their relative performances would be the opposite of the conclusion when comparing them with the more realistic (separate) training data case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Heuristically Designed Filter Banks</head><p>The basic assumption for most filtering approaches is that the energy distribution in the frequency domain identifies a texture. Hence, if the frequency spectrum of the textured image is decomposed into a sufficient number of subbands, the spectral energy signatures of different textures are different. Utilizing this, several filter bank approaches and related schemes have been proposed. Some major approaches are discussed here. Parameter choices for the approaches with respect to the experiments are also discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Laws Filter Masks</head><p>One of the first approaches to filtering for texture identification was presented in the work by Laws <ref type="bibr" target="#b2">[3]</ref>. Laws suggested using a bank of separable filters, five in each dimension, i.e., a total of 25 filters. The filter masks suggested were h 1 = <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b0">1]</ref>,</p><formula xml:id="formula_2">h 2 = [-1, -2, 0, 4, 1], h 3 = [-1, 0, 2, 0, -1], h 4 = [-1, 2, 0, -2, 1]</formula><p>, and h 5 = [1, -4, 6, -4, 1]. The resulting 25 subbands are illustrated in Fig. <ref type="figure" target="#fig_3">3b</ref>, with the onedimensional equivalent in Fig. <ref type="figure" target="#fig_3">3a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Ring and Wedge Filters</head><p>Assuming that texture is discriminated by spatial frequency and orientation, Coggins and Jain <ref type="bibr" target="#b11">[12]</ref> suggested using seven dyadically spaced ring filters and four wedge-shaped orientation filters for feature extraction. The filters are designed in the two-dimensional spatial frequency domain, giving the amplitude responses of Fig. <ref type="figure">4</ref>. The rings and wedges have Gaussian cross sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Dyadic Gabor Filter Bank</head><p>Jain and Farrokhnia <ref type="bibr" target="#b19">[20]</ref> suggested a bank of Gabor filters, i.e., Gaussian shaped band-pass filters, with dyadic coverage of the radial spatial frequency range and multiple orientations. This choice was justified by the relation to models for the early vision of mammals as well as the filters' joint optimum resolution in time and frequency.</p><p>The basic even-symmetric Gabor filter oriented at 0 o is a band-pass filter with unit pulse response</p><formula xml:id="formula_3">h k l e f k k x l y , c o s , 1 6 2 7 = - + 1 2 2 2 2 2 2 0 s s p<label>(2)</label></formula><p>where f 0 is the radial center frequency. Other orientations are obtained by rotating the reference coordinate system, (k, l). This filter has an infinite unit pulse response, but in practical experiments it is approximated by a finite length filter. Five radial frequencies are suggested <ref type="bibr" target="#b19">[20]</ref> (for images of size 256 256) and four orientations. In the tests presented here, the same number of filters are used, irrespective of the size of the input image. The discrete radial center frequencies </p><p>and orientations 0 o , 45 o , 90 o , and 135 o are used (see Fig. <ref type="figure">5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Wavelet Transform, Packets, and Frames</head><p>A transform like the discrete wavelet transform corresponds to a critically sampled filter bank with particular filter parameters and subband decompositions <ref type="bibr" target="#b36">[37]</ref>. Wavelet transform approaches are consequently filter bank approaches. The application of the discrete wavelet transform, and variants thereof for texture identification has received considerable attention in the literature. The use for texture analysis was pioneered by Mallat <ref type="bibr" target="#b37">[38]</ref>, who applied a "standard" wavelet transform for feature extraction, i.e., critically decimated with dyadic subband structure. The work by Chang and Kuo <ref type="bibr" target="#b23">[24]</ref>, however, indicates that texture features are most prevalent in intermediate frequency bands, thus that the octave band decomposition is not optimal. The trend probably therefore seems to be a concentration on the wavelet packet transform <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, which basically is the wavelet transform with subband decompositions not restricted to be dyadic. The discrete wavelet transform and the discrete wavelet packet transform are critically sampled multi rate filter banks. However, critically sampled filter banks typically imply inaccurate texture edge localization <ref type="bibr" target="#b16">[17]</ref>. The use of over-complete wavelet representations, i.e., wavelet frames <ref type="bibr" target="#b10">[11]</ref>, is a remedy for alleviating this problem. Improved results with over-complete representations have been reported <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b16">[17]</ref>, see also Section 3.</p><p>Evaluation of absolutely all approaches to texture analysis using wavelet representations is beyond the scope of the experiments. The attention will be restricted to the Daubechies family of wavelets <ref type="bibr" target="#b38">[39]</ref>. The subband decompositions illustrated in Fig. <ref type="figure" target="#fig_5">6</ref> will be evaluated. Using both full rate and critical subsampling and these decompositions, both wavelet transform, wavelet packet, and wavelet frame techniques are covered. The responses of the applied filters classes are illustrated in Fig. <ref type="figure" target="#fig_6">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5">Discrete Cosine Transform (DCT)</head><p>The discrete cosine transform is popular in image coding due to good performance and fast implementation <ref type="bibr" target="#b39">[40]</ref>. It is, for instance, the backbone in the JPEG compression standard. Ng et al. <ref type="bibr" target="#b40">[41]</ref> suggest using a 3 3 DCT for texture feature extraction. They furthermore suggest excluding the low-frequency component of the DCT, thus yielding eight features.</p><p>Image transforms are equivalent to critically sampled filter banks. The above approach is tested in a filter bank implementation, without critical sampling. The filter bank is separable, determined by the one-dimensional filter masks</p><formula xml:id="formula_5">h 1 = [1, 1, 1], h 2 = [1, 0, -1], h 3 = [1, -2, 1]</formula><p>. The amplitude responses are illustrated in Fig. <ref type="figure" target="#fig_7">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.6">Quadrature Mirror Filters (QMF)</head><p>Another class of filters, quadrature mirror filters (QMF), were used for texture analysis by Randen and Husøy <ref type="bibr" target="#b16">[17]</ref>. This is, like the class of wavelet filters, a very broad class of filters, incorporating both infinite impulse response (IIR) and finite impulse response (FIR) filters. In this study, we will analyze a few filters applied to the subband decompositions in Fig. <ref type="figure" target="#fig_5">6</ref>. The filters to be analyzed are the 8, 16, and 32-tap FIR filters "f8a," "f16b," and "f32d" <ref type="bibr" target="#b41">[42]</ref> and the IIR filters "F_2_1_09" and "F_2_1_smpl" <ref type="bibr" target="#b42">[43]</ref>. The two-channel amplitude responses (with a dB axis) for these filters are given in Fig. <ref type="figure" target="#fig_8">9</ref>. The two IIR filters require a low number of multiplications and additions <ref type="bibr" target="#b42">[43]</ref>, yielding low computational complexity in the feature extraction. For "F_2_1_smpl" all multiplications are by powers of two and can be implemented by bit-wise shifts. Like with the wavelet filters, these filters will be tested both at critical rate (subsampled) and full rate (not subsampled).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.7">Tree-Structured Gabor Filter Bank</head><p>Motivated by the success of the dyadic Gabor filter bank <ref type="bibr" target="#b19">[20]</ref> and the arbitrary QMF decompositions <ref type="bibr" target="#b16">[17]</ref>, we suggested using nondyadic Gabor filter banks <ref type="bibr" target="#b16">[17]</ref>. In this approach, the filter bank is decomposed with the decompositions of Fig. <ref type="figure" target="#fig_5">6</ref>. The subband filter of Section 2.3.3 is used with only minor modifications <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Optimized Filters and Filter Banks</head><p>The heuristically designed filter banks 2 have been reported</p><p>to yield successful results in numerous cases. However, most of the heuristically designed filter banks imply large numbers of features. Consequently, the computational complexities are typically large in both feature extraction and classification. It may, therefore, be desirable to attempt to optimize the filtering operation. Optimizing filters or filter banks may yield low feature vector dimensionality, 2. By a heuristically designed filter bank is meant a filter bank that is not optimized by some explicit criterion related to the texture classification.   maximized feature separation, and in some cases more simple classifiers.</p><p>As will be evident from the presentation, some of the optimization approaches are inherently restricted to twotexture problems, while others are applicable also to multitexture problems. Furthermore, some of the approaches yield one filter, while others yield banks of filters. However, common for all approaches is that the filters are optimized with respect to some criterion related to the texture classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Eigenfilter</head><p>An early attempt at optimizing the filter function for texture feature extraction was presented in 1983 by Ade <ref type="bibr" target="#b12">[13]</ref>. Ade suggests using eigenfilters derived from the autocorrelation functions of the textures. From each texture, the 9 9 matrix</p><formula xml:id="formula_6">R xx m n m n m n m n m n m n m n m n m n m n m n m n m n mn m n mn m n m n E x x E x x E x x E x x E x x E x x E x x E x x E x x = ! " $ # # # # # # + + + + + + + + + + + + + + + + + + , ,<label>, , , , , , , , , , , , , , , , , L L</label></formula><formula xml:id="formula_7">M M M L L M M M L L 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</formula><p>where x m,n is the image and E[¼] is the expectation operator is estimated and the eigenvectors and eigenvalues are computed. Each 9 1 eigenvector corresponds thus to a 3 3 filter mask. Then, the image is filtered with the 3 3 filters corresponding to the principal eigenvectors. One set of filters is designed for each texture and all filters are applied to the composite image.</p><p>In the original approach, the filters corresponding to the eigenvalues summing up to at least 99 percent of the total eigenvalue sum were selected. This leads to a significant number of filters, typically in the range 5 to 9 per texture. Since the test images in Fig. <ref type="figure" target="#fig_9">11</ref> have up to 16 textures, a considerable number of filters would be constructed. This implies very significant computational complexities for the feature extraction and classification systems. Therefore, the total number of filters was restricted to maximally 50/N T per texture, where N T is the number of textures. Hence, the maximum number of filters for any image is 50.</p><p>The filters designed by this technique are not band-pass filters. Consequently, using a smoothing operator dependent on the center frequency, as suggested in Section 2.1, is not appropriate. Hence, a fixed Gaussian smoothing filter with s s = 8 is used. This selection of filter size was based on numerous experiments.</p><p>It is worth noting that this approach is optimized with respect to image representation-it is closely related to the Karhunen-Loeve transform <ref type="bibr" target="#b39">[40]</ref>. However, optimized representation does not imply optimized discrimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Prediction Error Filter</head><p>Yet another filtering scheme optimized with respect to the representation is the linear prediction error filtering scheme of Randen and Husøy <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. The filters are designed to give the least squared prediction error for each texture, thus the number of filters is the same as the number of textures. A linear predictor in image processing is an equation of the form</p><formula xml:id="formula_8">$ , , , , , x m n k l x m k n l k l 0 5 1 6 1 6 1 5 = - - - ³ Ê q 1 (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>predicting a pixel value on the basis of neighboring pixels in the neighborhood 1 using the coefficients q(k, l). The filter is optimized by minimizing $ , , ,</p><formula xml:id="formula_10">x m n x m n m n 0 5 0 5 2 7 - Ê 2 .</formula><p>The least squares error (LSE) predictor for a texture will be the predictor yielding maximum similarity between the texture and the predictor output, in the squared error sense. Generally, the LSE predictors for different textures are different. Hence, for any texture the predictor yielding minimum mean error energy will be the predictor designed with respect to that texture. This may be used for classification, since the predictor yielding minimum local prediction error energy most likely corresponds to the underlying texture. In the experiments reported here, the smoothing filter is a Gaussian low pass filter with bandwidth given by s s = 8, just like with the eigenfilters. Classification is obtained by assigning each pixel to the class corresponding to the minimum prediction error. In the experiments herein, the region of support of the predictor is circular with radius four pixels.</p><p>Like the eigenfilter approach, this approach is only optimized with respect to image representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Optimized Representation Gabor Filter Bank</head><p>In order to tune the filters to the characteristics of the underlying textures, Bovik et al. <ref type="bibr" target="#b13">[14]</ref> suggested using narrowband Gabor filters. The filters' central frequencies are tuned to the spectral peaks of the textures. That is, for each texture the central frequencies of the corresponding Gabor filters are selected as the frequencies corresponding to the principal spectral peaks of the texture. Bovik et al. suggest a manual procedure for determining the spectral peaks. However, this procedure should easily be extendable to be fully automatic <ref type="bibr" target="#b13">[14]</ref>. The manual procedure was implemented, selecting two filters per texture. The smoothing filter was tuned with respect to the center frequency of the selected filter.</p><p>We note that also this approach is optimized with respect to image representation, thus giving no guarantee for good feature separation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.4">Optimized Two-Class Gabor Filter</head><p>A Gabor filter design scheme yielding filters optimized with respect to feature separation has been suggested by Dunn and Higgins <ref type="bibr" target="#b43">[44]</ref>. The scheme is designed to classify problems involving two textures. The Gabor filter center frequency giving features yielding minimum modeled classification error is designed. The optimal center frequency is determined by evaluating a large range of center frequencies (using the Fourier transform) and selecting the best candidate. The user is required to select the bandwidth, s, of the filter, see <ref type="bibr" target="#b1">(2)</ref>. Gabor filters with s-values 2, 4, 8, and 16 were evaluated. These s-values are suggested by Weldon et al. <ref type="bibr" target="#b14">[15]</ref>. Furthermore, as suggested by Weldon et al., smoothing Gaussian filters with spatial widths given by s s = 2s (see Section 2.1) were applied.</p><p>Inherently, this filter design approach is based on classification of the feature image by a threshold classifier. Such a simple classifier is less complex to design and use than classifiers like the LVQ. Furthermore, a large parameter size typically requires more training data vectors. Hence since a threshold classifier has only one parameter, the needed amount of training data is relatively low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.5">Optimized Multi-Class Gabor Filter Bank</head><p>The previous approach to optimized filter design was limited to two-texture problems with one filter. Furthermore, the filter bandwidth had to be determined heuristically. These issues are addressed by Weldon et al. <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. In their approach, a bank of Gabor filters is designed for problems involving an arbitrary number of textures. The user is only required to select the number of filters to be used. The approach is based on the feature extraction model developed by Dunn and Higgins <ref type="bibr" target="#b43">[44]</ref>. However, a modified criterion function, incorporating the effect of the filter size on the edge accuracy, is used. This approach furthermore allows more than two textures and more than one filter.</p><p>The filter size is determined by evaluating a number of filter sizes and selecting the best candidate. Different filter sizes are allowed for the different filters in the filter bank. The s and s s values, ( <ref type="formula" target="#formula_3">2</ref>) and (1), suggested by Weldon et al. <ref type="bibr" target="#b14">[15]</ref> were also used in these experiments, that is, s = 2, 4, 8, 16, and s s = 2s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.6">Optimized Two-Texture FIR Filters</head><p>The Gabor filter is a band pass filter with a Gaussian shaped pass band. The only free parameters of such a filter are the radial center frequency, the orientation, and the bandwidths. By allowing more free parameters, it should be possible to adapt the filter better to the underlying textures. Mahalanobis and Singh <ref type="bibr" target="#b30">[31]</ref> suggest a two-texture design approach yielding FIR filters with maximum ratio between the extracted mean feature values. That is, filters maximizing the criterion</p><formula xml:id="formula_11">J MS v v = m m 1 2 ,</formula><p>are designed, where m v i is the mean feature value for texture i.</p><p>Randen and Husøy <ref type="bibr" target="#b17">[18]</ref> show that this criterion is insufficient for some texture pairs, and develop an optimization scheme allowing other criterion functions. Optimizations with respect to the criteria</p><formula xml:id="formula_12">J U v v v v = - m m m m 1 2 1 2 2 4 9</formula><p>and</p><formula xml:id="formula_13">J F v v v v = - + m m s s 1 2 1 2 2 2 2<label>4 9</label></formula><p>, where s v i 2 is the feature variance, are shown to yield better results. The criterion J U was originally suggested by Unser <ref type="bibr" target="#b22">[23]</ref> for designing optimized texture transforms and J F was originally suggested by Fisher <ref type="bibr" target="#b28">[29]</ref> for linear classifier design.</p><p>For J U , a closed form solution was presented, while for J F an approximate closed form solution and a gradient search solution are presented. Only the closed form solutions will be evaluated here.</p><p>Inherently, all these filters assume a threshold classifier, as was also the case with the optimized Gabor filters. Like the eigenfilters, filters designed by these approaches are in general not band pass filters, thus we use a Gaussian smoothing filter with s s = 8.</p><p>The size of the filter mask is also of importance for the results. A symmetric region of support is intuitively preferential for accurate edge localization. In order to have a symmetric region of support, an odd sized mask is required. Preliminary experiments indicate that mask sizes 5 5 and up are adequate for the given resolution. A few texture pairs have required larger than 5 5 mask sizes. In the experiments, filters with mask sizes 7 7 are optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.7">Optimized FIR Filter Bank</head><p>The FIR two-texture optimization with respect to the criterion functions J MS and J U have been extended to multipletexture multiple-filter solutions <ref type="bibr" target="#b17">[18]</ref>. The solution is based on one filter separating one group of textures from another, and then subsequent filters separating the textures within a group, hierarchically.</p><p>Note that this technique is also designed with thresholding as the inherent classifier, making the classifier design and application computationally simple. The same smoothing is used with these filters as with the two-texture filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.8">Back Propagation Designed Mask</head><p>Neural networks have proved to be of practical utility in numerous applications and have also been applied to texture feature extraction. Jain and Karu <ref type="bibr" target="#b44">[45]</ref> suggest extracting features and classifying using a feed forward neural network trained by the back-propagation rule. In this approach, the input nodes cover a neighborhood of image pixels. The inputs are weighted and summed in the nodes in the network, thus parts of the network may be formulated as a filter or filter bank. Furthermore, the application of the nonlinearities in the network resembles the nonlinearity in the local energy function. Hence, this approach is very similar to filtering approaches. The scheme may be modified to utilize the effect of the smoothing operation in the local energy function <ref type="bibr" target="#b44">[45]</ref>. However, this generalization is not used in the experiments due to implementational and complexity issues.</p><p>A three-layer neural network is used and the neural network parameters (numbers of nodes in the layers, etc.) used are the same as the ones used in <ref type="bibr" target="#b44">[45]</ref>. Since this approach has filtering, nonlinearity, smoothing, and classification all in one, the standard setup (Fig. <ref type="figure" target="#fig_0">1</ref>) is not used for these operations. Furthermore a 5 5 median filter is applied as proposed <ref type="bibr" target="#b44">[45]</ref> to the resulting class map to reduce speckle-like classification errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Classical Nonfiltering Approaches</head><p>The focus of this paper is on filtering and local energy estimation for texture recognition. An extensive coverage of non-filtering approaches will not be given. However, due to the fundamental importance and wide range of applications of some nonfiltering approaches, a brief review is necessary. Furthermore, to provide a reference framework with techniques familiar to readers who are not familiar with filtering, comparisons with two classical nonfiltering approaches are provided. Results with co-occurrence (statistical) and autoregressive (model-based) features are presented in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Statistical Features</head><p>In statistical approaches, the textures are described by statistical measures. One commonly applied and referenced method is the co-occurrence method, introduced by Haralick <ref type="bibr" target="#b35">[36]</ref>. In the co-occurrence method, the relative frequencies of gray level pairs of pixels at certain relative displacements are computed and stored in a matrix, the cooccurrence matrix P. For G gray levels in the image, P will be of size G G. If G is large, the number of pixel pairs contributing to each element, p ij , in P will be low, and the statistical significance poor. On the other hand, if the number of gray levels is low, much of the texture information may be lost in the image quantization. Ohanian and Dubes <ref type="bibr" target="#b21">[22]</ref> reported that G = 8 was an appropriate choice for subimages of size 32 32. These parameters have been chosen for the experiments in this paper. Since the task is supervised segmentation, overlapping subimages will be used. As suggested by other researchers <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b21">[22]</ref>, the nearest neighbor pairs at orientations 0 o , 45 o , 90 o , and 135 o will be used in the experiments.</p><p>Haralick <ref type="bibr" target="#b35">[36]</ref> suggests 14 features describing the twodimensional probability density function p ij . Four features that are commonly used <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b35">[36]</ref> have been selected. These are the Angular Second Moment (ASM), Contrast (Con), Correlation (Cor), and Entropy (Ent). They are given by</p><formula xml:id="formula_14">ASM = = - = - Ê Ê p ij j G i G 2 0 1 0 1 (5) Con = % &amp; K ' K ( ) K * K -= = - Ê Ê N p ij i j n n G 2 0 1 (6) Cor = - = - = - Ê Ê 1 0 1 0 1 s s m m x y ij x y j G i G ijp (7) Ent = = - = - Ê Ê p p ij ij j G i G log , 0 1 0 1 (8)</formula><p>where m x , m y , s x , and s y are the means and the standard deviations corresponding to the distributions</p><formula xml:id="formula_15">p p i x ij j G 0 5 = = - Ê 0 1 (9) p p j y ij i G 1 6 = = - Ê 0 1 .<label>(10)</label></formula><p>We extract each of these four features at each of the four different orientations, thus the feature vectors are 16dimensional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Model-Based Features</head><p>Another major class of texture features is the model-based features. With model-based features, some image model is assumed, its parameters estimated for a subimage, and the model parameters, or attributes derived from them, are used as features.</p><p>As an example of this class of features, the multiresolution autoregressive (AR) features introduced by Mao and Jain <ref type="bibr" target="#b33">[34]</ref> are used. The autoregressive model for an image x(m, n) can be expressed as</p><formula xml:id="formula_16">x m n k l x m k n l m n k l , ,<label>, , ,</label></formula><p>, 0 5 1 6 1 6 0 5</p><formula xml:id="formula_17">1 5 = - -+ ³ Ê q</formula><p>s e e 1 <ref type="bibr" target="#b10">(11)</ref> where 1 is the model neighborhood, q(k, l) are the model parameters, and see(m, n) the model error term. The feature vectors are composed by all the model parameters from the three neighborhoods in Fig. <ref type="figure" target="#fig_0">10</ref>. Furthermore, the error en-Fig. <ref type="figure" target="#fig_0">10</ref>. Neighborhood sets 1 1 , 1 2 , and 1 3 for the AR features. Each 1 i corresponds to one relative pixel position.</p><p>ergy, se, is used as a feature. The parameters are determined in 25 25 pixel overlapping windows. In order to overcome problems with too high feature variances, the features are smoothed. The smoothing filter applied in the experiments here was a Gaussian low-pass filter with s s = 3, see <ref type="bibr" target="#b0">(1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>In our experiments, we evaluate the different feature extraction approaches by performing supervised segmentation on several test images of varying complexity, Figs. <ref type="figure" target="#fig_9">11</ref> and<ref type="figure" target="#fig_10">12</ref>. As the feature quality criterion, we use the classification error, "the most common measure of performance for a recognition system" <ref type="bibr" target="#b21">[22]</ref>.</p><p>All filter optimization and classifier training are performed on 256 256 subimages of the texture images that are not part of the test images. For the classifier design, about 16,000 features were extracted from these 256 256 images individually and used for training.</p><p>The local energy function used is the one described in Section 2.1, i.e., squaring, Gaussian smoothing, and taking the logarithm. For subsampled filters, the modification of Randen and Husøy <ref type="bibr" target="#b16">[17]</ref> is used. For filters not having a narrow pass-band, Gaussian low-pass filters with s s = 8 (empirically determined) are used. As described in Section 2.2, the classifier is LVQ <ref type="bibr" target="#b34">[35]</ref> in most cases. However, with the optimized Gabor filters <ref type="bibr" target="#b43">[44]</ref>, Section 2.4.4 and the optimized FIR filters, Sections 2.4.6 and 2.4.7, thresholding is used. With the optimized prediction error filters, Section 2.4.2, the image is classified by assigning the class label associated with the minimum error predictor. The classifiers and energy functions applied are summarized in Table <ref type="table">1</ref>. The method identifiers used in this and subsequent tables are defined in Table <ref type="table">2</ref>.</p><p>A normalization by a global normalization factor is applied for each feature. The global normalization factors are determined as the factors yielding unity variance for the image in Fig. <ref type="figure" target="#fig_9">11a</ref>.</p><p>The presentation of the results is divided in three parts. First, in Section 3.1 a discussion of the test images is given. Next, in Section 3.2, heuristically designed, i.e., fixed filter banks are considered. In Section 3.3, critically sampled filter banks (including wavelet transform/packets) are discussed. Finally, in Section 3.4, results with the optimized filters and filter banks are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Test Images</head><p>We have used three different and commonly used texture sources for our test images; the Brodatz album <ref type="bibr" target="#b46">[47]</ref>, the MIT Vision Texture database <ref type="bibr" target="#b47">[48]</ref>, and the MeasTex Image Texture Database <ref type="bibr" target="#b48">[49]</ref>. Consequently, we use images captured using different equipment and under different conditions. We have selected textures with a granularity which we have judged to be appropriate for the sizes of the test images. Since we train and test on separate portions of the texture images we have selected texture images which are visually stationary, i.e., their visual properties do not change too much over the image.</p><p>All textures are gray-scale images when presented to the methods. The dynamic ranges are represented by eight bits per sample. In order to make the textures nondiscriminable for the local mean gray level or local variance, the images have each separately been globally histogram equalized prior to being used.</p><p>We have tested simple two-texture images, complicated five-texture images, images with simple borders but as many as ten textures, and images with very complex borders and as many as 16 textures. Since all feature extractors extract features using some window or neighborhood, the complexity and shape of the borders is of major interest. The ability to cope with edges is of course an important feature and the test images should be appropriate in this respect.</p><p>The 256 256 5-texture images are: Fig. <ref type="figure" target="#fig_9">11a</ref>, consisting of D77, D84, D55, D53, and D24 from <ref type="bibr" target="#b46">[47]</ref>, Fig. <ref type="figure" target="#fig_9">11b</ref>, consisting of Fabric.0000, Fabric.0017, Flowers.0002, Leaves.0006, and Leaves.0013 from <ref type="bibr" target="#b47">[48]</ref>, Fig. <ref type="figure" target="#fig_9">11c</ref>, consisting of Fabric.0009, Fabric.0016, Fabric.0019, Flowers.0005, and Food.0005 from <ref type="bibr" target="#b47">[48]</ref>, Fig. <ref type="figure" target="#fig_9">11d</ref>, consisting of Fabric.0007, Fabric.0009, Leaves.0003, Misc.0002, and Sand.0000 from <ref type="bibr" target="#b47">[48]</ref>, and Fig. <ref type="figure" target="#fig_9">11e</ref>, consisting of Asphalt.0000, Concrete.0001, Grass.0002, Misc.0002, and Rock.0005 from <ref type="bibr" target="#b48">[49]</ref>.</p><p>The 512 512 16-texture images are: Fig. <ref type="figure" target="#fig_9">11f</ref>, consisting of D3, D4, D5, D6, D9, D21, D24, D29, D32, D33, D54, D55, D57, D68, D77, and D84 from <ref type="bibr" target="#b46">[47]</ref> and Fig. <ref type="figure" target="#fig_9">11g</ref>, consisting of Fabric.0007, Fabric.0009, Fabric.0013, Fabric.0014, Fabric.0016, Flowers.0005, Food.0005, Grass.0001, Leaves.0003, Leaves.0008, Leaves.0012, Metal.0000, Metal.0002, Misc.0002, Sand.0000, and Stone.0004 from <ref type="bibr" target="#b47">[48]</ref>.</p><p>The 256 640 10-texture images are: Fig. <ref type="figure" target="#fig_9">11h</ref>, consisting of D4, D9, D19, D21, D24, D28, D29, D36, D37, and D38 from <ref type="bibr" target="#b46">[47]</ref> and Fig. <ref type="figure" target="#fig_9">11i</ref>, consisting of Fabric.0009, Fabric.0016, Fabric.0019, Flowers.0005, Food.0005, Leaves.0003, Misc.0000, Misc.0002, Sand.0000, and Stone.0004 from <ref type="bibr" target="#b47">[48]</ref>.</p><p>Finally, we also have some 256 512 texture pair images which are: Fig. <ref type="figure" target="#fig_10">12a</ref>, consisting of D4 and D84 from <ref type="bibr" target="#b46">[47]</ref>, Fig. <ref type="figure" target="#fig_10">12b</ref>, consisting of D12 and D17 from <ref type="bibr" target="#b46">[47]</ref>, and Fig. <ref type="figure" target="#fig_10">12c</ref>, consisting of D5 and D92 from <ref type="bibr" target="#b46">[47]</ref>.</p><p>We note that although Fig. <ref type="figure" target="#fig_10">12c</ref> looks simple, it was very difficult to discriminate for several of the approaches. From the experiments, we will see the need for a wide variety of test images when assessing the relative performances of texture classification methods. If we look at for example the optimal representation Gabor filter bank, it is the best optimized approach for Fig. <ref type="figure" target="#fig_9">11a</ref> and fails completely for Fig. <ref type="figure" target="#fig_9">11b</ref>.</p><p>Another observation is that the texture pair of Fig. <ref type="figure" target="#fig_10">12c</ref> is rather difficult to discriminate for several approaches. It</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 1 DETAILS ON THE SMOOTHING FILTERS AND CLASSIFIERS USED IN THE EXPERIMENTS</head><p>For the smoothing filters, the s s -parameter of a Gaussian low-pass filter is given. Any f 0 is the subband center frequency and s is the parameter of a Gabor filter in the filter bank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 2 SUMMARY OF IDENTIFIERS USED TO IDENTIFY THE METHODS IN THE RESULT TABLES</head><p>must be kept in mind that 50 percent error would be attained by randomly picking a class assignment. Hence, 15-25 percent error is significant.</p><p>We also observe that the 10-texture image of Fig. <ref type="figure" target="#fig_9">11i</ref> gives close to random performance for all approaches (random picking of a class assignment would yield 10 percent chance of correct class assignment, i.e., 90 percent error). In essence, none of the approaches are giving any useful results for this image. We do not have any explanation of the poor performance on this image, but include it to stimulate research on how to improve texture classification methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments with the Heuristically Designed Filter Banks</head><p>The results for most of the heuristically designed feature extractors are presented in Table <ref type="table" target="#tab_1">3</ref>. For the wavelet frame experiments only one variant is listed in Table <ref type="table" target="#tab_1">3</ref>. The same is the case with the QMF and arbitrarily decomposed Gabor filter bank experiments. More detailed results from these filter classes are given in Tables <ref type="table" target="#tab_2">4</ref> and<ref type="table" target="#tab_3">5</ref>.</p><p>In order to get an increased insight from the experiments, there are multiple "dimensions" in the results. Some approaches allow variations of the filter responses and subband decomposition, some are fixed on filter response, some on decomposition, and some on both. The number of feature images also vary much, from eight to 40 features, having considerable impact on the computational complexity and memory requirements. The complexity, subband decomposition, and filter response issues will be discussed later, but first an overall discussion of the results is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Overall Discussion</head><p>No clear hierarchy of classification performances is observed in Table <ref type="table" target="#tab_1">3</ref>. For some images, some approaches are good, for different images, others are good. No methods are consistently poor, but many methods have examples with poor relative performance.</p><p>Considering Table <ref type="table" target="#tab_1">3</ref>, evidently the "old" Laws and ring/wedge filters are not very good. They never stand out as clear winners, and particularly the Laws approach fail completely in the case of the simple image in Fig. <ref type="figure" target="#fig_10">12a</ref>. One possible explanation might be that the frequency spectra of the filters are too smooth, giving too poor separation of the frequency components of the textures. Furthermore, we also have an indication that the basic assumption behind the ring/wedge filters that frequency and orientation can be treated separately is not true.</p><p>The commonly referred dyadic Gabor filter bank show rather poor performance for some of the test images, Figs. 11b, 11d, 11f and Fig. <ref type="figure" target="#fig_10">12c</ref>. Similar comments apply to the arbitrary Gabor filter bank. Compared to the best approaches, also these approaches have smooth frequency responses of the channel filters. This leads to poor separation of the frequency content in the image, which might account for the moderate performance.  The DCT approach did also show poor relative performance for a few images, Figs. <ref type="figure" target="#fig_9">11a</ref> and<ref type="figure" target="#fig_9">11d</ref> and Fig. <ref type="figure" target="#fig_10">12a</ref>. On the overall results, however, it was only beaten by the best QMF and wavelet approaches with 40-dimensional feature spaces. Compared to the 8-feature DCT approach this is remarkable.</p><p>With the QMF and wavelet approaches, only the best decomposition/filter response combinations are shown in Table <ref type="table" target="#tab_1">3</ref>. More results are given in Table <ref type="table" target="#tab_2">4</ref>. The QMF and wavelet frame approaches are among the best for most images. Examples of the classification results for one QMF filter bank (f16b (d)) are shown in Fig. <ref type="figure" target="#fig_3">13</ref>. These results correspond to the textures in Figs. <ref type="figure" target="#fig_9">11a</ref> and<ref type="figure" target="#fig_9">11f</ref>. The QMF f16b (d) is the overall best approach.</p><p>Also the popular co-occurrence method gives rather poor performance, giving actually the worst results in three cases, Figs. <ref type="figure" target="#fig_9">11d</ref> and<ref type="figure" target="#fig_9">11e</ref> and Fig. <ref type="figure" target="#fig_10">12b</ref>. The AR features were slightly better for most images, but they were giving the worst results in two cases, Figs. <ref type="figure" target="#fig_9">11a</ref> and<ref type="figure" target="#fig_9">11h</ref>. The best filtering approaches yield classifications that are as good as or better than the co-occurrence and AR methods in practically all cases.</p><p>To summarize, Laws and ring/wedge filters were never found to perform best, while each of the other approaches had at least one test image where it performed best. The best average results and the highest number of best cases is observed for the QMF filter bank f16b (d). Hence, we may conclude that f16b (d) is the winner and the Laws and ring/wedge filters are the losers. If computational complexity is an important issue however, the DCT approach is the winner due to its good overall performance and low complexity. We may also conclude that the popular Gabor filter and co-occurrence features are clearly not superior.</p><p>Finally, remember that it is a quite common practice in texture classification to pick training data from the test features as discussed in Section 2.2.2. This practice has not been used in these experiments. In order to simulate a real application environment, all classifier training has been performed on features from separate subimages. Furthermore, no edge or texture border specific training data are picked. These issues must be kept in mind when comparing the results with previously published results. For a further analysis of the impact of this choice, see Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Filter Response</head><p>Table <ref type="table" target="#tab_2">4</ref> gives the numbers for the performances of the wavelet frames, QMF, and arbitrary Gabor filter banks. Careful examination of the results tells us that there are consistent trends with respect to the performances of various filter responses. The most clear conclusion from the results is that the performance of the Gabor filters is inferior to the wavelet and QMF filter classes. This despite the fact that the Gabor filter is the preferred filter in several works <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b49">[50]</ref>.</p><p>Next, we may also see an overall detoriation in the results when we move from shorter Daubechies wavelet bases to longer bases. Note that the numbers in the identifiers for the QMF and wavelet filters represent number of coefficients in the prototype low-pass filter. A high number typically corresponds to a wide impulse response but a crisp frequency response, and vice versa, see Figs. <ref type="figure" target="#fig_8">9</ref> and<ref type="figure" target="#fig_6">7</ref>.</p><p>What do we learn from these experiments? Intuitively, we would desire a filter with a compact representation in the spatial domain (due to edge effects), and good frequency response crispness and high stop band attenuation (in order to discriminate the textures' spectra). However, the poor performance of the Gabor filter (which has optimal joint resolution in the spatial and the frequency domains) indicates that optimal joint resolution is no ultimate goal.</p><p>Can we then tell whether spatial resolution is more important than frequency resolution, or vice versa? The QMF filters have significantly crisper frequency responses than the Gabor filters, but also wider impulse responses. Since these filters give significantly better results than the Gabor filters, we may conclude that crisp frequency response is an important issue in texture classification. On the other hand, the variations in the different QMF filter crispnesses do not have a major performance impact.</p><p>As we can see, the QMF filters are overall giving better results than the Daubechies wavelets. This is probably attributable to the significant asymmetric unit pulse responses of the Daubechies wavelets. A nonsymmetric filter response will lead to a consistent edge detection error and higher classification errors. As we might expect, the Daubechies wavelets also give more error the longer the impulse response, i.e., the larger the asymmetry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Subband Decomposition</head><p>Except for the images where the methods fail (like Fig. <ref type="figure" target="#fig_9">11i</ref>), the choice of subband decomposition is very significant. The clear winner of the decompositions is the decomposition of Fig. <ref type="figure" target="#fig_5">6d</ref>. This is the overall best decomposition for all filters. This is also the decomposition with most subbands, i.e., highest feature dimensionality: 40.</p><p>It might seem like the expected conclusion that the decomposition with most features yields the best results. This would indeed be the case if we did not use separate test and training datasets. However, it should be kept in mind that more features makes it more difficult for the classifier to generalize, thus more features actually presents an increased challenge to the classification.</p><p>Decompositions of Figs. 6a-6c are all dyadic, also known as wavelet decompositions. The more levels of the dyadic decomposition, the more the low frequency band is Fig. <ref type="figure" target="#fig_3">13</ref>. Classification results for the QMF "f16b" filter bank for the textures in Figs. <ref type="figure" target="#fig_9">11a</ref> and<ref type="figure" target="#fig_9">11f</ref>.</p><p>split-and the more features. Since we may expect textures to have their characteristic features in higher frequency bands, we would not expect that increasing the depth of the decomposition would increase the performance. This is indeed seen on the results as well, where we can see a consistent lack of improvement when the depth is increased. In fact as the depth becomes as high as five (Fig. <ref type="figure" target="#fig_5">6c</ref>), the performance drops consistently probably due to the mentioned problems for the classifier to generalize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Complexity Issues</head><p>When comparing the results, complexity issues should also be kept in mind. Most of the filtering approaches are significantly less computationally complex than the co-occurrence and AR methods. For the filtering approaches, filtering and classification are the main contributors to the total complexity of the system. The DCT approach has low filtering complexity (short separable filter masks with fast implementation schemes) and low feature dimensionality, generally yielding relatively low classifier complexity. The Laws, ring and wedge, Gabor, and some of the wavelet and QMF filter banks have high filtering complexities, whereas the IIR QMF filters have low complexities. Low feature count yields low classification complexity. In our setup the complexity contribution from the LVQ classifier and the feature extractors were of the same order. Hence classifier complexity is an important component in the overall complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Summary</head><p>From Tables <ref type="table" target="#tab_1">3</ref> and<ref type="table" target="#tab_2">4</ref>, no single feature extraction method is consistently superior. The main insight we may learn from this, is that when designing a filter bank for a particular texture problem, it is advantageous to test multiple approaches. We do, however, see patterns in the results that may exclude several of the approaches from such a study.</p><p>An inherent assumption made when filter banks are used for texture feature extraction is that the spectral signatures of different textures are different, 3 see Section 2. For problems with many textures or textures with subtle spectral 3. Analog discussions do also apply to other representation spaces than the frequency space. differences, it is reasonable to assume that the spectral decomposition has a significant effect. This intuitive idea is supported by the experiments, and we see great importance of the filter classes and decompositions for difficult twotexture images and for most multi-texture images.</p><p>In many circumstances, the effort in testing numerous filter banks may be too large. For these applications, one filter bank should be recommended. This filter bank should have a reasonably good performance in most cases. One such choice is the bank with the QMF filter f16b using the sub-band decomposition in Fig. <ref type="figure" target="#fig_5">6d</ref>. However, in several cases this 40-dimensional filter bank may be too computationally complex. A viable alternative with significantly lower feature dimensionality is the DCT approach, which we would recommend if lower complexity is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiments with Critically Sampled Filter Banks</head><p>Considering the full rate QMF and wavelet frame approaches, Table <ref type="table" target="#tab_2">4</ref>, relative to the results from the critically  sampled QMF and wavelet transform/packet approaches, Table <ref type="table" target="#tab_3">5</ref>, a few conclusions may be drawn. First of all, the filter responses for the critically sampled QMF filters, the wavelet transforms and the wavelet packets are simply subsampled versions of the ones obtained by the full rate or over-complete counterparts. We see that, as expected, using decimated filter outputs overall degrades the results. The major cause is worse edge resolution due to the subsampling. However, the significantly decreased computational complexity <ref type="bibr" target="#b32">[33]</ref> should be kept in mind.</p><p>Furthermore, we see that the trend in the results is the same with the critically sampled approaches as it was with the full rate approaches. That is, image, filter class, and decomposition combinations that yielded poor relative results in full rate do also yield poor results when critically sampled, and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experiments with Optimized Filters</head><p>The results from the optimized filtering experiments are presented in Table <ref type="table" target="#tab_4">6</ref>. Some of the optimization approaches are only applicable for two-texture cases, and the multi-texture table entries for these are marked by "N/A."</p><p>Despite the fact that the training times for the back propagation designed masks were significant, the results were not useful for any of the images in this test. Useful results were only obtained for some very simple texture pairs. One example is shown in Fig. <ref type="figure" target="#fig_11">14</ref>. Improvements using a modified scheme have been reported <ref type="bibr" target="#b44">[45]</ref>, but has for implementational and complexity reasons not been tested here.</p><p>The eigenfilter approach is the overall best optimized approach. However, it must be remembered that the number of filters is relatively high with this approach. For twotexture images, the number of filters is typically in the range 16-18, while for multi-texture images it is in the range 36-50. Hence, the argument of low complexity versus the heuristic filters is not applicable. For reference we have made a list of number of features for the different feature extraction approaches in Table <ref type="table" target="#tab_5">7</ref>.</p><p>The optimized representation Gabor filter bank was the only optimized filtering approach doing a really good job on the image of Fig. <ref type="figure" target="#fig_9">11a</ref>. However, for most of the other test images, it is only giving similar, and even in some cases (Figs. 11b, 11e, and 11g and Fig. <ref type="figure" target="#fig_10">12c</ref>) significantly worse results than the best optimized filtering approaches, despite high feature dimensionality. We assume that the problems experienced with this approach are due to the fact that it is optimized with respect to representation, not discrimination.</p><p>The best result for the image in Fig. <ref type="figure" target="#fig_9">11f</ref> in this study was obtained with the prediction error filters. However, despite these nice results, a remarkably poor result was obtained with the image of Fig. <ref type="figure" target="#fig_10">12c</ref> and relatively poor results with the images of Figs. <ref type="figure" target="#fig_9">11a</ref> and<ref type="figure" target="#fig_9">11e</ref>. Hence, this approach is not very robust.</p><p>It is interesting to observe the performances of the three approaches optimizing filters with respect to representation, i.e., the eigenfilters, the optimized representation Gabor filter bank and the prediction error filters. For the latter two we do observe some cases with breakdown in performance, particularly for Fig. <ref type="figure" target="#fig_9">11e</ref> and Fig. <ref type="figure" target="#fig_10">12c</ref>, most likely corresponding to cases where textures are too similar for discrimination. Close examination of the confidence matrices 4 for these cases support this assumption, i.e., a few of the textures were severely misclassified while other textures had nice classification results. When the eigenfilter approach do not have the same problems with breakdowns, this might be due to the high number of features and the versatile classification algorithm which compensate for the problems.</p><p>The results from the optimized Gabor filters and optimized Gabor filter banks are fairly good, but the results indicate problems with similar textures-especially when using only one or a few filters. In particular, the results for the 4. The confidence matrix shows how the misclassification is distributed among the textures in the image, i.e., how many percent of texture 1 was classified as belonging to texture class 2, etc.  <ref type="figure" target="#fig_9">11a</ref> and<ref type="figure" target="#fig_10">12c</ref> are noted. On the other hand, the optimized Gabor filters yield one-dimensional feature spaces for two textures. Hence, class labels may be assigned to the feature values by thresholding. Thresholding has a very low computational complexity compared to classifiers like the LVQ. Furthermore, training the threshold classifier means determining one scalar parameter per feature image. This is clearly a simpler task than training the parameters of, say, the LVQ classifier.</p><p>Of the optimized FIR filters, the clearly best and most versatile criterion is the J U criterion, while the J MS gives poorer performance for most images. The J F criterion does not give any improvement over the J U criterion for any of the texture pairs and it is not applicable to multi-texture images. For two-texture images, the J U -optimized filters are the winners of this study. Overall, they outperform all other approaches, optimized and heuristic, irrespective of number of features for texture-pair images. Since these approaches yield only one feature image that may be classified by thresholding, they are also among the least computational demanding for two-texture images.</p><p>Even for multi-texture images, filters optimized with respect to J U are among the best optimized filters, except for the image in Fig. <ref type="figure" target="#fig_9">11e</ref>. Compared to the heuristic approaches on the other hand, the performance for the multi-textured images is not very good. However we note that these schemes are designed to utilize thresholding as the classification scheme also for multi-texture images, and that the filtering and classification scheme for multi-texture images is hierarchical. Hence, the computational complexity is very low which, in some cases, may make this approach viable still.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 8 DETAILED SUMMARY OF THE CLASSIFICATION ERRORS FOR DIFFERENT WAVELET, GABOR, AND QMF FULL RATE FILTER BANKS</head><p>The averages are summarized in Table <ref type="table" target="#tab_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSIONS</head><p>We have seen how various filtering approaches yield different results for different images. No single approach did perform best or very close to the best for all images, thus no single approach may be selected as the clear "winner" of this study. In addition to the classification error issue is the issue of computational complexity. If we take the classification error and computational complexity into consideration, the following conclusions may be drawn:</p><p>Much of the focus in the filter optimization approaches is on a low feature count, thus many of the optimization schemes yield nice computational characteristics. For multi-textured images this however comes at the cost of an increase in the classification error, in our experiments about 3.5 percent average increase from the best heuristic to the best optimized approach.</p><p>For two-textured images, the conclusion is very clear. The best results were obtained with the filters optimized with respect to J U or J F . Since none of the other approaches are less computationally complex they should be the clear choice.</p><p>For multi-textured images the most robust and overall best performance was achieved with the f16b (d) filter bank-having an overall error rate of only 26 percent. This is however a high-complexity 40-dimensional feature extractor which puts high requirements on the system. If the complexity can be allowed however, this is the system of choice.</p><p>Otherwise the choice is between the f16b (d) critically sampled filter bank and the full rate DCT approach. They both have about 29 percent overall error. The f16b (d) critically sampled filter bank will lead to only 1/8 the number of feature samples compared to the DCT approach, thus classification will be less complex.</p><p>If even these systems are too complex, the next choice will be an optimized approach. The best optimized approach-the Eigenfilter approach-is not an option. Its feature dimensionality, and thus its complexity, is in the range of the f16b (d) full rate filter The averages are summarized in Table <ref type="table" target="#tab_3">5</ref>.</p><p>bank. This leaves us with the second best optimized approach, the J U -optimized filter bank, or the fourth best approach, the prediction error filters. These approaches have overall error rates of 31.0 percent and 33.3 percent, respectively. Both of these approaches are characterized by a generally low feature dimensionality and extraordinary simple classification schemes. The third-best scheme, the 10-filter optimized Gabor filter bank is outperformed by the DCT approach regarding both complexity and overall error rate.</p><p>Based on the overall impression from the experiments reported here, we would not give a general recommendation to use any of the other approaches. We do however recognize that for specific images some of the other techniques give the best results. It might therefore be advisable to test the Gabor filter bank, AR, and co-occurrence features in the case that they may perform well for the specific dataset at hand. However the co-occurrence and AR schemes do have a significant computational complexity, which should be kept in mind.</p><p>In addition to these recommendations, we would also like to make some comments regarding system setups that are commonly presented in the literature.</p><p>The commonly used dyadic decomposition <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b37">[38]</ref> (also known as the wavelet transform decomposition or octave band decomposition) is generally not superior to other decompositions. Our results indicate that it is actually inferior to the decomposition of Fig. <ref type="figure" target="#fig_5">6d</ref>, supporting similar findings of Chang and Kuo <ref type="bibr" target="#b23">[24]</ref>. Furthermore, we see that increasing the depth (i.e., adding more subbands) of the dyadic decomposition do not improve the classification results. The very popular Gabor filter <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b24">[25]</ref> is outperformed in most cases. Hence, there is no evidence that the Gabor filter should be preferred. Experiments without true separate test and training datasets can not be trusted. We have presented experiments showing that testing with partially the same data that were used in training the classifier leads us to the opposite conclusion than we got when we tested with separate test and training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DIRECTIONS FOR FUTURE RESEARCH</head><p>The experiments reported in this paper have taken weeks, maybe months of computer time on powerful modern workstations. Of course, the software is prototype software, made with an emphasis on short development time and high flexibility. Yet the time consumption is an indication of the problem with several of the approaches-they are very computationally complex. The computer hardware industry is giving us some relief on this issue, but there's a long way yet until the most complex approaches reach what a user would deem as acceptable interactive performance on a standard desktop computer system.</p><p>A very useful direction for future research is therefore the development of powerful texture measures that can be extracted and classified with a low computational complexity. The experiments reported here show that the current least complex schemes do not yet have quite the same nice overall classification rate as the best of the more complex ones. In our opinion this is the most important direction for future research in texture analysis.</p><p>Finally, we would also like to point the readers attention towards the implicit directions for future research presented in the conclusions of Section 4.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Experimental setup.</figDesc><graphic coords="2,31.85,60.99,237.00,276.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of a typical texture feature extraction process with filters. (a) Two synthetic textures, (b) a horizontal scan line through the image, (c) filtered, (d) nonlinear transform, (e) smoothing, and (f) the resulting feature image.</figDesc><graphic coords="2,296.10,60.99,236.72,497.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Subband split of the one-dimensional equivalent separable Laws [3] filter masks (normalized). (b) The resulting two-dimensional frequency band split. The axis labels are vertical and horizontal normalized spatial frequencies.</figDesc><graphic coords="4,50.11,60.99,464.64,161.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig.<ref type="bibr" target="#b3">4</ref>. Amplitude responses of the ring and wedge filters<ref type="bibr" target="#b11">[12]</ref>. The axis labels are normalized spatial frequencies.</figDesc><graphic coords="5,60.20,60.99,456.35,298.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Subband decompositions evaluated in this paper. Decompositions (a-c) are dyadic (octave band), while (d) is not. The axes are the same as in Fig. 3b.</figDesc><graphic coords="6,46.85,207.94,470.86,129.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The two-channel filter bank dB amplitude responses for the wavelet filters (a) "Daubechies 4," (b) "Daubechies 6," (c) "Daubechies 8," (d) "Daubechies 10," and their respective unit pulse responses (e)-(h).</figDesc><graphic coords="6,62.16,369.60,440.22,155.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. (a) One-dimensional equivalent of the amplitude response of the filter bank corresponding to a separable 3 3 Discrete Cosine Transform (normalized). (b) The resulting two-dimensional frequency band split. The axis labels are vertical and horizontal normalized spatial frequencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. The two-channel dB amplitude responses for the quadrature mirror filters (QMF) (a) "f8a," (b) "f16b," (c) "f32d," (d) "F_2_1_09," and (e) "F_2_1_smpl" and their respective low-pass prototype unit pulse responses (f)-(j).</figDesc><graphic coords="7,60.20,60.99,456.35,125.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Composite texture images used in our experiments.</figDesc><graphic coords="10,54.50,60.79,455.53,526.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The 256 512 two-texture images used in our experiments.</figDesc><graphic coords="11,52.86,60.99,207.01,311.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. (a) Texture pair D8-D84 [47] and (b) supervised segmentation by the back propagation designed mask [45].</figDesc><graphic coords="15,312.74,510.56,215.26,214.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,54.19,84.94,456.35,244.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,62.24,388.65,440.22,299.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="13,52.15,84.94,472.45,124.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="16,38.06,84.94,488.58,214.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,46.93,94.98,470.86,395.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 3 CLASSIFICATION</head><label>3</label><figDesc>ERRORS FOR DIFFERENT HEURISTICALLY DESIGNED TEXTURE FEATURE EXTRACTORS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 4 CLASSIFICATION</head><label>4</label><figDesc>ERRORS FOR DIFFERENT WAVELET, GABOR,</figDesc><table /><note><p><p><p><p>AND QMF FULL RATE FILTER BANKS</p>For details on the individual experiments, see Table</p>8</p>. The numbers represent the mean classification errors over all test images.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 5 CLASSIFICATION</head><label>5</label><figDesc>ERRORS FOR DIFFERENT WAVELET TRANSFORMS/PACKETS AND CRITICALLYDECIMATED QMF FILTERS</figDesc><table /><note><p><p><p>For details on the individual experiments, see Table</p>9</p>. The numbers represent the mean classification errors over all test images.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 6 CLASSIFICATION</head><label>6</label><figDesc>ERRORS FOR DIFFERENT OPTIMIZED TEXTURE FEATURE EXTRACTORSSee Table2for an overview of the method descriptions.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 7 FEATURE</head><label>7</label><figDesc>DIMENSIONALITY FOR THE DIFFERENT FEATURE EXTRACTION SCHEMES images of Figs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 9 DETAILED</head><label>9</label><figDesc>SUMMARY OF THE CLASSIFICATION ERRORS FOR DIFFERENT WAVELET TRANSFORMS/PACKETS AND CRITICALLY DECIMATED QMF FILTERS</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Kalle Karu and Jianchang Mao, both formerly at Michigan State University, for providing software for their approaches.</p><p>The texture mosaics used in the experiments are available in the electronic version of this paper. The test images, along with software, are also available on an "as is" basis via the web pages of the Signal Processing Group at Stavanger College, http://www.ux.his.no/sigproc/. The software is partially available as MATLAB code and partially as C code based on the HIPS image processing library.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Review of Recent Texture Segmentation and Feature Extraction Techniques</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M H</forename><surname>Du Buf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP: Image Understanding</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="359" to="372" />
			<date type="published" when="1993-05">May 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Handbook Pattern Recognition and Computer Vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tuceryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<editor>C.H. Chen, L.F. Pau, and P.S.P. Wang</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>World Scientific</publisher>
			<biblScope unit="page" from="235" to="276" />
			<pubPlace>Singapore</pubPlace>
		</imprint>
	</monogr>
	<note>Texture Analysis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rapid Texture Identification</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Laws</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Conf. Image Processing for Missile Guidance</title>
		<meeting>SPIE Conf. Image essing for Missile Guidance</meeting>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="376" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Comparative Study of Texture Measures for Terrain Classification</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Weszka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="269" to="285" />
			<date type="published" when="1976-04">Apr. 1976</date>
			<pubPlace>Man, Cybernetics</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Theoretical Comparison of Texture Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Conners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Harlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="204" to="221" />
			<date type="published" when="1980-05">May 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Texture Feature Performance for Image Segmentation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M H</forename><surname>Du Buf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kardan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="291" to="309" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Local Frequency Features for Texture Classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Strand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Taxt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="397" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Experiments with Texture Classification Using Averages of Local Pattern Matches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, Cybernetics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="426" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards a Novel Approach for Segmentation of SAR Sea Ice Imagery</title>
		<author>
			<persName><forename type="first">D</forename><surname>Clausi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jernigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th Symp. Remote Sensing of Environment and 18th Ann. Symp. Canadian Remote Sensing Society</title>
		<meeting>26th Symp. Remote Sensing of Environment and 18th Ann. Symp. Canadian Remote Sensing Society</meeting>
		<imprint>
			<date type="published" when="1995-03">Mar. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Comparative Study of Texture Measures with Classification Based on Feature Distributions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Texture Classification and Segmentation Using Wavelet Frames</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="549" />
			<date type="published" when="1995-11">Nov. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Spatial Filtering Approach to Texture Analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Coggins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="203" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Characterization of Texture by &apos;Eigenfilter</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="451" to="457" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multichannel Texture Analysis Using Localized Spatial Filters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="55" to="73" />
			<date type="published" when="1990-01">Jan. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Design of Multiple Gabor Filters for Texture Segmentation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Weldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Acoustic Speech, Signal Proc</title>
		<meeting>Int&apos;l Conf. Acoustic Speech, Signal<address><addrLine>Atlanta, Ga</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="volume">246</biblScope>
			<biblScope unit="page" from="2" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Integrated Approach to Texture Segmentation Using Multiple Gabor Filters</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Weldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Image Processing</title>
		<meeting>Int&apos;l Conf. Image essing<address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-09">Sept. 1996</date>
			<biblScope unit="page" from="955" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multichannel Filtering for Image Texture Segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Randen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Husøy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="617" to="619" />
			<date type="published" when="1994-08">Aug. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Texture Segmentation Using Filters with Optimized Energy Separation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Randen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Husøy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1999-04">Apr. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multi-Channel Filtering Techniques for Texture Segmentation and Surface Quality Inspection</title>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
		<respStmt>
			<orgName>Michigan State Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised Texture Segmentation Using Gabor Filters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Texture Classification by Wavelet Packet Signatures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="186" />
			<date type="published" when="1993-11">190. Nov. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Performance Evaluation for Four Classes of Textural Features</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Ohanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Dubes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="819" to="833" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Local Linear Transforms for Texture Measurements</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Texture Analysis and Classification with Tree-Structured Wavelet Transform</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><forename type="middle">J</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="429" to="441" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised Texture Segmentation of Images Using Tuned Matched Gabor Filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Teuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pichler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Hosticka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="863" to="870" />
			<date type="published" when="1995-06">June 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Local Discriminant Bases and Their Applications</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="358" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlinear Operators for Improving Texture Segmentation Based on Features Extracted by Spatial Filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, Cybernetics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="804" to="815" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<title level="m">Pattern Classification and Scene Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Statistical Pattern Recognition, 2nd ed</title>
		<meeting><address><addrLine>San Diego, Calif</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Schalkoff</surname></persName>
		</author>
		<title level="m">Pattern Recognition: Statistical, Structural and Neural Approaches</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Application of Correlation Filters for Texture Recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mahalanobis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2" to="173" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Texture Segmentation with Optimal Linear Prediction Error Filters</title>
		<author>
			<persName><forename type="first">T</forename><surname>Randen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Husøy</surname></persName>
		</author>
		<ptr target="http://www.ux.his.no/~tranden/" />
		<imprint>
			<date type="published" when="1994-09">Sept. 1994</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Filter and Filter Bank Design for Image Texture Recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Randen</surname></persName>
		</author>
		<ptr target="http://www.ux.his.no/~tranden/" />
		<imprint>
			<date type="published" when="1997-10">Oct. 1997</date>
			<pubPlace>Trondheim, Norway</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Norwegian Univ. of Science and Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Texture Classification and Segmentation Using Multiresolution Simultaneous Autoregressive Models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="188" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Self-Organizing Map</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-09">Sept. 1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="464" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Textural Features for Image Classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973-11">Nov. 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Multiresolution Signal Decomposition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Akansu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Haddad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Academic Press</publisher>
			<pubPlace>San Diego, Calif</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A Theory for Multiresolution Signal Decomposition: The Wavelet Representation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="674" to="693" />
			<date type="published" when="1989-07">July 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wavelets</forename></persName>
		</author>
		<editor>S.I.A.M</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>Philadelphia, Pa</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Ramstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Aase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Husøy</surname></persName>
		</author>
		<title level="m">Subband Compression of Images-Principles and Examples</title>
		<meeting><address><addrLine>North Holland</addrLine></address></meeting>
		<imprint>
			<publisher>ELSEVIER Science Publishers BV</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On Local Linear Transform and Gabor Filter Representation of Texture</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Pattern Recognition</title>
		<meeting>Int&apos;l Conf. Pattern Recognition</meeting>
		<imprint>
			<publisher>Int&apos;l Assoc. for Pattern Recognition</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="627" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A Filter Family Designed for Use in Quadrature Mirror Filter Banks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Johnston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Acoustic Speech, Signal Processing</title>
		<meeting>Int&apos;l Conf. Acoustic Speech, Signal essing<address><addrLine>Denver, Colo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="291" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Low Complexity Subband Coding of Still Images and Video</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Husøy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Eng</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="904" to="911" />
			<date type="published" when="1991-07">July 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Optimal Gabor Filters for Texture Segmentation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="947" to="964" />
			<date type="published" when="1995-07">July 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning Texture Discrimination Masks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Karu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="195" to="205" />
			<date type="published" when="1996-02">Feb. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Analysis of Multichannel Narrow-Band Filters for Image Texture Segmentation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="25" to="27" />
			<date type="published" when="1991-09">Sept. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Textures: A Photographic Album for Artists and Designers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brodatz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>Dover</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<ptr target="http://www.media.mit.edu/vismod/" />
		<title level="m">MIT Vision and Modelling Group</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<ptr target="http://www.cssip.elec.uq.edu.au/~guy/meastex/meastex.html" />
		<title level="m">MeasTex Image Texture Database</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">From 1982 to 1986, he worked for the Canadian Department of Transportation, Ottawa, Ontario, and subsequently for Northern Telecom, Ottawa. The following two years were spent at the Chr</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wakeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IAPR, SEG, EAGE, the Norwegian Society for Image Processing and Pattern Recognition (NOBIM), and the Norwegian Society for Signal Processing (NORSIG), where he is currently vice chairman. John Håkon Husøy received his MSc and DrIng degrees in electrical engineering in 1981 and 1991, respectively, from the Norwegian Institute of Technology (NTH)</title>
		<title level="s">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<meeting><address><addrLine>Stavanger, Norway; Trondheim, Norway; Bergen, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Michelsen Institute</publisher>
			<date type="published" when="1992">Feb. 1994. 1992</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="130" to="149" />
		</imprint>
		<respStmt>
			<orgName>Electrical and Computer Engineering at Rogaland University Center (now Stavanger College</orgName>
		</respStmt>
	</monogr>
	<note>His research interests include image compression. digital filtering, bioelectrical signal processing, adaptive algorithms and image analysis. He is a member of the IEEE, EURASIP, IAPR, NOBIM, and NORSIG</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
