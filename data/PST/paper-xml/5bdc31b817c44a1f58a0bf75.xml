<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast Gradient Attack on Network Embedding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-09-15">15 Sep 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinyin</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yangyang</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xuanheng</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yixian</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haibin</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Xuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ieee</forename><surname>Member</surname></persName>
						</author>
						<title level="a" type="main">Fast Gradient Attack on Network Embedding</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-09-15">15 Sep 2018</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1809.02797v2[physics.soc-ph]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Network embedding</term>
					<term>adversarial network</term>
					<term>gradient attack</term>
					<term>node classification</term>
					<term>community detection</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Network embedding maps a network into a low-dimensional Euclidean space, and thus facilitate many network analysis tasks, such as node classification, link prediction and community detection etc, by utilizing machine learning methods. In social networks, we may pay special attention to user privacy, and would like to prevent some target nodes from being identified by such network analysis methods in certain cases. Inspired by successful adversarial attack on deep learning models, we propose a framework to generate adversarial networks based on the gradient information in Graph Convolutional Network (GCN). In particular, we extract the gradient of pairwise nodes based on the adversarial network, and select the pair of nodes with maximum absolute gradient to realize the Fast Gradient Attack (FGA) and update the adversarial network. This process is implemented iteratively and terminated until certain condition is satisfied, i.e., the number of modified links reaches certain predefined value. Comprehensive attacks, including unlimited attack, direct attack and indirect attack, are performed on six well-known network embedding methods. The experiments on real-world networks suggest that our proposed FGA behaves better than some baseline methods, i.e., the network embedding can be easily disturbed using FGA by only rewiring few links, achieving state-of-the-art attack performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>O UR lives are surrounded by various networks, such as social networks, communication networks, biological networks, traffic networks and so on. Network embedding <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, used to learn low-dimensional representations for nodes or links in the network, is capable to benefit a wide range of real-world applications such as link prediction <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, node classification <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, community detection <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, social network analysis <ref type="bibr" target="#b9">[10]</ref> etc. The embedding methods will directly determine the performances of downstream applications, and thus have been receiving more and more attentions in the past decades. Some earlier works, including IsoMAP <ref type="bibr" target="#b10">[11]</ref>, local linear embedding <ref type="bibr" target="#b11">[12]</ref> and Laplacian eigenmap <ref type="bibr" target="#b12">[13]</ref>, tried to embed the network by decomposing the similarity matrix. In the last few years, on the other hand, more and more studies focused on embedding the network into a low-dimensional vector space. For instance, since Mikolov et al. <ref type="bibr" target="#b13">[14]</ref> proposed the word2vec model, the skip-gram mechanism is widely adopted in many network embedding methods, such as DeepWalk <ref type="bibr" target="#b3">[4]</ref>, LINE <ref type="bibr" target="#b14">[15]</ref> and node2vec <ref type="bibr" target="#b15">[16]</ref> etc. DeepWalk <ref type="bibr" target="#b3">[4]</ref> was the first model to learn language from a network, which adopts random walk to sample a sequence of nodes for each node, and then treats these sequences as sentences by the skip-gram mechanism. LINE <ref type="bibr" target="#b14">[15]</ref> can be considered as a special case of DeepWalk, with the window size of contexts set to 1. Node2vec <ref type="bibr" target="#b15">[16]</ref> is an extension of DeepWalk, which is more flexible when generating the context of a node. The generated contexts of nodes are also treated as text in a language model to learn the embeddings by the skip-gram mechanism. Another embedding method,</p><p>• J. Chen, Y. Wu, X. Xu, Y. Chen, H Zheng, and Q. <ref type="bibr">Xuan</ref>  • This article has been submitted on August 18th, 2018.</p><p>• Corresponding author: Qi Xuan namely GraRep, is proposed by Cao et al. <ref type="bibr" target="#b16">[17]</ref>, which preserves node proximities by constructing different k-step probability transition matrices. Quite recently, a few deep embedding methods were proposed, which are generally based on generative adversarial networks (GAN) <ref type="bibr" target="#b17">[18]</ref> and graph convolutional network (GCN) <ref type="bibr" target="#b18">[19]</ref>. For example, Wang et al. <ref type="bibr" target="#b19">[20]</ref> proposed GraphGAN as a novel network representation learning framework, which unifies two classes of graph representation learning methodologies via adversarial training in a minimax game. Dai et al. <ref type="bibr" target="#b20">[21]</ref> proposed an adversarial network embedding method, which adopts the adversarial learning principle to regularize the representation learning. On the other hand, Kipf et al. <ref type="bibr" target="#b18">[19]</ref> proposed the GCN as a basic graph convolution method for semi-supervised classification, which learns the hidden layer representations that encode both local graph structure and features of nodes. Moreover, Pham et al. <ref type="bibr" target="#b21">[22]</ref> introduced Column Network (CLN) as a novel deep learning model for collective classification, inspired by the columnar organization of neocortex.</p><p>Although deep learning methods achieve great success in many real-world tasks, such as computer vision <ref type="bibr" target="#b22">[23]</ref>, natural language process <ref type="bibr" target="#b23">[24]</ref> and so on, they are confronted with security problem <ref type="bibr" target="#b24">[25]</ref>. The most typical one is adversarial attack <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b33">[34]</ref>, i.e., in computer vision tasks, we can add a designed tiny perturbation into an original image to fool a CNN model, leading to the wrong classification of the image <ref type="bibr" target="#b25">[26]</ref>. The study of network analysis attacks, on the other hand, roots in the need for protecting the user privacy from, or understanding the robustness of, those state-of-theart network analysis methods.</p><p>For instance, in community detection, Nagaraja <ref type="bibr" target="#b34">[35]</ref> proposed the first community deception method by adding links to the nodes of high centrality. Inspired by modularity, Waniek et al. <ref type="bibr" target="#b35">[36]</ref> proposed a scalable heuristic method, namely Disconnect Internally, Connect Externally (DICE), which randomly deletes the links between the nodes in the target community, while adds the links between them and those of different communities. Besides, Fionda et al. <ref type="bibr" target="#b36">[37]</ref> proposed a novel community deception method based on the safeness which evaluates the hiding level of a target community in the output of a detection algorithm. In link prediction, Zheleva et al. <ref type="bibr" target="#b37">[38]</ref> proposed a link reidentification attack to inferring sensitive links from the released data. Link perturbation is a common technique in early research that data publisher can randomly modify links on the original network to protect the sensitive links from being identified. Fard et al. <ref type="bibr" target="#b38">[39]</ref> introduced a subgraphwise perturbation in directed networks to randomize the destination of a link within subgraphs to protect sensitive links; they further proposed a neighborhood randomization mechanism to probabilistically randomize the destination of a link within a local neighborhood <ref type="bibr" target="#b39">[40]</ref>.</p><p>More interestingly, Z ügner et al. <ref type="bibr" target="#b40">[41]</ref> focused on the node classification using GCN, and proposed the first adversarial attacks on networks, namely NETTACK, which generated adversarial network iteratively. In each iteration, it first selected candidate links and features based on their important data characteristics such as degree distribution and cooccurence of features; then, it defined two scoring functions to evaluate the change in the confidence value of the target node after modifying a link and feature in the candidate sets, respectively; after that, it used the link or feature of the highest score to update the adversarial network. However, this approach is limited to node classification task, with little discussion on the transferability of the attack. On the other hand, while network embedding methods are getting more and more popular in network analysis, their security problem is largely ignored. We argue that the security problem of network embedding is more crucial than that of a particular network analysis method in community detection or link prediction, because if an embedding method is attacked, all downstream applications based on the obtained embedding vectors could be affected correspondingly.</p><p>Inspired by <ref type="bibr" target="#b40">[41]</ref>, in this paper, we propose a new fast gradient attack (FGA) on network embedding. Specifically, we make the following contributions.</p><p>• First, we design an adversarial network generator, utilizing the iterative gradient information of pairwise nodes based on the trained GCN model to generate adversarial network so as to realize the FGA.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head><p>In this section, we introduce the framework of FGA on network embedding, where we propose an adversarial network generator based the GCN model. For convenience, the definitions of symbols used in this paper are briefly summarized in TABLE <ref type="table" target="#tab_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>We first give the definitions of network embedding and network embedding attack as follows.</p><p>• Network embedding: It learns a mapping :</p><formula xml:id="formula_0">v i → y i ∈ R d of nodes in network G = (V, E)</formula><p>to features in a lowdimensional space, based on which the downstream methods can be designed to realize node classification or clustering tasks etc. Generally, the dimension of each node d is much smaller than the number of nodes |V |. • Network embedding attack: Given the network G = (V, E), network embedding attack selects some key links for target nodes to construct the perturbation network Ḡ = (V, Ē, M ), where M ij ∈ {−1, 0, 1} indicates the modification strategy of Ēij ∈ Ē. Then, the links Ê in the attacked network Ĝ = (V, Ê) is defined as</p><formula xml:id="formula_1">Êij = E ij + M ij Ēij .<label>(1)</label></formula><p>In this attacked network, the target nodes can be well hidden, e.g., they will be misclassified with a relatively high probability in a node classification task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Framework of FGA</head><p>Adversarial attack is launched by latent adversarial samples with minimized alternation from normal ones. In this study, the adversarial networks are elaborately designed to fool network embedding methods. When the original network is inputted, vectors of nodes are learned based on network embedding methods for a specific task, e.g., node classification, with satisfying performance. Then, we choose the target nodes, and generate adversarial networks to hide them, i.e., to make them misclassified. In other words, when the adversarial networks are inputted, the vectors of most nodes will keep the same as those in the original network, i.e., they will be correctly classified, while the target nodes will be unconsciously misclassified due to their significantly changed vectors. More remarkably, the adversarial networks are almost the same as the original one, e.g., only 1 to 6 links need to be rewired in a network of more than 5000 links in total. In particular, our FGA method consists of two stages: adversarial network generation and adversarial attack, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>• Adversarial network generation: Given a network, the adversarial network is generated based on the GCN gradient. First, we use the original network to train the GCN model. Then, for each target node, we design a target loss function, based on which we calculate the partial derivative, and further the gradient information, for each pair of nodes in the network. After that, we select the pair of nodes of the maximum absolute gradient to update the adversarial network. Finally, we stop the process when a certain number of links are modified, and then output the final adversarial network.</p><p>• Adversarial attack: We then use the generated adversarial network to protect the target node from the detection of GCN model. Since GCN has overwhelming generalization ability, the adversarial attack can be still effective for many other network embedding methods, i.e., the perturbation generated by GCN is universal and the attack thus has strong transferability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Adversarial Network Generator via GCN</head><p>In this stage, we use the GCN model to generate adversarial networks, described as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">GCN model</head><p>We consider a two-layer GCN model for node classification in a network with the adjacency matrix A. Ã = A + I N is the adjacency matrix of the undirected network G with the added self-connections, where I N is the identity matrix. Dii = j Ãij is the degree matrix of Ã.</p><p>We consider the GCN model with a single hidden layer, and its forward model takes the simple form:</p><formula xml:id="formula_2">Y (A) = f ( Āσ( ĀXW 0 )W 1 ),<label>(2)</label></formula><p>where X is a matrix of node feature vectors,</p><formula xml:id="formula_3">Ā = D− 1 2 Ã D− 1 2 = D− 1 2 (A + I N ) D− 1 2 , W 0 ∈ R C×H and W 1 ∈ R H×|F |</formula><p>are the input-to-hidden and hidden-to-output weight matrices, respectively, with the hidden layer of H feature maps; f and σ are the softmax function and Relu active function, respectively. Here, the softmax activation function is applied row-wise.</p><p>For node classification, we evaluate the cross-entropy error over all training examples:</p><formula xml:id="formula_4">L = − |V L | l=1 |F | k=1 Y lk ln(Y lk (A)),<label>(3)</label></formula><p>where V L is the set of nodes with labels,</p><formula xml:id="formula_5">F = [τ 1 , • • • , τ |F | ]</formula><p>is the category set for the nodes in the network, |F | denotes the number of categories, Y is the real label matrix with Y lk = 1 if node v l belongs to category τ k and Y lk = 0 otherwise, and Y (A) is the output of the model calculated by Eq. ( <ref type="formula" target="#formula_2">2</ref>). In the m-th iteration step, the weights W i , i ∈ {0, 1}, of the neural network model are trained using gradient descent, with the update role</p><formula xml:id="formula_6">W m+1 i = W m i − η ∂L ∂W m i , (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where η is the learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Link gradient based on GCN</head><p>According to Eq. ( <ref type="formula" target="#formula_6">4</ref>), the weight matrices are updated based on the gradient information in the GCN model, so that the model is continuously optimized and the node classification performance is steadily improved. As we can see in Eq. ( <ref type="formula" target="#formula_2">2</ref>) and Eq. ( <ref type="formula" target="#formula_4">3</ref>), the adjacency matrix A is another group of variables in the loss function. We thus can use the gradient information of the adjacency matrix to realize the attack, i.e., lead to an error in the node classification.</p><p>Based on the trained GCN model, we further design a target loss function L t as</p><formula xml:id="formula_8">L t = − |F | k=1 Y tk ln(Y tk (A)),<label>(5)</label></formula><p>which represents the difference between the predicted label and the real one of the target node v t . The larger value of this loss function corresponds to the worse prediction result.</p><p>We then calculate the partial derivatives of the target loss function L t with respect to the element of adjacency matrix, A ij , in the network, and further obtain all the link gradient matrix g, represented by</p><formula xml:id="formula_9">g ij = ∂L t ∂A ij ,<label>(6)</label></formula><p>with A ij being an element of A.</p><p>Here, we aim to maximize the target loss function L t . Generally, link changes along the same direction of the gradient can make the target loss function L t increase fastest locally, resulting in the misclassification of the target node quickly using the trained GCN model. Considering that the adjacent matrix of an undirected network is symmetry, here we symmetrize g to obtain ĝ.</p><formula xml:id="formula_10">ĝij = ĝji = gij +gji 2 i = j 0 i = j<label>(7)</label></formula><p>We treat ĝ as a link gradient network (LGN), where each pair of nodes could be connected with a positive or negative weight denoting the link gradient, with the following meanings:</p><p>• Sign: A positive/negative link gradient ĝij indicates that adding/deleting the link between the pair of nodes (v i , v j ) will increase the target loss function.</p><p>• Magnitude: The larger magnitude of link gradient ĝij means the added/deleted link between the pair of nodes (v i , v j ) can influence the classification result of the target node more significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Adversarial network generator</head><p>Based on Eq. ( <ref type="formula" target="#formula_9">6</ref>), we propose a model to generate adversarial networks to realize the efficient attack on the original network. In this model, we modify a link during each iteration, and the process lasts for K iterations in total. The h th iteration can be described by the following steps.</p><p>• Constructing the LGN: Based on Eq. ( <ref type="formula" target="#formula_9">6</ref>) and Eq. ( <ref type="formula" target="#formula_10">7</ref>), we generate the (h − 1) th LGN ĝh−1 using the adversarial network adjacency matrix Âh−1 , with Â0 = A. </p><formula xml:id="formula_11">Âh ij = Âh−1 ij + θ(ĝ ij ),<label>(8)</label></formula><p>where Âh ij and Âh−1 ij are the elements of Âh and Âh−1 , respectively, and θ(ĝ ij ) represents the sign of gradient of the selected pair of nodes (v i , v j ). The pseudo-code for the adversarial network generator is given in Algorithm 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">White-Box Adversarial Attack</head><p>Here, we perform the white-box adversarial attack, i.e., using the adversarial network to attack the GCN model. Specifically, the proposed adversarial network generator generates an adversarial network with tiny perturbations, and the re-trained GCN model with the generated adversarial network fails to classify the target nodes correctly. In particular, we will consider direct, indirect, and unlimited attacks, respectively, described as follows.</p><p>• Direct attack: Typically, individuals may have very limited knowledge of the social ties beyond their friends, but rather, they can easily manage their immediate neighborhoods. In order to simulate such cases, we only consider to attack the links around the target nodes, i.e., remove existent links of the target nodes or add new ones to them. • Indirect attack: When selecting the links to be modified in the adversarial network attack generator, we find some indirect links (i.e., they are not immediately connected to the target nodes) may also have an impact on the classification result of the target nodes. In certain situations, such indirect links might be preferred to be changed by the network manager in order to make the attack more concealed. • Unlimited attack: In this case, we don't limit the attack to the direct or indirect links, i.e., we can remove or add a link between any pair of nodes, in order to seek the maximum attack effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Black-Box Adversarial Attack</head><p>We also perform the adversarial attack generated by GCN to attack other embedding methods, to validate that such attack is quite universal. Since many embedding methods with any downstream classification or regression algorithms have similar decision boundaries, we believe the GCNbased adversarial attack can also be effective on many other embedding methods.</p><p>The strong transferability of such adversarial attacks may bring the security concern for network embedding applications, since malicious examples may be easily crafted even when the target network embedding method is unknown in advance. Moreover, in network theory, hub nodes and bridge nodes play important roles in many network dynamics and algorithms. Therefore, we also perform the adversarial attack on such special nodes to see the antiattack ability of FGA on the critical part of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>In order to testify the effectiveness of our FGA method, we compare it with some baseline attack methods by performing a number of experiments, including uniform attack, hub-node attack, bridge-node attack and community deception. Our experimental environment consists of i7-7700K 3.5GHzx8 (CPU), TITAN Xp 12GiB (GPU), 16GBx4 memory (DDR4) and Ubuntu 16.04 (OS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>In the task of node classification, each node in a network is assigned a label, and the following three networks are used. Their basic statistics are summarized in TABLE 2.</p><p>• Pol.Blogs: The Pol.Blogs dataset is compiled by Adamic and Glance <ref type="bibr" target="#b41">[42]</ref>. This dataset is about political leaning collected from blog directories. The blogs are divided into two classes. The links between blogs were automatically extracted from the front pages of the blogs. It contains 1,490 blogs and 19,090 links in total.</p><p>• Cora: This dataset contains a number of machinelearning papers of seven classes <ref type="bibr" target="#b42">[43]</ref>. The links between papers represent the citation relationships. It contains 2,708 papers and 5,429 links in total.</p><p>• Citeseer: This dataset is also a paper citation network with the papers divided into six classes <ref type="bibr" target="#b42">[43]</ref>. It contains 3,312 papers and 4,732 citation links in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline Methods</head><p>We compare our FGA method with three network embedding attack methods. Suppose the target node v t has n t links in the original network. These baseline methods are briefly described as follows.</p><p>• Random Attack (RA). RA randomly disconnects b (b &lt; K) links in the original network, while randomly connects K − b pairs of nodes that are originally not connected. This is the simplest attack method. • Disconnect Internally, Connect Externally (DICE) <ref type="bibr" target="#b35">[36]</ref>.</p><p>DICE first randomly disconnect b links of target node, then randomly connect the target node to K − b nodes of different classes.</p><p>• NETTACK <ref type="bibr" target="#b40">[41]</ref>. NETTACK generates adversarial network iteratively. In each iteration, it selects candidate links based on the degree distribution; then, it defines a scoring function, meaning the confidence loss of the target node in the trained GCN model when a certain link is changed; after that, it utilizes the scores of the candidate links to update the adversarial network. For RA and DICE, we simply set b = n t /2 if n t &lt; K; and b = K/2 otherwise.</p><p>In order to validate the transfer ability of our FGA method, besides GCN, we also compare it with the three baseline methods on attacking other network embedding approaches including GraRep, DeepWalk, Node2vec, LINE and GraphGAN.</p><p>We randomly choose 20% nodes in a network as the labeled nodes, which are divided into the training and validation sets of equal size. The rest 80% nodes are used for testing. For all the network embedding methods, the vector dimension is set to 128, the number of walks per node is set to 10, the length of walk is set to 80 and the size of context window is set to 10. For LINE method, the negative ratio is set to 5. The feature vectors are inputted into a logistic regression classifier to perform node classification with 9:1 train-test ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Now, let's present the attack results obtained by our FGA method and the baseline methods on GCN and other several network embedding methods. We use the following two metrics to measure the attack effectiveness.</p><p>• ASR: The attack success rate, i.e., the ratio of the successfully attacked embeddings of nodes, i.e., leading the misclassification of the node, versus all target nodes, by changing no more than γ links for each target node. For a certain value of γ, the larger ASR corresponds to the better attack effect. Here, the perturbation size γ is varied from 1 to 20.</p><p>• AML: The average number of modified links to successfully attack the embedding of a target node. Here, to avoid changing too many links, we limit each method to modify at most 20 links. In other words, if the embedding of the target node is unable to be successfully attacked by modifying 20 links, we simply set the number as 20. The smaller AML corresponds to the better attack effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Uniform attack</head><p>In this part, for each network, we random select 20 nodes in each category as the target nodes. The attack results are presented in TABLE <ref type="table" target="#tab_5">3</ref>, where we can see that the unlimited FGA outperforms all the other attack methods in all the cases, in terms of higher ASR and lower AML. Surprisingly, for the datasets of Cora and Citeseer, we can achieve 100% ASR when 20 links are changed for each target node. While for Pol.Blogs, we can only get 84.47% ASR on average, which may be because this network is relatively dense, with the average degree close to 25.6. Even though, the unlimited FGA still performs best on attacking any considered network embedding method. It might be argued that, for NETTACK and DICE, only those links around the target nodes are allowed to be changed, i.e., they can be considered as direct attacks. Therefore, it seems to be fairer to compare them with our direct FGA, rather than unlimited FGA. In fact, we can still find that our direct FGA presents better attack effect than NETTACK and DICE in most cases.</p><p>In particular, for the datasets of Cora and Citeseer, on average, we only need to change no more than 6 links to successfully attack the embedding of a target node for any network embedding method considered in this paper, by using our unlimited FGA. By comparison, we need to change more links in Pol.Blogs to successfully attack the network embedding methods, due to its denser structure. Overall, although our FGA attack is based on GCN, it has strong trasnferability to attack other network embedding methods, i.e., in TABLE <ref type="table" target="#tab_5">3</ref> we can see that both unlimited and direct FGA achieve higher ASR and lower AML than the three baseline attack methods, while DICE and RA are not designed for a particular network embedding method. On the other hand, white-box attack indeed performs slightly better than black-box attack, e.g., for the datasets of Cora and Citeseer, when unlimited FGA and direct FGA are used to attack GCN, on average, only less than 4 links need to be changed to make the attack successful.</p><p>More interestingly, for the datasets of Cora and Citeseer, where the networks are relatively sparse, indirect FGA can also achieve reasonable attack effect, similar to DICE. This indicates that we may also change the links far from the target nodes to realize the attack. In other words, the local structure of these nodes is not necessarily destroyed, making the attack more concealed. However, again it seems that indirect FGA doesn't work on Pol.Blogs, i.e., it only performs better than random attack. This is reasonable, since changing only 20 links far from a target node of mean degree larger than 25 seems not enough to cheat the algorithm to classify it into a wrong group.</p><p>Moreover, we also calculate the attack effect, in terms of ASR, obtained by different attack methods, under different perturbation size γ, varied from 1 to 20. Here, direct FGA is adopted to make fair comparison. The results are shown in Fig. <ref type="figure">3</ref>-Fig. <ref type="figure">5</ref>, for different datasets, where we can find that the direct FGA performs best no matter what perturbation size is adopted; NETTACK is better than DICE in most cases; while all of these heuristic and adversarial attacks behave much better than the random attack, indicating  that network structure does matter in attacking network embedding methods. Lastly, we want to compare the time complexity between the direct FGA method and the NETTACK method, as two comparable adversarial network attack methods. Without loss of generality, we record their running time on Cora dataset. In Fig. <ref type="figure">6</ref>, we can see that the running time of both direct FGA and NETTACK increases linearly with the number of modified links, while the running time of NETTACK is significantly more than that of FGA. This is reasonable, because NETTACK needs to select candidate links based on the degree distribution in each iteration, which largely increases the time complexity of this method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time (s)</head><p> Direct FGA: NETTACK:</p><p>Fig. <ref type="figure">6</ref>: The running time of direct FGA and NETTACK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Hub-node attack</head><p>The nodes of higher centrality are considered as hubs, which play important roles in many network dynamics. Various centrality metrics <ref type="bibr" target="#b43">[44]</ref>- <ref type="bibr" target="#b45">[46]</ref> were proposed, and we use the degree centrality <ref type="bibr" target="#b46">[47]</ref> here. We then choose 40 hub nodes of largest degree in each network as our target nodes. The attack results on the hub nodes are presented in TABLE <ref type="table" target="#tab_6">4</ref>. Again, we find that the unlimited FGA still outperforms all the other considered attack methods. The direct FGA follows, which performs better than the NETTACK and DICE in most cases, indicating the effectiveness of our FGA method on disturbing network embeddings of hub nodes in a network. The difference is that, at this time, the indirect FGA loses its effectiveness even in the dense networks of Cora and Citeseer, suggesting that changing the links far away from hub nodes has little influence on these nodes, since they always have a lot of neighbors, making their embeddings much more robust. Overall, by comparing TABLE <ref type="table" target="#tab_5">3</ref> and TABLE <ref type="table" target="#tab_6">4</ref>, we can find that the embeddings of hub nodes are relatively difficult to attack, i.e., the same attack methods obtain smaller ASR and larger AML on the corresponding same network embedding methods and datasets, for the hub nodes than for the normal ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Bridge-node attack</head><p>Since many real-world networks have modular and hierarchical structure, those nodes connecting different communities play key roles to make the whole network connected and further dominate the information spreading on the network. These nodes, namely bridge nodes, are thus as important as hub nodes and should be preferentially protected. The bridge nodes are always of higher betweenness centrality <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref> which is defined as the ratio of the shortest paths passing through the target node among all the shortest paths in the network. We thus use this metric to choose 40 nodes of highest betweenness centrality as our bridge nodes, and the attack results on their network embedding are presented in TABLE <ref type="table" target="#tab_7">5</ref>.</p><p>Similarly, the unlimited FGA performs best. By comparison, the direct FGA still performs better than the NETTACK and DICE in most cases, suggesting that our FGA method is also useful in attacking bridge nodes between different communities in a network. Again, the indirect FGA behaves  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Community Deception</head><p>Network embedding can map a network into a vector space, where each node is represented by a vector of relatively low dimension. As a result, many network algorithms, such as community detection <ref type="bibr" target="#b49">[50]</ref>- <ref type="bibr" target="#b51">[52]</ref>, can be realized in this vector space by using some machine learning methods.</p><p>Community deception <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref>, on the contrary, is used to protect certain nodes from identifying by community detection methods. Since our FGA methods can be used to disturb network embeddings, we thus think that they can also be used in community deception. In this experiment, we first use GCN to generate the adversarial network; then we use the network embedding methods to generate node embedding vectors, based on which we get the community detection results by adopting the simple K-means method. We use the following two datasets for community detection.</p><p>• PloBook: This network represents co-purchasing of books about US politics sold by the online bookseller <ref type="bibr" target="#b52">[53]</ref>. In this network, nodes represent books about US politics sold by the online bookseller Amazon.com, and two nodes are connected if the corresponding two books were co-purchased by the same buyers. There are 105 books and 441 links in total, and the books belongs to three communities, namely liberal, neutral and conservative.  Fig. <ref type="figure">8</ref>: The visualization of FGA on network embedding of a random target node in Dolphins. The purple node represents the target node and the purple link is selected by our FGA due to its largest gradient. Except for the target node, the nodes of same color belongs to the same community.</p><p>Zealand <ref type="bibr" target="#b53">[54]</ref>. There are 62 dolphins and 159 links in total, and the dolphins are partitioned into two groups by the temporary disappearance of dolphin number. In this experiment, suppose we know the community that each node belongs to in advance. For each network, we randomly select 20% nodes in each category to train our GCN, with the training and validation sets being of equal size, while the rest 80% nodes are used for testing. For all the network embedding methods considered here, the dimension of embedding vector is set to 20. Note that, without attack, the nodes in an original network can also be turned into vectors by each network embedding method, and then are grouped into communities by K-means method. There might be some nodes that are wrongly clustered themselves without any attack, and these nodes will not be considered as the target nodes here, i.e., we only attack those nodes that can be corrected clustered initially.</p><p>The community deception results are shown in TABLE <ref type="table" target="#tab_9">6</ref>, where we can see that these results are consistent with those in node classification, i.e., for each network embedding method on each dataset, the unlimited FGA outperforms all the others, direct FGA behaves better than NETTACK and DICE, while all of them behaves much better than the random attack. These results indicate that our FGA can also be used to attack community detection algorithms by disturbing network embeddings. Note that, we exclude GCN here, since GCN is in nature a supervised learning method, and thus is not suitable for community detection.</p><p>In order to make our FGA method easier to understand, we visualize the FGA on network embedding of a random target node in PolBook and Dolphins, as shown in Fig. <ref type="figure">7</ref> and Fig. <ref type="figure">8</ref>, respectively. Here, we adopt the unlimited FGA and use the low-dimensional network representations learned by DeepWalk as the input to the visualization tool t-SNE <ref type="bibr" target="#b54">[55]</ref>. We find that the embedding vector of the target node changes a lot even when only one link is changed in each network, indicating the powerful ability of FGA on disturbing network embedding methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>In this paper, we propose a framework to generate adversarial networks using GCN, based on which we realize a fast gradient attack (FGA) on network embedding. In this method, we first extract the gradient of pairwise nodes based on the adversarial network, and then select the pair of nodes with maximum absolute link gradient to realize the attack and update the adversarial network, and so forth. This iterative process is terminated when the number of modified links reaches certain predefined value. We conduct numerous experiments, such as uniform attack, hub-node attack and bridge-node attack on six network embedding methods, these embedding vectors are further used to classify nodes in three networks. The results suggest that, in any case, our proposed FGA outperform the other baseline attack methods, achieving the state-of-the-art results. The experiment on community deception also validates the effectiveness of FGA on disturbing network embeddings.</p><p>Every coin has two sides, network embedding methods and the corresponding attack methods could be improved iteratively. Therefore, in future, we will also try to propose new network embedding methods that are more robust to the adversarial attacks generated by FGA.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: The framework of FGA on network embedding methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 : 5 6</head><label>156</label><figDesc>Adversarial network generator via GCN Input: Original network G, number of iterations K. Output: The adversarial network Ĝ. 1 Train the GCN model on original network G to obtain ĝ0 via Eq. (6) and Eq. (7); 2 Initialize the adjacency matrix of the adversarial network by Â0 = A; 3 for h = 1 to K do 4 Construct ĝh−1 based on the Âh−1 ; Select the pair of nodes (v i , v j ) of the maximum absolute link gradient in ĝh−1 ; Update the adjacency matrix Âh by Âh ij = Âh−1 ij + θ(ĝ ij ); 7 end 8 return The adversarial network Ĝ, with the adjacency matrix of adversarial network ÂK .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Adversarial network attack generator via GCN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :Fig. 4 :Fig. 5 :</head><label>345</label><figDesc>Fig. 3: ASR of different attack methods as functions of perturbation size γ on various network embedding methods for Polblogs dataset.</figDesc><graphic url="image-1.png" coords="7,55.84,53.44,507.16,172.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 :</head><label>1</label><figDesc>The definitions of symbols.</figDesc><table><row><cell>Symbol</cell><cell cols="2">Definition</cell></row><row><cell>G = (V, E) Ḡ = (V, Ē, M )</cell><cell cols="2">input original network with nodes V and links E perturbation network with nodes V , links Ē and weight M</cell></row><row><cell>Ĝ = (V, Ê)</cell><cell>attacked network with nodes V and updated links</cell><cell>Ê</cell></row><row><cell>A</cell><cell cols="2">the adjacency matrix of original network G</cell></row><row><cell>Ã</cell><cell cols="2">the adjacency matrix added self-connections</cell></row><row><cell>I N</cell><cell cols="2">identity matrix</cell></row><row><cell>D</cell><cell>degree matrix of</cell><cell>Ã</cell></row><row><cell>Y (A)</cell><cell cols="2">the output of the GCN model</cell></row><row><cell>f and σ</cell><cell cols="2">the softmax function and Relu active function</cell></row><row><cell>X Ā</cell><cell cols="2">the matrix of node feature vectors the convolved signal matrix</cell></row><row><cell>W i</cell><cell cols="2">the weight matrices of GCN model</cell></row><row><cell>C</cell><cell cols="2">the number of feature vector dimensions in X</cell></row><row><cell>H</cell><cell cols="2">the number of feature maps for hidden layer</cell></row><row><cell>F</cell><cell cols="2">the categories set for nodes in the network</cell></row><row><cell>L</cell><cell cols="2">the loss function of the GCN model</cell></row><row><cell>V L</cell><cell cols="2">the set of nodes with labels</cell></row><row><cell>Y</cell><cell cols="2">the real label confidence list</cell></row><row><cell>η</cell><cell cols="2">learning rate</cell></row><row><cell>vt</cell><cell cols="2">target node</cell></row><row><cell>Lt</cell><cell cols="2">target loss function for node vt</cell></row><row><cell>g</cell><cell cols="2">link gradient matrix</cell></row><row><cell>ĝ</cell><cell cols="2">link gradient network</cell></row><row><cell>K</cell><cell cols="2">the number of modified links</cell></row><row><cell>Ĝh</cell><cell cols="2">the h th adversarial network</cell></row><row><cell>Âh</cell><cell cols="2">the h th adversarial adjacency matrix</cell></row><row><cell>ĝh</cell><cell cols="2">the h th link gradient network</cell></row><row><cell>θ</cell><cell cols="2">the sign function</cell></row><row><cell>nt</cell><cell cols="2">the number of links of the target node in G</cell></row><row><cell>b</cell><cell cols="2">the number of links we random disconnect</cell></row><row><cell>γ</cell><cell cols="2">perturbation size</cell></row><row><cell cols="3">on several real-world networks. In Sec. 4, we conclude the</cell></row><row><cell cols="2">paper and highlight future research directions.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>the target pair of nodes:</head><label></label><figDesc>Based on ĝh−1 , we select a pair of nodes (v i , v j ) of the maximum absolute link gradient. Note that, if they have positive/negative gradient and meanwhile are connected/disconnected in the original network, we cannot further add/remove the link between them. Therefore, we just ignore such pairs of nodes in the process.</figDesc><table /><note>• Selecting • Realize the attack: We use the selected pair of nodes (v i , v j ) to attack the (h − 1) th adversarial network, and generate the adversarial network Ĝh . The adjacency matrix Âh of the h th adversarial network is defined as:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 2 :</head><label>2</label><figDesc>The basic statistics of the three network datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3">#Nodes #Links #Classes</cell></row><row><cell>Pol.Blogs</cell><cell>1,490</cell><cell>19,090</cell><cell>2</cell></row><row><cell>Cora</cell><cell>2,708</cell><cell>5,429</cell><cell>7</cell></row><row><cell>Citeseer</cell><cell>3,312</cell><cell>4,732</cell><cell>6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 3 :</head><label>3</label><figDesc>The attack effects, in terms of ASR and AML, obtained by different attack methods on varous network embedding methods and multiple datasets. Here, ASR is obtained by changing 20 links.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ASR (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AML</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>NEM</cell><cell></cell><cell>FGA</cell><cell></cell><cell></cell><cell>Baseline</cell><cell></cell><cell></cell><cell>FGA</cell><cell></cell><cell></cell><cell>Baseline</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Unlimited Direct Indirect</cell><cell cols="2">NETTACK DICE</cell><cell>RA</cell><cell cols="3">Unlimited Direct Indirect</cell><cell cols="2">NETTACK DICE</cell><cell>RA</cell></row><row><cell></cell><cell>GCN</cell><cell>87.87</cell><cell>85.74</cell><cell>25.53</cell><cell>82.97</cell><cell>50.27</cell><cell>0.00</cell><cell>8.42</cell><cell>8.82</cell><cell>17.61</cell><cell>11.89</cell><cell>11.85</cell><cell>20.00</cell></row><row><cell></cell><cell>GraRep</cell><cell>83.88</cell><cell>81.66</cell><cell>4.25</cell><cell>79.91</cell><cell>61.06</cell><cell>0.00</cell><cell>9.58</cell><cell>10.42</cell><cell>19.36</cell><cell>10.48</cell><cell>14.22</cell><cell>20.00</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>84.26</cell><cell>81.66</cell><cell>6.25</cell><cell>75.41</cell><cell>64.52</cell><cell>0.00</cell><cell>9.84</cell><cell>10.93</cell><cell>19.20</cell><cell>10.06</cell><cell>12.35</cell><cell>20.00</cell></row><row><cell>Pol.Blogs</cell><cell>node2vec</cell><cell>84.34</cell><cell>81.83</cell><cell>0.00</cell><cell>78.32</cell><cell>67.89</cell><cell>0.00</cell><cell>9.72</cell><cell>10.16</cell><cell>20.00</cell><cell>10.58</cell><cell>14.86</cell><cell>20.00</cell></row><row><cell></cell><cell>LINE</cell><cell>85.25</cell><cell>82.03</cell><cell>0.00</cell><cell>76.35</cell><cell>66.74</cell><cell>0.00</cell><cell>9.90</cell><cell>11.01</cell><cell>20.00</cell><cell>10.26</cell><cell>12.82</cell><cell>20.00</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>81.21</cell><cell>80.24</cell><cell>0.00</cell><cell>72.26</cell><cell>64.58</cell><cell>0.00</cell><cell>9.41</cell><cell>11.02</cell><cell>20.00</cell><cell>11.08</cell><cell>12.26</cell><cell>20.00</cell></row><row><cell></cell><cell>Average</cell><cell>84.47</cell><cell>82.19</cell><cell>6.01</cell><cell>77.54</cell><cell>62.51</cell><cell>0.00</cell><cell>9.48</cell><cell>10.39</cell><cell>19.36</cell><cell>10.73</cell><cell>13.06</cell><cell>20.00</cell></row><row><cell></cell><cell>GCN</cell><cell>100</cell><cell>100</cell><cell>88.28</cell><cell>92.87</cell><cell>54.95</cell><cell>6.31</cell><cell>2.54</cell><cell>3.21</cell><cell>6.77</cell><cell>6.09</cell><cell>9.13</cell><cell>16.99</cell></row><row><cell></cell><cell>GraRep</cell><cell>100</cell><cell>100</cell><cell>84.47</cell><cell>97.22</cell><cell>89.09</cell><cell>9.43</cell><cell>5.56</cell><cell>5.57</cell><cell>9.41</cell><cell>5.94</cell><cell>7.37</cell><cell>18.43</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>100</cell><cell>97.22</cell><cell>81.55</cell><cell>94.06</cell><cell>93.52</cell><cell>12.16</cell><cell>5.61</cell><cell>6.27</cell><cell>10.59</cell><cell>7.24</cell><cell>7.20</cell><cell>17.69</cell></row><row><cell>Cora</cell><cell>node2vec</cell><cell>100</cell><cell>100</cell><cell>84.00</cell><cell>97.29</cell><cell>89.09</cell><cell>9.43</cell><cell>5.66</cell><cell>5.58</cell><cell>9.52</cell><cell>6.75</cell><cell>7.37</cell><cell>18.43</cell></row><row><cell></cell><cell>LINE</cell><cell>100</cell><cell>96.04</cell><cell>84.47</cell><cell>96.34</cell><cell>88.99</cell><cell>13.08</cell><cell>5.64</cell><cell>6.36</cell><cell>9.41</cell><cell>7.02</cell><cell>7.66</cell><cell>18.07</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>100</cell><cell>96.00</cell><cell>84.62</cell><cell>92.26</cell><cell>84.55</cell><cell>8.49</cell><cell>5.65</cell><cell>6.40</cell><cell>11.02</cell><cell>8.82</cell><cell>7.96</cell><cell>18.60</cell></row><row><cell></cell><cell>Average</cell><cell>100</cell><cell>98.21</cell><cell>84.57</cell><cell>95.01</cell><cell>83.37</cell><cell>9.82</cell><cell>5.11</cell><cell>5.57</cell><cell>9.62</cell><cell>6.98</cell><cell>7.78</cell><cell>18.04</cell></row><row><cell></cell><cell>GCN</cell><cell>100</cell><cell>100</cell><cell>91.36</cell><cell>87.50</cell><cell>70.37</cell><cell>2.47</cell><cell>3.52</cell><cell>3.88</cell><cell>7.69</cell><cell>6.88</cell><cell>9.87</cell><cell>19.36</cell></row><row><cell></cell><cell>GraRep</cell><cell>100</cell><cell>98.39</cell><cell>98.41</cell><cell>94.28</cell><cell>93.22</cell><cell>32.26</cell><cell>5.32</cell><cell>6.23</cell><cell>8.25</cell><cell>6.51</cell><cell>7.56</cell><cell>15.09</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>96.96</cell><cell>93.44</cell><cell>36.51</cell><cell>5.68</cell><cell>6.06</cell><cell>7.76</cell><cell>7.06</cell><cell>7.08</cell><cell>14.41</cell></row><row><cell>Citeseer</cell><cell>node2vec</cell><cell>100</cell><cell>100</cell><cell>98.21</cell><cell>93.93</cell><cell>91.38</cell><cell>34.43</cell><cell>5.62</cell><cell>6.50</cell><cell>7.75</cell><cell>6.34</cell><cell>7.13</cell><cell>14.87</cell></row><row><cell></cell><cell>LINE</cell><cell>100</cell><cell>100</cell><cell>98.36</cell><cell>95.82</cell><cell>96.72</cell><cell>32.26</cell><cell>5.88</cell><cell>6.25</cell><cell>7.56</cell><cell>6.02</cell><cell>7.21</cell><cell>15.27</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>100</cell><cell>97.89</cell><cell>93.15</cell><cell>92.06</cell><cell>88.24</cell><cell>20.00</cell><cell>5.91</cell><cell>6.67</cell><cell>8.18</cell><cell>7.42</cell><cell>8.26</cell><cell>16.55</cell></row><row><cell></cell><cell>Average</cell><cell>100</cell><cell>99.38</cell><cell>96.75</cell><cell>93.43</cell><cell>88.90</cell><cell>26.32</cell><cell>5.16</cell><cell>5.93</cell><cell>7.85</cell><cell>6.71</cell><cell>7.98</cell><cell>15.92</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 4 :</head><label>4</label><figDesc>The attack effects on hub node, in terms of ASR and AML, obtained by different attack methods on various network embedding methods and multiple datasets. Here, ASR is obtained by changing 20 links.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ASR (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AML</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>NEM</cell><cell></cell><cell>FGA</cell><cell></cell><cell></cell><cell>Baseline</cell><cell></cell><cell></cell><cell>FGA</cell><cell></cell><cell></cell><cell>Baseline</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Unlimited Direct Indirect</cell><cell cols="2">NETTACK DICE</cell><cell>RA</cell><cell cols="3">Unlimited Direct Indirect</cell><cell cols="2">NETTACK DICE</cell><cell>RA</cell></row><row><cell></cell><cell>GCN</cell><cell>50.00</cell><cell>45.00</cell><cell>5.00</cell><cell>10.00</cell><cell>10.00</cell><cell>0.00</cell><cell>14.78</cell><cell>15.28</cell><cell>19.70</cell><cell>18.95</cell><cell>19.50</cell><cell>20.00</cell></row><row><cell></cell><cell>GraRep</cell><cell>62.50</cell><cell>57.50</cell><cell>2.50</cell><cell>5.00</cell><cell>17.50</cell><cell>0.00</cell><cell>15.72</cell><cell>16.05</cell><cell>19.55</cell><cell>19.45</cell><cell>19.20</cell><cell>20.00</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>53.85</cell><cell>50.00</cell><cell>2.50</cell><cell>12.50</cell><cell>22.50</cell><cell>0.00</cell><cell>16.00</cell><cell>16.82</cell><cell>19.77</cell><cell>19.20</cell><cell>19.18</cell><cell>20.00</cell></row><row><cell>Pol.Blogs</cell><cell>node2vec</cell><cell>32.50</cell><cell>45.00</cell><cell>5.00</cell><cell>12.50</cell><cell>17.50</cell><cell>0.00</cell><cell>17.62</cell><cell>17.95</cell><cell>19.20</cell><cell>19.20</cell><cell>19.05</cell><cell>20.00</cell></row><row><cell></cell><cell>LINE</cell><cell>20.26</cell><cell>12.21</cell><cell>5.00</cell><cell>5.00</cell><cell>20.00</cell><cell>0.00</cell><cell>18.57</cell><cell>19.02</cell><cell>19.31</cell><cell>19.30</cell><cell>19.70</cell><cell>20.00</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>25.00</cell><cell>17.50</cell><cell>2.50</cell><cell>2.56</cell><cell>12.50</cell><cell>0.00</cell><cell>18.68</cell><cell>18.77</cell><cell>19.52</cell><cell>19.67</cell><cell>19.35</cell><cell>20.00</cell></row><row><cell></cell><cell>Average</cell><cell>40.69</cell><cell>37.86</cell><cell>3.75</cell><cell>7.92</cell><cell>16.67</cell><cell>0.00</cell><cell>16.90</cell><cell>17.32</cell><cell>19.51</cell><cell>19.30</cell><cell>19.16</cell><cell>20.00</cell></row><row><cell></cell><cell>GCN</cell><cell>88.90</cell><cell>87.18</cell><cell>54.54</cell><cell>85.71</cell><cell>48.57</cell><cell>4.74</cell><cell>6.48</cell><cell>6.62</cell><cell>14.37</cell><cell>8.64</cell><cell>11.38</cell><cell>18.25</cell></row><row><cell></cell><cell>GraRep</cell><cell>84.26</cell><cell>78.69</cell><cell>48.52</cell><cell>77.50</cell><cell>54.86</cell><cell>6.74</cell><cell>7.90</cell><cell>8.08</cell><cell>12.71</cell><cell>9.97</cell><cell>11.06</cell><cell>18.16</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>85.63</cell><cell>80.50</cell><cell>43.75</cell><cell>77.50</cell><cell>60.50</cell><cell>10.27</cell><cell>7.57</cell><cell>7.73</cell><cell>13.70</cell><cell>10.47</cell><cell>11.24</cell><cell>18.18</cell></row><row><cell>Cora</cell><cell>node2vec</cell><cell>81.82</cell><cell>80.34</cell><cell>41.96</cell><cell>74.38</cell><cell>55.80</cell><cell>7.68</cell><cell>7.22</cell><cell>7.52</cell><cell>13.05</cell><cell>10.81</cell><cell>12.43</cell><cell>19.70</cell></row><row><cell></cell><cell>LINE</cell><cell>85.25</cell><cell>83.96</cell><cell>46.90</cell><cell>77.10</cell><cell>57.69</cell><cell>9.96</cell><cell>8.01</cell><cell>8.25</cell><cell>13.24</cell><cell>10.00</cell><cell>12.60</cell><cell>19.00</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>84.36</cell><cell>82.57</cell><cell>48.74</cell><cell>73.87</cell><cell>54.81</cell><cell>6.20</cell><cell>8.00</cell><cell>8.15</cell><cell>12.98</cell><cell>9.52</cell><cell>11.91</cell><cell>19.87</cell></row><row><cell></cell><cell>Average</cell><cell>85.04</cell><cell>82.21</cell><cell>47.40</cell><cell>77.68</cell><cell>55.37</cell><cell>7.60</cell><cell>7.53</cell><cell>7.73</cell><cell>13.34</cell><cell>9.90</cell><cell>11.77</cell><cell>18.86</cell></row><row><cell></cell><cell>GCN</cell><cell>100</cell><cell>100</cell><cell>65.71</cell><cell>97.22</cell><cell>52.06</cell><cell>2.42</cell><cell>5.11</cell><cell>5.23</cell><cell>9.77</cell><cell>7.89</cell><cell>16.40</cell><cell>19.89</cell></row><row><cell></cell><cell>GraRep</cell><cell>88.89</cell><cell>87.89</cell><cell>11.11</cell><cell>87.30</cell><cell>61.11</cell><cell>5.52</cell><cell>12.06</cell><cell>11.61</cell><cell>18.69</cell><cell>12.16</cell><cell>15.06</cell><cell>19.06</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>88.89</cell><cell>86.89</cell><cell>8.33</cell><cell>84.44</cell><cell>61.11</cell><cell>6.34</cell><cell>10.67</cell><cell>12.14</cell><cell>18.89</cell><cell>13.03</cell><cell>14.36</cell><cell>19.42</cell></row><row><cell>Citeseer</cell><cell>node2vec</cell><cell>86.11</cell><cell>88.89</cell><cell>13.51</cell><cell>84.44</cell><cell>55.56</cell><cell>7.62</cell><cell>13.08</cell><cell>12.14</cell><cell>18.03</cell><cell>13.19</cell><cell>14.75</cell><cell>19.60</cell></row><row><cell></cell><cell>LINE</cell><cell>89.19</cell><cell>86.11</cell><cell>13.89</cell><cell>87.22</cell><cell>41.67</cell><cell>5.66</cell><cell>11.11</cell><cell>12.56</cell><cell>18.39</cell><cell>13.00</cell><cell>16.53</cell><cell>19.81</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>89.19</cell><cell>88.89</cell><cell>5.56</cell><cell>87.14</cell><cell>50.00</cell><cell>4.08</cell><cell>13.47</cell><cell>11.95</cell><cell>19.17</cell><cell>12.43</cell><cell>15.17</cell><cell>19.78</cell></row><row><cell></cell><cell>Average</cell><cell>90.38</cell><cell>90.28</cell><cell>19.69</cell><cell>87.96</cell><cell>53.59</cell><cell>5.27</cell><cell>10.92</cell><cell>10.94</cell><cell>17.16</cell><cell>11.95</cell><cell>15.38</cell><cell>19.59</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 5 :</head><label>5</label><figDesc>The attack effects on bridge node, in terms of ASR and AML, obtained by different attack methods on various network embedding methods and multiple datasets. Here, ASR is obtained by changing 20 links.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ASR (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AML</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>NEM</cell><cell></cell><cell>FGA</cell><cell></cell><cell cols="2">Baseline</cell><cell></cell><cell></cell><cell>FGA</cell><cell></cell><cell></cell><cell>Baseline</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Unlimited Direct Indirect</cell><cell cols="2">NETTACK DICE</cell><cell>RA</cell><cell cols="3">Unlimited Direct Indirect</cell><cell cols="2">NETTACK DICE</cell><cell>RA</cell></row><row><cell></cell><cell>GCN</cell><cell>62.16</cell><cell>54.05</cell><cell>5.26</cell><cell>45.95</cell><cell>8.96</cell><cell>0.00</cell><cell>14.65</cell><cell>14.95</cell><cell>19.29</cell><cell>13.08</cell><cell>19.35</cell><cell>20.00</cell></row><row><cell></cell><cell>GraRep</cell><cell>45.95</cell><cell>44.74</cell><cell>5.26</cell><cell>27.03</cell><cell>13.16</cell><cell>0.00</cell><cell>17.22</cell><cell>16.47</cell><cell>19.42</cell><cell>18.00</cell><cell>19.08</cell><cell>20.00</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>36.84</cell><cell>36.84</cell><cell>7.89</cell><cell>28.21</cell><cell>26.32</cell><cell>2.51</cell><cell>17.08</cell><cell>17.61</cell><cell>18.82</cell><cell>17.31</cell><cell>17.55</cell><cell>19.68</cell></row><row><cell>Pol.Blogs</cell><cell>node2vec</cell><cell>50.00</cell><cell>52.63</cell><cell>5.26</cell><cell>28.21</cell><cell>21.05</cell><cell>2.51</cell><cell>16.21</cell><cell>16.03</cell><cell>19.13</cell><cell>17.38</cell><cell>18.39</cell><cell>19.80</cell></row><row><cell></cell><cell>LINE</cell><cell>45.68</cell><cell>40.26</cell><cell>7.89</cell><cell>31.58</cell><cell>10.53</cell><cell>0.00</cell><cell>16.90</cell><cell>17.10</cell><cell>19.26</cell><cell>17.21</cell><cell>19.05</cell><cell>20.00</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>30.77</cell><cell>25.79</cell><cell>5.26</cell><cell>26.32</cell><cell>10.53</cell><cell>0.00</cell><cell>17.92</cell><cell>18.25</cell><cell>19.37</cell><cell>17.50</cell><cell>19.08</cell><cell>20.00</cell></row><row><cell></cell><cell>Average</cell><cell>45.23</cell><cell>42.39</cell><cell>6.14</cell><cell>31.22</cell><cell>15.09</cell><cell>0.84</cell><cell>16.66</cell><cell>16.74</cell><cell>19.22</cell><cell>16.75</cell><cell>18.75</cell><cell>20.00</cell></row><row><cell></cell><cell>GCN</cell><cell>92.59</cell><cell>88.89</cell><cell>55.56</cell><cell>86.21</cell><cell>50.52</cell><cell>3.06</cell><cell>4.63</cell><cell>4.78</cell><cell>10.93</cell><cell>7.07</cell><cell>15.61</cell><cell>19.90</cell></row><row><cell></cell><cell>GraRep</cell><cell>90.91</cell><cell>90.32</cell><cell>39.39</cell><cell>87.10</cell><cell>72.73</cell><cell>8.06</cell><cell>7.88</cell><cell>8.45</cell><cell>14.73</cell><cell>8.97</cell><cell>10.61</cell><cell>18.89</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>93.75</cell><cell>90.32</cell><cell>28.12</cell><cell>82.35</cell><cell>68.75</cell><cell>7.79</cell><cell>7.91</cell><cell>8.03</cell><cell>16.03</cell><cell>8.53</cell><cell>11.59</cell><cell>19.31</cell></row><row><cell>Cora</cell><cell>node2vec</cell><cell>93.75</cell><cell>86.67</cell><cell>40.00</cell><cell>84.85</cell><cell>68.75</cell><cell>6.90</cell><cell>8.25</cell><cell>9.03</cell><cell>14.46</cell><cell>8.61</cell><cell>10.38</cell><cell>19.56</cell></row><row><cell></cell><cell>LINE</cell><cell>93.33</cell><cell>88.31</cell><cell>42.56</cell><cell>85.35</cell><cell>73.33</cell><cell>7.02</cell><cell>7.67</cell><cell>8.52</cell><cell>14.02</cell><cell>9.06</cell><cell>11.10</cell><cell>19.00</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>90.62</cell><cell>90.00</cell><cell>33.33</cell><cell>87.50</cell><cell>60.00</cell><cell>5.85</cell><cell>8.69</cell><cell>8.87</cell><cell>15.97</cell><cell>8.44</cell><cell>11.83</cell><cell>19.64</cell></row><row><cell></cell><cell>Average</cell><cell>92.49</cell><cell>89.09</cell><cell>39.83</cell><cell>85.56</cell><cell>65.68</cell><cell>6.45</cell><cell>7.51</cell><cell>7.95</cell><cell>14.36</cell><cell>8.45</cell><cell>11.85</cell><cell>19.38</cell></row><row><cell></cell><cell>GCN</cell><cell>96.97</cell><cell>96.97</cell><cell>66.67</cell><cell>82.59</cell><cell>58.32</cell><cell>3.25</cell><cell>4.94</cell><cell>5.03</cell><cell>11.61</cell><cell>7.63</cell><cell>14.90</cell><cell>19.53</cell></row><row><cell></cell><cell>GraRep</cell><cell>96.77</cell><cell>96.67</cell><cell>35.48</cell><cell>89.67</cell><cell>70.00</cell><cell>10.24</cell><cell>8.94</cell><cell>9.50</cell><cell>16.61</cell><cell>9.67</cell><cell>12.17</cell><cell>18.96</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>93.33</cell><cell>93.33</cell><cell>20.69</cell><cell>86.67</cell><cell>70.97</cell><cell>12.06</cell><cell>8.80</cell><cell>9.33</cell><cell>18.76</cell><cell>9.40</cell><cell>12.90</cell><cell>18.65</cell></row><row><cell>Citeseer</cell><cell>node2vec</cell><cell>93.33</cell><cell>90.32</cell><cell>26.67</cell><cell>86.55</cell><cell>76.67</cell><cell>11.64</cell><cell>9.63</cell><cell>9.06</cell><cell>16.27</cell><cell>10.21</cell><cell>10.87</cell><cell>19.02</cell></row><row><cell></cell><cell>LINE</cell><cell>94.44</cell><cell>91.02</cell><cell>26.67</cell><cell>83.33</cell><cell>74.19</cell><cell>12.04</cell><cell>8.89</cell><cell>9.20</cell><cell>15.92</cell><cell>10.87</cell><cell>11.00</cell><cell>18.37</cell></row><row><cell></cell><cell>GraphGAN</cell><cell>93.55</cell><cell>93.33</cell><cell>19.35</cell><cell>82.59</cell><cell>66.67</cell><cell>9.50</cell><cell>8.97</cell><cell>8.33</cell><cell>17.87</cell><cell>9.22</cell><cell>12.87</cell><cell>19.26</cell></row><row><cell></cell><cell>Average</cell><cell>94.73</cell><cell>93.61</cell><cell>33.29</cell><cell>85.23</cell><cell>69.47</cell><cell>9.79</cell><cell>8.36</cell><cell>8.41</cell><cell>16.17</cell><cell>9.50</cell><cell>12.45</cell><cell>18.97</cell></row><row><cell cols="6">much worse than the direct FGA as well as the NETTACK</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">and DICE, suggesting that changing the links far away can</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">rarely influence these bridge nodes. Overall, by comparing</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">the results in TABLE 5 and those in TABLE 3 and TABLE 4,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">we can find that the embeddings of bridge nodes are rela-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">tively difficult to attack than those of normal ones, but are</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">relatively easier to attack than those of hub nodes.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 6 :</head><label>6</label><figDesc>The attack effects on community detection, in terms of ASR and AML, obtained by different attack methods on various network embedding methods and multiple datasets. Here, ASR is obtained by changing 20 links.</figDesc><table><row><cell></cell><cell></cell><cell>Target: 12</cell></row><row><cell>Target: 12</cell><cell>Target: 12</cell><cell>Target: 12</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comprehensive survey of graph embedding: problems, techniques and applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gram: Graph-based attention model for healthcare representation learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The ACM SIGKDD International Conference</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="787" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deepwalk: online learning of social representations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Signed network embedding in social media</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pte: Predictive text embedding through large-scale heterogeneous text networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1165" to="1174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Linked document embedding for classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Eighth AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A semi-nmf-pca unified framework for data clustering</title>
		<author>
			<persName><forename type="first">K</forename><surname>Allab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Labiod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nadif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="16" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Aligning users across social networks using network embedding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1774" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page">2319</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps and spectral techniques for embedding and clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="585" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
				<meeting>the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
				<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Graphgan: Graph representation learning with generative adversarial nets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adversarial network embedding</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07838</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Column networks for collective classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2485" to="2491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic pearl classification machine based on multi-stream convolutional neural network</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="page" from="338" to="342" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Deep learning</title>
				<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deepfool: a simple and accurate method to fool deep neural networks</title>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2574" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adversarial examples that fool both human and computer vision</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08195</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (SP), 2017 IEEE Symposium on</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="39" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Adversarial attacks and defences competition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.00097</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security</title>
				<meeting>the 2017 ACM on Asia Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="506" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Universal adversarial perturbations</title>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Security evaluation of pattern classifiers under attack</title>
		<author>
			<persName><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fumera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="984" to="996" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Using machine teaching to identify optimal training-set attacks on machine learners</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2871" to="2877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The impact of unlinkability on adversarial community detection: effects and countermeasures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nagaraja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Privacy Enhancing Technologies Symposium</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="253" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hiding individuals and communities in a social network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Waniek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rahwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Community deception or: How to stop fearing community detection algorithms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Fionda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pirro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="660" to="673" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Preserving the privacy of sensitive relationships in graph data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zheleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Privacy, security, and trust in KDD</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="153" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Limiting link disclosure in social network analysis through subgraph-wise perturbation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Fard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Extending Database Technology</title>
				<meeting>the 15th International Conference on Extending Database Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="109" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neighborhood randomization for link privacy in social network analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Fard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="32" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ünnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-08-19">2018. August 19-23. 2018. 2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The political blogosphere and the 2004 us election: divided they blog</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international workshop on Link discovery</title>
				<meeting>the 3rd international workshop on Link discovery</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automating the construction of internet portals with machine learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Seymore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="163" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Closeness centrality for networks with overlapping community structure</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Tarkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szczepa Ński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wooldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Lethality and centrality in protein networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">N</forename><surname>Oltvai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">411</biblScope>
			<biblScope unit="issue">6833</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Centrality in networks of urban streets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Crucitti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Latora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Porta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos: an interdisciplinary journal of nonlinear science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15113</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Degree centrality for social network with opsahl method</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yustiawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maharani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Gozali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="419" to="426" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Structural parameters of communication networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shimbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of Mathematical Biophysics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="501" to="507" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A mathematical model for group structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bavelas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Organization</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="16" to="30" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning community embedding with community detection and node embedding on graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cavallari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
				<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="377" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">From node embedding to community embedding</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cavallari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.09950</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Community preserving network embedding</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="203" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Modularity and community structure in networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
				<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="8577" to="8582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The bottlenose dolphin community of doubtful sound features a large proportion of long-lasting associations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lusseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Boisseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Slooten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Dawson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral Ecology and Sociobiology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="396" to="405" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2605</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
