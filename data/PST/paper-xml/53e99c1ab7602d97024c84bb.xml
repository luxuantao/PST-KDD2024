<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling a Dynamic Data Replication Strategy to Increase System Availability in Cloud Computing Environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Da-Wei</forename><surname>Sun</surname></persName>
							<email>sundaweicn@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Student Member, CCF, ACM</roleName><forename type="first">(</forename><surname>孙大为</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gui-Ran</forename><surname>Chang</surname></persName>
							<email>chang@neu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Computing Center</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shang</forename><surname>Gao</surname></persName>
							<email>shang.gao@deakin.edu.au</email>
							<affiliation key="aff2">
								<orgName type="department">School of Engineering and Information Technology</orgName>
								<orgName type="institution">Deakin University</orgName>
								<address>
									<postCode>3217</postCode>
									<settlement>Geelong</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li-Zhong</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xing-Wei</forename><surname>Wang</surname></persName>
							<email>wangxw@mail.neu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling a Dynamic Data Replication Strategy to Increase System Availability in Cloud Computing Environments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E4C71E2D4A89B93BFFF6B05CFD4DE328</idno>
					<idno type="DOI">10.1007/s11390-012-1221-4</idno>
					<note type="submission">Received June 17, 2011; revised January 29, 2012.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>system availability</term>
					<term>replication perspective</term>
					<term>high fault tolerance</term>
					<term>temporal locality</term>
					<term>cloud computing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Failures are normal rather than exceptional in the cloud computing environments. To improve system availability, replicating the popular data to multiple suitable locations is an advisable choice, as users can access the data from a nearby site. This is, however, not the case for replicas which must have a fixed number of copies on several locations. How to decide a reasonable number and right locations for replicas has become a challenge in the cloud computing. In this paper, a dynamic data replication strategy is put forward with a brief survey of replication strategy suitable for distributed computing environments. It includes: 1) analyzing and modeling the relationship between system availability and the number of replicas; 2) evaluating and identifying the popular data and triggering a replication operation when the popularity data passes a dynamic threshold; 3) calculating a suitable number of copies to meet a reasonable system byte effective rate requirement and placing replicas among data nodes in a balanced way; 4) designing the dynamic data replication algorithm in a cloud. Experimental results demonstrate the efficiency and effectiveness of the improved system brought by the proposed strategy in a cloud.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Introduction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Background and Motivation</head><p>Cloud computing (CC), the long-held dream of "computing as a utility", has opened up the new era of future computing, transformed a large part of IT industry, and reshaped the purchase and use of IT software and hardware <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> . Cloud computing is a large-scale distributed computing paradigm driven by economies of scale, in which a pool of abstracted, virtualized, dynamically-scalable, highly available, and configurable and reconfigurable computing resources (e.g., networks, servers, storage, applications, data) can be rapidly provisioned and released with minimal management effort in the data centers. Services are delivered on demand to external customers over high-speed Internet with the "X as a service (XaaS)" computing architecture, which is broken down into three segments: "applications", "platforms", and "infrastructure". Its aims <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> are to provide users with more flexible services in a transparent manner and with ever cheaper and more powerful processors. Similarly, IT companies with innovative ideas for new application services are no longer required to make large capital outlays in the hardware and software infrastructures. By using cloud computing platforms, they can register necessary services from the Internet and are free from the trivial task of setting up basic hardware and software infrastructures, which allows them to focus on the core aspects of their business. In computational view, cloud computing is a network of data centers and is described as a powerful, low-cost, and energy-efficient approach to future computing. The data centers form what we call clouds. From a sociological standpoint on the other hand, in the cloud, applications are accessible anywhere, anytime, and storage becomes infinite for all intents and purposes. And the users can access the powerful applications, platforms, and services delivered over Internet.</p><p>The difference between cloud and other large-scale distributed computing platforms can be summarized as follows <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> .</p><p>1) On-Demand Self-Service. A user can unilaterally provision computing capabilities, such as network storage, as needed automatically without requiring human interaction with each service's provider.</p><p>2) Broad Network Access. Capabilities are available over the network and accessed through standard mechanisms that promote the use by heterogeneous thin or thick client platforms.</p><p>3) Resource Pooling. The computing resources are pooled to serve multiple users by using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand.</p><p>4) Rapid Elasticity. Capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the users, the capabilities available for provisioning often appear to be unlimited and can be purchased in any quantity at any time.</p><p>5) Measured Services. Cloud systems automatically control and optimize resource usage by leveraging a metering capability at some level of abstraction appropriate to the type of the service. Resource usage can be monitored, controlled, and reported to provide transparency for both the provider and consumers of the utilized service.</p><p>In a word, clouds can be a highly available, much cheaper, and much more elastic, reliable, and scalable computing environment compared to supercomputers, grids and other large-scale distributed computing environments. Clouds promise "scale by credit card". Moreover, clouds also promise "bags of tasks" <ref type="bibr" target="#b4">[5]</ref> . More detailed discussion can be found in [3-9].</p><p>High availability, high fault tolerance and high efficiency access to cloud data centers where failures are normal rather than exceptional are significant issues, due to the large-scale data support. Data replication allows reducing user waiting time, speeding up data access and increasing data availability by providing the user with different replicas of the same service, all of them with a coherent state. Replication is a frequently used technique in the cloud, such as GFS (Google file system) <ref type="bibr" target="#b9">[10]</ref> , HDFS (Hadoop Distributed File System) <ref type="bibr" target="#b10">[11]</ref> . However, cloud data centers have grown rapidly in both size and number, and the dynamically-scalable and totally virtualized resources are provided as a service over the Internet <ref type="bibr" target="#b11">[12]</ref> . In most of the real cloud, data replication is achieved through data resource pool, the number of data replicas is statically set based on history experience and is usually less than 3. This strategy works well at most time, but it will fail at inclement times. And it is not necessary to create replica for all data files, especially for those non-popular data files. In order to meet the high availability, high fault tolerance and high efficiency requirement, it is necessary to dynamically adjust the popular data files, the number of data replicas and the sites to place the new replicas according to the current cloud environments.</p><p>In order to achieve the dynamic data replication, there are three important problems that must be solved. 1) Which data should be replicated and when to replicate in the cloud systems to meet the users' requirements on waiting time reduction and data access speeding up are important issues for further research, as the wrongly selected and too early replicated data will not reduce the waiting time or speed up data access. 2) How many suitable new replicas should be created in the cloud to meet a reasonable system availability requirement is another important issue to be thoroughly investigated. With the number of new replicas increasing, the system maintenance cost will significantly increase, and too many replicas may not increase availability, but bring unnecessary spending instead. 3) Where the new replicas should be placed to meet the system task successful execution rate and bandwidth consumption requirements is also an important issue to be explored in detail. By keeping all replicas active, the replicas may improve system task successful execution rate and bandwidth consumption if the replicas and requests are reasonably distributed. However, appropriate replica placement in ultra-large-scale, dynamically scalable and totally virtualized data centers is much more complicated.</p><p>Our work is originally motivated by the fact that a more recently accessed data will be accessed again in the near future according to the current data access pattern, which is called temporal locality <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> . With the fact of temporal locality, a popular data is determined by analyzing the users' access to the data. When the popularity of the data passes a dynamic threshold, the replication operation will be triggered. The number of replicas will be determined based on the system availability and failure probability. New replica will be created on near-by locations for users who generate the most requests for the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contributions</head><p>In this paper, a mathematical model is formulated to describe the relationship between the system availability and number of replicas, while the size, access time and failure probability of each data file are taken into consideration. A popular data file is identified by analyzing the access histories and setting different weights for different accessed data. Basically, the more recently accessed data is more pertinent to the analysis, and is thus set a big weight. When the popularity of a data file passes a dynamic threshold, the replication operation will be triggered. Replicas are placed among data nodes in a balanced way, taking into account the number of access of all users.</p><p>Based on the above facts and considerations, a novel dynamic data replication strategy named D2RS (Dynamic Data Replication Strategy) is proposed. It allows for increasing the data availability and minimizing cloud system bandwidth consumption. For evaluation purposes, the D2RS is implemented using the CloudSim toolkit and the experimental results demonstrate that the proposed strategy increases system availability, improves system task successful execution rate, and reduces bandwidth consumption in the cloud.</p><p>Our contributions can be summarized as follows. 1) A mathematical model is formulated to describe the relationship between the system availability and the number of replicas, which is missing in most existing research. 2) The popular data file is identified, when the popularity of a data file passes a dynamic threshold, the replication operation will be triggered. 3) Replicas are placed among data nodes in a balanced way. 4) A dynamic data replication algorithm named D2RS is proposed, implemented on a simulation toolkit and evaluated. It is proved that this algorithm is able to increase the system availability and reduce the bandwidth consumption in the cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Paper Organization</head><p>The remainder of this paper is organized as follows. In Section 2,the related work on data storage and data replicas of cloud computing systems is analyzed. Section 3 presents a system model, a series of availability definitions, and a mathematical analysis to describe the relationship between the system availability and the number of replicas. Section 4 describes the dynamic data replication strategy, including the replication decision, the number of replicas, the replica placement and the detailed design of the D2RS algorithm. Section 5 addresses the simulation environment, parameter setup and performance evaluation of the proposed dynamic data replication strategy. Finally, conclusions and future work are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, two broad categories of related work are presented: cloud data storage and cloud data replication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cloud Data Storage</head><p>Many large institutions have set up data centers and cloud computing platforms, such as Google, Amazon, IBM. Compared with traditional large scale storage systems, the clouds which are sensitive to workloads and user behaviors focus on providing and publishing storage service on Internet <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref> . The key components of the cloud are distributed file systems, such as GFS, HDFS.</p><p>In a GFS cluster, there are three components, multiple clients, a single master server, and multiple chunk servers, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Files are stripped into one or many fixed size chunks, and these chunks are stored in the data centers, which are managed by the chunk servers. The master server maintains all the metadata of the file system, including the namespace, the access control information, the mapping from files to chunks, and the current locations of chunks. Clients interact with the master for metadata operations, but all data bearing communication goes directly to the chunk servers <ref type="bibr" target="#b9">[10]</ref> . In a multi-cluster system, each cluster is a complete GFS cluster and with its own master, and each master maintains the metadata of its own file system. Different masters can share the metadata by the namespace, which describes how the log data is partitioned across multiple clusters <ref type="bibr" target="#b17">[18]</ref> . Compared with a single cluster, in a multi-cluster system, the performance of the cloud system and the size of the cloud data storage can be improved significantly.</p><p>The mechanism of HDFS is similar to that of GFS, but it is light-weighted and open-source. More detailed discussion can be found in [11].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cloud Data Replication</head><p>Data replication, a well-known technique from distributed systems, is the main mechanism used in the cloud for reducing user waiting time, increasing data availability and minimizing cloud system bandwidth consumption by offering the user different replicas with a coherent state of the same service <ref type="bibr" target="#b18">[19]</ref> . With the advancement and development of various technologies, data replication and replica management in distributed systems have been studied in many works, which are referenced and adopted in cloud data replication. Data replication algorithms can be classified into two groups: static replication <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b19">20]</ref> and dynamic replication algorithms <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> . In a static replication model, the replication strategy is predetermined and well defined. On the other hand, dynamic replication automatically creates and deletes replicas according to changing access patterns. Static and dynamic replication algorithms can be further classified into groups as distributed <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref> and centralized algorithms <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref> .</p><p>In [10], a static distributed cloud data replication algorithm is proposed. In the GFS, a single master considers three factors when making decisions on data chunk replications: 1) to place the new replicas on chunk servers with below-average disk space utilization; 2) to limit the number of "recent" creations on each chunk server; 3) to spread replicas of a chunk across racks. A data chuck is replicated when the number of replicas falls below a limit specified by the users. Similarly, in [11], an application can specify the number of replicas for each file, and the block size and replication factor are configurable per file.</p><p>In [20], a p-median static centralized data replication algorithm is proposed. The p-median model finds p replica placements sites that minimize the requestweighted total distance between the requesting sites and the replication sites holding the copies assigned.</p><p>In [15], a dynamic distributed cloud data replication algorithm CDRM is proposed. The CDRM is designed on the HDFS platform, the data replica placement is based on the capacity and location according to workload changing and node capacity, and the lower bound of the number of replicas is dynamically determined according to the availability requirement. In [21], six different data replication algorithms, Caching-PP, Cascading-PP, Fast Spread-PP, Cascading-Enhanced, and Fast Spread-Enhanced are proposed. All the six algorithms are dynamic replication algorithms and implemented in a distributed fashion.</p><p>In [22], a dynamic centralized data replication algorithm MinDmr is proposed. MinDmr treats hot and cold data differently and uses a weighting factor for the replication. And then MinDmr is developed into four prediction-based replica schemes. Similarly, in [13], an algorithm LALW is proposed. LALW selects a popular file for replication and calculates a suitable number of copies and grid sites for replication.</p><p>In the cloud, to reduce the access time, the data storage unit is a block. If a data file is too large, it will be stripped into many blocks. However, the data access unit usually is data file. The differences between the mentioned replication algorithms and our proposed strategy lie in the following aspects. 1) A mathematical model is formulated to describe the relationship between the system availability and the number of replicas. 2) The popular data is identified according to the temporal locality. When the popularity of a data file passes a dynamic threshold, the replication operation will be triggered. 3) Replicas are placed among data nodes in a balanced way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Model and Problem Statement</head><p>In this section, a system model, a series of availability definitions and a mathematical analysis to describe the relationship between system availability and the number of replicas are presented in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Model</head><p>The multi-tier hierarchical cloud system architecture <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref> supports an efficient method for sharing data and computational and other resources, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. It typically consists of different tiers of data centers with different regions and sizes. The super data centers in tier 0 will handle the data analysis in the intra domain and exchange data information among the inter domains. The main data centers are in tier 1, ordinary data centers are in tier 2, and users are in tier 3. The architecture minimizes the data access time and network load by creating and spreading replicas from the super data centers to main data centers, or to ordinary data centers. The super data centers periodically collect and broadcast the global information.</p><p>A cloud data service system typically consists of the scheduling broker, the replica broker and data centers, as shown in Fig. <ref type="figure" target="#fig_2">3</ref>. The scheduling broker is the central managing broker. The replica managers hold the general information about the replica locations in data centers. The specific features of cloud data servers can be described as follows. Let U = {u 1 , u 2 , . . . , u m } be a user set composed of m users, TS = {TS 1 , TS 2 , . . . , TS m } be a set of tasks of the user set U , and TS j = {ts j1 , ts j2 , . . . , ts jm j } be a sub-set of tasks of the j-th user u j , where m j is the number of sub-tasks, and ts k is the k-th task submitted to the scheduling broker through a user interface and independent of the other users. The replica broker schedules them to the appropriate cloud data server sites. If u 0 has two tasks, then TS 0 = {ts 01 , ts 02 }, and m 0 = 2. A task ts k is characterized by a 4-tuple ts k = (tid k , tr k , td k , tfn k ), where tid k , tr k , td k and tfn k are the task identification, task generation rate, task deadline time and the number of required files of task ts k , respectively. For simplicity, we assume that the tasks are non-preemptable and non-interruptible <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref> , which mean that a task cannot be broken into smaller sub-tasks and it has to be executed as a whole on a single processor with given resources. In addition, as soon as a task starts its execution on a processor, it cannot be interrupted and it occupies the processor until its execution completes successfully or a failure occurs.</p><p>Let DC = {dnd 1 , dnd 2 , . . . , dnd n } be a data center composed of n data nodes, which are running virtual machines on physical machines.</p><p>A data node dnd k is characterized by a 5-tuple dnd k = (dnd k , dr k , dst k , df k , dbw k ), where did k , dr k , dst k , df k and dbw k are the data node identification, request arrival rate, average service time, failure probability and network bandwidth of data node dnd k , respectively.</p><p>In order to guarantee the service performance of the data center DC , the task generation rate tr k of user set U , the request arrival rate dr k and failure probability df k of DC should meet (1).</p><formula xml:id="formula_0">jk j=0 tr j n i=0 dr i × (1 -df i ), jk = m j=0 j m k , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where tr j is the task generation rate of task j, dr i is the request arrival rate of task j, df k is the failure probability of task j, j m k is the number of tasks of user j.</p><p>Let F = {f 1 , f 2 , . . . , f l } be a data file set of a data center DC. B = {B 1 , B 2 , . . . , B l } be a set of blocks in the data center DC, and B i = {b i1 , b i2 , . . . , b in i } be the i-th sub-set of blocks belonging to the i-th data file f i , which is stripped into n i fixed blocks according to its length. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, if data file A is stripped into 3 blocks, then A = {a 1 , a 2 , a 3 }, and</p><formula xml:id="formula_2">n i = 3. An block b k is characterized by a 5-tuple b k = (bid k , bp k , bs k , bn k , bt k )</formula><p>, where bid k , bp k , bs k , bn k and bt k are the block identification, number of requests, block size, the number of replicas and the last access time of block b k , respectively.</p><p>When user u j requests a block b k from a data node dnd i with bandwidth performance guarantee, bandwidth bs k /dst i should be assigned to this session. The total bandwidth used to support different requests from use set U should be no more than dbw i , as shown by (2).</p><formula xml:id="formula_3">si i=0 bs k dst i dbw i , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where s i is the maximum number of network sessions of data node dnd i that can serve concurrently, bs k is the block size of block b k , dst i is the average service time of data node dnd i , dbw i is the network bandwidth of data node dnd i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System Byte Effective Rate</head><p>One of the most important objectives of cloud is to provide the highest availability by placing all replicas of blocks of data files in a load balanced way on different data nodes of data centers, which is similar to that for grid environments <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref> . Definition 1 (Availability). It is the ability of a system to limit, control, and provide proper service under given constraints, defined as the "readiness for correct service" of a system <ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref> . The lifetime of a cloud system can be divided into a set of "up states" and a set of "down states". And the availability can be categorized as instantaneous availability, steady-state availability and inherent availability.</p><p>The instantaneous availability a i (t) of a system is defined as the probability that a system is in an "up state" at time t under the constraint that it is correct at time t = 0 (i.e., a i (0) = 1), shown by (3).</p><formula xml:id="formula_5">a i (t) = r(t), if no repair operations, p{s t = p i (up)|s 0 = p i (init)}, otherwise,<label>(3)</label></formula><p>where r(t) is the reliability at time t of the system. If no repair operations, the instantaneous availability a i (t) equals to the system reliability r(t). s t refers to the state at time t, p i (up) is a predicate that specifies the states where the system is operational, doing something useful. p i (init) specifies the initial states, and</p><formula xml:id="formula_6">p i (init) = true.</formula><p>The steady-state availability a s (t) of a system is defined as the probability that a system is in an "up state" for "sufficiently long time" after the system starts and is examined at an arbitrary point of time. It is the limit value of a i (t) as t approaches infinity, as given by (4).</p><formula xml:id="formula_7">a s (t) = lim t→∞ a i (t) = lim t→∞ t 0 a i (k)dk t . (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>The inherent availability a(t) of a system is the expected value of the percentage of the time interval during which the system performs its required function, as defined by (5).</p><formula xml:id="formula_9">a(t) = MTBF MTBF + MTTR , (<label>5</label></formula><formula xml:id="formula_10">)</formula><p>where MTBF is the mean time between faults, and MTTR is the mean time to repair. Definition 2 (Block Availability). Block availability is the ability of a data block to limit, control, and provide proper service under given constraints. The block availability of a block b k is denoted as BA k . P (BA k ) is the probability of block b k in an available state. P (BA k ) is the probability of block b k in an unavailable state, and</p><formula xml:id="formula_11">P (BA k ) = 1 -P (BA k ).</formula><p>The number of replicas of block b k is bn k . It is obvious that block b k is considered unavailable only if all the replicas of block b k are not available. So the availability and unavailability of block b k is given in Theorem 1.</p><p>Theorem 1. If the number of replicas of block b k is bn k , the available and unavailable probability of each replica of block b k are p(ba k ) and p(ba k ) = 1 -p(ba k ), respectively, then,</p><formula xml:id="formula_12">P (BA k ) = 1 -(1 -p(ba k )) bn k , (<label>6</label></formula><formula xml:id="formula_13">)</formula><p>and</p><formula xml:id="formula_14">P (BA k ) = (1 -p(ba k )) bn k . (<label>7</label></formula><formula xml:id="formula_15">)</formula><p>Proof. The available and unavailable probability of each replica of block b k are p(ba k ) and p(ba k ), and the available and unavailable probability of block b k are P (BA k ) and P (BA k ). As there are bn k replicas of block b k , block b k is unavailable if and only if all the bn k replicas of block b k are unavailable. Therefore,</p><formula xml:id="formula_16">P (BA k ) = p(ba k1 , ba k2 , • • • , ba k bn k ).</formula><p>All the bn k replicas are distributed in different data nodes, and all the bn k replicas are independent of each other, thus,</p><formula xml:id="formula_17">P (BA k ) = p(ba k1 ) × p(ba k2 ) × • • • × p(ba k bn k ) = bn k i=1 p(ba ki ).</formula><p>Then,</p><formula xml:id="formula_18">P (BA k ) = bn k i=1 p(ba ki ) = bn k i=1 (1 -p(ba ki )) = bn k i=1 (1 -p(ba k )) = (1 -p(ba k )) bn k .</formula><p>As P (BA k ) = 1 -P (BA k ) , we obtain</p><formula xml:id="formula_19">P (BA k ) = 1 -P (BA k ) = 1 -(1 -p(ba k )) bn k .</formula><p>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, if the number of replicas of block a 1 is 3, that is bn k = 3, and the available probability of each replica is 0.98, i.e., p(ba a1 ) = 0.98, then the available probability of block a</p><formula xml:id="formula_20">1 is P (BA a1 ) = 1 -(1 -p(ba a1 )) bn k = 1 -(1 -0.98) 3 = 0.999 92, the unavailable probability of block a 1 is P (BA a1 ) = (1 -p(ba a1 )) bn k = (1 -0.98) 3 = 0.000 008.</formula><p>Definition 3 (File Availability). File availability is the ability of a data file to limit, control, and provide proper service under given constraints. The file availability of a data file f i is denoted as FA i . P (FA i ) is the probability of data file f i in an available state. P (FA i ) is the probability of data file f i in an unavailable state, and P (FA i ) = 1 -P (FA i ).</p><p>If the data file f i is stripped into n i fixed blocks denoted by B i = {b i1 , b i2 , . . . , b in i }, which are distributed on different data nodes. N i = {bn i1 , bn i2 , . . . , bn in i } is the set of the numbers of replicas of the blocks of B i . The availability and unavailability of data file f i is given in Theorem 2.</p><p>Theorem 2. If the data file f i is stripped into n i blocks, there are bn i replicas of each block in data file f i , and all blocks at the same site will have the same available probability as all blocks are stored in data nodes with the same configuration in cloud data centers, the available probability of each replica is p(ba i ) in data file f i , then,</p><formula xml:id="formula_21">P (FA i ) = 1 -(1 -p(ba i )) bni ni , (<label>8</label></formula><formula xml:id="formula_22">)</formula><p>and</p><formula xml:id="formula_23">P (FA i ) = 1 -(1 -p(ba i )) bni ni . (<label>9</label></formula><formula xml:id="formula_24">)</formula><p>Proof. As the data file f i is stripped into n i blocks, the data file f i is available if and only if each block in B i = {b i1 , b i2 , . . . , b in i } are available, and all blocks are independent of each other. Therefore,</p><formula xml:id="formula_25">P (FA i ) = P (BA i1 , BA i2 , . . . , BA in i ) = P (BA i1 ) × P (BA i2 ) × • • • × P (BA in i ) = ni j=1 P (BA ij ) = ni j=1 1 - ni j k=1 1 -p(ba ij ) .</formula><p>All blocks are stored in data nodes with the same configuration in cloud data centers, without loss of generality. So we set the probability of all blocks of data file f i to the same, that is,</p><formula xml:id="formula_26">p(ba i1 ) = p(ba i2 ) = • • • = p(ba in i ) = p(ba i ).</formula><p>As the set of numbers N i = {bn i1 , bn i2 , . . . , bn in i } of replicas of all blocks of data file f i are the same, that is,</p><formula xml:id="formula_27">bn i1 = bn i2 = • • • = bn in i = bn i .</formula><p>We obtain</p><formula xml:id="formula_28">P (FA i ) = ni j=1 1 - bni j k=1 (1 -p(ba ij )) = ni j=1 1 -(1 -p(ba i )) bni j = 1 -(1 -p(ba i )) bni ni .</formula><p>As P (FA i ) = 1 -P (FA i ), we obtain</p><formula xml:id="formula_29">P (FA i ) = 1 -P (FA i ) = 1 -1 -(1 -p(ba i )) bni ni .</formula><p>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, if the data file a is stripped into 3 blocks, that is n i = 3, the number of replicas of data file a is also 3, that is bn k = 3, and the available probability of each replica is 0.98, i.e., p(ba a ) = 0.98, then the availability and unavailability of data file f i are P (FA i ) = 1 -(1 -0.98) 3 3 = 0.999 976 and P (FA i ) = 1 -1 -(0.98) 3 3 = 0.000 024, respectively.</p><p>Because the system level data availability is more important than the single file availability in the cloud, higher system data availability will result in more benefits than higher file availability, especially when some data files are popular while other data files are not.</p><p>Definition 4 (System Byte Effective Rate). System byte effective rate is the rate of the number of bytes potentially available and the total number of bytes requested by all tasks in a system. The system byte effective rate of a system is denoted as R(SBER).</p><p>Given the fact that a particular data file access operation will only request one file, any two file request will access different replicas and be independent of each other. Each user from the user set U will request one or more data files at one data file request. The system byte effective rate and system byte non-effective rate of a system is given in Theorem 3.</p><p>Theorem 3. If F = {f 1 , f 2 , . . . , f fn } is the data file set of a data center DC and is composed of fn data files, B = {B 1 , B 2 , . . . , B f n } is a set of blocks of data center DC, B i = {b i1 , b i2 , . . . , b in i } is the i-th sub-set of blocks belonging to the i-th data file f i , which consists of n i blocks, the number of accesses of all users to the i-th data file f i is an i , the number of replicas of each block in data file is bn i , and the size of block b k is bs k , then,</p><formula xml:id="formula_30">R(SBER) = fn i=1 an i × ni h=1 bs h × 1 -(1 -p(ba i )) bni ni fn i=1 an i × ni h=1 bs h . (<label>10</label></formula><formula xml:id="formula_31">)</formula><p>Proof. The data file set F = {f 1 , f 2 , . . . , f fn } of a data center DC is composed of fn data files, and system byte effective rate R(SBER) of a system is the rate of the number of bytes potentially available and the total number of bytes requested by all tasks. Therefore,</p><formula xml:id="formula_32">R(SBER) = fn i=1 (P (FA i ) × FS i ) fn i=1 FS i ,</formula><p>where FS i is the total number of bytes requested by all tasks of the i-th data file f i .</p><p>If the number of accesses of the total users of the i-th data file f i is an i , and the size of data file f i is fs i , then, FS i is</p><formula xml:id="formula_33">FS i = ani k=1 fs k .</formula><p>If the i-th data file f i is stripped into n i blocks, and the size of block b k is bs k , then,</p><formula xml:id="formula_34">fs i = ni h=1 bs h .</formula><p>We have Without loss of generality, assume the available probabilities p(ba k ) of all replicas of block b k are the same in all an i access cycles. Then the following is obtained,</p><formula xml:id="formula_35">R(SBER) = fn i=1 ani k=1 ni h=1 bs h × 1 -(1 -p(ba i )) bni ni fn i=1 ani k=1 ni h=1 bs h = fn i=1 an i × ni h=1 bs h × 1 -(1 -p(ba i )) bni ni fn i=1 an i × ni h=1 bs h .</formula><p>For a scenario given in Fig. <ref type="figure" target="#fig_4">4</ref>, assume there are 3 data files a, b, and c in data center DC, and l = 3. Table <ref type="table">1</ref> shows the detailed parameter setup for the example in Fig. <ref type="figure" target="#fig_4">4</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dynamic Data Replication Strategy</head><p>The dynamic data replication strategy D2RS (Dynamic Data Replication Strategy) has three important phases: 1) which data file should be replicated and when to replicate in the cloud system to meet users' requirements such as waiting time reduction and data access speeding up; 2) how many suitable new replicas should be created in the cloud system to meet a given availability requirement; 3) where the new replicas should be placed to meet the system task successful execution rate and bandwidth consumption requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Decide Which and When to Replicate</head><p>Given the fact that a more recently accessed data file might be accessed again in the near future according to the current status of data access pattern, which is called temporal locality, a popular data file is determined by analyzing the access to the data from users. When the popularity of a data file passes a dynamic threshold, the replication operation will be triggered <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref> .</p><p>Definition 5 (Time-Based Forgetting Function). A time-based forgetting function ω is defined over the domain Time, with values within the interval [0, 1]. It is used to calculate the popularity degree PD b k of a block b k at the present time t p according to the access frequency at the start time t s , as shown by (11),</p><formula xml:id="formula_36">ω(t p , t s ) = a -(∆t) k = a -(tp-ts) k , a &gt; 1, k ∈ {1, 2, . . .}, (<label>11</label></formula><formula xml:id="formula_37">)</formula><p>where ∆t = t p -t s , as usual, parameter a is assigned as e, as shown by</p><formula xml:id="formula_38">ω(t p , t s ) = e -(∆t) k = e -(tp-ts) k , k ∈ {1, 2, . . .}. (<label>12</label></formula><formula xml:id="formula_39">)</formula><p>The value of k determines the rate of decay of the popularity degree with time ∆t, and is assigned by the block b k based on its perception about the change. Fig. <ref type="figure" target="#fig_5">5</ref> shows the nature of the change of ω(t p , t s ) with different values of k. If ∆t = 0, then ω(t p , t s ) = e -0 = 1. If ∆t → +∞, then ω(t p , t s ) = lim ∆t→+∞ e -(∆t) k = 0. This corroborates the fact that the time-based forgetting weight is asymptotic to zero at infinite time. Definition 6 (Popularity Degree). The popularity degree of a block b k is defined as the access frequency based on time factor. During the period from the start time t s to the present time t p , the popularity degree pd k of a block b k can be calculated by (13).</p><formula xml:id="formula_40">pd k = tp ti=ts (an k (t i , t i+1 ) × ω(t i , t p )), (<label>13</label></formula><formula xml:id="formula_41">)</formula><p>where an k (t i , t i+1 ) is the number of accesses during the time interval t i to t i+1 . Definition 7 (Replica Factor). The replica factor is defined as the ratio of the popularity degree and the total number of bytes of data file f i requested by all tasks under given constraints. It is used to determine whether the data file f i should be replicated, denoted as RF i in (14).</p><formula xml:id="formula_42">RF i = PD i RN i × FS i , (<label>14</label></formula><formula xml:id="formula_43">)</formula><p>where PD i , RN i , FS i are the popularity degree, number of replicas and file size of data file f i in million bytes, respectively. Theorem 4. If the data file f i is stripped into n i blocks, bn i , bs i , and an k (t i , t i+1 ) are the number of replicas, block size and number of accesses in the time interval t i to t i+1 of each block in the data file f i , respectively, then,</p><formula xml:id="formula_44">RF i = tp ti=ts (an k (t i , t i+1 ) × ω(t i , t p )) bn i × ni j=1 bs j . (<label>15</label></formula><formula xml:id="formula_45">)</formula><p>Proof. As the data file f i is stripped into n i blocks, and</p><formula xml:id="formula_46">B i = {b i1 , b i2 , . . . , b in i }, if the block b k ∈ f i ,</formula><p>once one user accesses block b k , he will access all the blocks of the file f i , then the popularity degree pd k of a block b k is equal to the popularity degree PD i of the file f i . At the same time, assume the set of numbers N i = {bn i1 , bn i2 , . . . , bn in i } of replicas of all blocks in the data file f i be the same, denoted as bn i . Therefore,</p><formula xml:id="formula_47">RF i = PD i RN i × FS i = pd k ni l=1 bni h=1 bs l h = tp ti=ts (an k (t i , t i+1 ) × ω(t i , t p )) bn i × ni j=1 bs j .</formula><p>According to Definition 7, we can prove that the system replica factor RF sys can be calculated by (16).</p><formula xml:id="formula_48">RF sys = l h=1 tp ti=ts (an h (t i , t i+1 ) × ω(t i , t p )) l i=1 bn i × ni j=1 bs j . (<label>16</label></formula><formula xml:id="formula_49">)</formula><p>In each time interval T, the replication operation of the data file f i will be triggered if the condition shown in (17) is met.</p><formula xml:id="formula_50">RF i &gt; min (1 + α) × RF sys , max ∀ k∈[1,2,...,l] RF k , α ∈ [0, 1], (<label>17</label></formula><formula xml:id="formula_51">)</formula><p>where α is the adjustable parameter according to different system performance. The better the requested system performance, the greater α can be selected.</p><p>If α = 0, then all files whose replica factors are greater than (1 + α) × RF sys will be replicated.</p><p>If</p><formula xml:id="formula_52">(1 + α) × RF sys = max ∀ k∈[1,2,...,l]</formula><p>RF k , then the only one file with the maximum replica factor will be replicated.</p><formula xml:id="formula_53">If (1 + α) × RF sys &gt; max ∀ k∈[1,2,...,l]</formula><p>RF k , then no file will be replicated.</p><p>For the scenario given in Fig. <ref type="figure" target="#fig_4">4</ref>, assume that data file a is stripped into 3 blocks a 1 , a 2 and a 3 , the number of replicas of each block is 3, the block sizes of the blocks are 64 MB, 64 MB and 53 MB. Table <ref type="table" target="#tab_1">2</ref> shows the detailed parameter setup used within the time interval t 0 to t 5 .  The data file b is stripped into 2 blocks b 1 and b 2 , as shown in Fig. <ref type="figure" target="#fig_4">4</ref>, the number of replicas of each block is 3, the block sizes of the blocks are 64 MB and 58 MB. Table <ref type="table" target="#tab_2">3</ref> shows the detailed parameter setup used within time interval t 1 to t 5 .  Assume that data file c be stripped into block c 1 , as shown in Fig. <ref type="figure" target="#fig_4">4</ref>, the number of replicas of block c 1 is 3, the block size of block c 1 is 39 MB. Table <ref type="table" target="#tab_3">4</ref> shows the detailed parameter setup used within time interval t 3 to t 5 .  If α = 0.2, (1 + α) × RF sys = (1 + 0.2) × 6.329 005 = 7.594 806, the files b and c will be replicated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RF</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RF</head><p>If α = 0.5, (1 + α) × RF sys = (1 + 0.5) × 6.329 005 = 9.493 507, the file c will be replicated.</p><p>If α = 0.9, (1 + α) × RF sys = (1 + 0.9) × 6.329 005 = 12.025 109, no file will be replicated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Determine the Number of New Replicas</head><p>To meet the system byte effective rate requirement, new replicas should be created <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref> . With a reasonable increase of file availability, the number of new replicas that need to be created can be calculated according to (18), which determines the new replicas on the basis of old file availability P old (FA i ) of data file f i and the replica factor based adjustable parameter β.</p><formula xml:id="formula_54">P new (FA i ) = P old (FA i ) + β × (1 -P old (FA i )), β ∈ [0, 1],<label>(18)</label></formula><p>where P new (FA i ) and P old (FA i ) are the new file availability and the old file availability of data file f i , respectively. β is the replica factor based adjustable parameter. It can be calculated according to (19).</p><formula xml:id="formula_55">β = RF i nums k=1 RF k , (<label>19</label></formula><formula xml:id="formula_56">)</formula><p>where num s is the number of files selected to be replicated.</p><p>Theorem 5. If the data file f i is stripped into n i blocks, P old (FA i ) is the old file availability of data file f i , RF i is the replica factor of data file f i , bn i (old ) is the old replica number of data file f i , num s is the number of files selected to be replicated, the number of new replicas bn i (inc) to be created is,</p><formula xml:id="formula_57">bn i (inc) =                 ln         1-       P old (FA i )+ RF i nums k=1 RF k × (1-P old (FA i ))       1 ni         ln(1 -p(ba i )) -bn i (old )                 . (<label>20</label></formula><formula xml:id="formula_58">)</formula><p>Proof.</p><p>As P new (FA i ) and P old (FA i ) are the new file availability and old file availability of data file f i , respectively, and</p><formula xml:id="formula_59">P new (FA i ) = 1 -1- p(ba i ) bni(new ) ni</formula><p>, according to ( <ref type="formula" target="#formula_54">18</ref>) and ( <ref type="formula" target="#formula_55">19</ref>), we obtain,</p><formula xml:id="formula_60">1 -(1 -p(ba i )) bni(new ) ni = P old (FA i ) + RF i nums k=1 RF k × (1 -P old (FA i )),</formula><p>and,</p><formula xml:id="formula_61">bn i (new ) =              ln         1-       P old (FA i )+ RF i nums k=1 RF k × (1-P old (FA i ))       1 ni         ln(1 -p(ba i ))              .</formula><p>If the old number of replicas is bn i (old ), the number of new replicas bn i (inc) to be created is,</p><formula xml:id="formula_62">bn i (inc) = bn i (new ) -bn i (old ) =                 ln         1-       P old (FA i )+ RF i nums k=1 RF k × (1-P old (FA i ))       1 ni         ln(1 -p(ba i )) -bn i (old )                 .</formula><p>For the scenario given in Subsection 4.1, assume α = 0.2 and the files b and c will be replicated, Table <ref type="table" target="#tab_4">5</ref> shows the detailed parameters used. bn b (inc) = ln(1 -(0.709 867 + (1 -0.709 867) × (9.342 559/(9.342 559 + 11.786 438))) 1/2 )/(ln(1 -0.46)) -3 = 1.010 306, so the number of new replicas of data file b to be created is 1; bn c (inc) = ln(1 -(0.945 128 + (1 -0.945 128) × (11.786 438/(9.342 559+11.786 438))) 1/1 )/(ln(1-0.62)) -3 = 0.843 406, so the number of new replicas of data file c to be created is 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Placement of New Replicas</head><p>To meet the system task successful execution rate and bandwidth consumption requirement, different tiers of data centers which have the selected replica data file f i will decide the replica placement and the placement of new replicas to be created according to the access information of directly connected data centers. The number of new replicas created at the directly connected data center dc k is calculated according to (21), based on the total number of new replicas bn i (inc) and the replica factor RF i (dc k ).</p><formula xml:id="formula_63">bn i (dc k ) =                        bn i (inc) - ¬ max(RF i(dck )) RF i (dc k ) RF i × bn i (inc) , if RF i (dc k ) is max(RF i (dc k )), RF i (dc k ) RF i × bn i (inc) , otherwise,<label>(21)</label></formula><p>where bn i (dc k ) is the number of new replicas to be created at the directly connected data center dc k , RF i (dc k ) is the replica factor of data file f i of the data center dc k directly connected, and RF i is the replica factor of the data file f i .</p><p>For the scenario given in Fig. <ref type="figure" target="#fig_10">6</ref>, assume the data file d has 2 replicas at a main data center and an ordinary data center, respectively, and 3 replicas need to be created. The detailed replica factor parameter setup is shown in Fig. <ref type="figure" target="#fig_10">6</ref>.  The main data center will create 1 replica at the dc1 directly connected to the data center, and the ordinary data center will create 2 replicas to the link dc6 directly connected to the data center.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">D2RS Algorithm</head><p>According to the above analysis, the replication decision is based on the theory of temporal locality. A popular data file is determined by the analysis of the access information to the data from users. When the popularity of a data file passes a dynamic threshold, the replication operation will be triggered. The number of replicas depends on the reasonable increase of file availability; the replica placement is determined by the access information of directly connected data centers and is accomplished in a balanced way. The core part of the D2RS algorithm is described as follows. The input of D2RM algorithm are the available probability p(ba k ) and unavailable probability p(ba k ) of all replicas of block b k of the data file f i , the number of replicas bn i , block size bs i and number of accesses an k (t i , t i+1 ) within time interval t i to t i+1 for each block in the data file f i , and the output is the system byte effective rate R(SBER). Steps 5∼14 calculate the replica factor and determine which data file should be replicated and when to replicate in a cloud system to meet the users' requirements, such as waiting time reduction and data access speeding up. Steps 15∼21 calculate the number of new replicas bn i (new ) and determine how many suitable new replicas bn i (inc) should be created in the cloud system to meet a given availability requirement. Steps 22∼31 calculate the number of new replicas bn i (dc k ) to be created at the directly connected data center dc k and decide where the new replicas should be placed to meet the system task successful execution rate and bandwidth consumption requirement.</p><p>Step 32 calculates the new system byte effective rate R(SBER). The time complexity of the D2RS algorithm is O(L × N ), in which L is the number of data files, and N is the maximum number of directly connected data centers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Simulation and Performance Evaluation</head><p>In order to evaluate the performance of the proposed D2RS algorithm, simulation environment and parameter setup are discussed in this section, followed by the precise performance evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Simulation Environment and Parameter Setup</head><p>CloudSim toolkit <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref> is used as the simulation environment. As a Java based simulation platform, it supports modeling and simulation of large scale cloud computing data centers. Special users and resources can be generated by rewriting the corresponding codes, which aligns well with various users and resources of the cloud system. It is feasible to simulate the proposed D2RS algorithm with CloudSim.</p><p>32 data centers are created in the simulation environment. The corresponding topology is shown in Fig. <ref type="figure" target="#fig_1">2</ref> and detailed configuration is shown in Table <ref type="table" target="#tab_6">6</ref>. 570 virtual machines are set as the service providers, and the processing elements (PEs) number of each virtual machine is within the range of 2 to 4. Forty different data files are placed in the cloud storage environment, with each size in the range of [0.1, 10] GB. Each file is stored in fixed size (bs = 0.2 GB) storage unit called block. Blocks of the same data file are scattered across different virtual machines. At the very beginning, the number of replicas of each data file is 1 and placed randomly. For simplicity, it is assumed that the basis element of data storage is block and the element of replication is one total data file.</p><p>One thousand tasks are submitted to the 570 virtual machines, each task is submitted according to Poisson distribution after the previous task and asks for 1 or 2 data files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Evaluation</head><p>The experiments set up four evaluation parameters: system byte effective rate, number of replicas, response time and successful execution rate.</p><p>1) System Byte Effective Rate. System byte effective rate reflects the byte availability of cloud systems under given constraints. It can be obtained by (10).</p><p>As shown in Fig. <ref type="figure">7</ref>, as the number of replicas increasing, the D2RS algorithm ensures the system byte effective rate at a high level. When the average block availability is more than 0.8, and the number of replicas is 4, the system byte effective rate is close to 1, even when the average block availability is less than 0.2. To keep the system byte effective rate close to 1, the number of replicas should be no more than 30. It can be seen that the D2RS algorithm is able to significantly improve the system byte effective rate.</p><p>In Fig. <ref type="figure">8</ref>, while the block availability is fixed at 0.8 and 0.9 and the number of replicas increases from 1 to 5, for the system byte effective rate, the gap between the experimental results of D2RS algorithm and the theoretical analysis results are dramatically narrowed. We assume all tasks can be completed within the deadline  at the first time submission according to theoretical analysis.</p><p>2) Number of Replicas. To maintain system byte effective rate at a high level, a reasonable number of replicas of data files is needed, which can be obtained by (20). To evaluate the convergence of D2RS algorithm, the block availability is fixed at 0.8, and different values of adjustable parameter α are chosen to compute the needed number of replicas.</p><p>As shown in Fig. <ref type="figure" target="#fig_12">9</ref>, with time elapses, the number of replicas is increasing within a very short period of time. Then this number of replicas is maintained at a relatively stable level, which is determined by the adjustable parameter α. We conclude that the greater the adjustable parameter α, the more replicas are needed to maintain the requested system byte effective rate. This proves the D2RS algorithm has a good convergence rate.</p><p>3) Response Time. The response time for a data file is the interval between the submission time of the task and return time of the result. The average response time of a system is the mean value of the response time for all data request tasks of the users, which can be obtained by (22).</p><formula xml:id="formula_64">rt avg = m j=1 mj k=1 (ts j k (rt) -ts j k (st)) m j=1 m j , (<label>22</label></formula><formula xml:id="formula_65">)</formula><p>where ts j k (st) and ts j k (rt) are the submission time and the return time of the result of task k of the user j, respectively, and m j is the number of the tasks of user j. When D2RS algorithm is not used, we set the number of replicas of large-scale data file fixed as 2 and the total number of copies of a data file is 3. As shown in Fig. <ref type="figure" target="#fig_13">10</ref>, with the number of tasks increasing, the response time increases dramatically, especially when the number of tasks is more than 70%. The less the block availability is, the longer the response time will be. A conclusion can be made that the D2RS algorithm improves the response time and maintains the response time at a stable level within a short period of time. 4) Successful Execution Rate. The successfully executed task is a task which is completely accomplished before its deadline dl at the first submission, where the deadline dl of a task can be obtained by (23).</p><formula xml:id="formula_66">dl j k = ts j k (st) + µ j k × rt avg + len j k pb avg , (<label>23</label></formula><formula xml:id="formula_67">)</formula><p>where ts j k (st) is the submission time of task k of user j, rt avg is the average response time of a system, µ j k is the network status based adjustable parameter and is usually set to 0.4, len j k is the length of task k of user j, and pb avg is the average processing ability.</p><p>The successful execution rate can be obtained by (24). </p><p>When D2RS algorithm is not used, we set the number of replicas of large-scale data file fixed as 2 and the total number of copies of a data file is 3. As shown in Fig. <ref type="figure" target="#fig_15">11</ref>, with the number of tasks increasing, the successful execution rate decreases dramatically, especially when the number of tasks is more than 50%. The less the block availability is, the less the successful execution rate will be. When the D2RS algorithm is used in the cloud, the successful execution rate can be maintained at a high level (more than 92%). A conclusion can be made that the D2RS algorithm improves the successful execution rate and maintains the successful execution rate at a high and stable level. From the above experimental results, the following conclusions can be drawn that 1) the proposed dynamic data replication strategy effectively increases data availability and reduces user waiting time by very small number of replicas; 2) the proposed dynamic data replication strategy improves the system task successful execution rate, minimizes cloud system bandwidth consumption and reduces bandwidth consumption by placing the popular data files closer to the users; 3) the proposed dynamic data replication strategy effectively achieves system load balance by placing the popular data files according to the access history and the theory of temporal locality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>High availability, high fault tolerance and high efficiency accesses to Internet based cloud data centers where failures are normal rather than exceptional are significant issues, and are often considered more valuable than high performance. Data replication allows reducing user waiting time and speeding up data access. It increases data availability by providing users with different replicas of the same service, and all of them in a coherent state. This paper presents a novel dynamic data replication strategy. It strives to increase data availability, improve cloud system task successful execution rate and minimize cloud system bandwidth consumption. Our contributions can be summarized as follows. 1) A mathematical model is formulated to describe the relationship between system availability and the number of replicas, which is missing in most existing research. 2) The popular data is identified, and corresponding replication operation will be triggered when the popularity of a data file passes a dynamic threshold. 3) Replicas are placed among data nodes in a balanced way. 4) A dynamic data replication strategy is proposed and evaluated. Experimental results demonstrate the efficiency of the improved system brought by the proposed strategy in a cloud.</p><p>There are still some studies to be done in the future. For instance, further reducing the user waiting time, speeding up data access, and further increasing data availability. In addition, the replication strategy will be deployed and tested on a real cloud computing platform. It is also planned to make data replication strategy as a part of cloud computing services to satisfy the special demands of cloud computing, and finally, to develop a complete dynamic data replication framework based on the proposed model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. GFS architecture.</figDesc><graphic coords="3,323.83,412.76,222.12,153.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Multi-tier hierarchical cloud system topology.</figDesc><graphic coords="4,318.83,526.10,232.44,211.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Cloud data server architecture.</figDesc><graphic coords="5,56.38,279.43,240.96,269.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>bs h × 1 -</head><label>1</label><figDesc>FA i ) × FS i ) (1 -p(ba i )) bni ni fn</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. Cloud data server instance.</figDesc><graphic coords="8,317.33,161.34,235.32,217.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. Time-based forgetting function.</figDesc><graphic coords="9,71.38,464.73,211.20,163.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>RF a = (1.388794e-011 × 96 + 1.125352e-007 × 89+ 1.234098e-004 × 902 + 1.831564e-002 × 883 + 3.678794e-001 × 1087 + 1.000000e-000 × 1279)/(3 × (64 + 64 + 53)) = 3.121 858.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>b = (1.125352e-007 × 523 + 1.234098e-004 × 678 + 1.831564e-002 × 2365 + 3.678794e-001 × 1987 + 1.000000e-000 × 3645)/(3 × (64 + 58)) = 9.342 559.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>c = (1.831564e-002 × 1035 + 3.678794e-001 × 1256 + 1.000000e-000 × 898)/(3 × 39) = 11.786 438. RF sys = (1.388794e -011 × 96 + 1.125352e-007 × 89 + 1.234098e-004 × 902 + 1.831564e-002 × 883 + 3.678794e-001 × 1087 + 1.000000e-000 × 1279 + 1.125352e-007 × 523 + 1.234098e-004 × 678 + 1.831564e-002 × 2365 + 3.678794e-001 × 1987 + 1.000000e-000 × 3645 + 1.831564e-002 × 1035 + 3.678794e-001 × 1256 + 1.000000e-000 × 898)/(3 × (64 + 64 + 53) + 3 × (64 + 58) + 3 × 39) = 6.329 005.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>bn d (dc 1 ) = (3.256 398/(3.256 398 + 0.125 999 8 + 5.960 163)) × 3 = 1; bn d (dc 2 ) = 0; bn d (dc 3 ) = 0; bn d (dc 4 ) = (0.125 999 8/(3.256 398 + 0.125 999 8 + 5.960 163)) × 3 = 0; bn d (dc 5 ) = 0; bn d (dc 6 ) = (5.960 163/(3.256 398 + 0.125 999 8 + 5.960 163)) × 3 = 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Replica placement instance.</figDesc><graphic coords="12,98.88,525.48,155.52,103.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig.7. System byte effective rate with different number of replicas.</figDesc><graphic coords="14,73.38,301.36,206.88,163.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Number of replicas with different parameter α.</figDesc><graphic coords="14,330.83,97.81,207.84,160.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Response time comparison.</figDesc><graphic coords="14,328.83,575.18,212.16,162.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>t j is success to r k , 0, otherwise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. Successful execution rate comparison.</figDesc><graphic coords="15,74.38,549.78,205.44,162.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1． ．</head><label>1．</label><figDesc>．Parameter Setup of R(SBER)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Data File</cell><cell></cell><cell></cell></row><row><cell>Parameter</cell><cell></cell><cell>a</cell><cell></cell><cell>b</cell><cell></cell><cell>c</cell></row><row><cell></cell><cell>a 1</cell><cell>a 2</cell><cell>a 3</cell><cell>b 1</cell><cell>b 2</cell><cell>c 1</cell></row><row><cell>n i</cell><cell>3.00</cell><cell>3.00</cell><cell>3.00</cell><cell>2.00</cell><cell>2.00</cell><cell>1.00</cell></row><row><cell>an i</cell><cell>4.00</cell><cell>4.00</cell><cell>4.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>bn i</cell><cell>3.00</cell><cell>3.00</cell><cell>3.00</cell><cell>3.00</cell><cell>3.00</cell><cell>3.00</cell></row><row><cell>bs i</cell><cell cols="3">64.00 64.00 53.00</cell><cell cols="2">64.00 58.00</cell><cell>39.00</cell></row><row><cell>p(ba i )</cell><cell>0.89</cell><cell>0.89</cell><cell>0.89</cell><cell>0.55</cell><cell>0.55</cell><cell>0.62</cell></row><row><cell cols="7">R(SBER) = ((4 × (64 + 64 + 53) × 0.999976 + 1 ×</cell></row><row><cell cols="7">(64 + 58) × 0.709867 + 1 × 39 × 0.945128)/(4 × (64 +</cell></row><row><cell cols="6">64 + 53) + 1 × (64 + 58) + 1 × 39) = 0.957567.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Parameter for PD about File a</figDesc><table><row><cell>k</cell><cell>ts</cell><cell>tp</cell><cell>∆t</cell><cell>ω(tp, ts)</cell><cell>an k (t i , t i+1 )</cell></row><row><cell>2</cell><cell>0.0</cell><cell>5.0</cell><cell>5.0</cell><cell>1.388794e-011</cell><cell>96</cell></row><row><cell>2</cell><cell>1.0</cell><cell>5.0</cell><cell>4.0</cell><cell>1.125352e-007</cell><cell>89</cell></row><row><cell>2</cell><cell>2.0</cell><cell>5.0</cell><cell>3.0</cell><cell>1.234098e-004</cell><cell>902</cell></row><row><cell>2</cell><cell>3.0</cell><cell>5.0</cell><cell>2.0</cell><cell>1.831564e-002</cell><cell>883</cell></row><row><cell>2</cell><cell>4.0</cell><cell>5.0</cell><cell>1.0</cell><cell>3.678794e-001</cell><cell>1 087</cell></row><row><cell>2</cell><cell>5.0</cell><cell>5.0</cell><cell>0.0</cell><cell>1.000000e-000</cell><cell>1 279</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Parameter for PD about File b</figDesc><table><row><cell>k</cell><cell>ts</cell><cell>tp</cell><cell>∆t</cell><cell>ω(tp, ts)</cell><cell>an k (t i , t i+1 )</cell></row><row><cell>2</cell><cell>1.0</cell><cell>5.0</cell><cell>4.0</cell><cell>1.125352e-007</cell><cell>523</cell></row><row><cell>2</cell><cell>2.0</cell><cell>5.0</cell><cell>3.0</cell><cell>1.234098e-004</cell><cell>678</cell></row><row><cell>2</cell><cell>3.0</cell><cell>5.0</cell><cell>2.0</cell><cell>1.831564e-002</cell><cell>2 365</cell></row><row><cell>2</cell><cell>4.0</cell><cell>5.0</cell><cell>1.0</cell><cell>3.678794e-001</cell><cell>1 987</cell></row><row><cell>2</cell><cell>5.0</cell><cell>5.0</cell><cell>0.0</cell><cell>1.000000e-000</cell><cell>2 645</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Parameter for PD about File c</figDesc><table><row><cell>k</cell><cell>ts</cell><cell>tp</cell><cell>∆t</cell><cell>ω(tp, ts)</cell><cell>an k (t i , t i+1 )</cell></row><row><cell>2</cell><cell>3.0</cell><cell>5.0</cell><cell>2.0</cell><cell>1.831564e-002</cell><cell>1 035</cell></row><row><cell>2</cell><cell>4.0</cell><cell>5.0</cell><cell>1.0</cell><cell>3.678794e-001</cell><cell>1 256</cell></row><row><cell>2</cell><cell>5.0</cell><cell>5.0</cell><cell>0.0</cell><cell>1.000000e-000</cell><cell>898</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Parameter for bn i</figDesc><table><row><cell>Parameter</cell><cell>b</cell><cell>Data File</cell><cell>c</cell></row><row><cell>P old (FA i )</cell><cell>0.826 054</cell><cell cols="2">0.978 048</cell></row><row><cell>p(ba i )</cell><cell>0.46</cell><cell cols="2">0.62</cell></row><row><cell>RF i</cell><cell>9.342 559</cell><cell cols="2">11.786 438</cell></row><row><cell>n i</cell><cell>2</cell><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>1</head><label></label><figDesc>Algorithm. D2RS Algorithm 2 Input: the available probability p(ba k ) and unavailable probability p(ba k ) of all replicas of block b k of the data file fi, the number of replicas bni, the block size bsi and the number of accesses an k (ti, ti+1) within time interval ti to ti+1 for each block of data file fi. 3 Output: system byte effective rate R(SBER). 4 Initialize available and unavailable probability of each replica of block b k p(ba k ) and p(ba k ). 5 for each data file fi at all data centers DC do 6 Calculate the popularity degree pd k of a block b k of data file fi by (13). 7 Calculate replica factor RF i of data file fi by (15). 8 end for 9 Calculate replica factor RF sys of the cloud system by (16). 10 for each data file fi at all data centers DC do 11 if RF space of the target data center DC obj is not enough then Quick sort all data file in descending order by replica factor of data file at data center DC obj .</figDesc><table><row><cell>RF k The replication operation of the data file fi will then be triggered. end if 14 end for 12 13 15 for each data file fi at all data centers DC do 16 Calculate the old file availability P (FAi) of data file fi by (8). 17 end for 18 for each triggered data file do 19 Calculate the new file availability Pnew (FAi) of data file fi by (18). 20 Calculate the number of new replicas needed bni(inc) by (20). 21 end for 22 for each triggered data file and bni(inc) &gt; 0 do 23 for each directly connected data center dc k do 24 Calculate the number of new replicas bni(dc k ) to be created at the directly connected data cen-ter dc k by (21). 25 end for 26 Determine the replica placement according to bni(dc k ). 27 if the storage 29 Delete the data file with the smallest replica factor. 30 end if 31 end for 32 Calculate the new system byte effective rate R(SBER) by (10). 33 Return R(SBER).</cell></row></table><note><p><p><p>i &gt; min (1 + α) × RF sys , max ∀</p>k∈</p>[1,2,...,l]   </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Configuration of Data Centers</figDesc><table><row><cell>Data Center ID</cell><cell>Machine Number</cell><cell>PE per Machine</cell><cell>Processing Ability (MIPS)</cell><cell>Bandwidth</cell></row><row><cell>Super Data Center 0∼2</cell><cell>20</cell><cell>8∼16</cell><cell>400∼800</cell><cell>10.0 Gbps</cell></row><row><cell>Main Data Center 3∼11</cell><cell>10</cell><cell>4∼8</cell><cell>200∼400</cell><cell>1.0 Gbps</cell></row><row><cell>Ordinary Data Center 12∼38</cell><cell>5</cell><cell>1∼4</cell><cell>100∼200</cell><cell>0.1 Gbps</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement The authors gratefully thank Jun-Ling Hu for her help and comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Supported by the National Natural Science Foundation of China under Grant Nos. 61070162, 71071028 and 70931001, the Specialized Research Fund for the Doctoral Program of Higher Education of China under Grant Nos. 20110042110024 and 20100042110025, the Fundamental Research Funds for the Central Universities of China under Grant Nos. N100604012, N090504003 and N090504006.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cloud computing and grid computing 360-degree compared</title>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Raicu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Grid Computing Environments Workshop</title>
		<meeting>Grid Computing Environments Workshop<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-12-16">Nov. 12-16, 2008</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cloud computing and emerging IT platforms: Vision, hype, and reality for delivering computing as the 5th utility</title>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C S</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venugopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Broberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Brandic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="599" to="616" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A view of cloud computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Armbrust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The NIST definition of cloud computing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance analysis of cloud computing services for many-tasks scientific computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iosup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ostermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yigitbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prodan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D H J</forename><surname>Epema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="931" to="945" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A cloud-based BPM architecture with user-end distribution of non-computeintensive activities and sensitive data</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1157" to="1167" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Privacy-preserving data sharing in cloud computing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="401" to="414" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic interoperability aggregation in service requirements refinement</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1103" to="1117" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Job scheduling algorithm based on Berger model in cloud environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="419" to="425" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Google file system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gobioff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Hadoop distributed file system</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shvachko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hairong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Radia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chansler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 26th Symposium on Mass Storage Systems and Technologies</title>
		<meeting>the 26th Symposium on Mass Storage Systems and Technologies<address><addrLine>Incline Village, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">May 3-7, 2010</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Achieving efficient agreement within a dual-failure cloud-computing environment</title>
		<author>
			<persName><forename type="first">S S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert System with Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="906" to="915" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A dynamic data replication strategy using access-weights in data grids</title>
		<author>
			<persName><forename type="first">R S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Supercomputing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="295" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Energy-aware real-time task scheduling exploiting temporal locality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Transactions on Information and Systems</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1147" to="1153" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CDRM: A cost-effective dynamic replication management scheme for cloud storage cluster</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Veeravalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2010 IEEE International Conference on Cluster Computing</title>
		<meeting>2010 IEEE International Conference on Cluster Computing<address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">Sept. 20-24, 2010</date>
			<biblScope unit="page" from="188" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A self-organized, fault-tolerant and scalable replication scheme for cloud storage</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bonvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Papaioannou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aberer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st ACM Symposium on Cloud Computing</title>
		<meeting>the 1st ACM Symposium on Cloud Computing<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">June 10-11, 2010</date>
			<biblScope unit="page" from="205" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differentiated replication strategy in data centers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cutway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IFIP International Conference on Network and Parallel Computing</title>
		<meeting>the IFIP International Conference on Network and Parallel Computing<address><addrLine>Zhengzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">Sept. 13-15, 2010</date>
			<biblScope unit="page" from="277" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evolution on fast-forward</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mckusick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quinlan</forename><forename type="middle">S</forename><surname>Gfs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="42" to="47" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Lowest data replication storage of binary vote assignment data grid</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A A C</forename><surname>Fauzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Sidek R M, Zin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Conference Networked Digital Technologies</title>
		<meeting>the 2nd International Conference Networked Digital Technologies<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">July 7-9, 2010</date>
			<biblScope unit="page" from="466" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Replica placement design with static optimality and dynamic maintainability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alhajj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 6th IEEE International Symposium on Cluster Computing and the Grid</title>
		<meeting>the 6th IEEE International Symposium on Cluster Computing and the Grid<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">May 16-19, 2006</date>
			<biblScope unit="page" from="434" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A study on performance of dynamic file replication algorithms for real-time file access in data grids</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="829" to="839" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An on-line replication strategy to increase availability in data grids</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Vrbsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="98" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Efficient task replication and management for adaptive fault tolerance in mobile grid environments. Future Generation Computer Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Litke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Skoutas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tserpes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Varvarigou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="163" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dynamic load balancing and job replication in a global-scale grid environment: A comparison</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dobber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Der Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Koole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A data placement strategy in scientific cloud workflows</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1200" to="1214" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Grid resource availability predictionbased scheduling and task replication</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Grid Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="479" to="500" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Quorum-based data replication in grid environment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Latip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Othman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Sulaiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Intelligence Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="386" to="397" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Basic concepts and taxonomy of dependable and secure computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avizienis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Laprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B R</forename><surname>Randell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Landwehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Dependable and Secure Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="33" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A comparative analysis of network dependability, fault-tolerance, reliability, security, and survivability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Kuwaiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kyriakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hussein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="106" to="124" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An interoperable context sensitive model of trust</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="104" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Secure data objects replication in data grid</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I L</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Thuraisingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Dependable and Secure Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="64" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A near-optimal database allocation for reducing the average waiting time in the grid computing environment</title>
		<author>
			<persName><forename type="first">J Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Jea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="3772" to="3790" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An effective job replication technique based on reliability and performance in mobile grids</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S H</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">InProc. the 5th International Conference Advances in Grid and Pervasive Computing</title>
		<meeting><address><addrLine>Hualien, Taiwan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">May 10-13, 2010</date>
			<biblScope unit="page" from="47" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Modeling and simulation of scalable cloud computing environments and the CloudSim toolkit: Challenges and opportunities</title>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2009 International Conference on High Performance Computing &amp; Simulation</title>
		<meeting>2009 International Conference on High Performance Computing &amp; Simulation<address><addrLine>Leipzig, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">June 21-24, 2009</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Approaches to improve the resources management in the simulator CloudSim</title>
		<author>
			<persName><forename type="first">G</forename><surname>Belalem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Z</forename><surname>Tayeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st International Conference Information Computing and Applications</title>
		<meeting>the 1st International Conference Information Computing and Applications<address><addrLine>Tangshan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">Oct. 15-18, 2010</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">CloudSim: A toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Calheiros R N, Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beloglazov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C A F</forename><surname>Buyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software-Practice &amp; Experience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="50" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
