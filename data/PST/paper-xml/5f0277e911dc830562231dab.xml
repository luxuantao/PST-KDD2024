<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dugang</forename><surname>Liu</surname></persName>
							<email>dugang.ldg@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Pengxiang</forename><surname>Cheng</surname></persName>
							<email>chengpengxiang1@huawei.com</email>
						</author>
						<author>
							<persName><forename type="first">Zhenhua</forename><surname>Dong</surname></persName>
							<email>dongzhenhua@huawei.com</email>
						</author>
						<author>
							<persName><forename type="first">Weike</forename><surname>Pan</surname></persName>
							<email>panweike@szu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Zhong</forename><surname>Ming</surname></persName>
							<email>mingz@szu.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Shenzhen University Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Shenzhen University Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Shenzhen University Shenzhen</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3397271.3401083</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T14:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Counterfactual learning</term>
					<term>Recommender systems</term>
					<term>Knowledge distillation</term>
					<term>Uniform data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommender systems are feedback loop systems, which often face bias problems such as popularity bias, previous model bias and position bias. In this paper, we focus on solving the bias problems in a recommender system via a uniform data. Through empirical studies in online and offline settings, we observe that simple modeling with a uniform data can alleviate the bias problems and improve the performance. However, the uniform data is always few and expensive to collect in a real product. In order to use the valuable uniform data more effectively, we propose a general knowledge distillation framework for counterfactual recommendation that enables uniform data modeling through four approaches: (1) label-based distillation focuses on using the imputed labels as a carrier to provide useful de-biasing guidance; (2) feature-based distillation aims to filter out the representative causal and stable features; (3) sample-based distillation considers mutual learning and alignment of the information of the uniform and non-uniform data; and (4) model structurebased distillation constrains the training of the models from the perspective of embedded representation. We conduct extensive experiments on both public and product datasets, demonstrating that the proposed four methods achieve better performance over the baseline models in terms of AUC and NLL. Moreover, we discuss the relation between the proposed methods and the previous works. We emphasize that counterfactual modeling with uniform data is a rich research area, and list some interesting and promising research topics worthy of further exploration. Note that the source codes are available at https://github.com/dgliu/SIGIR20_KDCRec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Recommender systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommender Systems as a feedback loop system may suffer from the bias problems such as popularity bias <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref>, previous model bias <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> and position bias <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28]</ref>. Previous studies have shown that models and evaluation metrics that ignore the biases do not reflect the true performance of a recommender system, and that explicitly handling of the biases may help improve the performance <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31]</ref>. Most of the previous works to solve the bias problems of recommender systems can be classified as counterfactual learning-based <ref type="bibr" target="#b24">[25]</ref> and heuristic-based approaches. The former mainly uses the inverse propensity score (IPS) <ref type="bibr" target="#b23">[24]</ref> and the counterfactual risk minimization (CRM) principle <ref type="bibr" target="#b24">[25]</ref>, while the latter mainly makes certain assumptions about the data being missing not at random (MNAR) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>A recent work has shown that a uniform data can alleviate the previous model bias problem <ref type="bibr" target="#b15">[16]</ref>. But the uniform data is always few and expensive to collect in real recommender systems. To collect a uniform data, we must intervene in the system by using a uniform logging policy instead of a stochastic recommendation policy, this is, for each user's request, we do not use the recommendation model for item delivery, but instead randomly select some items from all the candidate items and rank them with a uniform distribution. The uniform data can then be regarded as a good unbiased agent because it is not affected by a previously deployed recommendation model. However, the uniform logging policy would hurt the users' experiences and the revenue of the platform. This means that it is necessary to constrain the uniform data collection within a particularly small traffic (e.g., 1%).</p><p>In this paper, we focus on how to solve the bias problems in a recommender system with a uniform data. Along the line of <ref type="bibr" target="#b15">[16]</ref>, we conduct empirical studies on a real advertising system and a public dataset to validate the usefulness of the uniform data, where the uniform data is simply combined with the non-uniform data for training models. We observe that such a simple method can alleviate the bias and improve the performance, which motivates us to study more advanced methods that can make better use of the uniform data. Although there are many ways to extract information or knowledge from a uniform data, in this paper we focus on knowledge distillation because of its simplicity and flexibility.</p><p>To use the few and valuable uniform data more effectively, we propose a general knowledge distillation framework for counterfactual recommendation (KDCRec), which enables uniform data modeling with four approaches, i.e., label-based distillation, featurebased distillation, sample-based distillation and model structurebased distillation. Each one is based on a different concern, i.e., label-based distillation focuses on using the imputed labels as a carrier to provide useful de-biasing guidance; feature-based distillation aims to filter out the representative unbiased features; sample-based distillation considers mutual learning and alignment of the information of the uniform and non-uniform data; and model structure-based distillation constrains the training of the models from the perspective of embedded representation.</p><p>The main contributions of this paper are summarized as follows:</p><p>• We show empirical evidence that a uniform data is useful for preference modeling via an online A/B test and an offline evaluation, which justifies the importance of our research questions.</p><p>• We propose a general knowledge distillation framework KD-CRec for counterfactual recommendation via a uniform data, including label-based distillation, feature-based distillation, sample-based distillation and model structure-based distillation.</p><p>• We conduct extensive experiments on both public and product datasets, demonstrating that the four proposed methods achieve better performance over the baseline models in terms of AUC and NLL. • We discuss the relation between the proposed methods and the previous works, and list some interesting and promising research directions for further exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Since we study how to apply knowledge distillation techniques for counterfactual recommendation, we first review some related works on general knowledge distillation. We also include some counterfactual learning methods for recommendation and ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Knowledge Distillation</head><p>Hinton's work first proposes the concept of knowledge distillation <ref type="bibr" target="#b9">[10]</ref>. By introducing soft-targets related to teacher networks as part of the objective function, the training of student networks is guided to achieve knowledge transfer <ref type="bibr" target="#b17">[18]</ref>. A series of followup works develop different distillation structures (e.g., multiple teachers <ref type="bibr" target="#b7">[8]</ref> and cascade distillations <ref type="bibr" target="#b3">[4]</ref>) and different forms of knowledge (e.g., alignment of the hidden layers <ref type="bibr" target="#b21">[22]</ref> or the relation between the hidden layers <ref type="bibr" target="#b31">[32]</ref>). Some recent works are no longer limited to model structure, but considers sample-based knowledge distillation <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">27]</ref>. In this paper, we further expand the definition of distillation to include label-based and feature-based forms. The marriage of knowledge distillation and recommender systems has also attracted the attention of the researchers <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34]</ref>. Most of these works focus on using knowledge distillation to extract some useful knowledge from some auxiliary models to enhance the performance or interpretability of the target recommendation model. In this paper, we focus on using knowledge distillation to solve the bias problems in recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Counterfactual Learning for Ranking</head><p>For learning-to-rank tasks, Agarwal et al. <ref type="bibr" target="#b1">[2]</ref> provides a general and theoretically rigorous framework with two counterfactual learning methods, i.e., SVM PropDCG and DeepPropDCG. Some position bias estimation methods for ranking are proposed in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28]</ref>. IPS is one of the most popular counterfactual approaches for recommendation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b30">31]</ref>, where each sample is weighted with an IPS, referring to the likelihood of the sample being logged. If there are no unobserved confounders, IPS methods can get an unbiased prediction model in theory. A direct method tries to learn an imputation model, which can infer the labels for both the observed and unobserved samples. The imputation model can be learned by machine learning models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref> with the observed data. A doubly robust method <ref type="bibr" target="#b6">[7]</ref> combines the IPS method and the aforementioned direct method together, and the bias can be eliminated if either the direct method part or the IPS method part is unbiased. Wang et al. <ref type="bibr" target="#b28">[29]</ref> proposes a doubly robust method for joint learning of rating prediction and error imputation. Moreover, a uniform data is useful for counterfactual learning, such as imputation model learning <ref type="bibr" target="#b32">[33]</ref>, propensity computation <ref type="bibr" target="#b23">[24]</ref> and modeling with uniform data directly <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23]</ref>. In this paper, we would like to study methods for better use of the uniform data from the perspective of knowledge distillation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>In a recent work <ref type="bibr" target="#b15">[16]</ref>, it is shown that a uniform (i.e., unbiased) data can alleviate the previous model bias problem. In this section, to further verify the usefulness of a uniform data, we firstly compare the online performance of two models in a real advertising system, where one model is trained with a biased data, and the other is trained with both a uniform data and a biased data. Next, we conduct some pilot experiments to quantify the effectiveness of an unbiased data using a public dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Performance on a Product Dataset</head><p>We conduct an online A/B test on a large-scale advertising system. In the system, there is 1% traffic for "uniform data collection": for these requests, we randomly collect some advertisements from all candidates, and rank them with uniform distribution. The 1% training data is isolated from being influenced by the previously deployed recommendation models, which is thus called 1%-unbiased data, the other 99% non-uniform traffic is named 99%-biased data, and all the 100% traffic is named 100%-combined data. Because logistic regression (LR) is one of the most popular models for CTR prediction, we implement two LR models with the 99%-biased data and the 100%-combined data, respectively. Next, we deploy the two models in the advertising system.</p><p>Experimental Setting. In our preliminary experiments, we collect training data from an online display advertising system for 30 days, and generate three kinds of data sets: 1%-unbiased data, 99%-biased data and 100%-combined data. We verify the two models' effectiveness through an online A/B test for 30 consecutive days. The ads requests have been split into two groups, each of which contains more than two million ads requests each day. One request group receives recommendations from one of the two models. The candidates ads are ranked by 𝑏𝑖𝑑 * 𝑝𝐶𝑇 𝑅, where the advertiser offers the bid, and our models compute the 𝑝𝐶𝑇 𝑅 values. We thus use the effective cost per mille (eCPM) as the online performance:</p><formula xml:id="formula_0">𝑒𝐶𝑃𝑀 = 𝑇𝑜𝑡𝑎𝑙 𝐴𝑑𝑠 𝐼𝑛𝑐𝑜𝑚𝑒 𝑇𝑜𝑡𝑎𝑙 𝐴𝑑𝑠 𝐼𝑚𝑝𝑟𝑒𝑠𝑠𝑖𝑜𝑛𝑠 × 1000. (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>For the offline experiment, we split the 30-day data sequentially, where the first 28 days for training, the last 2 days for validation and test. Following most CTR prediction studies, we consider the area under the roc curve (AUC) as the offline evaluation metric.</p><p>Experiment Results. The experimental results are shown in Table <ref type="table">1</ref>, from which we can see that the 100%-combined data model wins the other model by 1.56% (from 0.7571 to 0.7689) in terms of AUC. Although the income degrades when collecting the 1% randomized training data, the improvement from the uniform data is 2.98%, which is much higher than the loss. We also train a model with the 1%-unbiased data, but the simulated ads ranking lists do not look well, which is thus not deployed by the product team.</p><p>Table <ref type="table">1</ref>: Performance comparisons on a product dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data approach</head><p>Offline AUC Online eCPM 99%-biased data 0.7571 0.0% 100%-combined data 0.7689 2.98% (improvement)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Performance on a Public Dataset</head><p>We conduct some pilot experiments on the Yahoo! R3 dataset to validate the usefulness of the unbiased data. Yahoo! R3 contains some user-song ratings, where users were asked to rate a uniformly drawn sample of songs. After processing of the data, we split the public dataset into three training subsets, one validation set and one test set, i.e., uniform data, biased data, uniform data ∪ biased data, uniform validation data and uniform test data. We implement three matrix factorization (MF) models with the three training subsets, respectively, and adopt AUC and the negative logarithmic loss (NLL) as the evaluation metrics. It is worth mentioning that we choose the uniform test data as the test set to ensure the unbiasedness of the experiment. We observe a forward effect about the performance of the uniform data. As shown in Table <ref type="table" target="#tab_0">2</ref>, the uniform data model has the best NLL score, but its AUC score is not competitive. The model trained with the combination of the uniform data and the biased data performs better than the model trained only with the biased data, which means that the uniform data can help to improve the accuracy.</p><p>Through the experiments with the product dataset and the public dataset, we find that the uniform data can improve the recommendation performance by simply being combined with the biased data, which inspires us to study some more advanced methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED FRAMEWORK</head><p>In order to effectively make use of the uniform data, we propose a general Knowledge Distillation framework for Counterfactual Recommendation in this section, KDCRec for short. Figure <ref type="figure">1</ref> shows the overview of the framework of our KDCRec. In our framework, the uniform data can be modeled with four different methods, including label-based distillation, feature-based distillation, samplebased distillation, and model structure-based distillation. Note that we use a general definition of distillation in the study rather than the past knowledge distillation approaches such as considering the level of sample <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">27]</ref> and model structure <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref>. Each method is based on different concerns to mine the potentially useful knowledge from the uniform data, which will be used to improve the learning of the biased data. Next, we will introduce the four methods in turn as different modules. More specifically, in each module, we will give a formal definition of the corresponding method, and list some practical solutions under the guidance of the definition.</p><p>Figure <ref type="figure">1</ref>: Overview of the KDCRec framework. The scale of the biased set 𝑆 𝑐 is much larger than that of the unbiased set 𝑆 𝑡 . Since the unobserved data is only used in some modules, we distinguish it from 𝑆 𝑐 and 𝑆 𝑡 using a different color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Label-Based Module</head><p>Models trained on a non-uniform data 𝑆 𝑐 tend to produce biased predictions, while predictions from a uniform data 𝑆 𝑡 are more unbiased. An intuitive idea is that when training a model on 𝑆 𝑐 , the model receives the imputed labels produced by 𝑆 𝑡 to correct the bias of its own predictions. Based on this idea, we develop the following formal definition of label-based distillation. Note that on the premise of using the imputed labels, we can also include the labels of 𝑆 𝑡 . We emphasize the use of the imputed labels to avoid confusion with other distillation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (D1).</head><p>A method can be classified as label-based distillation if and only if the training of a non-uniform data 𝑆 𝑐 can benefit from the imputed labels produced by a uniform data 𝑆 𝑡 .</p><p>Solutions. Next, we use the two strategies adopted in our experiments as examples to illustrate how label-based distillation can be realized. </p><formula xml:id="formula_2">W 𝑐 ,W 𝑡 1 |𝑆 𝑐 | (𝑖,𝑗) ∈𝑆 𝑐 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 1 |𝑆 𝑡 | (𝑖,𝑗) ∈𝑆 𝑡 ℓ 𝑦 𝑖 𝑗 , ŷ𝑡 𝑖 𝑗 + 1 |𝑆 𝑎 | (𝑖,𝑗) ∈𝑆 𝑎 ℓ ŷ𝑐 𝑖 𝑗 , ŷ𝑡 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) + 𝜆 𝑡 𝑅 (W 𝑡 ) ,<label>(2)</label></formula><p>where W 𝑐 and W 𝑡 denote the parameters of 𝑀 𝑐 and 𝑀 𝑡 , respectively, and ℓ (•, •) is an arbitrary loss function. And 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 and ŷ𝑡 𝑖 𝑗 denote the true label, and the predicted labels of 𝑀 𝑐 and 𝑀 𝑡 for the sample (𝑖, 𝑗), respectively, where (𝑖, 𝑗) is associated with user 𝑖 and item 𝑗. Note that 𝑅 (•) is the regularization term, and 𝜆 𝑐 and 𝜆 𝑡 are the parameters of the regularization.</p><p>• Refine Strategy. We next consider a scenario where only one model 𝑀 𝑐 is trained. The bias of 𝑆 𝑐 may be reflected in the labels, resulting in models trained on these labels being biased. For example, when generating samples for modeling, all the observed positive feedback are usually labeled as 1, and all the observed negative feedback are labeled as -1. But in fact, they should fit a preference distribution. With 𝑆 𝑡 , we expect to be able to better infer the true distribution of the labels on 𝑆 𝑐 and then refine them. Suppose we have obtained a model 𝑀 𝑡 pre-trained on 𝑆 𝑡 , and then use it to predict all the samples on 𝑆 𝑐 . These imputed labels are combined with the original labels of 𝑆 𝑐 through a weighting parameter, which are then used to train a more unbiased model 𝑀 𝑐 . Note that in order to avoid the distribution difference between the imputed labels and the original labels, we need to normalize the imputed labels. The final objective function of this strategy is, min</p><formula xml:id="formula_3">W 𝑐 1 |𝑆 𝑐 | (𝑖,𝑗) ∈𝑆 𝑐 ℓ 𝑦 𝑖 𝑗 + 𝛼𝑁 ŷ𝑡 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) , (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where 𝛼 is a tunable parameter that controls the importance of the imputed labels produced by 𝑀 𝑡 , and 𝑁 (•) denotes a normalization function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature-Based Module</head><p>Previous studies find that some features correlate with labels, but the correlation is not a causal relation. For example, from 1999 to 2009, the correlation between "the number of people who drowned by falling into a pool" and "the number of films Nicolas Cage appeared in" is 66.6%. But as we know, if Nicolas Cage does not appear in any film in a year, the number of people who drown in a pool may still not be 0. Hence, we need to learn some causal and stable features. The feature-based module can be divided into two steps, i.e., stable feature selection and biased data correction. Firstly, we filter out causal and stable features via a uniform data through some methods. Then, we need to employ the stable features to train a teacher model that can be used to guide the biased model. Thus, we develop the following formal definition of feature-based distillation.</p><p>Definition 2 (D2). A method can be classified as feature-based distillation if and only if the training of a non-uniform data 𝑆 𝑐 can benefit from the representative causal and stable features produced by a uniform data 𝑆 𝑡 .</p><p>Solutions. We employ stable feature strategy as an example to reveal how feature-based distillation can be realized.</p><p>• Stable Feature Strategy. We propose a stable feature distillation module to filter out the causal features for correcting the bias from 𝑆 𝑐 . Figure <ref type="figure" target="#fig_1">2</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sample-Based Module</head><p>In a real recommender system with a stochastic logging policy, the probability of an item being recommended is different, and the probability of a user making a choice is also different. This means that model 𝑀 𝑐 may treat some items and users unfairly, because the samples in 𝑆 𝑐 lack support for these items and users. This unfairness can be corrected to some extent by directly considering the samples in 𝑆 𝑡 during the training process of 𝑀 𝑐 , as empirically shown in Section 3. Because the uniform logging policy corresponding to 𝑆 𝑡 increases the probability of the less popular items being selected, and 𝑀 𝑐 needs to weigh this difference between 𝑆 𝑐 and 𝑆 𝑡 . Based on this idea, we develop the following formal definition of samplebased distillation, Definition 3 (D3). A method can be classified as sample-based distillation if and only if a uniform data 𝑆 𝑡 is directly applied to help learning on all the samples without generating some imputed labels.</p><p>Solutions. Next, we use the three strategies adopted in our experiments as examples to illustrate how sample-based distillation can be realized.</p><p>• Causal Embedding Strategy (CausE). The causal embedding method <ref type="bibr" target="#b4">[5]</ref> first considers the scenario of training 𝑀 𝑐 and 𝑀 𝑡 simultaneously. It designs an additional alignment term to explicitly represent the learning of 𝑀 𝑐 for 𝑀 𝑡 . Causal embedding defines this alignment term as the pairwise difference between the parameters of 𝑀 𝑐 and 𝑀 𝑡 , which is then included in the object function to be minimized. When the value of the alignment term becomes small, it means that 𝑀 𝑐 learns the causal information contained in 𝑆 𝑡 , which helps correct the bias in learning on 𝑆 𝑐 . Note that it is difficult to dynamically optimize the differences between all the parameters of the two neural networks, so we only use two low-rank models to implement this strategy in our experiments. The final objective function is, min</p><formula xml:id="formula_5">W 𝑐 ,W 𝑡 1 |𝑆 𝑐 | (𝑖,𝑗) ∈𝑆 𝑐 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 1 |𝑆 𝑡 | (𝑖,𝑗) ∈𝑆 𝑡 ℓ 𝑦 𝑖 𝑗 , ŷ𝑡 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) + 𝜆 𝑡 𝑅 (W 𝑡 ) + 𝜆 𝐶𝑎𝑢𝑠𝐸 𝑡𝑐 ∥W 𝑡 − W 𝑐 ∥ 2 𝐹 ,<label>(4)</label></formula><p>where 𝜆 𝐶𝑎𝑢𝑠𝐸 𝑡𝑐 is the regularization parameter for the alignment term of 𝑀 𝑐 and 𝑀 𝑡 .</p><p>• Weighted Combination Strategy (WeightC). How to effectively introduce the samples from 𝑆 𝑡 to help 𝑀 𝑐 ? Inspired by modeling of heterogeneous implicit feedback <ref type="bibr" target="#b19">[20]</ref>, we add a confidence parameter to each sample of 𝑆 𝑐 and 𝑆 𝑡 to indicate whether it is unbiased. Naturally, the confidence of the samples in 𝑆 𝑡 is set to 1, and the confidence of the samples in 𝑆 𝑐 has two schemes to be used. The first scheme is a global setting, i.e., we set a confidence value in advance for all the samples of 𝑆 𝑐 . The second scheme is a local setting, i.e., each sample of 𝑆 𝑐 has a confidence value that needs to be learned by 𝑀 𝑐 . The confidence of each sample is related to the corresponding loss function. The final objective function of this strategy is, min</p><formula xml:id="formula_6">W 𝑐 1 |𝑆 𝑐 | (𝑖,𝑗) ∈𝑆 𝑐 𝛼 𝑖 𝑗 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 1 |𝑆 𝑡 | (𝑖,𝑗) ∈𝑆 𝑡 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) ,<label>(5)</label></formula><p>where 𝛼 𝑖 𝑗 ∈ [0, 1] is a parameter used to control the confidence that we believe the sample (𝑖, 𝑗) is unbiased. When considering the global setting, 𝛼 𝑖 𝑗 shares a parameter value that we preset for all the samples in 𝑆 𝑐 , but in the local setting, 𝛼 𝑖 𝑗 is an independent parameter value learned by 𝑀 𝑐 . • Delayed Combination Strategy (DelayC). Instead of introducing a confidence parameter, we propose a strategy called delayed combination. This strategy directly applies the data of 𝑆 𝑐 and 𝑆 𝑡 to the training of 𝑀 𝑐 in an alternative manner. Specifically, in the 𝑆 𝑐 step of each iteration, 𝑀 𝑐 is trained on the data of 𝑠 batches in 𝑆 𝑐 . In the 𝑆 𝑡 step, we randomly sample one batch of data from 𝑆 𝑡 to train 𝑀 𝑐 . We repeat these two steps until all the data of 𝑆 𝑐 are used. The batch ratio is set to 𝑠 : 1, which can better ensure the training of 𝑀 𝑐 itself and the correction under the guidance of 𝑆 𝑡 . The final objective function of this strategy is, </p><formula xml:id="formula_7">         min W 𝑐 1 |𝑆 𝑐 | (𝑖,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Model Structure-Based Module</head><p>Finally, we return to the model itself through considering how to directly use the pre-trained model 𝑀 𝑡 to help the learning of 𝑀 𝑐 . This is the most commonly adopted distillation strategy in existing works. In order to help 𝑀 𝑐 with the guidance from 𝑀 𝑡 , we assume that some embedded representations of 𝑀 𝑐 correspond to some embedded representations of 𝑀 𝑡 . We constrain the selected embedded representations in 𝑀 𝑐 to be similar to their corresponding embedded representations in 𝑀 𝑡 . As a result, 𝑀 𝑐 will have a similar pattern to 𝑀 𝑡 and thus may benefit from it. Note that the selected embedded representations of 𝑀 𝑐 and 𝑀 𝑡 do not necessarily have the same index. For example, suppose A is a 4-layer network and B is an 8-layer network, we may specify that each layer of A corresponds to an even layer of B, namely 2, 4, 6 and 8. Based on this idea, we develop the following formal definition of model structure-based distillation. For the sake of discussion, as shown in Figure <ref type="figure" target="#fig_2">3</ref>, we classify all the embedded representations into three types with different functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4 (D4).</head><p>A method can be classified as model structurebased distillation if and only if instead of using the labels and data, the embedded representation trained on a uniform data 𝑆 𝑡 is used to help the learning of a non-uniform data 𝑆 𝑐 .</p><p>Solutions. Next, we use the three strategies adopted in our experiments as examples to illustrate how model structure-based distillation can be realized. • Feature Embedding Strategy (FeatE). Feature embedding are embedded representations that are directly connected to the users and items. In a neural network, it is usually the result of a one-hot coding after a lookup operation; and in a low-rank model, it is the users' preference vector 𝑢 and the items' attribute vector 𝑣.</p><p>As a special example, we think that the feature embedding of the autoencoder refers to the weights related to the number of items in the first layer and the last layer of the network. It may be unreasonable to directly match the feature embedding in 𝑀 𝑐 with the that in 𝑀 𝑡 , because 𝑀 𝑡 may not learn sufficiently on these user-and item-related embedded representations due to the small data size. We propose the following two alternatives to use the feature embedding in 𝑀 𝑡 , including initialization of 𝑀 𝑐 , and concatenation with the parameters of 𝑀 𝑐 , Initialization. We have three options to choose the type of feature embedding as the initialization of 𝑀 𝑐 , including using only user-related, only item-related, and both. In addition, if we know which of the user-related and item-related ones is trained better, we can further use the information from 𝑀 𝑡 by setting their update steps to 1 (for the better one) and 𝑠 (for the other, &gt; 1), respectively. We call it the FeatE-alter.</p><p>Concatenation. After the parameters of 𝑀 𝑐 are randomly initialized, the feature embedding of 𝑀 𝑡 will be concatenated with these parameters to form new parameters to train 𝑀 𝑐 . Note that the features embedded of 𝑀 𝑡 in the parameters will not be updated during the training process. • Hint Strategy. Hint refers to the hidden layer in a neural network, also known as feature map <ref type="bibr" target="#b21">[22]</ref>. They contain higher-order non-linear relations between users or items. Note that in the experiments we must use deep neural networks to implement this strategy. After we specify hint for alignment in 𝑀 𝑐 and 𝑀 𝑡 , we explicitly model the difference between the two hints on the objective function of 𝑀 𝑐 . The final objective function of this strategy is, min</p><formula xml:id="formula_8">W 𝑐 1 |𝑆 𝑐 | (𝑖,𝑗) ∈𝑆 𝑐 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) + 𝜆 ℎ𝑖𝑛𝑡 𝑡𝑐 𝑦 ℎ𝑖𝑛𝑡 𝑡 − 𝑦 ℎ𝑖𝑛𝑡 𝑐 2 𝐹 ,<label>(7)</label></formula><p>where 𝑦 ℎ𝑖𝑛𝑡 𝑐 and 𝑦 ℎ𝑖𝑛𝑡 𝑡 are the output of 𝑀 𝑐 and 𝑀 𝑡 on their respective designated hint layers.</p><p>• Soft Label Strategy. Previous works have shown that training the student network to mimic the output of the teacher network on hard-labeled objectives does not bring much useful information to the student network. But, by introducing softmax and temperature operations to relax the label, training the student network to keep the same output as the teacher network on a soft label will result in a significant improvement <ref type="bibr" target="#b9">[10]</ref>. We follow a similar setup in this strategy. Note that in the experiments we must also use deep neural networks to implement this strategy. The final objective function of this strategy is, min</p><formula xml:id="formula_9">W 𝑐 𝛼 |D | (𝑖,𝑗) ∈ D ℓ softmax ŷ𝑐 𝑖 𝑗 𝜏 , softmax ŷ𝑡 𝑖 𝑗 𝜏 + 1 |𝑆 𝑐 | (𝑖,𝑗) ∈𝑆 𝑐 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) ,<label>(8)</label></formula><p>where 𝜏 a is a temperature parameter, and 𝛼 is a tunable parameter that controls the importance of the soft labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Summary and Remarks</head><p>Based on the above description, we can see that different strategies exhibit their own characteristics about how to make use of 𝑆 𝑡 . Some methods commonly used in counterfactual recommendation can be incorporated into our framework. Label-based distillation includes a direct method for learning an imputation model and its variants. Sample-based distillation includes the IPS method <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b30">31]</ref> and other approaches as described in Section 2.2. Although we introduce the four distillation methods in different modules, their relations are close. This means that we can design new strategies with different combinations of the four distillation methods, such as the doubly robust method <ref type="bibr" target="#b6">[7]</ref> and its variants <ref type="bibr" target="#b32">[33]</ref>. Moreover, they are also related to the types of knowledge (instance, feature and model) and strategies (adaptive, collective and integrative) in transfer learning <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>In addition, we must keep in mind that the different considerations when using these four distillation methods. Although labelbased and sample-based distillations are easy to implement, they need to consider the potential factors on the label and sample that may affect the model, such as the differences in sample size and the label distributions. The difference in the label distributions is passed on to the distributions of the predicted labels, so that the strategy of directly using the predicted labels may lead to poor results. The difference in data size means that 𝑀 𝑐 in a rough strategy can almost ignore the guided information from 𝑆 𝑡 . Feature-based distillation relies on the accuracy of the method used to filter out the causal and stable features. However, the current research in this direction is still not sufficient, and the existing methods need more time and computing resources. Model structure-based distillation requires only the model itself without regarding to other potential factors. But it is not easy to design an effective distillation structure or select some good embedded representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMPIRICAL EVALUATION</head><p>In this section, we conduct experiments with the aim of answering the following two key questions.</p><p>• RQ1: How do the proposed methods perform against baselines? • RQ2: How does 𝑆 𝑡 improve the model trained on 𝑆 𝑐 ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Datasets.</head><p>To evaluate the recommendation performance of the proposed framework, the selected dataset must have a uniform subset for training and test. We consider the following datasets in the experiments, where the statistics are described in Table <ref type="table" target="#tab_3">3</ref>.</p><p>• Yahoo! R3 <ref type="bibr" target="#b16">[17]</ref>: This dataset contains ratings collected from two different sources on Yahoo! Music services, involving 15,400 users and 1000 songs. The Yahoo! user set consists of ratings supplied by users during normal interactions, i.e., users pick and rate items as they wish. This can be considered as a stochastic logging policy by following <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b30">31]</ref>, and thus the user set is biased. The Yahoo! random set consists of ratings collected during an online survey, when each of the first 5400 users is asked to provide ratings on ten songs. The random set is different because the songs are randomly selected by the system instead of by the users themselves. The random set corresponds to a uniform logging policy and can be considered as the ground truth without bias. We binarize the ratings based on a threshold 𝜖 = 3. Hence, a rating 𝑟 𝑖 𝑗 &gt; 𝜖 is considered as a positive feedback (i.e., label 𝑦 𝑖 𝑗 = 1), otherwise, it is considered as a negative feedback (i.e., label 𝑦 𝑖 𝑗 = −1). The Yahoo! user set is used as a training set in a biased environment (𝑆 𝑐 ). For Yahoo! random set, we randomly split the user-item interactions into three subsets: 5% for training in an unbiased environment (𝑆 𝑡 ), 5% for validation to tune the hyper-parameters (𝑆 𝑣𝑎 ), and the rest 90% for test (𝑆 𝑡𝑒 ). • Product: This is a large-scale dataset for CTR prediction, which includes three weeks of users' click records from a real-world advertising system. The first two weeks' samples are used for training and the next week's samples for test. To eliminate the effects of the bias problems in our experiments, we only filter out the samples at positions 1 and 2. There exists two polices in this dataset: non-uniform policy and uniform policy which are defined in Section 3.1. We can thus separate this dataset into two parts, i.e., a uniform data and a non-uniform data. The nonuniform data contains around 29 million records and 2.8 million users, which is directly used as a training set named as 𝑆 𝑐 . Next, we randomly split the uniform data into three subsets by the same way as that of Yahoo! R3, i.e., 5% as training set (𝑆 𝑡 ), 5% as validation set (𝑆 𝑣𝑎 ), and the rest as test set (𝑆 𝑡𝑒 ). Following the settings of the previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b32">33]</ref>, we employ two evaluation metrics that are widely used in industry recommendation, including the negative logarithmic loss (NLL) and the area under the roc curve (AUC). The NLL evaluates the performance of the predictions,</p><formula xml:id="formula_10">NLL ≡ − 1 𝐿 𝐿 (𝑖,𝑗) ∈Ω log 1 + 𝑒 −𝑦 𝑖 𝑗 ŷ𝑖 𝑗 ,<label>(9)</label></formula><p>where Ω denotes the validation set (when tuning the parameters) or the test set (in evaluation), and 𝐿 denotes the number of feedback in Ω. The AUC evaluates the performance of rankings and is defined as follows,</p><formula xml:id="formula_11">AUC ≡ 𝐿 𝑝 (𝑖,𝑗) ∈Ω + Rank 𝑖 𝑗 − 𝐿 𝑝 2 𝐿 𝑝 𝐿 − 𝐿 𝑝 ,<label>(10)</label></formula><p>where Ω + denotes a subset of the positive feedback in Ω, and 𝐿 𝑝 denotes the number of feedback in Ω + . Rank 𝑖 𝑗 denotes the rank of a positive feedback (𝑖, 𝑗) in all the 𝐿 feedback, which are ranked in a descending order according to their predicted values. Note that most users in the validation set 𝑆 𝑣𝑎 and test set 𝑆 𝑡𝑒 may only have negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Baselines.</head><p>To demonstrate the effectiveness of our proposed framework, we include with the following baselines which are widely used in recommendation scenarios. Low Rank Baselines: Biased Matrix Factorization (biasedMF). We first consider the case where the proposed framework is implemented using a lowrank model. We use biased matrix factorization (biasedMF) <ref type="bibr" target="#b11">[12]</ref> as the baseline, which is one of the most classic basic models in recommender systems. In this method, a user 𝑖's preference for an item 𝑗 is formalized as Ŷ𝑖 𝑗 = 𝑈 𝑇 𝑖 𝑉 𝑗 +𝑏𝑢 𝑖 +𝑏𝑣 𝑗 . We directly learn user, item and bias representations using the squared loss. All strategies in the framework are implemented when 𝑀 𝑐 and 𝑀 𝑡 are a biasedMF model. Inverse-Propensity-Scored Matrix Factorization (IPS-MF). To test and compare the performance of the propensity-based causal inference, we use a representative counterfactual-based recommendation method as the second low-rank baseline, i.e., IPS-MF <ref type="bibr" target="#b23">[24]</ref>. Note that we estimate the propensity scores via the naïve Bayes estimator,</p><formula xml:id="formula_12">𝑃 𝑂 𝑖,𝑗 = 1|𝑌 𝑖,𝑗 = 𝑦 = 𝑃 (𝑌 = 𝑦, 𝑂 = 1) 𝑃 (𝑌 = 𝑦) ,<label>(11)</label></formula><p>where 𝑦 = {−1, 1} is the label, 𝑃 (𝑌 = 𝑦, 𝑂 = 1) denotes the ratio of the feedback labeled as 𝑦 in the observed feedback, and 𝑃 (𝑌 = 𝑦) denotes the ratio of the feedback labeled as 𝑦 in an unbiased set. They are counted by 𝑆 𝑐 ∪ 𝑆 𝑡 and 𝑆 𝑡 , respectively, and the subscripts are dropped to reflect that the parameters are tied across all 𝑖 and 𝑗.</p><p>Neural Networks Baselines: AutoEncoder (AE). We next consider the case where the proposed framework is implemented using a neural network model. We choose the autoencoder as the baseline to include more model choices. Except for the hint and soft label strategies where we use a five-layer autoencoder, we use the original three-layer autoencoder by default. All strategies in the framework are also implemented when 𝑀 𝑐 and 𝑀 𝑡 are an autoencoder model. Note that in the FeatEuser strategy, we use the weights of the first layer of the autoencoder, and in the FeatE-item strategy, we use the weights of the last layer of the autoencoder.</p><p>Deep Logistic Regression (DLR). Since the DGBR model used in feature-based distillation requires logistic regression components, autoencoder are not suitable. Hence, we use DLR as a baseline in feature-based distillation. This approach consists of two parts: i) deep autoencoder model, which reconstructs the input-vectors in a high-dimensional space and encodes it into low-dimensional codes, and ii) logistic regression model, which handles the manual feature codes and optimizes the model parameters. Considering the odds of deep autoencoder on non-linear dimensionality reduction, we employ it to convert the high-dimensional data into some lowdimensional codes by defining a three-level encoder network and a three-level decoder network. Then we feed the output of this deep autoencoder model to the LR model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Implementation Details.</head><p>We implement all the methods on TensorFlow 1 . We perform grid search to tune the hyper-parameters for the candidate methods by evaluating the AUC on the validation set 𝑆 𝑣𝑎 , where the range of the values of the hyper-parameters are shown in Table <ref type="table" target="#tab_4">4</ref>.   The comparison results are shown in Table <ref type="table">5</ref> and Table <ref type="table">6</ref>. Because feature-based distillation requires a special baseline DLR as described in Section. 5.1.3, we list its results separately in Table <ref type="table">6</ref>.</p><p>As shown in the tables, our methods perform better than all the compared methods in most cases. More specifically, we have the following observations: (1) The sample combination of 𝑆 𝑐 and 𝑆 𝑡 improves the performance in all cases. The propensity-based method and the method using only 𝑆 𝑡 have similar performance, i.e., they have superior NLL and uncompetitive AUC on Yahoo! R3, but on Product, their NLL will also deteriorate. One possible reason is that 𝑆 𝑐 and 𝑆 𝑡 of Product dataset have a close ratio between the positive and negative feedback. (2) The trends of AUC and NLL metrics may be inconsistent. For example, some of our strategies have a better AUC value but a poor NLL value, while the uniform strategy is the opposite. Since the NLL value is susceptible to the difference in label distribution between the training and test sets, we mainly consider AUC. (3) Most of the bad cases of our proposed methods appear in the feature embedding strategy. This may be because the feature embedding in 𝑆 𝑡 is not sufficiently trained as described in Section 4.4. We can also see that FeatE-alter can effectively alleviate this issue. In addition, a special bad case appears when using WeightC-local on Product. We think it is still a challenge that modeling the local weights with a large-scale dataset. (4)</p><p>The improvements brought by all the proposed strategies vary in different model implementations and different data scales. It means that each strategy's ability to use 𝑆 𝑡 depends on distinct scenarios. We will conduct in-depth research on some strategies separately in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">RQ2: How Do 𝑆 𝑡 Improve the Model Trained on 𝑆 𝑐 ?</head><p>To explore the form of the useful knowledge provided by 𝑆 𝑡 , we conduct an in-depth analysis using the first three best strategies implemented with low-rank models on the Yahoo! R3 dataset as an example, i.e., WeightC-local, DelayC and Refine. Figure <ref type="figure" target="#fig_3">4</ref>(a) shows a visualization of the weight parameters learned from the WeightClocal strategy. User IDs and item IDs are sorted in ascending order w.r.t. the user activity and item popularity, respectively. As the item popularity increases, the weight value decreases, and this trend will gradually be weaken as the user activity increases. This means that the useful knowledge provided by 𝑆 𝑡 is to enhance the contribution of the active users and tail items. The original DelayC strategy randomly samples one batch of data from 𝑆 𝑡 to guide 𝑀 𝑐 . We can control the sampling method to analyze the efficacy of different types of data. Table <ref type="table">7</ref> shows the results under different sampling methods. The head users refers to that we only sample the data corresponding to the first 50% of the most active users in 𝑆 𝑡 , while the tail users means that the last 50% of users are sampled. The head items and tail items are defined in a similar way. We find that although the performance of the four sampling methods is not as good as random sampling, the head users and tail items are closer to the performance of random sampling than the other two sampling methods. This is consistent with the findings of Figure <ref type="figure" target="#fig_3">4(a)</ref>.</p><p>Finally, we examine the ranking difference between the Refine strategy and the Base strategy for positive samples in the validation set. The results are shown in Figure <ref type="figure" target="#fig_3">4</ref>(b). Item IDs are sorted in the ascending order of popularity. We find that the Refine strategy follows the intuition that a popular item is more likely to get feedback than a tail item. It tries to lower the ranking of tail items that may be recommended to the top and raise the ranking of popular items that may be recommended to the tail, as shown on the both sides of Figure <ref type="figure" target="#fig_3">4</ref>(b). In the middle of Figure <ref type="figure" target="#fig_3">4</ref>(b), we find that the rank difference of most items is not large, which means that a less popular item still has an opportunity to catch up with a more popular item. Since the Refine strategy achieves the best performance, we believe it is a good strategy to combine the advantages of 𝑆 𝑐 and 𝑆 𝑡 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">FUTURE WORKS</head><p>We have proposed some approaches about how to mine some useful knowledge from a uniform data to improve the modeling of a nonuniform data. Counterfactual recommendation via a uniform data is still a rich research field. In this section, we discuss some interesting and promising future directions.</p><p>Label-Based Module. Because 𝑆 𝑡 collected from different scenarios may have different label distributions, the distribution difference between 𝑆 𝑡 and 𝑆 𝑐 can be large or small. It is necessary to design some more robust strategies for addressing the difference.</p><p>for 𝑀 𝑡 and 𝑀 𝑐 instead of pre-training 𝑀 𝑡 before using it to train 𝑀 𝑐 . The current distillation structure selection methods are based on enumeration or empirical methods. How to effectively design a good distillation structure is another promising direction, for which AutoML has the potential to find a reasonable model structure based on 𝑆 𝑡 .</p><p>Others. There are also many other directions closely related to the framework. For example, the visualization or interpretation of the useful information (or knowledge) learned from 𝑆 𝑡 ; further exploration of the results at a micro level, i.e., the impact on each user or each item; and the relation between the size of 𝑆 𝑡 and the performance of the model. In addition, we would like to further investigate the trade-off of training on 𝑆 𝑐 introduced by 𝑆 𝑡 and gain more theoretical insight into why it is effective. These theoretical insights can also inspire us to design better distillation strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this work, motivated by the observation that simply modeling with a uniform data can alleviate the bias problems, we propose a general knowledge distillation framework for counterfactual recommendation via uniform data, i.e., KDCRec, including label-based, feature-based, sample-based and model structure-based distillations. We conduct extensive experiments on both public and product datasets, demonstrating that the proposed four methods can achieve better performance over the baseline models. We also analyze the proposed methods in depth, and discuss some promising directions worthy of further exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>illustrates the main idea of stable feature distillation, which consists of a deep global balancing regression (DGBR) algorithm<ref type="bibr" target="#b12">[13]</ref>, a teacher network and a student network. The DGBR algorithm optimizes a deep autoencoder model for feature selection and a global balancing model for learning the global sample weights and the predicting stability. The main idea of feature-based distillation is to filter out the representative stable features through DGBR from 𝑆 𝑡 , which are then used to train a teacher network. Next, we train a student network to mimic the output of the teacher model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of stable feature distillation.</figDesc><graphic url="image-2.png" coords="4,329.97,395.40,216.21,124.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of three types of model structure-based distillations, including feature embedding, hint and soft label. We use dotted arrows to indicate the matched pairs considered by different types of distillations.</figDesc><graphic url="image-3.png" coords="5,317.96,455.35,240.24,127.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) Visualization of the weight parameters learned by the WeightC-local strategy. (b) The ranking difference between the Refine strategy and the Base strategy for the positive samples in the validation set.</figDesc><graphic url="image-4.png" coords="8,320.44,152.56,93.21,69.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Performance comparisons on a public dataset.</figDesc><table><row><cell>Data approach</cell><cell>AUC</cell><cell>NLL</cell></row><row><cell>uniform data</cell><cell cols="2">0.5692 -0.50994</cell></row><row><cell>biased data</cell><cell cols="2">0.7275 -0.58905</cell></row><row><cell cols="3">uniform data ∪ biased data 0.7295 -0.58138</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>• Bridge Strategy. Let D denote the whole set of data, including the non-uniform data 𝑆 𝑐 , the uniform data 𝑆 𝑡 and the unobserved data. We first consider a scenario where two models are trained simultaneously, i.e., train the model 𝑀 𝑐 and 𝑀 𝑡 in a supervised manner on 𝑆 𝑐 and 𝑆 𝑡 , respectively. To correct the bias of 𝑀 𝑐 , we randomly sample an auxiliary set 𝑆 𝑎 from D as a bridge in each iterative training, and expect the predicted output of 𝑀 𝑐 and 𝑀 𝑡 on 𝑆 𝑎 to be close. Note that most of the samples in 𝑆 𝑎 are unobserved data because of the data sparsity in recommender systems. Due to the unbiased nature of 𝑆 𝑡 and 𝑆 𝑎 , this strategy can reduce the bias of 𝑀 𝑐 . The final objective function of this strategy is, min</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>𝑗) ∈𝑆 𝑐 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) , 𝑆 𝑐 step. |𝑆 𝑡 | (𝑖,𝑗) ∈𝑆 𝑡 ℓ 𝑦 𝑖 𝑗 , ŷ𝑐 𝑖 𝑗 + 𝜆 𝑐 𝑅 (W 𝑐 ) , 𝑆 𝑡 step.</figDesc><table><row><cell></cell><cell>(6)</cell></row><row><cell>min</cell><cell>1</cell></row><row><cell>W 𝑐</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Statistics of the datasets. P/N represents the ratio between the numbers of positive and negative feedback.</figDesc><table><row><cell></cell><cell cols="2">Yahoo! R3</cell><cell cols="2">Product</cell></row><row><cell></cell><cell>#Feedback</cell><cell>P/N</cell><cell cols="2">#Feedback P/N</cell></row><row><cell>𝑆 𝑐</cell><cell>311,704</cell><cell cols="3">67.02% 29,255,580 2.12%</cell></row><row><cell>𝑆 𝑡</cell><cell>2,700</cell><cell>9.36%</cell><cell>20,751</cell><cell>1.57%</cell></row><row><cell>𝑆 𝑣𝑎</cell><cell>2,700</cell><cell>8.74%</cell><cell>20,751</cell><cell>1.42%</cell></row><row><cell>𝑆 𝑡𝑒</cell><cell>48,600</cell><cell>9.71%</cell><cell>373,522</cell><cell>1.48%</cell></row><row><cell cols="2">5.1.2 Evaluation Metrics.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Hyper-parameters tuned in the experiments.</figDesc><table><row><cell>Name</cell><cell>Range</cell><cell>Functionality</cell></row><row><cell>𝑟𝑎𝑛𝑘</cell><cell>{10, 50, 100, 200}</cell><cell>Embedded dimension</cell></row><row><cell>𝜆</cell><cell>1𝑒 −5 , 1𝑒 −4 • • • 1𝑒 −1</cell><cell>Regularization</cell></row><row><cell>𝛼</cell><cell>{0.1, 0.2 • • • 0.9}</cell><cell>Loss weighting</cell></row><row><cell>𝑙</cell><cell>2 5 , 2</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>6 </figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.tensorflow.org</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Mr. Bowen Yuan for his helpful comments and discussions, and Prof. Kun Kuang from Tsinghua University for providing the source code of the DGBR algorithm. This work is supported by the National Natural Science Foundation of China Nos. 61872249, 61836005 and 61672358.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We can learn different imputation models with 𝑆 𝑡 , among which one promising direction is about how to ensemble the imputed labels from different imputation models to correct the labels of the biased samples. How to better combine the imputed label with the true label of 𝑆 𝑐 in a more sophisticated manner is another promising direction.</p><p>Feature-Based Module. The current stable feature approach <ref type="bibr" target="#b12">[13]</ref> needs much time and computing resources. For implementing the industry recommender system, we need more efficient methods to learn the stable features. Besides, the current approach only makes use of the feature information in each sample to learn the stable features, while the label in each sample from 𝑆 𝑡 is more stable and unbiased. So how to filter out the stable features with both labels and features in 𝑆 𝑡 is another interesting research question.</p><p>Sample-Based Module. The difference between the data size of 𝑆 𝑡 and that of 𝑆 𝑐 is a challenge for sample-based methods. This difference increases the difficulty of model training, e.g., 𝑀 𝑡 may converge faster than 𝑀 𝑐 because the number of 𝑆 𝑡 is much smaller. A large difference in the number means that 𝑆 𝑡 has very little corrective effect on 𝑆 𝑐 , which may also weaken the guiding role of 𝑆 𝑡 . One promising direction is to use the information in 𝑆 𝑡 to filter out a more unbiased subset from 𝑆 𝑐 , or use the information in 𝑆 𝑐 to perform data augmentation on 𝑆 𝑡 . Instead of using the label information, another promising direction is that we can consider modeling the preference ranking relation between 𝑆 𝑡 and 𝑆 𝑐 .</p><p>Model Structure-Based Module. The feature embeddings obtained by 𝑆 𝑡 are often not fully trained due to the size of 𝑆 𝑡 . A promising direction is to design a good mutual learning strategy</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Controlling popularity bias in learning-to-rank recommendation</title>
		<author>
			<persName><forename type="first">Himan</forename><surname>Abdollahpouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bamshad</forename><surname>Mobasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM Conference on Recommender Systems</title>
				<meeting>the 11th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="42" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A general framework for counterfactual learning-to-rank</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenta</forename><surname>Takatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Estimating position bias without intrusive interventions</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM International Conference on Web Search and Data Mining</title>
				<meeting>the 12th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="474" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Label refinery: Improving imagenet classification through label progression</title>
		<author>
			<persName><forename type="first">Hessam</forename><surname>Bagherinezhad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02641</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causal embeddings for recommendation</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flavian</forename><surname>Vasile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
				<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="104" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Should I follow the crowd?: A probabilistic analysis of the effectiveness of popularity in recommender systems</title>
		<author>
			<persName><forename type="first">Rocío</forename><surname>Cañamares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="415" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dudík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1103.4601</idno>
		<title level="m">Doubly robust policy evaluation and learning</title>
				<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient knowledge distillation from an ensemble of teachers</title>
		<author>
			<persName><forename type="first">Takashi</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayuki</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gakuto</forename><surname>Kurata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3697" to="3701" />
		</imprint>
	</monogr>
	<note>In Interspeech</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sample selection bias as a specification error</title>
		<author>
			<persName><forename type="first">J</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><surname>Heckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="153" to="161" />
			<date type="published" when="1979">1979. 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Removing hidden confounding by experimental grounding</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aahlad</forename><surname>Manas Puli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="10888" to="10897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stable prediction across unknown environments</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoxuan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1617" to="1626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Counterfactual learning from bandit feedback under deterministic logging: A case study in statistical machine translation</title>
		<author>
			<persName><forename type="first">Carolin</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09118</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spiral of silence in recommender systems</title>
		<author>
			<persName><forename type="first">Dugang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghua</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM International Conference on Web Search and Data Mining</title>
				<meeting>the 12th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="222" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Related pins at pinterest: The evolution of a real-world recommender system</title>
		<author>
			<persName><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Shiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">C</forename><surname>Kislyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhigang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion</title>
				<meeting>the 26th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="583" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Collaborative prediction and ranking with non-random missing data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marlin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd ACM Conference on Recommender systems</title>
				<meeting>the 3rd ACM Conference on Recommender systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="5" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Sinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey of transfer learning for collaborative recommendation with auxiliary data</title>
		<author>
			<persName><forename type="first">Weike</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adaptive Bayesian personalized ranking for heterogeneous implicit feedbacks</title>
		<author>
			<persName><forename type="first">Weike</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congfu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Ming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="173" to="180" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning deep representations with probabilistic knowledge transfer</title>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Passalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Tefas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th European Conference on Computer Vision</title>
				<meeting>the 15th European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="268" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting counterfactuals from large historical data and small randomized trials</title>
		<author>
			<persName><forename type="first">Nir</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elad</forename><surname>Yom-Tov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion</title>
				<meeting>the 26th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="602" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recommendations as treatments: Debiasing learning and evaluation</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashudeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navin</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
				<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Batch learning from logged bandit feedback through counterfactual risk minimization</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1731" to="1755" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ranking distillation: Learning compact ranking models with high performance for recommender system</title>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2289" to="2298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.10959</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Dataset distillation. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Position bias estimation for unbiased learning to rank in personal search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Golbandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM International Conference on Web Search and Data Mining</title>
				<meeting>the 11th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="610" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Doubly robust joint learning for recommendation on data missing not at random</title>
		<author>
			<persName><forename type="first">Xiaojie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhong</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
				<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6638" to="6647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Chen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhua</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwu</forename><surname>Ou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05171</idno>
		<title level="m">Privileged features distillation for e-commerce recommendations</title>
				<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback</title>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
				<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A gift from knowledge distillation: Fast optimization, network minimization and transfer learning</title>
		<author>
			<persName><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihoon</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the 2017 IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4133" to="4141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving ad click prediction by considering non-displayed events</title>
		<author>
			<persName><forename type="first">Jui-Yang</forename><surname>Bowen Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng-Yuan</forename><surname>Hsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Yao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhua</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Jen</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="329" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distilling structured knowledge into embeddings for explainable and accurate recommendation</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
				<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="735" to="743" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
