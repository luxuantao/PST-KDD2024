<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiple Aggregations Over Data Streams</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
							<email>fzhangru1@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">National Univ. of Singapore z Univ. of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nick</forename><surname>Koudas Z Beng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chin</forename><surname>Ooi</surname></persName>
							<email>ooibcg@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">National Univ. of Singapore z Univ. of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Divesh</forename><surname>Srivastava</surname></persName>
							<email>divesh@research.att.com</email>
							<affiliation key="aff1">
								<orgName type="institution">AT&amp;T Labs-Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Baltimore</settlement>
									<region>Maryland</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multiple Aggregations Over Data Streams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FAA31F04713EDC0EF65FA552E35F18EA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Monitoring aggregates on IP traffic data streams is a compelling application for data stream management systems. The need for exploratory IP traffic data analysis naturally leads to posing related aggregation queries on data streams, that differ only in the choice of grouping attributes. In this paper, we address this problem of efficiently computing multiple aggregations over high speed data streams, based on a two-level LFTA/HFTA DSMS architecture, inspired by Gigascope.</p><p>Our first contribution is the insight that in such a scenario, additionally computing and maintaining fine-granularity aggregation queries (phantoms) at the LFTA has the benefit of supporting shared computation. Our second contribution is an investigation into the problem of identifying beneficial LFTA configurations of phantoms and user-queries. We formulate this problem as a cost optimization problem, which consists of two sub-optimization problems: how to choose phantoms and how to allocate space for them in the LFTA. We formally show the hardness of determining the optimal configuration, and propose cost greedy heuristics for these independent sub-problems based on detailed analyses. Our final contribution is a thorough experimental study, based on real IP traffic data, as well as synthetic data, to demonstrate the effectiveness of our techniques for identifying beneficial configurations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The phenomenon of data streams is real. In data stream applications, data arrives very fast and the rate is so high that one may not wish to (or be able to) store all the data; yet, the need exists to query and analyze this data.</p><p>The quintessential application seems to be the processing of IP traffic data in the network (see, e.g., <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b15">15]</ref>). Routers forward IP packets at great speed, spending typically a few hundred nanoseconds per packet. Processing the IP packet data for a variety of monitoring tasks, e.g., keeping track of statistics, and detecting network attacks, at the speed at which packets are forwarded is an illustrative example of data stream processing. One can see the need for aggregation queries in this scenario: to provide simple statistical summaries of the traffic carried by a link, to identify normal activ-ity vs activity under denial of service attack, etc. For example, a common IP network analysis query is "for every source IP and 5 minute interval, report the total number of packets, provided this number of packets is more than 100". Thus, monitoring aggregates on IP traffic data streams is a compelling application.</p><p>There has been a concerted effort in recent years to build data stream management systems (DSMSs), either for general purpose or for a specific streaming application. Many of the DSMSs are motivated by monitoring applications. Example DSMSs are in <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b19">19]</ref>. Of these DSMSs, Gigascope <ref type="bibr" target="#b8">[8]</ref> appears to have been tailored for processing high speed IP traffic data. This is, in large measure, due to Gigascope's two layer architecture for query processing. The low level query nodes (or LFTAs <ref type="foot" target="#foot_0">1</ref> ) perform simple operations such as selection, projection and aggregation on a high speed stream, greatly reducing the volume of the data that is fed to the high level query nodes (or HFTAs). The HFTAs can then perform more complex processing on the reduced volume (and speed) of data obtained from the LFTA.</p><p>The need for exploratory IP traffic data analysis naturally leads to posing related aggregation queries on data streams, that differ only in the choice of grouping attributes. For example, "for every destination IP, destination port and 5 minute interval, report the average packet length", and "for every source IP, destination IP and 5 minute interval, report the average packet length". An extreme case is that of the data cube, i.e., computing aggregates for every subset of a given set of grouping attributes; more realistic is the case where specified subsets of the grouping attributes (such as "source IP, source port", "destination IP, destination port" and "source IP, destination IP") are of interest. In this paper, we address this problem of efficiently computing multiple aggregations over high speed data streams, based on the LFTA/HFTA architecture of Gigascope, and make the following contributions:</p><p>Our first contribution is the insight that when computing multiple aggregation queries that differ only in their grouping attributes, it is often beneficial to additionally compute and maintain phantoms at the LFTA. These are fine-granularity aggregation queries that, while not of interest to the user, allow for shared computation between multiple aggregation queries over a high speed data stream.</p><p>Our second contribution is an investigation into the problem of identifying beneficial configurations of phantoms and user-queries in Gigascope's LFTA.</p><p>We formulate this problem as a cost optimization problem, which consists of two sub-optimization problems: how to choose phantoms and how to allocate space for hash tables in the LFTA amongst a set of phantoms and user queries. We formally show the hardness of determining the optimal configuration, and propose cost greedy heuristics for both the sub-optimization problems based on detailed analyses.</p><p>Our final contribution is a thorough experimental study, based on real IP traffic data, as well as synthetic data, to understand the effectiveness of our techniques for identifying beneficial configurations.</p><p>We demonstrate that the heuristics result in near optimal configurations (within 15-20% most of the time) for processing multiple aggregations over high speed streams. Further, choosing a configuration is extremely fast, taking only a few milliseconds; this permits adaptive modification of the configuration to changes in the data stream distributions.</p><p>The rest of the paper is organized as follows. We first motivate the problem and our solution techniques in Section 2. We then give a formal definition of the problem, formulate the cost model for it, and present algorithms for choosing phantoms in Section 3. Section 4 presents our collision rate model at the LFTA, which is a key component of the cost model. Section 5 analyzes space allocation schemes. Section 6 presents our experimental study. Related work is summarized in Section 7. We finally conclude in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MOTIVATION</head><p>In this section, we describe the problem of efficiently processing multiple aggregations over high speed data streams, based on the architecture of Gigascope, and motivate our solution techniques, in an example driven fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gigascope's Two Level Architecture</head><p>Gigascope splits a (potentially complex) query over high speed tuple data streams into two parts, (i) simple low-level queries (at the LFTA) over high speed data streams, which serve to reduce data volumes, and (ii) (potentially complex) high-level queries (at the HFTA) over the low speed data streams seen at the HFTA. LF-TAs can be processed on a Network Interface Card (NIC), which has both processing capability and limited memory (a few MBs). HFTAs are typically processed in a host machine's main memory (which can be hundreds of MB to several GB).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Processing a Single Aggregation</head><p>Let us first see how a single aggregation query is processed in Gigascope. Consider a data stream relation R (e.g., IP packet headers), with four attributes A, B, C, D (e.g., source IP, source port, destination IP, destination port), in addition to a time attribute. Suppose the user defines the following aggregation query: Q0: select A, tb, count(*) as cnt from R group by A, time/60 as tb Figure <ref type="figure">1</ref> is an abstracted model of Gigascope. ML corresponds to the LFTA, and MH corresponds to the HFTA. Q0 is processed in Gigascope as follows. When a data stream record in R arrives, it is observed at ML. ML maintains a hash table consisting of a specified number of entries, and each entry is a fgroup, countg pair. group identifies the most recently observed group that hashes to this entry and count keep track of the number of times that group has been recently observed without observing other groups that hash to the same entry.  When a new record r hashes to entry bk, Gigascope checks if r belongs to the same group as the existing group in bk. If yes, the count is incremented by 1. Otherwise, a collision is said to occur.</p><p>In this case, first the current entry in bk is evicted to MH. Then, a new group corresponding to r is created in bk in ML and the count of the group corresponding to r is set to 1.</p><p>Query Q0 is processed by Gigascope in an epoch by epoch fashion, for an epoch of length 1 minute (i.e., time/60). This means that at the end of every minute, all the entries in ML would be evicted to MH to compute the aggregation results for this epoch at the HFTA.</p><p>At the HFTA, multiple tuples for the same group in the same epoch may be seen because of evictions, and these are combined to compute the desired query answer.</p><p>Consider an example stream with the following prefix: 2, 24, 2, 2, 3, 17, 3, 4. At the LFTA, suppose we use a simple hash function which is the remainder modulo 10. The first item in the stream, 2, hashes to a certain entry. We check the entry in the hash table, which is empty in the beginning, and so we add the entry (2 1) to the hash table. Then we see 24, which hashes to a different entry of the hash table. Similarly an entry (24 1) is added. The third item is 2. We check the hash table and find that the existing entry where 2 hashes to contains the same group 2, so we just increment the count of the entry by 1, resulting in (2 2). The rest of the items are similarly processed one by one. After we processed the 7 th item, which is 3, the status of the hash table <ref type="table">is</ref> shown in Figure <ref type="figure">1</ref>. The next item 4 hashes to the same entry as 24. When we check the existing entry in the hash table, we find the new group is different from the existing one. In this case, we evict the existing entry (24 1) to MH and set the entry to (4 1).</p><p>Gigascope is especially designed for processing network level packet data. Usually this data exhibits a lot of clusteredness, that is, all packets in a flow have the same source/destination IP/port. Therefore, the likelihood of a collision is very low until many packets have been observed. In this fashion, the data volume fed to MH is greatly reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cost of Processing a Single Aggregation</head><p>Since MH has much more space and a much reduced volume of data to process, processing at MH does not dominate the total cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The overall bottlenecks are:</head><p>The cost of looking up the hash table in ML, and possible update in case of a collision. This whole operation, called a probe, has a nearly constant cost c1. The cost of transferring an entry from ML to MH. This operation, called an eviction, has a nearly constant cost c2. Usually, c2 is much higher than c1 because the transfer from ML to MH is more expensive than a probe in ML. The total cost of query processing thus depends on the number of collisions incurred, which is determined by the number of groups of the data and collision rate of the hash table. The number of groups depends on the nature of the data. The collision rate depends on the hash function, size of the hash table, and the data distribution. Therefore, generally, what we can do is to devise a good hash function and allocate more space (within space and peak load constraints, as we will discuss more later) to the hash table in order to minimize the total cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Processing Multiple Aggregations Naively</head><p>Given the method to process single aggregation queries, and its cost model, based on the Gigascope architecture, we now examine the problem of evaluating multiple aggregation queries. Suppose the user is interested in the following three aggregation queries:</p><formula xml:id="formula_0">Q1: select A, count(*) from R group by A Q2: select B, count(*) from R group by B Q3: select C, count(*) From R group by C</formula><p>A straightforward method is to process each query separately using the above single aggregation query processing algorithm, so we maintain, in ML, three hash tables for A, B, and C separately.</p><p>For each incoming record, we need to probe each hash table, and if there is a collision, some entry gets evicted to MH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Processing Multiple Aggregations Using Phantoms</head><p>Since we are processing multiple aggregation queries, we may be able to share the computation that is common to each one and thereby reduce the overall processing cost. For example, we can additionally maintain a hash table for the relation ABC in ML as shown in Figure <ref type="figure" target="#fig_2">2</ref>. If we have the counts of each group in ABC, we can derive the counts of each group of A, B and C from it. The intuition is that, when a new record arrives, instead of probing three hash tables A, B and C, we only probe the hash table ABC. We would delay the probes on A, B and C (we omit "hash tables" when the context is clear) until the point when an entry is evicted from ABC.</p><p>Since the aggregation queries of A, B and C are derived from ABC, we say that ABC feeds A, B and C. Although ABC is not of interest to the user, its maintenance could help reduce the overall cost. We call such a relation as a phantom. While for A, B and C, whose aggregate information is of user interest, we call each of them as a query. Both queries and phantoms are called relations. Now we examine Figure <ref type="figure" target="#fig_2">2</ref> to illustrate how the instantiation of a phantom can benefit the total evaluation cost. To be fair, the total space used for the hash tables should be the same with or without the phantoms. So when we add the phantom ABC, the size of the hash tables for A, B and C need to be reduced. Suppose the total space allocated for the three queries is M. While we have many choices of space allocation between the hash table instantiations, let us allocate equal space to each instantiation, for simplicity of exposition. Without phantoms, we allocate M=3 to each hash table. With the phantom ABC, we allocate M=4 to each hash table. Also assume that A, B and C have the same collision rate. Without the phantom, their collision rate is denoted x1; with the phantom, their collision rate is denoted x 0 1 . Since the hash table size of A, B and C is smaller in the presence of the phantom, x 0 1 should be larger than x1. Let the collision rate of phantom ABC be x2.</p><p>Consider the cost for processing n records. Without the phantom, we need to probe 3 hash tables for each incoming record, and there are x1n evictions from each table. Therefore the total cost is:</p><formula xml:id="formula_1">E1 = 3 nc1 + 3 x1nc2<label>(1)</label></formula><p>With the phantom, we probe only ABC for each incoming record and there would be x2n evictions. For each of these evictions, we probe A, B and C, and hence there are x 0 1 x2n evictions from each of them. The total cost is:</p><formula xml:id="formula_2">E2 = nc1 + 3 x2nc1 + 3 x 0 1 x2nc2<label>(2)</label></formula><p>Comparing Equations 1 and 2, we can get the difference of E1 and E2 as follows</p><formula xml:id="formula_3">E1 ; E2 = ( 2 ; 3x2)c1 + 3 ( x1 ; x 0 1 x2)c2]n<label>(3)</label></formula><p>If x2 is small enough so that both (2 ; 3x2) and (x1 ; x 0 1 x2) are larger than 0, then E2 will be smaller than E1, and therefore instantiation of the phantom benefits the total cost. If x2 is not small enough so that one of (2 ; 3x2) and (x1 ; x 0 1 x2) is larger than 0 but the other is less than 0, then E1 ; E2 depends on the relationship of c1 and c2. If x2 is so large that both (2 ; 3x2) and (x1 ; x 0 1 x2) are less than 0, then the instantiation of the phantom increases the cost and therefore we should not instantiate it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Choice of Phantoms</head><p>In the above example, we have only considered one phantom. In fact, we can have many phantoms and multiple levels of phantoms.</p><p>Again, consider stream relation R with four attributes A, B, C, D. Suppose the queries are AB, BC, BD and CD. We could instantiate phantom ABC, which feeds AB and BC as shown in Figure <ref type="figure">3</ref>(a) (a shaded box is a phantom and a non-shaded box is a query); or we could instantiate phantom BCD, which feeds BC, BD and CD as shown in Figure <ref type="figure">3(b)</ref>; or we could instantiate BCD and ABCD, where ABCD feeds AB and BCD as shown in Figure <ref type="figure">3(c</ref>). We only list three choices here, although there are many other possibilities.</p><p>It is easy to prove that a phantom that feeds less than two relations is never beneficial. So by combining two or more queries, we can obtain all possible phantoms and plot them in a relation feeding graph as in Figure <ref type="figure" target="#fig_3">4</ref>. Each node in the graph is a relation and each directed edge shows a feed relationship between two nodes, that is, the parent feeds the child. Note that this feed relationship can be "short circuited", that is, a node can be directly fed by any of its ancestors in the graph. For example, AB could be fed directly by ABCD without having ABC or ABD instantiated.</p><p>Given the relation feeding graph, and a set of user queries that are instantiated in the LFTA, one optimization problem is to identify the phantoms that we should instantiate to minimize the cost. The exhaustive method is obvious, that is, we try all possible combinations of the phantoms and calculate the cost of each combination as in Section 2.5. Then we choose the one with the minimum cost. However, the exhaustive method is too expensive, especially for data stream systems where a fast response is essential.</p><p>In our example in Section 2.5, we assumed that each hash table has the same size for simplicity of exposition. However, given a set of phantoms and queries to instantiate in ML, how does the allocation of space to each hash table affect the collision rate and hence the cost? Therefore, another optimization problem is that, given a set of relations to instantiate, how to allocate space to them so that the cost is minimized.</p><p>In summary, our cost optimization problem consists of two suboptimization problems: how to choose phantoms and how to allocate space. We formulate the cost model for the multiple aggregation problem and propose a cost greedy algorithm to choose phantoms. In addition, for a given set of relations to instantiate, we analyze which space allocation gives the minimum cost; in case the optimal space allocation cannot be calculated, we propose heuristics which can approximate the optimal solution very well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM FORMULATION</head><p>In this section, we formulate our cost model, and give a formal definition of our optimization problem. We present hardness results, motivating the greedy heuristic algorithms for identifying optimal configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notation</head><p>When we have chosen a set of phantoms to instantiate in the LFTA, we call the set of instantiated relations (i.e., the chosen phantoms and user queries) as a configuration. For example, Figure <ref type="figure">3</ref> shows three configurations for an example query. While the feeding graph is a DAG, a configuration is always a tree, consistent with the path structure of the feeding graph. If a relation in a configuration is directly fed by the stream, we call it a raw relation. For example, ABC, BD, CD are raw relations in Figure <ref type="figure">3(a)</ref>; and ABCD is the only raw relation in Figure <ref type="figure">3(c</ref>). If a relation in a configuration has no child, then it is called a leaf relation or just leaf. User queries are always instantiated in the LFTA, therefore only queries are leaves. For all the configurations in Figure <ref type="figure">3</ref>, queries AB, BC, BD and CD are the leaves. Note that raw relations and leaf relations need not be mutually exclusive. For example, BD and CD are both raw and leaf relations in Figure <ref type="figure">3(a)</ref>.</p><p>We next develop our cost model, which determines the total cost incurred during data stream processing of a configuration. We then formalize the optimization problem studied in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cost Model</head><p>Recall that aggregation queries usually include a specification of temporal epochs of interest. For example, in the query "for every destination IP, destination port and 5 minute interval, report the average packet length", the "5 minute interval" is the epoch of interest. During stream processing within an epoch (e.g., a specific 5 minute interval), the aggregation query hash tables need to be maintained, for each record in the stream. At the end of an epoch, all the hash tables of the user queries at the LFTA need to be evicted to the HFTA to complete the user query computations. Thus, there are two components to the cost: intra-epoch cost, and end-of-epoch cost. We discuss each of these next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Intra-Epoch Cost</head><p>Let Em be the maintenance cost of all the hash tables during an epoch T (the maintenance cost for short). It includes updating all hash tables for the raw relations when a new record in the stream is processed. If (and only if) there is collision in hash tables for the raw relations, the hash tables of the relations they feed are updated. This process recurses until the hash tables for the leaf level. Each of these updates has a cost of c1.</p><p>If there are collisions in the hash tables for the leaf (user) queries, evictions to the HFTAs are incurred, each with the cost of c2. Therefore, the total maintenance cost is</p><formula xml:id="formula_4">Em = X R2I FRc1 + X R2L FRxRc2<label>(4)</label></formula><p>where I is a configuration, L is the set of all leaves in I, FR is the number of tuples fed to relation R during epoch T, and xR is the collision rate of the hash table for R. FR is derived as follows.</p><formula xml:id="formula_5">FR = nT if R 2 W Faxa else (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where W is the set of all raw relations, nT is the number of tuples observed in T, Fa is the number of tuples fed to the parent of R in I, and xa is the collision rate of the hash table for the parent of R in I. If we further define Fa = nT and xa = 1 , when R is a raw relation, Equation 4 can be rewritten as follows.</p><formula xml:id="formula_7">Em = 2 4 X R2I ( Y R 0 2A R x R 0 )c1 + X R2L ( Y R 0 2A R x R 0 )xRc2 3 5 nT (6)</formula><p>where AR is the set of all ancestors of R in I.</p><p>nT is determined by the data stream and is not affected by the configuration. Hence, the per record cost is:</p><formula xml:id="formula_8">em = X R2I ( Y R 0 2A R x R 0 )c1 + X R2L ( Y R 0 2A R x R 0 )xRc2<label>(7)</label></formula><p>where c1 and c2 are constants determined by the LFTA/HFTA architecture of the DSMS. Therefore, the cost is only affected by the feeding relationship and collision rates of the hash tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">End-of-Epoch Cost</head><p>Denote the update cost at the end of epoch T as Eu (the update cost for short). It includes the cost of the following operations.</p><p>From the raw level to the leaf level of the feeding graph of the configuration, we scan each hash table and propagate each item in the hash table to hash tables of the lower level relations they feed. Finally, we scan the leaf level hash table and evict each item in it to the HFTA, MH. Using an analysis similar to the one for intraepoch costs, taking the possibilities of collisions during this phase into account, the update cost Eu can be expressed as follows.</p><formula xml:id="formula_9">P R2I R 6 2W P R 0 2A R (M R 0 Q R 00 2A R 0 R 0 R 00 6 2W x R 00 )]c 1 + P R2L M R + P R 0 2A R (M R 0 Q R 00 2A R 0 R 0 R 00 6 2W x R 00 )]c 2 (8)</formula><p>where MR is the size of the hash table of relation R, and W is the set of all raw relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Our Problem</head><p>Intuitively, the lower the average per-record intra-epoch cost, the lower is the load at the LFTA, increasing the likelihood that records in the stream are not dropped during query processing. We also want to ensure that the total cost of the end-of-epoch processing is manageable. This leads to the multiple aggregation (MA) optimization problem studied for the two-level LFTA/HFTA architecture in this paper.</p><p>Consider a set of aggregation queries over a data stream that differ only in their grouping attributes, SQ = fQ1, Q2 : : : Q n Q g, and memory limit M in ML. Determine the configuration I, of relations in the feeding graph of SQ to instantiate in (the LFTA) ML and also the allocation of the available memory M to the hash tables or the relations so that the per-record intra-epoch cost (Equation 7) for answering all the queries is minimized, subject to the end-of-epoch cost being less than peak load cost Ep.</p><p>For the MA optimization problem we can show the following: THEOREM 1. Let n be the number of possible group-by queries in the feeding graph of SQ. If P 6 = N P , for every &gt; 0 every polynomial time approximation algorithm for the MA problem will have a performance ratio of at least n 1; . Moreover, the same is true for the corresponding maximization problem. Define the "benefit" of an aggregate in the feeding graph of SQ, as the cost improvement with respect to the solution that computes all aggregates in the LFTA. The maximization problem aims to identify the solution with the maximum benefit. It is possible to show that there does not exist a polynomial time algorithm for this problem with performance ratio better than n 1; , if P 6 = N P .</p><p>Our cost optimization problem consists of two sub-problems: how to choose phantoms and how to allocate space. Given the hardness result above, we next describe cost greedy algorithms to choose phantoms, based on the cost model presented earlier. The cost model critically depends on the collision rate model, which we discuss in detail in Section 4. For a given set of relations to instantiate, we analyze which space allocation gives the minimum cost, in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Algorithmic Strategies</head><p>The multi-aggregation (MA) problem has similarities to the view materialization (VM) problem <ref type="bibr" target="#b14">[14]</ref>. They both have a feeding graph consisting of nodes some of which can feed some others, and we need to choose some of them to instantiate. So one possibility is to adapt the greedy algorithm developed for VM to MA. However, there are two differences between these two problems. First, instantiation of any of the views in VM will add to the benefit; while in MA, instantiation of a phantom is not always beneficial. Second, the space needed for instantiation of a view is fixed but the hash table size is flexible. Therefore, in order to adapt the VM greedy algorithm, we need to have a space allocation scheme so that the hash tables must have low collision rate and therefore each instantiated phantom is beneficial. We discuss this next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Greedy by Increasing Space</head><p>The more space that is allocated to a hash table, the lower is the collision rate. On the other hand, the more groups a relation has for a fixed sized hash table, the higher is the collision rate. Let g be the number of groups in a relation. One way of allocating hash table space to a relation is proportional to the number of groups in the table. Thus, we can allocate space g for a relation with g groups. is a constant and we set it large so that the hash table is guaranteed to have a low collision rate. We will develop a model to estimate collision rate in Section 4. We can then have a better sense of what value of might be good according to the analysis there.</p><p>The greedy algorithm goes as follows. We calculate the benefit of each phantom according to the cost model, i.e., the difference between the maintenance costs without and with this phantom. Let us denote this benefit by bR. Then we calculate the benefit per unit space for each phantom R, bR=( ng R ). We choose the phantom with the largest benefit per unit space as the first phantom to instantiate. For the other phantoms, this process is iterated. The process ends when the benefit per unit space becomes negative, the space is exhausted, or all phantoms are instantiated.</p><p>This approach has two drawbacks: (1) needs to be tuned to find the best performance. A bad choice can result in suboptimal performance. ( <ref type="formula" target="#formula_2">2</ref>) By allocating space to a relation proportional to the number of its groups, we make the collision rates of all the relations the same. As we shall show later, this is not a good strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Greedy by Increasing Collision Rates</head><p>Here, we present a different greedy algorithm for allocating space to hash tables of the relations in the LFTA. Instead of allocating a fixed amount of space to each phantom progressively, we always allocate all available space to the current configuration (how to allocate space among relations in a configuration is analyzed in Section 5). So as each new phantom is added to a configuration, what changes is not the total space used, but the collision rate of each table. Since the more the number of groups mapped to a fixed space, the higher the collision rate, the collision rate would increase as new phantoms are instantiated.</p><p>The greedy algorithm is as follows. At first, the configuration I only includes all the queries. We calculate the maintenance cost if a phantom R is added to I. By comparing with the maintenance cost when R is not in I, we can get the benefit. After we add this phantom to I, we iterate with the other phantoms.</p><p>As more phantoms are added into I, the overall collision rate goes up and benefit decreases. We stop when the benefit becomes negative. This algorithm depends on estimating the collision rates. We derive a model to estimate the collision rate, in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE COLLISION RATE MODEL</head><p>In this section, we develop a model to estimate the collision rate. We assume that the hash function randomly hashes the data, so each hash value is equally possible for every record. We first consider uniformly distributed data, and subsequently consider when the data exhibits clusteredness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Randomly Distributed Data</head><p>Let g be the number of groups of a relation and b the number of buckets in the hash table. If k groups hash to a bucket, we say that this bucket has k groups. Let B k be the number of buckets having k groups. If the records in the stream are uniformly distributed, each group has the same expected number of records, denoted by nrg. So nrgk records will go to a bucket having k groups. Under the random hash assumption, the collision rate in this bucket is (1 ; 1=k). Therefore nrgk(1 ; 1=k) collisions happen in this bucket.</p><p>The overall collision rate is obtained by summing all the collisions and then dividing by the total number of records. Therefore, we have collision rate</p><formula xml:id="formula_10">x = g X k=2 B k nrgk(1 ; 1=k) gnrg = g X k=2 B k (k ; 1) g (9)</formula><p>k begins from 2 because when 0 or 1 group hashes to a bucket, no collision happens. In order to calculate it, we still need to know B k .</p><p>This problem belongs to a class of problems called the occupancy problem.</p><p>As we know, the expectation of k for each bucket is g=b <ref type="bibr" target="#b10">[10]</ref>. A rough estimation of B k based on expectation would be</p><formula xml:id="formula_11">B k = b k=g/b 0 k6 = g/b</formula><p>Substituting this for B k in Equation <ref type="formula">9</ref>, we get x = 1 ; b=g <ref type="bibr" target="#b10">(10)</ref> However, in a real random process, the probability of each bucket having the same number of groups is small. In <ref type="bibr" target="#b12">[12]</ref> (Chapter II.5), an example when g = b = 7 is given to calculate the probability of different distributions of groups. It is shown that probability of each of the 7 buckets having exactly 1 group is 0.006120, which makes it extremely unlikely. Therefore, we need to calculate B k based on probability. To the best of our knowledge, no study exists on estimating B k as we defined here. <ref type="foot" target="#foot_1">2</ref> Our derivation of Bi is as follows.</p><p>The probability of k groups out of g hashed to a given bucket is g k </p><formula xml:id="formula_12">! (1=b) k (1 ; 1=b) g;k<label>(11)</label></formula><p>buckets each of which has k groups. Substitute Equation 12 for B k in Equation <ref type="formula">9</ref>we have</p><formula xml:id="formula_14">x = b g X k=2 g k (1=b) k (1 ; 1=b) g;k (k ; 1) g<label>(13)</label></formula><p>Our experiments on both synthetic and real data show that the actual distribution of B k matches Equation <ref type="formula" target="#formula_14">13</ref>well, even though the buckets are not completely independent (they satisfy the equation</p><formula xml:id="formula_15">P b k=1 B k = b).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Validation of Collision Rate Model</head><p>We have measured experimentally the collision rates on both synthetic random datasets and real datasets. The results for the real datasets are shown in Figure <ref type="figure" target="#fig_5">5</ref>; the results for the synthetic datasets are very similar and omitted. are called occupancy numbers. This problem has been studied before and the Bi's follow the multinomial distribution <ref type="bibr" target="#b12">[12]</ref> (Chapter VI.9). However, our definition of B k is different from Bi. Instead of the probability of a certain arrangement of the "balls" in the buckets, what we want is the distribution of the "balls". The real datasets are extracted from the netflow dataset as described in Section 6.1. We have assumed random data distribution for the above analysis, while the netflow dataset has a lot clusteredness of multiple packets in a flow. In order to validate our analysis using the real data, we grouped all packets of a flow into a single record, eliminating the effect of clusteredness. (We consider clusterness in a later subsection.) After eliminating clusteredness of the data, we extracted 4 datasets which have 1, 2, 3 and 4 attributes respectively. The number of groups in these datasets are 552, 1846, 2117, 2837 respectively.</p><p>The "rough model" curve is plotted according to Equation 10 and the "precise model" curve is plotted according to Equation <ref type="formula" target="#formula_14">13</ref>. Collision rates of the real data match the precise model very well. In all the observed collision rates, more than 95% of the experimental results have less than 5% difference from the precise model. The rough model differs greatly from the precise model when g=bis small but becomes similar as g=bgets large. The reason is that the rough model only captures the expected case, which occurs with low probability. When g becomes larger, the behavior gets closer to the average case, therefore the rough model gets close to the precise model.</p><p>For the rough model, the collision rate is only dependent on the ratio of g to b as we can see from Equation <ref type="formula">10</ref>. We will show in Section 4.4 that the precise model is also dependent on g=b, though the function is different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Clustered Data</head><p>The above analysis was for randomly distributed data. However, real data streams, especially the packets in netflow data (which have exactly the same values for attributes such as source/destination IP/port), are clustered. Although packets from different flows are interleaved with each other in the stream, the likelihood of these interleaved flows hashing to the same bucket is very small. Therefore we can think of the packets in a flow going through a bucket without any collision until the end of the flow. To analyze collision rate for such clustered distributions, we should consider what happens at the per flow level. If we think of each flow as one record, then we can use the same formula as in the random distribution (Equation <ref type="formula">9</ref>) to calculate the total number of collisions as follows.</p><formula xml:id="formula_16">nc = g X k=2 B k n f g k(1 ; 1=k)<label>(14)</label></formula><p>where n f g is the number of flows in each group; B k is still calculated by Equation <ref type="formula" target="#formula_13">12</ref>. To obtain the collision rate, we divide nc by the total number of records, gn f g la, where la is the average length of all the flows. Then we have the collision rate for the data with a clustered distribution as follows. We can see that the difference of the collision rate on data with clusteredness from that of the random data is a linear relationship over average flow length la. We can view the collision rate of the random data as a special case of clustered data with la = 1 . The average flow length can be computed by maintaining the number of times hash table bucket entries are updated before being evicted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">On Computing Collision Rates</head><p>To calculate the collision according to Equations 13 and 15, we need to compute a sum of about g items, which can be hundreds to thousands of items. This computation is expensive. In this section, we show that actually we only need to sum up to a much smaller number of items. Further, the collision rate is almost solely dependent on g=b, therefore we can pre-compute the collision rates and store them as a function of g=b. In this way, the computational effort of collision rates is greatly reduced.</p><p>We computed the probability of collision of different k's according to Equation 13 to see how much each component contributes to the overall collision rate. Figure <ref type="figure">6</ref> shows the probability of collision as a function of k when g = 3000 and b = 1000. We can see that the contributions become almost 0 when k becomes larger than 11 and the shape of the curve looks like a bell. It looks like the PDF of the Gaussian distribution. Examining Equation <ref type="formula" target="#formula_14">13</ref>, we find that except the (k ; 1) part and b=g which is a constant, the rest are the same as the PDF of the binomial distribution. And the binomial distribution can be approximated by the Gaussian distribution. So the plots of the collision probability of different k components can be viewed as a Gaussian distribution with an amplitude of k ; 1.</p><p>That's why the plot mimics the Gaussian distribution. Given its similarity, we can understand many features of the plots according to characteristics of the Gaussian distribution. The peak of the plot appears at approximately the mean, which is = g=b= 3 (the actual maximum in Figure <ref type="figure">6</ref> appears at k = 4 due to the effect of the amplitude k ; 1). Also we know that the probability in the interval (;1 + 3 ] is 99.7%. So when we calculate the collision rate, we do not need to sum over all values of k but up to + 3 is enough, where = p g(1 ; 1=b)=b. In case of Figure <ref type="figure">6</ref>, 2:997 = 8:2. In Figure <ref type="figure">6</ref>, the component at k = 8 is as small as 0.02 already. It is not 0 yet due to the amplitude k ; 1, so we can calculate up to several more say + 5 , which is 12 in our case. The components after 12 are almost 0, and 12 is much smaller than 3000 (the number of groups). The cost of computing collision rates can be further reduced. A Gaussian distribution is determined by and 2 . Here we just want the sum, so we don't care about (the mean) but only As our sum is not exactly a Gaussian distribution, some errors are expected. In the following, we experimentally evaluate how much the errors are. We let g=bbe certain constants and compute the collision rates according to Equation <ref type="formula" target="#formula_14">13</ref>, for b varied from 300 to 3000. Note that once b is chosen, g is also determined for a given g=b. The resulting collision rate, for g=bvaried from 0.25 to 32, is almost constant for the same g=b. The maximum relative variations of collision rates as g=bvaries are listed in Table <ref type="table" target="#tab_0">1</ref>. We observe that all the variations are less than 1.5%. Therefore the collision rate only depends on g=band we can pre-compute collision rate and use regression to model the function.</p><formula xml:id="formula_17">+ 3 = 3 + 3</formula><p>The collision rate curve as a function of g=bis plotted in Fig- <ref type="figure">ure 7</ref>. We divided the whole curve into 6 intervals and used twodimensional regression to simulate the curve so as to achieve a maximum relative error of 5% in each interval. The average relative error is actually much lower, which is less than 1%.</p><p>According to our previous analysis, the hash table must have a low collision rate if we want to benefit from maintaining phantoms. Therefore, we examine the low collision rate part of this curve closely. A zoom in of the collision rate curve when collision rate is smaller than 0.4 as well as a linear regression of this part is shown in Figure <ref type="figure" target="#fig_9">8</ref>. We observe that this part of the curve is almost a straight line and the linear regression achieves an average error of 5%. The linear function for this part is x = 0 :0267 + 0:354 (g =b) <ref type="bibr" target="#b16">(16)</ref> Expressing this part of the collision rate linearly is important for the space allocation analysis as we will see in Section 5. In addition, since we now know how the collision rate is determined, we can suggest values of to use in the adapted greedy algorithm (by increasing space) of Section 3.4. For example, = 1 could be a good choice, since it corresponds to a collision rate of about 0.37.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">SPACE ALLOCATION</head><p>In this section, we consider the problem of space allocation, that is, given a configuration of certain relations (phantoms and queries) to be instantiated, how to allocate the available space M to their hash tables so that the overall cost is minimized. We start with a simple two-level configuration in Section 5.1, and identify the difficulties in analyzing more complex configurations. Heuristics for space allocation are discussed in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">A Case of Two Levels</head><p>We first study the case when there is only one phantom R0 and it feeds all f queries, R1, R2, . . . , R f . Let x0 be the collision rate of the phantom, x1, x2, . . . , x f be the collision rate of the queries.</p><p>In order to benefit from maintaining a phantom, its collision rate must be low, therefore we only care about the low collision rate part of the collision rate curve. According to Section 4.4, this part of the curve can be expressed as a linear function x = + g=b, where =0.0267 and =0.354. 3 Since is small, here we make a further approximation to let x = g=b. We will discuss later how the results are affected when we consider . Given the approximation, xi = gi=bi, i = 0 1 ::: f. The total size is M, so M = P f i=0 bi. The cost of this configuration is</p><formula xml:id="formula_18">e = c 1 + f x 0 c 1 + x 0 f X i=1 x i c 2 = f g 0 b 0 c 1 + g 0 b 0 f X i=1 g i b i c 2 + c 1 = g 0 b 0 (f c 1 + c 2 f X i=1 g i b i ) + c 1 = g 0 M ; f X i=1 b i (f c 1 + c 2 f X i=1 g i b i ) + c 1<label>(17)</label></formula><p>e is a function of multiple variables, b1 b 2 : : : b f . To find out the minimum, we equate the partial derivatives of e to 0. In the following, we calculate the partial derivative of e over bi, i = 1 2 :::f. @ e @ b i = g 0</p><formula xml:id="formula_19">(M ; f X i=1 b i ) 2 (f c 1 + c 2 f X i=1 g i b i ) + g 0 M ; f X i=1 b i c 2 g i (; 1 b 2 i ) Let @e @b i = 0 , then g 0 M ; f X i=1 b i 0 B B B B B @ f c 1 + c 2 f X i=1 g i b i M ; f X i=1 b i ; c 2 g i b 2 i 1 C C C C C A = 0 g 0 M; P f i=1 b i is non-zero, so f c 1 + c 2 f X i=1 g i b i M ; f X i=1 b i = c 2 g i b 2 i (<label>18</label></formula><formula xml:id="formula_20">)</formula><p>3 Actually, even if the collision rate for the optimal allocation is a little higher than 0.4, we can still use linear regression for that part. The values of and would be a little different, but experiments show that small variation in their values does not affect the result much.</p><p>for i = 1 2 : : : f . Observe that left hand side of the equation is the same for any i.</p><p>So we have</p><formula xml:id="formula_21">g 1 b 2 1 = g 2 b 2 2 = ::: = g f b 2</formula><p>f that is, bi is proportional to p g i . Let bi = p g i , i = 1 2 : : : f . Substituting this for bi in Equation 18, we have</p><formula xml:id="formula_22">c 2 M 2 ; 2 c 2 f X i=1 p g i ; f c 1 = 0 (19)</formula><p>This is a quadratic equation over . Solving it we have</p><formula xml:id="formula_23">= c 2 f X i=1 p g i v u u t 2 c 2 2 ( f X i=1 p g i ) 2 + f c 1 c 2 M c 2 M</formula><p>&gt; 0, so only the one with "+" before the square root on the numerator is the solution. So</p><formula xml:id="formula_24">b i = p g i = c 2 M p g i c 2 f X j=1 p g j + v u u u t 2 c 2 2 ( f X j=1 p g j ) 2 + f c 1 c 2 M = M f X j=1 p g j p g i + v u u u u u u u u t 0 B B B B B @ f X j=1 p g j p g i 1 C C C C C A 2 + f c 1 M c 2 g i (<label>20</label></formula><formula xml:id="formula_25">)</formula><p>where i = 1 2 : : : f .</p><formula xml:id="formula_26">b 0 = M ; P f i=1 b i = M ; M f X j=1 p g j f X j=1 p g j + v u u u t( f X j=1 p g j ) 2 + f c 1 M c 2<label>(21)</label></formula><p>A key consequence of our analysis is that we should allocate space proportional to the square root of the number of groups in order to achieve the minimum cost. Another interesting point is that b0 (the space allocated to the hash table of the phantom) always takes more than half the available space.</p><p>While the 2-level case results in a quadratic equation (that is, Equation <ref type="formula">19</ref>), a similar analysis on the simplest 3-level case results in an equation of order 8. According to Abel's impossibility theorem, equations of order higher than 4 cannot be solved algebraically in terms of a finite number of additions, subtractions, multiplications, divisions, and root extractions (in the sequel, we simply say "unsolvable"). More general multi-level configurations generate equations of even higher order which are unsolvable, therefore we would use heuristics to decide space allocation for the these unsolvable cases based on the analysis available. Experiments show that our proposed heuristics based on the analysis are very close to optimal and better than other heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Heuristics</head><p>For unsolvable configurations, we propose heuristics to allocate space based on the analysis of the solvable cases and partial results we can get from the unsolvable cases. We observe that while b 2 i (bi is a leaf relation) is proportional to c2gi, which is affected by its own number of groups, according to our analysis on the three level case, b 2 1 (b1 is a non-leaf relation) is proportional to d g1c1 + g1c2 P d i=1 x1i (note that g=b = x), where x1i are the collision rates of tables for the children of b1. b1 is affected not only by its own number of groups, but also its children's. The intuition is that we should care more about a relation when it has children in the feeding graph of the configuration. Therefore we will consider the following space allocation schemes which add some weights to a relation when it has children to feed.</p><p>Heuristic 1: Supernode with Linear Combination (SL). We start from the leaf level of the configuration. Each phantom at the record level together with all its children are viewed as a supernode. The number of groups of this supernode is the sum of the number of groups of the phantom and all its children. Then we view the supernode as a query and do the above compaction recursively until the configuration become all queries. For the all query configuration, we can allocate space optimally. After this allocation, each query (some may be supernodes) has some space. We decompose a supernode to a two-level structure and allocate space according to the analysis of Section 5.1, that is, allocate space proportional to the square root of the number of groups. If there are still supernodes in the structure, we do the decomposition recursively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristic 2: Supernode with Square Root Combination (SR).</head><p>This heuristic is the same as SL except the calculation of the group of the supernode. Since in the two level case we see that the space should be proportional to the square root of the number of groups, we can also let the square root of the number of groups of the supernode be the sum of the square roots of all its relations.</p><p>Note that both SL and SR give the optimal result for the case of one phantom feeding all queries. We will also try two other simple heuristics which are not based on our analysis as a comparison to the above two more well-founded heuristics.</p><p>Heuristic 3: Linear Proportional Allocation (PL). This heuristic simply allocates space to each relation proportional to the number of groups of that relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristic 4: Square Root Proportional Allocation (PR)</head><p>. This heuristic allocates space to each relation proportionally to the square root of the number of groups of that relation.</p><p>Although we cannot compute the optimal solution for space allocation of some cases, there does exist a space allocation which gives the minimum cost for each configuration. One way to find this optimal space allocation is to try all possibilities of allocation of space at certain granularity. For example, if the configuration is AB feeds A and B, and total space is 10, we can first allocate 1 to AB, 1 to A, and 8 to B. Then we try 1 to AB, 2 to A, and 7 to B, and so on. By comparing the cost of all these space allocation choices we will find the optimal one. We call this method the exhaustive space allocation (ES). Obviously this strategy is too expensive to be practical, but we use it in our experiments to compare with the four space allocation schemes and see how much the heuristics differ from the optimal choice. The results of ES are affected by the granularity of varying the space allocation. In our experiments, we found that using a granularity of 1% of M is small enough to provide accurate results.</p><p>The space allocation schemes are independent of the phantom choosing strategies, that is, given a configuration, a space allocation scheme will produce a space allocation no matter in what order the relations in the configuration are chosen. Therefore we will evaluate space allocation schemes and phantom choosing strategies independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Revisiting Simplifications</head><p>From the beginning of the analysis on space allocation, we have made an approximation on the linear expression of the collision rate, that is, we let x equal g=b instead of + g=b. We also did the analysis when we let x = + g=b. The result of the case with no phantom is the same. The case with one phantom feeding all queries results in a quartic equation which can be solved, so we can still get an optimal solution for this case. However, because solving a quartic equation is much more complex than a quadratic equation and it's more involved to decide which solution of the quartic equation is the one we want, we use the approximated linear expression, that is, x = g=b for space allocation in our experiments. The results of the experiments show that they have good accuracy.</p><p>We have made another simplification on the size of each hash table bucket entry in the analysis for ease of exposition. By using M = P bi, we have assumed that a hash table entry has the same size for all relations in the LFTA. Actually, the size of a hash table entry for different relations can vary a lot. Suppose we use an int (4 byte) to represent each attribute or a counter. Then a bucket for relation A takes 8 bytes and a bucket for ABCD takes 20 bytes.</p><p>If we denote the bucket entry size of relation i as hi, then M = P bihi. In this case, the results of the analysis are similar. Instead of allocating space proportional to p g, we should allocate space proportional to p gihi. We have used such variable sized buckets in our implementation, and experimental study, discussed next.</p><p>For clustered data, collision rates should be divided by the average flow length la. To consider this in space allocation, we should allocate space proportional to p gihi=li, where li is the average flow length of relation i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTAL STUDY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup and Datasets</head><p>We prototyped this framework in C in order to evaluate the different techniques we developed. We use 4 bytes as our unit of space allocation. Each attribute value and counter we instantiate has this size. In accordance to operational streaming data managers <ref type="bibr" target="#b8">[8]</ref>, we consider M between 20,000 and 100,000 units of space (4 bytes each). The ratio of eviction cost to probe cost c2=c1 is is modeled as 50 in our experiments, which is also a ratio measured in operational data stream management systems <ref type="bibr" target="#b8">[8]</ref>.</p><p>We used both synthetic and real datasets in our evaluation. The real dataset is obtained by tcpdump on a network server. We extracted TCP headers obtaining 860,000 records with attributes source IP, destination IP, source port and destination port, each of size 4 bytes. The duration of all these packets is 62 seconds. There are 2837 groups in this 4-attribute relation. For other relations we extracted in this way, the number of groups varies from 552 to 2836. For the synthetic datasets, we generated 1,000,000 3 and 4 dimensional tuples uniformly at random with the same number of groups as those encountered in real data. All the experiments are run on a desktop with Pentium4 2.6GHz CPU and 1GB RAM.</p><p>We adopt the following way to specify a configuration. "AB(A B)" is used to denote a phantom AB feeding A and B. We use this notation recursively. For example, the configuration in Figure <ref type="figure">3(c</ref>) can be expressed as (ABCD(AB BCD(BC BD CD))). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation of Space Allocation Strategies</head><p>Our first experiment aims to evaluate the performance of various space allocation strategies. In these experiments we derive our parameters from the real data set. Our observations were consistent across a large range of real and synthetic datasets. We vary M from 20,000 to 100,000 at steps of 20,000 and the granularity for increasing space while executing ES is set at 1% of M. In all experiments we compute the cost using Equation <ref type="formula" target="#formula_8">7</ref>with a suitable model for collision rate, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Solvable Configurations</head><p>We first experimentally validate the results of our analysis for the case of configurations for which we can analytically reason about the goodness of space allocation strategies.</p><p>For the case with no phantoms, (assuming x = g=b as collision rate) we compared the cost of the exhaustive space allocation (ES) with a scheme that allocates space according to our analytical expectations, namely, allocating space proportional to the square root of number of groups. For the case of real data, we tested all possible configurations with no phantoms. The cost obtained by the scheme performing space allocation as dictated by our analytical derivations incurred an error less than 1% compared to ES. The small error comes from our approximation to the collision rate, especially the value of , which can be different from the value the optimal solution assumes.</p><p>For the case with only one phantom feeding all queries, we use our optimal space allocation scheme derived based on the approximation of collision rate x by g=b. We again compare the accuracy of the space allocation scheme allocating space according to our analysis, to that of ES and test all possible configurations for the case of the real data set. The average cost error (compared to ES) of our scheme is usually less than 1% and the maximum observed was 2%. Therefore even with this approximation (x = g=b) to the collision rate, the results are still quite accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Unsolvable Configurations</head><p>For unsolvable configurations, we evaluated several heuristics. We compared SL, SR, PL, PR as described in Section 5.2 and ES. We evaluated all possible configurations for the case of the real data set (four attributes). The relative errors of the heuristics compared to the cost of ES are shown in Figures 9 and 10 for 4 representative configurations. Related results were obtained for other configurations; all those are summarized in Table <ref type="table">2</ref>.</p><p>We observe that generally SL and SR are better than PL and PR. Thus, heuristics inspired by our analytical results appear beneficial.</p><p>Except one case in Figure <ref type="figure" target="#fig_11">10</ref>(a) when M = 2 0 000, SL is always the best. PL and PR can have errors as large as 35% and although SR has smaller error, it is always less accurate than SL. In Table <ref type="table">2</ref>, we show the average relative error of the four different heuristics compared to ES. SL is the best for all values of M.</p><p>In Table <ref type="table" target="#tab_2">3</ref>, we accumulate statistics in order to show in all con-  Table <ref type="table">2</ref>: Average error for the four heuristics figurations tested how frequently SL is the heuristic yielding the minimum error. We preset the percentage of configurations tested in which SL yields minimum error, as well as for the cases that SL does not yield the minimum error, how far its error is from the error of the best heuristic, on the average. These results (which are representative of a large set of experiments conducted) attest that SL behaves very well across a wide range of configurations. Even in the cases that it's not the best it remains highly competitive to the best solution. Therefore we would choose SL for space allocation in our algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation of the Greedy Algorithms</head><p>We now turn to the evaluation of algorithms to determine beneficial configurations of phantoms. We will evaluate the greedy algorithm GS and our proposed greedy algorithm GC. GC makes use of the SL space allocation strategy; we refer to this combination as GCSL (algorithm GC using SL space allocation). For GS, we would add space of g each time a phantom is added in the current configuration under consideration until there is not enough space for any additional phantom to be considered. At this point we allocate the remaining space to relations already in the configuration proportional to their number of groups. We also consider the following method to obtain the optimal configuration cost. We explore all possible combinations of phantoms and for each configuration we use exhaustive space (ES) allocation to calculate the cost, choosing the configuration with the minimum overall cost. We will refer to this method as EPES in the sequel. Costs are computed using Equation 7 and our approximation to the collision rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Phantom Choosing Process</head><p>We first look at the query set fA, B, C, Dg on a 4-dimensional uniform random dataset with M set as 40,000. Since a good value of is not known a priori, we vary it and observe the trends. Figure <ref type="figure" target="#fig_1">11</ref> presents the cost of the different algorithms. The costs are normalized by the cost of EPES (the optimal cost). The cost of GS first decreases and then increases, as increases. If is too small, each phantom is allocated a small amount of space, at the expense of high collision rate.  phantom has low collision rate, but each phantom takes too much space and prohibits addition of further phantoms, which could be beneficial. This alludes to a knee in the cost curve signifying the existence of an optimum value. For the GCSL algorithm, cost is lower than the cost of GS for any , because when we adjust the space allocation and calculate the cost each time a phantom is added, we are essentially adapting to a better value. The gap between the minimum point of the GS curve and GCSL is due to the space allocation scheme. Using GC in conjunction with PL space allocation, yields a curve which precisely lower bounds GS. Thus, GCSL benefits from both the way we choose phantoms and the way space is allocated in these phantoms.</p><p>Figure <ref type="figure" target="#fig_12">12</ref> presents the change in the overall cost in the above scenario as each phantom is chosen. We observe that the first phantom introduces the largest decrease in cost. The benefit decreases as more phantoms are added and for GS with = 0:6, the cost goes up when adding the third phantom. Note that the third phantom added by GS with = 0 :6 is different from the third phantom added by GCSL due to the differences in space allocation. For GS with = 1 :2 1:3 there is no space to add more than one phantom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Validating Cost Estimation Framework</head><p>With our next experiment we wish to validate our cost estimation framework against the real measured errors. We implemented the hash tables and we let a uniform random dataset pass through the phantoms and queries computing the desired aggregates. The phantoms are chosen and the corresponding space allocation is conducted, using our heuristics. We count the collisions in the hash tables and calculate the true cost of this configuration. We normalize the actual cost of GCSL and GS by the actual cost of the optimal (according to our cost model) configuration obtained by EPES; the relative actual costs are shown in Figure <ref type="figure">13(a)</ref>. For GS, we tried different values, and only the one with the lowest cost at each value of M is presented in the figure . 
We can see that the actual cost of GCSL is always much lower than that of GS, even we could always choose the best for GS (which is impossible in practice). When M=60,000, the cost of GCSL is as low as 26% of the cost of GS. While GS can have cost as high as 6 times the optimal cost, GCSL is always within 3 times the optimal cost. We conducted a large set of experiments quantifying the accuracy of our estimation framework against actual measurements. In general, difference between the predictions of the cost model and the actual cost becomes large as M increases. The relative cost difference of GCSL compared to the optimal cost also increases as M increases. This is due to two factors: first when M is very large then collision rates are very small and become increasingly difficult to capture analytically. Second, for large M there are many phantom levels and as a result errors accumulate across multiple levels. However, despite certain inaccuracy, our technique results in a reasonable low cost compared to the optimal cost and outperforms GS considerably, for a variety of data sets, especially for low values of M (which is the common case in practice).</p><p>In order to validate the effectiveness of phantoms for computing multiple aggregates, we conducted the following experiment. We run the same queries without maintaining any phantoms and we compare the cost with the cost of GCSL. The results are presented in Figure <ref type="figure">13</ref>(b). It is evident that maintaining phantoms does reduce the cost greatly (more than an order of magnitude).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Experiments with Real Data</head><p>We repeated our validation experiment using real data this time and the query set fAB, BC, BD, CDg. Again we let the real data set stream by the configuration we have obtained using our algorithms and report the resulting actual costs incurred. Once again actual costs are normalized by the actual cost incurred by the EPES strategy. Flow length is derived temporally.</p><p>Figure <ref type="figure" target="#fig_13">14</ref>(a) presents the results. It is evident that GCSL outperforms GS. Once again we compare the cost of GCSL and the cost incurred without the maintenance of any phantoms. GCSL offers an improvement up to about 100 compared to the cost incurred without the use of phantoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.4">Peak Load Constraint</head><p>The update cost at the end of epoch as described in Section 3.2.2 can be calculated according to Equation <ref type="formula">8</ref>. This update cost must be within the peak load constraint Ep. If the update cost Eu exceeds Ep, we can use two methods to resolve it: shrink and shift.</p><p>The shrink method shrinks the space of all hash tables proportionally. The shift method shifts some space from queries to phantoms BC, BD, CDg, given a space allocation, we calculate its Eu; then we set Ep to a percentage of Eu and use the two methods to reallocate space. After the reallocation, we run the data through the configuration and we compute the cost when M = 4 0 000. The results are in Figure <ref type="figure" target="#fig_14">15</ref>. When Ep is not much smaller than Eu, the shift method performs better; while when Eu is much larger than Ep, the shrink method performs better. The reason is that when Eu is close to Ep, a small shift to reduce Eu suffices. When Eu and Ep differ by much, a major shift in space results in non optimal space allocation and thus shrink is better. Similar behavior is observed when M is set as other values.</p><p>In terms of the performance of our algorithms, the running time of GCSL in all configurations we tried was sub-millisecond; we don't expand further due to space limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RELATED WORK</head><p>Our problem is closely related to the problem of multi-query optimization, i.e., optimizing multiple queries for concurrent evaluation. This problem has been around for a long time, and several techniques for this problem have been proposed in the context of a conventional DBMS (see, e.g., <ref type="bibr" target="#b18">[18]</ref>). The basic idea of all these techniques is the identification of common query sub-expressions, whose evaluation can be shared among the query execution plans produced. This is also the basis for sharing of filters in pub-sub systems (see, e.g., <ref type="bibr" target="#b11">[11]</ref>). Our technique of sharing computation common to multiple aggregation queries is based on the same idea.</p><p>Our problem also has similarities to the view maintenance problem, which has been studied extensively in the literature (see, e.g., <ref type="bibr" target="#b13">[13]</ref>). In this context, Ross et al. <ref type="bibr" target="#b17">[17]</ref> have studied the problem of identifying, in a cost-based manner, what additional views to materialize, in order to reduce the total cost of view maintenance. Our idea of additionally maintaining phantoms, and choosing which phantoms to maintain, to efficiently process multiple aggregations is based on the same conceptual idea.</p><p>Many papers (see, e.g., <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b5">5]</ref>) have highlighted the importance of resource sharing in continuous queries. <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b16">16]</ref> use variants of predicate indexes for resource sharing in filters in continuous query processing systems. In the context of query processing over data streams, Dobra et al. <ref type="bibr">[9]</ref> consider the problem of sharing sketches for approximate join-based processing. <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b2">2]</ref> consider the problem of resource sharing when processing large numbers of sliding window aggregates over data streams. However, none of these papers proposed the maintenance of additional queries to improve the feasibility of resource sharing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>Monitoring aggregates on IP traffic data streams is a compelling application for data stream management systems. Evaluating mul-tiple aggregations in a two level DSMS architecture is an important practical problem. We introduced the notion of phantoms (finegranularity aggregation queries) that has the benefit of supporting shared computation. We formulated the MA optimization problem, analyzed its components and proposed greedy heuristics which we subsequently evaluated using real and synthetic data sets to demonstrate the effectiveness of our techniques.</p><p>We are currently considering deploying this framework in a real DSMS system. This raises important research questions at the system level, in terms of interaction of such algorithms with the current system, studying issues related to adaptivity and frequency of execution, etc. We hope to report such results in the near future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>17</head><label>17</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 MFigure 1 :</head><label>11</label><figDesc>Figure 1: Single aggregation in Gigascope</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Multiple aggregations using phantoms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 3: Choices of phantoms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Note this holds for any bucket, which means each bucket has the chance of Equation 11 to have k groups. If we assume that all b buckets are independent of each other, then statistically there are b g k ! (1=b) k (1 ; 1=b) g;k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Collision rates of real data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 6: Probability of collision vs. k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The low collision rate part</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Comparison of space allocation schemes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Comparison of space allocation schemes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Phantom choosing process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 14 :</head><label>14</label><figDesc>Figure 13: Comparison on synthetic dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Peak load constraint</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Variations of the collision rate</head><label>1</label><figDesc>2 , which equals g(1 ; 1=b)=b. b in the data stream case is usually several</figDesc><table><row><cell>g=b</cell><cell cols="2">0.25</cell><cell></cell><cell>0.5</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>8 16 32</cell></row><row><cell>variation(%)</cell><cell></cell><cell>1.4</cell><cell></cell><cell cols="4">0.43 0.15 0.03 0.004 0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>collision rate</cell><cell>0.4 0.5 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>5</cell><cell cols="4">10 15 20 25 30 35 40 45 50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>g/b</cell><cell></cell></row><row><cell></cell><cell cols="7">Figure 7: The collision rate curve</cell></row><row><cell cols="8">hundred to thousands, therefore 1 ; 1=b is almost 1 and the sum is essentially determined by g=b.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 : Statistics on SL</head><label>3</label><figDesc>On the other hand, if is too large, each</figDesc><table><row><cell>M (thousand)</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell cols="2">80 100</cell></row><row><cell>SL being best (%)</cell><cell>44</cell><cell>89</cell><cell>89</cell><cell cols="2">89 100</cell></row><row><cell cols="5">Relative error from the best (%) 2.2 0.006 0.15 0.6</cell><cell>0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>FTA stands for "Filter, Transform, Aggregate".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>If we use Bi to denote the number of balls in the i-th bucket, Bi</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">STREAM: The Stanford stream data manager</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arasu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="26" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Resource sharing in continuous sliding-window aggregates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Models and issues in data stream systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Babcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Monitoring streams -a new class of data management applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Carney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">TelegraphCQ: Continuous dataflow processing for an uncertain world</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chandrasekaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Streaming queries over streaming data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">NiagaraCQ: A scalable continuous query system for internet databases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gigascope: A stream database for network applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cranor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Spatscheck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shkapenyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sketch-based multi-query processing over data streams</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dobra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Garofalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rastogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Probability and statistics: an undergraduate course</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dwass</surname></persName>
		</author>
		<editor>W. A. Benjamin</editor>
		<imprint>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Filtering algorithms and implementation for very fast publish/subscribe</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fabret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An introduction to probability theory and its applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968">1968</date>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<biblScope unit="volume">I</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Maintenance of materialized views: Problems, techniques and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Mumick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1995-06">June 1995</date>
		</imprint>
	</monogr>
	<note>Special Issue on Materialized Views and Data Warehousing</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Implementing data cubes efficiently</title>
		<author>
			<persName><forename type="first">V</forename><surname>Harinarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data stream query processing: A tutorial</title>
		<author>
			<persName><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Continuously adaptive continuous queries over streams</title>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Raman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Materialized view maintenance and integrity constraint checking: Trading space for time</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sudarshan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multiple query optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TODS</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="52" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tribeca: A system for managing large databases of network traffic</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heybey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
